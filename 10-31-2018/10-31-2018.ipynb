{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing: Feasture Scaling\n",
    "\n",
    "1. Rescaling Data\n",
    "2. Normalizing Data\n",
    "3. Standardizing Data\n",
    "\n",
    "[More Information](https://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/)\n",
    "\n",
    "\n",
    "[Data Description](https://www.kaggle.com/uciml/pima-indians-diabetes-database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.353 0.744 0.59  0.354 0.    0.501 0.234 0.483]\n",
      " [0.059 0.427 0.541 0.293 0.    0.396 0.117 0.167]\n",
      " [0.471 0.92  0.525 0.    0.    0.347 0.254 0.183]\n",
      " [0.059 0.447 0.541 0.232 0.111 0.419 0.038 0.   ]\n",
      " [0.    0.688 0.328 0.354 0.199 0.642 0.944 0.2  ]]\n"
     ]
    }
   ],
   "source": [
    "# Rescale data (between 0 and 1)\n",
    "import pandas\n",
    "import scipy\n",
    "import numpy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataframe = pandas.read_csv(\"./files/prims.csv\")\n",
    "array = dataframe.values\n",
    "\n",
    "X = array[:,:8]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX=scaler.fit_transform(X)\n",
    "\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.034 0.828 0.403 0.196 0.    0.188 0.004 0.28 ]\n",
      " [0.008 0.716 0.556 0.244 0.    0.224 0.003 0.261]\n",
      " [0.04  0.924 0.323 0.    0.    0.118 0.003 0.162]\n",
      " [0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139]\n",
      " [0.    0.596 0.174 0.152 0.731 0.188 0.01  0.144]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data (length of 1)\n",
    "#Normalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 (called a unit norm in linear algebra).\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "dataframe = pandas.read_csv(\"./files/prims.csv\")\n",
    "array = dataframe.values\n",
    "\n",
    "X = array[:,0:8]\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(normalizedX[0:5,:])\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.646  0.853  0.16   0.912 -0.692  0.215  0.448  1.433]\n",
      " [-0.841 -1.104 -0.147  0.538 -0.692 -0.666 -0.371 -0.18 ]\n",
      " [ 1.241  1.941 -0.25  -1.272 -0.692 -1.081  0.581 -0.095]\n",
      " [-0.841 -0.98  -0.147  0.163  0.122 -0.477 -0.917 -1.03 ]\n",
      " [-1.138  0.511 -1.479  0.912  0.763  1.411  5.375 -0.011]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "\n",
      "[[-0.543  0.045  0.365  0.413  1.04   0.505  0.021 -0.605]\n",
      " [ 0.646  0.139  0.467  0.663 -0.692 -0.54   0.264  1.348]\n",
      " [-0.841  1.475  0.979  0.538 -0.692  0.391  1.273  1.603]\n",
      " [-0.543  0.263 -3.527 -1.272 -0.692  0.832 -0.51   0.669]\n",
      " [ 0.051 -0.328  0.365 -0.024  0.174 -0.439 -1.062 -0.52 ]]\n",
      "[1.016 0.907 0.879 0.937 0.966 0.892 0.764 0.971]\n"
     ]
    }
   ],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "# Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "\"\"\"\n",
    "scaled_train =  (train - train_mean) / train_std_deviation\n",
    "scaled_test = (test - train_mean) / train_std_deviation\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "dataframe = pandas.read_csv(\"./files/prims.csv\")\n",
    "array = dataframe.values\n",
    "\n",
    " \n",
    "X = array[:700,:8]\n",
    " \n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])\n",
    "\n",
    "std = numpy.std(rescaledX,axis=0)\n",
    "print(std)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "test=scaler.transform(array[700:,:8])\n",
    "\n",
    "print(test[0:5,:])\n",
    "\n",
    "std = numpy.std(test,axis=0)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network \n",
    "\n",
    "## Feedforward\n",
    "\n",
    "[Code](https://enlight.nyc/projects/neural-network/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output: \n",
      "[[0.528]\n",
      " [0.499]\n",
      " [0.609]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# X = (hours sleeping, hours studying), y = score on test\n",
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "\n",
    "# scale units\n",
    "X = X/np.amax(X, axis=0) # maximum of X array\n",
    "y = y/100 # max test score is 100\n",
    "\n",
    "class Neural_Network(object):\n",
    "  def __init__(self):\n",
    "    #parameters\n",
    "    self.inputSize = 2\n",
    "    self.outputSize = 1\n",
    "    self.hiddenSize = 3\n",
    "\n",
    "    #weights\n",
    "    self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # (3x2) weight matrix from input to hidden layer\n",
    "    self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # (3x1) weight matrix from hidden to output layer\n",
    "\n",
    "  def forward(self, X):\n",
    "    #forward propagation through our network\n",
    "    self.z = np.dot(X, self.W1) # dot product of X (input) and first set of 3x2 weights\n",
    "    self.z2 = self.sigmoid(self.z) # activation function\n",
    "    self.z3 = np.dot(self.z2, self.W2) # dot product of hidden layer (z2) and second set of 3x1 weights\n",
    "    o = self.sigmoid(self.z3) # final activation function\n",
    "    return o\n",
    "\n",
    "  def sigmoid(self, s):\n",
    "    # activation function\n",
    "    return 1/(1+np.exp(-s))\n",
    "\n",
    "NN = Neural_Network()\n",
    "\n",
    "#defining our output\n",
    "o = NN.forward(X)\n",
    "\n",
    "print(\"Predicted Output: \\n\" + str(o))\n",
    "print (\"Actual Output: \\n\" + str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network \n",
    "\n",
    "## Feedforward and Backpropagation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0\n",
      "\n",
      "Input (scaled): \n",
      "[[0.667 1.   ]\n",
      " [0.333 0.556]\n",
      " [1.    0.667]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.692]\n",
      " [0.707]\n",
      " [0.677]]\n",
      "Loss: \n",
      "0.04022376901072677\n",
      "\n",
      "\n",
      "# 1\n",
      "\n",
      "Input (scaled): \n",
      "[[0.667 1.   ]\n",
      " [0.333 0.556]\n",
      " [1.    0.667]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.705]\n",
      " [0.719]\n",
      " [0.69 ]]\n",
      "Loss: \n",
      "0.03541797204566044\n",
      "\n",
      "\n",
      "# 2\n",
      "\n",
      "Input (scaled): \n",
      "[[0.667 1.   ]\n",
      " [0.333 0.556]\n",
      " [1.    0.667]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.717]\n",
      " [0.73 ]\n",
      " [0.702]]\n",
      "Loss: \n",
      "0.031171036455726164\n",
      "\n",
      "\n",
      "# 3\n",
      "\n",
      "Input (scaled): \n",
      "[[0.667 1.   ]\n",
      " [0.333 0.556]\n",
      " [1.    0.667]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.728]\n",
      " [0.741]\n",
      " [0.713]]\n",
      "Loss: \n",
      "0.027436376319368575\n",
      "\n",
      "\n",
      "# 4\n",
      "\n",
      "Input (scaled): \n",
      "[[0.667 1.   ]\n",
      " [0.333 0.556]\n",
      " [1.    0.667]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.739]\n",
      " [0.75 ]\n",
      " [0.723]]\n",
      "Loss: \n",
      "0.024165087469337806\n",
      "\n",
      "\n",
      "# 5\n",
      "\n",
      "Input (scaled): \n",
      "[[0.667 1.   ]\n",
      " [0.333 0.556]\n",
      " [1.    0.667]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.749]\n",
      " [0.759]\n",
      " [0.733]]\n",
      "Loss: \n",
      "0.02130807821955419\n",
      "\n",
      "\n",
      "# 6\n",
      "\n",
      "Input (scaled): \n",
      "[[0.667 1.   ]\n",
      " [0.333 0.556]\n",
      " [1.    0.667]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.758]\n",
      " [0.767]\n",
      " [0.743]]\n",
      "Loss: \n",
      "0.01881783457697903\n",
      "\n",
      "\n",
      "# 7\n",
      "\n",
      "Input (scaled): \n",
      "[[0.667 1.   ]\n",
      " [0.333 0.556]\n",
      " [1.    0.667]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.767]\n",
      " [0.775]\n",
      " [0.751]]\n",
      "Loss: \n",
      "0.01664970582968271\n",
      "\n",
      "\n",
      "# 8\n",
      "\n",
      "Input (scaled): \n",
      "[[0.667 1.   ]\n",
      " [0.333 0.556]\n",
      " [1.    0.667]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.775]\n",
      " [0.782]\n",
      " [0.759]]\n",
      "Loss: \n",
      "0.014762711187703906\n",
      "\n",
      "\n",
      "# 9\n",
      "\n",
      "Input (scaled): \n",
      "[[0.667 1.   ]\n",
      " [0.333 0.556]\n",
      " [1.    0.667]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.782]\n",
      " [0.788]\n",
      " [0.767]]\n",
      "Loss: \n",
      "0.013119935523429167\n",
      "\n",
      "\n",
      "Predicted data based on trained weights: \n",
      "Input (scaled): \n",
      "[0.5 1. ]\n",
      "Output: \n",
      "[0.794]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# X = (hours studying, hours sleeping), y = score on test, xPredicted = 4 hours studying & 8 hours sleeping (input data for prediction)\n",
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "xPredicted = np.array(([4,8]), dtype=float)\n",
    "\n",
    "# scale units\n",
    "X = X/np.amax(X, axis=0) # maximum of X array\n",
    "xPredicted = xPredicted/np.amax(xPredicted, axis=0) # maximum of xPredicted (our input data for the prediction)\n",
    "y = y/100 # max test score is 100\n",
    "\n",
    "class Neural_Network(object):\n",
    "  def __init__(self):\n",
    "  #parameters\n",
    "    self.inputSize = 2\n",
    "    self.outputSize = 1\n",
    "    self.hiddenSize = 3\n",
    "\n",
    "  #weights\n",
    "    self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # (3x2) weight matrix from input to hidden layer\n",
    "    self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # (3x1) weight matrix from hidden to output layer\n",
    "\n",
    "  def forward(self, X):\n",
    "    #forward propagation through our network\n",
    "    self.z = np.dot(X, self.W1) # dot product of X (input) and first set of 3x2 weights\n",
    "    self.z2 = self.sigmoid(self.z) # activation function\n",
    "    self.z3 = np.dot(self.z2, self.W2) # dot product of hidden layer (z2) and second set of 3x1 weights\n",
    "    o = self.sigmoid(self.z3) # final activation function\n",
    "    return o\n",
    "\n",
    "  def sigmoid(self, s):\n",
    "    # activation function\n",
    "    return 1/(1+np.exp(-s))\n",
    "\n",
    "  def sigmoidPrime(self, s):\n",
    "    #derivative of sigmoid\n",
    "    return s * (1 - s)\n",
    "\n",
    "  def backward(self, X, y, o):\n",
    "    # backward propagate through the network\n",
    "    self.o_error = y - o # error in output\n",
    "    self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
    "\n",
    "    self.z2_error = self.o_delta.dot(self.W2.T) # z2 error: how much our hidden layer weights contributed to output error\n",
    "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2) # applying derivative of sigmoid to z2 error\n",
    "\n",
    "    self.W1 += X.T.dot(self.z2_delta) # adjusting first set (input --> hidden) weights\n",
    "    self.W2 += self.z2.T.dot(self.o_delta) # adjusting second set (hidden --> output) weights\n",
    "\n",
    "  def train(self, X, y):\n",
    "    o = self.forward(X)\n",
    "    self.backward(X, y, o)\n",
    "\n",
    "  def saveWeights(self):\n",
    "    np.savetxt(\"w1.txt\", self.W1, fmt=\"%s\")\n",
    "    np.savetxt(\"w2.txt\", self.W2, fmt=\"%s\")\n",
    "\n",
    "  def predict(self):\n",
    "    print (\"Predicted data based on trained weights: \")\n",
    "    print (\"Input (scaled): \\n\" + str(xPredicted))\n",
    "    print (\"Output: \\n\" + str(self.forward(xPredicted)));\n",
    "\n",
    "NN = Neural_Network()\n",
    "for i in range(0,10): # trains the NN 1,000 times\n",
    "  print(\"# \" + str(i) + \"\\n\")\n",
    "  print(\"Input (scaled): \\n\" + str(X))\n",
    "  print(\"Actual Output: \\n\" + str(y))\n",
    "  print(\"Predicted Output: \\n\" + str(NN.forward(X)))\n",
    "  print(\"Loss: \\n\" + str(np.mean(np.square(y - NN.forward(X))))) # mean sum squared loss\n",
    "  print (\"\\n\")\n",
    "  NN.train(X, y)\n",
    "\n",
    "NN.saveWeights()\n",
    "NN.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MLPClassifier in module sklearn.neural_network.multilayer_perceptron:\n",
      "\n",
      "class MLPClassifier(BaseMultilayerPerceptron, sklearn.base.ClassifierMixin)\n",
      " |  Multi-layer Perceptron classifier.\n",
      " |  \n",
      " |  This model optimizes the log-loss function using LBFGS or stochastic\n",
      " |  gradient descent.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
      " |      The ith element represents the number of neurons in the ith\n",
      " |      hidden layer.\n",
      " |  \n",
      " |  activation : {'identity', 'logistic', 'tanh', 'relu'}, default 'relu'\n",
      " |      Activation function for the hidden layer.\n",
      " |  \n",
      " |      - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      " |        returns f(x) = x\n",
      " |  \n",
      " |      - 'logistic', the logistic sigmoid function,\n",
      " |        returns f(x) = 1 / (1 + exp(-x)).\n",
      " |  \n",
      " |      - 'tanh', the hyperbolic tan function,\n",
      " |        returns f(x) = tanh(x).\n",
      " |  \n",
      " |      - 'relu', the rectified linear unit function,\n",
      " |        returns f(x) = max(0, x)\n",
      " |  \n",
      " |  solver : {'lbfgs', 'sgd', 'adam'}, default 'adam'\n",
      " |      The solver for weight optimization.\n",
      " |  \n",
      " |      - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      " |  \n",
      " |      - 'sgd' refers to stochastic gradient descent.\n",
      " |  \n",
      " |      - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
      " |        by Kingma, Diederik, and Jimmy Ba\n",
      " |  \n",
      " |      Note: The default solver 'adam' works pretty well on relatively\n",
      " |      large datasets (with thousands of training samples or more) in terms of\n",
      " |      both training time and validation score.\n",
      " |      For small datasets, however, 'lbfgs' can converge faster and perform\n",
      " |      better.\n",
      " |  \n",
      " |  alpha : float, optional, default 0.0001\n",
      " |      L2 penalty (regularization term) parameter.\n",
      " |  \n",
      " |  batch_size : int, optional, default 'auto'\n",
      " |      Size of minibatches for stochastic optimizers.\n",
      " |      If the solver is 'lbfgs', the classifier will not use minibatch.\n",
      " |      When set to \"auto\", `batch_size=min(200, n_samples)`\n",
      " |  \n",
      " |  learning_rate : {'constant', 'invscaling', 'adaptive'}, default 'constant'\n",
      " |      Learning rate schedule for weight updates.\n",
      " |  \n",
      " |      - 'constant' is a constant learning rate given by\n",
      " |        'learning_rate_init'.\n",
      " |  \n",
      " |      - 'invscaling' gradually decreases the learning rate ``learning_rate_``\n",
      " |        at each time step 't' using an inverse scaling exponent of 'power_t'.\n",
      " |        effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      " |  \n",
      " |      - 'adaptive' keeps the learning rate constant to\n",
      " |        'learning_rate_init' as long as training loss keeps decreasing.\n",
      " |        Each time two consecutive epochs fail to decrease training loss by at\n",
      " |        least tol, or fail to increase validation score by at least tol if\n",
      " |        'early_stopping' is on, the current learning rate is divided by 5.\n",
      " |  \n",
      " |      Only used when ``solver='sgd'``.\n",
      " |  \n",
      " |  learning_rate_init : double, optional, default 0.001\n",
      " |      The initial learning rate used. It controls the step-size\n",
      " |      in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  power_t : double, optional, default 0.5\n",
      " |      The exponent for inverse scaling learning rate.\n",
      " |      It is used in updating effective learning rate when the learning_rate\n",
      " |      is set to 'invscaling'. Only used when solver='sgd'.\n",
      " |  \n",
      " |  max_iter : int, optional, default 200\n",
      " |      Maximum number of iterations. The solver iterates until convergence\n",
      " |      (determined by 'tol') or this number of iterations. For stochastic\n",
      " |      solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
      " |      (how many times each data point will be used), not the number of\n",
      " |      gradient steps.\n",
      " |  \n",
      " |  shuffle : bool, optional, default True\n",
      " |      Whether to shuffle samples in each iteration. Only used when\n",
      " |      solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default None\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  tol : float, optional, default 1e-4\n",
      " |      Tolerance for the optimization. When the loss or score is not improving\n",
      " |      by at least tol for two consecutive iterations, unless `learning_rate`\n",
      " |      is set to 'adaptive', convergence is considered to be reached and\n",
      " |      training stops.\n",
      " |  \n",
      " |  verbose : bool, optional, default False\n",
      " |      Whether to print progress messages to stdout.\n",
      " |  \n",
      " |  warm_start : bool, optional, default False\n",
      " |      When set to True, reuse the solution of the previous\n",
      " |      call to fit as initialization, otherwise, just erase the\n",
      " |      previous solution.\n",
      " |  \n",
      " |  momentum : float, default 0.9\n",
      " |      Momentum for gradient descent update. Should be between 0 and 1. Only\n",
      " |      used when solver='sgd'.\n",
      " |  \n",
      " |  nesterovs_momentum : boolean, default True\n",
      " |      Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      " |      momentum > 0.\n",
      " |  \n",
      " |  early_stopping : bool, default False\n",
      " |      Whether to use early stopping to terminate training when validation\n",
      " |      score is not improving. If set to true, it will automatically set\n",
      " |      aside 10% of training data as validation and terminate training when\n",
      " |      validation score is not improving by at least tol for two consecutive\n",
      " |      epochs.\n",
      " |      Only effective when solver='sgd' or 'adam'\n",
      " |  \n",
      " |  validation_fraction : float, optional, default 0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True\n",
      " |  \n",
      " |  beta_1 : float, optional, default 0.9\n",
      " |      Exponential decay rate for estimates of first moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  beta_2 : float, optional, default 0.999\n",
      " |      Exponential decay rate for estimates of second moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  epsilon : float, optional, default 1e-8\n",
      " |      Value for numerical stability in adam. Only used when solver='adam'\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array or list of array of shape (n_classes,)\n",
      " |      Class labels for each output.\n",
      " |  \n",
      " |  loss_ : float\n",
      " |      The current loss computed with the loss function.\n",
      " |  \n",
      " |  coefs_ : list, length n_layers - 1\n",
      " |      The ith element in the list represents the weight matrix corresponding\n",
      " |      to layer i.\n",
      " |  \n",
      " |  intercepts_ : list, length n_layers - 1\n",
      " |      The ith element in the list represents the bias vector corresponding to\n",
      " |      layer i + 1.\n",
      " |  \n",
      " |  n_iter_ : int,\n",
      " |      The number of iterations the solver has ran.\n",
      " |  \n",
      " |  n_layers_ : int\n",
      " |      Number of layers.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      Number of outputs.\n",
      " |  \n",
      " |  out_activation_ : string\n",
      " |      Name of the output activation function.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  MLPClassifier trains iteratively since at each time step\n",
      " |  the partial derivatives of the loss function with respect to the model\n",
      " |  parameters are computed to update the parameters.\n",
      " |  \n",
      " |  It can also have a regularization term added to the loss function\n",
      " |  that shrinks model parameters to prevent overfitting.\n",
      " |  \n",
      " |  This implementation works with data represented as dense numpy arrays or\n",
      " |  sparse scipy arrays of floating point values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Hinton, Geoffrey E.\n",
      " |      \"Connectionist learning procedures.\" Artificial intelligence 40.1\n",
      " |      (1989): 185-234.\n",
      " |  \n",
      " |  Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of\n",
      " |      training deep feedforward neural networks.\" International Conference\n",
      " |      on Artificial Intelligence and Statistics. 2010.\n",
      " |  \n",
      " |  He, Kaiming, et al. \"Delving deep into rectifiers: Surpassing human-level\n",
      " |      performance on imagenet classification.\" arXiv preprint\n",
      " |      arXiv:1502.01852 (2015).\n",
      " |  \n",
      " |  Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic\n",
      " |      optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLPClassifier\n",
      " |      BaseMultilayerPerceptron\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model to data matrix X and target(s) y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the multi-layer perceptron classifier\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like, shape (n_samples,) or (n_samples, n_classes)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return the log of probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      log_y_prob : array-like, shape (n_samples, n_classes)\n",
      " |          The predicted log-probability of the sample for each class\n",
      " |          in the model, where classes are ordered as they are in\n",
      " |          `self.classes_`. Equivalent to log(predict_proba(X))\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_prob : array-like, shape (n_samples, n_classes)\n",
      " |          The predicted probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in `self.classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  partial_fit\n",
      " |      Fit the model to data matrix X and target y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      classes : array, shape (n_classes)\n",
      " |          Classes across all calls to partial_fit.\n",
      " |          Can be obtained via `np.unique(y_all)`, where y_all is the\n",
      " |          target vector of the entire dataset.\n",
      " |          This argument is required for the first call to partial_fit\n",
      " |          and can be omitted in the subsequent calls.\n",
      " |          Note that y doesn't need to contain all labels in `classes`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "help(MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69225859\n",
      "Iteration 2, loss = 0.68286383\n",
      "Iteration 3, loss = 0.67564925\n",
      "Iteration 4, loss = 0.66941684\n",
      "Iteration 5, loss = 0.66401914\n",
      "Iteration 6, loss = 0.66004404\n",
      "Iteration 7, loss = 0.65619876\n",
      "Iteration 8, loss = 0.65268342\n",
      "Iteration 9, loss = 0.64974644\n",
      "Iteration 10, loss = 0.64698598\n",
      "Iteration 11, loss = 0.64431285\n",
      "Iteration 12, loss = 0.64173960\n",
      "Iteration 13, loss = 0.63922889\n",
      "Iteration 14, loss = 0.63679691\n",
      "Iteration 15, loss = 0.63425251\n",
      "Iteration 16, loss = 0.63186714\n",
      "Iteration 17, loss = 0.62935345\n",
      "Iteration 18, loss = 0.62690308\n",
      "Iteration 19, loss = 0.62411275\n",
      "Iteration 20, loss = 0.62153795\n",
      "Iteration 21, loss = 0.61873835\n",
      "Iteration 22, loss = 0.61591680\n",
      "Iteration 23, loss = 0.61303832\n",
      "Iteration 24, loss = 0.61015721\n",
      "Iteration 25, loss = 0.60733694\n",
      "Iteration 26, loss = 0.60470102\n",
      "Iteration 27, loss = 0.60239766\n",
      "Iteration 28, loss = 0.59998877\n",
      "Iteration 29, loss = 0.59782174\n",
      "Iteration 30, loss = 0.59573785\n",
      "Iteration 31, loss = 0.59376595\n",
      "Iteration 32, loss = 0.59211323\n",
      "Iteration 33, loss = 0.59001078\n",
      "Iteration 34, loss = 0.58813692\n",
      "Iteration 35, loss = 0.58615512\n",
      "Iteration 36, loss = 0.58434587\n",
      "Iteration 37, loss = 0.58265595\n",
      "Iteration 38, loss = 0.58073111\n",
      "Iteration 39, loss = 0.57909680\n",
      "Iteration 40, loss = 0.57709015\n",
      "Iteration 41, loss = 0.57547678\n",
      "Iteration 42, loss = 0.57361414\n",
      "Iteration 43, loss = 0.57196319\n",
      "Iteration 44, loss = 0.57040082\n",
      "Iteration 45, loss = 0.56871326\n",
      "Iteration 46, loss = 0.56717427\n",
      "Iteration 47, loss = 0.56551319\n",
      "Iteration 48, loss = 0.56401813\n",
      "Iteration 49, loss = 0.56248878\n",
      "Iteration 50, loss = 0.56097352\n",
      "Iteration 51, loss = 0.55947382\n",
      "Iteration 52, loss = 0.55800981\n",
      "Iteration 53, loss = 0.55671929\n",
      "Iteration 54, loss = 0.55516038\n",
      "Iteration 55, loss = 0.55383384\n",
      "Iteration 56, loss = 0.55244165\n",
      "Iteration 57, loss = 0.55114551\n",
      "Iteration 58, loss = 0.54988338\n",
      "Iteration 59, loss = 0.54865214\n",
      "Iteration 60, loss = 0.54744167\n",
      "Iteration 61, loss = 0.54597220\n",
      "Iteration 62, loss = 0.54478675\n",
      "Iteration 63, loss = 0.54356295\n",
      "Iteration 64, loss = 0.54239272\n",
      "Iteration 65, loss = 0.54119360\n",
      "Iteration 66, loss = 0.54015023\n",
      "Iteration 67, loss = 0.53914195\n",
      "Iteration 68, loss = 0.53786330\n",
      "Iteration 69, loss = 0.53687967\n",
      "Iteration 70, loss = 0.53583072\n",
      "Iteration 71, loss = 0.53473390\n",
      "Iteration 72, loss = 0.53375777\n",
      "Iteration 73, loss = 0.53275281\n",
      "Iteration 74, loss = 0.53187432\n",
      "Iteration 75, loss = 0.53089048\n",
      "Iteration 76, loss = 0.52987853\n",
      "Iteration 77, loss = 0.52876701\n",
      "Iteration 78, loss = 0.52787622\n",
      "Iteration 79, loss = 0.52693827\n",
      "Iteration 80, loss = 0.52611279\n",
      "Iteration 81, loss = 0.52508624\n",
      "Iteration 82, loss = 0.52422805\n",
      "Iteration 83, loss = 0.52334383\n",
      "Iteration 84, loss = 0.52247765\n",
      "Iteration 85, loss = 0.52150410\n",
      "Iteration 86, loss = 0.52061613\n",
      "Iteration 87, loss = 0.51981645\n",
      "Iteration 88, loss = 0.51916807\n",
      "Iteration 89, loss = 0.51811986\n",
      "Iteration 90, loss = 0.51721264\n",
      "Iteration 91, loss = 0.51634883\n",
      "Iteration 92, loss = 0.51550605\n",
      "Iteration 93, loss = 0.51467773\n",
      "Iteration 94, loss = 0.51384576\n",
      "Iteration 95, loss = 0.51311184\n",
      "Iteration 96, loss = 0.51226965\n",
      "Iteration 97, loss = 0.51146854\n",
      "Iteration 98, loss = 0.51057985\n",
      "Iteration 99, loss = 0.50987077\n",
      "Iteration 100, loss = 0.50902887\n",
      "Iteration 101, loss = 0.50828216\n",
      "Iteration 102, loss = 0.50744591\n",
      "Iteration 103, loss = 0.50669901\n",
      "Iteration 104, loss = 0.50604421\n",
      "Iteration 105, loss = 0.50526205\n",
      "Iteration 106, loss = 0.50457172\n",
      "Iteration 107, loss = 0.50383729\n",
      "Iteration 108, loss = 0.50306276\n",
      "Iteration 109, loss = 0.50237849\n",
      "Iteration 110, loss = 0.50197427\n",
      "Iteration 111, loss = 0.50125721\n",
      "Iteration 112, loss = 0.50042321\n",
      "Iteration 113, loss = 0.49959835\n",
      "Iteration 114, loss = 0.49883649\n",
      "Iteration 115, loss = 0.49811503\n",
      "Iteration 116, loss = 0.49712047\n",
      "Iteration 117, loss = 0.49678081\n",
      "Iteration 118, loss = 0.49621683\n",
      "Iteration 119, loss = 0.49519641\n",
      "Iteration 120, loss = 0.49458220\n",
      "Iteration 121, loss = 0.49382379\n",
      "Iteration 122, loss = 0.49318897\n",
      "Iteration 123, loss = 0.49253116\n",
      "Iteration 124, loss = 0.49194417\n",
      "Iteration 125, loss = 0.49123320\n",
      "Iteration 126, loss = 0.49097438\n",
      "Iteration 127, loss = 0.49026243\n",
      "Iteration 128, loss = 0.48966675\n",
      "Iteration 129, loss = 0.48895449\n",
      "Iteration 130, loss = 0.48839765\n",
      "Iteration 131, loss = 0.48768157\n",
      "Iteration 132, loss = 0.48743613\n",
      "Iteration 133, loss = 0.48685266\n",
      "Iteration 134, loss = 0.48621033\n",
      "Iteration 135, loss = 0.48580916\n",
      "Iteration 136, loss = 0.48513393\n",
      "Iteration 137, loss = 0.48461708\n",
      "Iteration 138, loss = 0.48423711\n",
      "Iteration 139, loss = 0.48351635\n",
      "Iteration 140, loss = 0.48315703\n",
      "Iteration 141, loss = 0.48245629\n",
      "Iteration 142, loss = 0.48196230\n",
      "Iteration 143, loss = 0.48163177\n",
      "Iteration 144, loss = 0.48114423\n",
      "Iteration 145, loss = 0.48042696\n",
      "Iteration 146, loss = 0.48024942\n",
      "Iteration 147, loss = 0.47979875\n",
      "Iteration 148, loss = 0.47943441\n",
      "Iteration 149, loss = 0.47918742\n",
      "Iteration 150, loss = 0.47823566\n",
      "Iteration 151, loss = 0.47785567\n",
      "Iteration 152, loss = 0.47724345\n",
      "Iteration 153, loss = 0.47685757\n",
      "Iteration 154, loss = 0.47634188\n",
      "Iteration 155, loss = 0.47617390\n",
      "Iteration 156, loss = 0.47569148\n",
      "Iteration 157, loss = 0.47549644\n",
      "Iteration 158, loss = 0.47516032\n",
      "Iteration 159, loss = 0.47459239\n",
      "Iteration 160, loss = 0.47426290\n",
      "Iteration 161, loss = 0.47377252\n",
      "Iteration 162, loss = 0.47348595\n",
      "Iteration 163, loss = 0.47298732\n",
      "Iteration 164, loss = 0.47288676\n",
      "Iteration 165, loss = 0.47263148\n",
      "Iteration 166, loss = 0.47204165\n",
      "Iteration 167, loss = 0.47159980\n",
      "Iteration 168, loss = 0.47128761\n",
      "Iteration 169, loss = 0.47108203\n",
      "Iteration 170, loss = 0.47066679\n",
      "Iteration 171, loss = 0.47041136\n",
      "Iteration 172, loss = 0.47000112\n",
      "Iteration 173, loss = 0.46980145\n",
      "Iteration 174, loss = 0.46960149\n",
      "Iteration 175, loss = 0.46922246\n",
      "Iteration 176, loss = 0.46902738\n",
      "Iteration 177, loss = 0.46892669\n",
      "Iteration 178, loss = 0.46842897\n",
      "Iteration 179, loss = 0.46836653\n",
      "Iteration 180, loss = 0.46770885\n",
      "Iteration 181, loss = 0.46740985\n",
      "Iteration 182, loss = 0.46769289\n",
      "Iteration 183, loss = 0.46707656\n",
      "Iteration 184, loss = 0.46662271\n",
      "Iteration 185, loss = 0.46638076\n",
      "Iteration 186, loss = 0.46621965\n",
      "Iteration 187, loss = 0.46600801\n",
      "Iteration 188, loss = 0.46567952\n",
      "Iteration 189, loss = 0.46543345\n",
      "Iteration 190, loss = 0.46524097\n",
      "Iteration 191, loss = 0.46506568\n",
      "Iteration 192, loss = 0.46484214\n",
      "Iteration 193, loss = 0.46465235\n",
      "Iteration 194, loss = 0.46426545\n",
      "Iteration 195, loss = 0.46415589\n",
      "Iteration 196, loss = 0.46408837\n",
      "Iteration 197, loss = 0.46380908\n",
      "Iteration 198, loss = 0.46347328\n",
      "Iteration 199, loss = 0.46318547\n",
      "Iteration 200, loss = 0.46316388\n",
      "Iteration 201, loss = 0.46305083\n",
      "Iteration 202, loss = 0.46281926\n",
      "Iteration 203, loss = 0.46237775\n",
      "Iteration 204, loss = 0.46233476\n",
      "Iteration 205, loss = 0.46191951\n",
      "Iteration 206, loss = 0.46166659\n",
      "Iteration 207, loss = 0.46154500\n",
      "Iteration 208, loss = 0.46149260\n",
      "Iteration 209, loss = 0.46139699\n",
      "Iteration 210, loss = 0.46146017\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training set score: 0.785714\n",
      "Test set score: 0.794118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "dataframe = pandas.read_csv(\"./files/prims.csv\")\n",
    "array = dataframe.values\n",
    "X=array[:,:8]\n",
    "y = array[:,8]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X=scaler.fit_transform(X)\n",
    "\n",
    "# rescale the data, use the traditional train/test split\n",
    "X_train, X_test = X[:700], X[700:]\n",
    "y_train, y_test = y[:700], y[700:]\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10000, alpha=1e-4,\n",
    "                    solver='adam', verbose=10, tol=1e-4, random_state=1)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "#                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "#                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above code, play on the hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MLPRegressor in module sklearn.neural_network.multilayer_perceptron:\n",
      "\n",
      "class MLPRegressor(BaseMultilayerPerceptron, sklearn.base.RegressorMixin)\n",
      " |  Multi-layer Perceptron regressor.\n",
      " |  \n",
      " |  This model optimizes the squared-loss using LBFGS or stochastic gradient\n",
      " |  descent.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
      " |      The ith element represents the number of neurons in the ith\n",
      " |      hidden layer.\n",
      " |  \n",
      " |  activation : {'identity', 'logistic', 'tanh', 'relu'}, default 'relu'\n",
      " |      Activation function for the hidden layer.\n",
      " |  \n",
      " |      - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      " |        returns f(x) = x\n",
      " |  \n",
      " |      - 'logistic', the logistic sigmoid function,\n",
      " |        returns f(x) = 1 / (1 + exp(-x)).\n",
      " |  \n",
      " |      - 'tanh', the hyperbolic tan function,\n",
      " |        returns f(x) = tanh(x).\n",
      " |  \n",
      " |      - 'relu', the rectified linear unit function,\n",
      " |        returns f(x) = max(0, x)\n",
      " |  \n",
      " |  solver : {'lbfgs', 'sgd', 'adam'}, default 'adam'\n",
      " |      The solver for weight optimization.\n",
      " |  \n",
      " |      - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      " |  \n",
      " |      - 'sgd' refers to stochastic gradient descent.\n",
      " |  \n",
      " |      - 'adam' refers to a stochastic gradient-based optimizer proposed by\n",
      " |        Kingma, Diederik, and Jimmy Ba\n",
      " |  \n",
      " |      Note: The default solver 'adam' works pretty well on relatively\n",
      " |      large datasets (with thousands of training samples or more) in terms of\n",
      " |      both training time and validation score.\n",
      " |      For small datasets, however, 'lbfgs' can converge faster and perform\n",
      " |      better.\n",
      " |  \n",
      " |  alpha : float, optional, default 0.0001\n",
      " |      L2 penalty (regularization term) parameter.\n",
      " |  \n",
      " |  batch_size : int, optional, default 'auto'\n",
      " |      Size of minibatches for stochastic optimizers.\n",
      " |      If the solver is 'lbfgs', the classifier will not use minibatch.\n",
      " |      When set to \"auto\", `batch_size=min(200, n_samples)`\n",
      " |  \n",
      " |  learning_rate : {'constant', 'invscaling', 'adaptive'}, default 'constant'\n",
      " |      Learning rate schedule for weight updates.\n",
      " |  \n",
      " |      - 'constant' is a constant learning rate given by\n",
      " |        'learning_rate_init'.\n",
      " |  \n",
      " |      - 'invscaling' gradually decreases the learning rate ``learning_rate_``\n",
      " |        at each time step 't' using an inverse scaling exponent of 'power_t'.\n",
      " |        effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      " |  \n",
      " |      - 'adaptive' keeps the learning rate constant to\n",
      " |        'learning_rate_init' as long as training loss keeps decreasing.\n",
      " |        Each time two consecutive epochs fail to decrease training loss by at\n",
      " |        least tol, or fail to increase validation score by at least tol if\n",
      " |        'early_stopping' is on, the current learning rate is divided by 5.\n",
      " |  \n",
      " |      Only used when solver='sgd'.\n",
      " |  \n",
      " |  learning_rate_init : double, optional, default 0.001\n",
      " |      The initial learning rate used. It controls the step-size\n",
      " |      in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  power_t : double, optional, default 0.5\n",
      " |      The exponent for inverse scaling learning rate.\n",
      " |      It is used in updating effective learning rate when the learning_rate\n",
      " |      is set to 'invscaling'. Only used when solver='sgd'.\n",
      " |  \n",
      " |  max_iter : int, optional, default 200\n",
      " |      Maximum number of iterations. The solver iterates until convergence\n",
      " |      (determined by 'tol') or this number of iterations. For stochastic\n",
      " |      solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
      " |      (how many times each data point will be used), not the number of\n",
      " |      gradient steps.\n",
      " |  \n",
      " |  shuffle : bool, optional, default True\n",
      " |      Whether to shuffle samples in each iteration. Only used when\n",
      " |      solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default None\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  tol : float, optional, default 1e-4\n",
      " |      Tolerance for the optimization. When the loss or score is not improving\n",
      " |      by at least tol for two consecutive iterations, unless `learning_rate`\n",
      " |      is set to 'adaptive', convergence is considered to be reached and\n",
      " |      training stops.\n",
      " |  \n",
      " |  verbose : bool, optional, default False\n",
      " |      Whether to print progress messages to stdout.\n",
      " |  \n",
      " |  warm_start : bool, optional, default False\n",
      " |      When set to True, reuse the solution of the previous\n",
      " |      call to fit as initialization, otherwise, just erase the\n",
      " |      previous solution.\n",
      " |  \n",
      " |  momentum : float, default 0.9\n",
      " |      Momentum for gradient descent update.  Should be between 0 and 1. Only\n",
      " |      used when solver='sgd'.\n",
      " |  \n",
      " |  nesterovs_momentum : boolean, default True\n",
      " |      Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      " |      momentum > 0.\n",
      " |  \n",
      " |  early_stopping : bool, default False\n",
      " |      Whether to use early stopping to terminate training when validation\n",
      " |      score is not improving. If set to true, it will automatically set\n",
      " |      aside 10% of training data as validation and terminate training when\n",
      " |      validation score is not improving by at least tol for two consecutive\n",
      " |      epochs.\n",
      " |      Only effective when solver='sgd' or 'adam'\n",
      " |  \n",
      " |  validation_fraction : float, optional, default 0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True\n",
      " |  \n",
      " |  beta_1 : float, optional, default 0.9\n",
      " |      Exponential decay rate for estimates of first moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  beta_2 : float, optional, default 0.999\n",
      " |      Exponential decay rate for estimates of second moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  epsilon : float, optional, default 1e-8\n",
      " |      Value for numerical stability in adam. Only used when solver='adam'\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  loss_ : float\n",
      " |      The current loss computed with the loss function.\n",
      " |  \n",
      " |  coefs_ : list, length n_layers - 1\n",
      " |      The ith element in the list represents the weight matrix corresponding\n",
      " |      to layer i.\n",
      " |  \n",
      " |  intercepts_ : list, length n_layers - 1\n",
      " |      The ith element in the list represents the bias vector corresponding to\n",
      " |      layer i + 1.\n",
      " |  \n",
      " |  n_iter_ : int,\n",
      " |      The number of iterations the solver has ran.\n",
      " |  \n",
      " |  n_layers_ : int\n",
      " |      Number of layers.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      Number of outputs.\n",
      " |  \n",
      " |  out_activation_ : string\n",
      " |      Name of the output activation function.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  MLPRegressor trains iteratively since at each time step\n",
      " |  the partial derivatives of the loss function with respect to the model\n",
      " |  parameters are computed to update the parameters.\n",
      " |  \n",
      " |  It can also have a regularization term added to the loss function\n",
      " |  that shrinks model parameters to prevent overfitting.\n",
      " |  \n",
      " |  This implementation works with data represented as dense and sparse numpy\n",
      " |  arrays of floating point values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Hinton, Geoffrey E.\n",
      " |      \"Connectionist learning procedures.\" Artificial intelligence 40.1\n",
      " |      (1989): 185-234.\n",
      " |  \n",
      " |  Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of\n",
      " |      training deep feedforward neural networks.\" International Conference\n",
      " |      on Artificial Intelligence and Statistics. 2010.\n",
      " |  \n",
      " |  He, Kaiming, et al. \"Delving deep into rectifiers: Surpassing human-level\n",
      " |      performance on imagenet classification.\" arXiv preprint\n",
      " |      arXiv:1502.01852 (2015).\n",
      " |  \n",
      " |  Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic\n",
      " |      optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLPRegressor\n",
      " |      BaseMultilayerPerceptron\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the multi-layer perceptron model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like, shape (n_samples, n_outputs)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model to data matrix X and target(s) y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  partial_fit\n",
      " |      Fit the model to data matrix X and target y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "help(MLPRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4576.85361484\n",
      "Iteration 2, loss = 4576.29953733\n",
      "Iteration 3, loss = 4575.74594857\n",
      "Iteration 4, loss = 4575.19286444\n",
      "Iteration 5, loss = 4574.64030059\n",
      "Iteration 6, loss = 4574.08827245\n",
      "Iteration 7, loss = 4573.53679519\n",
      "Iteration 8, loss = 4572.98588368\n",
      "Iteration 9, loss = 4572.43555249\n",
      "Iteration 10, loss = 4571.88581588\n",
      "Iteration 11, loss = 4571.33668775\n",
      "Iteration 12, loss = 4570.78818165\n",
      "Iteration 13, loss = 4570.24031074\n",
      "Iteration 14, loss = 4569.69308778\n",
      "Iteration 15, loss = 4569.14652512\n",
      "Iteration 16, loss = 4568.60063466\n",
      "Iteration 17, loss = 4568.05542787\n",
      "Iteration 18, loss = 4567.51091573\n",
      "Iteration 19, loss = 4566.96710874\n",
      "Iteration 20, loss = 4566.42401690\n",
      "Iteration 21, loss = 4565.88164967\n",
      "Iteration 22, loss = 4565.34001600\n",
      "Iteration 23, loss = 4564.79912426\n",
      "Iteration 24, loss = 4564.25898227\n",
      "Iteration 25, loss = 4563.71959730\n",
      "Iteration 26, loss = 4563.18097603\n",
      "Iteration 27, loss = 4562.64312462\n",
      "Iteration 28, loss = 4562.10604868\n",
      "Iteration 29, loss = 4561.56975336\n",
      "Iteration 30, loss = 4561.03424334\n",
      "Iteration 31, loss = 4560.49952295\n",
      "Iteration 32, loss = 4559.96559620\n",
      "Iteration 33, loss = 4559.43246684\n",
      "Iteration 34, loss = 4558.90013848\n",
      "Iteration 35, loss = 4558.36861455\n",
      "Iteration 36, loss = 4557.83789843\n",
      "Iteration 37, loss = 4557.30799342\n",
      "Iteration 38, loss = 4556.77890282\n",
      "Iteration 39, loss = 4556.25062984\n",
      "Iteration 40, loss = 4555.72317769\n",
      "Iteration 41, loss = 4555.19654952\n",
      "Iteration 42, loss = 4554.67074843\n",
      "Iteration 43, loss = 4554.14577744\n",
      "Iteration 44, loss = 4553.62163948\n",
      "Iteration 45, loss = 4553.09833739\n",
      "Iteration 46, loss = 4552.57587390\n",
      "Iteration 47, loss = 4552.05425163\n",
      "Iteration 48, loss = 4551.53347306\n",
      "Iteration 49, loss = 4551.01354056\n",
      "Iteration 50, loss = 4550.49445635\n",
      "Iteration 51, loss = 4549.97622250\n",
      "Iteration 52, loss = 4549.45884098\n",
      "Iteration 53, loss = 4548.94231359\n",
      "Iteration 54, loss = 4548.42664198\n",
      "Iteration 55, loss = 4547.91182767\n",
      "Iteration 56, loss = 4547.39787205\n",
      "Iteration 57, loss = 4546.88477635\n",
      "Iteration 58, loss = 4546.37254167\n",
      "Iteration 59, loss = 4545.86116895\n",
      "Iteration 60, loss = 4545.35065901\n",
      "Iteration 61, loss = 4544.84101253\n",
      "Iteration 62, loss = 4544.33223004\n",
      "Iteration 63, loss = 4543.82431197\n",
      "Iteration 64, loss = 4543.31725858\n",
      "Iteration 65, loss = 4542.81107001\n",
      "Iteration 66, loss = 4542.30574628\n",
      "Iteration 67, loss = 4541.80128728\n",
      "Iteration 68, loss = 4541.29769276\n",
      "Iteration 69, loss = 4540.79496237\n",
      "Iteration 70, loss = 4540.29309562\n",
      "Iteration 71, loss = 4539.79209192\n",
      "Iteration 72, loss = 4539.29195054\n",
      "Iteration 73, loss = 4538.79267065\n",
      "Iteration 74, loss = 4538.29425130\n",
      "Iteration 75, loss = 4537.79669144\n",
      "Iteration 76, loss = 4537.29998990\n",
      "Iteration 77, loss = 4536.80414541\n",
      "Iteration 78, loss = 4536.30915659\n",
      "Iteration 79, loss = 4535.81502195\n",
      "Iteration 80, loss = 4535.32173992\n",
      "Iteration 81, loss = 4534.82930881\n",
      "Iteration 82, loss = 4534.33772684\n",
      "Iteration 83, loss = 4533.84699212\n",
      "Iteration 84, loss = 4533.35710269\n",
      "Iteration 85, loss = 4532.86805647\n",
      "Iteration 86, loss = 4532.37985130\n",
      "Iteration 87, loss = 4531.89248492\n",
      "Iteration 88, loss = 4531.40595499\n",
      "Iteration 89, loss = 4530.92025906\n",
      "Iteration 90, loss = 4530.43539461\n",
      "Iteration 91, loss = 4529.95135901\n",
      "Iteration 92, loss = 4529.46814956\n",
      "Iteration 93, loss = 4528.98576345\n",
      "Iteration 94, loss = 4528.50419779\n",
      "Iteration 95, loss = 4528.02344960\n",
      "Iteration 96, loss = 4527.54351581\n",
      "Iteration 97, loss = 4527.06439325\n",
      "Iteration 98, loss = 4526.58607867\n",
      "Iteration 99, loss = 4526.10856872\n",
      "Iteration 100, loss = 4525.63185995\n",
      "Iteration 101, loss = 4525.15594883\n",
      "Iteration 102, loss = 4524.68083172\n",
      "Iteration 103, loss = 4524.20650487\n",
      "Iteration 104, loss = 4523.73296445\n",
      "Iteration 105, loss = 4523.26020652\n",
      "Iteration 106, loss = 4522.78822700\n",
      "Iteration 107, loss = 4522.31702174\n",
      "Iteration 108, loss = 4521.84658645\n",
      "Iteration 109, loss = 4521.37691672\n",
      "Iteration 110, loss = 4520.90800801\n",
      "Iteration 111, loss = 4520.43985564\n",
      "Iteration 112, loss = 4519.97245483\n",
      "Iteration 113, loss = 4519.50580059\n",
      "Iteration 114, loss = 4519.03988783\n",
      "Iteration 115, loss = 4518.57471127\n",
      "Iteration 116, loss = 4518.11026547\n",
      "Iteration 117, loss = 4517.64654481\n",
      "Iteration 118, loss = 4517.18354348\n",
      "Iteration 119, loss = 4516.72125547\n",
      "Iteration 120, loss = 4516.25967456\n",
      "Iteration 121, loss = 4515.79879432\n",
      "Iteration 122, loss = 4515.33860809\n",
      "Iteration 123, loss = 4514.87910895\n",
      "Iteration 124, loss = 4514.42028974\n",
      "Iteration 125, loss = 4513.96214304\n",
      "Iteration 126, loss = 4513.50466115\n",
      "Iteration 127, loss = 4513.04783608\n",
      "Iteration 128, loss = 4512.59165952\n",
      "Iteration 129, loss = 4512.13612287\n",
      "Iteration 130, loss = 4511.68121719\n",
      "Iteration 131, loss = 4511.22693320\n",
      "Iteration 132, loss = 4510.77326125\n",
      "Iteration 133, loss = 4510.32019135\n",
      "Iteration 134, loss = 4509.86771311\n",
      "Iteration 135, loss = 4509.41581573\n",
      "Iteration 136, loss = 4508.96448803\n",
      "Iteration 137, loss = 4508.51371838\n",
      "Iteration 138, loss = 4508.06349473\n",
      "Iteration 139, loss = 4507.61380457\n",
      "Iteration 140, loss = 4507.16463494\n",
      "Iteration 141, loss = 4506.71597237\n",
      "Iteration 142, loss = 4506.26780294\n",
      "Iteration 143, loss = 4505.82011220\n",
      "Iteration 144, loss = 4505.37288517\n",
      "Iteration 145, loss = 4504.92610639\n",
      "Iteration 146, loss = 4504.47975979\n",
      "Iteration 147, loss = 4504.03382881\n",
      "Iteration 148, loss = 4503.58829629\n",
      "Iteration 149, loss = 4503.14314449\n",
      "Iteration 150, loss = 4502.69835510\n",
      "Iteration 151, loss = 4502.25390919\n",
      "Iteration 152, loss = 4501.80978725\n",
      "Iteration 153, loss = 4501.36596912\n",
      "Iteration 154, loss = 4500.92243406\n",
      "Iteration 155, loss = 4500.47916064\n",
      "Iteration 156, loss = 4500.03612685\n",
      "Iteration 157, loss = 4499.59330999\n",
      "Iteration 158, loss = 4499.15068674\n",
      "Iteration 159, loss = 4498.70823312\n",
      "Iteration 160, loss = 4498.26592449\n",
      "Iteration 161, loss = 4497.82373556\n",
      "Iteration 162, loss = 4497.38164040\n",
      "Iteration 163, loss = 4496.93961242\n",
      "Iteration 164, loss = 4496.49762438\n",
      "Iteration 165, loss = 4496.05564843\n",
      "Iteration 166, loss = 4495.61365607\n",
      "Iteration 167, loss = 4495.17161818\n",
      "Iteration 168, loss = 4494.72950507\n",
      "Iteration 169, loss = 4494.28728644\n",
      "Iteration 170, loss = 4493.84493144\n",
      "Iteration 171, loss = 4493.40240868\n",
      "Iteration 172, loss = 4492.95968626\n",
      "Iteration 173, loss = 4492.51673179\n",
      "Iteration 174, loss = 4492.07351245\n",
      "Iteration 175, loss = 4491.62999501\n",
      "Iteration 176, loss = 4491.18614586\n",
      "Iteration 177, loss = 4490.74193111\n",
      "Iteration 178, loss = 4490.29731656\n",
      "Iteration 179, loss = 4489.85226785\n",
      "Iteration 180, loss = 4489.40675044\n",
      "Iteration 181, loss = 4488.96072974\n",
      "Iteration 182, loss = 4488.51417114\n",
      "Iteration 183, loss = 4488.06704011\n",
      "Iteration 184, loss = 4487.61930227\n",
      "Iteration 185, loss = 4487.17092350\n",
      "Iteration 186, loss = 4486.72187000\n",
      "Iteration 187, loss = 4486.27210843\n",
      "Iteration 188, loss = 4485.82160595\n",
      "Iteration 189, loss = 4485.37033041\n",
      "Iteration 190, loss = 4484.91825040\n",
      "Iteration 191, loss = 4484.46533538\n",
      "Iteration 192, loss = 4484.01155581\n",
      "Iteration 193, loss = 4483.55688328\n",
      "Iteration 194, loss = 4483.10129058\n",
      "Iteration 195, loss = 4482.64475191\n",
      "Iteration 196, loss = 4482.18724292\n",
      "Iteration 197, loss = 4481.72874091\n",
      "Iteration 198, loss = 4481.26922490\n",
      "Iteration 199, loss = 4480.80867577\n",
      "Iteration 200, loss = 4480.34707637\n",
      "Iteration 201, loss = 4479.88441165\n",
      "Iteration 202, loss = 4479.42066876\n",
      "Iteration 203, loss = 4478.95583715\n",
      "Iteration 204, loss = 4478.48990864\n",
      "Iteration 205, loss = 4478.02287752\n",
      "Iteration 206, loss = 4477.55474064\n",
      "Iteration 207, loss = 4477.08549744\n",
      "Iteration 208, loss = 4476.61514998\n",
      "Iteration 209, loss = 4476.14370301\n",
      "Iteration 210, loss = 4475.67116398\n",
      "Iteration 211, loss = 4475.19754301\n",
      "Iteration 212, loss = 4474.72285288\n",
      "Iteration 213, loss = 4474.24710903\n",
      "Iteration 214, loss = 4473.77032946\n",
      "Iteration 215, loss = 4473.29253470\n",
      "Iteration 216, loss = 4472.81374768\n",
      "Iteration 217, loss = 4472.33399368\n",
      "Iteration 218, loss = 4471.85330016\n",
      "Iteration 219, loss = 4471.37169663\n",
      "Iteration 220, loss = 4470.88921453\n",
      "Iteration 221, loss = 4470.40588703\n",
      "Iteration 222, loss = 4469.92174888\n",
      "Iteration 223, loss = 4469.43683618\n",
      "Iteration 224, loss = 4468.95118622\n",
      "Iteration 225, loss = 4468.46483726\n",
      "Iteration 226, loss = 4467.97782833\n",
      "Iteration 227, loss = 4467.49019899\n",
      "Iteration 228, loss = 4467.00198914\n",
      "Iteration 229, loss = 4466.51323877\n",
      "Iteration 230, loss = 4466.02398781\n",
      "Iteration 231, loss = 4465.53427586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 232, loss = 4465.04414200\n",
      "Iteration 233, loss = 4464.55362464\n",
      "Iteration 234, loss = 4464.06276127\n",
      "Iteration 235, loss = 4463.57158834\n",
      "Iteration 236, loss = 4463.08014105\n",
      "Iteration 237, loss = 4462.58845326\n",
      "Iteration 238, loss = 4462.09655731\n",
      "Iteration 239, loss = 4461.60448390\n",
      "Iteration 240, loss = 4461.11226203\n",
      "Iteration 241, loss = 4460.61991884\n",
      "Iteration 242, loss = 4460.12747962\n",
      "Iteration 243, loss = 4459.63496766\n",
      "Iteration 244, loss = 4459.14240430\n",
      "Iteration 245, loss = 4458.64980880\n",
      "Iteration 246, loss = 4458.15719842\n",
      "Iteration 247, loss = 4457.66458834\n",
      "Iteration 248, loss = 4457.17199172\n",
      "Iteration 249, loss = 4456.67941970\n",
      "Iteration 250, loss = 4456.18688144\n",
      "Iteration 251, loss = 4455.69438414\n",
      "Iteration 252, loss = 4455.20193310\n",
      "Iteration 253, loss = 4454.70953182\n",
      "Iteration 254, loss = 4454.21718200\n",
      "Iteration 255, loss = 4453.72488363\n",
      "Iteration 256, loss = 4453.23263509\n",
      "Iteration 257, loss = 4452.74043322\n",
      "Iteration 258, loss = 4452.24827338\n",
      "Iteration 259, loss = 4451.75614955\n",
      "Iteration 260, loss = 4451.26405444\n",
      "Iteration 261, loss = 4450.77197954\n",
      "Iteration 262, loss = 4450.27991524\n",
      "Iteration 263, loss = 4449.78785090\n",
      "Iteration 264, loss = 4449.29577496\n",
      "Iteration 265, loss = 4448.80367501\n",
      "Iteration 266, loss = 4448.31153787\n",
      "Iteration 267, loss = 4447.81934972\n",
      "Iteration 268, loss = 4447.32709614\n",
      "Iteration 269, loss = 4446.83476221\n",
      "Iteration 270, loss = 4446.34233258\n",
      "Iteration 271, loss = 4445.84979158\n",
      "Iteration 272, loss = 4445.35712326\n",
      "Iteration 273, loss = 4444.86431147\n",
      "Iteration 274, loss = 4444.37133995\n",
      "Iteration 275, loss = 4443.87819238\n",
      "Iteration 276, loss = 4443.38485245\n",
      "Iteration 277, loss = 4442.89130391\n",
      "Iteration 278, loss = 4442.39753066\n",
      "Iteration 279, loss = 4441.90351676\n",
      "Iteration 280, loss = 4441.40924653\n",
      "Iteration 281, loss = 4440.91470455\n",
      "Iteration 282, loss = 4440.41987574\n",
      "Iteration 283, loss = 4439.92474540\n",
      "Iteration 284, loss = 4439.42929922\n",
      "Iteration 285, loss = 4438.93352336\n",
      "Iteration 286, loss = 4438.43740442\n",
      "Iteration 287, loss = 4437.94092952\n",
      "Iteration 288, loss = 4437.44408632\n",
      "Iteration 289, loss = 4436.94686299\n",
      "Iteration 290, loss = 4436.44924830\n",
      "Iteration 291, loss = 4435.95123157\n",
      "Iteration 292, loss = 4435.45280272\n",
      "Iteration 293, loss = 4434.95395224\n",
      "Iteration 294, loss = 4434.45467125\n",
      "Iteration 295, loss = 4433.95495144\n",
      "Iteration 296, loss = 4433.45478509\n",
      "Iteration 297, loss = 4432.95416507\n",
      "Iteration 298, loss = 4432.45308484\n",
      "Iteration 299, loss = 4431.95153841\n",
      "Iteration 300, loss = 4431.44952034\n",
      "Iteration 301, loss = 4430.94702574\n",
      "Iteration 302, loss = 4430.44405023\n",
      "Iteration 303, loss = 4429.94058992\n",
      "Iteration 304, loss = 4429.43664142\n",
      "Iteration 305, loss = 4428.93220179\n",
      "Iteration 306, loss = 4428.42726851\n",
      "Iteration 307, loss = 4427.92183950\n",
      "Iteration 308, loss = 4427.41591305\n",
      "Iteration 309, loss = 4426.90948783\n",
      "Iteration 310, loss = 4426.40256283\n",
      "Iteration 311, loss = 4425.89513740\n",
      "Iteration 312, loss = 4425.38721114\n",
      "Iteration 313, loss = 4424.87878398\n",
      "Iteration 314, loss = 4424.36985606\n",
      "Iteration 315, loss = 4423.86042779\n",
      "Iteration 316, loss = 4423.35049978\n",
      "Iteration 317, loss = 4422.84007285\n",
      "Iteration 318, loss = 4422.32914800\n",
      "Iteration 319, loss = 4421.81772637\n",
      "Iteration 320, loss = 4421.30580929\n",
      "Iteration 321, loss = 4420.79339817\n",
      "Iteration 322, loss = 4420.28049457\n",
      "Iteration 323, loss = 4419.76710012\n",
      "Iteration 324, loss = 4419.25321653\n",
      "Iteration 325, loss = 4418.73884554\n",
      "Iteration 326, loss = 4418.22398894\n",
      "Iteration 327, loss = 4417.70864850\n",
      "Iteration 328, loss = 4417.19282596\n",
      "Iteration 329, loss = 4416.67652301\n",
      "Iteration 330, loss = 4416.15974123\n",
      "Iteration 331, loss = 4415.64248207\n",
      "Iteration 332, loss = 4415.12474681\n",
      "Iteration 333, loss = 4414.60653650\n",
      "Iteration 334, loss = 4414.08785196\n",
      "Iteration 335, loss = 4413.56869373\n",
      "Iteration 336, loss = 4413.04906201\n",
      "Iteration 337, loss = 4412.52895669\n",
      "Iteration 338, loss = 4412.00837730\n",
      "Iteration 339, loss = 4411.48732301\n",
      "Iteration 340, loss = 4410.96579267\n",
      "Iteration 341, loss = 4410.44378483\n",
      "Iteration 342, loss = 4409.92129779\n",
      "Iteration 343, loss = 4409.39832967\n",
      "Iteration 344, loss = 4408.87487850\n",
      "Iteration 345, loss = 4408.35094232\n",
      "Iteration 346, loss = 4407.82651927\n",
      "Iteration 347, loss = 4407.30160772\n",
      "Iteration 348, loss = 4406.77620638\n",
      "Iteration 349, loss = 4406.25031434\n",
      "Iteration 350, loss = 4405.72393119\n",
      "Iteration 351, loss = 4405.19705705\n",
      "Iteration 352, loss = 4404.66969259\n",
      "Iteration 353, loss = 4404.14183901\n",
      "Iteration 354, loss = 4403.61349802\n",
      "Iteration 355, loss = 4403.08467175\n",
      "Iteration 356, loss = 4402.55536273\n",
      "Iteration 357, loss = 4402.02557375\n",
      "Iteration 358, loss = 4401.49530780\n",
      "Iteration 359, loss = 4400.96456800\n",
      "Iteration 360, loss = 4400.43335750\n",
      "Iteration 361, loss = 4399.90167944\n",
      "Iteration 362, loss = 4399.36953690\n",
      "Iteration 363, loss = 4398.83693288\n",
      "Iteration 364, loss = 4398.30387028\n",
      "Iteration 365, loss = 4397.77035191\n",
      "Iteration 366, loss = 4397.23638048\n",
      "Iteration 367, loss = 4396.70195862\n",
      "Iteration 368, loss = 4396.16708888\n",
      "Iteration 369, loss = 4395.63177376\n",
      "Iteration 370, loss = 4395.09601566\n",
      "Iteration 371, loss = 4394.55981693\n",
      "Iteration 372, loss = 4394.02317982\n",
      "Iteration 373, loss = 4393.48610647\n",
      "Iteration 374, loss = 4392.94859891\n",
      "Iteration 375, loss = 4392.41065903\n",
      "Iteration 376, loss = 4391.87228855\n",
      "Iteration 377, loss = 4391.33348903\n",
      "Iteration 378, loss = 4390.79426187\n",
      "Iteration 379, loss = 4390.25460827\n",
      "Iteration 380, loss = 4389.71452932\n",
      "Iteration 381, loss = 4389.17402595\n",
      "Iteration 382, loss = 4388.63309898\n",
      "Iteration 383, loss = 4388.09174915\n",
      "Iteration 384, loss = 4387.54997714\n",
      "Iteration 385, loss = 4387.00778358\n",
      "Iteration 386, loss = 4386.46516908\n",
      "Iteration 387, loss = 4385.92213418\n",
      "Iteration 388, loss = 4385.37867940\n",
      "Iteration 389, loss = 4384.83480518\n",
      "Iteration 390, loss = 4384.29051182\n",
      "Iteration 391, loss = 4383.74579951\n",
      "Iteration 392, loss = 4383.20066821\n",
      "Iteration 393, loss = 4382.65511764\n",
      "Iteration 394, loss = 4382.10914722\n",
      "Iteration 395, loss = 4381.56275604\n",
      "Iteration 396, loss = 4381.01594282\n",
      "Iteration 397, loss = 4380.46870588\n",
      "Iteration 398, loss = 4379.92104313\n",
      "Iteration 399, loss = 4379.37295205\n",
      "Iteration 400, loss = 4378.82442973\n",
      "Iteration 401, loss = 4378.27547281\n",
      "Iteration 402, loss = 4377.72607754\n",
      "Iteration 403, loss = 4377.17623978\n",
      "Iteration 404, loss = 4376.62595499\n",
      "Iteration 405, loss = 4376.07521828\n",
      "Iteration 406, loss = 4375.52402443\n",
      "Iteration 407, loss = 4374.97236786\n",
      "Iteration 408, loss = 4374.42024270\n",
      "Iteration 409, loss = 4373.86764279\n",
      "Iteration 410, loss = 4373.31456167\n",
      "Iteration 411, loss = 4372.76099268\n",
      "Iteration 412, loss = 4372.20692888\n",
      "Iteration 413, loss = 4371.65236315\n",
      "Iteration 414, loss = 4371.09728820\n",
      "Iteration 415, loss = 4370.54169653\n",
      "Iteration 416, loss = 4369.98558054\n",
      "Iteration 417, loss = 4369.42893249\n",
      "Iteration 418, loss = 4368.87174455\n",
      "Iteration 419, loss = 4368.31400881\n",
      "Iteration 420, loss = 4367.75571731\n",
      "Iteration 421, loss = 4367.19686205\n",
      "Iteration 422, loss = 4366.63743506\n",
      "Iteration 423, loss = 4366.07742840\n",
      "Iteration 424, loss = 4365.51683418\n",
      "Iteration 425, loss = 4364.95564466\n",
      "Iteration 426, loss = 4364.39385220\n",
      "Iteration 427, loss = 4363.83144941\n",
      "Iteration 428, loss = 4363.26842908\n",
      "Iteration 429, loss = 4362.70478432\n",
      "Iteration 430, loss = 4362.14050854\n",
      "Iteration 431, loss = 4361.57559552\n",
      "Iteration 432, loss = 4361.01003945\n",
      "Iteration 433, loss = 4360.44383499\n",
      "Iteration 434, loss = 4359.87697725\n",
      "Iteration 435, loss = 4359.30946192\n",
      "Iteration 436, loss = 4358.74128523\n",
      "Iteration 437, loss = 4358.17244404\n",
      "Iteration 438, loss = 4357.60293585\n",
      "Iteration 439, loss = 4357.03275887\n",
      "Iteration 440, loss = 4356.46191201\n",
      "Iteration 441, loss = 4355.89039494\n",
      "Iteration 442, loss = 4355.31820812\n",
      "Iteration 443, loss = 4354.74535284\n",
      "Iteration 444, loss = 4354.17183122\n",
      "Iteration 445, loss = 4353.59764625\n",
      "Iteration 446, loss = 4353.02280180\n",
      "Iteration 447, loss = 4352.44730267\n",
      "Iteration 448, loss = 4351.87115457\n",
      "Iteration 449, loss = 4351.29436413\n",
      "Iteration 450, loss = 4350.71693894\n",
      "Iteration 451, loss = 4350.13888750\n",
      "Iteration 452, loss = 4349.56021927\n",
      "Iteration 453, loss = 4348.98094465\n",
      "Iteration 454, loss = 4348.40107492\n",
      "Iteration 455, loss = 4347.82062229\n",
      "Iteration 456, loss = 4347.23959984\n",
      "Iteration 457, loss = 4346.65802149\n",
      "Iteration 458, loss = 4346.07590198\n",
      "Iteration 459, loss = 4345.49325686\n",
      "Iteration 460, loss = 4344.91010238\n",
      "Iteration 461, loss = 4344.32645551\n",
      "Iteration 462, loss = 4343.74233387\n",
      "Iteration 463, loss = 4343.15775567\n",
      "Iteration 464, loss = 4342.57273966\n",
      "Iteration 465, loss = 4341.98730508\n",
      "Iteration 466, loss = 4341.40147158\n",
      "Iteration 467, loss = 4340.81525918\n",
      "Iteration 468, loss = 4340.22868818\n",
      "Iteration 469, loss = 4339.64177912\n",
      "Iteration 470, loss = 4339.05455269\n",
      "Iteration 471, loss = 4338.46702967\n",
      "Iteration 472, loss = 4337.87923088\n",
      "Iteration 473, loss = 4337.29117709\n",
      "Iteration 474, loss = 4336.70288895\n",
      "Iteration 475, loss = 4336.11438697\n",
      "Iteration 476, loss = 4335.52569140\n",
      "Iteration 477, loss = 4334.93682224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 478, loss = 4334.34779911\n",
      "Iteration 479, loss = 4333.75864126\n",
      "Iteration 480, loss = 4333.16936751\n",
      "Iteration 481, loss = 4332.57999617\n",
      "Iteration 482, loss = 4331.99054505\n",
      "Iteration 483, loss = 4331.40103142\n",
      "Iteration 484, loss = 4330.81147196\n",
      "Iteration 485, loss = 4330.22188274\n",
      "Iteration 486, loss = 4329.63227922\n",
      "Iteration 487, loss = 4329.04267624\n",
      "Iteration 488, loss = 4328.45308798\n",
      "Iteration 489, loss = 4327.86352798\n",
      "Iteration 490, loss = 4327.27400915\n",
      "Iteration 491, loss = 4326.68454373\n",
      "Iteration 492, loss = 4326.09514335\n",
      "Iteration 493, loss = 4325.50581903\n",
      "Iteration 494, loss = 4324.91658114\n",
      "Iteration 495, loss = 4324.32743951\n",
      "Iteration 496, loss = 4323.73840334\n",
      "Iteration 497, loss = 4323.14948132\n",
      "Iteration 498, loss = 4322.56068158\n",
      "Iteration 499, loss = 4321.97201173\n",
      "Iteration 500, loss = 4321.38347889\n",
      "Iteration 501, loss = 4320.79508971\n",
      "Iteration 502, loss = 4320.20685039\n",
      "Iteration 503, loss = 4319.61876667\n",
      "Iteration 504, loss = 4319.03084389\n",
      "Iteration 505, loss = 4318.44308698\n",
      "Iteration 506, loss = 4317.85550049\n",
      "Iteration 507, loss = 4317.26808860\n",
      "Iteration 508, loss = 4316.68085514\n",
      "Iteration 509, loss = 4316.09380359\n",
      "Iteration 510, loss = 4315.50693711\n",
      "Iteration 511, loss = 4314.92025852\n",
      "Iteration 512, loss = 4314.33377038\n",
      "Iteration 513, loss = 4313.74747490\n",
      "Iteration 514, loss = 4313.16137403\n",
      "Iteration 515, loss = 4312.57546946\n",
      "Iteration 516, loss = 4311.98976258\n",
      "Iteration 517, loss = 4311.40425453\n",
      "Iteration 518, loss = 4310.81894623\n",
      "Iteration 519, loss = 4310.23383832\n",
      "Iteration 520, loss = 4309.64893124\n",
      "Iteration 521, loss = 4309.06422520\n",
      "Iteration 522, loss = 4308.47972020\n",
      "Iteration 523, loss = 4307.89541605\n",
      "Iteration 524, loss = 4307.31131234\n",
      "Iteration 525, loss = 4306.72740852\n",
      "Iteration 526, loss = 4306.14370385\n",
      "Iteration 527, loss = 4305.56019743\n",
      "Iteration 528, loss = 4304.97688822\n",
      "Iteration 529, loss = 4304.39377502\n",
      "Iteration 530, loss = 4303.81085653\n",
      "Iteration 531, loss = 4303.22813131\n",
      "Iteration 532, loss = 4302.64559780\n",
      "Iteration 533, loss = 4302.06325435\n",
      "Iteration 534, loss = 4301.48109922\n",
      "Iteration 535, loss = 4300.89913057\n",
      "Iteration 536, loss = 4300.31734647\n",
      "Iteration 537, loss = 4299.73574493\n",
      "Iteration 538, loss = 4299.15432388\n",
      "Iteration 539, loss = 4298.57308119\n",
      "Iteration 540, loss = 4297.99201467\n",
      "Iteration 541, loss = 4297.41112208\n",
      "Iteration 542, loss = 4296.83040112\n",
      "Iteration 543, loss = 4296.24984943\n",
      "Iteration 544, loss = 4295.66946463\n",
      "Iteration 545, loss = 4295.08924428\n",
      "Iteration 546, loss = 4294.50918591\n",
      "Iteration 547, loss = 4293.92928699\n",
      "Iteration 548, loss = 4293.34954497\n",
      "Iteration 549, loss = 4292.76995728\n",
      "Iteration 550, loss = 4292.19052127\n",
      "Iteration 551, loss = 4291.61123431\n",
      "Iteration 552, loss = 4291.03209370\n",
      "Iteration 553, loss = 4290.45309672\n",
      "Iteration 554, loss = 4289.87424063\n",
      "Iteration 555, loss = 4289.29552266\n",
      "Iteration 556, loss = 4288.71694000\n",
      "Iteration 557, loss = 4288.13848981\n",
      "Iteration 558, loss = 4287.56016924\n",
      "Iteration 559, loss = 4286.98197539\n",
      "Iteration 560, loss = 4286.40390537\n",
      "Iteration 561, loss = 4285.82595622\n",
      "Iteration 562, loss = 4285.24812499\n",
      "Iteration 563, loss = 4284.67040868\n",
      "Iteration 564, loss = 4284.09280427\n",
      "Iteration 565, loss = 4283.51530872\n",
      "Iteration 566, loss = 4282.93791895\n",
      "Iteration 567, loss = 4282.36063187\n",
      "Iteration 568, loss = 4281.78344435\n",
      "Iteration 569, loss = 4281.20635323\n",
      "Iteration 570, loss = 4280.62935533\n",
      "Iteration 571, loss = 4280.05244743\n",
      "Iteration 572, loss = 4279.47562628\n",
      "Iteration 573, loss = 4278.89888861\n",
      "Iteration 574, loss = 4278.32223109\n",
      "Iteration 575, loss = 4277.74565038\n",
      "Iteration 576, loss = 4277.16914309\n",
      "Iteration 577, loss = 4276.59270581\n",
      "Iteration 578, loss = 4276.01633506\n",
      "Iteration 579, loss = 4275.44002734\n",
      "Iteration 580, loss = 4274.86377910\n",
      "Iteration 581, loss = 4274.28758677\n",
      "Iteration 582, loss = 4273.71144668\n",
      "Iteration 583, loss = 4273.13535517\n",
      "Iteration 584, loss = 4272.55930848\n",
      "Iteration 585, loss = 4271.98330284\n",
      "Iteration 586, loss = 4271.40733440\n",
      "Iteration 587, loss = 4270.83139925\n",
      "Iteration 588, loss = 4270.25549344\n",
      "Iteration 589, loss = 4269.67961294\n",
      "Iteration 590, loss = 4269.10375366\n",
      "Iteration 591, loss = 4268.52791145\n",
      "Iteration 592, loss = 4267.95208208\n",
      "Iteration 593, loss = 4267.37626126\n",
      "Iteration 594, loss = 4266.80044460\n",
      "Iteration 595, loss = 4266.22462765\n",
      "Iteration 596, loss = 4265.64880587\n",
      "Iteration 597, loss = 4265.07297464\n",
      "Iteration 598, loss = 4264.49712923\n",
      "Iteration 599, loss = 4263.92126485\n",
      "Iteration 600, loss = 4263.34537658\n",
      "Iteration 601, loss = 4262.76945940\n",
      "Iteration 602, loss = 4262.19350820\n",
      "Iteration 603, loss = 4261.61751776\n",
      "Iteration 604, loss = 4261.04148271\n",
      "Iteration 605, loss = 4260.46539760\n",
      "Iteration 606, loss = 4259.88925684\n",
      "Iteration 607, loss = 4259.31305469\n",
      "Iteration 608, loss = 4258.73678529\n",
      "Iteration 609, loss = 4258.16044265\n",
      "Iteration 610, loss = 4257.58402060\n",
      "Iteration 611, loss = 4257.00751284\n",
      "Iteration 612, loss = 4256.43091290\n",
      "Iteration 613, loss = 4255.85421413\n",
      "Iteration 614, loss = 4255.27740974\n",
      "Iteration 615, loss = 4254.70049273\n",
      "Iteration 616, loss = 4254.12345591\n",
      "Iteration 617, loss = 4253.54629190\n",
      "Iteration 618, loss = 4252.96899314\n",
      "Iteration 619, loss = 4252.39155182\n",
      "Iteration 620, loss = 4251.81395993\n",
      "Iteration 621, loss = 4251.23620924\n",
      "Iteration 622, loss = 4250.65829127\n",
      "Iteration 623, loss = 4250.08019731\n",
      "Iteration 624, loss = 4249.50191838\n",
      "Iteration 625, loss = 4248.92344527\n",
      "Iteration 626, loss = 4248.34476848\n",
      "Iteration 627, loss = 4247.76587823\n",
      "Iteration 628, loss = 4247.18676448\n",
      "Iteration 629, loss = 4246.60741687\n",
      "Iteration 630, loss = 4246.02782477\n",
      "Iteration 631, loss = 4245.44797721\n",
      "Iteration 632, loss = 4244.86786296\n",
      "Iteration 633, loss = 4244.28747042\n",
      "Iteration 634, loss = 4243.70678769\n",
      "Iteration 635, loss = 4243.12580256\n",
      "Iteration 636, loss = 4242.54450247\n",
      "Iteration 637, loss = 4241.96287454\n",
      "Iteration 638, loss = 4241.38090557\n",
      "Iteration 639, loss = 4240.79858200\n",
      "Iteration 640, loss = 4240.21589000\n",
      "Iteration 641, loss = 4239.63281537\n",
      "Iteration 642, loss = 4239.04934366\n",
      "Iteration 643, loss = 4238.46546007\n",
      "Iteration 644, loss = 4237.88114956\n",
      "Iteration 645, loss = 4237.29639683\n",
      "Iteration 646, loss = 4236.71118632\n",
      "Iteration 647, loss = 4236.12550228\n",
      "Iteration 648, loss = 4235.53932880\n",
      "Iteration 649, loss = 4234.95264980\n",
      "Iteration 650, loss = 4234.36544914\n",
      "Iteration 651, loss = 4233.77771062\n",
      "Iteration 652, loss = 4233.18941806\n",
      "Iteration 653, loss = 4232.60055537\n",
      "Iteration 654, loss = 4232.01110659\n",
      "Iteration 655, loss = 4231.42105601\n",
      "Iteration 656, loss = 4230.83038822\n",
      "Iteration 657, loss = 4230.23908823\n",
      "Iteration 658, loss = 4229.64714156\n",
      "Iteration 659, loss = 4229.05453435\n",
      "Iteration 660, loss = 4228.46125347\n",
      "Iteration 661, loss = 4227.86728666\n",
      "Iteration 662, loss = 4227.27262265\n",
      "Iteration 663, loss = 4226.67725129\n",
      "Iteration 664, loss = 4226.08116369\n",
      "Iteration 665, loss = 4225.48435234\n",
      "Iteration 666, loss = 4224.88681129\n",
      "Iteration 667, loss = 4224.28853622\n",
      "Iteration 668, loss = 4223.68952461\n",
      "Iteration 669, loss = 4223.08977583\n",
      "Iteration 670, loss = 4222.48929125\n",
      "Iteration 671, loss = 4221.88807428\n",
      "Iteration 672, loss = 4221.28613048\n",
      "Iteration 673, loss = 4220.68346751\n",
      "Iteration 674, loss = 4220.08009517\n",
      "Iteration 675, loss = 4219.47602528\n",
      "Iteration 676, loss = 4218.87127161\n",
      "Iteration 677, loss = 4218.26584968\n",
      "Iteration 678, loss = 4217.65977653\n",
      "Iteration 679, loss = 4217.05307042\n",
      "Iteration 680, loss = 4216.44575046\n",
      "Iteration 681, loss = 4215.83783616\n",
      "Iteration 682, loss = 4215.22934694\n",
      "Iteration 683, loss = 4214.62030150\n",
      "Iteration 684, loss = 4214.01071720\n",
      "Iteration 685, loss = 4213.40060942\n",
      "Iteration 686, loss = 4212.78999076\n",
      "Iteration 687, loss = 4212.17887036\n",
      "Iteration 688, loss = 4211.56725319\n",
      "Iteration 689, loss = 4210.95513935\n",
      "Iteration 690, loss = 4210.34252354\n",
      "Iteration 691, loss = 4209.72939453\n",
      "Iteration 692, loss = 4209.11573491\n",
      "Iteration 693, loss = 4208.50152089\n",
      "Iteration 694, loss = 4207.88672243\n",
      "Iteration 695, loss = 4207.27130349\n",
      "Iteration 696, loss = 4206.65522260\n",
      "Iteration 697, loss = 4206.03843352\n",
      "Iteration 698, loss = 4205.42088623\n",
      "Iteration 699, loss = 4204.80252794\n",
      "Iteration 700, loss = 4204.18330419\n",
      "Iteration 701, loss = 4203.56316003\n",
      "Iteration 702, loss = 4202.94204108\n",
      "Iteration 703, loss = 4202.31989443\n",
      "Iteration 704, loss = 4201.69666945\n",
      "Iteration 705, loss = 4201.07231828\n",
      "Iteration 706, loss = 4200.44679609\n",
      "Iteration 707, loss = 4199.82006114\n",
      "Iteration 708, loss = 4199.19207457\n",
      "Iteration 709, loss = 4198.56279997\n",
      "Iteration 710, loss = 4197.93220293\n",
      "Iteration 711, loss = 4197.30025035\n",
      "Iteration 712, loss = 4196.66690989\n",
      "Iteration 713, loss = 4196.03214936\n",
      "Iteration 714, loss = 4195.39593624\n",
      "Iteration 715, loss = 4194.75823732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 716, loss = 4194.11901845\n",
      "Iteration 717, loss = 4193.47824454\n",
      "Iteration 718, loss = 4192.83587959\n",
      "Iteration 719, loss = 4192.19188697\n",
      "Iteration 720, loss = 4191.54622981\n",
      "Iteration 721, loss = 4190.89887141\n",
      "Iteration 722, loss = 4190.24977585\n",
      "Iteration 723, loss = 4189.59890856\n",
      "Iteration 724, loss = 4188.94623695\n",
      "Iteration 725, loss = 4188.29173103\n",
      "Iteration 726, loss = 4187.63536401\n",
      "Iteration 727, loss = 4186.97711289\n",
      "Iteration 728, loss = 4186.31695894\n",
      "Iteration 729, loss = 4185.65488822\n",
      "Iteration 730, loss = 4184.99089196\n",
      "Iteration 731, loss = 4184.32496695\n",
      "Iteration 732, loss = 4183.65711580\n",
      "Iteration 733, loss = 4182.98734720\n",
      "Iteration 734, loss = 4182.31567614\n",
      "Iteration 735, loss = 4181.64212403\n",
      "Iteration 736, loss = 4180.96671880\n",
      "Iteration 737, loss = 4180.28949502\n",
      "Iteration 738, loss = 4179.61049385\n",
      "Iteration 739, loss = 4178.92976309\n",
      "Iteration 740, loss = 4178.24735709\n",
      "Iteration 741, loss = 4177.56333668\n",
      "Iteration 742, loss = 4176.87776900\n",
      "Iteration 743, loss = 4176.19072731\n",
      "Iteration 744, loss = 4175.50229078\n",
      "Iteration 745, loss = 4174.81254412\n",
      "Iteration 746, loss = 4174.12157727\n",
      "Iteration 747, loss = 4173.42948496\n",
      "Iteration 748, loss = 4172.73636618\n",
      "Iteration 749, loss = 4172.04232368\n",
      "Iteration 750, loss = 4171.34746337\n",
      "Iteration 751, loss = 4170.65189361\n",
      "Iteration 752, loss = 4169.95572461\n",
      "Iteration 753, loss = 4169.25906763\n",
      "Iteration 754, loss = 4168.56203430\n",
      "Iteration 755, loss = 4167.86473589\n",
      "Iteration 756, loss = 4167.16728252\n",
      "Iteration 757, loss = 4166.46978252\n",
      "Iteration 758, loss = 4165.77234175\n",
      "Iteration 759, loss = 4165.07506292\n",
      "Iteration 760, loss = 4164.37804506\n",
      "Iteration 761, loss = 4163.68138299\n",
      "Iteration 762, loss = 4162.98516688\n",
      "Iteration 763, loss = 4162.28948183\n",
      "Iteration 764, loss = 4161.59440760\n",
      "Iteration 765, loss = 4160.90001834\n",
      "Iteration 766, loss = 4160.20638244\n",
      "Iteration 767, loss = 4159.51356240\n",
      "Iteration 768, loss = 4158.82161480\n",
      "Iteration 769, loss = 4158.13059030\n",
      "Iteration 770, loss = 4157.44053372\n",
      "Iteration 771, loss = 4156.75148417\n",
      "Iteration 772, loss = 4156.06347517\n",
      "Iteration 773, loss = 4155.37653487\n",
      "Iteration 774, loss = 4154.69068625\n",
      "Iteration 775, loss = 4154.00594740\n",
      "Iteration 776, loss = 4153.32233178\n",
      "Iteration 777, loss = 4152.63984847\n",
      "Iteration 778, loss = 4151.95850252\n",
      "Iteration 779, loss = 4151.27829522\n",
      "Iteration 780, loss = 4150.59922440\n",
      "Iteration 781, loss = 4149.92128475\n",
      "Iteration 782, loss = 4149.24446812\n",
      "Iteration 783, loss = 4148.56876379\n",
      "Iteration 784, loss = 4147.89415878\n",
      "Iteration 785, loss = 4147.22063809\n",
      "Iteration 786, loss = 4146.54818500\n",
      "Iteration 787, loss = 4145.87678126\n",
      "Iteration 788, loss = 4145.20640734\n",
      "Iteration 789, loss = 4144.53704268\n",
      "Iteration 790, loss = 4143.86866580\n",
      "Iteration 791, loss = 4143.20125455\n",
      "Iteration 792, loss = 4142.53478625\n",
      "Iteration 793, loss = 4141.86923782\n",
      "Iteration 794, loss = 4141.20458593\n",
      "Iteration 795, loss = 4140.54080711\n",
      "Iteration 796, loss = 4139.87787786\n",
      "Iteration 797, loss = 4139.21577473\n",
      "Iteration 798, loss = 4138.55447442\n",
      "Iteration 799, loss = 4137.89395383\n",
      "Iteration 800, loss = 4137.23419012\n",
      "Iteration 801, loss = 4136.57516079\n",
      "Iteration 802, loss = 4135.91684370\n",
      "Iteration 803, loss = 4135.25921708\n",
      "Iteration 804, loss = 4134.60225964\n",
      "Iteration 805, loss = 4133.94595049\n",
      "Iteration 806, loss = 4133.29026924\n",
      "Iteration 807, loss = 4132.63519597\n",
      "Iteration 808, loss = 4131.98071126\n",
      "Iteration 809, loss = 4131.32679617\n",
      "Iteration 810, loss = 4130.67343227\n",
      "Iteration 811, loss = 4130.02060161\n",
      "Iteration 812, loss = 4129.36828675\n",
      "Iteration 813, loss = 4128.71647072\n",
      "Iteration 814, loss = 4128.06513703\n",
      "Iteration 815, loss = 4127.41426964\n",
      "Iteration 816, loss = 4126.76385299\n",
      "Iteration 817, loss = 4126.11387195\n",
      "Iteration 818, loss = 4125.46431183\n",
      "Iteration 819, loss = 4124.81515835\n",
      "Iteration 820, loss = 4124.16639765\n",
      "Iteration 821, loss = 4123.51801623\n",
      "Iteration 822, loss = 4122.87000100\n",
      "Iteration 823, loss = 4122.22233922\n",
      "Iteration 824, loss = 4121.57501851\n",
      "Iteration 825, loss = 4120.92802681\n",
      "Iteration 826, loss = 4120.28135239\n",
      "Iteration 827, loss = 4119.63498384\n",
      "Iteration 828, loss = 4118.98891003\n",
      "Iteration 829, loss = 4118.34312013\n",
      "Iteration 830, loss = 4117.69760355\n",
      "Iteration 831, loss = 4117.05234999\n",
      "Iteration 832, loss = 4116.40734938\n",
      "Iteration 833, loss = 4115.76259189\n",
      "Iteration 834, loss = 4115.11806792\n",
      "Iteration 835, loss = 4114.47376806\n",
      "Iteration 836, loss = 4113.82968313\n",
      "Iteration 837, loss = 4113.18580413\n",
      "Iteration 838, loss = 4112.54212223\n",
      "Iteration 839, loss = 4111.89862881\n",
      "Iteration 840, loss = 4111.25531538\n",
      "Iteration 841, loss = 4110.61217362\n",
      "Iteration 842, loss = 4109.96919538\n",
      "Iteration 843, loss = 4109.32637262\n",
      "Iteration 844, loss = 4108.68369746\n",
      "Iteration 845, loss = 4108.04116213\n",
      "Iteration 846, loss = 4107.39875899\n",
      "Iteration 847, loss = 4106.75648054\n",
      "Iteration 848, loss = 4106.11431935\n",
      "Iteration 849, loss = 4105.47226812\n",
      "Iteration 850, loss = 4104.83031966\n",
      "Iteration 851, loss = 4104.18846685\n",
      "Iteration 852, loss = 4103.54670269\n",
      "Iteration 853, loss = 4102.90502024\n",
      "Iteration 854, loss = 4102.26341268\n",
      "Iteration 855, loss = 4101.62187324\n",
      "Iteration 856, loss = 4100.98039525\n",
      "Iteration 857, loss = 4100.33897210\n",
      "Iteration 858, loss = 4099.69759727\n",
      "Iteration 859, loss = 4099.05626430\n",
      "Iteration 860, loss = 4098.41496680\n",
      "Iteration 861, loss = 4097.77369845\n",
      "Iteration 862, loss = 4097.13245300\n",
      "Iteration 863, loss = 4096.49122426\n",
      "Iteration 864, loss = 4095.85000611\n",
      "Iteration 865, loss = 4095.20879249\n",
      "Iteration 866, loss = 4094.56757740\n",
      "Iteration 867, loss = 4093.92635491\n",
      "Iteration 868, loss = 4093.28511915\n",
      "Iteration 869, loss = 4092.64386431\n",
      "Iteration 870, loss = 4092.00258465\n",
      "Iteration 871, loss = 4091.36127447\n",
      "Iteration 872, loss = 4090.71992817\n",
      "Iteration 873, loss = 4090.07854019\n",
      "Iteration 874, loss = 4089.43710504\n",
      "Iteration 875, loss = 4088.79561730\n",
      "Iteration 876, loss = 4088.15407161\n",
      "Iteration 877, loss = 4087.51246270\n",
      "Iteration 878, loss = 4086.87078535\n",
      "Iteration 879, loss = 4086.22903441\n",
      "Iteration 880, loss = 4085.58720482\n",
      "Iteration 881, loss = 4084.94529158\n",
      "Iteration 882, loss = 4084.30328977\n",
      "Iteration 883, loss = 4083.66119456\n",
      "Iteration 884, loss = 4083.01900118\n",
      "Iteration 885, loss = 4082.37670497\n",
      "Iteration 886, loss = 4081.73430132\n",
      "Iteration 887, loss = 4081.09178573\n",
      "Iteration 888, loss = 4080.44915378\n",
      "Iteration 889, loss = 4079.80640114\n",
      "Iteration 890, loss = 4079.16352357\n",
      "Iteration 891, loss = 4078.52051693\n",
      "Iteration 892, loss = 4077.87737715\n",
      "Iteration 893, loss = 4077.23410029\n",
      "Iteration 894, loss = 4076.59068248\n",
      "Iteration 895, loss = 4075.94711997\n",
      "Iteration 896, loss = 4075.30340908\n",
      "Iteration 897, loss = 4074.65954627\n",
      "Iteration 898, loss = 4074.01552807\n",
      "Iteration 899, loss = 4073.37135113\n",
      "Iteration 900, loss = 4072.72701219\n",
      "Iteration 901, loss = 4072.08250811\n",
      "Iteration 902, loss = 4071.43783585\n",
      "Iteration 903, loss = 4070.79299247\n",
      "Iteration 904, loss = 4070.14797513\n",
      "Iteration 905, loss = 4069.50278111\n",
      "Iteration 906, loss = 4068.85740779\n",
      "Iteration 907, loss = 4068.21185265\n",
      "Iteration 908, loss = 4067.56611329\n",
      "Iteration 909, loss = 4066.92018739\n",
      "Iteration 910, loss = 4066.27407275\n",
      "Iteration 911, loss = 4065.62776727\n",
      "Iteration 912, loss = 4064.98126896\n",
      "Iteration 913, loss = 4064.33457592\n",
      "Iteration 914, loss = 4063.68768637\n",
      "Iteration 915, loss = 4063.04059861\n",
      "Iteration 916, loss = 4062.39331104\n",
      "Iteration 917, loss = 4061.74582219\n",
      "Iteration 918, loss = 4061.09813066\n",
      "Iteration 919, loss = 4060.45023514\n",
      "Iteration 920, loss = 4059.80213446\n",
      "Iteration 921, loss = 4059.15382750\n",
      "Iteration 922, loss = 4058.50531327\n",
      "Iteration 923, loss = 4057.85659087\n",
      "Iteration 924, loss = 4057.20765948\n",
      "Iteration 925, loss = 4056.55851839\n",
      "Iteration 926, loss = 4055.90916699\n",
      "Iteration 927, loss = 4055.25960476\n",
      "Iteration 928, loss = 4054.60983128\n",
      "Iteration 929, loss = 4053.95984622\n",
      "Iteration 930, loss = 4053.30964936\n",
      "Iteration 931, loss = 4052.65924057\n",
      "Iteration 932, loss = 4052.00861981\n",
      "Iteration 933, loss = 4051.35778717\n",
      "Iteration 934, loss = 4050.70674279\n",
      "Iteration 935, loss = 4050.05548694\n",
      "Iteration 936, loss = 4049.40402000\n",
      "Iteration 937, loss = 4048.75234241\n",
      "Iteration 938, loss = 4048.10045475\n",
      "Iteration 939, loss = 4047.44835766\n",
      "Iteration 940, loss = 4046.79605190\n",
      "Iteration 941, loss = 4046.14353831\n",
      "Iteration 942, loss = 4045.49081784\n",
      "Iteration 943, loss = 4044.83789152\n",
      "Iteration 944, loss = 4044.18476045\n",
      "Iteration 945, loss = 4043.53142585\n",
      "Iteration 946, loss = 4042.87788899\n",
      "Iteration 947, loss = 4042.22415123\n",
      "Iteration 948, loss = 4041.57021400\n",
      "Iteration 949, loss = 4040.91607879\n",
      "Iteration 950, loss = 4040.26174716\n",
      "Iteration 951, loss = 4039.60722071\n",
      "Iteration 952, loss = 4038.95250110\n",
      "Iteration 953, loss = 4038.29759002\n",
      "Iteration 954, loss = 4037.64248919\n",
      "Iteration 955, loss = 4036.98720037\n",
      "Iteration 956, loss = 4036.33172533\n",
      "Iteration 957, loss = 4035.67606583\n",
      "Iteration 958, loss = 4035.02022366\n",
      "Iteration 959, loss = 4034.36420059\n",
      "Iteration 960, loss = 4033.70799838\n",
      "Iteration 961, loss = 4033.05161876\n",
      "Iteration 962, loss = 4032.39506345\n",
      "Iteration 963, loss = 4031.73833411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 964, loss = 4031.08143241\n",
      "Iteration 965, loss = 4030.42435992\n",
      "Iteration 966, loss = 4029.76711821\n",
      "Iteration 967, loss = 4029.10970878\n",
      "Iteration 968, loss = 4028.45213308\n",
      "Iteration 969, loss = 4027.79439254\n",
      "Iteration 970, loss = 4027.13648850\n",
      "Iteration 971, loss = 4026.47842229\n",
      "Iteration 972, loss = 4025.82019517\n",
      "Iteration 973, loss = 4025.16180839\n",
      "Iteration 974, loss = 4024.50326315\n",
      "Iteration 975, loss = 4023.84456065\n",
      "Iteration 976, loss = 4023.18570204\n",
      "Iteration 977, loss = 4022.52668850\n",
      "Iteration 978, loss = 4021.86752119\n",
      "Iteration 979, loss = 4021.20820130\n",
      "Iteration 980, loss = 4020.54873005\n",
      "Iteration 981, loss = 4019.88910869\n",
      "Iteration 982, loss = 4019.22933854\n",
      "Iteration 983, loss = 4018.56942098\n",
      "Iteration 984, loss = 4017.90935746\n",
      "Iteration 985, loss = 4017.24914954\n",
      "Iteration 986, loss = 4016.58879888\n",
      "Iteration 987, loss = 4015.92830728\n",
      "Iteration 988, loss = 4015.26767664\n",
      "Iteration 989, loss = 4014.60690904\n",
      "Iteration 990, loss = 4013.94600669\n",
      "Iteration 991, loss = 4013.28497198\n",
      "Iteration 992, loss = 4012.62380747\n",
      "Iteration 993, loss = 4011.96251592\n",
      "Iteration 994, loss = 4011.30110025\n",
      "Iteration 995, loss = 4010.63956360\n",
      "Iteration 996, loss = 4009.97790932\n",
      "Iteration 997, loss = 4009.31614092\n",
      "Iteration 998, loss = 4008.65426216\n",
      "Iteration 999, loss = 4007.99227698\n",
      "Iteration 1000, loss = 4007.33018952\n",
      "Iteration 1001, loss = 4006.66800413\n",
      "Iteration 1002, loss = 4006.00572536\n",
      "Iteration 1003, loss = 4005.34335791\n",
      "Iteration 1004, loss = 4004.68090671\n",
      "Iteration 1005, loss = 4004.01837682\n",
      "Iteration 1006, loss = 4003.35577349\n",
      "Iteration 1007, loss = 4002.69310209\n",
      "Iteration 1008, loss = 4002.03036816\n",
      "Iteration 1009, loss = 4001.36757733\n",
      "Iteration 1010, loss = 4000.70473537\n",
      "Iteration 1011, loss = 4000.04184810\n",
      "Iteration 1012, loss = 3999.37892147\n",
      "Iteration 1013, loss = 3998.71596144\n",
      "Iteration 1014, loss = 3998.05297403\n",
      "Iteration 1015, loss = 3997.38996530\n",
      "Iteration 1016, loss = 3996.72694129\n",
      "Iteration 1017, loss = 3996.06390804\n",
      "Iteration 1018, loss = 3995.40087156\n",
      "Iteration 1019, loss = 3994.73783779\n",
      "Iteration 1020, loss = 3994.07481262\n",
      "Iteration 1021, loss = 3993.41180186\n",
      "Iteration 1022, loss = 3992.74881119\n",
      "Iteration 1023, loss = 3992.08584620\n",
      "Iteration 1024, loss = 3991.42291231\n",
      "Iteration 1025, loss = 3990.76001481\n",
      "Iteration 1026, loss = 3990.09715882\n",
      "Iteration 1027, loss = 3989.43434927\n",
      "Iteration 1028, loss = 3988.77159091\n",
      "Iteration 1029, loss = 3988.10888828\n",
      "Iteration 1030, loss = 3987.44624569\n",
      "Iteration 1031, loss = 3986.78366727\n",
      "Iteration 1032, loss = 3986.12115687\n",
      "Iteration 1033, loss = 3985.45871816\n",
      "Iteration 1034, loss = 3984.79635454\n",
      "Iteration 1035, loss = 3984.13406917\n",
      "Iteration 1036, loss = 3983.47186499\n",
      "Iteration 1037, loss = 3982.80974470\n",
      "Iteration 1038, loss = 3982.14771074\n",
      "Iteration 1039, loss = 3981.48576536\n",
      "Iteration 1040, loss = 3980.82391055\n",
      "Iteration 1041, loss = 3980.16214811\n",
      "Iteration 1042, loss = 3979.50047960\n",
      "Iteration 1043, loss = 3978.83890642\n",
      "Iteration 1044, loss = 3978.17742975\n",
      "Iteration 1045, loss = 3977.51605060\n",
      "Iteration 1046, loss = 3976.85476982\n",
      "Iteration 1047, loss = 3976.19358810\n",
      "Iteration 1048, loss = 3975.53250600\n",
      "Iteration 1049, loss = 3974.87152395\n",
      "Iteration 1050, loss = 3974.21064226\n",
      "Iteration 1051, loss = 3973.54986115\n",
      "Iteration 1052, loss = 3972.88918076\n",
      "Iteration 1053, loss = 3972.22860113\n",
      "Iteration 1054, loss = 3971.56812227\n",
      "Iteration 1055, loss = 3970.90774413\n",
      "Iteration 1056, loss = 3970.24746662\n",
      "Iteration 1057, loss = 3969.58728964\n",
      "Iteration 1058, loss = 3968.92721306\n",
      "Iteration 1059, loss = 3968.26723674\n",
      "Iteration 1060, loss = 3967.60736056\n",
      "Iteration 1061, loss = 3966.94758440\n",
      "Iteration 1062, loss = 3966.28790816\n",
      "Iteration 1063, loss = 3965.62833174\n",
      "Iteration 1064, loss = 3964.96885509\n",
      "Iteration 1065, loss = 3964.30947818\n",
      "Iteration 1066, loss = 3963.65020102\n",
      "Iteration 1067, loss = 3962.99102364\n",
      "Iteration 1068, loss = 3962.33194611\n",
      "Iteration 1069, loss = 3961.67296855\n",
      "Iteration 1070, loss = 3961.01409108\n",
      "Iteration 1071, loss = 3960.35531389\n",
      "Iteration 1072, loss = 3959.69663718\n",
      "Iteration 1073, loss = 3959.03806120\n",
      "Iteration 1074, loss = 3958.37958620\n",
      "Iteration 1075, loss = 3957.72121250\n",
      "Iteration 1076, loss = 3957.06294040\n",
      "Iteration 1077, loss = 3956.40477025\n",
      "Iteration 1078, loss = 3955.74670241\n",
      "Iteration 1079, loss = 3955.08873725\n",
      "Iteration 1080, loss = 3954.43087515\n",
      "Iteration 1081, loss = 3953.77311653\n",
      "Iteration 1082, loss = 3953.11546179\n",
      "Iteration 1083, loss = 3952.45791133\n",
      "Iteration 1084, loss = 3951.80046557\n",
      "Iteration 1085, loss = 3951.14312494\n",
      "Iteration 1086, loss = 3950.48588984\n",
      "Iteration 1087, loss = 3949.82876068\n",
      "Iteration 1088, loss = 3949.17173789\n",
      "Iteration 1089, loss = 3948.51482185\n",
      "Iteration 1090, loss = 3947.85801298\n",
      "Iteration 1091, loss = 3947.20131165\n",
      "Iteration 1092, loss = 3946.54471825\n",
      "Iteration 1093, loss = 3945.88823315\n",
      "Iteration 1094, loss = 3945.23185673\n",
      "Iteration 1095, loss = 3944.57558934\n",
      "Iteration 1096, loss = 3943.91943133\n",
      "Iteration 1097, loss = 3943.26338304\n",
      "Iteration 1098, loss = 3942.60744480\n",
      "Iteration 1099, loss = 3941.95161695\n",
      "Iteration 1100, loss = 3941.29589979\n",
      "Iteration 1101, loss = 3940.64029364\n",
      "Iteration 1102, loss = 3939.98479880\n",
      "Iteration 1103, loss = 3939.32941559\n",
      "Iteration 1104, loss = 3938.67414428\n",
      "Iteration 1105, loss = 3938.01898518\n",
      "Iteration 1106, loss = 3937.36393858\n",
      "Iteration 1107, loss = 3936.70900475\n",
      "Iteration 1108, loss = 3936.05418399\n",
      "Iteration 1109, loss = 3935.39947658\n",
      "Iteration 1110, loss = 3934.74488279\n",
      "Iteration 1111, loss = 3934.09040292\n",
      "Iteration 1112, loss = 3933.43603724\n",
      "Iteration 1113, loss = 3932.78178603\n",
      "Iteration 1114, loss = 3932.12764959\n",
      "Iteration 1115, loss = 3931.47362821\n",
      "Iteration 1116, loss = 3930.81972216\n",
      "Iteration 1117, loss = 3930.16593176\n",
      "Iteration 1118, loss = 3929.51225729\n",
      "Iteration 1119, loss = 3928.85869906\n",
      "Iteration 1120, loss = 3928.20525737\n",
      "Iteration 1121, loss = 3927.55193255\n",
      "Iteration 1122, loss = 3926.89872490\n",
      "Iteration 1123, loss = 3926.24563474\n",
      "Iteration 1124, loss = 3925.59266242\n",
      "Iteration 1125, loss = 3924.93980826\n",
      "Iteration 1126, loss = 3924.28707261\n",
      "Iteration 1127, loss = 3923.63445581\n",
      "Iteration 1128, loss = 3922.98195823\n",
      "Iteration 1129, loss = 3922.32958023\n",
      "Iteration 1130, loss = 3921.67732218\n",
      "Iteration 1131, loss = 3921.02518446\n",
      "Iteration 1132, loss = 3920.37316746\n",
      "Iteration 1133, loss = 3919.72127157\n",
      "Iteration 1134, loss = 3919.06949720\n",
      "Iteration 1135, loss = 3918.41784477\n",
      "Iteration 1136, loss = 3917.76631470\n",
      "Iteration 1137, loss = 3917.11490741\n",
      "Iteration 1138, loss = 3916.46362335\n",
      "Iteration 1139, loss = 3915.81246297\n",
      "Iteration 1140, loss = 3915.16142673\n",
      "Iteration 1141, loss = 3914.51051509\n",
      "Iteration 1142, loss = 3913.85972854\n",
      "Iteration 1143, loss = 3913.20906755\n",
      "Iteration 1144, loss = 3912.55853263\n",
      "Iteration 1145, loss = 3911.90812428\n",
      "Iteration 1146, loss = 3911.25784300\n",
      "Iteration 1147, loss = 3910.60768933\n",
      "Iteration 1148, loss = 3909.95766380\n",
      "Iteration 1149, loss = 3909.30776695\n",
      "Iteration 1150, loss = 3908.65799932\n",
      "Iteration 1151, loss = 3908.00836147\n",
      "Iteration 1152, loss = 3907.35885397\n",
      "Iteration 1153, loss = 3906.70947740\n",
      "Iteration 1154, loss = 3906.06023233\n",
      "Iteration 1155, loss = 3905.41111935\n",
      "Iteration 1156, loss = 3904.76213906\n",
      "Iteration 1157, loss = 3904.11329207\n",
      "Iteration 1158, loss = 3903.46457899\n",
      "Iteration 1159, loss = 3902.81600042\n",
      "Iteration 1160, loss = 3902.16755700\n",
      "Iteration 1161, loss = 3901.51924936\n",
      "Iteration 1162, loss = 3900.87107813\n",
      "Iteration 1163, loss = 3900.22304394\n",
      "Iteration 1164, loss = 3899.57514745\n",
      "Iteration 1165, loss = 3898.92738930\n",
      "Iteration 1166, loss = 3898.27977015\n",
      "Iteration 1167, loss = 3897.63229065\n",
      "Iteration 1168, loss = 3896.98495146\n",
      "Iteration 1169, loss = 3896.33775325\n",
      "Iteration 1170, loss = 3895.69069668\n",
      "Iteration 1171, loss = 3895.04378242\n",
      "Iteration 1172, loss = 3894.39701113\n",
      "Iteration 1173, loss = 3893.75038348\n",
      "Iteration 1174, loss = 3893.10390015\n",
      "Iteration 1175, loss = 3892.45756181\n",
      "Iteration 1176, loss = 3891.81136912\n",
      "Iteration 1177, loss = 3891.16532276\n",
      "Iteration 1178, loss = 3890.51942340\n",
      "Iteration 1179, loss = 3889.87367171\n",
      "Iteration 1180, loss = 3889.22806834\n",
      "Iteration 1181, loss = 3888.58261397\n",
      "Iteration 1182, loss = 3887.93730926\n",
      "Iteration 1183, loss = 3887.29215487\n",
      "Iteration 1184, loss = 3886.64715146\n",
      "Iteration 1185, loss = 3886.00229967\n",
      "Iteration 1186, loss = 3885.35760016\n",
      "Iteration 1187, loss = 3884.71305357\n",
      "Iteration 1188, loss = 3884.06866055\n",
      "Iteration 1189, loss = 3883.42442173\n",
      "Iteration 1190, loss = 3882.78033775\n",
      "Iteration 1191, loss = 3882.13640923\n",
      "Iteration 1192, loss = 3881.49263679\n",
      "Iteration 1193, loss = 3880.84902105\n",
      "Iteration 1194, loss = 3880.20556262\n",
      "Iteration 1195, loss = 3879.56226211\n",
      "Iteration 1196, loss = 3878.91912012\n",
      "Iteration 1197, loss = 3878.27613724\n",
      "Iteration 1198, loss = 3877.63331405\n",
      "Iteration 1199, loss = 3876.99065115\n",
      "Iteration 1200, loss = 3876.34814909\n",
      "Iteration 1201, loss = 3875.70580846\n",
      "Iteration 1202, loss = 3875.06362981\n",
      "Iteration 1203, loss = 3874.42161370\n",
      "Iteration 1204, loss = 3873.77976068\n",
      "Iteration 1205, loss = 3873.13807129\n",
      "Iteration 1206, loss = 3872.49654607\n",
      "Iteration 1207, loss = 3871.85518554\n",
      "Iteration 1208, loss = 3871.21399024\n",
      "Iteration 1209, loss = 3870.57296066\n",
      "Iteration 1210, loss = 3869.93209734\n",
      "Iteration 1211, loss = 3869.29140076\n",
      "Iteration 1212, loss = 3868.65087143\n",
      "Iteration 1213, loss = 3868.01050984\n",
      "Iteration 1214, loss = 3867.37031648\n",
      "Iteration 1215, loss = 3866.73029182\n",
      "Iteration 1216, loss = 3866.09043634\n",
      "Iteration 1217, loss = 3865.45075051\n",
      "Iteration 1218, loss = 3864.81123479\n",
      "Iteration 1219, loss = 3864.17188963\n",
      "Iteration 1220, loss = 3863.53271549\n",
      "Iteration 1221, loss = 3862.89371282\n",
      "Iteration 1222, loss = 3862.25488205\n",
      "Iteration 1223, loss = 3861.61622363\n",
      "Iteration 1224, loss = 3860.97773798\n",
      "Iteration 1225, loss = 3860.33942553\n",
      "Iteration 1226, loss = 3859.70128670\n",
      "Iteration 1227, loss = 3859.06332191\n",
      "Iteration 1228, loss = 3858.42553158\n",
      "Iteration 1229, loss = 3857.78791611\n",
      "Iteration 1230, loss = 3857.15047591\n",
      "Iteration 1231, loss = 3856.51321138\n",
      "Iteration 1232, loss = 3855.87612292\n",
      "Iteration 1233, loss = 3855.23921092\n",
      "Iteration 1234, loss = 3854.60247577\n",
      "Iteration 1235, loss = 3853.96591786\n",
      "Iteration 1236, loss = 3853.32953756\n",
      "Iteration 1237, loss = 3852.69333527\n",
      "Iteration 1238, loss = 3852.05731135\n",
      "Iteration 1239, loss = 3851.42146619\n",
      "Iteration 1240, loss = 3850.78580014\n",
      "Iteration 1241, loss = 3850.15031358\n",
      "Iteration 1242, loss = 3849.51500687\n",
      "Iteration 1243, loss = 3848.87988037\n",
      "Iteration 1244, loss = 3848.24493444\n",
      "Iteration 1245, loss = 3847.61016944\n",
      "Iteration 1246, loss = 3846.97558572\n",
      "Iteration 1247, loss = 3846.34118363\n",
      "Iteration 1248, loss = 3845.70696351\n",
      "Iteration 1249, loss = 3845.07292572\n",
      "Iteration 1250, loss = 3844.43907060\n",
      "Iteration 1251, loss = 3843.80539848\n",
      "Iteration 1252, loss = 3843.17190970\n",
      "Iteration 1253, loss = 3842.53860460\n",
      "Iteration 1254, loss = 3841.90548352\n",
      "Iteration 1255, loss = 3841.27254677\n",
      "Iteration 1256, loss = 3840.63979470\n",
      "Iteration 1257, loss = 3840.00722762\n",
      "Iteration 1258, loss = 3839.37484586\n",
      "Iteration 1259, loss = 3838.74264973\n",
      "Iteration 1260, loss = 3838.11063957\n",
      "Iteration 1261, loss = 3837.47881568\n",
      "Iteration 1262, loss = 3836.84717838\n",
      "Iteration 1263, loss = 3836.21572797\n",
      "Iteration 1264, loss = 3835.58446478\n",
      "Iteration 1265, loss = 3834.95338910\n",
      "Iteration 1266, loss = 3834.32250124\n",
      "Iteration 1267, loss = 3833.69180150\n",
      "Iteration 1268, loss = 3833.06129018\n",
      "Iteration 1269, loss = 3832.43096758\n",
      "Iteration 1270, loss = 3831.80083400\n",
      "Iteration 1271, loss = 3831.17088972\n",
      "Iteration 1272, loss = 3830.54113504\n",
      "Iteration 1273, loss = 3829.91157024\n",
      "Iteration 1274, loss = 3829.28219562\n",
      "Iteration 1275, loss = 3828.65301144\n",
      "Iteration 1276, loss = 3828.02401801\n",
      "Iteration 1277, loss = 3827.39521558\n",
      "Iteration 1278, loss = 3826.76660445\n",
      "Iteration 1279, loss = 3826.13818488\n",
      "Iteration 1280, loss = 3825.50995714\n",
      "Iteration 1281, loss = 3824.88192151\n",
      "Iteration 1282, loss = 3824.25407825\n",
      "Iteration 1283, loss = 3823.62642762\n",
      "Iteration 1284, loss = 3822.99896989\n",
      "Iteration 1285, loss = 3822.37170532\n",
      "Iteration 1286, loss = 3821.74463417\n",
      "Iteration 1287, loss = 3821.11775668\n",
      "Iteration 1288, loss = 3820.49107312\n",
      "Iteration 1289, loss = 3819.86458373\n",
      "Iteration 1290, loss = 3819.23828876\n",
      "Iteration 1291, loss = 3818.61218846\n",
      "Iteration 1292, loss = 3817.98628307\n",
      "Iteration 1293, loss = 3817.36057284\n",
      "Iteration 1294, loss = 3816.73505799\n",
      "Iteration 1295, loss = 3816.10973878\n",
      "Iteration 1296, loss = 3815.48461542\n",
      "Iteration 1297, loss = 3814.85968817\n",
      "Iteration 1298, loss = 3814.23495723\n",
      "Iteration 1299, loss = 3813.61042285\n",
      "Iteration 1300, loss = 3812.98608525\n",
      "Iteration 1301, loss = 3812.36194465\n",
      "Iteration 1302, loss = 3811.73800127\n",
      "Iteration 1303, loss = 3811.11425534\n",
      "Iteration 1304, loss = 3810.49070706\n",
      "Iteration 1305, loss = 3809.86735666\n",
      "Iteration 1306, loss = 3809.24420434\n",
      "Iteration 1307, loss = 3808.62125032\n",
      "Iteration 1308, loss = 3807.99849481\n",
      "Iteration 1309, loss = 3807.37593800\n",
      "Iteration 1310, loss = 3806.75358011\n",
      "Iteration 1311, loss = 3806.13142134\n",
      "Iteration 1312, loss = 3805.50946189\n",
      "Iteration 1313, loss = 3804.88770195\n",
      "Iteration 1314, loss = 3804.26614172\n",
      "Iteration 1315, loss = 3803.64478139\n",
      "Iteration 1316, loss = 3803.02362117\n",
      "Iteration 1317, loss = 3802.40266123\n",
      "Iteration 1318, loss = 3801.78190176\n",
      "Iteration 1319, loss = 3801.16134296\n",
      "Iteration 1320, loss = 3800.54098500\n",
      "Iteration 1321, loss = 3799.92082807\n",
      "Iteration 1322, loss = 3799.30087234\n",
      "Iteration 1323, loss = 3798.68111800\n",
      "Iteration 1324, loss = 3798.06156522\n",
      "Iteration 1325, loss = 3797.44221418\n",
      "Iteration 1326, loss = 3796.82306505\n",
      "Iteration 1327, loss = 3796.20411800\n",
      "Iteration 1328, loss = 3795.58537320\n",
      "Iteration 1329, loss = 3794.96683082\n",
      "Iteration 1330, loss = 3794.34849101\n",
      "Iteration 1331, loss = 3793.73035396\n",
      "Iteration 1332, loss = 3793.11241981\n",
      "Iteration 1333, loss = 3792.49468873\n",
      "Iteration 1334, loss = 3791.87716087\n",
      "Iteration 1335, loss = 3791.25983640\n",
      "Iteration 1336, loss = 3790.64271547\n",
      "Iteration 1337, loss = 3790.02579823\n",
      "Iteration 1338, loss = 3789.40908484\n",
      "Iteration 1339, loss = 3788.79257543\n",
      "Iteration 1340, loss = 3788.17627017\n",
      "Iteration 1341, loss = 3787.56016920\n",
      "Iteration 1342, loss = 3786.94427266\n",
      "Iteration 1343, loss = 3786.32858070\n",
      "Iteration 1344, loss = 3785.71309346\n",
      "Iteration 1345, loss = 3785.09781108\n",
      "Iteration 1346, loss = 3784.48273369\n",
      "Iteration 1347, loss = 3783.86786145\n",
      "Iteration 1348, loss = 3783.25319447\n",
      "Iteration 1349, loss = 3782.63873290\n",
      "Iteration 1350, loss = 3782.02447687\n",
      "Iteration 1351, loss = 3781.41042651\n",
      "Iteration 1352, loss = 3780.79658194\n",
      "Iteration 1353, loss = 3780.18294331\n",
      "Iteration 1354, loss = 3779.56951073\n",
      "Iteration 1355, loss = 3778.95628433\n",
      "Iteration 1356, loss = 3778.34326423\n",
      "Iteration 1357, loss = 3777.73045056\n",
      "Iteration 1358, loss = 3777.11784343\n",
      "Iteration 1359, loss = 3776.50544297\n",
      "Iteration 1360, loss = 3775.89324930\n",
      "Iteration 1361, loss = 3775.28126252\n",
      "Iteration 1362, loss = 3774.66948277\n",
      "Iteration 1363, loss = 3774.05791014\n",
      "Iteration 1364, loss = 3773.44654476\n",
      "Iteration 1365, loss = 3772.83538674\n",
      "Iteration 1366, loss = 3772.22443618\n",
      "Iteration 1367, loss = 3771.61369320\n",
      "Iteration 1368, loss = 3771.00315789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1369, loss = 3770.39283038\n",
      "Iteration 1370, loss = 3769.78271076\n",
      "Iteration 1371, loss = 3769.17279914\n",
      "Iteration 1372, loss = 3768.56309561\n",
      "Iteration 1373, loss = 3767.95360029\n",
      "Iteration 1374, loss = 3767.34431327\n",
      "Iteration 1375, loss = 3766.73523465\n",
      "Iteration 1376, loss = 3766.12636452\n",
      "Iteration 1377, loss = 3765.51770299\n",
      "Iteration 1378, loss = 3764.90925015\n",
      "Iteration 1379, loss = 3764.30100609\n",
      "Iteration 1380, loss = 3763.69297091\n",
      "Iteration 1381, loss = 3763.08514470\n",
      "Iteration 1382, loss = 3762.47752754\n",
      "Iteration 1383, loss = 3761.87011953\n",
      "Iteration 1384, loss = 3761.26292076\n",
      "Iteration 1385, loss = 3760.65593130\n",
      "Iteration 1386, loss = 3760.04915126\n",
      "Iteration 1387, loss = 3759.44258071\n",
      "Iteration 1388, loss = 3758.83621974\n",
      "Iteration 1389, loss = 3758.23006843\n",
      "Iteration 1390, loss = 3757.62412686\n",
      "Iteration 1391, loss = 3757.01839511\n",
      "Iteration 1392, loss = 3756.41287327\n",
      "Iteration 1393, loss = 3755.80756140\n",
      "Iteration 1394, loss = 3755.20245959\n",
      "Iteration 1395, loss = 3754.59756792\n",
      "Iteration 1396, loss = 3753.99288646\n",
      "Iteration 1397, loss = 3753.38841528\n",
      "Iteration 1398, loss = 3752.78415446\n",
      "Iteration 1399, loss = 3752.18010406\n",
      "Iteration 1400, loss = 3751.57626417\n",
      "Iteration 1401, loss = 3750.97263485\n",
      "Iteration 1402, loss = 3750.36921617\n",
      "Iteration 1403, loss = 3749.76600820\n",
      "Iteration 1404, loss = 3749.16301100\n",
      "Iteration 1405, loss = 3748.56022465\n",
      "Iteration 1406, loss = 3747.95764921\n",
      "Iteration 1407, loss = 3747.35528474\n",
      "Iteration 1408, loss = 3746.75313130\n",
      "Iteration 1409, loss = 3746.15118897\n",
      "Iteration 1410, loss = 3745.54945780\n",
      "Iteration 1411, loss = 3744.94793784\n",
      "Iteration 1412, loss = 3744.34662918\n",
      "Iteration 1413, loss = 3743.74553185\n",
      "Iteration 1414, loss = 3743.14464592\n",
      "Iteration 1415, loss = 3742.54397145\n",
      "Iteration 1416, loss = 3741.94350849\n",
      "Iteration 1417, loss = 3741.34325710\n",
      "Iteration 1418, loss = 3740.74321734\n",
      "Iteration 1419, loss = 3740.14338925\n",
      "Iteration 1420, loss = 3739.54377289\n",
      "Iteration 1421, loss = 3738.94436832\n",
      "Iteration 1422, loss = 3738.34517558\n",
      "Iteration 1423, loss = 3737.74619472\n",
      "Iteration 1424, loss = 3737.14742580\n",
      "Iteration 1425, loss = 3736.54886886\n",
      "Iteration 1426, loss = 3735.95052396\n",
      "Iteration 1427, loss = 3735.35239113\n",
      "Iteration 1428, loss = 3734.75447043\n",
      "Iteration 1429, loss = 3734.15676189\n",
      "Iteration 1430, loss = 3733.55926558\n",
      "Iteration 1431, loss = 3732.96198152\n",
      "Iteration 1432, loss = 3732.36490977\n",
      "Iteration 1433, loss = 3731.76805036\n",
      "Iteration 1434, loss = 3731.17140334\n",
      "Iteration 1435, loss = 3730.57496875\n",
      "Iteration 1436, loss = 3729.97874663\n",
      "Iteration 1437, loss = 3729.38273702\n",
      "Iteration 1438, loss = 3728.78693995\n",
      "Iteration 1439, loss = 3728.19135547\n",
      "Iteration 1440, loss = 3727.59598362\n",
      "Iteration 1441, loss = 3727.00082442\n",
      "Iteration 1442, loss = 3726.40587792\n",
      "Iteration 1443, loss = 3725.81114415\n",
      "Iteration 1444, loss = 3725.21662314\n",
      "Iteration 1445, loss = 3724.62231494\n",
      "Iteration 1446, loss = 3724.02821956\n",
      "Iteration 1447, loss = 3723.43433705\n",
      "Iteration 1448, loss = 3722.84066744\n",
      "Iteration 1449, loss = 3722.24721076\n",
      "Iteration 1450, loss = 3721.65396703\n",
      "Iteration 1451, loss = 3721.06093629\n",
      "Iteration 1452, loss = 3720.46811857\n",
      "Iteration 1453, loss = 3719.87551389\n",
      "Iteration 1454, loss = 3719.28312229\n",
      "Iteration 1455, loss = 3718.69094379\n",
      "Iteration 1456, loss = 3718.09897841\n",
      "Iteration 1457, loss = 3717.50722619\n",
      "Iteration 1458, loss = 3716.91568714\n",
      "Iteration 1459, loss = 3716.32436129\n",
      "Iteration 1460, loss = 3715.73324868\n",
      "Iteration 1461, loss = 3715.14234931\n",
      "Iteration 1462, loss = 3714.55166321\n",
      "Iteration 1463, loss = 3713.96119041\n",
      "Iteration 1464, loss = 3713.37093092\n",
      "Iteration 1465, loss = 3712.78088477\n",
      "Iteration 1466, loss = 3712.19105197\n",
      "Iteration 1467, loss = 3711.60143255\n",
      "Iteration 1468, loss = 3711.01202653\n",
      "Iteration 1469, loss = 3710.42283392\n",
      "Iteration 1470, loss = 3709.83385474\n",
      "Iteration 1471, loss = 3709.24508901\n",
      "Iteration 1472, loss = 3708.65653675\n",
      "Iteration 1473, loss = 3708.06819797\n",
      "Iteration 1474, loss = 3707.48007268\n",
      "Iteration 1475, loss = 3706.89216091\n",
      "Iteration 1476, loss = 3706.30446267\n",
      "Iteration 1477, loss = 3705.71697796\n",
      "Iteration 1478, loss = 3705.12970681\n",
      "Iteration 1479, loss = 3704.54264923\n",
      "Iteration 1480, loss = 3703.95580523\n",
      "Iteration 1481, loss = 3703.36917482\n",
      "Iteration 1482, loss = 3702.78275801\n",
      "Iteration 1483, loss = 3702.19655481\n",
      "Iteration 1484, loss = 3701.61056523\n",
      "Iteration 1485, loss = 3701.02478929\n",
      "Iteration 1486, loss = 3700.43922699\n",
      "Iteration 1487, loss = 3699.85387834\n",
      "Iteration 1488, loss = 3699.26874335\n",
      "Iteration 1489, loss = 3698.68382202\n",
      "Iteration 1490, loss = 3698.09911437\n",
      "Iteration 1491, loss = 3697.51462039\n",
      "Iteration 1492, loss = 3696.93034011\n",
      "Iteration 1493, loss = 3696.34627351\n",
      "Iteration 1494, loss = 3695.76242060\n",
      "Iteration 1495, loss = 3695.17878140\n",
      "Iteration 1496, loss = 3694.59535590\n",
      "Iteration 1497, loss = 3694.01214411\n",
      "Iteration 1498, loss = 3693.42914604\n",
      "Iteration 1499, loss = 3692.84636167\n",
      "Iteration 1500, loss = 3692.26379102\n",
      "Iteration 1501, loss = 3691.68143409\n",
      "Iteration 1502, loss = 3691.09929088\n",
      "Iteration 1503, loss = 3690.51736138\n",
      "Iteration 1504, loss = 3689.93564561\n",
      "Iteration 1505, loss = 3689.35414355\n",
      "Iteration 1506, loss = 3688.77285521\n",
      "Iteration 1507, loss = 3688.19178059\n",
      "Iteration 1508, loss = 3687.61091969\n",
      "Iteration 1509, loss = 3687.03027250\n",
      "Iteration 1510, loss = 3686.44983902\n",
      "Iteration 1511, loss = 3685.86961925\n",
      "Iteration 1512, loss = 3685.28961319\n",
      "Iteration 1513, loss = 3684.70982083\n",
      "Iteration 1514, loss = 3684.13024216\n",
      "Iteration 1515, loss = 3683.55087719\n",
      "Iteration 1516, loss = 3682.97172591\n",
      "Iteration 1517, loss = 3682.39278830\n",
      "Iteration 1518, loss = 3681.81406438\n",
      "Iteration 1519, loss = 3681.23555412\n",
      "Iteration 1520, loss = 3680.65725753\n",
      "Iteration 1521, loss = 3680.07917459\n",
      "Iteration 1522, loss = 3679.50130530\n",
      "Iteration 1523, loss = 3678.92364965\n",
      "Iteration 1524, loss = 3678.34620763\n",
      "Iteration 1525, loss = 3677.76897924\n",
      "Iteration 1526, loss = 3677.19196446\n",
      "Iteration 1527, loss = 3676.61516329\n",
      "Iteration 1528, loss = 3676.03857571\n",
      "Iteration 1529, loss = 3675.46220171\n",
      "Iteration 1530, loss = 3674.88604129\n",
      "Iteration 1531, loss = 3674.31009443\n",
      "Iteration 1532, loss = 3673.73436112\n",
      "Iteration 1533, loss = 3673.15884135\n",
      "Iteration 1534, loss = 3672.58353510\n",
      "Iteration 1535, loss = 3672.00844237\n",
      "Iteration 1536, loss = 3671.43356315\n",
      "Iteration 1537, loss = 3670.85889740\n",
      "Iteration 1538, loss = 3670.28444514\n",
      "Iteration 1539, loss = 3669.71020633\n",
      "Iteration 1540, loss = 3669.13618096\n",
      "Iteration 1541, loss = 3668.56236903\n",
      "Iteration 1542, loss = 3667.98877051\n",
      "Iteration 1543, loss = 3667.41538539\n",
      "Iteration 1544, loss = 3666.84221366\n",
      "Iteration 1545, loss = 3666.26925529\n",
      "Iteration 1546, loss = 3665.69651027\n",
      "Iteration 1547, loss = 3665.12397858\n",
      "Iteration 1548, loss = 3664.55166021\n",
      "Iteration 1549, loss = 3663.97955514\n",
      "Iteration 1550, loss = 3663.40766335\n",
      "Iteration 1551, loss = 3662.83598482\n",
      "Iteration 1552, loss = 3662.26451953\n",
      "Iteration 1553, loss = 3661.69326747\n",
      "Iteration 1554, loss = 3661.12222861\n",
      "Iteration 1555, loss = 3660.55140294\n",
      "Iteration 1556, loss = 3659.98079043\n",
      "Iteration 1557, loss = 3659.41039106\n",
      "Iteration 1558, loss = 3658.84020482\n",
      "Iteration 1559, loss = 3658.27023169\n",
      "Iteration 1560, loss = 3657.70047163\n",
      "Iteration 1561, loss = 3657.13092463\n",
      "Iteration 1562, loss = 3656.56159067\n",
      "Iteration 1563, loss = 3655.99246973\n",
      "Iteration 1564, loss = 3655.42356177\n",
      "Iteration 1565, loss = 3654.85486679\n",
      "Iteration 1566, loss = 3654.28638475\n",
      "Iteration 1567, loss = 3653.71811564\n",
      "Iteration 1568, loss = 3653.15005942\n",
      "Iteration 1569, loss = 3652.58221608\n",
      "Iteration 1570, loss = 3652.01458559\n",
      "Iteration 1571, loss = 3651.44716793\n",
      "Iteration 1572, loss = 3650.87996306\n",
      "Iteration 1573, loss = 3650.31297097\n",
      "Iteration 1574, loss = 3649.74619163\n",
      "Iteration 1575, loss = 3649.17962501\n",
      "Iteration 1576, loss = 3648.61327109\n",
      "Iteration 1577, loss = 3648.04712984\n",
      "Iteration 1578, loss = 3647.48120123\n",
      "Iteration 1579, loss = 3646.91548524\n",
      "Iteration 1580, loss = 3646.34998184\n",
      "Iteration 1581, loss = 3645.78469100\n",
      "Iteration 1582, loss = 3645.21961269\n",
      "Iteration 1583, loss = 3644.65474689\n",
      "Iteration 1584, loss = 3644.09009356\n",
      "Iteration 1585, loss = 3643.52565268\n",
      "Iteration 1586, loss = 3642.96142422\n",
      "Iteration 1587, loss = 3642.39740815\n",
      "Iteration 1588, loss = 3641.83360444\n",
      "Iteration 1589, loss = 3641.27001306\n",
      "Iteration 1590, loss = 3640.70663397\n",
      "Iteration 1591, loss = 3640.14346716\n",
      "Iteration 1592, loss = 3639.58051258\n",
      "Iteration 1593, loss = 3639.01777021\n",
      "Iteration 1594, loss = 3638.45524002\n",
      "Iteration 1595, loss = 3637.89292197\n",
      "Iteration 1596, loss = 3637.33081604\n",
      "Iteration 1597, loss = 3636.76892218\n",
      "Iteration 1598, loss = 3636.20724037\n",
      "Iteration 1599, loss = 3635.64577058\n",
      "Iteration 1600, loss = 3635.08451277\n",
      "Iteration 1601, loss = 3634.52346692\n",
      "Iteration 1602, loss = 3633.96263297\n",
      "Iteration 1603, loss = 3633.40201092\n",
      "Iteration 1604, loss = 3632.84160071\n",
      "Iteration 1605, loss = 3632.28140231\n",
      "Iteration 1606, loss = 3631.72141570\n",
      "Iteration 1607, loss = 3631.16164084\n",
      "Iteration 1608, loss = 3630.60207768\n",
      "Iteration 1609, loss = 3630.04272621\n",
      "Iteration 1610, loss = 3629.48358637\n",
      "Iteration 1611, loss = 3628.92465814\n",
      "Iteration 1612, loss = 3628.36594148\n",
      "Iteration 1613, loss = 3627.80743636\n",
      "Iteration 1614, loss = 3627.24914273\n",
      "Iteration 1615, loss = 3626.69106057\n",
      "Iteration 1616, loss = 3626.13318983\n",
      "Iteration 1617, loss = 3625.57553048\n",
      "Iteration 1618, loss = 3625.01808248\n",
      "Iteration 1619, loss = 3624.46084580\n",
      "Iteration 1620, loss = 3623.90382039\n",
      "Iteration 1621, loss = 3623.34700622\n",
      "Iteration 1622, loss = 3622.79040325\n",
      "Iteration 1623, loss = 3622.23401145\n",
      "Iteration 1624, loss = 3621.67783077\n",
      "Iteration 1625, loss = 3621.12186117\n",
      "Iteration 1626, loss = 3620.56610262\n",
      "Iteration 1627, loss = 3620.01055508\n",
      "Iteration 1628, loss = 3619.45521851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1629, loss = 3618.90009287\n",
      "Iteration 1630, loss = 3618.34517811\n",
      "Iteration 1631, loss = 3617.79047421\n",
      "Iteration 1632, loss = 3617.23598111\n",
      "Iteration 1633, loss = 3616.68169878\n",
      "Iteration 1634, loss = 3616.12762718\n",
      "Iteration 1635, loss = 3615.57376627\n",
      "Iteration 1636, loss = 3615.02011601\n",
      "Iteration 1637, loss = 3614.46667635\n",
      "Iteration 1638, loss = 3613.91344725\n",
      "Iteration 1639, loss = 3613.36042868\n",
      "Iteration 1640, loss = 3612.80762059\n",
      "Iteration 1641, loss = 3612.25502294\n",
      "Iteration 1642, loss = 3611.70263568\n",
      "Iteration 1643, loss = 3611.15045878\n",
      "Iteration 1644, loss = 3610.59849219\n",
      "Iteration 1645, loss = 3610.04673587\n",
      "Iteration 1646, loss = 3609.49518978\n",
      "Iteration 1647, loss = 3608.94385387\n",
      "Iteration 1648, loss = 3608.39272810\n",
      "Iteration 1649, loss = 3607.84181242\n",
      "Iteration 1650, loss = 3607.29110680\n",
      "Iteration 1651, loss = 3606.74061119\n",
      "Iteration 1652, loss = 3606.19032554\n",
      "Iteration 1653, loss = 3605.64024981\n",
      "Iteration 1654, loss = 3605.09038396\n",
      "Iteration 1655, loss = 3604.54072794\n",
      "Iteration 1656, loss = 3603.99128171\n",
      "Iteration 1657, loss = 3603.44204522\n",
      "Iteration 1658, loss = 3602.89301843\n",
      "Iteration 1659, loss = 3602.34420129\n",
      "Iteration 1660, loss = 3601.79559375\n",
      "Iteration 1661, loss = 3601.24719577\n",
      "Iteration 1662, loss = 3600.69900731\n",
      "Iteration 1663, loss = 3600.15102832\n",
      "Iteration 1664, loss = 3599.60325875\n",
      "Iteration 1665, loss = 3599.05569856\n",
      "Iteration 1666, loss = 3598.50834769\n",
      "Iteration 1667, loss = 3597.96120611\n",
      "Iteration 1668, loss = 3597.41427376\n",
      "Iteration 1669, loss = 3596.86755061\n",
      "Iteration 1670, loss = 3596.32103659\n",
      "Iteration 1671, loss = 3595.77473167\n",
      "Iteration 1672, loss = 3595.22863579\n",
      "Iteration 1673, loss = 3594.68274892\n",
      "Iteration 1674, loss = 3594.13707100\n",
      "Iteration 1675, loss = 3593.59160198\n",
      "Iteration 1676, loss = 3593.04634181\n",
      "Iteration 1677, loss = 3592.50129045\n",
      "Iteration 1678, loss = 3591.95644785\n",
      "Iteration 1679, loss = 3591.41181396\n",
      "Iteration 1680, loss = 3590.86738873\n",
      "Iteration 1681, loss = 3590.32317211\n",
      "Iteration 1682, loss = 3589.77916406\n",
      "Iteration 1683, loss = 3589.23536452\n",
      "Iteration 1684, loss = 3588.69177344\n",
      "Iteration 1685, loss = 3588.14839078\n",
      "Iteration 1686, loss = 3587.60521648\n",
      "Iteration 1687, loss = 3587.06225050\n",
      "Iteration 1688, loss = 3586.51949278\n",
      "Iteration 1689, loss = 3585.97694328\n",
      "Iteration 1690, loss = 3585.43460194\n",
      "Iteration 1691, loss = 3584.89246872\n",
      "Iteration 1692, loss = 3584.35054356\n",
      "Iteration 1693, loss = 3583.80882641\n",
      "Iteration 1694, loss = 3583.26731722\n",
      "Iteration 1695, loss = 3582.72601595\n",
      "Iteration 1696, loss = 3582.18492253\n",
      "Iteration 1697, loss = 3581.64403693\n",
      "Iteration 1698, loss = 3581.10335908\n",
      "Iteration 1699, loss = 3580.56288893\n",
      "Iteration 1700, loss = 3580.02262644\n",
      "Iteration 1701, loss = 3579.48257155\n",
      "Iteration 1702, loss = 3578.94272421\n",
      "Iteration 1703, loss = 3578.40308437\n",
      "Iteration 1704, loss = 3577.86365197\n",
      "Iteration 1705, loss = 3577.32442697\n",
      "Iteration 1706, loss = 3576.78540930\n",
      "Iteration 1707, loss = 3576.24659892\n",
      "Iteration 1708, loss = 3575.70799578\n",
      "Iteration 1709, loss = 3575.16959982\n",
      "Iteration 1710, loss = 3574.63141099\n",
      "Iteration 1711, loss = 3574.09342924\n",
      "Iteration 1712, loss = 3573.55565450\n",
      "Iteration 1713, loss = 3573.01808674\n",
      "Iteration 1714, loss = 3572.48072589\n",
      "Iteration 1715, loss = 3571.94357190\n",
      "Iteration 1716, loss = 3571.40662472\n",
      "Iteration 1717, loss = 3570.86988429\n",
      "Iteration 1718, loss = 3570.33335057\n",
      "Iteration 1719, loss = 3569.79702348\n",
      "Iteration 1720, loss = 3569.26090299\n",
      "Iteration 1721, loss = 3568.72498904\n",
      "Iteration 1722, loss = 3568.18928157\n",
      "Iteration 1723, loss = 3567.65378052\n",
      "Iteration 1724, loss = 3567.11848585\n",
      "Iteration 1725, loss = 3566.58339749\n",
      "Iteration 1726, loss = 3566.04851540\n",
      "Iteration 1727, loss = 3565.51383952\n",
      "Iteration 1728, loss = 3564.97936978\n",
      "Iteration 1729, loss = 3564.44510615\n",
      "Iteration 1730, loss = 3563.91104855\n",
      "Iteration 1731, loss = 3563.37719694\n",
      "Iteration 1732, loss = 3562.84355126\n",
      "Iteration 1733, loss = 3562.31011145\n",
      "Iteration 1734, loss = 3561.77687747\n",
      "Iteration 1735, loss = 3561.24384924\n",
      "Iteration 1736, loss = 3560.71102672\n",
      "Iteration 1737, loss = 3560.17840985\n",
      "Iteration 1738, loss = 3559.64599857\n",
      "Iteration 1739, loss = 3559.11379283\n",
      "Iteration 1740, loss = 3558.58179257\n",
      "Iteration 1741, loss = 3558.04999773\n",
      "Iteration 1742, loss = 3557.51840825\n",
      "Iteration 1743, loss = 3556.98702409\n",
      "Iteration 1744, loss = 3556.45584518\n",
      "Iteration 1745, loss = 3555.92487146\n",
      "Iteration 1746, loss = 3555.39410289\n",
      "Iteration 1747, loss = 3554.86353939\n",
      "Iteration 1748, loss = 3554.33318091\n",
      "Iteration 1749, loss = 3553.80302740\n",
      "Iteration 1750, loss = 3553.27307880\n",
      "Iteration 1751, loss = 3552.74333505\n",
      "Iteration 1752, loss = 3552.21379609\n",
      "Iteration 1753, loss = 3551.68446187\n",
      "Iteration 1754, loss = 3551.15533232\n",
      "Iteration 1755, loss = 3550.62640738\n",
      "Iteration 1756, loss = 3550.09768701\n",
      "Iteration 1757, loss = 3549.56917114\n",
      "Iteration 1758, loss = 3549.04085972\n",
      "Iteration 1759, loss = 3548.51275267\n",
      "Iteration 1760, loss = 3547.98484995\n",
      "Iteration 1761, loss = 3547.45715150\n",
      "Iteration 1762, loss = 3546.92965726\n",
      "Iteration 1763, loss = 3546.40236717\n",
      "Iteration 1764, loss = 3545.87528117\n",
      "Iteration 1765, loss = 3545.34839919\n",
      "Iteration 1766, loss = 3544.82172119\n",
      "Iteration 1767, loss = 3544.29524711\n",
      "Iteration 1768, loss = 3543.76897687\n",
      "Iteration 1769, loss = 3543.24291043\n",
      "Iteration 1770, loss = 3542.71704773\n",
      "Iteration 1771, loss = 3542.19138869\n",
      "Iteration 1772, loss = 3541.66593328\n",
      "Iteration 1773, loss = 3541.14068141\n",
      "Iteration 1774, loss = 3540.61563305\n",
      "Iteration 1775, loss = 3540.09078812\n",
      "Iteration 1776, loss = 3539.56614656\n",
      "Iteration 1777, loss = 3539.04170832\n",
      "Iteration 1778, loss = 3538.51747333\n",
      "Iteration 1779, loss = 3537.99344154\n",
      "Iteration 1780, loss = 3537.46961288\n",
      "Iteration 1781, loss = 3536.94598729\n",
      "Iteration 1782, loss = 3536.42256472\n",
      "Iteration 1783, loss = 3535.89934510\n",
      "Iteration 1784, loss = 3535.37632837\n",
      "Iteration 1785, loss = 3534.85351447\n",
      "Iteration 1786, loss = 3534.33090334\n",
      "Iteration 1787, loss = 3533.80849492\n",
      "Iteration 1788, loss = 3533.28628915\n",
      "Iteration 1789, loss = 3532.76428596\n",
      "Iteration 1790, loss = 3532.24248530\n",
      "Iteration 1791, loss = 3531.72088710\n",
      "Iteration 1792, loss = 3531.19949131\n",
      "Iteration 1793, loss = 3530.67829785\n",
      "Iteration 1794, loss = 3530.15730668\n",
      "Iteration 1795, loss = 3529.63651772\n",
      "Iteration 1796, loss = 3529.11593093\n",
      "Iteration 1797, loss = 3528.59554622\n",
      "Iteration 1798, loss = 3528.07536355\n",
      "Iteration 1799, loss = 3527.55538285\n",
      "Iteration 1800, loss = 3527.03560406\n",
      "Iteration 1801, loss = 3526.51602712\n",
      "Iteration 1802, loss = 3525.99665196\n",
      "Iteration 1803, loss = 3525.47747852\n",
      "Iteration 1804, loss = 3524.95850674\n",
      "Iteration 1805, loss = 3524.43973657\n",
      "Iteration 1806, loss = 3523.92116793\n",
      "Iteration 1807, loss = 3523.40280076\n",
      "Iteration 1808, loss = 3522.88463500\n",
      "Iteration 1809, loss = 3522.36667059\n",
      "Iteration 1810, loss = 3521.84890747\n",
      "Iteration 1811, loss = 3521.33134557\n",
      "Iteration 1812, loss = 3520.81398483\n",
      "Iteration 1813, loss = 3520.29682519\n",
      "Iteration 1814, loss = 3519.77986658\n",
      "Iteration 1815, loss = 3519.26310895\n",
      "Iteration 1816, loss = 3518.74655222\n",
      "Iteration 1817, loss = 3518.23019634\n",
      "Iteration 1818, loss = 3517.71404124\n",
      "Iteration 1819, loss = 3517.19808686\n",
      "Iteration 1820, loss = 3516.68233313\n",
      "Iteration 1821, loss = 3516.16678000\n",
      "Iteration 1822, loss = 3515.65142739\n",
      "Iteration 1823, loss = 3515.13627526\n",
      "Iteration 1824, loss = 3514.62132352\n",
      "Iteration 1825, loss = 3514.10657212\n",
      "Iteration 1826, loss = 3513.59202100\n",
      "Iteration 1827, loss = 3513.07767009\n",
      "Iteration 1828, loss = 3512.56351932\n",
      "Iteration 1829, loss = 3512.04956864\n",
      "Iteration 1830, loss = 3511.53581798\n",
      "Iteration 1831, loss = 3511.02226727\n",
      "Iteration 1832, loss = 3510.50891646\n",
      "Iteration 1833, loss = 3509.99576547\n",
      "Iteration 1834, loss = 3509.48281425\n",
      "Iteration 1835, loss = 3508.97006272\n",
      "Iteration 1836, loss = 3508.45751083\n",
      "Iteration 1837, loss = 3507.94515851\n",
      "Iteration 1838, loss = 3507.43300570\n",
      "Iteration 1839, loss = 3506.92105233\n",
      "Iteration 1840, loss = 3506.40929834\n",
      "Iteration 1841, loss = 3505.89774366\n",
      "Iteration 1842, loss = 3505.38638823\n",
      "Iteration 1843, loss = 3504.87523198\n",
      "Iteration 1844, loss = 3504.36427485\n",
      "Iteration 1845, loss = 3503.85351678\n",
      "Iteration 1846, loss = 3503.34295770\n",
      "Iteration 1847, loss = 3502.83259754\n",
      "Iteration 1848, loss = 3502.32243624\n",
      "Iteration 1849, loss = 3501.81247374\n",
      "Iteration 1850, loss = 3501.30270997\n",
      "Iteration 1851, loss = 3500.79314487\n",
      "Iteration 1852, loss = 3500.28377836\n",
      "Iteration 1853, loss = 3499.77461039\n",
      "Iteration 1854, loss = 3499.26564089\n",
      "Iteration 1855, loss = 3498.75686980\n",
      "Iteration 1856, loss = 3498.24829704\n",
      "Iteration 1857, loss = 3497.73992256\n",
      "Iteration 1858, loss = 3497.23174629\n",
      "Iteration 1859, loss = 3496.72376816\n",
      "Iteration 1860, loss = 3496.21598811\n",
      "Iteration 1861, loss = 3495.70840608\n",
      "Iteration 1862, loss = 3495.20102199\n",
      "Iteration 1863, loss = 3494.69383578\n",
      "Iteration 1864, loss = 3494.18684739\n",
      "Iteration 1865, loss = 3493.68005675\n",
      "Iteration 1866, loss = 3493.17346380\n",
      "Iteration 1867, loss = 3492.66706846\n",
      "Iteration 1868, loss = 3492.16087068\n",
      "Iteration 1869, loss = 3491.65487038\n",
      "Iteration 1870, loss = 3491.14906751\n",
      "Iteration 1871, loss = 3490.64346200\n",
      "Iteration 1872, loss = 3490.13805377\n",
      "Iteration 1873, loss = 3489.63284277\n",
      "Iteration 1874, loss = 3489.12782892\n",
      "Iteration 1875, loss = 3488.62301217\n",
      "Iteration 1876, loss = 3488.11839245\n",
      "Iteration 1877, loss = 3487.61396968\n",
      "Iteration 1878, loss = 3487.10974381\n",
      "Iteration 1879, loss = 3486.60571477\n",
      "Iteration 1880, loss = 3486.10188248\n",
      "Iteration 1881, loss = 3485.59824689\n",
      "Iteration 1882, loss = 3485.09480793\n",
      "Iteration 1883, loss = 3484.59156554\n",
      "Iteration 1884, loss = 3484.08851964\n",
      "Iteration 1885, loss = 3483.58567017\n",
      "Iteration 1886, loss = 3483.08301706\n",
      "Iteration 1887, loss = 3482.58056025\n",
      "Iteration 1888, loss = 3482.07829966\n",
      "Iteration 1889, loss = 3481.57623525\n",
      "Iteration 1890, loss = 3481.07436693\n",
      "Iteration 1891, loss = 3480.57269464\n",
      "Iteration 1892, loss = 3480.07121831\n",
      "Iteration 1893, loss = 3479.56993788\n",
      "Iteration 1894, loss = 3479.06885328\n",
      "Iteration 1895, loss = 3478.56796444\n",
      "Iteration 1896, loss = 3478.06727131\n",
      "Iteration 1897, loss = 3477.56677380\n",
      "Iteration 1898, loss = 3477.06647185\n",
      "Iteration 1899, loss = 3476.56636540\n",
      "Iteration 1900, loss = 3476.06645438\n",
      "Iteration 1901, loss = 3475.56673872\n",
      "Iteration 1902, loss = 3475.06721836\n",
      "Iteration 1903, loss = 3474.56789323\n",
      "Iteration 1904, loss = 3474.06876325\n",
      "Iteration 1905, loss = 3473.56982837\n",
      "Iteration 1906, loss = 3473.07108852\n",
      "Iteration 1907, loss = 3472.57254363\n",
      "Iteration 1908, loss = 3472.07419363\n",
      "Iteration 1909, loss = 3471.57603846\n",
      "Iteration 1910, loss = 3471.07807805\n",
      "Iteration 1911, loss = 3470.58031232\n",
      "Iteration 1912, loss = 3470.08274122\n",
      "Iteration 1913, loss = 3469.58536468\n",
      "Iteration 1914, loss = 3469.08818263\n",
      "Iteration 1915, loss = 3468.59119500\n",
      "Iteration 1916, loss = 3468.09440172\n",
      "Iteration 1917, loss = 3467.59780273\n",
      "Iteration 1918, loss = 3467.10139797\n",
      "Iteration 1919, loss = 3466.60518735\n",
      "Iteration 1920, loss = 3466.10917082\n",
      "Iteration 1921, loss = 3465.61334831\n",
      "Iteration 1922, loss = 3465.11771974\n",
      "Iteration 1923, loss = 3464.62228506\n",
      "Iteration 1924, loss = 3464.12704420\n",
      "Iteration 1925, loss = 3463.63199708\n",
      "Iteration 1926, loss = 3463.13714364\n",
      "Iteration 1927, loss = 3462.64248382\n",
      "Iteration 1928, loss = 3462.14801754\n",
      "Iteration 1929, loss = 3461.65374473\n",
      "Iteration 1930, loss = 3461.15966534\n",
      "Iteration 1931, loss = 3460.66577928\n",
      "Iteration 1932, loss = 3460.17208650\n",
      "Iteration 1933, loss = 3459.67858693\n",
      "Iteration 1934, loss = 3459.18528049\n",
      "Iteration 1935, loss = 3458.69216713\n",
      "Iteration 1936, loss = 3458.19924676\n",
      "Iteration 1937, loss = 3457.70651933\n",
      "Iteration 1938, loss = 3457.21398477\n",
      "Iteration 1939, loss = 3456.72164301\n",
      "Iteration 1940, loss = 3456.22949398\n",
      "Iteration 1941, loss = 3455.73753761\n",
      "Iteration 1942, loss = 3455.24577384\n",
      "Iteration 1943, loss = 3454.75420259\n",
      "Iteration 1944, loss = 3454.26282381\n",
      "Iteration 1945, loss = 3453.77163741\n",
      "Iteration 1946, loss = 3453.28064334\n",
      "Iteration 1947, loss = 3452.78984153\n",
      "Iteration 1948, loss = 3452.29923190\n",
      "Iteration 1949, loss = 3451.80881439\n",
      "Iteration 1950, loss = 3451.31858893\n",
      "Iteration 1951, loss = 3450.82855546\n",
      "Iteration 1952, loss = 3450.33871390\n",
      "Iteration 1953, loss = 3449.84906418\n",
      "Iteration 1954, loss = 3449.35960625\n",
      "Iteration 1955, loss = 3448.87034002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1956, loss = 3448.38126544\n",
      "Iteration 1957, loss = 3447.89238244\n",
      "Iteration 1958, loss = 3447.40369094\n",
      "Iteration 1959, loss = 3446.91519087\n",
      "Iteration 1960, loss = 3446.42688218\n",
      "Iteration 1961, loss = 3445.93876479\n",
      "Iteration 1962, loss = 3445.45083863\n",
      "Iteration 1963, loss = 3444.96310364\n",
      "Iteration 1964, loss = 3444.47555974\n",
      "Iteration 1965, loss = 3443.98820687\n",
      "Iteration 1966, loss = 3443.50104497\n",
      "Iteration 1967, loss = 3443.01407395\n",
      "Iteration 1968, loss = 3442.52729376\n",
      "Iteration 1969, loss = 3442.04070432\n",
      "Iteration 1970, loss = 3441.55430557\n",
      "Iteration 1971, loss = 3441.06809744\n",
      "Iteration 1972, loss = 3440.58207985\n",
      "Iteration 1973, loss = 3440.09625275\n",
      "Iteration 1974, loss = 3439.61061607\n",
      "Iteration 1975, loss = 3439.12516973\n",
      "Iteration 1976, loss = 3438.63991366\n",
      "Iteration 1977, loss = 3438.15484780\n",
      "Iteration 1978, loss = 3437.66997209\n",
      "Iteration 1979, loss = 3437.18528644\n",
      "Iteration 1980, loss = 3436.70079080\n",
      "Iteration 1981, loss = 3436.21648509\n",
      "Iteration 1982, loss = 3435.73236924\n",
      "Iteration 1983, loss = 3435.24844320\n",
      "Iteration 1984, loss = 3434.76470688\n",
      "Iteration 1985, loss = 3434.28116023\n",
      "Iteration 1986, loss = 3433.79780316\n",
      "Iteration 1987, loss = 3433.31463562\n",
      "Iteration 1988, loss = 3432.83165754\n",
      "Iteration 1989, loss = 3432.34886884\n",
      "Iteration 1990, loss = 3431.86626946\n",
      "Iteration 1991, loss = 3431.38385933\n",
      "Iteration 1992, loss = 3430.90163838\n",
      "Iteration 1993, loss = 3430.41960654\n",
      "Iteration 1994, loss = 3429.93776375\n",
      "Iteration 1995, loss = 3429.45610993\n",
      "Iteration 1996, loss = 3428.97464502\n",
      "Iteration 1997, loss = 3428.49336894\n",
      "Iteration 1998, loss = 3428.01228164\n",
      "Iteration 1999, loss = 3427.53138304\n",
      "Iteration 2000, loss = 3427.05067307\n",
      "Iteration 2001, loss = 3426.57015166\n",
      "Iteration 2002, loss = 3426.08981875\n",
      "Iteration 2003, loss = 3425.60967426\n",
      "Iteration 2004, loss = 3425.12971814\n",
      "Iteration 2005, loss = 3424.64995030\n",
      "Iteration 2006, loss = 3424.17037069\n",
      "Iteration 2007, loss = 3423.69097922\n",
      "Iteration 2008, loss = 3423.21177584\n",
      "Iteration 2009, loss = 3422.73276048\n",
      "Iteration 2010, loss = 3422.25393306\n",
      "Iteration 2011, loss = 3421.77529352\n",
      "Iteration 2012, loss = 3421.29684179\n",
      "Iteration 2013, loss = 3420.81857780\n",
      "Iteration 2014, loss = 3420.34050148\n",
      "Iteration 2015, loss = 3419.86261277\n",
      "Iteration 2016, loss = 3419.38491159\n",
      "Iteration 2017, loss = 3418.90739788\n",
      "Iteration 2018, loss = 3418.43007156\n",
      "Iteration 2019, loss = 3417.95293257\n",
      "Iteration 2020, loss = 3417.47598085\n",
      "Iteration 2021, loss = 3416.99921631\n",
      "Iteration 2022, loss = 3416.52263890\n",
      "Iteration 2023, loss = 3416.04624854\n",
      "Iteration 2024, loss = 3415.57004517\n",
      "Iteration 2025, loss = 3415.09402872\n",
      "Iteration 2026, loss = 3414.61819911\n",
      "Iteration 2027, loss = 3414.14255629\n",
      "Iteration 2028, loss = 3413.66710017\n",
      "Iteration 2029, loss = 3413.19183070\n",
      "Iteration 2030, loss = 3412.71674780\n",
      "Iteration 2031, loss = 3412.24185141\n",
      "Iteration 2032, loss = 3411.76714146\n",
      "Iteration 2033, loss = 3411.29261787\n",
      "Iteration 2034, loss = 3410.81828058\n",
      "Iteration 2035, loss = 3410.34412952\n",
      "Iteration 2036, loss = 3409.87016463\n",
      "Iteration 2037, loss = 3409.39638583\n",
      "Iteration 2038, loss = 3408.92279305\n",
      "Iteration 2039, loss = 3408.44938623\n",
      "Iteration 2040, loss = 3407.97616530\n",
      "Iteration 2041, loss = 3407.50313019\n",
      "Iteration 2042, loss = 3407.03028083\n",
      "Iteration 2043, loss = 3406.55761715\n",
      "Iteration 2044, loss = 3406.08513909\n",
      "Iteration 2045, loss = 3405.61284657\n",
      "Iteration 2046, loss = 3405.14073952\n",
      "Iteration 2047, loss = 3404.66881788\n",
      "Iteration 2048, loss = 3404.19708159\n",
      "Iteration 2049, loss = 3403.72553056\n",
      "Iteration 2050, loss = 3403.25416474\n",
      "Iteration 2051, loss = 3402.78298404\n",
      "Iteration 2052, loss = 3402.31198842\n",
      "Iteration 2053, loss = 3401.84117779\n",
      "Iteration 2054, loss = 3401.37055209\n",
      "Iteration 2055, loss = 3400.90011124\n",
      "Iteration 2056, loss = 3400.42985519\n",
      "Iteration 2057, loss = 3399.95978386\n",
      "Iteration 2058, loss = 3399.48989719\n",
      "Iteration 2059, loss = 3399.02019510\n",
      "Iteration 2060, loss = 3398.55067752\n",
      "Iteration 2061, loss = 3398.08134440\n",
      "Iteration 2062, loss = 3397.61219565\n",
      "Iteration 2063, loss = 3397.14323121\n",
      "Iteration 2064, loss = 3396.67445102\n",
      "Iteration 2065, loss = 3396.20585500\n",
      "Iteration 2066, loss = 3395.73744309\n",
      "Iteration 2067, loss = 3395.26921521\n",
      "Iteration 2068, loss = 3394.80117131\n",
      "Iteration 2069, loss = 3394.33331130\n",
      "Iteration 2070, loss = 3393.86563513\n",
      "Iteration 2071, loss = 3393.39814272\n",
      "Iteration 2072, loss = 3392.93083400\n",
      "Iteration 2073, loss = 3392.46370891\n",
      "Iteration 2074, loss = 3391.99676738\n",
      "Iteration 2075, loss = 3391.53000934\n",
      "Iteration 2076, loss = 3391.06343472\n",
      "Iteration 2077, loss = 3390.59704345\n",
      "Iteration 2078, loss = 3390.13083547\n",
      "Iteration 2079, loss = 3389.66481070\n",
      "Iteration 2080, loss = 3389.19896908\n",
      "Iteration 2081, loss = 3388.73331055\n",
      "Iteration 2082, loss = 3388.26783502\n",
      "Iteration 2083, loss = 3387.80254243\n",
      "Iteration 2084, loss = 3387.33743272\n",
      "Iteration 2085, loss = 3386.87250582\n",
      "Iteration 2086, loss = 3386.40776165\n",
      "Iteration 2087, loss = 3385.94320016\n",
      "Iteration 2088, loss = 3385.47882126\n",
      "Iteration 2089, loss = 3385.01462490\n",
      "Iteration 2090, loss = 3384.55061100\n",
      "Iteration 2091, loss = 3384.08677950\n",
      "Iteration 2092, loss = 3383.62313033\n",
      "Iteration 2093, loss = 3383.15966342\n",
      "Iteration 2094, loss = 3382.69637870\n",
      "Iteration 2095, loss = 3382.23327610\n",
      "Iteration 2096, loss = 3381.77035556\n",
      "Iteration 2097, loss = 3381.30761701\n",
      "Iteration 2098, loss = 3380.84506037\n",
      "Iteration 2099, loss = 3380.38268559\n",
      "Iteration 2100, loss = 3379.92049259\n",
      "Iteration 2101, loss = 3379.45848130\n",
      "Iteration 2102, loss = 3378.99665166\n",
      "Iteration 2103, loss = 3378.53500360\n",
      "Iteration 2104, loss = 3378.07353705\n",
      "Iteration 2105, loss = 3377.61225194\n",
      "Iteration 2106, loss = 3377.15114820\n",
      "Iteration 2107, loss = 3376.69022578\n",
      "Iteration 2108, loss = 3376.22948458\n",
      "Iteration 2109, loss = 3375.76892456\n",
      "Iteration 2110, loss = 3375.30854564\n",
      "Iteration 2111, loss = 3374.84834776\n",
      "Iteration 2112, loss = 3374.38833084\n",
      "Iteration 2113, loss = 3373.92849482\n",
      "Iteration 2114, loss = 3373.46883963\n",
      "Iteration 2115, loss = 3373.00936520\n",
      "Iteration 2116, loss = 3372.55007147\n",
      "Iteration 2117, loss = 3372.09095836\n",
      "Iteration 2118, loss = 3371.63202581\n",
      "Iteration 2119, loss = 3371.17327375\n",
      "Iteration 2120, loss = 3370.71470211\n",
      "Iteration 2121, loss = 3370.25631082\n",
      "Iteration 2122, loss = 3369.79809983\n",
      "Iteration 2123, loss = 3369.34006905\n",
      "Iteration 2124, loss = 3368.88221842\n",
      "Iteration 2125, loss = 3368.42454788\n",
      "Iteration 2126, loss = 3367.96705735\n",
      "Iteration 2127, loss = 3367.50974677\n",
      "Iteration 2128, loss = 3367.05261607\n",
      "Iteration 2129, loss = 3366.59566518\n",
      "Iteration 2130, loss = 3366.13889404\n",
      "Iteration 2131, loss = 3365.68230257\n",
      "Iteration 2132, loss = 3365.22589071\n",
      "Iteration 2133, loss = 3364.76965839\n",
      "Iteration 2134, loss = 3364.31360555\n",
      "Iteration 2135, loss = 3363.85773211\n",
      "Iteration 2136, loss = 3363.40203801\n",
      "Iteration 2137, loss = 3362.94652318\n",
      "Iteration 2138, loss = 3362.49118755\n",
      "Iteration 2139, loss = 3362.03603106\n",
      "Iteration 2140, loss = 3361.58105364\n",
      "Iteration 2141, loss = 3361.12625521\n",
      "Iteration 2142, loss = 3360.67163572\n",
      "Iteration 2143, loss = 3360.21719509\n",
      "Iteration 2144, loss = 3359.76293327\n",
      "Iteration 2145, loss = 3359.30885017\n",
      "Iteration 2146, loss = 3358.85494573\n",
      "Iteration 2147, loss = 3358.40121989\n",
      "Iteration 2148, loss = 3357.94767258\n",
      "Iteration 2149, loss = 3357.49430373\n",
      "Iteration 2150, loss = 3357.04111327\n",
      "Iteration 2151, loss = 3356.58810113\n",
      "Iteration 2152, loss = 3356.13526726\n",
      "Iteration 2153, loss = 3355.68261157\n",
      "Iteration 2154, loss = 3355.23013401\n",
      "Iteration 2155, loss = 3354.77783450\n",
      "Iteration 2156, loss = 3354.32571299\n",
      "Iteration 2157, loss = 3353.87376939\n",
      "Iteration 2158, loss = 3353.42200365\n",
      "Iteration 2159, loss = 3352.97041569\n",
      "Iteration 2160, loss = 3352.51900546\n",
      "Iteration 2161, loss = 3352.06777287\n",
      "Iteration 2162, loss = 3351.61671788\n",
      "Iteration 2163, loss = 3351.16584040\n",
      "Iteration 2164, loss = 3350.71514037\n",
      "Iteration 2165, loss = 3350.26461772\n",
      "Iteration 2166, loss = 3349.81427240\n",
      "Iteration 2167, loss = 3349.36410432\n",
      "Iteration 2168, loss = 3348.91411342\n",
      "Iteration 2169, loss = 3348.46429964\n",
      "Iteration 2170, loss = 3348.01466291\n",
      "Iteration 2171, loss = 3347.56520316\n",
      "Iteration 2172, loss = 3347.11592032\n",
      "Iteration 2173, loss = 3346.66681433\n",
      "Iteration 2174, loss = 3346.21788512\n",
      "Iteration 2175, loss = 3345.76913263\n",
      "Iteration 2176, loss = 3345.32055678\n",
      "Iteration 2177, loss = 3344.87215751\n",
      "Iteration 2178, loss = 3344.42393475\n",
      "Iteration 2179, loss = 3343.97588844\n",
      "Iteration 2180, loss = 3343.52801851\n",
      "Iteration 2181, loss = 3343.08032489\n",
      "Iteration 2182, loss = 3342.63280751\n",
      "Iteration 2183, loss = 3342.18546632\n",
      "Iteration 2184, loss = 3341.73830123\n",
      "Iteration 2185, loss = 3341.29131219\n",
      "Iteration 2186, loss = 3340.84449913\n",
      "Iteration 2187, loss = 3340.39786198\n",
      "Iteration 2188, loss = 3339.95140068\n",
      "Iteration 2189, loss = 3339.50511515\n",
      "Iteration 2190, loss = 3339.05900534\n",
      "Iteration 2191, loss = 3338.61307117\n",
      "Iteration 2192, loss = 3338.16731258\n",
      "Iteration 2193, loss = 3337.72172950\n",
      "Iteration 2194, loss = 3337.27632187\n",
      "Iteration 2195, loss = 3336.83108961\n",
      "Iteration 2196, loss = 3336.38603267\n",
      "Iteration 2197, loss = 3335.94115097\n",
      "Iteration 2198, loss = 3335.49644445\n",
      "Iteration 2199, loss = 3335.05191305\n",
      "Iteration 2200, loss = 3334.60755669\n",
      "Iteration 2201, loss = 3334.16337531\n",
      "Iteration 2202, loss = 3333.71936885\n",
      "Iteration 2203, loss = 3333.27553723\n",
      "Iteration 2204, loss = 3332.83188039\n",
      "Iteration 2205, loss = 3332.38839827\n",
      "Iteration 2206, loss = 3331.94509079\n",
      "Iteration 2207, loss = 3331.50195790\n",
      "Iteration 2208, loss = 3331.05899953\n",
      "Iteration 2209, loss = 3330.61621560\n",
      "Iteration 2210, loss = 3330.17360606\n",
      "Iteration 2211, loss = 3329.73117083\n",
      "Iteration 2212, loss = 3329.28890985\n",
      "Iteration 2213, loss = 3328.84682306\n",
      "Iteration 2214, loss = 3328.40491039\n",
      "Iteration 2215, loss = 3327.96317177\n",
      "Iteration 2216, loss = 3327.52160714\n",
      "Iteration 2217, loss = 3327.08021643\n",
      "Iteration 2218, loss = 3326.63899957\n",
      "Iteration 2219, loss = 3326.19795650\n",
      "Iteration 2220, loss = 3325.75708715\n",
      "Iteration 2221, loss = 3325.31639147\n",
      "Iteration 2222, loss = 3324.87586937\n",
      "Iteration 2223, loss = 3324.43552079\n",
      "Iteration 2224, loss = 3323.99534568\n",
      "Iteration 2225, loss = 3323.55534395\n",
      "Iteration 2226, loss = 3323.11551556\n",
      "Iteration 2227, loss = 3322.67586042\n",
      "Iteration 2228, loss = 3322.23637849\n",
      "Iteration 2229, loss = 3321.79706968\n",
      "Iteration 2230, loss = 3321.35793393\n",
      "Iteration 2231, loss = 3320.91897119\n",
      "Iteration 2232, loss = 3320.48018137\n",
      "Iteration 2233, loss = 3320.04156443\n",
      "Iteration 2234, loss = 3319.60312028\n",
      "Iteration 2235, loss = 3319.16484887\n",
      "Iteration 2236, loss = 3318.72675013\n",
      "Iteration 2237, loss = 3318.28882400\n",
      "Iteration 2238, loss = 3317.85107040\n",
      "Iteration 2239, loss = 3317.41348928\n",
      "Iteration 2240, loss = 3316.97608057\n",
      "Iteration 2241, loss = 3316.53884420\n",
      "Iteration 2242, loss = 3316.10178010\n",
      "Iteration 2243, loss = 3315.66488822\n",
      "Iteration 2244, loss = 3315.22816848\n",
      "Iteration 2245, loss = 3314.79162083\n",
      "Iteration 2246, loss = 3314.35524519\n",
      "Iteration 2247, loss = 3313.91904150\n",
      "Iteration 2248, loss = 3313.48300969\n",
      "Iteration 2249, loss = 3313.04714971\n",
      "Iteration 2250, loss = 3312.61146148\n",
      "Iteration 2251, loss = 3312.17594494\n",
      "Iteration 2252, loss = 3311.74060002\n",
      "Iteration 2253, loss = 3311.30542666\n",
      "Iteration 2254, loss = 3310.87042480\n",
      "Iteration 2255, loss = 3310.43559436\n",
      "Iteration 2256, loss = 3310.00093529\n",
      "Iteration 2257, loss = 3309.56644751\n",
      "Iteration 2258, loss = 3309.13213097\n",
      "Iteration 2259, loss = 3308.69798560\n",
      "Iteration 2260, loss = 3308.26401133\n",
      "Iteration 2261, loss = 3307.83020810\n",
      "Iteration 2262, loss = 3307.39657584\n",
      "Iteration 2263, loss = 3306.96311449\n",
      "Iteration 2264, loss = 3306.52982399\n",
      "Iteration 2265, loss = 3306.09670426\n",
      "Iteration 2266, loss = 3305.66375525\n",
      "Iteration 2267, loss = 3305.23097688\n",
      "Iteration 2268, loss = 3304.79836910\n",
      "Iteration 2269, loss = 3304.36593184\n",
      "Iteration 2270, loss = 3303.93366504\n",
      "Iteration 2271, loss = 3303.50156862\n",
      "Iteration 2272, loss = 3303.06964254\n",
      "Iteration 2273, loss = 3302.63788671\n",
      "Iteration 2274, loss = 3302.20630108\n",
      "Iteration 2275, loss = 3301.77488557\n",
      "Iteration 2276, loss = 3301.34364014\n",
      "Iteration 2277, loss = 3300.91256471\n",
      "Iteration 2278, loss = 3300.48165922\n",
      "Iteration 2279, loss = 3300.05092360\n",
      "Iteration 2280, loss = 3299.62035779\n",
      "Iteration 2281, loss = 3299.18996172\n",
      "Iteration 2282, loss = 3298.75973533\n",
      "Iteration 2283, loss = 3298.32967856\n",
      "Iteration 2284, loss = 3297.89979134\n",
      "Iteration 2285, loss = 3297.47007361\n",
      "Iteration 2286, loss = 3297.04052530\n",
      "Iteration 2287, loss = 3296.61114635\n",
      "Iteration 2288, loss = 3296.18193670\n",
      "Iteration 2289, loss = 3295.75289627\n",
      "Iteration 2290, loss = 3295.32402501\n",
      "Iteration 2291, loss = 3294.89532285\n",
      "Iteration 2292, loss = 3294.46678973\n",
      "Iteration 2293, loss = 3294.03842558\n",
      "Iteration 2294, loss = 3293.61023034\n",
      "Iteration 2295, loss = 3293.18220395\n",
      "Iteration 2296, loss = 3292.75434633\n",
      "Iteration 2297, loss = 3292.32665744\n",
      "Iteration 2298, loss = 3291.89913720\n",
      "Iteration 2299, loss = 3291.47178554\n",
      "Iteration 2300, loss = 3291.04460242\n",
      "Iteration 2301, loss = 3290.61758775\n",
      "Iteration 2302, loss = 3290.19074148\n",
      "Iteration 2303, loss = 3289.76406355\n",
      "Iteration 2304, loss = 3289.33755388\n",
      "Iteration 2305, loss = 3288.91121242\n",
      "Iteration 2306, loss = 3288.48503911\n",
      "Iteration 2307, loss = 3288.05903387\n",
      "Iteration 2308, loss = 3287.63319664\n",
      "Iteration 2309, loss = 3287.20752737\n",
      "Iteration 2310, loss = 3286.78202599\n",
      "Iteration 2311, loss = 3286.35669243\n",
      "Iteration 2312, loss = 3285.93152663\n",
      "Iteration 2313, loss = 3285.50652853\n",
      "Iteration 2314, loss = 3285.08169806\n",
      "Iteration 2315, loss = 3284.65703516\n",
      "Iteration 2316, loss = 3284.23253976\n",
      "Iteration 2317, loss = 3283.80821181\n",
      "Iteration 2318, loss = 3283.38405124\n",
      "Iteration 2319, loss = 3282.96005799\n",
      "Iteration 2320, loss = 3282.53623198\n",
      "Iteration 2321, loss = 3282.11257317\n",
      "Iteration 2322, loss = 3281.68908149\n",
      "Iteration 2323, loss = 3281.26575686\n",
      "Iteration 2324, loss = 3280.84259924\n",
      "Iteration 2325, loss = 3280.41960855\n",
      "Iteration 2326, loss = 3279.99678473\n",
      "Iteration 2327, loss = 3279.57412773\n",
      "Iteration 2328, loss = 3279.15163747\n",
      "Iteration 2329, loss = 3278.72931390\n",
      "Iteration 2330, loss = 3278.30715694\n",
      "Iteration 2331, loss = 3277.88516655\n",
      "Iteration 2332, loss = 3277.46334265\n",
      "Iteration 2333, loss = 3277.04168518\n",
      "Iteration 2334, loss = 3276.62019408\n",
      "Iteration 2335, loss = 3276.19886928\n",
      "Iteration 2336, loss = 3275.77771073\n",
      "Iteration 2337, loss = 3275.35671836\n",
      "Iteration 2338, loss = 3274.93589210\n",
      "Iteration 2339, loss = 3274.51523190\n",
      "Iteration 2340, loss = 3274.09473769\n",
      "Iteration 2341, loss = 3273.67440941\n",
      "Iteration 2342, loss = 3273.25424700\n",
      "Iteration 2343, loss = 3272.83425039\n",
      "Iteration 2344, loss = 3272.41441952\n",
      "Iteration 2345, loss = 3271.99475433\n",
      "Iteration 2346, loss = 3271.57525475\n",
      "Iteration 2347, loss = 3271.15592073\n",
      "Iteration 2348, loss = 3270.73675219\n",
      "Iteration 2349, loss = 3270.31774909\n",
      "Iteration 2350, loss = 3269.89891135\n",
      "Iteration 2351, loss = 3269.48023891\n",
      "Iteration 2352, loss = 3269.06173171\n",
      "Iteration 2353, loss = 3268.64338969\n",
      "Iteration 2354, loss = 3268.22521279\n",
      "Iteration 2355, loss = 3267.80720094\n",
      "Iteration 2356, loss = 3267.38935408\n",
      "Iteration 2357, loss = 3266.97167215\n",
      "Iteration 2358, loss = 3266.55415508\n",
      "Iteration 2359, loss = 3266.13680282\n",
      "Iteration 2360, loss = 3265.71961530\n",
      "Iteration 2361, loss = 3265.30259247\n",
      "Iteration 2362, loss = 3264.88573425\n",
      "Iteration 2363, loss = 3264.46904058\n",
      "Iteration 2364, loss = 3264.05251141\n",
      "Iteration 2365, loss = 3263.63614667\n",
      "Iteration 2366, loss = 3263.21994630\n",
      "Iteration 2367, loss = 3262.80391023\n",
      "Iteration 2368, loss = 3262.38803842\n",
      "Iteration 2369, loss = 3261.97233078\n",
      "Iteration 2370, loss = 3261.55678727\n",
      "Iteration 2371, loss = 3261.14140782\n",
      "Iteration 2372, loss = 3260.72619236\n",
      "Iteration 2373, loss = 3260.31114085\n",
      "Iteration 2374, loss = 3259.89625320\n",
      "Iteration 2375, loss = 3259.48152937\n",
      "Iteration 2376, loss = 3259.06696929\n",
      "Iteration 2377, loss = 3258.65257290\n",
      "Iteration 2378, loss = 3258.23834013\n",
      "Iteration 2379, loss = 3257.82427094\n",
      "Iteration 2380, loss = 3257.41036524\n",
      "Iteration 2381, loss = 3256.99662299\n",
      "Iteration 2382, loss = 3256.58304412\n",
      "Iteration 2383, loss = 3256.16962857\n",
      "Iteration 2384, loss = 3255.75637628\n",
      "Iteration 2385, loss = 3255.34328719\n",
      "Iteration 2386, loss = 3254.93036123\n",
      "Iteration 2387, loss = 3254.51759834\n",
      "Iteration 2388, loss = 3254.10499847\n",
      "Iteration 2389, loss = 3253.69256155\n",
      "Iteration 2390, loss = 3253.28028752\n",
      "Iteration 2391, loss = 3252.86817632\n",
      "Iteration 2392, loss = 3252.45622788\n",
      "Iteration 2393, loss = 3252.04444216\n",
      "Iteration 2394, loss = 3251.63281907\n",
      "Iteration 2395, loss = 3251.22135857\n",
      "Iteration 2396, loss = 3250.81006060\n",
      "Iteration 2397, loss = 3250.39892508\n",
      "Iteration 2398, loss = 3249.98795197\n",
      "Iteration 2399, loss = 3249.57714120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2400, loss = 3249.16649270\n",
      "Iteration 2401, loss = 3248.75600643\n",
      "Iteration 2402, loss = 3248.34568231\n",
      "Iteration 2403, loss = 3247.93552028\n",
      "Iteration 2404, loss = 3247.52552030\n",
      "Iteration 2405, loss = 3247.11568228\n",
      "Iteration 2406, loss = 3246.70600618\n",
      "Iteration 2407, loss = 3246.29649193\n",
      "Iteration 2408, loss = 3245.88713948\n",
      "Iteration 2409, loss = 3245.47794875\n",
      "Iteration 2410, loss = 3245.06891970\n",
      "Iteration 2411, loss = 3244.66005225\n",
      "Iteration 2412, loss = 3244.25134636\n",
      "Iteration 2413, loss = 3243.84280195\n",
      "Iteration 2414, loss = 3243.43441898\n",
      "Iteration 2415, loss = 3243.02619737\n",
      "Iteration 2416, loss = 3242.61813706\n",
      "Iteration 2417, loss = 3242.21023801\n",
      "Iteration 2418, loss = 3241.80250014\n",
      "Iteration 2419, loss = 3241.39492340\n",
      "Iteration 2420, loss = 3240.98750772\n",
      "Iteration 2421, loss = 3240.58025304\n",
      "Iteration 2422, loss = 3240.17315932\n",
      "Iteration 2423, loss = 3239.76622647\n",
      "Iteration 2424, loss = 3239.35945445\n",
      "Iteration 2425, loss = 3238.95284320\n",
      "Iteration 2426, loss = 3238.54639265\n",
      "Iteration 2427, loss = 3238.14010274\n",
      "Iteration 2428, loss = 3237.73397342\n",
      "Iteration 2429, loss = 3237.32800462\n",
      "Iteration 2430, loss = 3236.92219628\n",
      "Iteration 2431, loss = 3236.51654835\n",
      "Iteration 2432, loss = 3236.11106076\n",
      "Iteration 2433, loss = 3235.70573345\n",
      "Iteration 2434, loss = 3235.30056637\n",
      "Iteration 2435, loss = 3234.89555945\n",
      "Iteration 2436, loss = 3234.49071264\n",
      "Iteration 2437, loss = 3234.08602587\n",
      "Iteration 2438, loss = 3233.68149908\n",
      "Iteration 2439, loss = 3233.27713222\n",
      "Iteration 2440, loss = 3232.87292522\n",
      "Iteration 2441, loss = 3232.46887803\n",
      "Iteration 2442, loss = 3232.06499059\n",
      "Iteration 2443, loss = 3231.66126282\n",
      "Iteration 2444, loss = 3231.25769469\n",
      "Iteration 2445, loss = 3230.85428612\n",
      "Iteration 2446, loss = 3230.45103706\n",
      "Iteration 2447, loss = 3230.04794744\n",
      "Iteration 2448, loss = 3229.64501722\n",
      "Iteration 2449, loss = 3229.24224632\n",
      "Iteration 2450, loss = 3228.83963469\n",
      "Iteration 2451, loss = 3228.43718227\n",
      "Iteration 2452, loss = 3228.03488900\n",
      "Iteration 2453, loss = 3227.63275482\n",
      "Iteration 2454, loss = 3227.23077967\n",
      "Iteration 2455, loss = 3226.82896350\n",
      "Iteration 2456, loss = 3226.42730623\n",
      "Iteration 2457, loss = 3226.02580782\n",
      "Iteration 2458, loss = 3225.62446821\n",
      "Iteration 2459, loss = 3225.22328733\n",
      "Iteration 2460, loss = 3224.82226513\n",
      "Iteration 2461, loss = 3224.42140154\n",
      "Iteration 2462, loss = 3224.02069652\n",
      "Iteration 2463, loss = 3223.62014999\n",
      "Iteration 2464, loss = 3223.21976190\n",
      "Iteration 2465, loss = 3222.81953220\n",
      "Iteration 2466, loss = 3222.41946081\n",
      "Iteration 2467, loss = 3222.01954769\n",
      "Iteration 2468, loss = 3221.61979277\n",
      "Iteration 2469, loss = 3221.22019600\n",
      "Iteration 2470, loss = 3220.82075732\n",
      "Iteration 2471, loss = 3220.42147666\n",
      "Iteration 2472, loss = 3220.02235398\n",
      "Iteration 2473, loss = 3219.62338920\n",
      "Iteration 2474, loss = 3219.22458228\n",
      "Iteration 2475, loss = 3218.82593315\n",
      "Iteration 2476, loss = 3218.42744175\n",
      "Iteration 2477, loss = 3218.02910803\n",
      "Iteration 2478, loss = 3217.63093193\n",
      "Iteration 2479, loss = 3217.23291339\n",
      "Iteration 2480, loss = 3216.83505235\n",
      "Iteration 2481, loss = 3216.43734875\n",
      "Iteration 2482, loss = 3216.03980253\n",
      "Iteration 2483, loss = 3215.64241364\n",
      "Iteration 2484, loss = 3215.24518201\n",
      "Iteration 2485, loss = 3214.84810760\n",
      "Iteration 2486, loss = 3214.45119033\n",
      "Iteration 2487, loss = 3214.05443016\n",
      "Iteration 2488, loss = 3213.65782702\n",
      "Iteration 2489, loss = 3213.26138086\n",
      "Iteration 2490, loss = 3212.86509161\n",
      "Iteration 2491, loss = 3212.46895922\n",
      "Iteration 2492, loss = 3212.07298364\n",
      "Iteration 2493, loss = 3211.67716479\n",
      "Iteration 2494, loss = 3211.28150263\n",
      "Iteration 2495, loss = 3210.88599710\n",
      "Iteration 2496, loss = 3210.49064814\n",
      "Iteration 2497, loss = 3210.09545569\n",
      "Iteration 2498, loss = 3209.70041969\n",
      "Iteration 2499, loss = 3209.30554009\n",
      "Iteration 2500, loss = 3208.91081683\n",
      "Iteration 2501, loss = 3208.51624984\n",
      "Iteration 2502, loss = 3208.12183908\n",
      "Iteration 2503, loss = 3207.72758448\n",
      "Iteration 2504, loss = 3207.33348599\n",
      "Iteration 2505, loss = 3206.93954354\n",
      "Iteration 2506, loss = 3206.54575709\n",
      "Iteration 2507, loss = 3206.15212657\n",
      "Iteration 2508, loss = 3205.75865193\n",
      "Iteration 2509, loss = 3205.36533310\n",
      "Iteration 2510, loss = 3204.97217004\n",
      "Iteration 2511, loss = 3204.57916268\n",
      "Iteration 2512, loss = 3204.18631096\n",
      "Iteration 2513, loss = 3203.79361483\n",
      "Iteration 2514, loss = 3203.40107424\n",
      "Iteration 2515, loss = 3203.00868911\n",
      "Iteration 2516, loss = 3202.61645940\n",
      "Iteration 2517, loss = 3202.22438506\n",
      "Iteration 2518, loss = 3201.83246601\n",
      "Iteration 2519, loss = 3201.44070221\n",
      "Iteration 2520, loss = 3201.04909359\n",
      "Iteration 2521, loss = 3200.65764011\n",
      "Iteration 2522, loss = 3200.26634169\n",
      "Iteration 2523, loss = 3199.87519830\n",
      "Iteration 2524, loss = 3199.48420986\n",
      "Iteration 2525, loss = 3199.09337632\n",
      "Iteration 2526, loss = 3198.70269763\n",
      "Iteration 2527, loss = 3198.31217372\n",
      "Iteration 2528, loss = 3197.92180455\n",
      "Iteration 2529, loss = 3197.53159005\n",
      "Iteration 2530, loss = 3197.14153017\n",
      "Iteration 2531, loss = 3196.75162484\n",
      "Iteration 2532, loss = 3196.36187402\n",
      "Iteration 2533, loss = 3195.97227764\n",
      "Iteration 2534, loss = 3195.58283566\n",
      "Iteration 2535, loss = 3195.19354801\n",
      "Iteration 2536, loss = 3194.80441463\n",
      "Iteration 2537, loss = 3194.41543547\n",
      "Iteration 2538, loss = 3194.02661047\n",
      "Iteration 2539, loss = 3193.63793959\n",
      "Iteration 2540, loss = 3193.24942275\n",
      "Iteration 2541, loss = 3192.86105990\n",
      "Iteration 2542, loss = 3192.47285099\n",
      "Iteration 2543, loss = 3192.08479596\n",
      "Iteration 2544, loss = 3191.69689475\n",
      "Iteration 2545, loss = 3191.30914731\n",
      "Iteration 2546, loss = 3190.92155358\n",
      "Iteration 2547, loss = 3190.53411350\n",
      "Iteration 2548, loss = 3190.14682703\n",
      "Iteration 2549, loss = 3189.75969409\n",
      "Iteration 2550, loss = 3189.37271464\n",
      "Iteration 2551, loss = 3188.98588862\n",
      "Iteration 2552, loss = 3188.59921597\n",
      "Iteration 2553, loss = 3188.21269664\n",
      "Iteration 2554, loss = 3187.82633057\n",
      "Iteration 2555, loss = 3187.44011770\n",
      "Iteration 2556, loss = 3187.05405799\n",
      "Iteration 2557, loss = 3186.66815136\n",
      "Iteration 2558, loss = 3186.28239777\n",
      "Iteration 2559, loss = 3185.89679716\n",
      "Iteration 2560, loss = 3185.51134948\n",
      "Iteration 2561, loss = 3185.12605466\n",
      "Iteration 2562, loss = 3184.74091266\n",
      "Iteration 2563, loss = 3184.35592342\n",
      "Iteration 2564, loss = 3183.97108687\n",
      "Iteration 2565, loss = 3183.58640297\n",
      "Iteration 2566, loss = 3183.20187166\n",
      "Iteration 2567, loss = 3182.81749289\n",
      "Iteration 2568, loss = 3182.43326659\n",
      "Iteration 2569, loss = 3182.04919271\n",
      "Iteration 2570, loss = 3181.66527121\n",
      "Iteration 2571, loss = 3181.28150201\n",
      "Iteration 2572, loss = 3180.89788507\n",
      "Iteration 2573, loss = 3180.51442033\n",
      "Iteration 2574, loss = 3180.13110773\n",
      "Iteration 2575, loss = 3179.74794722\n",
      "Iteration 2576, loss = 3179.36493875\n",
      "Iteration 2577, loss = 3178.98208225\n",
      "Iteration 2578, loss = 3178.59937768\n",
      "Iteration 2579, loss = 3178.21682498\n",
      "Iteration 2580, loss = 3177.83442408\n",
      "Iteration 2581, loss = 3177.45217495\n",
      "Iteration 2582, loss = 3177.07007751\n",
      "Iteration 2583, loss = 3176.68813173\n",
      "Iteration 2584, loss = 3176.30633753\n",
      "Iteration 2585, loss = 3175.92469487\n",
      "Iteration 2586, loss = 3175.54320369\n",
      "Iteration 2587, loss = 3175.16186394\n",
      "Iteration 2588, loss = 3174.78067556\n",
      "Iteration 2589, loss = 3174.39963850\n",
      "Iteration 2590, loss = 3174.01875269\n",
      "Iteration 2591, loss = 3173.63801809\n",
      "Iteration 2592, loss = 3173.25743465\n",
      "Iteration 2593, loss = 3172.87700229\n",
      "Iteration 2594, loss = 3172.49672099\n",
      "Iteration 2595, loss = 3172.11659066\n",
      "Iteration 2596, loss = 3171.73661127\n",
      "Iteration 2597, loss = 3171.35678276\n",
      "Iteration 2598, loss = 3170.97710506\n",
      "Iteration 2599, loss = 3170.59757814\n",
      "Iteration 2600, loss = 3170.21820193\n",
      "Iteration 2601, loss = 3169.83897637\n",
      "Iteration 2602, loss = 3169.45990142\n",
      "Iteration 2603, loss = 3169.08097702\n",
      "Iteration 2604, loss = 3168.70220312\n",
      "Iteration 2605, loss = 3168.32357965\n",
      "Iteration 2606, loss = 3167.94510657\n",
      "Iteration 2607, loss = 3167.56678382\n",
      "Iteration 2608, loss = 3167.18861134\n",
      "Iteration 2609, loss = 3166.81058909\n",
      "Iteration 2610, loss = 3166.43271701\n",
      "Iteration 2611, loss = 3166.05499504\n",
      "Iteration 2612, loss = 3165.67742313\n",
      "Iteration 2613, loss = 3165.30000122\n",
      "Iteration 2614, loss = 3164.92272927\n",
      "Iteration 2615, loss = 3164.54560721\n",
      "Iteration 2616, loss = 3164.16863499\n",
      "Iteration 2617, loss = 3163.79181256\n",
      "Iteration 2618, loss = 3163.41513987\n",
      "Iteration 2619, loss = 3163.03861685\n",
      "Iteration 2620, loss = 3162.66224346\n",
      "Iteration 2621, loss = 3162.28601965\n",
      "Iteration 2622, loss = 3161.90994535\n",
      "Iteration 2623, loss = 3161.53402051\n",
      "Iteration 2624, loss = 3161.15824509\n",
      "Iteration 2625, loss = 3160.78261902\n",
      "Iteration 2626, loss = 3160.40714226\n",
      "Iteration 2627, loss = 3160.03181474\n",
      "Iteration 2628, loss = 3159.65663642\n",
      "Iteration 2629, loss = 3159.28160724\n",
      "Iteration 2630, loss = 3158.90672714\n",
      "Iteration 2631, loss = 3158.53199608\n",
      "Iteration 2632, loss = 3158.15741400\n",
      "Iteration 2633, loss = 3157.78298085\n",
      "Iteration 2634, loss = 3157.40869656\n",
      "Iteration 2635, loss = 3157.03456110\n",
      "Iteration 2636, loss = 3156.66057440\n",
      "Iteration 2637, loss = 3156.28673642\n",
      "Iteration 2638, loss = 3155.91304709\n",
      "Iteration 2639, loss = 3155.53950637\n",
      "Iteration 2640, loss = 3155.16611420\n",
      "Iteration 2641, loss = 3154.79287053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2642, loss = 3154.41977530\n",
      "Iteration 2643, loss = 3154.04682847\n",
      "Iteration 2644, loss = 3153.67402997\n",
      "Iteration 2645, loss = 3153.30137976\n",
      "Iteration 2646, loss = 3152.92887778\n",
      "Iteration 2647, loss = 3152.55652398\n",
      "Iteration 2648, loss = 3152.18431831\n",
      "Iteration 2649, loss = 3151.81226070\n",
      "Iteration 2650, loss = 3151.44035112\n",
      "Iteration 2651, loss = 3151.06858950\n",
      "Iteration 2652, loss = 3150.69697580\n",
      "Iteration 2653, loss = 3150.32550995\n",
      "Iteration 2654, loss = 3149.95419192\n",
      "Iteration 2655, loss = 3149.58302163\n",
      "Iteration 2656, loss = 3149.21199905\n",
      "Iteration 2657, loss = 3148.84112412\n",
      "Iteration 2658, loss = 3148.47039678\n",
      "Iteration 2659, loss = 3148.09981699\n",
      "Iteration 2660, loss = 3147.72938468\n",
      "Iteration 2661, loss = 3147.35909982\n",
      "Iteration 2662, loss = 3146.98896233\n",
      "Iteration 2663, loss = 3146.61897218\n",
      "Iteration 2664, loss = 3146.24912931\n",
      "Iteration 2665, loss = 3145.87943367\n",
      "Iteration 2666, loss = 3145.50988520\n",
      "Iteration 2667, loss = 3145.14048385\n",
      "Iteration 2668, loss = 3144.77122956\n",
      "Iteration 2669, loss = 3144.40212230\n",
      "Iteration 2670, loss = 3144.03316200\n",
      "Iteration 2671, loss = 3143.66434861\n",
      "Iteration 2672, loss = 3143.29568208\n",
      "Iteration 2673, loss = 3142.92716235\n",
      "Iteration 2674, loss = 3142.55878938\n",
      "Iteration 2675, loss = 3142.19056311\n",
      "Iteration 2676, loss = 3141.82248350\n",
      "Iteration 2677, loss = 3141.45455047\n",
      "Iteration 2678, loss = 3141.08676400\n",
      "Iteration 2679, loss = 3140.71912401\n",
      "Iteration 2680, loss = 3140.35163047\n",
      "Iteration 2681, loss = 3139.98428332\n",
      "Iteration 2682, loss = 3139.61708250\n",
      "Iteration 2683, loss = 3139.25002797\n",
      "Iteration 2684, loss = 3138.88311967\n",
      "Iteration 2685, loss = 3138.51635755\n",
      "Iteration 2686, loss = 3138.14974155\n",
      "Iteration 2687, loss = 3137.78327164\n",
      "Iteration 2688, loss = 3137.41694775\n",
      "Iteration 2689, loss = 3137.05076983\n",
      "Iteration 2690, loss = 3136.68473783\n",
      "Iteration 2691, loss = 3136.31885170\n",
      "Iteration 2692, loss = 3135.95311139\n",
      "Iteration 2693, loss = 3135.58751684\n",
      "Iteration 2694, loss = 3135.22206801\n",
      "Iteration 2695, loss = 3134.85676484\n",
      "Iteration 2696, loss = 3134.49160728\n",
      "Iteration 2697, loss = 3134.12659527\n",
      "Iteration 2698, loss = 3133.76172878\n",
      "Iteration 2699, loss = 3133.39700774\n",
      "Iteration 2700, loss = 3133.03243210\n",
      "Iteration 2701, loss = 3132.66800182\n",
      "Iteration 2702, loss = 3132.30371683\n",
      "Iteration 2703, loss = 3131.93957710\n",
      "Iteration 2704, loss = 3131.57558256\n",
      "Iteration 2705, loss = 3131.21173317\n",
      "Iteration 2706, loss = 3130.84802888\n",
      "Iteration 2707, loss = 3130.48446963\n",
      "Iteration 2708, loss = 3130.12105537\n",
      "Iteration 2709, loss = 3129.75778605\n",
      "Iteration 2710, loss = 3129.39466163\n",
      "Iteration 2711, loss = 3129.03168204\n",
      "Iteration 2712, loss = 3128.66884724\n",
      "Iteration 2713, loss = 3128.30615718\n",
      "Iteration 2714, loss = 3127.94361180\n",
      "Iteration 2715, loss = 3127.58121105\n",
      "Iteration 2716, loss = 3127.21895489\n",
      "Iteration 2717, loss = 3126.85684326\n",
      "Iteration 2718, loss = 3126.49487611\n",
      "Iteration 2719, loss = 3126.13305339\n",
      "Iteration 2720, loss = 3125.77137506\n",
      "Iteration 2721, loss = 3125.40984105\n",
      "Iteration 2722, loss = 3125.04845131\n",
      "Iteration 2723, loss = 3124.68720581\n",
      "Iteration 2724, loss = 3124.32610447\n",
      "Iteration 2725, loss = 3123.96514727\n",
      "Iteration 2726, loss = 3123.60433414\n",
      "Iteration 2727, loss = 3123.24366503\n",
      "Iteration 2728, loss = 3122.88313989\n",
      "Iteration 2729, loss = 3122.52275868\n",
      "Iteration 2730, loss = 3122.16252134\n",
      "Iteration 2731, loss = 3121.80242782\n",
      "Iteration 2732, loss = 3121.44247807\n",
      "Iteration 2733, loss = 3121.08267203\n",
      "Iteration 2734, loss = 3120.72300967\n",
      "Iteration 2735, loss = 3120.36349093\n",
      "Iteration 2736, loss = 3120.00411575\n",
      "Iteration 2737, loss = 3119.64488410\n",
      "Iteration 2738, loss = 3119.28579591\n",
      "Iteration 2739, loss = 3118.92685113\n",
      "Iteration 2740, loss = 3118.56804973\n",
      "Iteration 2741, loss = 3118.20939164\n",
      "Iteration 2742, loss = 3117.85087682\n",
      "Iteration 2743, loss = 3117.49250521\n",
      "Iteration 2744, loss = 3117.13427677\n",
      "Iteration 2745, loss = 3116.77619144\n",
      "Iteration 2746, loss = 3116.41824918\n",
      "Iteration 2747, loss = 3116.06044993\n",
      "Iteration 2748, loss = 3115.70279365\n",
      "Iteration 2749, loss = 3115.34528029\n",
      "Iteration 2750, loss = 3114.98790979\n",
      "Iteration 2751, loss = 3114.63068210\n",
      "Iteration 2752, loss = 3114.27359718\n",
      "Iteration 2753, loss = 3113.91665498\n",
      "Iteration 2754, loss = 3113.55985544\n",
      "Iteration 2755, loss = 3113.20319851\n",
      "Iteration 2756, loss = 3112.84668415\n",
      "Iteration 2757, loss = 3112.49031231\n",
      "Iteration 2758, loss = 3112.13408293\n",
      "Iteration 2759, loss = 3111.77799597\n",
      "Iteration 2760, loss = 3111.42205138\n",
      "Iteration 2761, loss = 3111.06624910\n",
      "Iteration 2762, loss = 3110.71058909\n",
      "Iteration 2763, loss = 3110.35507129\n",
      "Iteration 2764, loss = 3109.99969567\n",
      "Iteration 2765, loss = 3109.64446216\n",
      "Iteration 2766, loss = 3109.28937072\n",
      "Iteration 2767, loss = 3108.93442130\n",
      "Iteration 2768, loss = 3108.57961385\n",
      "Iteration 2769, loss = 3108.22494832\n",
      "Iteration 2770, loss = 3107.87042466\n",
      "Iteration 2771, loss = 3107.51604282\n",
      "Iteration 2772, loss = 3107.16180275\n",
      "Iteration 2773, loss = 3106.80770441\n",
      "Iteration 2774, loss = 3106.45374774\n",
      "Iteration 2775, loss = 3106.09993269\n",
      "Iteration 2776, loss = 3105.74625922\n",
      "Iteration 2777, loss = 3105.39272727\n",
      "Iteration 2778, loss = 3105.03933680\n",
      "Iteration 2779, loss = 3104.68608775\n",
      "Iteration 2780, loss = 3104.33298009\n",
      "Iteration 2781, loss = 3103.98001375\n",
      "Iteration 2782, loss = 3103.62718869\n",
      "Iteration 2783, loss = 3103.27450487\n",
      "Iteration 2784, loss = 3102.92196222\n",
      "Iteration 2785, loss = 3102.56956071\n",
      "Iteration 2786, loss = 3102.21730028\n",
      "Iteration 2787, loss = 3101.86518088\n",
      "Iteration 2788, loss = 3101.51320248\n",
      "Iteration 2789, loss = 3101.16136501\n",
      "Iteration 2790, loss = 3100.80966842\n",
      "Iteration 2791, loss = 3100.45811268\n",
      "Iteration 2792, loss = 3100.10669773\n",
      "Iteration 2793, loss = 3099.75542351\n",
      "Iteration 2794, loss = 3099.40429000\n",
      "Iteration 2795, loss = 3099.05329712\n",
      "Iteration 2796, loss = 3098.70244484\n",
      "Iteration 2797, loss = 3098.35173311\n",
      "Iteration 2798, loss = 3098.00116188\n",
      "Iteration 2799, loss = 3097.65073110\n",
      "Iteration 2800, loss = 3097.30044072\n",
      "Iteration 2801, loss = 3096.95029069\n",
      "Iteration 2802, loss = 3096.60028096\n",
      "Iteration 2803, loss = 3096.25041150\n",
      "Iteration 2804, loss = 3095.90068223\n",
      "Iteration 2805, loss = 3095.55109313\n",
      "Iteration 2806, loss = 3095.20164414\n",
      "Iteration 2807, loss = 3094.85233521\n",
      "Iteration 2808, loss = 3094.50316630\n",
      "Iteration 2809, loss = 3094.15413735\n",
      "Iteration 2810, loss = 3093.80524832\n",
      "Iteration 2811, loss = 3093.45649915\n",
      "Iteration 2812, loss = 3093.10788981\n",
      "Iteration 2813, loss = 3092.75942024\n",
      "Iteration 2814, loss = 3092.41109040\n",
      "Iteration 2815, loss = 3092.06290023\n",
      "Iteration 2816, loss = 3091.71484969\n",
      "Iteration 2817, loss = 3091.36693873\n",
      "Iteration 2818, loss = 3091.01916731\n",
      "Iteration 2819, loss = 3090.67153536\n",
      "Iteration 2820, loss = 3090.32404286\n",
      "Iteration 2821, loss = 3089.97668974\n",
      "Iteration 2822, loss = 3089.62947596\n",
      "Iteration 2823, loss = 3089.28240148\n",
      "Iteration 2824, loss = 3088.93546624\n",
      "Iteration 2825, loss = 3088.58867020\n",
      "Iteration 2826, loss = 3088.24201331\n",
      "Iteration 2827, loss = 3087.89549551\n",
      "Iteration 2828, loss = 3087.54911678\n",
      "Iteration 2829, loss = 3087.20287704\n",
      "Iteration 2830, loss = 3086.85677627\n",
      "Iteration 2831, loss = 3086.51081441\n",
      "Iteration 2832, loss = 3086.16499141\n",
      "Iteration 2833, loss = 3085.81930722\n",
      "Iteration 2834, loss = 3085.47376181\n",
      "Iteration 2835, loss = 3085.12835511\n",
      "Iteration 2836, loss = 3084.78308709\n",
      "Iteration 2837, loss = 3084.43795769\n",
      "Iteration 2838, loss = 3084.09296687\n",
      "Iteration 2839, loss = 3083.74811458\n",
      "Iteration 2840, loss = 3083.40340078\n",
      "Iteration 2841, loss = 3083.05882541\n",
      "Iteration 2842, loss = 3082.71438842\n",
      "Iteration 2843, loss = 3082.37008978\n",
      "Iteration 2844, loss = 3082.02592943\n",
      "Iteration 2845, loss = 3081.68190733\n",
      "Iteration 2846, loss = 3081.33802343\n",
      "Iteration 2847, loss = 3080.99427768\n",
      "Iteration 2848, loss = 3080.65067004\n",
      "Iteration 2849, loss = 3080.30720045\n",
      "Iteration 2850, loss = 3079.96386888\n",
      "Iteration 2851, loss = 3079.62067526\n",
      "Iteration 2852, loss = 3079.27761957\n",
      "Iteration 2853, loss = 3078.93470174\n",
      "Iteration 2854, loss = 3078.59192174\n",
      "Iteration 2855, loss = 3078.24927951\n",
      "Iteration 2856, loss = 3077.90677501\n",
      "Iteration 2857, loss = 3077.56440820\n",
      "Iteration 2858, loss = 3077.22217901\n",
      "Iteration 2859, loss = 3076.88008742\n",
      "Iteration 2860, loss = 3076.53813337\n",
      "Iteration 2861, loss = 3076.19631681\n",
      "Iteration 2862, loss = 3075.85463770\n",
      "Iteration 2863, loss = 3075.51309599\n",
      "Iteration 2864, loss = 3075.17169163\n",
      "Iteration 2865, loss = 3074.83042458\n",
      "Iteration 2866, loss = 3074.48929479\n",
      "Iteration 2867, loss = 3074.14830222\n",
      "Iteration 2868, loss = 3073.80744681\n",
      "Iteration 2869, loss = 3073.46672853\n",
      "Iteration 2870, loss = 3073.12614732\n",
      "Iteration 2871, loss = 3072.78570314\n",
      "Iteration 2872, loss = 3072.44539593\n",
      "Iteration 2873, loss = 3072.10522567\n",
      "Iteration 2874, loss = 3071.76519229\n",
      "Iteration 2875, loss = 3071.42529576\n",
      "Iteration 2876, loss = 3071.08553602\n",
      "Iteration 2877, loss = 3070.74591303\n",
      "Iteration 2878, loss = 3070.40642674\n",
      "Iteration 2879, loss = 3070.06707711\n",
      "Iteration 2880, loss = 3069.72786409\n",
      "Iteration 2881, loss = 3069.38878764\n",
      "Iteration 2882, loss = 3069.04984770\n",
      "Iteration 2883, loss = 3068.71104424\n",
      "Iteration 2884, loss = 3068.37237720\n",
      "Iteration 2885, loss = 3068.03384654\n",
      "Iteration 2886, loss = 3067.69545221\n",
      "Iteration 2887, loss = 3067.35719417\n",
      "Iteration 2888, loss = 3067.01907238\n",
      "Iteration 2889, loss = 3066.68108678\n",
      "Iteration 2890, loss = 3066.34323733\n",
      "Iteration 2891, loss = 3066.00552398\n",
      "Iteration 2892, loss = 3065.66794669\n",
      "Iteration 2893, loss = 3065.33050541\n",
      "Iteration 2894, loss = 3064.99320010\n",
      "Iteration 2895, loss = 3064.65603070\n",
      "Iteration 2896, loss = 3064.31899719\n",
      "Iteration 2897, loss = 3063.98209950\n",
      "Iteration 2898, loss = 3063.64533759\n",
      "Iteration 2899, loss = 3063.30871142\n",
      "Iteration 2900, loss = 3062.97222094\n",
      "Iteration 2901, loss = 3062.63586610\n",
      "Iteration 2902, loss = 3062.29964687\n",
      "Iteration 2903, loss = 3061.96356319\n",
      "Iteration 2904, loss = 3061.62761502\n",
      "Iteration 2905, loss = 3061.29180231\n",
      "Iteration 2906, loss = 3060.95612502\n",
      "Iteration 2907, loss = 3060.62058310\n",
      "Iteration 2908, loss = 3060.28517651\n",
      "Iteration 2909, loss = 3059.94990520\n",
      "Iteration 2910, loss = 3059.61476912\n",
      "Iteration 2911, loss = 3059.27976823\n",
      "Iteration 2912, loss = 3058.94490249\n",
      "Iteration 2913, loss = 3058.61017185\n",
      "Iteration 2914, loss = 3058.27557626\n",
      "Iteration 2915, loss = 3057.94111569\n",
      "Iteration 2916, loss = 3057.60679007\n",
      "Iteration 2917, loss = 3057.27259937\n",
      "Iteration 2918, loss = 3056.93854355\n",
      "Iteration 2919, loss = 3056.60462256\n",
      "Iteration 2920, loss = 3056.27083634\n",
      "Iteration 2921, loss = 3055.93718487\n",
      "Iteration 2922, loss = 3055.60366808\n",
      "Iteration 2923, loss = 3055.27028595\n",
      "Iteration 2924, loss = 3054.93703842\n",
      "Iteration 2925, loss = 3054.60392544\n",
      "Iteration 2926, loss = 3054.27094698\n",
      "Iteration 2927, loss = 3053.93810298\n",
      "Iteration 2928, loss = 3053.60539341\n",
      "Iteration 2929, loss = 3053.27281821\n",
      "Iteration 2930, loss = 3052.94037735\n",
      "Iteration 2931, loss = 3052.60807077\n",
      "Iteration 2932, loss = 3052.27589844\n",
      "Iteration 2933, loss = 3051.94386031\n",
      "Iteration 2934, loss = 3051.61195632\n",
      "Iteration 2935, loss = 3051.28018645\n",
      "Iteration 2936, loss = 3050.94855064\n",
      "Iteration 2937, loss = 3050.61704885\n",
      "Iteration 2938, loss = 3050.28568104\n",
      "Iteration 2939, loss = 3049.95444715\n",
      "Iteration 2940, loss = 3049.62334715\n",
      "Iteration 2941, loss = 3049.29238099\n",
      "Iteration 2942, loss = 3048.96154863\n",
      "Iteration 2943, loss = 3048.63085002\n",
      "Iteration 2944, loss = 3048.30028511\n",
      "Iteration 2945, loss = 3047.96985387\n",
      "Iteration 2946, loss = 3047.63955624\n",
      "Iteration 2947, loss = 3047.30939219\n",
      "Iteration 2948, loss = 3046.97936167\n",
      "Iteration 2949, loss = 3046.64946463\n",
      "Iteration 2950, loss = 3046.31970104\n",
      "Iteration 2951, loss = 3045.99007084\n",
      "Iteration 2952, loss = 3045.66057399\n",
      "Iteration 2953, loss = 3045.33121045\n",
      "Iteration 2954, loss = 3045.00198017\n",
      "Iteration 2955, loss = 3044.67288311\n",
      "Iteration 2956, loss = 3044.34391922\n",
      "Iteration 2957, loss = 3044.01508847\n",
      "Iteration 2958, loss = 3043.68639080\n",
      "Iteration 2959, loss = 3043.35782618\n",
      "Iteration 2960, loss = 3043.02939455\n",
      "Iteration 2961, loss = 3042.70109588\n",
      "Iteration 2962, loss = 3042.37293012\n",
      "Iteration 2963, loss = 3042.04489722\n",
      "Iteration 2964, loss = 3041.71699715\n",
      "Iteration 2965, loss = 3041.38922986\n",
      "Iteration 2966, loss = 3041.06159530\n",
      "Iteration 2967, loss = 3040.73409342\n",
      "Iteration 2968, loss = 3040.40672420\n",
      "Iteration 2969, loss = 3040.07948758\n",
      "Iteration 2970, loss = 3039.75238352\n",
      "Iteration 2971, loss = 3039.42541197\n",
      "Iteration 2972, loss = 3039.09857290\n",
      "Iteration 2973, loss = 3038.77186625\n",
      "Iteration 2974, loss = 3038.44529198\n",
      "Iteration 2975, loss = 3038.11885006\n",
      "Iteration 2976, loss = 3037.79254043\n",
      "Iteration 2977, loss = 3037.46636306\n",
      "Iteration 2978, loss = 3037.14031789\n",
      "Iteration 2979, loss = 3036.81440489\n",
      "Iteration 2980, loss = 3036.48862401\n",
      "Iteration 2981, loss = 3036.16297522\n",
      "Iteration 2982, loss = 3035.83745845\n",
      "Iteration 2983, loss = 3035.51207368\n",
      "Iteration 2984, loss = 3035.18682085\n",
      "Iteration 2985, loss = 3034.86169993\n",
      "Iteration 2986, loss = 3034.53671088\n",
      "Iteration 2987, loss = 3034.21185363\n",
      "Iteration 2988, loss = 3033.88712817\n",
      "Iteration 2989, loss = 3033.56253443\n",
      "Iteration 2990, loss = 3033.23807239\n",
      "Iteration 2991, loss = 3032.91374198\n",
      "Iteration 2992, loss = 3032.58954318\n",
      "Iteration 2993, loss = 3032.26547594\n",
      "Iteration 2994, loss = 3031.94154021\n",
      "Iteration 2995, loss = 3031.61773595\n",
      "Iteration 2996, loss = 3031.29406312\n",
      "Iteration 2997, loss = 3030.97052168\n",
      "Iteration 2998, loss = 3030.64711158\n",
      "Iteration 2999, loss = 3030.32383278\n",
      "Iteration 3000, loss = 3030.00068523\n",
      "Iteration 3001, loss = 3029.67766890\n",
      "Iteration 3002, loss = 3029.35478374\n",
      "Iteration 3003, loss = 3029.03202970\n",
      "Iteration 3004, loss = 3028.70940675\n",
      "Iteration 3005, loss = 3028.38691485\n",
      "Iteration 3006, loss = 3028.06455393\n",
      "Iteration 3007, loss = 3027.74232398\n",
      "Iteration 3008, loss = 3027.42022494\n",
      "Iteration 3009, loss = 3027.09825677\n",
      "Iteration 3010, loss = 3026.77641942\n",
      "Iteration 3011, loss = 3026.45471286\n",
      "Iteration 3012, loss = 3026.13313704\n",
      "Iteration 3013, loss = 3025.81169192\n",
      "Iteration 3014, loss = 3025.49037746\n",
      "Iteration 3015, loss = 3025.16919361\n",
      "Iteration 3016, loss = 3024.84814033\n",
      "Iteration 3017, loss = 3024.52721757\n",
      "Iteration 3018, loss = 3024.20642531\n",
      "Iteration 3019, loss = 3023.88576349\n",
      "Iteration 3020, loss = 3023.56523206\n",
      "Iteration 3021, loss = 3023.24483100\n",
      "Iteration 3022, loss = 3022.92456025\n",
      "Iteration 3023, loss = 3022.60441978\n",
      "Iteration 3024, loss = 3022.28440953\n",
      "Iteration 3025, loss = 3021.96452948\n",
      "Iteration 3026, loss = 3021.64477957\n",
      "Iteration 3027, loss = 3021.32515976\n",
      "Iteration 3028, loss = 3021.00567002\n",
      "Iteration 3029, loss = 3020.68631029\n",
      "Iteration 3030, loss = 3020.36708054\n",
      "Iteration 3031, loss = 3020.04798072\n",
      "Iteration 3032, loss = 3019.72901080\n",
      "Iteration 3033, loss = 3019.41017073\n",
      "Iteration 3034, loss = 3019.09146046\n",
      "Iteration 3035, loss = 3018.77287996\n",
      "Iteration 3036, loss = 3018.45442918\n",
      "Iteration 3037, loss = 3018.13610809\n",
      "Iteration 3038, loss = 3017.81791663\n",
      "Iteration 3039, loss = 3017.49985477\n",
      "Iteration 3040, loss = 3017.18192247\n",
      "Iteration 3041, loss = 3016.86411968\n",
      "Iteration 3042, loss = 3016.54644636\n",
      "Iteration 3043, loss = 3016.22890247\n",
      "Iteration 3044, loss = 3015.91148796\n",
      "Iteration 3045, loss = 3015.59420281\n",
      "Iteration 3046, loss = 3015.27704695\n",
      "Iteration 3047, loss = 3014.96002036\n",
      "Iteration 3048, loss = 3014.64312299\n",
      "Iteration 3049, loss = 3014.32635479\n",
      "Iteration 3050, loss = 3014.00971573\n",
      "Iteration 3051, loss = 3013.69320577\n",
      "Iteration 3052, loss = 3013.37682485\n",
      "Iteration 3053, loss = 3013.06057295\n",
      "Iteration 3054, loss = 3012.74445002\n",
      "Iteration 3055, loss = 3012.42845601\n",
      "Iteration 3056, loss = 3012.11259090\n",
      "Iteration 3057, loss = 3011.79685462\n",
      "Iteration 3058, loss = 3011.48124715\n",
      "Iteration 3059, loss = 3011.16576844\n",
      "Iteration 3060, loss = 3010.85041845\n",
      "Iteration 3061, loss = 3010.53519713\n",
      "Iteration 3062, loss = 3010.22010446\n",
      "Iteration 3063, loss = 3009.90514038\n",
      "Iteration 3064, loss = 3009.59030485\n",
      "Iteration 3065, loss = 3009.27559783\n",
      "Iteration 3066, loss = 3008.96101929\n",
      "Iteration 3067, loss = 3008.64656917\n",
      "Iteration 3068, loss = 3008.33224745\n",
      "Iteration 3069, loss = 3008.01805406\n",
      "Iteration 3070, loss = 3007.70398899\n",
      "Iteration 3071, loss = 3007.39005218\n",
      "Iteration 3072, loss = 3007.07624359\n",
      "Iteration 3073, loss = 3006.76256319\n",
      "Iteration 3074, loss = 3006.44901092\n",
      "Iteration 3075, loss = 3006.13558675\n",
      "Iteration 3076, loss = 3005.82229065\n",
      "Iteration 3077, loss = 3005.50912256\n",
      "Iteration 3078, loss = 3005.19608244\n",
      "Iteration 3079, loss = 3004.88317026\n",
      "Iteration 3080, loss = 3004.57038598\n",
      "Iteration 3081, loss = 3004.25772954\n",
      "Iteration 3082, loss = 3003.94520092\n",
      "Iteration 3083, loss = 3003.63280007\n",
      "Iteration 3084, loss = 3003.32052695\n",
      "Iteration 3085, loss = 3003.00838152\n",
      "Iteration 3086, loss = 3002.69636373\n",
      "Iteration 3087, loss = 3002.38447356\n",
      "Iteration 3088, loss = 3002.07271095\n",
      "Iteration 3089, loss = 3001.76107586\n",
      "Iteration 3090, loss = 3001.44956826\n",
      "Iteration 3091, loss = 3001.13818811\n",
      "Iteration 3092, loss = 3000.82693535\n",
      "Iteration 3093, loss = 3000.51580996\n",
      "Iteration 3094, loss = 3000.20481189\n",
      "Iteration 3095, loss = 2999.89394110\n",
      "Iteration 3096, loss = 2999.58319755\n",
      "Iteration 3097, loss = 2999.27258121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3098, loss = 2998.96209202\n",
      "Iteration 3099, loss = 2998.65172994\n",
      "Iteration 3100, loss = 2998.34149495\n",
      "Iteration 3101, loss = 2998.03138699\n",
      "Iteration 3102, loss = 2997.72140603\n",
      "Iteration 3103, loss = 2997.41155203\n",
      "Iteration 3104, loss = 2997.10182494\n",
      "Iteration 3105, loss = 2996.79222473\n",
      "Iteration 3106, loss = 2996.48275135\n",
      "Iteration 3107, loss = 2996.17340477\n",
      "Iteration 3108, loss = 2995.86418494\n",
      "Iteration 3109, loss = 2995.55509182\n",
      "Iteration 3110, loss = 2995.24612538\n",
      "Iteration 3111, loss = 2994.93728557\n",
      "Iteration 3112, loss = 2994.62857235\n",
      "Iteration 3113, loss = 2994.31998569\n",
      "Iteration 3114, loss = 2994.01152553\n",
      "Iteration 3115, loss = 2993.70319185\n",
      "Iteration 3116, loss = 2993.39498460\n",
      "Iteration 3117, loss = 2993.08690375\n",
      "Iteration 3118, loss = 2992.77894924\n",
      "Iteration 3119, loss = 2992.47112105\n",
      "Iteration 3120, loss = 2992.16341912\n",
      "Iteration 3121, loss = 2991.85584343\n",
      "Iteration 3122, loss = 2991.54839393\n",
      "Iteration 3123, loss = 2991.24107058\n",
      "Iteration 3124, loss = 2990.93387334\n",
      "Iteration 3125, loss = 2990.62680217\n",
      "Iteration 3126, loss = 2990.31985703\n",
      "Iteration 3127, loss = 2990.01303788\n",
      "Iteration 3128, loss = 2989.70634469\n",
      "Iteration 3129, loss = 2989.39977740\n",
      "Iteration 3130, loss = 2989.09333599\n",
      "Iteration 3131, loss = 2988.78702041\n",
      "Iteration 3132, loss = 2988.48083062\n",
      "Iteration 3133, loss = 2988.17476658\n",
      "Iteration 3134, loss = 2987.86882826\n",
      "Iteration 3135, loss = 2987.56301560\n",
      "Iteration 3136, loss = 2987.25732858\n",
      "Iteration 3137, loss = 2986.95176716\n",
      "Iteration 3138, loss = 2986.64633128\n",
      "Iteration 3139, loss = 2986.34102092\n",
      "Iteration 3140, loss = 2986.03583603\n",
      "Iteration 3141, loss = 2985.73077658\n",
      "Iteration 3142, loss = 2985.42584252\n",
      "Iteration 3143, loss = 2985.12103382\n",
      "Iteration 3144, loss = 2984.81635043\n",
      "Iteration 3145, loss = 2984.51179232\n",
      "Iteration 3146, loss = 2984.20735944\n",
      "Iteration 3147, loss = 2983.90305177\n",
      "Iteration 3148, loss = 2983.59886925\n",
      "Iteration 3149, loss = 2983.29481184\n",
      "Iteration 3150, loss = 2982.99087952\n",
      "Iteration 3151, loss = 2982.68707224\n",
      "Iteration 3152, loss = 2982.38338995\n",
      "Iteration 3153, loss = 2982.07983263\n",
      "Iteration 3154, loss = 2981.77640022\n",
      "Iteration 3155, loss = 2981.47309270\n",
      "Iteration 3156, loss = 2981.16991003\n",
      "Iteration 3157, loss = 2980.86685215\n",
      "Iteration 3158, loss = 2980.56391904\n",
      "Iteration 3159, loss = 2980.26111066\n",
      "Iteration 3160, loss = 2979.95842696\n",
      "Iteration 3161, loss = 2979.65586790\n",
      "Iteration 3162, loss = 2979.35343346\n",
      "Iteration 3163, loss = 2979.05112358\n",
      "Iteration 3164, loss = 2978.74893824\n",
      "Iteration 3165, loss = 2978.44687738\n",
      "Iteration 3166, loss = 2978.14494097\n",
      "Iteration 3167, loss = 2977.84312898\n",
      "Iteration 3168, loss = 2977.54144136\n",
      "Iteration 3169, loss = 2977.23987807\n",
      "Iteration 3170, loss = 2976.93843908\n",
      "Iteration 3171, loss = 2976.63712434\n",
      "Iteration 3172, loss = 2976.33593382\n",
      "Iteration 3173, loss = 2976.03486748\n",
      "Iteration 3174, loss = 2975.73392528\n",
      "Iteration 3175, loss = 2975.43310719\n",
      "Iteration 3176, loss = 2975.13241315\n",
      "Iteration 3177, loss = 2974.83184313\n",
      "Iteration 3178, loss = 2974.53139710\n",
      "Iteration 3179, loss = 2974.23107502\n",
      "Iteration 3180, loss = 2973.93087684\n",
      "Iteration 3181, loss = 2973.63080253\n",
      "Iteration 3182, loss = 2973.33085205\n",
      "Iteration 3183, loss = 2973.03102536\n",
      "Iteration 3184, loss = 2972.73132242\n",
      "Iteration 3185, loss = 2972.43174320\n",
      "Iteration 3186, loss = 2972.13228765\n",
      "Iteration 3187, loss = 2971.83295573\n",
      "Iteration 3188, loss = 2971.53374742\n",
      "Iteration 3189, loss = 2971.23466266\n",
      "Iteration 3190, loss = 2970.93570142\n",
      "Iteration 3191, loss = 2970.63686367\n",
      "Iteration 3192, loss = 2970.33814936\n",
      "Iteration 3193, loss = 2970.03955845\n",
      "Iteration 3194, loss = 2969.74109091\n",
      "Iteration 3195, loss = 2969.44274670\n",
      "Iteration 3196, loss = 2969.14452578\n",
      "Iteration 3197, loss = 2968.84642811\n",
      "Iteration 3198, loss = 2968.54845366\n",
      "Iteration 3199, loss = 2968.25060237\n",
      "Iteration 3200, loss = 2967.95287423\n",
      "Iteration 3201, loss = 2967.65526918\n",
      "Iteration 3202, loss = 2967.35778720\n",
      "Iteration 3203, loss = 2967.06042823\n",
      "Iteration 3204, loss = 2966.76319225\n",
      "Iteration 3205, loss = 2966.46607922\n",
      "Iteration 3206, loss = 2966.16908909\n",
      "Iteration 3207, loss = 2965.87222183\n",
      "Iteration 3208, loss = 2965.57547740\n",
      "Iteration 3209, loss = 2965.27885576\n",
      "Iteration 3210, loss = 2964.98235688\n",
      "Iteration 3211, loss = 2964.68598072\n",
      "Iteration 3212, loss = 2964.38972723\n",
      "Iteration 3213, loss = 2964.09359639\n",
      "Iteration 3214, loss = 2963.79758815\n",
      "Iteration 3215, loss = 2963.50170247\n",
      "Iteration 3216, loss = 2963.20593932\n",
      "Iteration 3217, loss = 2962.91029866\n",
      "Iteration 3218, loss = 2962.61478045\n",
      "Iteration 3219, loss = 2962.31938465\n",
      "Iteration 3220, loss = 2962.02411122\n",
      "Iteration 3221, loss = 2961.72896014\n",
      "Iteration 3222, loss = 2961.43393135\n",
      "Iteration 3223, loss = 2961.13902483\n",
      "Iteration 3224, loss = 2960.84424053\n",
      "Iteration 3225, loss = 2960.54957841\n",
      "Iteration 3226, loss = 2960.25503845\n",
      "Iteration 3227, loss = 2959.96062059\n",
      "Iteration 3228, loss = 2959.66632481\n",
      "Iteration 3229, loss = 2959.37215106\n",
      "Iteration 3230, loss = 2959.07809931\n",
      "Iteration 3231, loss = 2958.78416952\n",
      "Iteration 3232, loss = 2958.49036165\n",
      "Iteration 3233, loss = 2958.19667567\n",
      "Iteration 3234, loss = 2957.90311153\n",
      "Iteration 3235, loss = 2957.60966921\n",
      "Iteration 3236, loss = 2957.31634865\n",
      "Iteration 3237, loss = 2957.02314983\n",
      "Iteration 3238, loss = 2956.73007271\n",
      "Iteration 3239, loss = 2956.43711725\n",
      "Iteration 3240, loss = 2956.14428341\n",
      "Iteration 3241, loss = 2955.85157115\n",
      "Iteration 3242, loss = 2955.55898044\n",
      "Iteration 3243, loss = 2955.26651125\n",
      "Iteration 3244, loss = 2954.97416352\n",
      "Iteration 3245, loss = 2954.68193723\n",
      "Iteration 3246, loss = 2954.38983234\n",
      "Iteration 3247, loss = 2954.09784881\n",
      "Iteration 3248, loss = 2953.80598660\n",
      "Iteration 3249, loss = 2953.51424568\n",
      "Iteration 3250, loss = 2953.22262600\n",
      "Iteration 3251, loss = 2952.93112754\n",
      "Iteration 3252, loss = 2952.63975025\n",
      "Iteration 3253, loss = 2952.34849410\n",
      "Iteration 3254, loss = 2952.05735905\n",
      "Iteration 3255, loss = 2951.76634507\n",
      "Iteration 3256, loss = 2951.47545211\n",
      "Iteration 3257, loss = 2951.18468014\n",
      "Iteration 3258, loss = 2950.89402912\n",
      "Iteration 3259, loss = 2950.60349901\n",
      "Iteration 3260, loss = 2950.31308979\n",
      "Iteration 3261, loss = 2950.02280140\n",
      "Iteration 3262, loss = 2949.73263382\n",
      "Iteration 3263, loss = 2949.44258700\n",
      "Iteration 3264, loss = 2949.15266091\n",
      "Iteration 3265, loss = 2948.86285552\n",
      "Iteration 3266, loss = 2948.57317078\n",
      "Iteration 3267, loss = 2948.28360667\n",
      "Iteration 3268, loss = 2947.99416313\n",
      "Iteration 3269, loss = 2947.70484014\n",
      "Iteration 3270, loss = 2947.41563766\n",
      "Iteration 3271, loss = 2947.12655565\n",
      "Iteration 3272, loss = 2946.83759407\n",
      "Iteration 3273, loss = 2946.54875290\n",
      "Iteration 3274, loss = 2946.26003208\n",
      "Iteration 3275, loss = 2945.97143159\n",
      "Iteration 3276, loss = 2945.68295139\n",
      "Iteration 3277, loss = 2945.39459144\n",
      "Iteration 3278, loss = 2945.10635170\n",
      "Iteration 3279, loss = 2944.81823214\n",
      "Iteration 3280, loss = 2944.53023273\n",
      "Iteration 3281, loss = 2944.24235342\n",
      "Iteration 3282, loss = 2943.95459417\n",
      "Iteration 3283, loss = 2943.66695496\n",
      "Iteration 3284, loss = 2943.37943575\n",
      "Iteration 3285, loss = 2943.09203649\n",
      "Iteration 3286, loss = 2942.80475715\n",
      "Iteration 3287, loss = 2942.51759770\n",
      "Iteration 3288, loss = 2942.23055810\n",
      "Iteration 3289, loss = 2941.94363832\n",
      "Iteration 3290, loss = 2941.65683831\n",
      "Iteration 3291, loss = 2941.37015803\n",
      "Iteration 3292, loss = 2941.08359747\n",
      "Iteration 3293, loss = 2940.79715657\n",
      "Iteration 3294, loss = 2940.51083530\n",
      "Iteration 3295, loss = 2940.22463363\n",
      "Iteration 3296, loss = 2939.93855151\n",
      "Iteration 3297, loss = 2939.65258892\n",
      "Iteration 3298, loss = 2939.36674581\n",
      "Iteration 3299, loss = 2939.08102215\n",
      "Iteration 3300, loss = 2938.79541791\n",
      "Iteration 3301, loss = 2938.50993304\n",
      "Iteration 3302, loss = 2938.22456751\n",
      "Iteration 3303, loss = 2937.93932129\n",
      "Iteration 3304, loss = 2937.65419434\n",
      "Iteration 3305, loss = 2937.36918662\n",
      "Iteration 3306, loss = 2937.08429810\n",
      "Iteration 3307, loss = 2936.79952874\n",
      "Iteration 3308, loss = 2936.51487850\n",
      "Iteration 3309, loss = 2936.23034735\n",
      "Iteration 3310, loss = 2935.94593525\n",
      "Iteration 3311, loss = 2935.66164217\n",
      "Iteration 3312, loss = 2935.37746807\n",
      "Iteration 3313, loss = 2935.09341291\n",
      "Iteration 3314, loss = 2934.80947666\n",
      "Iteration 3315, loss = 2934.52565929\n",
      "Iteration 3316, loss = 2934.24196075\n",
      "Iteration 3317, loss = 2933.95838101\n",
      "Iteration 3318, loss = 2933.67492004\n",
      "Iteration 3319, loss = 2933.39157780\n",
      "Iteration 3320, loss = 2933.10835425\n",
      "Iteration 3321, loss = 2932.82524935\n",
      "Iteration 3322, loss = 2932.54226308\n",
      "Iteration 3323, loss = 2932.25939540\n",
      "Iteration 3324, loss = 2931.97664626\n",
      "Iteration 3325, loss = 2931.69401564\n",
      "Iteration 3326, loss = 2931.41150350\n",
      "Iteration 3327, loss = 2931.12910980\n",
      "Iteration 3328, loss = 2930.84683451\n",
      "Iteration 3329, loss = 2930.56467759\n",
      "Iteration 3330, loss = 2930.28263901\n",
      "Iteration 3331, loss = 2930.00071872\n",
      "Iteration 3332, loss = 2929.71891671\n",
      "Iteration 3333, loss = 2929.43723292\n",
      "Iteration 3334, loss = 2929.15566732\n",
      "Iteration 3335, loss = 2928.87421989\n",
      "Iteration 3336, loss = 2928.59289058\n",
      "Iteration 3337, loss = 2928.31167935\n",
      "Iteration 3338, loss = 2928.03058618\n",
      "Iteration 3339, loss = 2927.74961102\n",
      "Iteration 3340, loss = 2927.46875384\n",
      "Iteration 3341, loss = 2927.18801461\n",
      "Iteration 3342, loss = 2926.90739329\n",
      "Iteration 3343, loss = 2926.62688985\n",
      "Iteration 3344, loss = 2926.34650424\n",
      "Iteration 3345, loss = 2926.06623644\n",
      "Iteration 3346, loss = 2925.78608640\n",
      "Iteration 3347, loss = 2925.50605410\n",
      "Iteration 3348, loss = 2925.22613950\n",
      "Iteration 3349, loss = 2924.94634256\n",
      "Iteration 3350, loss = 2924.66666325\n",
      "Iteration 3351, loss = 2924.38710153\n",
      "Iteration 3352, loss = 2924.10765737\n",
      "Iteration 3353, loss = 2923.82833073\n",
      "Iteration 3354, loss = 2923.54912158\n",
      "Iteration 3355, loss = 2923.27002988\n",
      "Iteration 3356, loss = 2922.99105560\n",
      "Iteration 3357, loss = 2922.71219870\n",
      "Iteration 3358, loss = 2922.43345914\n",
      "Iteration 3359, loss = 2922.15483690\n",
      "Iteration 3360, loss = 2921.87633193\n",
      "Iteration 3361, loss = 2921.59794420\n",
      "Iteration 3362, loss = 2921.31967368\n",
      "Iteration 3363, loss = 2921.04152033\n",
      "Iteration 3364, loss = 2920.76348412\n",
      "Iteration 3365, loss = 2920.48556501\n",
      "Iteration 3366, loss = 2920.20776297\n",
      "Iteration 3367, loss = 2919.93007795\n",
      "Iteration 3368, loss = 2919.65250994\n",
      "Iteration 3369, loss = 2919.37505888\n",
      "Iteration 3370, loss = 2919.09772475\n",
      "Iteration 3371, loss = 2918.82050752\n",
      "Iteration 3372, loss = 2918.54340714\n",
      "Iteration 3373, loss = 2918.26642358\n",
      "Iteration 3374, loss = 2917.98955682\n",
      "Iteration 3375, loss = 2917.71280680\n",
      "Iteration 3376, loss = 2917.43617350\n",
      "Iteration 3377, loss = 2917.15965689\n",
      "Iteration 3378, loss = 2916.88325692\n",
      "Iteration 3379, loss = 2916.60697357\n",
      "Iteration 3380, loss = 2916.33080680\n",
      "Iteration 3381, loss = 2916.05475657\n",
      "Iteration 3382, loss = 2915.77882285\n",
      "Iteration 3383, loss = 2915.50300561\n",
      "Iteration 3384, loss = 2915.22730481\n",
      "Iteration 3385, loss = 2914.95172042\n",
      "Iteration 3386, loss = 2914.67625239\n",
      "Iteration 3387, loss = 2914.40090071\n",
      "Iteration 3388, loss = 2914.12566532\n",
      "Iteration 3389, loss = 2913.85054620\n",
      "Iteration 3390, loss = 2913.57554332\n",
      "Iteration 3391, loss = 2913.30065664\n",
      "Iteration 3392, loss = 2913.02588612\n",
      "Iteration 3393, loss = 2912.75123173\n",
      "Iteration 3394, loss = 2912.47669344\n",
      "Iteration 3395, loss = 2912.20227121\n",
      "Iteration 3396, loss = 2911.92796500\n",
      "Iteration 3397, loss = 2911.65377479\n",
      "Iteration 3398, loss = 2911.37970053\n",
      "Iteration 3399, loss = 2911.10574220\n",
      "Iteration 3400, loss = 2910.83189976\n",
      "Iteration 3401, loss = 2910.55817318\n",
      "Iteration 3402, loss = 2910.28456241\n",
      "Iteration 3403, loss = 2910.01106744\n",
      "Iteration 3404, loss = 2909.73768821\n",
      "Iteration 3405, loss = 2909.46442470\n",
      "Iteration 3406, loss = 2909.19127688\n",
      "Iteration 3407, loss = 2908.91824471\n",
      "Iteration 3408, loss = 2908.64532815\n",
      "Iteration 3409, loss = 2908.37252717\n",
      "Iteration 3410, loss = 2908.09984175\n",
      "Iteration 3411, loss = 2907.82727183\n",
      "Iteration 3412, loss = 2907.55481740\n",
      "Iteration 3413, loss = 2907.28247841\n",
      "Iteration 3414, loss = 2907.01025483\n",
      "Iteration 3415, loss = 2906.73814662\n",
      "Iteration 3416, loss = 2906.46615376\n",
      "Iteration 3417, loss = 2906.19427621\n",
      "Iteration 3418, loss = 2905.92251394\n",
      "Iteration 3419, loss = 2905.65086690\n",
      "Iteration 3420, loss = 2905.37933508\n",
      "Iteration 3421, loss = 2905.10791842\n",
      "Iteration 3422, loss = 2904.83661691\n",
      "Iteration 3423, loss = 2904.56543050\n",
      "Iteration 3424, loss = 2904.29435916\n",
      "Iteration 3425, loss = 2904.02340286\n",
      "Iteration 3426, loss = 2903.75256157\n",
      "Iteration 3427, loss = 2903.48183524\n",
      "Iteration 3428, loss = 2903.21122385\n",
      "Iteration 3429, loss = 2902.94072736\n",
      "Iteration 3430, loss = 2902.67034574\n",
      "Iteration 3431, loss = 2902.40007896\n",
      "Iteration 3432, loss = 2902.12992697\n",
      "Iteration 3433, loss = 2901.85988976\n",
      "Iteration 3434, loss = 2901.58996727\n",
      "Iteration 3435, loss = 2901.32015949\n",
      "Iteration 3436, loss = 2901.05046637\n",
      "Iteration 3437, loss = 2900.78088789\n",
      "Iteration 3438, loss = 2900.51142401\n",
      "Iteration 3439, loss = 2900.24207469\n",
      "Iteration 3440, loss = 2899.97283990\n",
      "Iteration 3441, loss = 2899.70371961\n",
      "Iteration 3442, loss = 2899.43471378\n",
      "Iteration 3443, loss = 2899.16582239\n",
      "Iteration 3444, loss = 2898.89704539\n",
      "Iteration 3445, loss = 2898.62838276\n",
      "Iteration 3446, loss = 2898.35983446\n",
      "Iteration 3447, loss = 2898.09140045\n",
      "Iteration 3448, loss = 2897.82308071\n",
      "Iteration 3449, loss = 2897.55487520\n",
      "Iteration 3450, loss = 2897.28678389\n",
      "Iteration 3451, loss = 2897.01880674\n",
      "Iteration 3452, loss = 2896.75094372\n",
      "Iteration 3453, loss = 2896.48319479\n",
      "Iteration 3454, loss = 2896.21555993\n",
      "Iteration 3455, loss = 2895.94803910\n",
      "Iteration 3456, loss = 2895.68063226\n",
      "Iteration 3457, loss = 2895.41333939\n",
      "Iteration 3458, loss = 2895.14616045\n",
      "Iteration 3459, loss = 2894.87909540\n",
      "Iteration 3460, loss = 2894.61214422\n",
      "Iteration 3461, loss = 2894.34530687\n",
      "Iteration 3462, loss = 2894.07858331\n",
      "Iteration 3463, loss = 2893.81197352\n",
      "Iteration 3464, loss = 2893.54547746\n",
      "Iteration 3465, loss = 2893.27909510\n",
      "Iteration 3466, loss = 2893.01282640\n",
      "Iteration 3467, loss = 2892.74667133\n",
      "Iteration 3468, loss = 2892.48062986\n",
      "Iteration 3469, loss = 2892.21470195\n",
      "Iteration 3470, loss = 2891.94888758\n",
      "Iteration 3471, loss = 2891.68318671\n",
      "Iteration 3472, loss = 2891.41759930\n",
      "Iteration 3473, loss = 2891.15212532\n",
      "Iteration 3474, loss = 2890.88676474\n",
      "Iteration 3475, loss = 2890.62151753\n",
      "Iteration 3476, loss = 2890.35638365\n",
      "Iteration 3477, loss = 2890.09136308\n",
      "Iteration 3478, loss = 2889.82645577\n",
      "Iteration 3479, loss = 2889.56166170\n",
      "Iteration 3480, loss = 2889.29698082\n",
      "Iteration 3481, loss = 2889.03241312\n",
      "Iteration 3482, loss = 2888.76795855\n",
      "Iteration 3483, loss = 2888.50361709\n",
      "Iteration 3484, loss = 2888.23938869\n",
      "Iteration 3485, loss = 2887.97527334\n",
      "Iteration 3486, loss = 2887.71127099\n",
      "Iteration 3487, loss = 2887.44738161\n",
      "Iteration 3488, loss = 2887.18360517\n",
      "Iteration 3489, loss = 2886.91994163\n",
      "Iteration 3490, loss = 2886.65639097\n",
      "Iteration 3491, loss = 2886.39295315\n",
      "Iteration 3492, loss = 2886.12962814\n",
      "Iteration 3493, loss = 2885.86641590\n",
      "Iteration 3494, loss = 2885.60331641\n",
      "Iteration 3495, loss = 2885.34032962\n",
      "Iteration 3496, loss = 2885.07745552\n",
      "Iteration 3497, loss = 2884.81469406\n",
      "Iteration 3498, loss = 2884.55204521\n",
      "Iteration 3499, loss = 2884.28950894\n",
      "Iteration 3500, loss = 2884.02708521\n",
      "Iteration 3501, loss = 2883.76477401\n",
      "Iteration 3502, loss = 2883.50257528\n",
      "Iteration 3503, loss = 2883.24048900\n",
      "Iteration 3504, loss = 2882.97851514\n",
      "Iteration 3505, loss = 2882.71665366\n",
      "Iteration 3506, loss = 2882.45490454\n",
      "Iteration 3507, loss = 2882.19326773\n",
      "Iteration 3508, loss = 2881.93174322\n",
      "Iteration 3509, loss = 2881.67033095\n",
      "Iteration 3510, loss = 2881.40903091\n",
      "Iteration 3511, loss = 2881.14784306\n",
      "Iteration 3512, loss = 2880.88676736\n",
      "Iteration 3513, loss = 2880.62580379\n",
      "Iteration 3514, loss = 2880.36495231\n",
      "Iteration 3515, loss = 2880.10421290\n",
      "Iteration 3516, loss = 2879.84358551\n",
      "Iteration 3517, loss = 2879.58307011\n",
      "Iteration 3518, loss = 2879.32266668\n",
      "Iteration 3519, loss = 2879.06237518\n",
      "Iteration 3520, loss = 2878.80219558\n",
      "Iteration 3521, loss = 2878.54212784\n",
      "Iteration 3522, loss = 2878.28217194\n",
      "Iteration 3523, loss = 2878.02232784\n",
      "Iteration 3524, loss = 2877.76259551\n",
      "Iteration 3525, loss = 2877.50297492\n",
      "Iteration 3526, loss = 2877.24346603\n",
      "Iteration 3527, loss = 2876.98406882\n",
      "Iteration 3528, loss = 2876.72478325\n",
      "Iteration 3529, loss = 2876.46560928\n",
      "Iteration 3530, loss = 2876.20654690\n",
      "Iteration 3531, loss = 2875.94759606\n",
      "Iteration 3532, loss = 2875.68875673\n",
      "Iteration 3533, loss = 2875.43002888\n",
      "Iteration 3534, loss = 2875.17141248\n",
      "Iteration 3535, loss = 2874.91290750\n",
      "Iteration 3536, loss = 2874.65451390\n",
      "Iteration 3537, loss = 2874.39623166\n",
      "Iteration 3538, loss = 2874.13806073\n",
      "Iteration 3539, loss = 2873.88000109\n",
      "Iteration 3540, loss = 2873.62205272\n",
      "Iteration 3541, loss = 2873.36421556\n",
      "Iteration 3542, loss = 2873.10648960\n",
      "Iteration 3543, loss = 2872.84887480\n",
      "Iteration 3544, loss = 2872.59137113\n",
      "Iteration 3545, loss = 2872.33397855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3546, loss = 2872.07669705\n",
      "Iteration 3547, loss = 2871.81952657\n",
      "Iteration 3548, loss = 2871.56246710\n",
      "Iteration 3549, loss = 2871.30551860\n",
      "Iteration 3550, loss = 2871.04868103\n",
      "Iteration 3551, loss = 2870.79195437\n",
      "Iteration 3552, loss = 2870.53533859\n",
      "Iteration 3553, loss = 2870.27883365\n",
      "Iteration 3554, loss = 2870.02243952\n",
      "Iteration 3555, loss = 2869.76615617\n",
      "Iteration 3556, loss = 2869.50998357\n",
      "Iteration 3557, loss = 2869.25392168\n",
      "Iteration 3558, loss = 2868.99797048\n",
      "Iteration 3559, loss = 2868.74212993\n",
      "Iteration 3560, loss = 2868.48640000\n",
      "Iteration 3561, loss = 2868.23078066\n",
      "Iteration 3562, loss = 2867.97527188\n",
      "Iteration 3563, loss = 2867.71987363\n",
      "Iteration 3564, loss = 2867.46458587\n",
      "Iteration 3565, loss = 2867.20940857\n",
      "Iteration 3566, loss = 2866.95434171\n",
      "Iteration 3567, loss = 2866.69938525\n",
      "Iteration 3568, loss = 2866.44453915\n",
      "Iteration 3569, loss = 2866.18980339\n",
      "Iteration 3570, loss = 2865.93517794\n",
      "Iteration 3571, loss = 2865.68066276\n",
      "Iteration 3572, loss = 2865.42625783\n",
      "Iteration 3573, loss = 2865.17196311\n",
      "Iteration 3574, loss = 2864.91777856\n",
      "Iteration 3575, loss = 2864.66370417\n",
      "Iteration 3576, loss = 2864.40973989\n",
      "Iteration 3577, loss = 2864.15588570\n",
      "Iteration 3578, loss = 2863.90214156\n",
      "Iteration 3579, loss = 2863.64850744\n",
      "Iteration 3580, loss = 2863.39498332\n",
      "Iteration 3581, loss = 2863.14156916\n",
      "Iteration 3582, loss = 2862.88826492\n",
      "Iteration 3583, loss = 2862.63507059\n",
      "Iteration 3584, loss = 2862.38198612\n",
      "Iteration 3585, loss = 2862.12901149\n",
      "Iteration 3586, loss = 2861.87614666\n",
      "Iteration 3587, loss = 2861.62339160\n",
      "Iteration 3588, loss = 2861.37074629\n",
      "Iteration 3589, loss = 2861.11821068\n",
      "Iteration 3590, loss = 2860.86578476\n",
      "Iteration 3591, loss = 2860.61346848\n",
      "Iteration 3592, loss = 2860.36126182\n",
      "Iteration 3593, loss = 2860.10916475\n",
      "Iteration 3594, loss = 2859.85717723\n",
      "Iteration 3595, loss = 2859.60529923\n",
      "Iteration 3596, loss = 2859.35353073\n",
      "Iteration 3597, loss = 2859.10187169\n",
      "Iteration 3598, loss = 2858.85032208\n",
      "Iteration 3599, loss = 2858.59888186\n",
      "Iteration 3600, loss = 2858.34755102\n",
      "Iteration 3601, loss = 2858.09632952\n",
      "Iteration 3602, loss = 2857.84521732\n",
      "Iteration 3603, loss = 2857.59421439\n",
      "Iteration 3604, loss = 2857.34332071\n",
      "Iteration 3605, loss = 2857.09253625\n",
      "Iteration 3606, loss = 2856.84186096\n",
      "Iteration 3607, loss = 2856.59129483\n",
      "Iteration 3608, loss = 2856.34083782\n",
      "Iteration 3609, loss = 2856.09048990\n",
      "Iteration 3610, loss = 2855.84025104\n",
      "Iteration 3611, loss = 2855.59012120\n",
      "Iteration 3612, loss = 2855.34010036\n",
      "Iteration 3613, loss = 2855.09018849\n",
      "Iteration 3614, loss = 2854.84038556\n",
      "Iteration 3615, loss = 2854.59069153\n",
      "Iteration 3616, loss = 2854.34110637\n",
      "Iteration 3617, loss = 2854.09163006\n",
      "Iteration 3618, loss = 2853.84226255\n",
      "Iteration 3619, loss = 2853.59300383\n",
      "Iteration 3620, loss = 2853.34385387\n",
      "Iteration 3621, loss = 2853.09481262\n",
      "Iteration 3622, loss = 2852.84588006\n",
      "Iteration 3623, loss = 2852.59705616\n",
      "Iteration 3624, loss = 2852.34834089\n",
      "Iteration 3625, loss = 2852.09973421\n",
      "Iteration 3626, loss = 2851.85123610\n",
      "Iteration 3627, loss = 2851.60284653\n",
      "Iteration 3628, loss = 2851.35456546\n",
      "Iteration 3629, loss = 2851.10639287\n",
      "Iteration 3630, loss = 2850.85832873\n",
      "Iteration 3631, loss = 2850.61037299\n",
      "Iteration 3632, loss = 2850.36252564\n",
      "Iteration 3633, loss = 2850.11478665\n",
      "Iteration 3634, loss = 2849.86715597\n",
      "Iteration 3635, loss = 2849.61963359\n",
      "Iteration 3636, loss = 2849.37221946\n",
      "Iteration 3637, loss = 2849.12491357\n",
      "Iteration 3638, loss = 2848.87771588\n",
      "Iteration 3639, loss = 2848.63062636\n",
      "Iteration 3640, loss = 2848.38364497\n",
      "Iteration 3641, loss = 2848.13677170\n",
      "Iteration 3642, loss = 2847.89000650\n",
      "Iteration 3643, loss = 2847.64334936\n",
      "Iteration 3644, loss = 2847.39680023\n",
      "Iteration 3645, loss = 2847.15035908\n",
      "Iteration 3646, loss = 2846.90402590\n",
      "Iteration 3647, loss = 2846.65780064\n",
      "Iteration 3648, loss = 2846.41168327\n",
      "Iteration 3649, loss = 2846.16567377\n",
      "Iteration 3650, loss = 2845.91977211\n",
      "Iteration 3651, loss = 2845.67397825\n",
      "Iteration 3652, loss = 2845.42829217\n",
      "Iteration 3653, loss = 2845.18271383\n",
      "Iteration 3654, loss = 2844.93724321\n",
      "Iteration 3655, loss = 2844.69188027\n",
      "Iteration 3656, loss = 2844.44662498\n",
      "Iteration 3657, loss = 2844.20147732\n",
      "Iteration 3658, loss = 2843.95643725\n",
      "Iteration 3659, loss = 2843.71150475\n",
      "Iteration 3660, loss = 2843.46667978\n",
      "Iteration 3661, loss = 2843.22196231\n",
      "Iteration 3662, loss = 2842.97735231\n",
      "Iteration 3663, loss = 2842.73284976\n",
      "Iteration 3664, loss = 2842.48845462\n",
      "Iteration 3665, loss = 2842.24416686\n",
      "Iteration 3666, loss = 2841.99998646\n",
      "Iteration 3667, loss = 2841.75591337\n",
      "Iteration 3668, loss = 2841.51194758\n",
      "Iteration 3669, loss = 2841.26808905\n",
      "Iteration 3670, loss = 2841.02433776\n",
      "Iteration 3671, loss = 2840.78069366\n",
      "Iteration 3672, loss = 2840.53715674\n",
      "Iteration 3673, loss = 2840.29372696\n",
      "Iteration 3674, loss = 2840.05040430\n",
      "Iteration 3675, loss = 2839.80718871\n",
      "Iteration 3676, loss = 2839.56408018\n",
      "Iteration 3677, loss = 2839.32107867\n",
      "Iteration 3678, loss = 2839.07818415\n",
      "Iteration 3679, loss = 2838.83539659\n",
      "Iteration 3680, loss = 2838.59271597\n",
      "Iteration 3681, loss = 2838.35014225\n",
      "Iteration 3682, loss = 2838.10767540\n",
      "Iteration 3683, loss = 2837.86531540\n",
      "Iteration 3684, loss = 2837.62306221\n",
      "Iteration 3685, loss = 2837.38091580\n",
      "Iteration 3686, loss = 2837.13887615\n",
      "Iteration 3687, loss = 2836.89694322\n",
      "Iteration 3688, loss = 2836.65511698\n",
      "Iteration 3689, loss = 2836.41339741\n",
      "Iteration 3690, loss = 2836.17178447\n",
      "Iteration 3691, loss = 2835.93027814\n",
      "Iteration 3692, loss = 2835.68887838\n",
      "Iteration 3693, loss = 2835.44758517\n",
      "Iteration 3694, loss = 2835.20639847\n",
      "Iteration 3695, loss = 2834.96531826\n",
      "Iteration 3696, loss = 2834.72434451\n",
      "Iteration 3697, loss = 2834.48347718\n",
      "Iteration 3698, loss = 2834.24271625\n",
      "Iteration 3699, loss = 2834.00206168\n",
      "Iteration 3700, loss = 2833.76151346\n",
      "Iteration 3701, loss = 2833.52107154\n",
      "Iteration 3702, loss = 2833.28073590\n",
      "Iteration 3703, loss = 2833.04050650\n",
      "Iteration 3704, loss = 2832.80038333\n",
      "Iteration 3705, loss = 2832.56036635\n",
      "Iteration 3706, loss = 2832.32045553\n",
      "Iteration 3707, loss = 2832.08065083\n",
      "Iteration 3708, loss = 2831.84095224\n",
      "Iteration 3709, loss = 2831.60135972\n",
      "Iteration 3710, loss = 2831.36187324\n",
      "Iteration 3711, loss = 2831.12249278\n",
      "Iteration 3712, loss = 2830.88321830\n",
      "Iteration 3713, loss = 2830.64404977\n",
      "Iteration 3714, loss = 2830.40498716\n",
      "Iteration 3715, loss = 2830.16603046\n",
      "Iteration 3716, loss = 2829.92717961\n",
      "Iteration 3717, loss = 2829.68843460\n",
      "Iteration 3718, loss = 2829.44979540\n",
      "Iteration 3719, loss = 2829.21126198\n",
      "Iteration 3720, loss = 2828.97283430\n",
      "Iteration 3721, loss = 2828.73451234\n",
      "Iteration 3722, loss = 2828.49629607\n",
      "Iteration 3723, loss = 2828.25818546\n",
      "Iteration 3724, loss = 2828.02018048\n",
      "Iteration 3725, loss = 2827.78228110\n",
      "Iteration 3726, loss = 2827.54448730\n",
      "Iteration 3727, loss = 2827.30679903\n",
      "Iteration 3728, loss = 2827.06921628\n",
      "Iteration 3729, loss = 2826.83173902\n",
      "Iteration 3730, loss = 2826.59436721\n",
      "Iteration 3731, loss = 2826.35710082\n",
      "Iteration 3732, loss = 2826.11993983\n",
      "Iteration 3733, loss = 2825.88288421\n",
      "Iteration 3734, loss = 2825.64593392\n",
      "Iteration 3735, loss = 2825.40908895\n",
      "Iteration 3736, loss = 2825.17234925\n",
      "Iteration 3737, loss = 2824.93571481\n",
      "Iteration 3738, loss = 2824.69918558\n",
      "Iteration 3739, loss = 2824.46276155\n",
      "Iteration 3740, loss = 2824.22644269\n",
      "Iteration 3741, loss = 2823.99022895\n",
      "Iteration 3742, loss = 2823.75412032\n",
      "Iteration 3743, loss = 2823.51811677\n",
      "Iteration 3744, loss = 2823.28221826\n",
      "Iteration 3745, loss = 2823.04642477\n",
      "Iteration 3746, loss = 2822.81073627\n",
      "Iteration 3747, loss = 2822.57515273\n",
      "Iteration 3748, loss = 2822.33967412\n",
      "Iteration 3749, loss = 2822.10430042\n",
      "Iteration 3750, loss = 2821.86903158\n",
      "Iteration 3751, loss = 2821.63386759\n",
      "Iteration 3752, loss = 2821.39880841\n",
      "Iteration 3753, loss = 2821.16385402\n",
      "Iteration 3754, loss = 2820.92900439\n",
      "Iteration 3755, loss = 2820.69425948\n",
      "Iteration 3756, loss = 2820.45961928\n",
      "Iteration 3757, loss = 2820.22508374\n",
      "Iteration 3758, loss = 2819.99065285\n",
      "Iteration 3759, loss = 2819.75632656\n",
      "Iteration 3760, loss = 2819.52210486\n",
      "Iteration 3761, loss = 2819.28798772\n",
      "Iteration 3762, loss = 2819.05397510\n",
      "Iteration 3763, loss = 2818.82006698\n",
      "Iteration 3764, loss = 2818.58626333\n",
      "Iteration 3765, loss = 2818.35256412\n",
      "Iteration 3766, loss = 2818.11896931\n",
      "Iteration 3767, loss = 2817.88547889\n",
      "Iteration 3768, loss = 2817.65209282\n",
      "Iteration 3769, loss = 2817.41881108\n",
      "Iteration 3770, loss = 2817.18563363\n",
      "Iteration 3771, loss = 2816.95256045\n",
      "Iteration 3772, loss = 2816.71959151\n",
      "Iteration 3773, loss = 2816.48672678\n",
      "Iteration 3774, loss = 2816.25396623\n",
      "Iteration 3775, loss = 2816.02130983\n",
      "Iteration 3776, loss = 2815.78875755\n",
      "Iteration 3777, loss = 2815.55630937\n",
      "Iteration 3778, loss = 2815.32396526\n",
      "Iteration 3779, loss = 2815.09172518\n",
      "Iteration 3780, loss = 2814.85958911\n",
      "Iteration 3781, loss = 2814.62755702\n",
      "Iteration 3782, loss = 2814.39562889\n",
      "Iteration 3783, loss = 2814.16380467\n",
      "Iteration 3784, loss = 2813.93208435\n",
      "Iteration 3785, loss = 2813.70046790\n",
      "Iteration 3786, loss = 2813.46895529\n",
      "Iteration 3787, loss = 2813.23754648\n",
      "Iteration 3788, loss = 2813.00624146\n",
      "Iteration 3789, loss = 2812.77504018\n",
      "Iteration 3790, loss = 2812.54394263\n",
      "Iteration 3791, loss = 2812.31294878\n",
      "Iteration 3792, loss = 2812.08205859\n",
      "Iteration 3793, loss = 2811.85127204\n",
      "Iteration 3794, loss = 2811.62058910\n",
      "Iteration 3795, loss = 2811.39000974\n",
      "Iteration 3796, loss = 2811.15953394\n",
      "Iteration 3797, loss = 2810.92916165\n",
      "Iteration 3798, loss = 2810.69889287\n",
      "Iteration 3799, loss = 2810.46872755\n",
      "Iteration 3800, loss = 2810.23866567\n",
      "Iteration 3801, loss = 2810.00870720\n",
      "Iteration 3802, loss = 2809.77885212\n",
      "Iteration 3803, loss = 2809.54910038\n",
      "Iteration 3804, loss = 2809.31945198\n",
      "Iteration 3805, loss = 2809.08990687\n",
      "Iteration 3806, loss = 2808.86046503\n",
      "Iteration 3807, loss = 2808.63112643\n",
      "Iteration 3808, loss = 2808.40189105\n",
      "Iteration 3809, loss = 2808.17275885\n",
      "Iteration 3810, loss = 2807.94372980\n",
      "Iteration 3811, loss = 2807.71480388\n",
      "Iteration 3812, loss = 2807.48598106\n",
      "Iteration 3813, loss = 2807.25726132\n",
      "Iteration 3814, loss = 2807.02864462\n",
      "Iteration 3815, loss = 2806.80013093\n",
      "Iteration 3816, loss = 2806.57172023\n",
      "Iteration 3817, loss = 2806.34341248\n",
      "Iteration 3818, loss = 2806.11520767\n",
      "Iteration 3819, loss = 2805.88710576\n",
      "Iteration 3820, loss = 2805.65910672\n",
      "Iteration 3821, loss = 2805.43121053\n",
      "Iteration 3822, loss = 2805.20341716\n",
      "Iteration 3823, loss = 2804.97572658\n",
      "Iteration 3824, loss = 2804.74813876\n",
      "Iteration 3825, loss = 2804.52065367\n",
      "Iteration 3826, loss = 2804.29327129\n",
      "Iteration 3827, loss = 2804.06599159\n",
      "Iteration 3828, loss = 2803.83881453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3829, loss = 2803.61174010\n",
      "Iteration 3830, loss = 2803.38476826\n",
      "Iteration 3831, loss = 2803.15789898\n",
      "Iteration 3832, loss = 2802.93113225\n",
      "Iteration 3833, loss = 2802.70446802\n",
      "Iteration 3834, loss = 2802.47790627\n",
      "Iteration 3835, loss = 2802.25144698\n",
      "Iteration 3836, loss = 2802.02509011\n",
      "Iteration 3837, loss = 2801.79883564\n",
      "Iteration 3838, loss = 2801.57268354\n",
      "Iteration 3839, loss = 2801.34663378\n",
      "Iteration 3840, loss = 2801.12068634\n",
      "Iteration 3841, loss = 2800.89484118\n",
      "Iteration 3842, loss = 2800.66909827\n",
      "Iteration 3843, loss = 2800.44345760\n",
      "Iteration 3844, loss = 2800.21791913\n",
      "Iteration 3845, loss = 2799.99248284\n",
      "Iteration 3846, loss = 2799.76714869\n",
      "Iteration 3847, loss = 2799.54191666\n",
      "Iteration 3848, loss = 2799.31678672\n",
      "Iteration 3849, loss = 2799.09175884\n",
      "Iteration 3850, loss = 2798.86683300\n",
      "Iteration 3851, loss = 2798.64200917\n",
      "Iteration 3852, loss = 2798.41728731\n",
      "Iteration 3853, loss = 2798.19266741\n",
      "Iteration 3854, loss = 2797.96814943\n",
      "Iteration 3855, loss = 2797.74373335\n",
      "Iteration 3856, loss = 2797.51941914\n",
      "Iteration 3857, loss = 2797.29520676\n",
      "Iteration 3858, loss = 2797.07109620\n",
      "Iteration 3859, loss = 2796.84708743\n",
      "Iteration 3860, loss = 2796.62318041\n",
      "Iteration 3861, loss = 2796.39937513\n",
      "Iteration 3862, loss = 2796.17567154\n",
      "Iteration 3863, loss = 2795.95206963\n",
      "Iteration 3864, loss = 2795.72856937\n",
      "Iteration 3865, loss = 2795.50517073\n",
      "Iteration 3866, loss = 2795.28187368\n",
      "Iteration 3867, loss = 2795.05867819\n",
      "Iteration 3868, loss = 2794.83558424\n",
      "Iteration 3869, loss = 2794.61259180\n",
      "Iteration 3870, loss = 2794.38970084\n",
      "Iteration 3871, loss = 2794.16691133\n",
      "Iteration 3872, loss = 2793.94422325\n",
      "Iteration 3873, loss = 2793.72163657\n",
      "Iteration 3874, loss = 2793.49915126\n",
      "Iteration 3875, loss = 2793.27676729\n",
      "Iteration 3876, loss = 2793.05448464\n",
      "Iteration 3877, loss = 2792.83230328\n",
      "Iteration 3878, loss = 2792.61022318\n",
      "Iteration 3879, loss = 2792.38824431\n",
      "Iteration 3880, loss = 2792.16636665\n",
      "Iteration 3881, loss = 2791.94459017\n",
      "Iteration 3882, loss = 2791.72291484\n",
      "Iteration 3883, loss = 2791.50134064\n",
      "Iteration 3884, loss = 2791.27986752\n",
      "Iteration 3885, loss = 2791.05849548\n",
      "Iteration 3886, loss = 2790.83722448\n",
      "Iteration 3887, loss = 2790.61605450\n",
      "Iteration 3888, loss = 2790.39498550\n",
      "Iteration 3889, loss = 2790.17401746\n",
      "Iteration 3890, loss = 2789.95315035\n",
      "Iteration 3891, loss = 2789.73238415\n",
      "Iteration 3892, loss = 2789.51171882\n",
      "Iteration 3893, loss = 2789.29115435\n",
      "Iteration 3894, loss = 2789.07069069\n",
      "Iteration 3895, loss = 2788.85032784\n",
      "Iteration 3896, loss = 2788.63006575\n",
      "Iteration 3897, loss = 2788.40990440\n",
      "Iteration 3898, loss = 2788.18984376\n",
      "Iteration 3899, loss = 2787.96988381\n",
      "Iteration 3900, loss = 2787.75002452\n",
      "Iteration 3901, loss = 2787.53026586\n",
      "Iteration 3902, loss = 2787.31060781\n",
      "Iteration 3903, loss = 2787.09105033\n",
      "Iteration 3904, loss = 2786.87159340\n",
      "Iteration 3905, loss = 2786.65223700\n",
      "Iteration 3906, loss = 2786.43298109\n",
      "Iteration 3907, loss = 2786.21382565\n",
      "Iteration 3908, loss = 2785.99477065\n",
      "Iteration 3909, loss = 2785.77581606\n",
      "Iteration 3910, loss = 2785.55696186\n",
      "Iteration 3911, loss = 2785.33820802\n",
      "Iteration 3912, loss = 2785.11955452\n",
      "Iteration 3913, loss = 2784.90100132\n",
      "Iteration 3914, loss = 2784.68254839\n",
      "Iteration 3915, loss = 2784.46419572\n",
      "Iteration 3916, loss = 2784.24594327\n",
      "Iteration 3917, loss = 2784.02779102\n",
      "Iteration 3918, loss = 2783.80973894\n",
      "Iteration 3919, loss = 2783.59178700\n",
      "Iteration 3920, loss = 2783.37393518\n",
      "Iteration 3921, loss = 2783.15618345\n",
      "Iteration 3922, loss = 2782.93853178\n",
      "Iteration 3923, loss = 2782.72098014\n",
      "Iteration 3924, loss = 2782.50352851\n",
      "Iteration 3925, loss = 2782.28617686\n",
      "Iteration 3926, loss = 2782.06892517\n",
      "Iteration 3927, loss = 2781.85177340\n",
      "Iteration 3928, loss = 2781.63472153\n",
      "Iteration 3929, loss = 2781.41776953\n",
      "Iteration 3930, loss = 2781.20091738\n",
      "Iteration 3931, loss = 2780.98416505\n",
      "Iteration 3932, loss = 2780.76751251\n",
      "Iteration 3933, loss = 2780.55095974\n",
      "Iteration 3934, loss = 2780.33450670\n",
      "Iteration 3935, loss = 2780.11815338\n",
      "Iteration 3936, loss = 2779.90189974\n",
      "Iteration 3937, loss = 2779.68574575\n",
      "Iteration 3938, loss = 2779.46969140\n",
      "Iteration 3939, loss = 2779.25373665\n",
      "Iteration 3940, loss = 2779.03788148\n",
      "Iteration 3941, loss = 2778.82212585\n",
      "Iteration 3942, loss = 2778.60646975\n",
      "Iteration 3943, loss = 2778.39091315\n",
      "Iteration 3944, loss = 2778.17545602\n",
      "Iteration 3945, loss = 2777.96009833\n",
      "Iteration 3946, loss = 2777.74484005\n",
      "Iteration 3947, loss = 2777.52968116\n",
      "Iteration 3948, loss = 2777.31462164\n",
      "Iteration 3949, loss = 2777.09966145\n",
      "Iteration 3950, loss = 2776.88480057\n",
      "Iteration 3951, loss = 2776.67003897\n",
      "Iteration 3952, loss = 2776.45537663\n",
      "Iteration 3953, loss = 2776.24081352\n",
      "Iteration 3954, loss = 2776.02634960\n",
      "Iteration 3955, loss = 2775.81198487\n",
      "Iteration 3956, loss = 2775.59771928\n",
      "Iteration 3957, loss = 2775.38355281\n",
      "Iteration 3958, loss = 2775.16948544\n",
      "Iteration 3959, loss = 2774.95551714\n",
      "Iteration 3960, loss = 2774.74164787\n",
      "Iteration 3961, loss = 2774.52787763\n",
      "Iteration 3962, loss = 2774.31420637\n",
      "Iteration 3963, loss = 2774.10063407\n",
      "Iteration 3964, loss = 2773.88716071\n",
      "Iteration 3965, loss = 2773.67378626\n",
      "Iteration 3966, loss = 2773.46051069\n",
      "Iteration 3967, loss = 2773.24733397\n",
      "Iteration 3968, loss = 2773.03425609\n",
      "Iteration 3969, loss = 2772.82127700\n",
      "Iteration 3970, loss = 2772.60839669\n",
      "Iteration 3971, loss = 2772.39561513\n",
      "Iteration 3972, loss = 2772.18293230\n",
      "Iteration 3973, loss = 2771.97034815\n",
      "Iteration 3974, loss = 2771.75786268\n",
      "Iteration 3975, loss = 2771.54547585\n",
      "Iteration 3976, loss = 2771.33318764\n",
      "Iteration 3977, loss = 2771.12099802\n",
      "Iteration 3978, loss = 2770.90890696\n",
      "Iteration 3979, loss = 2770.69691444\n",
      "Iteration 3980, loss = 2770.48502043\n",
      "Iteration 3981, loss = 2770.27322490\n",
      "Iteration 3982, loss = 2770.06152783\n",
      "Iteration 3983, loss = 2769.84992919\n",
      "Iteration 3984, loss = 2769.63842896\n",
      "Iteration 3985, loss = 2769.42702711\n",
      "Iteration 3986, loss = 2769.21572360\n",
      "Iteration 3987, loss = 2769.00451843\n",
      "Iteration 3988, loss = 2768.79341155\n",
      "Iteration 3989, loss = 2768.58240294\n",
      "Iteration 3990, loss = 2768.37149258\n",
      "Iteration 3991, loss = 2768.16068044\n",
      "Iteration 3992, loss = 2767.94996650\n",
      "Iteration 3993, loss = 2767.73935072\n",
      "Iteration 3994, loss = 2767.52883308\n",
      "Iteration 3995, loss = 2767.31841356\n",
      "Iteration 3996, loss = 2767.10809212\n",
      "Iteration 3997, loss = 2766.89786875\n",
      "Iteration 3998, loss = 2766.68774342\n",
      "Iteration 3999, loss = 2766.47771609\n",
      "Iteration 4000, loss = 2766.26778674\n",
      "Iteration 4001, loss = 2766.05795536\n",
      "Iteration 4002, loss = 2765.84822190\n",
      "Iteration 4003, loss = 2765.63858635\n",
      "Iteration 4004, loss = 2765.42904868\n",
      "Iteration 4005, loss = 2765.21960885\n",
      "Iteration 4006, loss = 2765.01026686\n",
      "Iteration 4007, loss = 2764.80102266\n",
      "Iteration 4008, loss = 2764.59187624\n",
      "Iteration 4009, loss = 2764.38282756\n",
      "Iteration 4010, loss = 2764.17387660\n",
      "Iteration 4011, loss = 2763.96502334\n",
      "Iteration 4012, loss = 2763.75626775\n",
      "Iteration 4013, loss = 2763.54760980\n",
      "Iteration 4014, loss = 2763.33904946\n",
      "Iteration 4015, loss = 2763.13058672\n",
      "Iteration 4016, loss = 2762.92222154\n",
      "Iteration 4017, loss = 2762.71395390\n",
      "Iteration 4018, loss = 2762.50578376\n",
      "Iteration 4019, loss = 2762.29771112\n",
      "Iteration 4020, loss = 2762.08973593\n",
      "Iteration 4021, loss = 2761.88185818\n",
      "Iteration 4022, loss = 2761.67407783\n",
      "Iteration 4023, loss = 2761.46639487\n",
      "Iteration 4024, loss = 2761.25880926\n",
      "Iteration 4025, loss = 2761.05132098\n",
      "Iteration 4026, loss = 2760.84393000\n",
      "Iteration 4027, loss = 2760.63663630\n",
      "Iteration 4028, loss = 2760.42943985\n",
      "Iteration 4029, loss = 2760.22234063\n",
      "Iteration 4030, loss = 2760.01533860\n",
      "Iteration 4031, loss = 2759.80843375\n",
      "Iteration 4032, loss = 2759.60162605\n",
      "Iteration 4033, loss = 2759.39491546\n",
      "Iteration 4034, loss = 2759.18830197\n",
      "Iteration 4035, loss = 2758.98178555\n",
      "Iteration 4036, loss = 2758.77536617\n",
      "Iteration 4037, loss = 2758.56904381\n",
      "Iteration 4038, loss = 2758.36281844\n",
      "Iteration 4039, loss = 2758.15669004\n",
      "Iteration 4040, loss = 2757.95065857\n",
      "Iteration 4041, loss = 2757.74472402\n",
      "Iteration 4042, loss = 2757.53888636\n",
      "Iteration 4043, loss = 2757.33314555\n",
      "Iteration 4044, loss = 2757.12750159\n",
      "Iteration 4045, loss = 2756.92195443\n",
      "Iteration 4046, loss = 2756.71650406\n",
      "Iteration 4047, loss = 2756.51115044\n",
      "Iteration 4048, loss = 2756.30589356\n",
      "Iteration 4049, loss = 2756.10073338\n",
      "Iteration 4050, loss = 2755.89566988\n",
      "Iteration 4051, loss = 2755.69070304\n",
      "Iteration 4052, loss = 2755.48583283\n",
      "Iteration 4053, loss = 2755.28105922\n",
      "Iteration 4054, loss = 2755.07638219\n",
      "Iteration 4055, loss = 2754.87180171\n",
      "Iteration 4056, loss = 2754.66731775\n",
      "Iteration 4057, loss = 2754.46293030\n",
      "Iteration 4058, loss = 2754.25863932\n",
      "Iteration 4059, loss = 2754.05444478\n",
      "Iteration 4060, loss = 2753.85034667\n",
      "Iteration 4061, loss = 2753.64634496\n",
      "Iteration 4062, loss = 2753.44243962\n",
      "Iteration 4063, loss = 2753.23863062\n",
      "Iteration 4064, loss = 2753.03491794\n",
      "Iteration 4065, loss = 2752.83130156\n",
      "Iteration 4066, loss = 2752.62778144\n",
      "Iteration 4067, loss = 2752.42435757\n",
      "Iteration 4068, loss = 2752.22102992\n",
      "Iteration 4069, loss = 2752.01779845\n",
      "Iteration 4070, loss = 2751.81466315\n",
      "Iteration 4071, loss = 2751.61162400\n",
      "Iteration 4072, loss = 2751.40868095\n",
      "Iteration 4073, loss = 2751.20583399\n",
      "Iteration 4074, loss = 2751.00308310\n",
      "Iteration 4075, loss = 2750.80042825\n",
      "Iteration 4076, loss = 2750.59786940\n",
      "Iteration 4077, loss = 2750.39540654\n",
      "Iteration 4078, loss = 2750.19303965\n",
      "Iteration 4079, loss = 2749.99076869\n",
      "Iteration 4080, loss = 2749.78859363\n",
      "Iteration 4081, loss = 2749.58651446\n",
      "Iteration 4082, loss = 2749.38453115\n",
      "Iteration 4083, loss = 2749.18264367\n",
      "Iteration 4084, loss = 2748.98085200\n",
      "Iteration 4085, loss = 2748.77915611\n",
      "Iteration 4086, loss = 2748.57755598\n",
      "Iteration 4087, loss = 2748.37605158\n",
      "Iteration 4088, loss = 2748.17464288\n",
      "Iteration 4089, loss = 2747.97332986\n",
      "Iteration 4090, loss = 2747.77211249\n",
      "Iteration 4091, loss = 2747.57099076\n",
      "Iteration 4092, loss = 2747.36996462\n",
      "Iteration 4093, loss = 2747.16903407\n",
      "Iteration 4094, loss = 2746.96819906\n",
      "Iteration 4095, loss = 2746.76745959\n",
      "Iteration 4096, loss = 2746.56681561\n",
      "Iteration 4097, loss = 2746.36626711\n",
      "Iteration 4098, loss = 2746.16581406\n",
      "Iteration 4099, loss = 2745.96545643\n",
      "Iteration 4100, loss = 2745.76519421\n",
      "Iteration 4101, loss = 2745.56502736\n",
      "Iteration 4102, loss = 2745.36495585\n",
      "Iteration 4103, loss = 2745.16497967\n",
      "Iteration 4104, loss = 2744.96509879\n",
      "Iteration 4105, loss = 2744.76531318\n",
      "Iteration 4106, loss = 2744.56562281\n",
      "Iteration 4107, loss = 2744.36602767\n",
      "Iteration 4108, loss = 2744.16652773\n",
      "Iteration 4109, loss = 2743.96712295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4110, loss = 2743.76781332\n",
      "Iteration 4111, loss = 2743.56859881\n",
      "Iteration 4112, loss = 2743.36947940\n",
      "Iteration 4113, loss = 2743.17045506\n",
      "Iteration 4114, loss = 2742.97152576\n",
      "Iteration 4115, loss = 2742.77269147\n",
      "Iteration 4116, loss = 2742.57395219\n",
      "Iteration 4117, loss = 2742.37530787\n",
      "Iteration 4118, loss = 2742.17675849\n",
      "Iteration 4119, loss = 2741.97830403\n",
      "Iteration 4120, loss = 2741.77994447\n",
      "Iteration 4121, loss = 2741.58167977\n",
      "Iteration 4122, loss = 2741.38350991\n",
      "Iteration 4123, loss = 2741.18543488\n",
      "Iteration 4124, loss = 2740.98745463\n",
      "Iteration 4125, loss = 2740.78956915\n",
      "Iteration 4126, loss = 2740.59177841\n",
      "Iteration 4127, loss = 2740.39408238\n",
      "Iteration 4128, loss = 2740.19648105\n",
      "Iteration 4129, loss = 2739.99897438\n",
      "Iteration 4130, loss = 2739.80156235\n",
      "Iteration 4131, loss = 2739.60424494\n",
      "Iteration 4132, loss = 2739.40702212\n",
      "Iteration 4133, loss = 2739.20989386\n",
      "Iteration 4134, loss = 2739.01286014\n",
      "Iteration 4135, loss = 2738.81592094\n",
      "Iteration 4136, loss = 2738.61907623\n",
      "Iteration 4137, loss = 2738.42232598\n",
      "Iteration 4138, loss = 2738.22567017\n",
      "Iteration 4139, loss = 2738.02910877\n",
      "Iteration 4140, loss = 2737.83264177\n",
      "Iteration 4141, loss = 2737.63626912\n",
      "Iteration 4142, loss = 2737.43999082\n",
      "Iteration 4143, loss = 2737.24380683\n",
      "Iteration 4144, loss = 2737.04771712\n",
      "Iteration 4145, loss = 2736.85172168\n",
      "Iteration 4146, loss = 2736.65582048\n",
      "Iteration 4147, loss = 2736.46001350\n",
      "Iteration 4148, loss = 2736.26430070\n",
      "Iteration 4149, loss = 2736.06868206\n",
      "Iteration 4150, loss = 2735.87315756\n",
      "Iteration 4151, loss = 2735.67772718\n",
      "Iteration 4152, loss = 2735.48239088\n",
      "Iteration 4153, loss = 2735.28714865\n",
      "Iteration 4154, loss = 2735.09200046\n",
      "Iteration 4155, loss = 2734.89694628\n",
      "Iteration 4156, loss = 2734.70198608\n",
      "Iteration 4157, loss = 2734.50711985\n",
      "Iteration 4158, loss = 2734.31234756\n",
      "Iteration 4159, loss = 2734.11766918\n",
      "Iteration 4160, loss = 2733.92308469\n",
      "Iteration 4161, loss = 2733.72859406\n",
      "Iteration 4162, loss = 2733.53419728\n",
      "Iteration 4163, loss = 2733.33989430\n",
      "Iteration 4164, loss = 2733.14568511\n",
      "Iteration 4165, loss = 2732.95156969\n",
      "Iteration 4166, loss = 2732.75754801\n",
      "Iteration 4167, loss = 2732.56362004\n",
      "Iteration 4168, loss = 2732.36978575\n",
      "Iteration 4169, loss = 2732.17604514\n",
      "Iteration 4170, loss = 2731.98239816\n",
      "Iteration 4171, loss = 2731.78884479\n",
      "Iteration 4172, loss = 2731.59538502\n",
      "Iteration 4173, loss = 2731.40201881\n",
      "Iteration 4174, loss = 2731.20874614\n",
      "Iteration 4175, loss = 2731.01556698\n",
      "Iteration 4176, loss = 2730.82248131\n",
      "Iteration 4177, loss = 2730.62948911\n",
      "Iteration 4178, loss = 2730.43659035\n",
      "Iteration 4179, loss = 2730.24378501\n",
      "Iteration 4180, loss = 2730.05107305\n",
      "Iteration 4181, loss = 2729.85845446\n",
      "Iteration 4182, loss = 2729.66592921\n",
      "Iteration 4183, loss = 2729.47349728\n",
      "Iteration 4184, loss = 2729.28115864\n",
      "Iteration 4185, loss = 2729.08891327\n",
      "Iteration 4186, loss = 2728.89676113\n",
      "Iteration 4187, loss = 2728.70470222\n",
      "Iteration 4188, loss = 2728.51273649\n",
      "Iteration 4189, loss = 2728.32086394\n",
      "Iteration 4190, loss = 2728.12908453\n",
      "Iteration 4191, loss = 2727.93739823\n",
      "Iteration 4192, loss = 2727.74580503\n",
      "Iteration 4193, loss = 2727.55430490\n",
      "Iteration 4194, loss = 2727.36289781\n",
      "Iteration 4195, loss = 2727.17158374\n",
      "Iteration 4196, loss = 2726.98036266\n",
      "Iteration 4197, loss = 2726.78923456\n",
      "Iteration 4198, loss = 2726.59819940\n",
      "Iteration 4199, loss = 2726.40725716\n",
      "Iteration 4200, loss = 2726.21640782\n",
      "Iteration 4201, loss = 2726.02565134\n",
      "Iteration 4202, loss = 2725.83498772\n",
      "Iteration 4203, loss = 2725.64441691\n",
      "Iteration 4204, loss = 2725.45393890\n",
      "Iteration 4205, loss = 2725.26355367\n",
      "Iteration 4206, loss = 2725.07326118\n",
      "Iteration 4207, loss = 2724.88306142\n",
      "Iteration 4208, loss = 2724.69295435\n",
      "Iteration 4209, loss = 2724.50293996\n",
      "Iteration 4210, loss = 2724.31301822\n",
      "Iteration 4211, loss = 2724.12318910\n",
      "Iteration 4212, loss = 2723.93345258\n",
      "Iteration 4213, loss = 2723.74380864\n",
      "Iteration 4214, loss = 2723.55425725\n",
      "Iteration 4215, loss = 2723.36479839\n",
      "Iteration 4216, loss = 2723.17543202\n",
      "Iteration 4217, loss = 2722.98615814\n",
      "Iteration 4218, loss = 2722.79697671\n",
      "Iteration 4219, loss = 2722.60788770\n",
      "Iteration 4220, loss = 2722.41889110\n",
      "Iteration 4221, loss = 2722.22998688\n",
      "Iteration 4222, loss = 2722.04117501\n",
      "Iteration 4223, loss = 2721.85245548\n",
      "Iteration 4224, loss = 2721.66382824\n",
      "Iteration 4225, loss = 2721.47529329\n",
      "Iteration 4226, loss = 2721.28685060\n",
      "Iteration 4227, loss = 2721.09850014\n",
      "Iteration 4228, loss = 2720.91024188\n",
      "Iteration 4229, loss = 2720.72207581\n",
      "Iteration 4230, loss = 2720.53400190\n",
      "Iteration 4231, loss = 2720.34602012\n",
      "Iteration 4232, loss = 2720.15813045\n",
      "Iteration 4233, loss = 2719.97033287\n",
      "Iteration 4234, loss = 2719.78262735\n",
      "Iteration 4235, loss = 2719.59501386\n",
      "Iteration 4236, loss = 2719.40749239\n",
      "Iteration 4237, loss = 2719.22006290\n",
      "Iteration 4238, loss = 2719.03272538\n",
      "Iteration 4239, loss = 2718.84547979\n",
      "Iteration 4240, loss = 2718.65832612\n",
      "Iteration 4241, loss = 2718.47126434\n",
      "Iteration 4242, loss = 2718.28429442\n",
      "Iteration 4243, loss = 2718.09741635\n",
      "Iteration 4244, loss = 2717.91063009\n",
      "Iteration 4245, loss = 2717.72393563\n",
      "Iteration 4246, loss = 2717.53733293\n",
      "Iteration 4247, loss = 2717.35082197\n",
      "Iteration 4248, loss = 2717.16440274\n",
      "Iteration 4249, loss = 2716.97807520\n",
      "Iteration 4250, loss = 2716.79183933\n",
      "Iteration 4251, loss = 2716.60569511\n",
      "Iteration 4252, loss = 2716.41964251\n",
      "Iteration 4253, loss = 2716.23368150\n",
      "Iteration 4254, loss = 2716.04781207\n",
      "Iteration 4255, loss = 2715.86203419\n",
      "Iteration 4256, loss = 2715.67634783\n",
      "Iteration 4257, loss = 2715.49075297\n",
      "Iteration 4258, loss = 2715.30524959\n",
      "Iteration 4259, loss = 2715.11983766\n",
      "Iteration 4260, loss = 2714.93451716\n",
      "Iteration 4261, loss = 2714.74928806\n",
      "Iteration 4262, loss = 2714.56415034\n",
      "Iteration 4263, loss = 2714.37910398\n",
      "Iteration 4264, loss = 2714.19414894\n",
      "Iteration 4265, loss = 2714.00928521\n",
      "Iteration 4266, loss = 2713.82451277\n",
      "Iteration 4267, loss = 2713.63983158\n",
      "Iteration 4268, loss = 2713.45524162\n",
      "Iteration 4269, loss = 2713.27074288\n",
      "Iteration 4270, loss = 2713.08633531\n",
      "Iteration 4271, loss = 2712.90201891\n",
      "Iteration 4272, loss = 2712.71779365\n",
      "Iteration 4273, loss = 2712.53365950\n",
      "Iteration 4274, loss = 2712.34961643\n",
      "Iteration 4275, loss = 2712.16566443\n",
      "Iteration 4276, loss = 2711.98180347\n",
      "Iteration 4277, loss = 2711.79803353\n",
      "Iteration 4278, loss = 2711.61435458\n",
      "Iteration 4279, loss = 2711.43076659\n",
      "Iteration 4280, loss = 2711.24726955\n",
      "Iteration 4281, loss = 2711.06386342\n",
      "Iteration 4282, loss = 2710.88054820\n",
      "Iteration 4283, loss = 2710.69732384\n",
      "Iteration 4284, loss = 2710.51419033\n",
      "Iteration 4285, loss = 2710.33114764\n",
      "Iteration 4286, loss = 2710.14819575\n",
      "Iteration 4287, loss = 2709.96533463\n",
      "Iteration 4288, loss = 2709.78256426\n",
      "Iteration 4289, loss = 2709.59988462\n",
      "Iteration 4290, loss = 2709.41729568\n",
      "Iteration 4291, loss = 2709.23479742\n",
      "Iteration 4292, loss = 2709.05238981\n",
      "Iteration 4293, loss = 2708.87007284\n",
      "Iteration 4294, loss = 2708.68784646\n",
      "Iteration 4295, loss = 2708.50571067\n",
      "Iteration 4296, loss = 2708.32366544\n",
      "Iteration 4297, loss = 2708.14171074\n",
      "Iteration 4298, loss = 2707.95984655\n",
      "Iteration 4299, loss = 2707.77807285\n",
      "Iteration 4300, loss = 2707.59638960\n",
      "Iteration 4301, loss = 2707.41479680\n",
      "Iteration 4302, loss = 2707.23329440\n",
      "Iteration 4303, loss = 2707.05188240\n",
      "Iteration 4304, loss = 2706.87056076\n",
      "Iteration 4305, loss = 2706.68932946\n",
      "Iteration 4306, loss = 2706.50818848\n",
      "Iteration 4307, loss = 2706.32713779\n",
      "Iteration 4308, loss = 2706.14617737\n",
      "Iteration 4309, loss = 2705.96530720\n",
      "Iteration 4310, loss = 2705.78452725\n",
      "Iteration 4311, loss = 2705.60383749\n",
      "Iteration 4312, loss = 2705.42323791\n",
      "Iteration 4313, loss = 2705.24272848\n",
      "Iteration 4314, loss = 2705.06230917\n",
      "Iteration 4315, loss = 2704.88197997\n",
      "Iteration 4316, loss = 2704.70174084\n",
      "Iteration 4317, loss = 2704.52159177\n",
      "Iteration 4318, loss = 2704.34153272\n",
      "Iteration 4319, loss = 2704.16156368\n",
      "Iteration 4320, loss = 2703.98168462\n",
      "Iteration 4321, loss = 2703.80189552\n",
      "Iteration 4322, loss = 2703.62219636\n",
      "Iteration 4323, loss = 2703.44258710\n",
      "Iteration 4324, loss = 2703.26306773\n",
      "Iteration 4325, loss = 2703.08363822\n",
      "Iteration 4326, loss = 2702.90429855\n",
      "Iteration 4327, loss = 2702.72504870\n",
      "Iteration 4328, loss = 2702.54588864\n",
      "Iteration 4329, loss = 2702.36681834\n",
      "Iteration 4330, loss = 2702.18783778\n",
      "Iteration 4331, loss = 2702.00894695\n",
      "Iteration 4332, loss = 2701.83014581\n",
      "Iteration 4333, loss = 2701.65143434\n",
      "Iteration 4334, loss = 2701.47281252\n",
      "Iteration 4335, loss = 2701.29428032\n",
      "Iteration 4336, loss = 2701.11583772\n",
      "Iteration 4337, loss = 2700.93748470\n",
      "Iteration 4338, loss = 2700.75922123\n",
      "Iteration 4339, loss = 2700.58104728\n",
      "Iteration 4340, loss = 2700.40296285\n",
      "Iteration 4341, loss = 2700.22496789\n",
      "Iteration 4342, loss = 2700.04706239\n",
      "Iteration 4343, loss = 2699.86924632\n",
      "Iteration 4344, loss = 2699.69151966\n",
      "Iteration 4345, loss = 2699.51388239\n",
      "Iteration 4346, loss = 2699.33633448\n",
      "Iteration 4347, loss = 2699.15887591\n",
      "Iteration 4348, loss = 2698.98150665\n",
      "Iteration 4349, loss = 2698.80422668\n",
      "Iteration 4350, loss = 2698.62703598\n",
      "Iteration 4351, loss = 2698.44993452\n",
      "Iteration 4352, loss = 2698.27292228\n",
      "Iteration 4353, loss = 2698.09599924\n",
      "Iteration 4354, loss = 2697.91916537\n",
      "Iteration 4355, loss = 2697.74242064\n",
      "Iteration 4356, loss = 2697.56576504\n",
      "Iteration 4357, loss = 2697.38919854\n",
      "Iteration 4358, loss = 2697.21272112\n",
      "Iteration 4359, loss = 2697.03633275\n",
      "Iteration 4360, loss = 2696.86003341\n",
      "Iteration 4361, loss = 2696.68382308\n",
      "Iteration 4362, loss = 2696.50770172\n",
      "Iteration 4363, loss = 2696.33166933\n",
      "Iteration 4364, loss = 2696.15572587\n",
      "Iteration 4365, loss = 2695.97987132\n",
      "Iteration 4366, loss = 2695.80410566\n",
      "Iteration 4367, loss = 2695.62842887\n",
      "Iteration 4368, loss = 2695.45284091\n",
      "Iteration 4369, loss = 2695.27734177\n",
      "Iteration 4370, loss = 2695.10193142\n",
      "Iteration 4371, loss = 2694.92660984\n",
      "Iteration 4372, loss = 2694.75137701\n",
      "Iteration 4373, loss = 2694.57623290\n",
      "Iteration 4374, loss = 2694.40117748\n",
      "Iteration 4375, loss = 2694.22621074\n",
      "Iteration 4376, loss = 2694.05133266\n",
      "Iteration 4377, loss = 2693.87654319\n",
      "Iteration 4378, loss = 2693.70184234\n",
      "Iteration 4379, loss = 2693.52723006\n",
      "Iteration 4380, loss = 2693.35270634\n",
      "Iteration 4381, loss = 2693.17827115\n",
      "Iteration 4382, loss = 2693.00392447\n",
      "Iteration 4383, loss = 2692.82966628\n",
      "Iteration 4384, loss = 2692.65549655\n",
      "Iteration 4385, loss = 2692.48141526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4386, loss = 2692.30742238\n",
      "Iteration 4387, loss = 2692.13351790\n",
      "Iteration 4388, loss = 2691.95970178\n",
      "Iteration 4389, loss = 2691.78597401\n",
      "Iteration 4390, loss = 2691.61233455\n",
      "Iteration 4391, loss = 2691.43878340\n",
      "Iteration 4392, loss = 2691.26532052\n",
      "Iteration 4393, loss = 2691.09194588\n",
      "Iteration 4394, loss = 2690.91865948\n",
      "Iteration 4395, loss = 2690.74546128\n",
      "Iteration 4396, loss = 2690.57235126\n",
      "Iteration 4397, loss = 2690.39932939\n",
      "Iteration 4398, loss = 2690.22639566\n",
      "Iteration 4399, loss = 2690.05355003\n",
      "Iteration 4400, loss = 2689.88079249\n",
      "Iteration 4401, loss = 2689.70812302\n",
      "Iteration 4402, loss = 2689.53554158\n",
      "Iteration 4403, loss = 2689.36304816\n",
      "Iteration 4404, loss = 2689.19064273\n",
      "Iteration 4405, loss = 2689.01832526\n",
      "Iteration 4406, loss = 2688.84609575\n",
      "Iteration 4407, loss = 2688.67395415\n",
      "Iteration 4408, loss = 2688.50190045\n",
      "Iteration 4409, loss = 2688.32993462\n",
      "Iteration 4410, loss = 2688.15805665\n",
      "Iteration 4411, loss = 2687.98626650\n",
      "Iteration 4412, loss = 2687.81456416\n",
      "Iteration 4413, loss = 2687.64294960\n",
      "Iteration 4414, loss = 2687.47142279\n",
      "Iteration 4415, loss = 2687.29998372\n",
      "Iteration 4416, loss = 2687.12863236\n",
      "Iteration 4417, loss = 2686.95736869\n",
      "Iteration 4418, loss = 2686.78619268\n",
      "Iteration 4419, loss = 2686.61510431\n",
      "Iteration 4420, loss = 2686.44410355\n",
      "Iteration 4421, loss = 2686.27319039\n",
      "Iteration 4422, loss = 2686.10236480\n",
      "Iteration 4423, loss = 2685.93162676\n",
      "Iteration 4424, loss = 2685.76097624\n",
      "Iteration 4425, loss = 2685.59041322\n",
      "Iteration 4426, loss = 2685.41993767\n",
      "Iteration 4427, loss = 2685.24954958\n",
      "Iteration 4428, loss = 2685.07924892\n",
      "Iteration 4429, loss = 2684.90903566\n",
      "Iteration 4430, loss = 2684.73890979\n",
      "Iteration 4431, loss = 2684.56887127\n",
      "Iteration 4432, loss = 2684.39892010\n",
      "Iteration 4433, loss = 2684.22905623\n",
      "Iteration 4434, loss = 2684.05927966\n",
      "Iteration 4435, loss = 2683.88959035\n",
      "Iteration 4436, loss = 2683.71998828\n",
      "Iteration 4437, loss = 2683.55047344\n",
      "Iteration 4438, loss = 2683.38104579\n",
      "Iteration 4439, loss = 2683.21170531\n",
      "Iteration 4440, loss = 2683.04245198\n",
      "Iteration 4441, loss = 2682.87328578\n",
      "Iteration 4442, loss = 2682.70420668\n",
      "Iteration 4443, loss = 2682.53521466\n",
      "Iteration 4444, loss = 2682.36630970\n",
      "Iteration 4445, loss = 2682.19749177\n",
      "Iteration 4446, loss = 2682.02876085\n",
      "Iteration 4447, loss = 2681.86011692\n",
      "Iteration 4448, loss = 2681.69155995\n",
      "Iteration 4449, loss = 2681.52308992\n",
      "Iteration 4450, loss = 2681.35470681\n",
      "Iteration 4451, loss = 2681.18641059\n",
      "Iteration 4452, loss = 2681.01820124\n",
      "Iteration 4453, loss = 2680.85007874\n",
      "Iteration 4454, loss = 2680.68204306\n",
      "Iteration 4455, loss = 2680.51409419\n",
      "Iteration 4456, loss = 2680.34623209\n",
      "Iteration 4457, loss = 2680.17845674\n",
      "Iteration 4458, loss = 2680.01076813\n",
      "Iteration 4459, loss = 2679.84316622\n",
      "Iteration 4460, loss = 2679.67565099\n",
      "Iteration 4461, loss = 2679.50822243\n",
      "Iteration 4462, loss = 2679.34088051\n",
      "Iteration 4463, loss = 2679.17362520\n",
      "Iteration 4464, loss = 2679.00645648\n",
      "Iteration 4465, loss = 2678.83937433\n",
      "Iteration 4466, loss = 2678.67237873\n",
      "Iteration 4467, loss = 2678.50546965\n",
      "Iteration 4468, loss = 2678.33864706\n",
      "Iteration 4469, loss = 2678.17191096\n",
      "Iteration 4470, loss = 2678.00526130\n",
      "Iteration 4471, loss = 2677.83869808\n",
      "Iteration 4472, loss = 2677.67222126\n",
      "Iteration 4473, loss = 2677.50583082\n",
      "Iteration 4474, loss = 2677.33952674\n",
      "Iteration 4475, loss = 2677.17330900\n",
      "Iteration 4476, loss = 2677.00717757\n",
      "Iteration 4477, loss = 2676.84113244\n",
      "Iteration 4478, loss = 2676.67517357\n",
      "Iteration 4479, loss = 2676.50930094\n",
      "Iteration 4480, loss = 2676.34351454\n",
      "Iteration 4481, loss = 2676.17781433\n",
      "Iteration 4482, loss = 2676.01220030\n",
      "Iteration 4483, loss = 2675.84667242\n",
      "Iteration 4484, loss = 2675.68123067\n",
      "Iteration 4485, loss = 2675.51587502\n",
      "Iteration 4486, loss = 2675.35060546\n",
      "Iteration 4487, loss = 2675.18542195\n",
      "Iteration 4488, loss = 2675.02032448\n",
      "Iteration 4489, loss = 2674.85531303\n",
      "Iteration 4490, loss = 2674.69038756\n",
      "Iteration 4491, loss = 2674.52554806\n",
      "Iteration 4492, loss = 2674.36079450\n",
      "Iteration 4493, loss = 2674.19612687\n",
      "Iteration 4494, loss = 2674.03154513\n",
      "Iteration 4495, loss = 2673.86704927\n",
      "Iteration 4496, loss = 2673.70263925\n",
      "Iteration 4497, loss = 2673.53831507\n",
      "Iteration 4498, loss = 2673.37407669\n",
      "Iteration 4499, loss = 2673.20992409\n",
      "Iteration 4500, loss = 2673.04585726\n",
      "Iteration 4501, loss = 2672.88187615\n",
      "Iteration 4502, loss = 2672.71798077\n",
      "Iteration 4503, loss = 2672.55417107\n",
      "Iteration 4504, loss = 2672.39044704\n",
      "Iteration 4505, loss = 2672.22680865\n",
      "Iteration 4506, loss = 2672.06325588\n",
      "Iteration 4507, loss = 2671.89978871\n",
      "Iteration 4508, loss = 2671.73640712\n",
      "Iteration 4509, loss = 2671.57311108\n",
      "Iteration 4510, loss = 2671.40990056\n",
      "Iteration 4511, loss = 2671.24677556\n",
      "Iteration 4512, loss = 2671.08373603\n",
      "Iteration 4513, loss = 2670.92078197\n",
      "Iteration 4514, loss = 2670.75791334\n",
      "Iteration 4515, loss = 2670.59513012\n",
      "Iteration 4516, loss = 2670.43243230\n",
      "Iteration 4517, loss = 2670.26981984\n",
      "Iteration 4518, loss = 2670.10729273\n",
      "Iteration 4519, loss = 2669.94485095\n",
      "Iteration 4520, loss = 2669.78249446\n",
      "Iteration 4521, loss = 2669.62022324\n",
      "Iteration 4522, loss = 2669.45803728\n",
      "Iteration 4523, loss = 2669.29593655\n",
      "Iteration 4524, loss = 2669.13392103\n",
      "Iteration 4525, loss = 2668.97199069\n",
      "Iteration 4526, loss = 2668.81014551\n",
      "Iteration 4527, loss = 2668.64838547\n",
      "Iteration 4528, loss = 2668.48671054\n",
      "Iteration 4529, loss = 2668.32512071\n",
      "Iteration 4530, loss = 2668.16361595\n",
      "Iteration 4531, loss = 2668.00219623\n",
      "Iteration 4532, loss = 2667.84086154\n",
      "Iteration 4533, loss = 2667.67961184\n",
      "Iteration 4534, loss = 2667.51844713\n",
      "Iteration 4535, loss = 2667.35736737\n",
      "Iteration 4536, loss = 2667.19637254\n",
      "Iteration 4537, loss = 2667.03546262\n",
      "Iteration 4538, loss = 2666.87463759\n",
      "Iteration 4539, loss = 2666.71389742\n",
      "Iteration 4540, loss = 2666.55324209\n",
      "Iteration 4541, loss = 2666.39267158\n",
      "Iteration 4542, loss = 2666.23218586\n",
      "Iteration 4543, loss = 2666.07178491\n",
      "Iteration 4544, loss = 2665.91146871\n",
      "Iteration 4545, loss = 2665.75123724\n",
      "Iteration 4546, loss = 2665.59109047\n",
      "Iteration 4547, loss = 2665.43102839\n",
      "Iteration 4548, loss = 2665.27105095\n",
      "Iteration 4549, loss = 2665.11115816\n",
      "Iteration 4550, loss = 2664.95134997\n",
      "Iteration 4551, loss = 2664.79162637\n",
      "Iteration 4552, loss = 2664.63198734\n",
      "Iteration 4553, loss = 2664.47243285\n",
      "Iteration 4554, loss = 2664.31296289\n",
      "Iteration 4555, loss = 2664.15357742\n",
      "Iteration 4556, loss = 2663.99427642\n",
      "Iteration 4557, loss = 2663.83505987\n",
      "Iteration 4558, loss = 2663.67592776\n",
      "Iteration 4559, loss = 2663.51688005\n",
      "Iteration 4560, loss = 2663.35791672\n",
      "Iteration 4561, loss = 2663.19903775\n",
      "Iteration 4562, loss = 2663.04024312\n",
      "Iteration 4563, loss = 2662.88153281\n",
      "Iteration 4564, loss = 2662.72290679\n",
      "Iteration 4565, loss = 2662.56436503\n",
      "Iteration 4566, loss = 2662.40590752\n",
      "Iteration 4567, loss = 2662.24753424\n",
      "Iteration 4568, loss = 2662.08924515\n",
      "Iteration 4569, loss = 2661.93104025\n",
      "Iteration 4570, loss = 2661.77291950\n",
      "Iteration 4571, loss = 2661.61488288\n",
      "Iteration 4572, loss = 2661.45693037\n",
      "Iteration 4573, loss = 2661.29906195\n",
      "Iteration 4574, loss = 2661.14127759\n",
      "Iteration 4575, loss = 2660.98357727\n",
      "Iteration 4576, loss = 2660.82596097\n",
      "Iteration 4577, loss = 2660.66842867\n",
      "Iteration 4578, loss = 2660.51098033\n",
      "Iteration 4579, loss = 2660.35361595\n",
      "Iteration 4580, loss = 2660.19633550\n",
      "Iteration 4581, loss = 2660.03913895\n",
      "Iteration 4582, loss = 2659.88202628\n",
      "Iteration 4583, loss = 2659.72499747\n",
      "Iteration 4584, loss = 2659.56805250\n",
      "Iteration 4585, loss = 2659.41119134\n",
      "Iteration 4586, loss = 2659.25441398\n",
      "Iteration 4587, loss = 2659.09772038\n",
      "Iteration 4588, loss = 2658.94111052\n",
      "Iteration 4589, loss = 2658.78458439\n",
      "Iteration 4590, loss = 2658.62814196\n",
      "Iteration 4591, loss = 2658.47178320\n",
      "Iteration 4592, loss = 2658.31550810\n",
      "Iteration 4593, loss = 2658.15931663\n",
      "Iteration 4594, loss = 2658.00320877\n",
      "Iteration 4595, loss = 2657.84718450\n",
      "Iteration 4596, loss = 2657.69124379\n",
      "Iteration 4597, loss = 2657.53538662\n",
      "Iteration 4598, loss = 2657.37961297\n",
      "Iteration 4599, loss = 2657.22392282\n",
      "Iteration 4600, loss = 2657.06831614\n",
      "Iteration 4601, loss = 2656.91279290\n",
      "Iteration 4602, loss = 2656.75735310\n",
      "Iteration 4603, loss = 2656.60199670\n",
      "Iteration 4604, loss = 2656.44672368\n",
      "Iteration 4605, loss = 2656.29153402\n",
      "Iteration 4606, loss = 2656.13642770\n",
      "Iteration 4607, loss = 2655.98140469\n",
      "Iteration 4608, loss = 2655.82646498\n",
      "Iteration 4609, loss = 2655.67160853\n",
      "Iteration 4610, loss = 2655.51683533\n",
      "Iteration 4611, loss = 2655.36214535\n",
      "Iteration 4612, loss = 2655.20753858\n",
      "Iteration 4613, loss = 2655.05301498\n",
      "Iteration 4614, loss = 2654.89857453\n",
      "Iteration 4615, loss = 2654.74421722\n",
      "Iteration 4616, loss = 2654.58994302\n",
      "Iteration 4617, loss = 2654.43575191\n",
      "Iteration 4618, loss = 2654.28164386\n",
      "Iteration 4619, loss = 2654.12761886\n",
      "Iteration 4620, loss = 2653.97367687\n",
      "Iteration 4621, loss = 2653.81981788\n",
      "Iteration 4622, loss = 2653.66604187\n",
      "Iteration 4623, loss = 2653.51234880\n",
      "Iteration 4624, loss = 2653.35873867\n",
      "Iteration 4625, loss = 2653.20521144\n",
      "Iteration 4626, loss = 2653.05176710\n",
      "Iteration 4627, loss = 2652.89840562\n",
      "Iteration 4628, loss = 2652.74512697\n",
      "Iteration 4629, loss = 2652.59193115\n",
      "Iteration 4630, loss = 2652.43881811\n",
      "Iteration 4631, loss = 2652.28578785\n",
      "Iteration 4632, loss = 2652.13284034\n",
      "Iteration 4633, loss = 2651.97997555\n",
      "Iteration 4634, loss = 2651.82719346\n",
      "Iteration 4635, loss = 2651.67449406\n",
      "Iteration 4636, loss = 2651.52187731\n",
      "Iteration 4637, loss = 2651.36934320\n",
      "Iteration 4638, loss = 2651.21689170\n",
      "Iteration 4639, loss = 2651.06452279\n",
      "Iteration 4640, loss = 2650.91223645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4641, loss = 2650.76003265\n",
      "Iteration 4642, loss = 2650.60791138\n",
      "Iteration 4643, loss = 2650.45587261\n",
      "Iteration 4644, loss = 2650.30391631\n",
      "Iteration 4645, loss = 2650.15204247\n",
      "Iteration 4646, loss = 2650.00025106\n",
      "Iteration 4647, loss = 2649.84854206\n",
      "Iteration 4648, loss = 2649.69691545\n",
      "Iteration 4649, loss = 2649.54537120\n",
      "Iteration 4650, loss = 2649.39390930\n",
      "Iteration 4651, loss = 2649.24252971\n",
      "Iteration 4652, loss = 2649.09123242\n",
      "Iteration 4653, loss = 2648.94001741\n",
      "Iteration 4654, loss = 2648.78888464\n",
      "Iteration 4655, loss = 2648.63783411\n",
      "Iteration 4656, loss = 2648.48686579\n",
      "Iteration 4657, loss = 2648.33597964\n",
      "Iteration 4658, loss = 2648.18517566\n",
      "Iteration 4659, loss = 2648.03445382\n",
      "Iteration 4660, loss = 2647.88381410\n",
      "Iteration 4661, loss = 2647.73325647\n",
      "Iteration 4662, loss = 2647.58278091\n",
      "Iteration 4663, loss = 2647.43238741\n",
      "Iteration 4664, loss = 2647.28207592\n",
      "Iteration 4665, loss = 2647.13184645\n",
      "Iteration 4666, loss = 2646.98169895\n",
      "Iteration 4667, loss = 2646.83163341\n",
      "Iteration 4668, loss = 2646.68164982\n",
      "Iteration 4669, loss = 2646.53174813\n",
      "Iteration 4670, loss = 2646.38192834\n",
      "Iteration 4671, loss = 2646.23219041\n",
      "Iteration 4672, loss = 2646.08253434\n",
      "Iteration 4673, loss = 2645.93296008\n",
      "Iteration 4674, loss = 2645.78346763\n",
      "Iteration 4675, loss = 2645.63405696\n",
      "Iteration 4676, loss = 2645.48472805\n",
      "Iteration 4677, loss = 2645.33548087\n",
      "Iteration 4678, loss = 2645.18631540\n",
      "Iteration 4679, loss = 2645.03723162\n",
      "Iteration 4680, loss = 2644.88822951\n",
      "Iteration 4681, loss = 2644.73930904\n",
      "Iteration 4682, loss = 2644.59047019\n",
      "Iteration 4683, loss = 2644.44171295\n",
      "Iteration 4684, loss = 2644.29303728\n",
      "Iteration 4685, loss = 2644.14444317\n",
      "Iteration 4686, loss = 2643.99593059\n",
      "Iteration 4687, loss = 2643.84749952\n",
      "Iteration 4688, loss = 2643.69914993\n",
      "Iteration 4689, loss = 2643.55088181\n",
      "Iteration 4690, loss = 2643.40269514\n",
      "Iteration 4691, loss = 2643.25458988\n",
      "Iteration 4692, loss = 2643.10656602\n",
      "Iteration 4693, loss = 2642.95862354\n",
      "Iteration 4694, loss = 2642.81076241\n",
      "Iteration 4695, loss = 2642.66298261\n",
      "Iteration 4696, loss = 2642.51528412\n",
      "Iteration 4697, loss = 2642.36766691\n",
      "Iteration 4698, loss = 2642.22013097\n",
      "Iteration 4699, loss = 2642.07267626\n",
      "Iteration 4700, loss = 2641.92530278\n",
      "Iteration 4701, loss = 2641.77801049\n",
      "Iteration 4702, loss = 2641.63079938\n",
      "Iteration 4703, loss = 2641.48366941\n",
      "Iteration 4704, loss = 2641.33662058\n",
      "Iteration 4705, loss = 2641.18965285\n",
      "Iteration 4706, loss = 2641.04276620\n",
      "Iteration 4707, loss = 2640.89596062\n",
      "Iteration 4708, loss = 2640.74923607\n",
      "Iteration 4709, loss = 2640.60259255\n",
      "Iteration 4710, loss = 2640.45603001\n",
      "Iteration 4711, loss = 2640.30954845\n",
      "Iteration 4712, loss = 2640.16314784\n",
      "Iteration 4713, loss = 2640.01682815\n",
      "Iteration 4714, loss = 2639.87058937\n",
      "Iteration 4715, loss = 2639.72443147\n",
      "Iteration 4716, loss = 2639.57835443\n",
      "Iteration 4717, loss = 2639.43235823\n",
      "Iteration 4718, loss = 2639.28644285\n",
      "Iteration 4719, loss = 2639.14060826\n",
      "Iteration 4720, loss = 2638.99485443\n",
      "Iteration 4721, loss = 2638.84918136\n",
      "Iteration 4722, loss = 2638.70358901\n",
      "Iteration 4723, loss = 2638.55807737\n",
      "Iteration 4724, loss = 2638.41264640\n",
      "Iteration 4725, loss = 2638.26729610\n",
      "Iteration 4726, loss = 2638.12202643\n",
      "Iteration 4727, loss = 2637.97683737\n",
      "Iteration 4728, loss = 2637.83172891\n",
      "Iteration 4729, loss = 2637.68670102\n",
      "Iteration 4730, loss = 2637.54175367\n",
      "Iteration 4731, loss = 2637.39688685\n",
      "Iteration 4732, loss = 2637.25210053\n",
      "Iteration 4733, loss = 2637.10739469\n",
      "Iteration 4734, loss = 2636.96276931\n",
      "Iteration 4735, loss = 2636.81822436\n",
      "Iteration 4736, loss = 2636.67375982\n",
      "Iteration 4737, loss = 2636.52937568\n",
      "Iteration 4738, loss = 2636.38507190\n",
      "Iteration 4739, loss = 2636.24084847\n",
      "Iteration 4740, loss = 2636.09670537\n",
      "Iteration 4741, loss = 2635.95264256\n",
      "Iteration 4742, loss = 2635.80866004\n",
      "Iteration 4743, loss = 2635.66475777\n",
      "Iteration 4744, loss = 2635.52093573\n",
      "Iteration 4745, loss = 2635.37719391\n",
      "Iteration 4746, loss = 2635.23353228\n",
      "Iteration 4747, loss = 2635.08995081\n",
      "Iteration 4748, loss = 2634.94644949\n",
      "Iteration 4749, loss = 2634.80302829\n",
      "Iteration 4750, loss = 2634.65968719\n",
      "Iteration 4751, loss = 2634.51642617\n",
      "Iteration 4752, loss = 2634.37324521\n",
      "Iteration 4753, loss = 2634.23014428\n",
      "Iteration 4754, loss = 2634.08712336\n",
      "Iteration 4755, loss = 2633.94418243\n",
      "Iteration 4756, loss = 2633.80132147\n",
      "Iteration 4757, loss = 2633.65854045\n",
      "Iteration 4758, loss = 2633.51583935\n",
      "Iteration 4759, loss = 2633.37321815\n",
      "Iteration 4760, loss = 2633.23067683\n",
      "Iteration 4761, loss = 2633.08821537\n",
      "Iteration 4762, loss = 2632.94583374\n",
      "Iteration 4763, loss = 2632.80353192\n",
      "Iteration 4764, loss = 2632.66130989\n",
      "Iteration 4765, loss = 2632.51916762\n",
      "Iteration 4766, loss = 2632.37710510\n",
      "Iteration 4767, loss = 2632.23512230\n",
      "Iteration 4768, loss = 2632.09321919\n",
      "Iteration 4769, loss = 2631.95139577\n",
      "Iteration 4770, loss = 2631.80965200\n",
      "Iteration 4771, loss = 2631.66798786\n",
      "Iteration 4772, loss = 2631.52640334\n",
      "Iteration 4773, loss = 2631.38489840\n",
      "Iteration 4774, loss = 2631.24347302\n",
      "Iteration 4775, loss = 2631.10212719\n",
      "Iteration 4776, loss = 2630.96086089\n",
      "Iteration 4777, loss = 2630.81967408\n",
      "Iteration 4778, loss = 2630.67856674\n",
      "Iteration 4779, loss = 2630.53753886\n",
      "Iteration 4780, loss = 2630.39659042\n",
      "Iteration 4781, loss = 2630.25572138\n",
      "Iteration 4782, loss = 2630.11493173\n",
      "Iteration 4783, loss = 2629.97422145\n",
      "Iteration 4784, loss = 2629.83359051\n",
      "Iteration 4785, loss = 2629.69303889\n",
      "Iteration 4786, loss = 2629.55256657\n",
      "Iteration 4787, loss = 2629.41217353\n",
      "Iteration 4788, loss = 2629.27185974\n",
      "Iteration 4789, loss = 2629.13162518\n",
      "Iteration 4790, loss = 2628.99146983\n",
      "Iteration 4791, loss = 2628.85139367\n",
      "Iteration 4792, loss = 2628.71139668\n",
      "Iteration 4793, loss = 2628.57147883\n",
      "Iteration 4794, loss = 2628.43164010\n",
      "Iteration 4795, loss = 2628.29188047\n",
      "Iteration 4796, loss = 2628.15219991\n",
      "Iteration 4797, loss = 2628.01259841\n",
      "Iteration 4798, loss = 2627.87307594\n",
      "Iteration 4799, loss = 2627.73363248\n",
      "Iteration 4800, loss = 2627.59426801\n",
      "Iteration 4801, loss = 2627.45498251\n",
      "Iteration 4802, loss = 2627.31577594\n",
      "Iteration 4803, loss = 2627.17664830\n",
      "Iteration 4804, loss = 2627.03759956\n",
      "Iteration 4805, loss = 2626.89862969\n",
      "Iteration 4806, loss = 2626.75973868\n",
      "Iteration 4807, loss = 2626.62092650\n",
      "Iteration 4808, loss = 2626.48219313\n",
      "Iteration 4809, loss = 2626.34353855\n",
      "Iteration 4810, loss = 2626.20496274\n",
      "Iteration 4811, loss = 2626.06646566\n",
      "Iteration 4812, loss = 2625.92804731\n",
      "Iteration 4813, loss = 2625.78970766\n",
      "Iteration 4814, loss = 2625.65144668\n",
      "Iteration 4815, loss = 2625.51326436\n",
      "Iteration 4816, loss = 2625.37516067\n",
      "Iteration 4817, loss = 2625.23713559\n",
      "Iteration 4818, loss = 2625.09918910\n",
      "Iteration 4819, loss = 2624.96132118\n",
      "Iteration 4820, loss = 2624.82353180\n",
      "Iteration 4821, loss = 2624.68582094\n",
      "Iteration 4822, loss = 2624.54818858\n",
      "Iteration 4823, loss = 2624.41063470\n",
      "Iteration 4824, loss = 2624.27315927\n",
      "Iteration 4825, loss = 2624.13576227\n",
      "Iteration 4826, loss = 2623.99844369\n",
      "Iteration 4827, loss = 2623.86120349\n",
      "Iteration 4828, loss = 2623.72404166\n",
      "Iteration 4829, loss = 2623.58695818\n",
      "Iteration 4830, loss = 2623.44995302\n",
      "Iteration 4831, loss = 2623.31302615\n",
      "Iteration 4832, loss = 2623.17617757\n",
      "Iteration 4833, loss = 2623.03940724\n",
      "Iteration 4834, loss = 2622.90271514\n",
      "Iteration 4835, loss = 2622.76610125\n",
      "Iteration 4836, loss = 2622.62956556\n",
      "Iteration 4837, loss = 2622.49310803\n",
      "Iteration 4838, loss = 2622.35672864\n",
      "Iteration 4839, loss = 2622.22042738\n",
      "Iteration 4840, loss = 2622.08420422\n",
      "Iteration 4841, loss = 2621.94805913\n",
      "Iteration 4842, loss = 2621.81199210\n",
      "Iteration 4843, loss = 2621.67600311\n",
      "Iteration 4844, loss = 2621.54009213\n",
      "Iteration 4845, loss = 2621.40425914\n",
      "Iteration 4846, loss = 2621.26850411\n",
      "Iteration 4847, loss = 2621.13282703\n",
      "Iteration 4848, loss = 2620.99722787\n",
      "Iteration 4849, loss = 2620.86170662\n",
      "Iteration 4850, loss = 2620.72626324\n",
      "Iteration 4851, loss = 2620.59089772\n",
      "Iteration 4852, loss = 2620.45561004\n",
      "Iteration 4853, loss = 2620.32040017\n",
      "Iteration 4854, loss = 2620.18526808\n",
      "Iteration 4855, loss = 2620.05021377\n",
      "Iteration 4856, loss = 2619.91523720\n",
      "Iteration 4857, loss = 2619.78033836\n",
      "Iteration 4858, loss = 2619.64551722\n",
      "Iteration 4859, loss = 2619.51077376\n",
      "Iteration 4860, loss = 2619.37610795\n",
      "Iteration 4861, loss = 2619.24151978\n",
      "Iteration 4862, loss = 2619.10700923\n",
      "Iteration 4863, loss = 2618.97257626\n",
      "Iteration 4864, loss = 2618.83822087\n",
      "Iteration 4865, loss = 2618.70394302\n",
      "Iteration 4866, loss = 2618.56974270\n",
      "Iteration 4867, loss = 2618.43561988\n",
      "Iteration 4868, loss = 2618.30157454\n",
      "Iteration 4869, loss = 2618.16760665\n",
      "Iteration 4870, loss = 2618.03371621\n",
      "Iteration 4871, loss = 2617.89990318\n",
      "Iteration 4872, loss = 2617.76616754\n",
      "Iteration 4873, loss = 2617.63250927\n",
      "Iteration 4874, loss = 2617.49892835\n",
      "Iteration 4875, loss = 2617.36542476\n",
      "Iteration 4876, loss = 2617.23199847\n",
      "Iteration 4877, loss = 2617.09864946\n",
      "Iteration 4878, loss = 2616.96537771\n",
      "Iteration 4879, loss = 2616.83218320\n",
      "Iteration 4880, loss = 2616.69906590\n",
      "Iteration 4881, loss = 2616.56602580\n",
      "Iteration 4882, loss = 2616.43306287\n",
      "Iteration 4883, loss = 2616.30017708\n",
      "Iteration 4884, loss = 2616.16736843\n",
      "Iteration 4885, loss = 2616.03463688\n",
      "Iteration 4886, loss = 2615.90198241\n",
      "Iteration 4887, loss = 2615.76940500\n",
      "Iteration 4888, loss = 2615.63690463\n",
      "Iteration 4889, loss = 2615.50448128\n",
      "Iteration 4890, loss = 2615.37213492\n",
      "Iteration 4891, loss = 2615.23986553\n",
      "Iteration 4892, loss = 2615.10767310\n",
      "Iteration 4893, loss = 2614.97555759\n",
      "Iteration 4894, loss = 2614.84351899\n",
      "Iteration 4895, loss = 2614.71155727\n",
      "Iteration 4896, loss = 2614.57967241\n",
      "Iteration 4897, loss = 2614.44786440\n",
      "Iteration 4898, loss = 2614.31613320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4899, loss = 2614.18447880\n",
      "Iteration 4900, loss = 2614.05290117\n",
      "Iteration 4901, loss = 2613.92140029\n",
      "Iteration 4902, loss = 2613.78997614\n",
      "Iteration 4903, loss = 2613.65862870\n",
      "Iteration 4904, loss = 2613.52735794\n",
      "Iteration 4905, loss = 2613.39616385\n",
      "Iteration 4906, loss = 2613.26504640\n",
      "Iteration 4907, loss = 2613.13400556\n",
      "Iteration 4908, loss = 2613.00304133\n",
      "Iteration 4909, loss = 2612.87215367\n",
      "Iteration 4910, loss = 2612.74134256\n",
      "Iteration 4911, loss = 2612.61060798\n",
      "Iteration 4912, loss = 2612.47994991\n",
      "Iteration 4913, loss = 2612.34936833\n",
      "Iteration 4914, loss = 2612.21886321\n",
      "Iteration 4915, loss = 2612.08843453\n",
      "Iteration 4916, loss = 2611.95808228\n",
      "Iteration 4917, loss = 2611.82780642\n",
      "Iteration 4918, loss = 2611.69760694\n",
      "Iteration 4919, loss = 2611.56748381\n",
      "Iteration 4920, loss = 2611.43743702\n",
      "Iteration 4921, loss = 2611.30746653\n",
      "Iteration 4922, loss = 2611.17757233\n",
      "Iteration 4923, loss = 2611.04775440\n",
      "Iteration 4924, loss = 2610.91801272\n",
      "Iteration 4925, loss = 2610.78834725\n",
      "Iteration 4926, loss = 2610.65875798\n",
      "Iteration 4927, loss = 2610.52924490\n",
      "Iteration 4928, loss = 2610.39980796\n",
      "Iteration 4929, loss = 2610.27044716\n",
      "Iteration 4930, loss = 2610.14116248\n",
      "Iteration 4931, loss = 2610.01195388\n",
      "Iteration 4932, loss = 2609.88282135\n",
      "Iteration 4933, loss = 2609.75376486\n",
      "Iteration 4934, loss = 2609.62478440\n",
      "Iteration 4935, loss = 2609.49587994\n",
      "Iteration 4936, loss = 2609.36705146\n",
      "Iteration 4937, loss = 2609.23829893\n",
      "Iteration 4938, loss = 2609.10962234\n",
      "Iteration 4939, loss = 2608.98102166\n",
      "Iteration 4940, loss = 2608.85249688\n",
      "Iteration 4941, loss = 2608.72404796\n",
      "Iteration 4942, loss = 2608.59567489\n",
      "Iteration 4943, loss = 2608.46737764\n",
      "Iteration 4944, loss = 2608.33915620\n",
      "Iteration 4945, loss = 2608.21101054\n",
      "Iteration 4946, loss = 2608.08294064\n",
      "Iteration 4947, loss = 2607.95494647\n",
      "Iteration 4948, loss = 2607.82702802\n",
      "Iteration 4949, loss = 2607.69918526\n",
      "Iteration 4950, loss = 2607.57141817\n",
      "Iteration 4951, loss = 2607.44372673\n",
      "Iteration 4952, loss = 2607.31611091\n",
      "Iteration 4953, loss = 2607.18857070\n",
      "Iteration 4954, loss = 2607.06110608\n",
      "Iteration 4955, loss = 2606.93371701\n",
      "Iteration 4956, loss = 2606.80640348\n",
      "Iteration 4957, loss = 2606.67916547\n",
      "Iteration 4958, loss = 2606.55200295\n",
      "Iteration 4959, loss = 2606.42491590\n",
      "Iteration 4960, loss = 2606.29790431\n",
      "Iteration 4961, loss = 2606.17096814\n",
      "Iteration 4962, loss = 2606.04410738\n",
      "Iteration 4963, loss = 2605.91732200\n",
      "Iteration 4964, loss = 2605.79061198\n",
      "Iteration 4965, loss = 2605.66397731\n",
      "Iteration 4966, loss = 2605.53741795\n",
      "Iteration 4967, loss = 2605.41093388\n",
      "Iteration 4968, loss = 2605.28452510\n",
      "Iteration 4969, loss = 2605.15819156\n",
      "Iteration 4970, loss = 2605.03193325\n",
      "Iteration 4971, loss = 2604.90575015\n",
      "Iteration 4972, loss = 2604.77964224\n",
      "Iteration 4973, loss = 2604.65360949\n",
      "Iteration 4974, loss = 2604.52765188\n",
      "Iteration 4975, loss = 2604.40176939\n",
      "Iteration 4976, loss = 2604.27596200\n",
      "Iteration 4977, loss = 2604.15022969\n",
      "Iteration 4978, loss = 2604.02457242\n",
      "Iteration 4979, loss = 2603.89899019\n",
      "Iteration 4980, loss = 2603.77348297\n",
      "Iteration 4981, loss = 2603.64805074\n",
      "Iteration 4982, loss = 2603.52269347\n",
      "Iteration 4983, loss = 2603.39741115\n",
      "Iteration 4984, loss = 2603.27220375\n",
      "Iteration 4985, loss = 2603.14707124\n",
      "Iteration 4986, loss = 2603.02201362\n",
      "Iteration 4987, loss = 2602.89703084\n",
      "Iteration 4988, loss = 2602.77212291\n",
      "Iteration 4989, loss = 2602.64728978\n",
      "Iteration 4990, loss = 2602.52253144\n",
      "Iteration 4991, loss = 2602.39784787\n",
      "Iteration 4992, loss = 2602.27323905\n",
      "Iteration 4993, loss = 2602.14870495\n",
      "Iteration 4994, loss = 2602.02424555\n",
      "Iteration 4995, loss = 2601.89986083\n",
      "Iteration 4996, loss = 2601.77555076\n",
      "Iteration 4997, loss = 2601.65131534\n",
      "Iteration 4998, loss = 2601.52715452\n",
      "Iteration 4999, loss = 2601.40306830\n",
      "Iteration 5000, loss = 2601.27905664\n",
      "Iteration 5001, loss = 2601.15511953\n",
      "Iteration 5002, loss = 2601.03125695\n",
      "Iteration 5003, loss = 2600.90746887\n",
      "Iteration 5004, loss = 2600.78375527\n",
      "Iteration 5005, loss = 2600.66011613\n",
      "Iteration 5006, loss = 2600.53655143\n",
      "Iteration 5007, loss = 2600.41306114\n",
      "Iteration 5008, loss = 2600.28964524\n",
      "Iteration 5009, loss = 2600.16630372\n",
      "Iteration 5010, loss = 2600.04303654\n",
      "Iteration 5011, loss = 2599.91984370\n",
      "Iteration 5012, loss = 2599.79672515\n",
      "Iteration 5013, loss = 2599.67368089\n",
      "Iteration 5014, loss = 2599.55071089\n",
      "Iteration 5015, loss = 2599.42781513\n",
      "Iteration 5016, loss = 2599.30499359\n",
      "Iteration 5017, loss = 2599.18224624\n",
      "Iteration 5018, loss = 2599.05957306\n",
      "Iteration 5019, loss = 2598.93697404\n",
      "Iteration 5020, loss = 2598.81444914\n",
      "Iteration 5021, loss = 2598.69199835\n",
      "Iteration 5022, loss = 2598.56962164\n",
      "Iteration 5023, loss = 2598.44731900\n",
      "Iteration 5024, loss = 2598.32509040\n",
      "Iteration 5025, loss = 2598.20293582\n",
      "Iteration 5026, loss = 2598.08085523\n",
      "Iteration 5027, loss = 2597.95884862\n",
      "Iteration 5028, loss = 2597.83691596\n",
      "Iteration 5029, loss = 2597.71505723\n",
      "Iteration 5030, loss = 2597.59327241\n",
      "Iteration 5031, loss = 2597.47156148\n",
      "Iteration 5032, loss = 2597.34992441\n",
      "Iteration 5033, loss = 2597.22836119\n",
      "Iteration 5034, loss = 2597.10687178\n",
      "Iteration 5035, loss = 2596.98545618\n",
      "Iteration 5036, loss = 2596.86411435\n",
      "Iteration 5037, loss = 2596.74284627\n",
      "Iteration 5038, loss = 2596.62165193\n",
      "Iteration 5039, loss = 2596.50053130\n",
      "Iteration 5040, loss = 2596.37948436\n",
      "Iteration 5041, loss = 2596.25851108\n",
      "Iteration 5042, loss = 2596.13761145\n",
      "Iteration 5043, loss = 2596.01678544\n",
      "Iteration 5044, loss = 2595.89603303\n",
      "Iteration 5045, loss = 2595.77535420\n",
      "Iteration 5046, loss = 2595.65474892\n",
      "Iteration 5047, loss = 2595.53421719\n",
      "Iteration 5048, loss = 2595.41375896\n",
      "Iteration 5049, loss = 2595.29337422\n",
      "Iteration 5050, loss = 2595.17306296\n",
      "Iteration 5051, loss = 2595.05282513\n",
      "Iteration 5052, loss = 2594.93266074\n",
      "Iteration 5053, loss = 2594.81256974\n",
      "Iteration 5054, loss = 2594.69255213\n",
      "Iteration 5055, loss = 2594.57260787\n",
      "Iteration 5056, loss = 2594.45273696\n",
      "Iteration 5057, loss = 2594.33293935\n",
      "Iteration 5058, loss = 2594.21321504\n",
      "Iteration 5059, loss = 2594.09356400\n",
      "Iteration 5060, loss = 2593.97398620\n",
      "Iteration 5061, loss = 2593.85448164\n",
      "Iteration 5062, loss = 2593.73505028\n",
      "Iteration 5063, loss = 2593.61569210\n",
      "Iteration 5064, loss = 2593.49640708\n",
      "Iteration 5065, loss = 2593.37719520\n",
      "Iteration 5066, loss = 2593.25805643\n",
      "Iteration 5067, loss = 2593.13899076\n",
      "Iteration 5068, loss = 2593.01999816\n",
      "Iteration 5069, loss = 2592.90107861\n",
      "Iteration 5070, loss = 2592.78223210\n",
      "Iteration 5071, loss = 2592.66345858\n",
      "Iteration 5072, loss = 2592.54475805\n",
      "Iteration 5073, loss = 2592.42613049\n",
      "Iteration 5074, loss = 2592.30757586\n",
      "Iteration 5075, loss = 2592.18909415\n",
      "Iteration 5076, loss = 2592.07068534\n",
      "Iteration 5077, loss = 2591.95234940\n",
      "Iteration 5078, loss = 2591.83408632\n",
      "Iteration 5079, loss = 2591.71589606\n",
      "Iteration 5080, loss = 2591.59777862\n",
      "Iteration 5081, loss = 2591.47973396\n",
      "Iteration 5082, loss = 2591.36176206\n",
      "Iteration 5083, loss = 2591.24386291\n",
      "Iteration 5084, loss = 2591.12603647\n",
      "Iteration 5085, loss = 2591.00828274\n",
      "Iteration 5086, loss = 2590.89060168\n",
      "Iteration 5087, loss = 2590.77299327\n",
      "Iteration 5088, loss = 2590.65545750\n",
      "Iteration 5089, loss = 2590.53799434\n",
      "Iteration 5090, loss = 2590.42060376\n",
      "Iteration 5091, loss = 2590.30328576\n",
      "Iteration 5092, loss = 2590.18604029\n",
      "Iteration 5093, loss = 2590.06886735\n",
      "Iteration 5094, loss = 2589.95176691\n",
      "Iteration 5095, loss = 2589.83473894\n",
      "Iteration 5096, loss = 2589.71778343\n",
      "Iteration 5097, loss = 2589.60090036\n",
      "Iteration 5098, loss = 2589.48408970\n",
      "Iteration 5099, loss = 2589.36735143\n",
      "Iteration 5100, loss = 2589.25068552\n",
      "Iteration 5101, loss = 2589.13409196\n",
      "Iteration 5102, loss = 2589.01757073\n",
      "Iteration 5103, loss = 2588.90112180\n",
      "Iteration 5104, loss = 2588.78474514\n",
      "Iteration 5105, loss = 2588.66844075\n",
      "Iteration 5106, loss = 2588.55220859\n",
      "Iteration 5107, loss = 2588.43604865\n",
      "Iteration 5108, loss = 2588.31996089\n",
      "Iteration 5109, loss = 2588.20394531\n",
      "Iteration 5110, loss = 2588.08800188\n",
      "Iteration 5111, loss = 2587.97213057\n",
      "Iteration 5112, loss = 2587.85633136\n",
      "Iteration 5113, loss = 2587.74060424\n",
      "Iteration 5114, loss = 2587.62494918\n",
      "Iteration 5115, loss = 2587.50936615\n",
      "Iteration 5116, loss = 2587.39385514\n",
      "Iteration 5117, loss = 2587.27841612\n",
      "Iteration 5118, loss = 2587.16304908\n",
      "Iteration 5119, loss = 2587.04775398\n",
      "Iteration 5120, loss = 2586.93253082\n",
      "Iteration 5121, loss = 2586.81737955\n",
      "Iteration 5122, loss = 2586.70230017\n",
      "Iteration 5123, loss = 2586.58729266\n",
      "Iteration 5124, loss = 2586.47235698\n",
      "Iteration 5125, loss = 2586.35749312\n",
      "Iteration 5126, loss = 2586.24270106\n",
      "Iteration 5127, loss = 2586.12798077\n",
      "Iteration 5128, loss = 2586.01333223\n",
      "Iteration 5129, loss = 2585.89875542\n",
      "Iteration 5130, loss = 2585.78425032\n",
      "Iteration 5131, loss = 2585.66981690\n",
      "Iteration 5132, loss = 2585.55545515\n",
      "Iteration 5133, loss = 2585.44116503\n",
      "Iteration 5134, loss = 2585.32694654\n",
      "Iteration 5135, loss = 2585.21279965\n",
      "Iteration 5136, loss = 2585.09872433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5137, loss = 2584.98472056\n",
      "Iteration 5138, loss = 2584.87078832\n",
      "Iteration 5139, loss = 2584.75692760\n",
      "Iteration 5140, loss = 2584.64313836\n",
      "Iteration 5141, loss = 2584.52942058\n",
      "Iteration 5142, loss = 2584.41577425\n",
      "Iteration 5143, loss = 2584.30219934\n",
      "Iteration 5144, loss = 2584.18869583\n",
      "Iteration 5145, loss = 2584.07526370\n",
      "Iteration 5146, loss = 2583.96190292\n",
      "Iteration 5147, loss = 2583.84861347\n",
      "Iteration 5148, loss = 2583.73539534\n",
      "Iteration 5149, loss = 2583.62224849\n",
      "Iteration 5150, loss = 2583.50917291\n",
      "Iteration 5151, loss = 2583.39616858\n",
      "Iteration 5152, loss = 2583.28323547\n",
      "Iteration 5153, loss = 2583.17037356\n",
      "Iteration 5154, loss = 2583.05758282\n",
      "Iteration 5155, loss = 2582.94486325\n",
      "Iteration 5156, loss = 2582.83221481\n",
      "Iteration 5157, loss = 2582.71963748\n",
      "Iteration 5158, loss = 2582.60713124\n",
      "Iteration 5159, loss = 2582.49469607\n",
      "Iteration 5160, loss = 2582.38233195\n",
      "Iteration 5161, loss = 2582.27003885\n",
      "Iteration 5162, loss = 2582.15781676\n",
      "Iteration 5163, loss = 2582.04566564\n",
      "Iteration 5164, loss = 2581.93358548\n",
      "Iteration 5165, loss = 2581.82157626\n",
      "Iteration 5166, loss = 2581.70963796\n",
      "Iteration 5167, loss = 2581.59777054\n",
      "Iteration 5168, loss = 2581.48597400\n",
      "Iteration 5169, loss = 2581.37424830\n",
      "Iteration 5170, loss = 2581.26259343\n",
      "Iteration 5171, loss = 2581.15100936\n",
      "Iteration 5172, loss = 2581.03949608\n",
      "Iteration 5173, loss = 2580.92805356\n",
      "Iteration 5174, loss = 2580.81668177\n",
      "Iteration 5175, loss = 2580.70538070\n",
      "Iteration 5176, loss = 2580.59415032\n",
      "Iteration 5177, loss = 2580.48299062\n",
      "Iteration 5178, loss = 2580.37190156\n",
      "Iteration 5179, loss = 2580.26088313\n",
      "Iteration 5180, loss = 2580.14993531\n",
      "Iteration 5181, loss = 2580.03905807\n",
      "Iteration 5182, loss = 2579.92825140\n",
      "Iteration 5183, loss = 2579.81751526\n",
      "Iteration 5184, loss = 2579.70684964\n",
      "Iteration 5185, loss = 2579.59625451\n",
      "Iteration 5186, loss = 2579.48572986\n",
      "Iteration 5187, loss = 2579.37527566\n",
      "Iteration 5188, loss = 2579.26489189\n",
      "Iteration 5189, loss = 2579.15457852\n",
      "Iteration 5190, loss = 2579.04433554\n",
      "Iteration 5191, loss = 2578.93416293\n",
      "Iteration 5192, loss = 2578.82406065\n",
      "Iteration 5193, loss = 2578.71402870\n",
      "Iteration 5194, loss = 2578.60406704\n",
      "Iteration 5195, loss = 2578.49417565\n",
      "Iteration 5196, loss = 2578.38435452\n",
      "Iteration 5197, loss = 2578.27460362\n",
      "Iteration 5198, loss = 2578.16492292\n",
      "Iteration 5199, loss = 2578.05531241\n",
      "Iteration 5200, loss = 2577.94577207\n",
      "Iteration 5201, loss = 2577.83630187\n",
      "Iteration 5202, loss = 2577.72690179\n",
      "Iteration 5203, loss = 2577.61757181\n",
      "Iteration 5204, loss = 2577.50831190\n",
      "Iteration 5205, loss = 2577.39912205\n",
      "Iteration 5206, loss = 2577.29000223\n",
      "Iteration 5207, loss = 2577.18095242\n",
      "Iteration 5208, loss = 2577.07197260\n",
      "Iteration 5209, loss = 2576.96306274\n",
      "Iteration 5210, loss = 2576.85422283\n",
      "Iteration 5211, loss = 2576.74545284\n",
      "Iteration 5212, loss = 2576.63675274\n",
      "Iteration 5213, loss = 2576.52812253\n",
      "Iteration 5214, loss = 2576.41956217\n",
      "Iteration 5215, loss = 2576.31107165\n",
      "Iteration 5216, loss = 2576.20265093\n",
      "Iteration 5217, loss = 2576.09430001\n",
      "Iteration 5218, loss = 2575.98601885\n",
      "Iteration 5219, loss = 2575.87780743\n",
      "Iteration 5220, loss = 2575.76966574\n",
      "Iteration 5221, loss = 2575.66159375\n",
      "Iteration 5222, loss = 2575.55359144\n",
      "Iteration 5223, loss = 2575.44565879\n",
      "Iteration 5224, loss = 2575.33779577\n",
      "Iteration 5225, loss = 2575.23000236\n",
      "Iteration 5226, loss = 2575.12227854\n",
      "Iteration 5227, loss = 2575.01462429\n",
      "Iteration 5228, loss = 2574.90703959\n",
      "Iteration 5229, loss = 2574.79952441\n",
      "Iteration 5230, loss = 2574.69207873\n",
      "Iteration 5231, loss = 2574.58470254\n",
      "Iteration 5232, loss = 2574.47739580\n",
      "Iteration 5233, loss = 2574.37015849\n",
      "Iteration 5234, loss = 2574.26299060\n",
      "Iteration 5235, loss = 2574.15589211\n",
      "Iteration 5236, loss = 2574.04886298\n",
      "Iteration 5237, loss = 2573.94190320\n",
      "Iteration 5238, loss = 2573.83501274\n",
      "Iteration 5239, loss = 2573.72819159\n",
      "Iteration 5240, loss = 2573.62143971\n",
      "Iteration 5241, loss = 2573.51475710\n",
      "Iteration 5242, loss = 2573.40814372\n",
      "Iteration 5243, loss = 2573.30159956\n",
      "Iteration 5244, loss = 2573.19512459\n",
      "Iteration 5245, loss = 2573.08871879\n",
      "Iteration 5246, loss = 2572.98238214\n",
      "Iteration 5247, loss = 2572.87611462\n",
      "Iteration 5248, loss = 2572.76991620\n",
      "Iteration 5249, loss = 2572.66378686\n",
      "Iteration 5250, loss = 2572.55772658\n",
      "Iteration 5251, loss = 2572.45173534\n",
      "Iteration 5252, loss = 2572.34581311\n",
      "Iteration 5253, loss = 2572.23995988\n",
      "Iteration 5254, loss = 2572.13417562\n",
      "Iteration 5255, loss = 2572.02846031\n",
      "Iteration 5256, loss = 2571.92281393\n",
      "Iteration 5257, loss = 2571.81723645\n",
      "Iteration 5258, loss = 2571.71172785\n",
      "Iteration 5259, loss = 2571.60628812\n",
      "Iteration 5260, loss = 2571.50091722\n",
      "Iteration 5261, loss = 2571.39561515\n",
      "Iteration 5262, loss = 2571.29038186\n",
      "Iteration 5263, loss = 2571.18521735\n",
      "Iteration 5264, loss = 2571.08012159\n",
      "Iteration 5265, loss = 2570.97509455\n",
      "Iteration 5266, loss = 2570.87013622\n",
      "Iteration 5267, loss = 2570.76524658\n",
      "Iteration 5268, loss = 2570.66042560\n",
      "Iteration 5269, loss = 2570.55567325\n",
      "Iteration 5270, loss = 2570.45098953\n",
      "Iteration 5271, loss = 2570.34637440\n",
      "Iteration 5272, loss = 2570.24182784\n",
      "Iteration 5273, loss = 2570.13734983\n",
      "Iteration 5274, loss = 2570.03294036\n",
      "Iteration 5275, loss = 2569.92859939\n",
      "Iteration 5276, loss = 2569.82432690\n",
      "Iteration 5277, loss = 2569.72012288\n",
      "Iteration 5278, loss = 2569.61598729\n",
      "Iteration 5279, loss = 2569.51192013\n",
      "Iteration 5280, loss = 2569.40792136\n",
      "Iteration 5281, loss = 2569.30399096\n",
      "Iteration 5282, loss = 2569.20012892\n",
      "Iteration 5283, loss = 2569.09633521\n",
      "Iteration 5284, loss = 2568.99260980\n",
      "Iteration 5285, loss = 2568.88895268\n",
      "Iteration 5286, loss = 2568.78536382\n",
      "Iteration 5287, loss = 2568.68184320\n",
      "Iteration 5288, loss = 2568.57839080\n",
      "Iteration 5289, loss = 2568.47500660\n",
      "Iteration 5290, loss = 2568.37169057\n",
      "Iteration 5291, loss = 2568.26844270\n",
      "Iteration 5292, loss = 2568.16526295\n",
      "Iteration 5293, loss = 2568.06215132\n",
      "Iteration 5294, loss = 2567.95910777\n",
      "Iteration 5295, loss = 2567.85613228\n",
      "Iteration 5296, loss = 2567.75322483\n",
      "Iteration 5297, loss = 2567.65038540\n",
      "Iteration 5298, loss = 2567.54761398\n",
      "Iteration 5299, loss = 2567.44491052\n",
      "Iteration 5300, loss = 2567.34227502\n",
      "Iteration 5301, loss = 2567.23970745\n",
      "Iteration 5302, loss = 2567.13720779\n",
      "Iteration 5303, loss = 2567.03477601\n",
      "Iteration 5304, loss = 2566.93241210\n",
      "Iteration 5305, loss = 2566.83011603\n",
      "Iteration 5306, loss = 2566.72788778\n",
      "Iteration 5307, loss = 2566.62572732\n",
      "Iteration 5308, loss = 2566.52363465\n",
      "Iteration 5309, loss = 2566.42160972\n",
      "Iteration 5310, loss = 2566.31965253\n",
      "Iteration 5311, loss = 2566.21776304\n",
      "Iteration 5312, loss = 2566.11594125\n",
      "Iteration 5313, loss = 2566.01418711\n",
      "Iteration 5314, loss = 2565.91250062\n",
      "Iteration 5315, loss = 2565.81088175\n",
      "Iteration 5316, loss = 2565.70933048\n",
      "Iteration 5317, loss = 2565.60784678\n",
      "Iteration 5318, loss = 2565.50643064\n",
      "Iteration 5319, loss = 2565.40508202\n",
      "Iteration 5320, loss = 2565.30380092\n",
      "Iteration 5321, loss = 2565.20258730\n",
      "Iteration 5322, loss = 2565.10144115\n",
      "Iteration 5323, loss = 2565.00036244\n",
      "Iteration 5324, loss = 2564.89935115\n",
      "Iteration 5325, loss = 2564.79840726\n",
      "Iteration 5326, loss = 2564.69753075\n",
      "Iteration 5327, loss = 2564.59672159\n",
      "Iteration 5328, loss = 2564.49597976\n",
      "Iteration 5329, loss = 2564.39530524\n",
      "Iteration 5330, loss = 2564.29469800\n",
      "Iteration 5331, loss = 2564.19415803\n",
      "Iteration 5332, loss = 2564.09368531\n",
      "Iteration 5333, loss = 2563.99327980\n",
      "Iteration 5334, loss = 2563.89294149\n",
      "Iteration 5335, loss = 2563.79267036\n",
      "Iteration 5336, loss = 2563.69246639\n",
      "Iteration 5337, loss = 2563.59232954\n",
      "Iteration 5338, loss = 2563.49225980\n",
      "Iteration 5339, loss = 2563.39225715\n",
      "Iteration 5340, loss = 2563.29232157\n",
      "Iteration 5341, loss = 2563.19245302\n",
      "Iteration 5342, loss = 2563.09265150\n",
      "Iteration 5343, loss = 2562.99291698\n",
      "Iteration 5344, loss = 2562.89324943\n",
      "Iteration 5345, loss = 2562.79364884\n",
      "Iteration 5346, loss = 2562.69411517\n",
      "Iteration 5347, loss = 2562.59464842\n",
      "Iteration 5348, loss = 2562.49524855\n",
      "Iteration 5349, loss = 2562.39591555\n",
      "Iteration 5350, loss = 2562.29664939\n",
      "Iteration 5351, loss = 2562.19745005\n",
      "Iteration 5352, loss = 2562.09831751\n",
      "Iteration 5353, loss = 2561.99925175\n",
      "Iteration 5354, loss = 2561.90025274\n",
      "Iteration 5355, loss = 2561.80132046\n",
      "Iteration 5356, loss = 2561.70245488\n",
      "Iteration 5357, loss = 2561.60365600\n",
      "Iteration 5358, loss = 2561.50492378\n",
      "Iteration 5359, loss = 2561.40625820\n",
      "Iteration 5360, loss = 2561.30765924\n",
      "Iteration 5361, loss = 2561.20912688\n",
      "Iteration 5362, loss = 2561.11066110\n",
      "Iteration 5363, loss = 2561.01226187\n",
      "Iteration 5364, loss = 2560.91392917\n",
      "Iteration 5365, loss = 2560.81566298\n",
      "Iteration 5366, loss = 2560.71746327\n",
      "Iteration 5367, loss = 2560.61933003\n",
      "Iteration 5368, loss = 2560.52126323\n",
      "Iteration 5369, loss = 2560.42326285\n",
      "Iteration 5370, loss = 2560.32532887\n",
      "Iteration 5371, loss = 2560.22746126\n",
      "Iteration 5372, loss = 2560.12966001\n",
      "Iteration 5373, loss = 2560.03192508\n",
      "Iteration 5374, loss = 2559.93425647\n",
      "Iteration 5375, loss = 2559.83665414\n",
      "Iteration 5376, loss = 2559.73911807\n",
      "Iteration 5377, loss = 2559.64164825\n",
      "Iteration 5378, loss = 2559.54424464\n",
      "Iteration 5379, loss = 2559.44690723\n",
      "Iteration 5380, loss = 2559.34963600\n",
      "Iteration 5381, loss = 2559.25243092\n",
      "Iteration 5382, loss = 2559.15529197\n",
      "Iteration 5383, loss = 2559.05821912\n",
      "Iteration 5384, loss = 2558.96121236\n",
      "Iteration 5385, loss = 2558.86427167\n",
      "Iteration 5386, loss = 2558.76739701\n",
      "Iteration 5387, loss = 2558.67058838\n",
      "Iteration 5388, loss = 2558.57384574\n",
      "Iteration 5389, loss = 2558.47716907\n",
      "Iteration 5390, loss = 2558.38055836\n",
      "Iteration 5391, loss = 2558.28401357\n",
      "Iteration 5392, loss = 2558.18753469\n",
      "Iteration 5393, loss = 2558.09112170\n",
      "Iteration 5394, loss = 2557.99477456\n",
      "Iteration 5395, loss = 2557.89849327\n",
      "Iteration 5396, loss = 2557.80227780\n",
      "Iteration 5397, loss = 2557.70612812\n",
      "Iteration 5398, loss = 2557.61004421\n",
      "Iteration 5399, loss = 2557.51402606\n",
      "Iteration 5400, loss = 2557.41807363\n",
      "Iteration 5401, loss = 2557.32218691\n",
      "Iteration 5402, loss = 2557.22636588\n",
      "Iteration 5403, loss = 2557.13061050\n",
      "Iteration 5404, loss = 2557.03492076\n",
      "Iteration 5405, loss = 2556.93929665\n",
      "Iteration 5406, loss = 2556.84373812\n",
      "Iteration 5407, loss = 2556.74824517\n",
      "Iteration 5408, loss = 2556.65281776\n",
      "Iteration 5409, loss = 2556.55745589\n",
      "Iteration 5410, loss = 2556.46215952\n",
      "Iteration 5411, loss = 2556.36692863\n",
      "Iteration 5412, loss = 2556.27176320\n",
      "Iteration 5413, loss = 2556.17666321\n",
      "Iteration 5414, loss = 2556.08162864\n",
      "Iteration 5415, loss = 2555.98665946\n",
      "Iteration 5416, loss = 2555.89175565\n",
      "Iteration 5417, loss = 2555.79691719\n",
      "Iteration 5418, loss = 2555.70214405\n",
      "Iteration 5419, loss = 2555.60743622\n",
      "Iteration 5420, loss = 2555.51279368\n",
      "Iteration 5421, loss = 2555.41821639\n",
      "Iteration 5422, loss = 2555.32370433\n",
      "Iteration 5423, loss = 2555.22925750\n",
      "Iteration 5424, loss = 2555.13487585\n",
      "Iteration 5425, loss = 2555.04055937\n",
      "Iteration 5426, loss = 2554.94630804\n",
      "Iteration 5427, loss = 2554.85212184\n",
      "Iteration 5428, loss = 2554.75800074\n",
      "Iteration 5429, loss = 2554.66394472\n",
      "Iteration 5430, loss = 2554.56995375\n",
      "Iteration 5431, loss = 2554.47602783\n",
      "Iteration 5432, loss = 2554.38216691\n",
      "Iteration 5433, loss = 2554.28837099\n",
      "Iteration 5434, loss = 2554.19464003\n",
      "Iteration 5435, loss = 2554.10097402\n",
      "Iteration 5436, loss = 2554.00737294\n",
      "Iteration 5437, loss = 2553.91383675\n",
      "Iteration 5438, loss = 2553.82036545\n",
      "Iteration 5439, loss = 2553.72695900\n",
      "Iteration 5440, loss = 2553.63361738\n",
      "Iteration 5441, loss = 2553.54034058\n",
      "Iteration 5442, loss = 2553.44712857\n",
      "Iteration 5443, loss = 2553.35398132\n",
      "Iteration 5444, loss = 2553.26089882\n",
      "Iteration 5445, loss = 2553.16788104\n",
      "Iteration 5446, loss = 2553.07492795\n",
      "Iteration 5447, loss = 2552.98203955\n",
      "Iteration 5448, loss = 2552.88921580\n",
      "Iteration 5449, loss = 2552.79645668\n",
      "Iteration 5450, loss = 2552.70376218\n",
      "Iteration 5451, loss = 2552.61113226\n",
      "Iteration 5452, loss = 2552.51856690\n",
      "Iteration 5453, loss = 2552.42606609\n",
      "Iteration 5454, loss = 2552.33362980\n",
      "Iteration 5455, loss = 2552.24125801\n",
      "Iteration 5456, loss = 2552.14895069\n",
      "Iteration 5457, loss = 2552.05670782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5458, loss = 2551.96452939\n",
      "Iteration 5459, loss = 2551.87241536\n",
      "Iteration 5460, loss = 2551.78036572\n",
      "Iteration 5461, loss = 2551.68838045\n",
      "Iteration 5462, loss = 2551.59645951\n",
      "Iteration 5463, loss = 2551.50460289\n",
      "Iteration 5464, loss = 2551.41281057\n",
      "Iteration 5465, loss = 2551.32108252\n",
      "Iteration 5466, loss = 2551.22941873\n",
      "Iteration 5467, loss = 2551.13781916\n",
      "Iteration 5468, loss = 2551.04628380\n",
      "Iteration 5469, loss = 2550.95481262\n",
      "Iteration 5470, loss = 2550.86340560\n",
      "Iteration 5471, loss = 2550.77206272\n",
      "Iteration 5472, loss = 2550.68078396\n",
      "Iteration 5473, loss = 2550.58956929\n",
      "Iteration 5474, loss = 2550.49841870\n",
      "Iteration 5475, loss = 2550.40733215\n",
      "Iteration 5476, loss = 2550.31630963\n",
      "Iteration 5477, loss = 2550.22535111\n",
      "Iteration 5478, loss = 2550.13445657\n",
      "Iteration 5479, loss = 2550.04362600\n",
      "Iteration 5480, loss = 2549.95285936\n",
      "Iteration 5481, loss = 2549.86215663\n",
      "Iteration 5482, loss = 2549.77151780\n",
      "Iteration 5483, loss = 2549.68094283\n",
      "Iteration 5484, loss = 2549.59043172\n",
      "Iteration 5485, loss = 2549.49998442\n",
      "Iteration 5486, loss = 2549.40960093\n",
      "Iteration 5487, loss = 2549.31928122\n",
      "Iteration 5488, loss = 2549.22902526\n",
      "Iteration 5489, loss = 2549.13883304\n",
      "Iteration 5490, loss = 2549.04870453\n",
      "Iteration 5491, loss = 2548.95863971\n",
      "Iteration 5492, loss = 2548.86863856\n",
      "Iteration 5493, loss = 2548.77870105\n",
      "Iteration 5494, loss = 2548.68882716\n",
      "Iteration 5495, loss = 2548.59901687\n",
      "Iteration 5496, loss = 2548.50927016\n",
      "Iteration 5497, loss = 2548.41958700\n",
      "Iteration 5498, loss = 2548.32996738\n",
      "Iteration 5499, loss = 2548.24041126\n",
      "Iteration 5500, loss = 2548.15091863\n",
      "Iteration 5501, loss = 2548.06148946\n",
      "Iteration 5502, loss = 2547.97212374\n",
      "Iteration 5503, loss = 2547.88282144\n",
      "Iteration 5504, loss = 2547.79358253\n",
      "Iteration 5505, loss = 2547.70440699\n",
      "Iteration 5506, loss = 2547.61529481\n",
      "Iteration 5507, loss = 2547.52624596\n",
      "Iteration 5508, loss = 2547.43726041\n",
      "Iteration 5509, loss = 2547.34833815\n",
      "Iteration 5510, loss = 2547.25947915\n",
      "Iteration 5511, loss = 2547.17068339\n",
      "Iteration 5512, loss = 2547.08195084\n",
      "Iteration 5513, loss = 2546.99328149\n",
      "Iteration 5514, loss = 2546.90467531\n",
      "Iteration 5515, loss = 2546.81613228\n",
      "Iteration 5516, loss = 2546.72765237\n",
      "Iteration 5517, loss = 2546.63923557\n",
      "Iteration 5518, loss = 2546.55088185\n",
      "Iteration 5519, loss = 2546.46259118\n",
      "Iteration 5520, loss = 2546.37436356\n",
      "Iteration 5521, loss = 2546.28619894\n",
      "Iteration 5522, loss = 2546.19809732\n",
      "Iteration 5523, loss = 2546.11005867\n",
      "Iteration 5524, loss = 2546.02208296\n",
      "Iteration 5525, loss = 2545.93417017\n",
      "Iteration 5526, loss = 2545.84632029\n",
      "Iteration 5527, loss = 2545.75853328\n",
      "Iteration 5528, loss = 2545.67080913\n",
      "Iteration 5529, loss = 2545.58314781\n",
      "Iteration 5530, loss = 2545.49554931\n",
      "Iteration 5531, loss = 2545.40801359\n",
      "Iteration 5532, loss = 2545.32054063\n",
      "Iteration 5533, loss = 2545.23313042\n",
      "Iteration 5534, loss = 2545.14578292\n",
      "Iteration 5535, loss = 2545.05849813\n",
      "Iteration 5536, loss = 2544.97127601\n",
      "Iteration 5537, loss = 2544.88411654\n",
      "Iteration 5538, loss = 2544.79701970\n",
      "Iteration 5539, loss = 2544.70998547\n",
      "Iteration 5540, loss = 2544.62301382\n",
      "Iteration 5541, loss = 2544.53610473\n",
      "Iteration 5542, loss = 2544.44925819\n",
      "Iteration 5543, loss = 2544.36247416\n",
      "Iteration 5544, loss = 2544.27575262\n",
      "Iteration 5545, loss = 2544.18909355\n",
      "Iteration 5546, loss = 2544.10249694\n",
      "Iteration 5547, loss = 2544.01596275\n",
      "Iteration 5548, loss = 2543.92949096\n",
      "Iteration 5549, loss = 2543.84308155\n",
      "Iteration 5550, loss = 2543.75673450\n",
      "Iteration 5551, loss = 2543.67044979\n",
      "Iteration 5552, loss = 2543.58422739\n",
      "Iteration 5553, loss = 2543.49806728\n",
      "Iteration 5554, loss = 2543.41196944\n",
      "Iteration 5555, loss = 2543.32593384\n",
      "Iteration 5556, loss = 2543.23996047\n",
      "Iteration 5557, loss = 2543.15404929\n",
      "Iteration 5558, loss = 2543.06820030\n",
      "Iteration 5559, loss = 2542.98241345\n",
      "Iteration 5560, loss = 2542.89668874\n",
      "Iteration 5561, loss = 2542.81102614\n",
      "Iteration 5562, loss = 2542.72542562\n",
      "Iteration 5563, loss = 2542.63988717\n",
      "Iteration 5564, loss = 2542.55441076\n",
      "Iteration 5565, loss = 2542.46899637\n",
      "Iteration 5566, loss = 2542.38364397\n",
      "Iteration 5567, loss = 2542.29835355\n",
      "Iteration 5568, loss = 2542.21312507\n",
      "Iteration 5569, loss = 2542.12795853\n",
      "Iteration 5570, loss = 2542.04285389\n",
      "Iteration 5571, loss = 2541.95781113\n",
      "Iteration 5572, loss = 2541.87283023\n",
      "Iteration 5573, loss = 2541.78791117\n",
      "Iteration 5574, loss = 2541.70305393\n",
      "Iteration 5575, loss = 2541.61825847\n",
      "Iteration 5576, loss = 2541.53352479\n",
      "Iteration 5577, loss = 2541.44885285\n",
      "Iteration 5578, loss = 2541.36424263\n",
      "Iteration 5579, loss = 2541.27969412\n",
      "Iteration 5580, loss = 2541.19520729\n",
      "Iteration 5581, loss = 2541.11078210\n",
      "Iteration 5582, loss = 2541.02641856\n",
      "Iteration 5583, loss = 2540.94211662\n",
      "Iteration 5584, loss = 2540.85787627\n",
      "Iteration 5585, loss = 2540.77369749\n",
      "Iteration 5586, loss = 2540.68958024\n",
      "Iteration 5587, loss = 2540.60552452\n",
      "Iteration 5588, loss = 2540.52153029\n",
      "Iteration 5589, loss = 2540.43759754\n",
      "Iteration 5590, loss = 2540.35372624\n",
      "Iteration 5591, loss = 2540.26991637\n",
      "Iteration 5592, loss = 2540.18616790\n",
      "Iteration 5593, loss = 2540.10248082\n",
      "Iteration 5594, loss = 2540.01885509\n",
      "Iteration 5595, loss = 2539.93529071\n",
      "Iteration 5596, loss = 2539.85178763\n",
      "Iteration 5597, loss = 2539.76834585\n",
      "Iteration 5598, loss = 2539.68496534\n",
      "Iteration 5599, loss = 2539.60164608\n",
      "Iteration 5600, loss = 2539.51838804\n",
      "Iteration 5601, loss = 2539.43519120\n",
      "Iteration 5602, loss = 2539.35205554\n",
      "Iteration 5603, loss = 2539.26898104\n",
      "Iteration 5604, loss = 2539.18596767\n",
      "Iteration 5605, loss = 2539.10301541\n",
      "Iteration 5606, loss = 2539.02012423\n",
      "Iteration 5607, loss = 2538.93729412\n",
      "Iteration 5608, loss = 2538.85452506\n",
      "Iteration 5609, loss = 2538.77181701\n",
      "Iteration 5610, loss = 2538.68916995\n",
      "Iteration 5611, loss = 2538.60658388\n",
      "Iteration 5612, loss = 2538.52405875\n",
      "Iteration 5613, loss = 2538.44159455\n",
      "Iteration 5614, loss = 2538.35919125\n",
      "Iteration 5615, loss = 2538.27684884\n",
      "Iteration 5616, loss = 2538.19456729\n",
      "Iteration 5617, loss = 2538.11234657\n",
      "Iteration 5618, loss = 2538.03018667\n",
      "Iteration 5619, loss = 2537.94808756\n",
      "Iteration 5620, loss = 2537.86604922\n",
      "Iteration 5621, loss = 2537.78407162\n",
      "Iteration 5622, loss = 2537.70215475\n",
      "Iteration 5623, loss = 2537.62029857\n",
      "Iteration 5624, loss = 2537.53850308\n",
      "Iteration 5625, loss = 2537.45676823\n",
      "Iteration 5626, loss = 2537.37509402\n",
      "Iteration 5627, loss = 2537.29348042\n",
      "Iteration 5628, loss = 2537.21192741\n",
      "Iteration 5629, loss = 2537.13043496\n",
      "Iteration 5630, loss = 2537.04900304\n",
      "Iteration 5631, loss = 2536.96763165\n",
      "Iteration 5632, loss = 2536.88632075\n",
      "Iteration 5633, loss = 2536.80507032\n",
      "Iteration 5634, loss = 2536.72388034\n",
      "Iteration 5635, loss = 2536.64275079\n",
      "Iteration 5636, loss = 2536.56168164\n",
      "Iteration 5637, loss = 2536.48067287\n",
      "Iteration 5638, loss = 2536.39972446\n",
      "Iteration 5639, loss = 2536.31883639\n",
      "Iteration 5640, loss = 2536.23800862\n",
      "Iteration 5641, loss = 2536.15724115\n",
      "Iteration 5642, loss = 2536.07653394\n",
      "Iteration 5643, loss = 2535.99588698\n",
      "Iteration 5644, loss = 2535.91530023\n",
      "Iteration 5645, loss = 2535.83477368\n",
      "Iteration 5646, loss = 2535.75430731\n",
      "Iteration 5647, loss = 2535.67390109\n",
      "Iteration 5648, loss = 2535.59355500\n",
      "Iteration 5649, loss = 2535.51326902\n",
      "Iteration 5650, loss = 2535.43304312\n",
      "Iteration 5651, loss = 2535.35287728\n",
      "Iteration 5652, loss = 2535.27277148\n",
      "Iteration 5653, loss = 2535.19272569\n",
      "Iteration 5654, loss = 2535.11273989\n",
      "Iteration 5655, loss = 2535.03281407\n",
      "Iteration 5656, loss = 2534.95294819\n",
      "Iteration 5657, loss = 2534.87314223\n",
      "Iteration 5658, loss = 2534.79339617\n",
      "Iteration 5659, loss = 2534.71370999\n",
      "Iteration 5660, loss = 2534.63408367\n",
      "Iteration 5661, loss = 2534.55451718\n",
      "Iteration 5662, loss = 2534.47501049\n",
      "Iteration 5663, loss = 2534.39556359\n",
      "Iteration 5664, loss = 2534.31617646\n",
      "Iteration 5665, loss = 2534.23684906\n",
      "Iteration 5666, loss = 2534.15758138\n",
      "Iteration 5667, loss = 2534.07837340\n",
      "Iteration 5668, loss = 2533.99922509\n",
      "Iteration 5669, loss = 2533.92013642\n",
      "Iteration 5670, loss = 2533.84110738\n",
      "Iteration 5671, loss = 2533.76213795\n",
      "Iteration 5672, loss = 2533.68322809\n",
      "Iteration 5673, loss = 2533.60437779\n",
      "Iteration 5674, loss = 2533.52558702\n",
      "Iteration 5675, loss = 2533.44685577\n",
      "Iteration 5676, loss = 2533.36818400\n",
      "Iteration 5677, loss = 2533.28957170\n",
      "Iteration 5678, loss = 2533.21101884\n",
      "Iteration 5679, loss = 2533.13252540\n",
      "Iteration 5680, loss = 2533.05409135\n",
      "Iteration 5681, loss = 2532.97571668\n",
      "Iteration 5682, loss = 2532.89740136\n",
      "Iteration 5683, loss = 2532.81914536\n",
      "Iteration 5684, loss = 2532.74094867\n",
      "Iteration 5685, loss = 2532.66281126\n",
      "Iteration 5686, loss = 2532.58473311\n",
      "Iteration 5687, loss = 2532.50671419\n",
      "Iteration 5688, loss = 2532.42875449\n",
      "Iteration 5689, loss = 2532.35085397\n",
      "Iteration 5690, loss = 2532.27301263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5691, loss = 2532.19523042\n",
      "Iteration 5692, loss = 2532.11750734\n",
      "Iteration 5693, loss = 2532.03984335\n",
      "Iteration 5694, loss = 2531.96223844\n",
      "Iteration 5695, loss = 2531.88469258\n",
      "Iteration 5696, loss = 2531.80720575\n",
      "Iteration 5697, loss = 2531.72977792\n",
      "Iteration 5698, loss = 2531.65240907\n",
      "Iteration 5699, loss = 2531.57509919\n",
      "Iteration 5700, loss = 2531.49784824\n",
      "Iteration 5701, loss = 2531.42065621\n",
      "Iteration 5702, loss = 2531.34352306\n",
      "Iteration 5703, loss = 2531.26644879\n",
      "Iteration 5704, loss = 2531.18943335\n",
      "Iteration 5705, loss = 2531.11247674\n",
      "Iteration 5706, loss = 2531.03557893\n",
      "Iteration 5707, loss = 2530.95873989\n",
      "Iteration 5708, loss = 2530.88195961\n",
      "Iteration 5709, loss = 2530.80523805\n",
      "Iteration 5710, loss = 2530.72857520\n",
      "Iteration 5711, loss = 2530.65197104\n",
      "Iteration 5712, loss = 2530.57542553\n",
      "Iteration 5713, loss = 2530.49893866\n",
      "Iteration 5714, loss = 2530.42251041\n",
      "Iteration 5715, loss = 2530.34614074\n",
      "Iteration 5716, loss = 2530.26982965\n",
      "Iteration 5717, loss = 2530.19357710\n",
      "Iteration 5718, loss = 2530.11738307\n",
      "Iteration 5719, loss = 2530.04124754\n",
      "Iteration 5720, loss = 2529.96517049\n",
      "Iteration 5721, loss = 2529.88915189\n",
      "Iteration 5722, loss = 2529.81319171\n",
      "Iteration 5723, loss = 2529.73728995\n",
      "Iteration 5724, loss = 2529.66144657\n",
      "Iteration 5725, loss = 2529.58566155\n",
      "Iteration 5726, loss = 2529.50993486\n",
      "Iteration 5727, loss = 2529.43426649\n",
      "Iteration 5728, loss = 2529.35865642\n",
      "Iteration 5729, loss = 2529.28310461\n",
      "Iteration 5730, loss = 2529.20761104\n",
      "Iteration 5731, loss = 2529.13217570\n",
      "Iteration 5732, loss = 2529.05679856\n",
      "Iteration 5733, loss = 2528.98147959\n",
      "Iteration 5734, loss = 2528.90621877\n",
      "Iteration 5735, loss = 2528.83101609\n",
      "Iteration 5736, loss = 2528.75587151\n",
      "Iteration 5737, loss = 2528.68078501\n",
      "Iteration 5738, loss = 2528.60575657\n",
      "Iteration 5739, loss = 2528.53078618\n",
      "Iteration 5740, loss = 2528.45587379\n",
      "Iteration 5741, loss = 2528.38101940\n",
      "Iteration 5742, loss = 2528.30622297\n",
      "Iteration 5743, loss = 2528.23148449\n",
      "Iteration 5744, loss = 2528.15680393\n",
      "Iteration 5745, loss = 2528.08218127\n",
      "Iteration 5746, loss = 2528.00761648\n",
      "Iteration 5747, loss = 2527.93310955\n",
      "Iteration 5748, loss = 2527.85866044\n",
      "Iteration 5749, loss = 2527.78426914\n",
      "Iteration 5750, loss = 2527.70993563\n",
      "Iteration 5751, loss = 2527.63565987\n",
      "Iteration 5752, loss = 2527.56144185\n",
      "Iteration 5753, loss = 2527.48728154\n",
      "Iteration 5754, loss = 2527.41317892\n",
      "Iteration 5755, loss = 2527.33913397\n",
      "Iteration 5756, loss = 2527.26514667\n",
      "Iteration 5757, loss = 2527.19121698\n",
      "Iteration 5758, loss = 2527.11734489\n",
      "Iteration 5759, loss = 2527.04353038\n",
      "Iteration 5760, loss = 2526.96977341\n",
      "Iteration 5761, loss = 2526.89607398\n",
      "Iteration 5762, loss = 2526.82243205\n",
      "Iteration 5763, loss = 2526.74884760\n",
      "Iteration 5764, loss = 2526.67532061\n",
      "Iteration 5765, loss = 2526.60185105\n",
      "Iteration 5766, loss = 2526.52843891\n",
      "Iteration 5767, loss = 2526.45508415\n",
      "Iteration 5768, loss = 2526.38178676\n",
      "Iteration 5769, loss = 2526.30854672\n",
      "Iteration 5770, loss = 2526.23536399\n",
      "Iteration 5771, loss = 2526.16223856\n",
      "Iteration 5772, loss = 2526.08917040\n",
      "Iteration 5773, loss = 2526.01615949\n",
      "Iteration 5774, loss = 2525.94320581\n",
      "Iteration 5775, loss = 2525.87030933\n",
      "Iteration 5776, loss = 2525.79747003\n",
      "Iteration 5777, loss = 2525.72468788\n",
      "Iteration 5778, loss = 2525.65196287\n",
      "Iteration 5779, loss = 2525.57929497\n",
      "Iteration 5780, loss = 2525.50668416\n",
      "Iteration 5781, loss = 2525.43413041\n",
      "Iteration 5782, loss = 2525.36163370\n",
      "Iteration 5783, loss = 2525.28919401\n",
      "Iteration 5784, loss = 2525.21681131\n",
      "Iteration 5785, loss = 2525.14448559\n",
      "Iteration 5786, loss = 2525.07221681\n",
      "Iteration 5787, loss = 2525.00000496\n",
      "Iteration 5788, loss = 2524.92785000\n",
      "Iteration 5789, loss = 2524.85575193\n",
      "Iteration 5790, loss = 2524.78371071\n",
      "Iteration 5791, loss = 2524.71172632\n",
      "Iteration 5792, loss = 2524.63979873\n",
      "Iteration 5793, loss = 2524.56792794\n",
      "Iteration 5794, loss = 2524.49611390\n",
      "Iteration 5795, loss = 2524.42435660\n",
      "Iteration 5796, loss = 2524.35265602\n",
      "Iteration 5797, loss = 2524.28101213\n",
      "Iteration 5798, loss = 2524.20942491\n",
      "Iteration 5799, loss = 2524.13789433\n",
      "Iteration 5800, loss = 2524.06642038\n",
      "Iteration 5801, loss = 2523.99500302\n",
      "Iteration 5802, loss = 2523.92364224\n",
      "Iteration 5803, loss = 2523.85233801\n",
      "Iteration 5804, loss = 2523.78109030\n",
      "Iteration 5805, loss = 2523.70989911\n",
      "Iteration 5806, loss = 2523.63876439\n",
      "Iteration 5807, loss = 2523.56768614\n",
      "Iteration 5808, loss = 2523.49666432\n",
      "Iteration 5809, loss = 2523.42569891\n",
      "Iteration 5810, loss = 2523.35478989\n",
      "Iteration 5811, loss = 2523.28393723\n",
      "Iteration 5812, loss = 2523.21314092\n",
      "Iteration 5813, loss = 2523.14240093\n",
      "Iteration 5814, loss = 2523.07171723\n",
      "Iteration 5815, loss = 2523.00108980\n",
      "Iteration 5816, loss = 2522.93051863\n",
      "Iteration 5817, loss = 2522.86000368\n",
      "Iteration 5818, loss = 2522.78954493\n",
      "Iteration 5819, loss = 2522.71914235\n",
      "Iteration 5820, loss = 2522.64879594\n",
      "Iteration 5821, loss = 2522.57850565\n",
      "Iteration 5822, loss = 2522.50827148\n",
      "Iteration 5823, loss = 2522.43809339\n",
      "Iteration 5824, loss = 2522.36797136\n",
      "Iteration 5825, loss = 2522.29790537\n",
      "Iteration 5826, loss = 2522.22789540\n",
      "Iteration 5827, loss = 2522.15794141\n",
      "Iteration 5828, loss = 2522.08804340\n",
      "Iteration 5829, loss = 2522.01820133\n",
      "Iteration 5830, loss = 2521.94841518\n",
      "Iteration 5831, loss = 2521.87868493\n",
      "Iteration 5832, loss = 2521.80901056\n",
      "Iteration 5833, loss = 2521.73939203\n",
      "Iteration 5834, loss = 2521.66982934\n",
      "Iteration 5835, loss = 2521.60032245\n",
      "Iteration 5836, loss = 2521.53087134\n",
      "Iteration 5837, loss = 2521.46147599\n",
      "Iteration 5838, loss = 2521.39213637\n",
      "Iteration 5839, loss = 2521.32285247\n",
      "Iteration 5840, loss = 2521.25362425\n",
      "Iteration 5841, loss = 2521.18445170\n",
      "Iteration 5842, loss = 2521.11533479\n",
      "Iteration 5843, loss = 2521.04627349\n",
      "Iteration 5844, loss = 2520.97726779\n",
      "Iteration 5845, loss = 2520.90831766\n",
      "Iteration 5846, loss = 2520.83942308\n",
      "Iteration 5847, loss = 2520.77058402\n",
      "Iteration 5848, loss = 2520.70180046\n",
      "Iteration 5849, loss = 2520.63307238\n",
      "Iteration 5850, loss = 2520.56439975\n",
      "Iteration 5851, loss = 2520.49578255\n",
      "Iteration 5852, loss = 2520.42722076\n",
      "Iteration 5853, loss = 2520.35871435\n",
      "Iteration 5854, loss = 2520.29026330\n",
      "Iteration 5855, loss = 2520.22186759\n",
      "Iteration 5856, loss = 2520.15352719\n",
      "Iteration 5857, loss = 2520.08524207\n",
      "Iteration 5858, loss = 2520.01701223\n",
      "Iteration 5859, loss = 2519.94883763\n",
      "Iteration 5860, loss = 2519.88071824\n",
      "Iteration 5861, loss = 2519.81265405\n",
      "Iteration 5862, loss = 2519.74464504\n",
      "Iteration 5863, loss = 2519.67669117\n",
      "Iteration 5864, loss = 2519.60879242\n",
      "Iteration 5865, loss = 2519.54094878\n",
      "Iteration 5866, loss = 2519.47316022\n",
      "Iteration 5867, loss = 2519.40542671\n",
      "Iteration 5868, loss = 2519.33774823\n",
      "Iteration 5869, loss = 2519.27012476\n",
      "Iteration 5870, loss = 2519.20255627\n",
      "Iteration 5871, loss = 2519.13504275\n",
      "Iteration 5872, loss = 2519.06758416\n",
      "Iteration 5873, loss = 2519.00018048\n",
      "Iteration 5874, loss = 2518.93283169\n",
      "Iteration 5875, loss = 2518.86553777\n",
      "Iteration 5876, loss = 2518.79829870\n",
      "Iteration 5877, loss = 2518.73111444\n",
      "Iteration 5878, loss = 2518.66398498\n",
      "Iteration 5879, loss = 2518.59691029\n",
      "Iteration 5880, loss = 2518.52989035\n",
      "Iteration 5881, loss = 2518.46292513\n",
      "Iteration 5882, loss = 2518.39601462\n",
      "Iteration 5883, loss = 2518.32915879\n",
      "Iteration 5884, loss = 2518.26235761\n",
      "Iteration 5885, loss = 2518.19561106\n",
      "Iteration 5886, loss = 2518.12891911\n",
      "Iteration 5887, loss = 2518.06228176\n",
      "Iteration 5888, loss = 2517.99569896\n",
      "Iteration 5889, loss = 2517.92917070\n",
      "Iteration 5890, loss = 2517.86269695\n",
      "Iteration 5891, loss = 2517.79627769\n",
      "Iteration 5892, loss = 2517.72991290\n",
      "Iteration 5893, loss = 2517.66360255\n",
      "Iteration 5894, loss = 2517.59734663\n",
      "Iteration 5895, loss = 2517.53114509\n",
      "Iteration 5896, loss = 2517.46499793\n",
      "Iteration 5897, loss = 2517.39890511\n",
      "Iteration 5898, loss = 2517.33286663\n",
      "Iteration 5899, loss = 2517.26688244\n",
      "Iteration 5900, loss = 2517.20095253\n",
      "Iteration 5901, loss = 2517.13507687\n",
      "Iteration 5902, loss = 2517.06925544\n",
      "Iteration 5903, loss = 2517.00348822\n",
      "Iteration 5904, loss = 2516.93777519\n",
      "Iteration 5905, loss = 2516.87211631\n",
      "Iteration 5906, loss = 2516.80651157\n",
      "Iteration 5907, loss = 2516.74096094\n",
      "Iteration 5908, loss = 2516.67546440\n",
      "Iteration 5909, loss = 2516.61002193\n",
      "Iteration 5910, loss = 2516.54463349\n",
      "Iteration 5911, loss = 2516.47929908\n",
      "Iteration 5912, loss = 2516.41401865\n",
      "Iteration 5913, loss = 2516.34879220\n",
      "Iteration 5914, loss = 2516.28361970\n",
      "Iteration 5915, loss = 2516.21850112\n",
      "Iteration 5916, loss = 2516.15343643\n",
      "Iteration 5917, loss = 2516.08842563\n",
      "Iteration 5918, loss = 2516.02346868\n",
      "Iteration 5919, loss = 2515.95856555\n",
      "Iteration 5920, loss = 2515.89371623\n",
      "Iteration 5921, loss = 2515.82892069\n",
      "Iteration 5922, loss = 2515.76417891\n",
      "Iteration 5923, loss = 2515.69949086\n",
      "Iteration 5924, loss = 2515.63485653\n",
      "Iteration 5925, loss = 2515.57027588\n",
      "Iteration 5926, loss = 2515.50574889\n",
      "Iteration 5927, loss = 2515.44127554\n",
      "Iteration 5928, loss = 2515.37685581\n",
      "Iteration 5929, loss = 2515.31248967\n",
      "Iteration 5930, loss = 2515.24817710\n",
      "Iteration 5931, loss = 2515.18391807\n",
      "Iteration 5932, loss = 2515.11971257\n",
      "Iteration 5933, loss = 2515.05556056\n",
      "Iteration 5934, loss = 2514.99146202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5935, loss = 2514.92741693\n",
      "Iteration 5936, loss = 2514.86342527\n",
      "Iteration 5937, loss = 2514.79948702\n",
      "Iteration 5938, loss = 2514.73560214\n",
      "Iteration 5939, loss = 2514.67177061\n",
      "Iteration 5940, loss = 2514.60799242\n",
      "Iteration 5941, loss = 2514.54426754\n",
      "Iteration 5942, loss = 2514.48059593\n",
      "Iteration 5943, loss = 2514.41697759\n",
      "Iteration 5944, loss = 2514.35341249\n",
      "Iteration 5945, loss = 2514.28990059\n",
      "Iteration 5946, loss = 2514.22644189\n",
      "Iteration 5947, loss = 2514.16303635\n",
      "Iteration 5948, loss = 2514.09968395\n",
      "Iteration 5949, loss = 2514.03638467\n",
      "Iteration 5950, loss = 2513.97313849\n",
      "Iteration 5951, loss = 2513.90994537\n",
      "Iteration 5952, loss = 2513.84680530\n",
      "Iteration 5953, loss = 2513.78371825\n",
      "Iteration 5954, loss = 2513.72068420\n",
      "Iteration 5955, loss = 2513.65770313\n",
      "Iteration 5956, loss = 2513.59477501\n",
      "Iteration 5957, loss = 2513.53189981\n",
      "Iteration 5958, loss = 2513.46907752\n",
      "Iteration 5959, loss = 2513.40630811\n",
      "Iteration 5960, loss = 2513.34359156\n",
      "Iteration 5961, loss = 2513.28092783\n",
      "Iteration 5962, loss = 2513.21831692\n",
      "Iteration 5963, loss = 2513.15575879\n",
      "Iteration 5964, loss = 2513.09325342\n",
      "Iteration 5965, loss = 2513.03080079\n",
      "Iteration 5966, loss = 2512.96840087\n",
      "Iteration 5967, loss = 2512.90605364\n",
      "Iteration 5968, loss = 2512.84375908\n",
      "Iteration 5969, loss = 2512.78151716\n",
      "Iteration 5970, loss = 2512.71932786\n",
      "Iteration 5971, loss = 2512.65719115\n",
      "Iteration 5972, loss = 2512.59510701\n",
      "Iteration 5973, loss = 2512.53307542\n",
      "Iteration 5974, loss = 2512.47109635\n",
      "Iteration 5975, loss = 2512.40916978\n",
      "Iteration 5976, loss = 2512.34729569\n",
      "Iteration 5977, loss = 2512.28547405\n",
      "Iteration 5978, loss = 2512.22370483\n",
      "Iteration 5979, loss = 2512.16198802\n",
      "Iteration 5980, loss = 2512.10032359\n",
      "Iteration 5981, loss = 2512.03871151\n",
      "Iteration 5982, loss = 2511.97715177\n",
      "Iteration 5983, loss = 2511.91564434\n",
      "Iteration 5984, loss = 2511.85418919\n",
      "Iteration 5985, loss = 2511.79278629\n",
      "Iteration 5986, loss = 2511.73143564\n",
      "Iteration 5987, loss = 2511.67013720\n",
      "Iteration 5988, loss = 2511.60889095\n",
      "Iteration 5989, loss = 2511.54769686\n",
      "Iteration 5990, loss = 2511.48655492\n",
      "Iteration 5991, loss = 2511.42546509\n",
      "Iteration 5992, loss = 2511.36442735\n",
      "Iteration 5993, loss = 2511.30344169\n",
      "Iteration 5994, loss = 2511.24250807\n",
      "Iteration 5995, loss = 2511.18162647\n",
      "Iteration 5996, loss = 2511.12079687\n",
      "Iteration 5997, loss = 2511.06001924\n",
      "Iteration 5998, loss = 2510.99929357\n",
      "Iteration 5999, loss = 2510.93861982\n",
      "Iteration 6000, loss = 2510.87799797\n",
      "Iteration 6001, loss = 2510.81742800\n",
      "Iteration 6002, loss = 2510.75690988\n",
      "Iteration 6003, loss = 2510.69644360\n",
      "Iteration 6004, loss = 2510.63602912\n",
      "Iteration 6005, loss = 2510.57566643\n",
      "Iteration 6006, loss = 2510.51535549\n",
      "Iteration 6007, loss = 2510.45509629\n",
      "Iteration 6008, loss = 2510.39488880\n",
      "Iteration 6009, loss = 2510.33473299\n",
      "Iteration 6010, loss = 2510.27462885\n",
      "Iteration 6011, loss = 2510.21457635\n",
      "Iteration 6012, loss = 2510.15457546\n",
      "Iteration 6013, loss = 2510.09462616\n",
      "Iteration 6014, loss = 2510.03472844\n",
      "Iteration 6015, loss = 2509.97488225\n",
      "Iteration 6016, loss = 2509.91508758\n",
      "Iteration 6017, loss = 2509.85534441\n",
      "Iteration 6018, loss = 2509.79565271\n",
      "Iteration 6019, loss = 2509.73601246\n",
      "Iteration 6020, loss = 2509.67642363\n",
      "Iteration 6021, loss = 2509.61688620\n",
      "Iteration 6022, loss = 2509.55740015\n",
      "Iteration 6023, loss = 2509.49796544\n",
      "Iteration 6024, loss = 2509.43858207\n",
      "Iteration 6025, loss = 2509.37924999\n",
      "Iteration 6026, loss = 2509.31996920\n",
      "Iteration 6027, loss = 2509.26073966\n",
      "Iteration 6028, loss = 2509.20156136\n",
      "Iteration 6029, loss = 2509.14243426\n",
      "Iteration 6030, loss = 2509.08335834\n",
      "Iteration 6031, loss = 2509.02433359\n",
      "Iteration 6032, loss = 2508.96535997\n",
      "Iteration 6033, loss = 2508.90643746\n",
      "Iteration 6034, loss = 2508.84756604\n",
      "Iteration 6035, loss = 2508.78874568\n",
      "Iteration 6036, loss = 2508.72997636\n",
      "Iteration 6037, loss = 2508.67125806\n",
      "Iteration 6038, loss = 2508.61259074\n",
      "Iteration 6039, loss = 2508.55397440\n",
      "Iteration 6040, loss = 2508.49540900\n",
      "Iteration 6041, loss = 2508.43689451\n",
      "Iteration 6042, loss = 2508.37843093\n",
      "Iteration 6043, loss = 2508.32001821\n",
      "Iteration 6044, loss = 2508.26165634\n",
      "Iteration 6045, loss = 2508.20334529\n",
      "Iteration 6046, loss = 2508.14508505\n",
      "Iteration 6047, loss = 2508.08687557\n",
      "Iteration 6048, loss = 2508.02871685\n",
      "Iteration 6049, loss = 2507.97060886\n",
      "Iteration 6050, loss = 2507.91255156\n",
      "Iteration 6051, loss = 2507.85454495\n",
      "Iteration 6052, loss = 2507.79658899\n",
      "Iteration 6053, loss = 2507.73868366\n",
      "Iteration 6054, loss = 2507.68082894\n",
      "Iteration 6055, loss = 2507.62302480\n",
      "Iteration 6056, loss = 2507.56527121\n",
      "Iteration 6057, loss = 2507.50756817\n",
      "Iteration 6058, loss = 2507.44991563\n",
      "Iteration 6059, loss = 2507.39231357\n",
      "Iteration 6060, loss = 2507.33476198\n",
      "Iteration 6061, loss = 2507.27726083\n",
      "Iteration 6062, loss = 2507.21981009\n",
      "Iteration 6063, loss = 2507.16240974\n",
      "Iteration 6064, loss = 2507.10505976\n",
      "Iteration 6065, loss = 2507.04776011\n",
      "Iteration 6066, loss = 2506.99051079\n",
      "Iteration 6067, loss = 2506.93331175\n",
      "Iteration 6068, loss = 2506.87616299\n",
      "Iteration 6069, loss = 2506.81906447\n",
      "Iteration 6070, loss = 2506.76201617\n",
      "Iteration 6071, loss = 2506.70501806\n",
      "Iteration 6072, loss = 2506.64807013\n",
      "Iteration 6073, loss = 2506.59117235\n",
      "Iteration 6074, loss = 2506.53432469\n",
      "Iteration 6075, loss = 2506.47752713\n",
      "Iteration 6076, loss = 2506.42077965\n",
      "Iteration 6077, loss = 2506.36408222\n",
      "Iteration 6078, loss = 2506.30743481\n",
      "Iteration 6079, loss = 2506.25083741\n",
      "Iteration 6080, loss = 2506.19428999\n",
      "Iteration 6081, loss = 2506.13779252\n",
      "Iteration 6082, loss = 2506.08134499\n",
      "Iteration 6083, loss = 2506.02494736\n",
      "Iteration 6084, loss = 2505.96859961\n",
      "Iteration 6085, loss = 2505.91230172\n",
      "Iteration 6086, loss = 2505.85605366\n",
      "Iteration 6087, loss = 2505.79985542\n",
      "Iteration 6088, loss = 2505.74370696\n",
      "Iteration 6089, loss = 2505.68760826\n",
      "Iteration 6090, loss = 2505.63155930\n",
      "Iteration 6091, loss = 2505.57556005\n",
      "Iteration 6092, loss = 2505.51961049\n",
      "Iteration 6093, loss = 2505.46371059\n",
      "Iteration 6094, loss = 2505.40786034\n",
      "Iteration 6095, loss = 2505.35205970\n",
      "Iteration 6096, loss = 2505.29630865\n",
      "Iteration 6097, loss = 2505.24060717\n",
      "Iteration 6098, loss = 2505.18495524\n",
      "Iteration 6099, loss = 2505.12935282\n",
      "Iteration 6100, loss = 2505.07379990\n",
      "Iteration 6101, loss = 2505.01829645\n",
      "Iteration 6102, loss = 2504.96284244\n",
      "Iteration 6103, loss = 2504.90743786\n",
      "Iteration 6104, loss = 2504.85208268\n",
      "Iteration 6105, loss = 2504.79677687\n",
      "Iteration 6106, loss = 2504.74152041\n",
      "Iteration 6107, loss = 2504.68631327\n",
      "Iteration 6108, loss = 2504.63115544\n",
      "Iteration 6109, loss = 2504.57604688\n",
      "Iteration 6110, loss = 2504.52098758\n",
      "Iteration 6111, loss = 2504.46597750\n",
      "Iteration 6112, loss = 2504.41101663\n",
      "Iteration 6113, loss = 2504.35610494\n",
      "Iteration 6114, loss = 2504.30124240\n",
      "Iteration 6115, loss = 2504.24642899\n",
      "Iteration 6116, loss = 2504.19166469\n",
      "Iteration 6117, loss = 2504.13694948\n",
      "Iteration 6118, loss = 2504.08228332\n",
      "Iteration 6119, loss = 2504.02766620\n",
      "Iteration 6120, loss = 2503.97309808\n",
      "Iteration 6121, loss = 2503.91857895\n",
      "Iteration 6122, loss = 2503.86410878\n",
      "Iteration 6123, loss = 2503.80968755\n",
      "Iteration 6124, loss = 2503.75531524\n",
      "Iteration 6125, loss = 2503.70099180\n",
      "Iteration 6126, loss = 2503.64671724\n",
      "Iteration 6127, loss = 2503.59249151\n",
      "Iteration 6128, loss = 2503.53831460\n",
      "Iteration 6129, loss = 2503.48418648\n",
      "Iteration 6130, loss = 2503.43010713\n",
      "Iteration 6131, loss = 2503.37607651\n",
      "Iteration 6132, loss = 2503.32209462\n",
      "Iteration 6133, loss = 2503.26816142\n",
      "Iteration 6134, loss = 2503.21427689\n",
      "Iteration 6135, loss = 2503.16044100\n",
      "Iteration 6136, loss = 2503.10665374\n",
      "Iteration 6137, loss = 2503.05291507\n",
      "Iteration 6138, loss = 2502.99922497\n",
      "Iteration 6139, loss = 2502.94558342\n",
      "Iteration 6140, loss = 2502.89199040\n",
      "Iteration 6141, loss = 2502.83844587\n",
      "Iteration 6142, loss = 2502.78494981\n",
      "Iteration 6143, loss = 2502.73150221\n",
      "Iteration 6144, loss = 2502.67810303\n",
      "Iteration 6145, loss = 2502.62475226\n",
      "Iteration 6146, loss = 2502.57144986\n",
      "Iteration 6147, loss = 2502.51819581\n",
      "Iteration 6148, loss = 2502.46499009\n",
      "Iteration 6149, loss = 2502.41183268\n",
      "Iteration 6150, loss = 2502.35872354\n",
      "Iteration 6151, loss = 2502.30566266\n",
      "Iteration 6152, loss = 2502.25265001\n",
      "Iteration 6153, loss = 2502.19968557\n",
      "Iteration 6154, loss = 2502.14676931\n",
      "Iteration 6155, loss = 2502.09390120\n",
      "Iteration 6156, loss = 2502.04108123\n",
      "Iteration 6157, loss = 2501.98830937\n",
      "Iteration 6158, loss = 2501.93558559\n",
      "Iteration 6159, loss = 2501.88290987\n",
      "Iteration 6160, loss = 2501.83028219\n",
      "Iteration 6161, loss = 2501.77770252\n",
      "Iteration 6162, loss = 2501.72517083\n",
      "Iteration 6163, loss = 2501.67268711\n",
      "Iteration 6164, loss = 2501.62025132\n",
      "Iteration 6165, loss = 2501.56786345\n",
      "Iteration 6166, loss = 2501.51552346\n",
      "Iteration 6167, loss = 2501.46323134\n",
      "Iteration 6168, loss = 2501.41098706\n",
      "Iteration 6169, loss = 2501.35879059\n",
      "Iteration 6170, loss = 2501.30664192\n",
      "Iteration 6171, loss = 2501.25454101\n",
      "Iteration 6172, loss = 2501.20248785\n",
      "Iteration 6173, loss = 2501.15048240\n",
      "Iteration 6174, loss = 2501.09852464\n",
      "Iteration 6175, loss = 2501.04661455\n",
      "Iteration 6176, loss = 2500.99475211\n",
      "Iteration 6177, loss = 2500.94293729\n",
      "Iteration 6178, loss = 2500.89117006\n",
      "Iteration 6179, loss = 2500.83945040\n",
      "Iteration 6180, loss = 2500.78777829\n",
      "Iteration 6181, loss = 2500.73615370\n",
      "Iteration 6182, loss = 2500.68457661\n",
      "Iteration 6183, loss = 2500.63304699\n",
      "Iteration 6184, loss = 2500.58156482\n",
      "Iteration 6185, loss = 2500.53013007\n",
      "Iteration 6186, loss = 2500.47874272\n",
      "Iteration 6187, loss = 2500.42740275\n",
      "Iteration 6188, loss = 2500.37611013\n",
      "Iteration 6189, loss = 2500.32486483\n",
      "Iteration 6190, loss = 2500.27366683\n",
      "Iteration 6191, loss = 2500.22251611\n",
      "Iteration 6192, loss = 2500.17141265\n",
      "Iteration 6193, loss = 2500.12035641\n",
      "Iteration 6194, loss = 2500.06934737\n",
      "Iteration 6195, loss = 2500.01838551\n",
      "Iteration 6196, loss = 2499.96747080\n",
      "Iteration 6197, loss = 2499.91660323\n",
      "Iteration 6198, loss = 2499.86578276\n",
      "Iteration 6199, loss = 2499.81500937\n",
      "Iteration 6200, loss = 2499.76428303\n",
      "Iteration 6201, loss = 2499.71360373\n",
      "Iteration 6202, loss = 2499.66297144\n",
      "Iteration 6203, loss = 2499.61238612\n",
      "Iteration 6204, loss = 2499.56184776\n",
      "Iteration 6205, loss = 2499.51135634\n",
      "Iteration 6206, loss = 2499.46091183\n",
      "Iteration 6207, loss = 2499.41051419\n",
      "Iteration 6208, loss = 2499.36016342\n",
      "Iteration 6209, loss = 2499.30985949\n",
      "Iteration 6210, loss = 2499.25960236\n",
      "Iteration 6211, loss = 2499.20939202\n",
      "Iteration 6212, loss = 2499.15922844\n",
      "Iteration 6213, loss = 2499.10911159\n",
      "Iteration 6214, loss = 2499.05904146\n",
      "Iteration 6215, loss = 2499.00901801\n",
      "Iteration 6216, loss = 2498.95904123\n",
      "Iteration 6217, loss = 2498.90911109\n",
      "Iteration 6218, loss = 2498.85922755\n",
      "Iteration 6219, loss = 2498.80939061\n",
      "Iteration 6220, loss = 2498.75960023\n",
      "Iteration 6221, loss = 2498.70985639\n",
      "Iteration 6222, loss = 2498.66015907\n",
      "Iteration 6223, loss = 2498.61050824\n",
      "Iteration 6224, loss = 2498.56090387\n",
      "Iteration 6225, loss = 2498.51134594\n",
      "Iteration 6226, loss = 2498.46183443\n",
      "Iteration 6227, loss = 2498.41236931\n",
      "Iteration 6228, loss = 2498.36295056\n",
      "Iteration 6229, loss = 2498.31357815\n",
      "Iteration 6230, loss = 2498.26425206\n",
      "Iteration 6231, loss = 2498.21497226\n",
      "Iteration 6232, loss = 2498.16573873\n",
      "Iteration 6233, loss = 2498.11655145\n",
      "Iteration 6234, loss = 2498.06741038\n",
      "Iteration 6235, loss = 2498.01831551\n",
      "Iteration 6236, loss = 2497.96926681\n",
      "Iteration 6237, loss = 2497.92026425\n",
      "Iteration 6238, loss = 2497.87130782\n",
      "Iteration 6239, loss = 2497.82239748\n",
      "Iteration 6240, loss = 2497.77353321\n",
      "Iteration 6241, loss = 2497.72471498\n",
      "Iteration 6242, loss = 2497.67594278\n",
      "Iteration 6243, loss = 2497.62721658\n",
      "Iteration 6244, loss = 2497.57853635\n",
      "Iteration 6245, loss = 2497.52990207\n",
      "Iteration 6246, loss = 2497.48131371\n",
      "Iteration 6247, loss = 2497.43277125\n",
      "Iteration 6248, loss = 2497.38427466\n",
      "Iteration 6249, loss = 2497.33582392\n",
      "Iteration 6250, loss = 2497.28741901\n",
      "Iteration 6251, loss = 2497.23905989\n",
      "Iteration 6252, loss = 2497.19074655\n",
      "Iteration 6253, loss = 2497.14247896\n",
      "Iteration 6254, loss = 2497.09425710\n",
      "Iteration 6255, loss = 2497.04608094\n",
      "Iteration 6256, loss = 2496.99795045\n",
      "Iteration 6257, loss = 2496.94986562\n",
      "Iteration 6258, loss = 2496.90182641\n",
      "Iteration 6259, loss = 2496.85383280\n",
      "Iteration 6260, loss = 2496.80588477\n",
      "Iteration 6261, loss = 2496.75798229\n",
      "Iteration 6262, loss = 2496.71012534\n",
      "Iteration 6263, loss = 2496.66231389\n",
      "Iteration 6264, loss = 2496.61454793\n",
      "Iteration 6265, loss = 2496.56682741\n",
      "Iteration 6266, loss = 2496.51915232\n",
      "Iteration 6267, loss = 2496.47152264\n",
      "Iteration 6268, loss = 2496.42393834\n",
      "Iteration 6269, loss = 2496.37639939\n",
      "Iteration 6270, loss = 2496.32890577\n",
      "Iteration 6271, loss = 2496.28145745\n",
      "Iteration 6272, loss = 2496.23405442\n",
      "Iteration 6273, loss = 2496.18669664\n",
      "Iteration 6274, loss = 2496.13938409\n",
      "Iteration 6275, loss = 2496.09211674\n",
      "Iteration 6276, loss = 2496.04489458\n",
      "Iteration 6277, loss = 2495.99771757\n",
      "Iteration 6278, loss = 2495.95058570\n",
      "Iteration 6279, loss = 2495.90349893\n",
      "Iteration 6280, loss = 2495.85645724\n",
      "Iteration 6281, loss = 2495.80946061\n",
      "Iteration 6282, loss = 2495.76250901\n",
      "Iteration 6283, loss = 2495.71560242\n",
      "Iteration 6284, loss = 2495.66874082\n",
      "Iteration 6285, loss = 2495.62192416\n",
      "Iteration 6286, loss = 2495.57515245\n",
      "Iteration 6287, loss = 2495.52842564\n",
      "Iteration 6288, loss = 2495.48174371\n",
      "Iteration 6289, loss = 2495.43510664\n",
      "Iteration 6290, loss = 2495.38851441\n",
      "Iteration 6291, loss = 2495.34196699\n",
      "Iteration 6292, loss = 2495.29546434\n",
      "Iteration 6293, loss = 2495.24900646\n",
      "Iteration 6294, loss = 2495.20259331\n",
      "Iteration 6295, loss = 2495.15622488\n",
      "Iteration 6296, loss = 2495.10990112\n",
      "Iteration 6297, loss = 2495.06362203\n",
      "Iteration 6298, loss = 2495.01738757\n",
      "Iteration 6299, loss = 2494.97119772\n",
      "Iteration 6300, loss = 2494.92505245\n",
      "Iteration 6301, loss = 2494.87895175\n",
      "Iteration 6302, loss = 2494.83289558\n",
      "Iteration 6303, loss = 2494.78688392\n",
      "Iteration 6304, loss = 2494.74091675\n",
      "Iteration 6305, loss = 2494.69499404\n",
      "Iteration 6306, loss = 2494.64911577\n",
      "Iteration 6307, loss = 2494.60328190\n",
      "Iteration 6308, loss = 2494.55749242\n",
      "Iteration 6309, loss = 2494.51174731\n",
      "Iteration 6310, loss = 2494.46604653\n",
      "Iteration 6311, loss = 2494.42039006\n",
      "Iteration 6312, loss = 2494.37477788\n",
      "Iteration 6313, loss = 2494.32920996\n",
      "Iteration 6314, loss = 2494.28368627\n",
      "Iteration 6315, loss = 2494.23820680\n",
      "Iteration 6316, loss = 2494.19277152\n",
      "Iteration 6317, loss = 2494.14738039\n",
      "Iteration 6318, loss = 2494.10203341\n",
      "Iteration 6319, loss = 2494.05673054\n",
      "Iteration 6320, loss = 2494.01147175\n",
      "Iteration 6321, loss = 2493.96625703\n",
      "Iteration 6322, loss = 2493.92108634\n",
      "Iteration 6323, loss = 2493.87595967\n",
      "Iteration 6324, loss = 2493.83087698\n",
      "Iteration 6325, loss = 2493.78583826\n",
      "Iteration 6326, loss = 2493.74084348\n",
      "Iteration 6327, loss = 2493.69589260\n",
      "Iteration 6328, loss = 2493.65098562\n",
      "Iteration 6329, loss = 2493.60612250\n",
      "Iteration 6330, loss = 2493.56130322\n",
      "Iteration 6331, loss = 2493.51652775\n",
      "Iteration 6332, loss = 2493.47179606\n",
      "Iteration 6333, loss = 2493.42710815\n",
      "Iteration 6334, loss = 2493.38246397\n",
      "Iteration 6335, loss = 2493.33786350\n",
      "Iteration 6336, loss = 2493.29330672\n",
      "Iteration 6337, loss = 2493.24879360\n",
      "Iteration 6338, loss = 2493.20432413\n",
      "Iteration 6339, loss = 2493.15989826\n",
      "Iteration 6340, loss = 2493.11551599\n",
      "Iteration 6341, loss = 2493.07117728\n",
      "Iteration 6342, loss = 2493.02688210\n",
      "Iteration 6343, loss = 2492.98263044\n",
      "Iteration 6344, loss = 2492.93842227\n",
      "Iteration 6345, loss = 2492.89425756\n",
      "Iteration 6346, loss = 2492.85013629\n",
      "Iteration 6347, loss = 2492.80605844\n",
      "Iteration 6348, loss = 2492.76202397\n",
      "Iteration 6349, loss = 2492.71803287\n",
      "Iteration 6350, loss = 2492.67408510\n",
      "Iteration 6351, loss = 2492.63018065\n",
      "Iteration 6352, loss = 2492.58631949\n",
      "Iteration 6353, loss = 2492.54250159\n",
      "Iteration 6354, loss = 2492.49872692\n",
      "Iteration 6355, loss = 2492.45499548\n",
      "Iteration 6356, loss = 2492.41130722\n",
      "Iteration 6357, loss = 2492.36766212\n",
      "Iteration 6358, loss = 2492.32406016\n",
      "Iteration 6359, loss = 2492.28050132\n",
      "Iteration 6360, loss = 2492.23698556\n",
      "Iteration 6361, loss = 2492.19351287\n",
      "Iteration 6362, loss = 2492.15008321\n",
      "Iteration 6363, loss = 2492.10669657\n",
      "Iteration 6364, loss = 2492.06335291\n",
      "Iteration 6365, loss = 2492.02005222\n",
      "Iteration 6366, loss = 2491.97679447\n",
      "Iteration 6367, loss = 2491.93357963\n",
      "Iteration 6368, loss = 2491.89040768\n",
      "Iteration 6369, loss = 2491.84727859\n",
      "Iteration 6370, loss = 2491.80419234\n",
      "Iteration 6371, loss = 2491.76114890\n",
      "Iteration 6372, loss = 2491.71814824\n",
      "Iteration 6373, loss = 2491.67519036\n",
      "Iteration 6374, loss = 2491.63227520\n",
      "Iteration 6375, loss = 2491.58940277\n",
      "Iteration 6376, loss = 2491.54657301\n",
      "Iteration 6377, loss = 2491.50378592\n",
      "Iteration 6378, loss = 2491.46104147\n",
      "Iteration 6379, loss = 2491.41833963\n",
      "Iteration 6380, loss = 2491.37568038\n",
      "Iteration 6381, loss = 2491.33306369\n",
      "Iteration 6382, loss = 2491.29048953\n",
      "Iteration 6383, loss = 2491.24795789\n",
      "Iteration 6384, loss = 2491.20546873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6385, loss = 2491.16302204\n",
      "Iteration 6386, loss = 2491.12061778\n",
      "Iteration 6387, loss = 2491.07825593\n",
      "Iteration 6388, loss = 2491.03593647\n",
      "Iteration 6389, loss = 2490.99365937\n",
      "Iteration 6390, loss = 2490.95142460\n",
      "Iteration 6391, loss = 2490.90923215\n",
      "Iteration 6392, loss = 2490.86708198\n",
      "Iteration 6393, loss = 2490.82497407\n",
      "Iteration 6394, loss = 2490.78290840\n",
      "Iteration 6395, loss = 2490.74088494\n",
      "Iteration 6396, loss = 2490.69890366\n",
      "Iteration 6397, loss = 2490.65696454\n",
      "Iteration 6398, loss = 2490.61506756\n",
      "Iteration 6399, loss = 2490.57321269\n",
      "Iteration 6400, loss = 2490.53139990\n",
      "Iteration 6401, loss = 2490.48962917\n",
      "Iteration 6402, loss = 2490.44790048\n",
      "Iteration 6403, loss = 2490.40621379\n",
      "Iteration 6404, loss = 2490.36456909\n",
      "Iteration 6405, loss = 2490.32296635\n",
      "Iteration 6406, loss = 2490.28140554\n",
      "Iteration 6407, loss = 2490.23988664\n",
      "Iteration 6408, loss = 2490.19840962\n",
      "Iteration 6409, loss = 2490.15697446\n",
      "Iteration 6410, loss = 2490.11558113\n",
      "Iteration 6411, loss = 2490.07422961\n",
      "Iteration 6412, loss = 2490.03291988\n",
      "Iteration 6413, loss = 2489.99165190\n",
      "Iteration 6414, loss = 2489.95042565\n",
      "Iteration 6415, loss = 2489.90924111\n",
      "Iteration 6416, loss = 2489.86809825\n",
      "Iteration 6417, loss = 2489.82699705\n",
      "Iteration 6418, loss = 2489.78593748\n",
      "Iteration 6419, loss = 2489.74491951\n",
      "Iteration 6420, loss = 2489.70394313\n",
      "Iteration 6421, loss = 2489.66300830\n",
      "Iteration 6422, loss = 2489.62211501\n",
      "Iteration 6423, loss = 2489.58126321\n",
      "Iteration 6424, loss = 2489.54045290\n",
      "Iteration 6425, loss = 2489.49968405\n",
      "Iteration 6426, loss = 2489.45895662\n",
      "Iteration 6427, loss = 2489.41827060\n",
      "Iteration 6428, loss = 2489.37762595\n",
      "Iteration 6429, loss = 2489.33702266\n",
      "Iteration 6430, loss = 2489.29646070\n",
      "Iteration 6431, loss = 2489.25594004\n",
      "Iteration 6432, loss = 2489.21546067\n",
      "Iteration 6433, loss = 2489.17502254\n",
      "Iteration 6434, loss = 2489.13462564\n",
      "Iteration 6435, loss = 2489.09426995\n",
      "Iteration 6436, loss = 2489.05395543\n",
      "Iteration 6437, loss = 2489.01368206\n",
      "Iteration 6438, loss = 2488.97344982\n",
      "Iteration 6439, loss = 2488.93325868\n",
      "Iteration 6440, loss = 2488.89310862\n",
      "Iteration 6441, loss = 2488.85299961\n",
      "Iteration 6442, loss = 2488.81293163\n",
      "Iteration 6443, loss = 2488.77290464\n",
      "Iteration 6444, loss = 2488.73291863\n",
      "Iteration 6445, loss = 2488.69297358\n",
      "Iteration 6446, loss = 2488.65306944\n",
      "Iteration 6447, loss = 2488.61320621\n",
      "Iteration 6448, loss = 2488.57338384\n",
      "Iteration 6449, loss = 2488.53360233\n",
      "Iteration 6450, loss = 2488.49386164\n",
      "Iteration 6451, loss = 2488.45416175\n",
      "Iteration 6452, loss = 2488.41450264\n",
      "Iteration 6453, loss = 2488.37488427\n",
      "Iteration 6454, loss = 2488.33530662\n",
      "Iteration 6455, loss = 2488.29576967\n",
      "Iteration 6456, loss = 2488.25627339\n",
      "Iteration 6457, loss = 2488.21681776\n",
      "Iteration 6458, loss = 2488.17740275\n",
      "Iteration 6459, loss = 2488.13802834\n",
      "Iteration 6460, loss = 2488.09869449\n",
      "Iteration 6461, loss = 2488.05940119\n",
      "Iteration 6462, loss = 2488.02014841\n",
      "Iteration 6463, loss = 2487.98093613\n",
      "Iteration 6464, loss = 2487.94176431\n",
      "Iteration 6465, loss = 2487.90263294\n",
      "Iteration 6466, loss = 2487.86354199\n",
      "Iteration 6467, loss = 2487.82449143\n",
      "Iteration 6468, loss = 2487.78548124\n",
      "Iteration 6469, loss = 2487.74651139\n",
      "Iteration 6470, loss = 2487.70758186\n",
      "Iteration 6471, loss = 2487.66869262\n",
      "Iteration 6472, loss = 2487.62984365\n",
      "Iteration 6473, loss = 2487.59103492\n",
      "Iteration 6474, loss = 2487.55226640\n",
      "Iteration 6475, loss = 2487.51353808\n",
      "Iteration 6476, loss = 2487.47484992\n",
      "Iteration 6477, loss = 2487.43620190\n",
      "Iteration 6478, loss = 2487.39759399\n",
      "Iteration 6479, loss = 2487.35902618\n",
      "Iteration 6480, loss = 2487.32049842\n",
      "Iteration 6481, loss = 2487.28201071\n",
      "Iteration 6482, loss = 2487.24356301\n",
      "Iteration 6483, loss = 2487.20515530\n",
      "Iteration 6484, loss = 2487.16678754\n",
      "Iteration 6485, loss = 2487.12845973\n",
      "Iteration 6486, loss = 2487.09017183\n",
      "Iteration 6487, loss = 2487.05192381\n",
      "Iteration 6488, loss = 2487.01371566\n",
      "Iteration 6489, loss = 2486.97554734\n",
      "Iteration 6490, loss = 2486.93741883\n",
      "Iteration 6491, loss = 2486.89933010\n",
      "Iteration 6492, loss = 2486.86128113\n",
      "Iteration 6493, loss = 2486.82327190\n",
      "Iteration 6494, loss = 2486.78530238\n",
      "Iteration 6495, loss = 2486.74737254\n",
      "Iteration 6496, loss = 2486.70948235\n",
      "Iteration 6497, loss = 2486.67163180\n",
      "Iteration 6498, loss = 2486.63382086\n",
      "Iteration 6499, loss = 2486.59604949\n",
      "Iteration 6500, loss = 2486.55831769\n",
      "Iteration 6501, loss = 2486.52062541\n",
      "Iteration 6502, loss = 2486.48297264\n",
      "Iteration 6503, loss = 2486.44535935\n",
      "Iteration 6504, loss = 2486.40778551\n",
      "Iteration 6505, loss = 2486.37025110\n",
      "Iteration 6506, loss = 2486.33275609\n",
      "Iteration 6507, loss = 2486.29530047\n",
      "Iteration 6508, loss = 2486.25788419\n",
      "Iteration 6509, loss = 2486.22050724\n",
      "Iteration 6510, loss = 2486.18316960\n",
      "Iteration 6511, loss = 2486.14587123\n",
      "Iteration 6512, loss = 2486.10861211\n",
      "Iteration 6513, loss = 2486.07139222\n",
      "Iteration 6514, loss = 2486.03421152\n",
      "Iteration 6515, loss = 2485.99707000\n",
      "Iteration 6516, loss = 2485.95996763\n",
      "Iteration 6517, loss = 2485.92290439\n",
      "Iteration 6518, loss = 2485.88588024\n",
      "Iteration 6519, loss = 2485.84889516\n",
      "Iteration 6520, loss = 2485.81194913\n",
      "Iteration 6521, loss = 2485.77504212\n",
      "Iteration 6522, loss = 2485.73817411\n",
      "Iteration 6523, loss = 2485.70134507\n",
      "Iteration 6524, loss = 2485.66455498\n",
      "Iteration 6525, loss = 2485.62780380\n",
      "Iteration 6526, loss = 2485.59109152\n",
      "Iteration 6527, loss = 2485.55441811\n",
      "Iteration 6528, loss = 2485.51778354\n",
      "Iteration 6529, loss = 2485.48118779\n",
      "Iteration 6530, loss = 2485.44463083\n",
      "Iteration 6531, loss = 2485.40811264\n",
      "Iteration 6532, loss = 2485.37163319\n",
      "Iteration 6533, loss = 2485.33519245\n",
      "Iteration 6534, loss = 2485.29879041\n",
      "Iteration 6535, loss = 2485.26242703\n",
      "Iteration 6536, loss = 2485.22610229\n",
      "Iteration 6537, loss = 2485.18981616\n",
      "Iteration 6538, loss = 2485.15356863\n",
      "Iteration 6539, loss = 2485.11735965\n",
      "Iteration 6540, loss = 2485.08118921\n",
      "Iteration 6541, loss = 2485.04505729\n",
      "Iteration 6542, loss = 2485.00896385\n",
      "Iteration 6543, loss = 2484.97290887\n",
      "Iteration 6544, loss = 2484.93689233\n",
      "Iteration 6545, loss = 2484.90091419\n",
      "Iteration 6546, loss = 2484.86497444\n",
      "Iteration 6547, loss = 2484.82907305\n",
      "Iteration 6548, loss = 2484.79320999\n",
      "Iteration 6549, loss = 2484.75738524\n",
      "Iteration 6550, loss = 2484.72159878\n",
      "Iteration 6551, loss = 2484.68585057\n",
      "Iteration 6552, loss = 2484.65014059\n",
      "Iteration 6553, loss = 2484.61446881\n",
      "Iteration 6554, loss = 2484.57883522\n",
      "Iteration 6555, loss = 2484.54323978\n",
      "Iteration 6556, loss = 2484.50768246\n",
      "Iteration 6557, loss = 2484.47216325\n",
      "Iteration 6558, loss = 2484.43668212\n",
      "Iteration 6559, loss = 2484.40123905\n",
      "Iteration 6560, loss = 2484.36583399\n",
      "Iteration 6561, loss = 2484.33046694\n",
      "Iteration 6562, loss = 2484.29513787\n",
      "Iteration 6563, loss = 2484.25984674\n",
      "Iteration 6564, loss = 2484.22459354\n",
      "Iteration 6565, loss = 2484.18937824\n",
      "Iteration 6566, loss = 2484.15420081\n",
      "Iteration 6567, loss = 2484.11906123\n",
      "Iteration 6568, loss = 2484.08395947\n",
      "Iteration 6569, loss = 2484.04889550\n",
      "Iteration 6570, loss = 2484.01386931\n",
      "Iteration 6571, loss = 2483.97888086\n",
      "Iteration 6572, loss = 2483.94393014\n",
      "Iteration 6573, loss = 2483.90901710\n",
      "Iteration 6574, loss = 2483.87414174\n",
      "Iteration 6575, loss = 2483.83930401\n",
      "Iteration 6576, loss = 2483.80450391\n",
      "Iteration 6577, loss = 2483.76974140\n",
      "Iteration 6578, loss = 2483.73501645\n",
      "Iteration 6579, loss = 2483.70032904\n",
      "Iteration 6580, loss = 2483.66567915\n",
      "Iteration 6581, loss = 2483.63106675\n",
      "Iteration 6582, loss = 2483.59649181\n",
      "Iteration 6583, loss = 2483.56195431\n",
      "Iteration 6584, loss = 2483.52745422\n",
      "Iteration 6585, loss = 2483.49299152\n",
      "Iteration 6586, loss = 2483.45856618\n",
      "Iteration 6587, loss = 2483.42417818\n",
      "Iteration 6588, loss = 2483.38982748\n",
      "Iteration 6589, loss = 2483.35551407\n",
      "Iteration 6590, loss = 2483.32123792\n",
      "Iteration 6591, loss = 2483.28699901\n",
      "Iteration 6592, loss = 2483.25279730\n",
      "Iteration 6593, loss = 2483.21863277\n",
      "Iteration 6594, loss = 2483.18450539\n",
      "Iteration 6595, loss = 2483.15041515\n",
      "Iteration 6596, loss = 2483.11636201\n",
      "Iteration 6597, loss = 2483.08234596\n",
      "Iteration 6598, loss = 2483.04836695\n",
      "Iteration 6599, loss = 2483.01442498\n",
      "Iteration 6600, loss = 2482.98052000\n",
      "Iteration 6601, loss = 2482.94665201\n",
      "Iteration 6602, loss = 2482.91282096\n",
      "Iteration 6603, loss = 2482.87902684\n",
      "Iteration 6604, loss = 2482.84526962\n",
      "Iteration 6605, loss = 2482.81154927\n",
      "Iteration 6606, loss = 2482.77786577\n",
      "Iteration 6607, loss = 2482.74421910\n",
      "Iteration 6608, loss = 2482.71060922\n",
      "Iteration 6609, loss = 2482.67703611\n",
      "Iteration 6610, loss = 2482.64349975\n",
      "Iteration 6611, loss = 2482.61000011\n",
      "Iteration 6612, loss = 2482.57653716\n",
      "Iteration 6613, loss = 2482.54311088\n",
      "Iteration 6614, loss = 2482.50972125\n",
      "Iteration 6615, loss = 2482.47636823\n",
      "Iteration 6616, loss = 2482.44305180\n",
      "Iteration 6617, loss = 2482.40977194\n",
      "Iteration 6618, loss = 2482.37652862\n",
      "Iteration 6619, loss = 2482.34332181\n",
      "Iteration 6620, loss = 2482.31015150\n",
      "Iteration 6621, loss = 2482.27701764\n",
      "Iteration 6622, loss = 2482.24392023\n",
      "Iteration 6623, loss = 2482.21085922\n",
      "Iteration 6624, loss = 2482.17783461\n",
      "Iteration 6625, loss = 2482.14484635\n",
      "Iteration 6626, loss = 2482.11189442\n",
      "Iteration 6627, loss = 2482.07897881\n",
      "Iteration 6628, loss = 2482.04609948\n",
      "Iteration 6629, loss = 2482.01325641\n",
      "Iteration 6630, loss = 2481.98044956\n",
      "Iteration 6631, loss = 2481.94767893\n",
      "Iteration 6632, loss = 2481.91494447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6633, loss = 2481.88224617\n",
      "Iteration 6634, loss = 2481.84958400\n",
      "Iteration 6635, loss = 2481.81695793\n",
      "Iteration 6636, loss = 2481.78436794\n",
      "Iteration 6637, loss = 2481.75181401\n",
      "Iteration 6638, loss = 2481.71929609\n",
      "Iteration 6639, loss = 2481.68681418\n",
      "Iteration 6640, loss = 2481.65436824\n",
      "Iteration 6641, loss = 2481.62195825\n",
      "Iteration 6642, loss = 2481.58958419\n",
      "Iteration 6643, loss = 2481.55724602\n",
      "Iteration 6644, loss = 2481.52494372\n",
      "Iteration 6645, loss = 2481.49267727\n",
      "Iteration 6646, loss = 2481.46044664\n",
      "Iteration 6647, loss = 2481.42825181\n",
      "Iteration 6648, loss = 2481.39609274\n",
      "Iteration 6649, loss = 2481.36396942\n",
      "Iteration 6650, loss = 2481.33188181\n",
      "Iteration 6651, loss = 2481.29982989\n",
      "Iteration 6652, loss = 2481.26781364\n",
      "Iteration 6653, loss = 2481.23583303\n",
      "Iteration 6654, loss = 2481.20388804\n",
      "Iteration 6655, loss = 2481.17197863\n",
      "Iteration 6656, loss = 2481.14010478\n",
      "Iteration 6657, loss = 2481.10826647\n",
      "Iteration 6658, loss = 2481.07646368\n",
      "Iteration 6659, loss = 2481.04469636\n",
      "Iteration 6660, loss = 2481.01296451\n",
      "Iteration 6661, loss = 2480.98126809\n",
      "Iteration 6662, loss = 2480.94960708\n",
      "Iteration 6663, loss = 2480.91798145\n",
      "Iteration 6664, loss = 2480.88639118\n",
      "Iteration 6665, loss = 2480.85483624\n",
      "Iteration 6666, loss = 2480.82331660\n",
      "Iteration 6667, loss = 2480.79183225\n",
      "Iteration 6668, loss = 2480.76038314\n",
      "Iteration 6669, loss = 2480.72896926\n",
      "Iteration 6670, loss = 2480.69759059\n",
      "Iteration 6671, loss = 2480.66624709\n",
      "Iteration 6672, loss = 2480.63493874\n",
      "Iteration 6673, loss = 2480.60366552\n",
      "Iteration 6674, loss = 2480.57242739\n",
      "Iteration 6675, loss = 2480.54122433\n",
      "Iteration 6676, loss = 2480.51005633\n",
      "Iteration 6677, loss = 2480.47892334\n",
      "Iteration 6678, loss = 2480.44782535\n",
      "Iteration 6679, loss = 2480.41676233\n",
      "Iteration 6680, loss = 2480.38573425\n",
      "Iteration 6681, loss = 2480.35474109\n",
      "Iteration 6682, loss = 2480.32378283\n",
      "Iteration 6683, loss = 2480.29285942\n",
      "Iteration 6684, loss = 2480.26197086\n",
      "Iteration 6685, loss = 2480.23111712\n",
      "Iteration 6686, loss = 2480.20029816\n",
      "Iteration 6687, loss = 2480.16951396\n",
      "Iteration 6688, loss = 2480.13876451\n",
      "Iteration 6689, loss = 2480.10804976\n",
      "Iteration 6690, loss = 2480.07736970\n",
      "Iteration 6691, loss = 2480.04672430\n",
      "Iteration 6692, loss = 2480.01611353\n",
      "Iteration 6693, loss = 2479.98553737\n",
      "Iteration 6694, loss = 2479.95499579\n",
      "Iteration 6695, loss = 2479.92448877\n",
      "Iteration 6696, loss = 2479.89401628\n",
      "Iteration 6697, loss = 2479.86357829\n",
      "Iteration 6698, loss = 2479.83317479\n",
      "Iteration 6699, loss = 2479.80280573\n",
      "Iteration 6700, loss = 2479.77247110\n",
      "Iteration 6701, loss = 2479.74217088\n",
      "Iteration 6702, loss = 2479.71190503\n",
      "Iteration 6703, loss = 2479.68167352\n",
      "Iteration 6704, loss = 2479.65147635\n",
      "Iteration 6705, loss = 2479.62131347\n",
      "Iteration 6706, loss = 2479.59118486\n",
      "Iteration 6707, loss = 2479.56109049\n",
      "Iteration 6708, loss = 2479.53103035\n",
      "Iteration 6709, loss = 2479.50100440\n",
      "Iteration 6710, loss = 2479.47101263\n",
      "Iteration 6711, loss = 2479.44105499\n",
      "Iteration 6712, loss = 2479.41113147\n",
      "Iteration 6713, loss = 2479.38124204\n",
      "Iteration 6714, loss = 2479.35138668\n",
      "Iteration 6715, loss = 2479.32156535\n",
      "Iteration 6716, loss = 2479.29177804\n",
      "Iteration 6717, loss = 2479.26202471\n",
      "Iteration 6718, loss = 2479.23230535\n",
      "Iteration 6719, loss = 2479.20261992\n",
      "Iteration 6720, loss = 2479.17296840\n",
      "Iteration 6721, loss = 2479.14335077\n",
      "Iteration 6722, loss = 2479.11376699\n",
      "Iteration 6723, loss = 2479.08421705\n",
      "Iteration 6724, loss = 2479.05470091\n",
      "Iteration 6725, loss = 2479.02521856\n",
      "Iteration 6726, loss = 2478.99576995\n",
      "Iteration 6727, loss = 2478.96635508\n",
      "Iteration 6728, loss = 2478.93697391\n",
      "Iteration 6729, loss = 2478.90762641\n",
      "Iteration 6730, loss = 2478.87831257\n",
      "Iteration 6731, loss = 2478.84903235\n",
      "Iteration 6732, loss = 2478.81978572\n",
      "Iteration 6733, loss = 2478.79057268\n",
      "Iteration 6734, loss = 2478.76139318\n",
      "Iteration 6735, loss = 2478.73224720\n",
      "Iteration 6736, loss = 2478.70313471\n",
      "Iteration 6737, loss = 2478.67405570\n",
      "Iteration 6738, loss = 2478.64501013\n",
      "Iteration 6739, loss = 2478.61599797\n",
      "Iteration 6740, loss = 2478.58701921\n",
      "Iteration 6741, loss = 2478.55807382\n",
      "Iteration 6742, loss = 2478.52916176\n",
      "Iteration 6743, loss = 2478.50028302\n",
      "Iteration 6744, loss = 2478.47143756\n",
      "Iteration 6745, loss = 2478.44262537\n",
      "Iteration 6746, loss = 2478.41384641\n",
      "Iteration 6747, loss = 2478.38510067\n",
      "Iteration 6748, loss = 2478.35638811\n",
      "Iteration 6749, loss = 2478.32770870\n",
      "Iteration 6750, loss = 2478.29906243\n",
      "Iteration 6751, loss = 2478.27044927\n",
      "Iteration 6752, loss = 2478.24186919\n",
      "Iteration 6753, loss = 2478.21332216\n",
      "Iteration 6754, loss = 2478.18480816\n",
      "Iteration 6755, loss = 2478.15632716\n",
      "Iteration 6756, loss = 2478.12787914\n",
      "Iteration 6757, loss = 2478.09946407\n",
      "Iteration 6758, loss = 2478.07108192\n",
      "Iteration 6759, loss = 2478.04273268\n",
      "Iteration 6760, loss = 2478.01441631\n",
      "Iteration 6761, loss = 2477.98613278\n",
      "Iteration 6762, loss = 2477.95788207\n",
      "Iteration 6763, loss = 2477.92966416\n",
      "Iteration 6764, loss = 2477.90147902\n",
      "Iteration 6765, loss = 2477.87332663\n",
      "Iteration 6766, loss = 2477.84520695\n",
      "Iteration 6767, loss = 2477.81711996\n",
      "Iteration 6768, loss = 2477.78906564\n",
      "Iteration 6769, loss = 2477.76104395\n",
      "Iteration 6770, loss = 2477.73305488\n",
      "Iteration 6771, loss = 2477.70509840\n",
      "Iteration 6772, loss = 2477.67717448\n",
      "Iteration 6773, loss = 2477.64928310\n",
      "Iteration 6774, loss = 2477.62142422\n",
      "Iteration 6775, loss = 2477.59359784\n",
      "Iteration 6776, loss = 2477.56580392\n",
      "Iteration 6777, loss = 2477.53804245\n",
      "Iteration 6778, loss = 2477.51031342\n",
      "Iteration 6779, loss = 2477.48261686\n",
      "Iteration 6780, loss = 2477.45495281\n",
      "Iteration 6781, loss = 2477.42732143\n",
      "Iteration 6782, loss = 2477.39972289\n",
      "Iteration 6783, loss = 2477.37215725\n",
      "Iteration 6784, loss = 2477.34462366\n",
      "Iteration 6785, loss = 2477.31712015\n",
      "Iteration 6786, loss = 2477.28964624\n",
      "Iteration 6787, loss = 2477.26220541\n",
      "Iteration 6788, loss = 2477.23480010\n",
      "Iteration 6789, loss = 2477.20742762\n",
      "Iteration 6790, loss = 2477.18008456\n",
      "Iteration 6791, loss = 2477.15277236\n",
      "Iteration 6792, loss = 2477.12549444\n",
      "Iteration 6793, loss = 2477.09824970\n",
      "Iteration 6794, loss = 2477.07103511\n",
      "Iteration 6795, loss = 2477.04385162\n",
      "Iteration 6796, loss = 2477.01670173\n",
      "Iteration 6797, loss = 2476.98958424\n",
      "Iteration 6798, loss = 2476.96249722\n",
      "Iteration 6799, loss = 2476.93544194\n",
      "Iteration 6800, loss = 2476.90841970\n",
      "Iteration 6801, loss = 2476.88142909\n",
      "Iteration 6802, loss = 2476.85446933\n",
      "Iteration 6803, loss = 2476.82754174\n",
      "Iteration 6804, loss = 2476.80064653\n",
      "Iteration 6805, loss = 2476.77378250\n",
      "Iteration 6806, loss = 2476.74694979\n",
      "Iteration 6807, loss = 2476.72014928\n",
      "Iteration 6808, loss = 2476.69338051\n",
      "Iteration 6809, loss = 2476.66664287\n",
      "Iteration 6810, loss = 2476.63993686\n",
      "Iteration 6811, loss = 2476.61326278\n",
      "Iteration 6812, loss = 2476.58662004\n",
      "Iteration 6813, loss = 2476.56000855\n",
      "Iteration 6814, loss = 2476.53342877\n",
      "Iteration 6815, loss = 2476.50688054\n",
      "Iteration 6816, loss = 2476.48036352\n",
      "Iteration 6817, loss = 2476.45387786\n",
      "Iteration 6818, loss = 2476.42742376\n",
      "Iteration 6819, loss = 2476.40100095\n",
      "Iteration 6820, loss = 2476.37460932\n",
      "Iteration 6821, loss = 2476.34824906\n",
      "Iteration 6822, loss = 2476.32192015\n",
      "Iteration 6823, loss = 2476.29562237\n",
      "Iteration 6824, loss = 2476.26935577\n",
      "Iteration 6825, loss = 2476.24312045\n",
      "Iteration 6826, loss = 2476.21691628\n",
      "Iteration 6827, loss = 2476.19074316\n",
      "Iteration 6828, loss = 2476.16460118\n",
      "Iteration 6829, loss = 2476.13849033\n",
      "Iteration 6830, loss = 2476.11241050\n",
      "Iteration 6831, loss = 2476.08636166\n",
      "Iteration 6832, loss = 2476.06034387\n",
      "Iteration 6833, loss = 2476.03435706\n",
      "Iteration 6834, loss = 2476.00840116\n",
      "Iteration 6835, loss = 2475.98247619\n",
      "Iteration 6836, loss = 2475.95658214\n",
      "Iteration 6837, loss = 2475.93071896\n",
      "Iteration 6838, loss = 2475.90488660\n",
      "Iteration 6839, loss = 2475.87908507\n",
      "Iteration 6840, loss = 2475.85331434\n",
      "Iteration 6841, loss = 2475.82757437\n",
      "Iteration 6842, loss = 2475.80186513\n",
      "Iteration 6843, loss = 2475.77618662\n",
      "Iteration 6844, loss = 2475.75053880\n",
      "Iteration 6845, loss = 2475.72492163\n",
      "Iteration 6846, loss = 2475.69933510\n",
      "Iteration 6847, loss = 2475.67377919\n",
      "Iteration 6848, loss = 2475.64825386\n",
      "Iteration 6849, loss = 2475.62275908\n",
      "Iteration 6850, loss = 2475.59729483\n",
      "Iteration 6851, loss = 2475.57186110\n",
      "Iteration 6852, loss = 2475.54645784\n",
      "Iteration 6853, loss = 2475.52108503\n",
      "Iteration 6854, loss = 2475.49574266\n",
      "Iteration 6855, loss = 2475.47043068\n",
      "Iteration 6856, loss = 2475.44514908\n",
      "Iteration 6857, loss = 2475.41989783\n",
      "Iteration 6858, loss = 2475.39467690\n",
      "Iteration 6859, loss = 2475.36948627\n",
      "Iteration 6860, loss = 2475.34432591\n",
      "Iteration 6861, loss = 2475.31919579\n",
      "Iteration 6862, loss = 2475.29409589\n",
      "Iteration 6863, loss = 2475.26902619\n",
      "Iteration 6864, loss = 2475.24398665\n",
      "Iteration 6865, loss = 2475.21897726\n",
      "Iteration 6866, loss = 2475.19399797\n",
      "Iteration 6867, loss = 2475.16904878\n",
      "Iteration 6868, loss = 2475.14412965\n",
      "Iteration 6869, loss = 2475.11924055\n",
      "Iteration 6870, loss = 2475.09438147\n",
      "Iteration 6871, loss = 2475.06955237\n",
      "Iteration 6872, loss = 2475.04475322\n",
      "Iteration 6873, loss = 2475.01998401\n",
      "Iteration 6874, loss = 2474.99524470\n",
      "Iteration 6875, loss = 2474.97053528\n",
      "Iteration 6876, loss = 2474.94585570\n",
      "Iteration 6877, loss = 2474.92120596\n",
      "Iteration 6878, loss = 2474.89658601\n",
      "Iteration 6879, loss = 2474.87199584\n",
      "Iteration 6880, loss = 2474.84743542\n",
      "Iteration 6881, loss = 2474.82290473\n",
      "Iteration 6882, loss = 2474.79840373\n",
      "Iteration 6883, loss = 2474.77393240\n",
      "Iteration 6884, loss = 2474.74949071\n",
      "Iteration 6885, loss = 2474.72507864\n",
      "Iteration 6886, loss = 2474.70069617\n",
      "Iteration 6887, loss = 2474.67634326\n",
      "Iteration 6888, loss = 2474.65201989\n",
      "Iteration 6889, loss = 2474.62772604\n",
      "Iteration 6890, loss = 2474.60346168\n",
      "Iteration 6891, loss = 2474.57922677\n",
      "Iteration 6892, loss = 2474.55502130\n",
      "Iteration 6893, loss = 2474.53084524\n",
      "Iteration 6894, loss = 2474.50669857\n",
      "Iteration 6895, loss = 2474.48258125\n",
      "Iteration 6896, loss = 2474.45849326\n",
      "Iteration 6897, loss = 2474.43443458\n",
      "Iteration 6898, loss = 2474.41040518\n",
      "Iteration 6899, loss = 2474.38640503\n",
      "Iteration 6900, loss = 2474.36243410\n",
      "Iteration 6901, loss = 2474.33849238\n",
      "Iteration 6902, loss = 2474.31457983\n",
      "Iteration 6903, loss = 2474.29069643\n",
      "Iteration 6904, loss = 2474.26684215\n",
      "Iteration 6905, loss = 2474.24301697\n",
      "Iteration 6906, loss = 2474.21922086\n",
      "Iteration 6907, loss = 2474.19545379\n",
      "Iteration 6908, loss = 2474.17171574\n",
      "Iteration 6909, loss = 2474.14800668\n",
      "Iteration 6910, loss = 2474.12432659\n",
      "Iteration 6911, loss = 2474.10067543\n",
      "Iteration 6912, loss = 2474.07705319\n",
      "Iteration 6913, loss = 2474.05345983\n",
      "Iteration 6914, loss = 2474.02989534\n",
      "Iteration 6915, loss = 2474.00635968\n",
      "Iteration 6916, loss = 2473.98285283\n",
      "Iteration 6917, loss = 2473.95937476\n",
      "Iteration 6918, loss = 2473.93592545\n",
      "Iteration 6919, loss = 2473.91250487\n",
      "Iteration 6920, loss = 2473.88911299\n",
      "Iteration 6921, loss = 2473.86574979\n",
      "Iteration 6922, loss = 2473.84241524\n",
      "Iteration 6923, loss = 2473.81910931\n",
      "Iteration 6924, loss = 2473.79583199\n",
      "Iteration 6925, loss = 2473.77258324\n",
      "Iteration 6926, loss = 2473.74936303\n",
      "Iteration 6927, loss = 2473.72617135\n",
      "Iteration 6928, loss = 2473.70300816\n",
      "Iteration 6929, loss = 2473.67987344\n",
      "Iteration 6930, loss = 2473.65676716\n",
      "Iteration 6931, loss = 2473.63368930\n",
      "Iteration 6932, loss = 2473.61063982\n",
      "Iteration 6933, loss = 2473.58761872\n",
      "Iteration 6934, loss = 2473.56462595\n",
      "Iteration 6935, loss = 2473.54166149\n",
      "Iteration 6936, loss = 2473.51872531\n",
      "Iteration 6937, loss = 2473.49581740\n",
      "Iteration 6938, loss = 2473.47293772\n",
      "Iteration 6939, loss = 2473.45008624\n",
      "Iteration 6940, loss = 2473.42726295\n",
      "Iteration 6941, loss = 2473.40446781\n",
      "Iteration 6942, loss = 2473.38170080\n",
      "Iteration 6943, loss = 2473.35896189\n",
      "Iteration 6944, loss = 2473.33625106\n",
      "Iteration 6945, loss = 2473.31356827\n",
      "Iteration 6946, loss = 2473.29091351\n",
      "Iteration 6947, loss = 2473.26828675\n",
      "Iteration 6948, loss = 2473.24568796\n",
      "Iteration 6949, loss = 2473.22311712\n",
      "Iteration 6950, loss = 2473.20057419\n",
      "Iteration 6951, loss = 2473.17805916\n",
      "Iteration 6952, loss = 2473.15557199\n",
      "Iteration 6953, loss = 2473.13311266\n",
      "Iteration 6954, loss = 2473.11068115\n",
      "Iteration 6955, loss = 2473.08827742\n",
      "Iteration 6956, loss = 2473.06590146\n",
      "Iteration 6957, loss = 2473.04355324\n",
      "Iteration 6958, loss = 2473.02123272\n",
      "Iteration 6959, loss = 2472.99893988\n",
      "Iteration 6960, loss = 2472.97667471\n",
      "Iteration 6961, loss = 2472.95443716\n",
      "Iteration 6962, loss = 2472.93222722\n",
      "Iteration 6963, loss = 2472.91004486\n",
      "Iteration 6964, loss = 2472.88789005\n",
      "Iteration 6965, loss = 2472.86576276\n",
      "Iteration 6966, loss = 2472.84366298\n",
      "Iteration 6967, loss = 2472.82159067\n",
      "Iteration 6968, loss = 2472.79954581\n",
      "Iteration 6969, loss = 2472.77752837\n",
      "Iteration 6970, loss = 2472.75553832\n",
      "Iteration 6971, loss = 2472.73357564\n",
      "Iteration 6972, loss = 2472.71164031\n",
      "Iteration 6973, loss = 2472.68973229\n",
      "Iteration 6974, loss = 2472.66785157\n",
      "Iteration 6975, loss = 2472.64599810\n",
      "Iteration 6976, loss = 2472.62417188\n",
      "Iteration 6977, loss = 2472.60237287\n",
      "Iteration 6978, loss = 2472.58060104\n",
      "Iteration 6979, loss = 2472.55885637\n",
      "Iteration 6980, loss = 2472.53713884\n",
      "Iteration 6981, loss = 2472.51544841\n",
      "Iteration 6982, loss = 2472.49378506\n",
      "Iteration 6983, loss = 2472.47214877\n",
      "Iteration 6984, loss = 2472.45053951\n",
      "Iteration 6985, loss = 2472.42895725\n",
      "Iteration 6986, loss = 2472.40740196\n",
      "Iteration 6987, loss = 2472.38587363\n",
      "Iteration 6988, loss = 2472.36437222\n",
      "Iteration 6989, loss = 2472.34289770\n",
      "Iteration 6990, loss = 2472.32145006\n",
      "Iteration 6991, loss = 2472.30002926\n",
      "Iteration 6992, loss = 2472.27863528\n",
      "Iteration 6993, loss = 2472.25726809\n",
      "Iteration 6994, loss = 2472.23592767\n",
      "Iteration 6995, loss = 2472.21461399\n",
      "Iteration 6996, loss = 2472.19332703\n",
      "Iteration 6997, loss = 2472.17206675\n",
      "Iteration 6998, loss = 2472.15083313\n",
      "Iteration 6999, loss = 2472.12962615\n",
      "Iteration 7000, loss = 2472.10844577\n",
      "Iteration 7001, loss = 2472.08729198\n",
      "Iteration 7002, loss = 2472.06616475\n",
      "Iteration 7003, loss = 2472.04506405\n",
      "Iteration 7004, loss = 2472.02398985\n",
      "Iteration 7005, loss = 2472.00294213\n",
      "Iteration 7006, loss = 2471.98192086\n",
      "Iteration 7007, loss = 2471.96092601\n",
      "Iteration 7008, loss = 2471.93995757\n",
      "Iteration 7009, loss = 2471.91901550\n",
      "Iteration 7010, loss = 2471.89809977\n",
      "Iteration 7011, loss = 2471.87721037\n",
      "Iteration 7012, loss = 2471.85634726\n",
      "Iteration 7013, loss = 2471.83551041\n",
      "Iteration 7014, loss = 2471.81469981\n",
      "Iteration 7015, loss = 2471.79391543\n",
      "Iteration 7016, loss = 2471.77315723\n",
      "Iteration 7017, loss = 2471.75242520\n",
      "Iteration 7018, loss = 2471.73171931\n",
      "Iteration 7019, loss = 2471.71103952\n",
      "Iteration 7020, loss = 2471.69038582\n",
      "Iteration 7021, loss = 2471.66975818\n",
      "Iteration 7022, loss = 2471.64915657\n",
      "Iteration 7023, loss = 2471.62858097\n",
      "Iteration 7024, loss = 2471.60803134\n",
      "Iteration 7025, loss = 2471.58750767\n",
      "Iteration 7026, loss = 2471.56700993\n",
      "Iteration 7027, loss = 2471.54653808\n",
      "Iteration 7028, loss = 2471.52609212\n",
      "Iteration 7029, loss = 2471.50567200\n",
      "Iteration 7030, loss = 2471.48527770\n",
      "Iteration 7031, loss = 2471.46490920\n",
      "Iteration 7032, loss = 2471.44456646\n",
      "Iteration 7033, loss = 2471.42424947\n",
      "Iteration 7034, loss = 2471.40395820\n",
      "Iteration 7035, loss = 2471.38369262\n",
      "Iteration 7036, loss = 2471.36345270\n",
      "Iteration 7037, loss = 2471.34323843\n",
      "Iteration 7038, loss = 2471.32304976\n",
      "Iteration 7039, loss = 2471.30288668\n",
      "Iteration 7040, loss = 2471.28274916\n",
      "Iteration 7041, loss = 2471.26263717\n",
      "Iteration 7042, loss = 2471.24255069\n",
      "Iteration 7043, loss = 2471.22248969\n",
      "Iteration 7044, loss = 2471.20245415\n",
      "Iteration 7045, loss = 2471.18244403\n",
      "Iteration 7046, loss = 2471.16245932\n",
      "Iteration 7047, loss = 2471.14249998\n",
      "Iteration 7048, loss = 2471.12256599\n",
      "Iteration 7049, loss = 2471.10265733\n",
      "Iteration 7050, loss = 2471.08277396\n",
      "Iteration 7051, loss = 2471.06291586\n",
      "Iteration 7052, loss = 2471.04308301\n",
      "Iteration 7053, loss = 2471.02327538\n",
      "Iteration 7054, loss = 2471.00349294\n",
      "Iteration 7055, loss = 2470.98373566\n",
      "Iteration 7056, loss = 2470.96400352\n",
      "Iteration 7057, loss = 2470.94429650\n",
      "Iteration 7058, loss = 2470.92461456\n",
      "Iteration 7059, loss = 2470.90495769\n",
      "Iteration 7060, loss = 2470.88532585\n",
      "Iteration 7061, loss = 2470.86571902\n",
      "Iteration 7062, loss = 2470.84613717\n",
      "Iteration 7063, loss = 2470.82658027\n",
      "Iteration 7064, loss = 2470.80704831\n",
      "Iteration 7065, loss = 2470.78754124\n",
      "Iteration 7066, loss = 2470.76805906\n",
      "Iteration 7067, loss = 2470.74860172\n",
      "Iteration 7068, loss = 2470.72916921\n",
      "Iteration 7069, loss = 2470.70976150\n",
      "Iteration 7070, loss = 2470.69037856\n",
      "Iteration 7071, loss = 2470.67102037\n",
      "Iteration 7072, loss = 2470.65168689\n",
      "Iteration 7073, loss = 2470.63237811\n",
      "Iteration 7074, loss = 2470.61309400\n",
      "Iteration 7075, loss = 2470.59383452\n",
      "Iteration 7076, loss = 2470.57459966\n",
      "Iteration 7077, loss = 2470.55538939\n",
      "Iteration 7078, loss = 2470.53620368\n",
      "Iteration 7079, loss = 2470.51704250\n",
      "Iteration 7080, loss = 2470.49790583\n",
      "Iteration 7081, loss = 2470.47879365\n",
      "Iteration 7082, loss = 2470.45970592\n",
      "Iteration 7083, loss = 2470.44064263\n",
      "Iteration 7084, loss = 2470.42160373\n",
      "Iteration 7085, loss = 2470.40258922\n",
      "Iteration 7086, loss = 2470.38359906\n",
      "Iteration 7087, loss = 2470.36463322\n",
      "Iteration 7088, loss = 2470.34569168\n",
      "Iteration 7089, loss = 2470.32677441\n",
      "Iteration 7090, loss = 2470.30788139\n",
      "Iteration 7091, loss = 2470.28901259\n",
      "Iteration 7092, loss = 2470.27016798\n",
      "Iteration 7093, loss = 2470.25134755\n",
      "Iteration 7094, loss = 2470.23255125\n",
      "Iteration 7095, loss = 2470.21377906\n",
      "Iteration 7096, loss = 2470.19503097\n",
      "Iteration 7097, loss = 2470.17630694\n",
      "Iteration 7098, loss = 2470.15760694\n",
      "Iteration 7099, loss = 2470.13893096\n",
      "Iteration 7100, loss = 2470.12027895\n",
      "Iteration 7101, loss = 2470.10165091\n",
      "Iteration 7102, loss = 2470.08304679\n",
      "Iteration 7103, loss = 2470.06446658\n",
      "Iteration 7104, loss = 2470.04591025\n",
      "Iteration 7105, loss = 2470.02737777\n",
      "Iteration 7106, loss = 2470.00886911\n",
      "Iteration 7107, loss = 2469.99038426\n",
      "Iteration 7108, loss = 2469.97192318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7109, loss = 2469.95348584\n",
      "Iteration 7110, loss = 2469.93507223\n",
      "Iteration 7111, loss = 2469.91668231\n",
      "Iteration 7112, loss = 2469.89831605\n",
      "Iteration 7113, loss = 2469.87997344\n",
      "Iteration 7114, loss = 2469.86165445\n",
      "Iteration 7115, loss = 2469.84335904\n",
      "Iteration 7116, loss = 2469.82508720\n",
      "Iteration 7117, loss = 2469.80683889\n",
      "Iteration 7118, loss = 2469.78861409\n",
      "Iteration 7119, loss = 2469.77041278\n",
      "Iteration 7120, loss = 2469.75223492\n",
      "Iteration 7121, loss = 2469.73408050\n",
      "Iteration 7122, loss = 2469.71594948\n",
      "Iteration 7123, loss = 2469.69784184\n",
      "Iteration 7124, loss = 2469.67975755\n",
      "Iteration 7125, loss = 2469.66169658\n",
      "Iteration 7126, loss = 2469.64365892\n",
      "Iteration 7127, loss = 2469.62564453\n",
      "Iteration 7128, loss = 2469.60765339\n",
      "Iteration 7129, loss = 2469.58968546\n",
      "Iteration 7130, loss = 2469.57174074\n",
      "Iteration 7131, loss = 2469.55381918\n",
      "Iteration 7132, loss = 2469.53592076\n",
      "Iteration 7133, loss = 2469.51804545\n",
      "Iteration 7134, loss = 2469.50019324\n",
      "Iteration 7135, loss = 2469.48236409\n",
      "Iteration 7136, loss = 2469.46455798\n",
      "Iteration 7137, loss = 2469.44677487\n",
      "Iteration 7138, loss = 2469.42901475\n",
      "Iteration 7139, loss = 2469.41127759\n",
      "Iteration 7140, loss = 2469.39356336\n",
      "Iteration 7141, loss = 2469.37587203\n",
      "Iteration 7142, loss = 2469.35820358\n",
      "Iteration 7143, loss = 2469.34055799\n",
      "Iteration 7144, loss = 2469.32293522\n",
      "Iteration 7145, loss = 2469.30533525\n",
      "Iteration 7146, loss = 2469.28775805\n",
      "Iteration 7147, loss = 2469.27020360\n",
      "Iteration 7148, loss = 2469.25267187\n",
      "Iteration 7149, loss = 2469.23516283\n",
      "Iteration 7150, loss = 2469.21767647\n",
      "Iteration 7151, loss = 2469.20021274\n",
      "Iteration 7152, loss = 2469.18277163\n",
      "Iteration 7153, loss = 2469.16535311\n",
      "Iteration 7154, loss = 2469.14795715\n",
      "Iteration 7155, loss = 2469.13058373\n",
      "Iteration 7156, loss = 2469.11323282\n",
      "Iteration 7157, loss = 2469.09590439\n",
      "Iteration 7158, loss = 2469.07859842\n",
      "Iteration 7159, loss = 2469.06131488\n",
      "Iteration 7160, loss = 2469.04405375\n",
      "Iteration 7161, loss = 2469.02681499\n",
      "Iteration 7162, loss = 2469.00959858\n",
      "Iteration 7163, loss = 2468.99240450\n",
      "Iteration 7164, loss = 2468.97523272\n",
      "Iteration 7165, loss = 2468.95808322\n",
      "Iteration 7166, loss = 2468.94095596\n",
      "Iteration 7167, loss = 2468.92385092\n",
      "Iteration 7168, loss = 2468.90676807\n",
      "Iteration 7169, loss = 2468.88970739\n",
      "Iteration 7170, loss = 2468.87266886\n",
      "Iteration 7171, loss = 2468.85565244\n",
      "Iteration 7172, loss = 2468.83865810\n",
      "Iteration 7173, loss = 2468.82168583\n",
      "Iteration 7174, loss = 2468.80473560\n",
      "Iteration 7175, loss = 2468.78780737\n",
      "Iteration 7176, loss = 2468.77090113\n",
      "Iteration 7177, loss = 2468.75401684\n",
      "Iteration 7178, loss = 2468.73715449\n",
      "Iteration 7179, loss = 2468.72031404\n",
      "Iteration 7180, loss = 2468.70349546\n",
      "Iteration 7181, loss = 2468.68669874\n",
      "Iteration 7182, loss = 2468.66992385\n",
      "Iteration 7183, loss = 2468.65317075\n",
      "Iteration 7184, loss = 2468.63643942\n",
      "Iteration 7185, loss = 2468.61972984\n",
      "Iteration 7186, loss = 2468.60304198\n",
      "Iteration 7187, loss = 2468.58637582\n",
      "Iteration 7188, loss = 2468.56973132\n",
      "Iteration 7189, loss = 2468.55310846\n",
      "Iteration 7190, loss = 2468.53650722\n",
      "Iteration 7191, loss = 2468.51992756\n",
      "Iteration 7192, loss = 2468.50336947\n",
      "Iteration 7193, loss = 2468.48683291\n",
      "Iteration 7194, loss = 2468.47031785\n",
      "Iteration 7195, loss = 2468.45382429\n",
      "Iteration 7196, loss = 2468.43735217\n",
      "Iteration 7197, loss = 2468.42090149\n",
      "Iteration 7198, loss = 2468.40447221\n",
      "Iteration 7199, loss = 2468.38806431\n",
      "Iteration 7200, loss = 2468.37167776\n",
      "Iteration 7201, loss = 2468.35531253\n",
      "Iteration 7202, loss = 2468.33896860\n",
      "Iteration 7203, loss = 2468.32264594\n",
      "Iteration 7204, loss = 2468.30634453\n",
      "Iteration 7205, loss = 2468.29006434\n",
      "Iteration 7206, loss = 2468.27380533\n",
      "Iteration 7207, loss = 2468.25756750\n",
      "Iteration 7208, loss = 2468.24135080\n",
      "Iteration 7209, loss = 2468.22515522\n",
      "Iteration 7210, loss = 2468.20898072\n",
      "Iteration 7211, loss = 2468.19282729\n",
      "Iteration 7212, loss = 2468.17669489\n",
      "Iteration 7213, loss = 2468.16058349\n",
      "Iteration 7214, loss = 2468.14449308\n",
      "Iteration 7215, loss = 2468.12842362\n",
      "Iteration 7216, loss = 2468.11237509\n",
      "Iteration 7217, loss = 2468.09634747\n",
      "Iteration 7218, loss = 2468.08034072\n",
      "Iteration 7219, loss = 2468.06435481\n",
      "Iteration 7220, loss = 2468.04838974\n",
      "Iteration 7221, loss = 2468.03244545\n",
      "Iteration 7222, loss = 2468.01652194\n",
      "Iteration 7223, loss = 2468.00061918\n",
      "Iteration 7224, loss = 2467.98473713\n",
      "Iteration 7225, loss = 2467.96887577\n",
      "Iteration 7226, loss = 2467.95303508\n",
      "Iteration 7227, loss = 2467.93721503\n",
      "Iteration 7228, loss = 2467.92141559\n",
      "Iteration 7229, loss = 2467.90563676\n",
      "Iteration 7230, loss = 2467.88987852\n",
      "Iteration 7231, loss = 2467.87414087\n",
      "Iteration 7232, loss = 2467.85842388\n",
      "Iteration 7233, loss = 2467.84272765\n",
      "Iteration 7234, loss = 2467.82705241\n",
      "Iteration 7235, loss = 2467.81139835\n",
      "Iteration 7236, loss = 2467.79576499\n",
      "Iteration 7237, loss = 2467.78015034\n",
      "Iteration 7238, loss = 2467.76455271\n",
      "Iteration 7239, loss = 2467.74897490\n",
      "Iteration 7240, loss = 2467.73342105\n",
      "Iteration 7241, loss = 2467.71788958\n",
      "Iteration 7242, loss = 2467.70237588\n",
      "Iteration 7243, loss = 2467.68688004\n",
      "Iteration 7244, loss = 2467.67140638\n",
      "Iteration 7245, loss = 2467.65595496\n",
      "Iteration 7246, loss = 2467.64052198\n",
      "Iteration 7247, loss = 2467.62510754\n",
      "Iteration 7248, loss = 2467.60971486\n",
      "Iteration 7249, loss = 2467.59434326\n",
      "Iteration 7250, loss = 2467.57899010\n",
      "Iteration 7251, loss = 2467.56365652\n",
      "Iteration 7252, loss = 2467.54834435\n",
      "Iteration 7253, loss = 2467.53305209\n",
      "Iteration 7254, loss = 2467.51777860\n",
      "Iteration 7255, loss = 2467.50252544\n",
      "Iteration 7256, loss = 2467.48729295\n",
      "Iteration 7257, loss = 2467.47207969\n",
      "Iteration 7258, loss = 2467.45688583\n",
      "Iteration 7259, loss = 2467.44171242\n",
      "Iteration 7260, loss = 2467.42655889\n",
      "Iteration 7261, loss = 2467.41142453\n",
      "Iteration 7262, loss = 2467.39631001\n",
      "Iteration 7263, loss = 2467.38121560\n",
      "Iteration 7264, loss = 2467.36614058\n",
      "Iteration 7265, loss = 2467.35108497\n",
      "Iteration 7266, loss = 2467.33604927\n",
      "Iteration 7267, loss = 2467.32103323\n",
      "Iteration 7268, loss = 2467.30603647\n",
      "Iteration 7269, loss = 2467.29105928\n",
      "Iteration 7270, loss = 2467.27610181\n",
      "Iteration 7271, loss = 2467.26116369\n",
      "Iteration 7272, loss = 2467.24624490\n",
      "Iteration 7273, loss = 2467.23134568\n",
      "Iteration 7274, loss = 2467.21646590\n",
      "Iteration 7275, loss = 2467.20160535\n",
      "Iteration 7276, loss = 2467.18676417\n",
      "Iteration 7277, loss = 2467.17194240\n",
      "Iteration 7278, loss = 2467.15713988\n",
      "Iteration 7279, loss = 2467.14235655\n",
      "Iteration 7280, loss = 2467.12759253\n",
      "Iteration 7281, loss = 2467.11284775\n",
      "Iteration 7282, loss = 2467.09812209\n",
      "Iteration 7283, loss = 2467.08341559\n",
      "Iteration 7284, loss = 2467.06872827\n",
      "Iteration 7285, loss = 2467.05406004\n",
      "Iteration 7286, loss = 2467.03941085\n",
      "Iteration 7287, loss = 2467.02478074\n",
      "Iteration 7288, loss = 2467.01016968\n",
      "Iteration 7289, loss = 2466.99557759\n",
      "Iteration 7290, loss = 2466.98100446\n",
      "Iteration 7291, loss = 2466.96645031\n",
      "Iteration 7292, loss = 2466.95191507\n",
      "Iteration 7293, loss = 2466.93739871\n",
      "Iteration 7294, loss = 2466.92290123\n",
      "Iteration 7295, loss = 2466.90842259\n",
      "Iteration 7296, loss = 2466.89396277\n",
      "Iteration 7297, loss = 2466.87952172\n",
      "Iteration 7298, loss = 2466.86509944\n",
      "Iteration 7299, loss = 2466.85069590\n",
      "Iteration 7300, loss = 2466.83631106\n",
      "Iteration 7301, loss = 2466.82194490\n",
      "Iteration 7302, loss = 2466.80759740\n",
      "Iteration 7303, loss = 2466.79326853\n",
      "Iteration 7304, loss = 2466.77895826\n",
      "Iteration 7305, loss = 2466.76466656\n",
      "Iteration 7306, loss = 2466.75039342\n",
      "Iteration 7307, loss = 2466.73613880\n",
      "Iteration 7308, loss = 2466.72190267\n",
      "Iteration 7309, loss = 2466.70768502\n",
      "Iteration 7310, loss = 2466.69348580\n",
      "Iteration 7311, loss = 2466.67930501\n",
      "Iteration 7312, loss = 2466.66514260\n",
      "Iteration 7313, loss = 2466.65099856\n",
      "Iteration 7314, loss = 2466.63687285\n",
      "Iteration 7315, loss = 2466.62276545\n",
      "Iteration 7316, loss = 2466.60867634\n",
      "Iteration 7317, loss = 2466.59460549\n",
      "Iteration 7318, loss = 2466.58055286\n",
      "Iteration 7319, loss = 2466.56651844\n",
      "Iteration 7320, loss = 2466.55250220\n",
      "Iteration 7321, loss = 2466.53850411\n",
      "Iteration 7322, loss = 2466.52452415\n",
      "Iteration 7323, loss = 2466.51056228\n",
      "Iteration 7324, loss = 2466.49661849\n",
      "Iteration 7325, loss = 2466.48269274\n",
      "Iteration 7326, loss = 2466.46878501\n",
      "Iteration 7327, loss = 2466.45489527\n",
      "Iteration 7328, loss = 2466.44102349\n",
      "Iteration 7329, loss = 2466.42716966\n",
      "Iteration 7330, loss = 2466.41333374\n",
      "Iteration 7331, loss = 2466.39951570\n",
      "Iteration 7332, loss = 2466.38571552\n",
      "Iteration 7333, loss = 2466.37193318\n",
      "Iteration 7334, loss = 2466.35816864\n",
      "Iteration 7335, loss = 2466.34442189\n",
      "Iteration 7336, loss = 2466.33069288\n",
      "Iteration 7337, loss = 2466.31698160\n",
      "Iteration 7338, loss = 2466.30328803\n",
      "Iteration 7339, loss = 2466.28961212\n",
      "Iteration 7340, loss = 2466.27595387\n",
      "Iteration 7341, loss = 2466.26231323\n",
      "Iteration 7342, loss = 2466.24869019\n",
      "Iteration 7343, loss = 2466.23508471\n",
      "Iteration 7344, loss = 2466.22149678\n",
      "Iteration 7345, loss = 2466.20792635\n",
      "Iteration 7346, loss = 2466.19437342\n",
      "Iteration 7347, loss = 2466.18083795\n",
      "Iteration 7348, loss = 2466.16731991\n",
      "Iteration 7349, loss = 2466.15381928\n",
      "Iteration 7350, loss = 2466.14033603\n",
      "Iteration 7351, loss = 2466.12687013\n",
      "Iteration 7352, loss = 2466.11342157\n",
      "Iteration 7353, loss = 2466.09999030\n",
      "Iteration 7354, loss = 2466.08657631\n",
      "Iteration 7355, loss = 2466.07317957\n",
      "Iteration 7356, loss = 2466.05980005\n",
      "Iteration 7357, loss = 2466.04643772\n",
      "Iteration 7358, loss = 2466.03309257\n",
      "Iteration 7359, loss = 2466.01976455\n",
      "Iteration 7360, loss = 2466.00645365\n",
      "Iteration 7361, loss = 2465.99315984\n",
      "Iteration 7362, loss = 2465.97988309\n",
      "Iteration 7363, loss = 2465.96662337\n",
      "Iteration 7364, loss = 2465.95338067\n",
      "Iteration 7365, loss = 2465.94015494\n",
      "Iteration 7366, loss = 2465.92694617\n",
      "Iteration 7367, loss = 2465.91375434\n",
      "Iteration 7368, loss = 2465.90057940\n",
      "Iteration 7369, loss = 2465.88742134\n",
      "Iteration 7370, loss = 2465.87428012\n",
      "Iteration 7371, loss = 2465.86115573\n",
      "Iteration 7372, loss = 2465.84804814\n",
      "Iteration 7373, loss = 2465.83495731\n",
      "Iteration 7374, loss = 2465.82188323\n",
      "Iteration 7375, loss = 2465.80882586\n",
      "Iteration 7376, loss = 2465.79578518\n",
      "Iteration 7377, loss = 2465.78276117\n",
      "Iteration 7378, loss = 2465.76975378\n",
      "Iteration 7379, loss = 2465.75676301\n",
      "Iteration 7380, loss = 2465.74378882\n",
      "Iteration 7381, loss = 2465.73083119\n",
      "Iteration 7382, loss = 2465.71789009\n",
      "Iteration 7383, loss = 2465.70496549\n",
      "Iteration 7384, loss = 2465.69205736\n",
      "Iteration 7385, loss = 2465.67916568\n",
      "Iteration 7386, loss = 2465.66629043\n",
      "Iteration 7387, loss = 2465.65343157\n",
      "Iteration 7388, loss = 2465.64058908\n",
      "Iteration 7389, loss = 2465.62776293\n",
      "Iteration 7390, loss = 2465.61495310\n",
      "Iteration 7391, loss = 2465.60215956\n",
      "Iteration 7392, loss = 2465.58938228\n",
      "Iteration 7393, loss = 2465.57662124\n",
      "Iteration 7394, loss = 2465.56387640\n",
      "Iteration 7395, loss = 2465.55114775\n",
      "Iteration 7396, loss = 2465.53843525\n",
      "Iteration 7397, loss = 2465.52573888\n",
      "Iteration 7398, loss = 2465.51305861\n",
      "Iteration 7399, loss = 2465.50039442\n",
      "Iteration 7400, loss = 2465.48774628\n",
      "Iteration 7401, loss = 2465.47511416\n",
      "Iteration 7402, loss = 2465.46249803\n",
      "Iteration 7403, loss = 2465.44989787\n",
      "Iteration 7404, loss = 2465.43731366\n",
      "Iteration 7405, loss = 2465.42474536\n",
      "Iteration 7406, loss = 2465.41219295\n",
      "Iteration 7407, loss = 2465.39965640\n",
      "Iteration 7408, loss = 2465.38713568\n",
      "Iteration 7409, loss = 2465.37463077\n",
      "Iteration 7410, loss = 2465.36214165\n",
      "Iteration 7411, loss = 2465.34966828\n",
      "Iteration 7412, loss = 2465.33721063\n",
      "Iteration 7413, loss = 2465.32476869\n",
      "Iteration 7414, loss = 2465.31234242\n",
      "Iteration 7415, loss = 2465.29993180\n",
      "Iteration 7416, loss = 2465.28753680\n",
      "Iteration 7417, loss = 2465.27515739\n",
      "Iteration 7418, loss = 2465.26279355\n",
      "Iteration 7419, loss = 2465.25044526\n",
      "Iteration 7420, loss = 2465.23811247\n",
      "Iteration 7421, loss = 2465.22579517\n",
      "Iteration 7422, loss = 2465.21349333\n",
      "Iteration 7423, loss = 2465.20120693\n",
      "Iteration 7424, loss = 2465.18893593\n",
      "Iteration 7425, loss = 2465.17668031\n",
      "Iteration 7426, loss = 2465.16444005\n",
      "Iteration 7427, loss = 2465.15221511\n",
      "Iteration 7428, loss = 2465.14000547\n",
      "Iteration 7429, loss = 2465.12781110\n",
      "Iteration 7430, loss = 2465.11563198\n",
      "Iteration 7431, loss = 2465.10346808\n",
      "Iteration 7432, loss = 2465.09131937\n",
      "Iteration 7433, loss = 2465.07918582\n",
      "Iteration 7434, loss = 2465.06706741\n",
      "Iteration 7435, loss = 2465.05496412\n",
      "Iteration 7436, loss = 2465.04287591\n",
      "Iteration 7437, loss = 2465.03080275\n",
      "Iteration 7438, loss = 2465.01874463\n",
      "Iteration 7439, loss = 2465.00670151\n",
      "Iteration 7440, loss = 2464.99467337\n",
      "Iteration 7441, loss = 2464.98266018\n",
      "Iteration 7442, loss = 2464.97066192\n",
      "Iteration 7443, loss = 2464.95867855\n",
      "Iteration 7444, loss = 2464.94671005\n",
      "Iteration 7445, loss = 2464.93475639\n",
      "Iteration 7446, loss = 2464.92281755\n",
      "Iteration 7447, loss = 2464.91089350\n",
      "Iteration 7448, loss = 2464.89898421\n",
      "Iteration 7449, loss = 2464.88708965\n",
      "Iteration 7450, loss = 2464.87520981\n",
      "Iteration 7451, loss = 2464.86334465\n",
      "Iteration 7452, loss = 2464.85149414\n",
      "Iteration 7453, loss = 2464.83965826\n",
      "Iteration 7454, loss = 2464.82783698\n",
      "Iteration 7455, loss = 2464.81603027\n",
      "Iteration 7456, loss = 2464.80423811\n",
      "Iteration 7457, loss = 2464.79246047\n",
      "Iteration 7458, loss = 2464.78069733\n",
      "Iteration 7459, loss = 2464.76894865\n",
      "Iteration 7460, loss = 2464.75721441\n",
      "Iteration 7461, loss = 2464.74549458\n",
      "Iteration 7462, loss = 2464.73378914\n",
      "Iteration 7463, loss = 2464.72209806\n",
      "Iteration 7464, loss = 2464.71042131\n",
      "Iteration 7465, loss = 2464.69875886\n",
      "Iteration 7466, loss = 2464.68711070\n",
      "Iteration 7467, loss = 2464.67547678\n",
      "Iteration 7468, loss = 2464.66385708\n",
      "Iteration 7469, loss = 2464.65225159\n",
      "Iteration 7470, loss = 2464.64066026\n",
      "Iteration 7471, loss = 2464.62908308\n",
      "Iteration 7472, loss = 2464.61752001\n",
      "Iteration 7473, loss = 2464.60597103\n",
      "Iteration 7474, loss = 2464.59443611\n",
      "Iteration 7475, loss = 2464.58291523\n",
      "Iteration 7476, loss = 2464.57140835\n",
      "Iteration 7477, loss = 2464.55991546\n",
      "Iteration 7478, loss = 2464.54843652\n",
      "Iteration 7479, loss = 2464.53697151\n",
      "Iteration 7480, loss = 2464.52552040\n",
      "Iteration 7481, loss = 2464.51408316\n",
      "Iteration 7482, loss = 2464.50265976\n",
      "Iteration 7483, loss = 2464.49125019\n",
      "Iteration 7484, loss = 2464.47985440\n",
      "Iteration 7485, loss = 2464.46847238\n",
      "Iteration 7486, loss = 2464.45710410\n",
      "Iteration 7487, loss = 2464.44574953\n",
      "Iteration 7488, loss = 2464.43440864\n",
      "Iteration 7489, loss = 2464.42308141\n",
      "Iteration 7490, loss = 2464.41176781\n",
      "Iteration 7491, loss = 2464.40046781\n",
      "Iteration 7492, loss = 2464.38918139\n",
      "Iteration 7493, loss = 2464.37790851\n",
      "Iteration 7494, loss = 2464.36664915\n",
      "Iteration 7495, loss = 2464.35540329\n",
      "Iteration 7496, loss = 2464.34417090\n",
      "Iteration 7497, loss = 2464.33295194\n",
      "Iteration 7498, loss = 2464.32174640\n",
      "Iteration 7499, loss = 2464.31055425\n",
      "Iteration 7500, loss = 2464.29937545\n",
      "Iteration 7501, loss = 2464.28820998\n",
      "Iteration 7502, loss = 2464.27705782\n",
      "Iteration 7503, loss = 2464.26591893\n",
      "Iteration 7504, loss = 2464.25479330\n",
      "Iteration 7505, loss = 2464.24368088\n",
      "Iteration 7506, loss = 2464.23258166\n",
      "Iteration 7507, loss = 2464.22149561\n",
      "Iteration 7508, loss = 2464.21042271\n",
      "Iteration 7509, loss = 2464.19936291\n",
      "Iteration 7510, loss = 2464.18831620\n",
      "Iteration 7511, loss = 2464.17728255\n",
      "Iteration 7512, loss = 2464.16626194\n",
      "Iteration 7513, loss = 2464.15525433\n",
      "Iteration 7514, loss = 2464.14425970\n",
      "Iteration 7515, loss = 2464.13327801\n",
      "Iteration 7516, loss = 2464.12230926\n",
      "Iteration 7517, loss = 2464.11135340\n",
      "Iteration 7518, loss = 2464.10041040\n",
      "Iteration 7519, loss = 2464.08948025\n",
      "Iteration 7520, loss = 2464.07856292\n",
      "Iteration 7521, loss = 2464.06765837\n",
      "Iteration 7522, loss = 2464.05676658\n",
      "Iteration 7523, loss = 2464.04588753\n",
      "Iteration 7524, loss = 2464.03502118\n",
      "Iteration 7525, loss = 2464.02416750\n",
      "Iteration 7526, loss = 2464.01332649\n",
      "Iteration 7527, loss = 2464.00249809\n",
      "Iteration 7528, loss = 2463.99168229\n",
      "Iteration 7529, loss = 2463.98087906\n",
      "Iteration 7530, loss = 2463.97008837\n",
      "Iteration 7531, loss = 2463.95931020\n",
      "Iteration 7532, loss = 2463.94854451\n",
      "Iteration 7533, loss = 2463.93779129\n",
      "Iteration 7534, loss = 2463.92705049\n",
      "Iteration 7535, loss = 2463.91632211\n",
      "Iteration 7536, loss = 2463.90560610\n",
      "Iteration 7537, loss = 2463.89490244\n",
      "Iteration 7538, loss = 2463.88421110\n",
      "Iteration 7539, loss = 2463.87353206\n",
      "Iteration 7540, loss = 2463.86286529\n",
      "Iteration 7541, loss = 2463.85221076\n",
      "Iteration 7542, loss = 2463.84156845\n",
      "Iteration 7543, loss = 2463.83093832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7544, loss = 2463.82032035\n",
      "Iteration 7545, loss = 2463.80971451\n",
      "Iteration 7546, loss = 2463.79912078\n",
      "Iteration 7547, loss = 2463.78853912\n",
      "Iteration 7548, loss = 2463.77796951\n",
      "Iteration 7549, loss = 2463.76741193\n",
      "Iteration 7550, loss = 2463.75686634\n",
      "Iteration 7551, loss = 2463.74633272\n",
      "Iteration 7552, loss = 2463.73581103\n",
      "Iteration 7553, loss = 2463.72530126\n",
      "Iteration 7554, loss = 2463.71480338\n",
      "Iteration 7555, loss = 2463.70431735\n",
      "Iteration 7556, loss = 2463.69384315\n",
      "Iteration 7557, loss = 2463.68338075\n",
      "Iteration 7558, loss = 2463.67293013\n",
      "Iteration 7559, loss = 2463.66249126\n",
      "Iteration 7560, loss = 2463.65206410\n",
      "Iteration 7561, loss = 2463.64164864\n",
      "Iteration 7562, loss = 2463.63124485\n",
      "Iteration 7563, loss = 2463.62085269\n",
      "Iteration 7564, loss = 2463.61047214\n",
      "Iteration 7565, loss = 2463.60010317\n",
      "Iteration 7566, loss = 2463.58974576\n",
      "Iteration 7567, loss = 2463.57939988\n",
      "Iteration 7568, loss = 2463.56906549\n",
      "Iteration 7569, loss = 2463.55874258\n",
      "Iteration 7570, loss = 2463.54843111\n",
      "Iteration 7571, loss = 2463.53813106\n",
      "Iteration 7572, loss = 2463.52784240\n",
      "Iteration 7573, loss = 2463.51756510\n",
      "Iteration 7574, loss = 2463.50729914\n",
      "Iteration 7575, loss = 2463.49704448\n",
      "Iteration 7576, loss = 2463.48680110\n",
      "Iteration 7577, loss = 2463.47656897\n",
      "Iteration 7578, loss = 2463.46634807\n",
      "Iteration 7579, loss = 2463.45613836\n",
      "Iteration 7580, loss = 2463.44593982\n",
      "Iteration 7581, loss = 2463.43575242\n",
      "Iteration 7582, loss = 2463.42557613\n",
      "Iteration 7583, loss = 2463.41541093\n",
      "Iteration 7584, loss = 2463.40525679\n",
      "Iteration 7585, loss = 2463.39511367\n",
      "Iteration 7586, loss = 2463.38498156\n",
      "Iteration 7587, loss = 2463.37486043\n",
      "Iteration 7588, loss = 2463.36475024\n",
      "Iteration 7589, loss = 2463.35465097\n",
      "Iteration 7590, loss = 2463.34456259\n",
      "Iteration 7591, loss = 2463.33448507\n",
      "Iteration 7592, loss = 2463.32441839\n",
      "Iteration 7593, loss = 2463.31436252\n",
      "Iteration 7594, loss = 2463.30431743\n",
      "Iteration 7595, loss = 2463.29428310\n",
      "Iteration 7596, loss = 2463.28425950\n",
      "Iteration 7597, loss = 2463.27424660\n",
      "Iteration 7598, loss = 2463.26424441\n",
      "Iteration 7599, loss = 2463.25425291\n",
      "Iteration 7600, loss = 2463.24427218\n",
      "Iteration 7601, loss = 2463.23430234\n",
      "Iteration 7602, loss = 2463.22434367\n",
      "Iteration 7603, loss = 2463.21439650\n",
      "Iteration 7604, loss = 2463.20446057\n",
      "Iteration 7605, loss = 2463.19453351\n",
      "Iteration 7606, loss = 2463.18461243\n",
      "Iteration 7607, loss = 2463.17470030\n",
      "Iteration 7608, loss = 2463.16480330\n",
      "Iteration 7609, loss = 2463.15491980\n",
      "Iteration 7610, loss = 2463.14504329\n",
      "Iteration 7611, loss = 2463.13517400\n",
      "Iteration 7612, loss = 2463.12531803\n",
      "Iteration 7613, loss = 2463.11547470\n",
      "Iteration 7614, loss = 2463.10563873\n",
      "Iteration 7615, loss = 2463.09581160\n",
      "Iteration 7616, loss = 2463.08599742\n",
      "Iteration 7617, loss = 2463.07619368\n",
      "Iteration 7618, loss = 2463.06639770\n",
      "Iteration 7619, loss = 2463.05661244\n",
      "Iteration 7620, loss = 2463.04683894\n",
      "Iteration 7621, loss = 2463.03707426\n",
      "Iteration 7622, loss = 2463.02731873\n",
      "Iteration 7623, loss = 2463.01757455\n",
      "Iteration 7624, loss = 2463.00784039\n",
      "Iteration 7625, loss = 2462.99811500\n",
      "Iteration 7626, loss = 2462.98839998\n",
      "Iteration 7627, loss = 2462.97869554\n",
      "Iteration 7628, loss = 2462.96900018\n",
      "Iteration 7629, loss = 2462.95931443\n",
      "Iteration 7630, loss = 2462.94963916\n",
      "Iteration 7631, loss = 2462.93997345\n",
      "Iteration 7632, loss = 2462.93031699\n",
      "Iteration 7633, loss = 2462.92067061\n",
      "Iteration 7634, loss = 2462.91103408\n",
      "Iteration 7635, loss = 2462.90140677\n",
      "Iteration 7636, loss = 2462.89178913\n",
      "Iteration 7637, loss = 2462.88218137\n",
      "Iteration 7638, loss = 2462.87258297\n",
      "Iteration 7639, loss = 2462.86299393\n",
      "Iteration 7640, loss = 2462.85341463\n",
      "Iteration 7641, loss = 2462.84384480\n",
      "Iteration 7642, loss = 2462.83428421\n",
      "Iteration 7643, loss = 2462.82473311\n",
      "Iteration 7644, loss = 2462.81519152\n",
      "Iteration 7645, loss = 2462.80565915\n",
      "Iteration 7646, loss = 2462.79613607\n",
      "Iteration 7647, loss = 2462.78662240\n",
      "Iteration 7648, loss = 2462.77711797\n",
      "Iteration 7649, loss = 2462.76762270\n",
      "Iteration 7650, loss = 2462.75813669\n",
      "Iteration 7651, loss = 2462.74865991\n",
      "Iteration 7652, loss = 2462.73919222\n",
      "Iteration 7653, loss = 2462.72973365\n",
      "Iteration 7654, loss = 2462.72028423\n",
      "Iteration 7655, loss = 2462.71084386\n",
      "Iteration 7656, loss = 2462.70141249\n",
      "Iteration 7657, loss = 2462.69199017\n",
      "Iteration 7658, loss = 2462.68257684\n",
      "Iteration 7659, loss = 2462.67317244\n",
      "Iteration 7660, loss = 2462.66377696\n",
      "Iteration 7661, loss = 2462.65439041\n",
      "Iteration 7662, loss = 2462.64501271\n",
      "Iteration 7663, loss = 2462.63564384\n",
      "Iteration 7664, loss = 2462.62628380\n",
      "Iteration 7665, loss = 2462.61693254\n",
      "Iteration 7666, loss = 2462.60759003\n",
      "Iteration 7667, loss = 2462.59825625\n",
      "Iteration 7668, loss = 2462.58893117\n",
      "Iteration 7669, loss = 2462.57961476\n",
      "Iteration 7670, loss = 2462.57030698\n",
      "Iteration 7671, loss = 2462.56100782\n",
      "Iteration 7672, loss = 2462.55171725\n",
      "Iteration 7673, loss = 2462.54243523\n",
      "Iteration 7674, loss = 2462.53316173\n",
      "Iteration 7675, loss = 2462.52389674\n",
      "Iteration 7676, loss = 2462.51464021\n",
      "Iteration 7677, loss = 2462.50539212\n",
      "Iteration 7678, loss = 2462.49615245\n",
      "Iteration 7679, loss = 2462.48692116\n",
      "Iteration 7680, loss = 2462.47769822\n",
      "Iteration 7681, loss = 2462.46848361\n",
      "Iteration 7682, loss = 2462.45927730\n",
      "Iteration 7683, loss = 2462.45007925\n",
      "Iteration 7684, loss = 2462.44088945\n",
      "Iteration 7685, loss = 2462.43170785\n",
      "Iteration 7686, loss = 2462.42253444\n",
      "Iteration 7687, loss = 2462.41336918\n",
      "Iteration 7688, loss = 2462.40421204\n",
      "Iteration 7689, loss = 2462.39506300\n",
      "Iteration 7690, loss = 2462.38592203\n",
      "Iteration 7691, loss = 2462.37678910\n",
      "Iteration 7692, loss = 2462.36766417\n",
      "Iteration 7693, loss = 2462.35854722\n",
      "Iteration 7694, loss = 2462.34943823\n",
      "Iteration 7695, loss = 2462.34033716\n",
      "Iteration 7696, loss = 2462.33124398\n",
      "Iteration 7697, loss = 2462.32215867\n",
      "Iteration 7698, loss = 2462.31308119\n",
      "Iteration 7699, loss = 2462.30401152\n",
      "Iteration 7700, loss = 2462.29494963\n",
      "Iteration 7701, loss = 2462.28589548\n",
      "Iteration 7702, loss = 2462.27684906\n",
      "Iteration 7703, loss = 2462.26781033\n",
      "Iteration 7704, loss = 2462.25877926\n",
      "Iteration 7705, loss = 2462.24975582\n",
      "Iteration 7706, loss = 2462.24073998\n",
      "Iteration 7707, loss = 2462.23173172\n",
      "Iteration 7708, loss = 2462.22273101\n",
      "Iteration 7709, loss = 2462.21373781\n",
      "Iteration 7710, loss = 2462.20475210\n",
      "Iteration 7711, loss = 2462.19577385\n",
      "Iteration 7712, loss = 2462.18680302\n",
      "Iteration 7713, loss = 2462.17783960\n",
      "Iteration 7714, loss = 2462.16888355\n",
      "Iteration 7715, loss = 2462.15993484\n",
      "Iteration 7716, loss = 2462.15099344\n",
      "Iteration 7717, loss = 2462.14205932\n",
      "Iteration 7718, loss = 2462.13313246\n",
      "Iteration 7719, loss = 2462.12421283\n",
      "Iteration 7720, loss = 2462.11530039\n",
      "Iteration 7721, loss = 2462.10639511\n",
      "Iteration 7722, loss = 2462.09749697\n",
      "Iteration 7723, loss = 2462.08860594\n",
      "Iteration 7724, loss = 2462.07972199\n",
      "Iteration 7725, loss = 2462.07084509\n",
      "Iteration 7726, loss = 2462.06197520\n",
      "Iteration 7727, loss = 2462.05311231\n",
      "Iteration 7728, loss = 2462.04425638\n",
      "Iteration 7729, loss = 2462.03540738\n",
      "Iteration 7730, loss = 2462.02656528\n",
      "Iteration 7731, loss = 2462.01773005\n",
      "Iteration 7732, loss = 2462.00890167\n",
      "Iteration 7733, loss = 2462.00008010\n",
      "Iteration 7734, loss = 2461.99126531\n",
      "Iteration 7735, loss = 2461.98245728\n",
      "Iteration 7736, loss = 2461.97365598\n",
      "Iteration 7737, loss = 2461.96486136\n",
      "Iteration 7738, loss = 2461.95607342\n",
      "Iteration 7739, loss = 2461.94729211\n",
      "Iteration 7740, loss = 2461.93851741\n",
      "Iteration 7741, loss = 2461.92974929\n",
      "Iteration 7742, loss = 2461.92098771\n",
      "Iteration 7743, loss = 2461.91223265\n",
      "Iteration 7744, loss = 2461.90348409\n",
      "Iteration 7745, loss = 2461.89474197\n",
      "Iteration 7746, loss = 2461.88600629\n",
      "Iteration 7747, loss = 2461.87727701\n",
      "Iteration 7748, loss = 2461.86855410\n",
      "Iteration 7749, loss = 2461.85983753\n",
      "Iteration 7750, loss = 2461.85112726\n",
      "Iteration 7751, loss = 2461.84242328\n",
      "Iteration 7752, loss = 2461.83372555\n",
      "Iteration 7753, loss = 2461.82503404\n",
      "Iteration 7754, loss = 2461.81634872\n",
      "Iteration 7755, loss = 2461.80766956\n",
      "Iteration 7756, loss = 2461.79899653\n",
      "Iteration 7757, loss = 2461.79032961\n",
      "Iteration 7758, loss = 2461.78166875\n",
      "Iteration 7759, loss = 2461.77301394\n",
      "Iteration 7760, loss = 2461.76436514\n",
      "Iteration 7761, loss = 2461.75572232\n",
      "Iteration 7762, loss = 2461.74708545\n",
      "Iteration 7763, loss = 2461.73845450\n",
      "Iteration 7764, loss = 2461.72982945\n",
      "Iteration 7765, loss = 2461.72121025\n",
      "Iteration 7766, loss = 2461.71259689\n",
      "Iteration 7767, loss = 2461.70398933\n",
      "Iteration 7768, loss = 2461.69538754\n",
      "Iteration 7769, loss = 2461.68679149\n",
      "Iteration 7770, loss = 2461.67820116\n",
      "Iteration 7771, loss = 2461.66961650\n",
      "Iteration 7772, loss = 2461.66103750\n",
      "Iteration 7773, loss = 2461.65246412\n",
      "Iteration 7774, loss = 2461.64389632\n",
      "Iteration 7775, loss = 2461.63533409\n",
      "Iteration 7776, loss = 2461.62677739\n",
      "Iteration 7777, loss = 2461.61822619\n",
      "Iteration 7778, loss = 2461.60968046\n",
      "Iteration 7779, loss = 2461.60114016\n",
      "Iteration 7780, loss = 2461.59260528\n",
      "Iteration 7781, loss = 2461.58407577\n",
      "Iteration 7782, loss = 2461.57555161\n",
      "Iteration 7783, loss = 2461.56703278\n",
      "Iteration 7784, loss = 2461.55851922\n",
      "Iteration 7785, loss = 2461.55001093\n",
      "Iteration 7786, loss = 2461.54150786\n",
      "Iteration 7787, loss = 2461.53300999\n",
      "Iteration 7788, loss = 2461.52451728\n",
      "Iteration 7789, loss = 2461.51602971\n",
      "Iteration 7790, loss = 2461.50754725\n",
      "Iteration 7791, loss = 2461.49906986\n",
      "Iteration 7792, loss = 2461.49059751\n",
      "Iteration 7793, loss = 2461.48213017\n",
      "Iteration 7794, loss = 2461.47366782\n",
      "Iteration 7795, loss = 2461.46521042\n",
      "Iteration 7796, loss = 2461.45675794\n",
      "Iteration 7797, loss = 2461.44831035\n",
      "Iteration 7798, loss = 2461.43986762\n",
      "Iteration 7799, loss = 2461.43142972\n",
      "Iteration 7800, loss = 2461.42299662\n",
      "Iteration 7801, loss = 2461.41456829\n",
      "Iteration 7802, loss = 2461.40614469\n",
      "Iteration 7803, loss = 2461.39772580\n",
      "Iteration 7804, loss = 2461.38931159\n",
      "Iteration 7805, loss = 2461.38090202\n",
      "Iteration 7806, loss = 2461.37249706\n",
      "Iteration 7807, loss = 2461.36409668\n",
      "Iteration 7808, loss = 2461.35570086\n",
      "Iteration 7809, loss = 2461.34730956\n",
      "Iteration 7810, loss = 2461.33892275\n",
      "Iteration 7811, loss = 2461.33054040\n",
      "Iteration 7812, loss = 2461.32216247\n",
      "Iteration 7813, loss = 2461.31378895\n",
      "Iteration 7814, loss = 2461.30541979\n",
      "Iteration 7815, loss = 2461.29705496\n",
      "Iteration 7816, loss = 2461.28869444\n",
      "Iteration 7817, loss = 2461.28033819\n",
      "Iteration 7818, loss = 2461.27198618\n",
      "Iteration 7819, loss = 2461.26363838\n",
      "Iteration 7820, loss = 2461.25529477\n",
      "Iteration 7821, loss = 2461.24695530\n",
      "Iteration 7822, loss = 2461.23861994\n",
      "Iteration 7823, loss = 2461.23028868\n",
      "Iteration 7824, loss = 2461.22196146\n",
      "Iteration 7825, loss = 2461.21363828\n",
      "Iteration 7826, loss = 2461.20531908\n",
      "Iteration 7827, loss = 2461.19700384\n",
      "Iteration 7828, loss = 2461.18869253\n",
      "Iteration 7829, loss = 2461.18038512\n",
      "Iteration 7830, loss = 2461.17208158\n",
      "Iteration 7831, loss = 2461.16378187\n",
      "Iteration 7832, loss = 2461.15548597\n",
      "Iteration 7833, loss = 2461.14719383\n",
      "Iteration 7834, loss = 2461.13890544\n",
      "Iteration 7835, loss = 2461.13062076\n",
      "Iteration 7836, loss = 2461.12233975\n",
      "Iteration 7837, loss = 2461.11406239\n",
      "Iteration 7838, loss = 2461.10578864\n",
      "Iteration 7839, loss = 2461.09751848\n",
      "Iteration 7840, loss = 2461.08925187\n",
      "Iteration 7841, loss = 2461.08098877\n",
      "Iteration 7842, loss = 2461.07272917\n",
      "Iteration 7843, loss = 2461.06447302\n",
      "Iteration 7844, loss = 2461.05622029\n",
      "Iteration 7845, loss = 2461.04797096\n",
      "Iteration 7846, loss = 2461.03972499\n",
      "Iteration 7847, loss = 2461.03148234\n",
      "Iteration 7848, loss = 2461.02324300\n",
      "Iteration 7849, loss = 2461.01500692\n",
      "Iteration 7850, loss = 2461.00677407\n",
      "Iteration 7851, loss = 2460.99854442\n",
      "Iteration 7852, loss = 2460.99031794\n",
      "Iteration 7853, loss = 2460.98209460\n",
      "Iteration 7854, loss = 2460.97387437\n",
      "Iteration 7855, loss = 2460.96565720\n",
      "Iteration 7856, loss = 2460.95744308\n",
      "Iteration 7857, loss = 2460.94923197\n",
      "Iteration 7858, loss = 2460.94102383\n",
      "Iteration 7859, loss = 2460.93281864\n",
      "Iteration 7860, loss = 2460.92461637\n",
      "Iteration 7861, loss = 2460.91641697\n",
      "Iteration 7862, loss = 2460.90822042\n",
      "Iteration 7863, loss = 2460.90002669\n",
      "Iteration 7864, loss = 2460.89183574\n",
      "Iteration 7865, loss = 2460.88364754\n",
      "Iteration 7866, loss = 2460.87546206\n",
      "Iteration 7867, loss = 2460.86727927\n",
      "Iteration 7868, loss = 2460.85909913\n",
      "Iteration 7869, loss = 2460.85092162\n",
      "Iteration 7870, loss = 2460.84274669\n",
      "Iteration 7871, loss = 2460.83457432\n",
      "Iteration 7872, loss = 2460.82640448\n",
      "Iteration 7873, loss = 2460.81823712\n",
      "Iteration 7874, loss = 2460.81007223\n",
      "Iteration 7875, loss = 2460.80190977\n",
      "Iteration 7876, loss = 2460.79374969\n",
      "Iteration 7877, loss = 2460.78559198\n",
      "Iteration 7878, loss = 2460.77743660\n",
      "Iteration 7879, loss = 2460.76928352\n",
      "Iteration 7880, loss = 2460.76113270\n",
      "Iteration 7881, loss = 2460.75298411\n",
      "Iteration 7882, loss = 2460.74483772\n",
      "Iteration 7883, loss = 2460.73669349\n",
      "Iteration 7884, loss = 2460.72855140\n",
      "Iteration 7885, loss = 2460.72041140\n",
      "Iteration 7886, loss = 2460.71227347\n",
      "Iteration 7887, loss = 2460.70413758\n",
      "Iteration 7888, loss = 2460.69600369\n",
      "Iteration 7889, loss = 2460.68787176\n",
      "Iteration 7890, loss = 2460.67974177\n",
      "Iteration 7891, loss = 2460.67161368\n",
      "Iteration 7892, loss = 2460.66348746\n",
      "Iteration 7893, loss = 2460.65536308\n",
      "Iteration 7894, loss = 2460.64724050\n",
      "Iteration 7895, loss = 2460.63911968\n",
      "Iteration 7896, loss = 2460.63100061\n",
      "Iteration 7897, loss = 2460.62288323\n",
      "Iteration 7898, loss = 2460.61476753\n",
      "Iteration 7899, loss = 2460.60665346\n",
      "Iteration 7900, loss = 2460.59854100\n",
      "Iteration 7901, loss = 2460.59043010\n",
      "Iteration 7902, loss = 2460.58232075\n",
      "Iteration 7903, loss = 2460.57421289\n",
      "Iteration 7904, loss = 2460.56610651\n",
      "Iteration 7905, loss = 2460.55800157\n",
      "Iteration 7906, loss = 2460.54989803\n",
      "Iteration 7907, loss = 2460.54179588\n",
      "Iteration 7908, loss = 2460.53369510\n",
      "Iteration 7909, loss = 2460.52559570\n",
      "Iteration 7910, loss = 2460.51749774\n",
      "Iteration 7911, loss = 2460.50940135\n",
      "Iteration 7912, loss = 2460.50130686\n",
      "Iteration 7913, loss = 2460.49321462\n",
      "Iteration 7914, loss = 2460.48512428\n",
      "Iteration 7915, loss = 2460.47703330\n",
      "Iteration 7916, loss = 2460.46893847\n",
      "Iteration 7917, loss = 2460.46084288\n",
      "Iteration 7918, loss = 2460.45275333\n",
      "Iteration 7919, loss = 2460.44466854\n",
      "Iteration 7920, loss = 2460.43658139\n",
      "Iteration 7921, loss = 2460.42849130\n",
      "Iteration 7922, loss = 2460.42040490\n",
      "Iteration 7923, loss = 2460.41232253\n",
      "Iteration 7924, loss = 2460.40423833\n",
      "Iteration 7925, loss = 2460.39615264\n",
      "Iteration 7926, loss = 2460.38807038\n",
      "Iteration 7927, loss = 2460.37999004\n",
      "Iteration 7928, loss = 2460.37190784\n",
      "Iteration 7929, loss = 2460.36382604\n",
      "Iteration 7930, loss = 2460.35574699\n",
      "Iteration 7931, loss = 2460.34766796\n",
      "Iteration 7932, loss = 2460.33958789\n",
      "Iteration 7933, loss = 2460.33150935\n",
      "Iteration 7934, loss = 2460.32343215\n",
      "Iteration 7935, loss = 2460.31535417\n",
      "Iteration 7936, loss = 2460.30727636\n",
      "Iteration 7937, loss = 2460.29919996\n",
      "Iteration 7938, loss = 2460.29112363\n",
      "Iteration 7939, loss = 2460.28304681\n",
      "Iteration 7940, loss = 2460.27497077\n",
      "Iteration 7941, loss = 2460.26689534\n",
      "Iteration 7942, loss = 2460.25881950\n",
      "Iteration 7943, loss = 2460.25074372\n",
      "Iteration 7944, loss = 2460.24266856\n",
      "Iteration 7945, loss = 2460.23459332\n",
      "Iteration 7946, loss = 2460.22651777\n",
      "Iteration 7947, loss = 2460.21844249\n",
      "Iteration 7948, loss = 2460.21036735\n",
      "Iteration 7949, loss = 2460.20229186\n",
      "Iteration 7950, loss = 2460.19421623\n",
      "Iteration 7951, loss = 2460.18614071\n",
      "Iteration 7952, loss = 2460.17806495\n",
      "Iteration 7953, loss = 2460.16998881\n",
      "Iteration 7954, loss = 2460.16191254\n",
      "Iteration 7955, loss = 2460.15383609\n",
      "Iteration 7956, loss = 2460.14575920\n",
      "Iteration 7957, loss = 2460.13768193\n",
      "Iteration 7958, loss = 2460.12960438\n",
      "Iteration 7959, loss = 2460.12152641\n",
      "Iteration 7960, loss = 2460.11344789\n",
      "Iteration 7961, loss = 2460.10536891\n",
      "Iteration 7962, loss = 2460.09728947\n",
      "Iteration 7963, loss = 2460.08920942\n",
      "Iteration 7964, loss = 2460.08112874\n",
      "Iteration 7965, loss = 2460.07304747\n",
      "Iteration 7966, loss = 2460.06496555\n",
      "Iteration 7967, loss = 2460.05688289\n",
      "Iteration 7968, loss = 2460.04879948\n",
      "Iteration 7969, loss = 2460.04071533\n",
      "Iteration 7970, loss = 2460.03263036\n",
      "Iteration 7971, loss = 2460.02454452\n",
      "Iteration 7972, loss = 2460.01645781\n",
      "Iteration 7973, loss = 2460.00837020\n",
      "Iteration 7974, loss = 2460.00028162\n",
      "Iteration 7975, loss = 2459.99219203\n",
      "Iteration 7976, loss = 2459.98410144\n",
      "Iteration 7977, loss = 2459.97600979\n",
      "Iteration 7978, loss = 2459.96791702\n",
      "Iteration 7979, loss = 2459.95982312\n",
      "Iteration 7980, loss = 2459.95172806\n",
      "Iteration 7981, loss = 2459.94363180\n",
      "Iteration 7982, loss = 2459.93553428\n",
      "Iteration 7983, loss = 2459.92743548\n",
      "Iteration 7984, loss = 2459.91933538\n",
      "Iteration 7985, loss = 2459.91123392\n",
      "Iteration 7986, loss = 2459.90313107\n",
      "Iteration 7987, loss = 2459.89502681\n",
      "Iteration 7988, loss = 2459.88692109\n",
      "Iteration 7989, loss = 2459.87881389\n",
      "Iteration 7990, loss = 2459.87070517\n",
      "Iteration 7991, loss = 2459.86259492\n",
      "Iteration 7992, loss = 2459.85448313\n",
      "Iteration 7993, loss = 2459.84636981\n",
      "Iteration 7994, loss = 2459.83825500\n",
      "Iteration 7995, loss = 2459.83013875\n",
      "Iteration 7996, loss = 2459.82202110\n",
      "Iteration 7997, loss = 2459.81390185\n",
      "Iteration 7998, loss = 2459.80578040\n",
      "Iteration 7999, loss = 2459.79765578\n",
      "Iteration 8000, loss = 2459.78952771\n",
      "Iteration 8001, loss = 2459.78139750\n",
      "Iteration 8002, loss = 2459.77326684\n",
      "Iteration 8003, loss = 2459.76513582\n",
      "Iteration 8004, loss = 2459.75700292\n",
      "Iteration 8005, loss = 2459.74886666\n",
      "Iteration 8006, loss = 2459.74072711\n",
      "Iteration 8007, loss = 2459.73258570\n",
      "Iteration 8008, loss = 2459.72444331\n",
      "Iteration 8009, loss = 2459.71629923\n",
      "Iteration 8010, loss = 2459.70815221\n",
      "Iteration 8011, loss = 2459.70000203\n",
      "Iteration 8012, loss = 2459.69184958\n",
      "Iteration 8013, loss = 2459.68369549\n",
      "Iteration 8014, loss = 2459.67553935\n",
      "Iteration 8015, loss = 2459.66738032\n",
      "Iteration 8016, loss = 2459.65921829\n",
      "Iteration 8017, loss = 2459.65105379\n",
      "Iteration 8018, loss = 2459.64288718\n",
      "Iteration 8019, loss = 2459.63471815\n",
      "Iteration 8020, loss = 2459.62654619\n",
      "Iteration 8021, loss = 2459.61837125\n",
      "Iteration 8022, loss = 2459.61019366\n",
      "Iteration 8023, loss = 2459.60201359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8024, loss = 2459.59383080\n",
      "Iteration 8025, loss = 2459.58564501\n",
      "Iteration 8026, loss = 2459.57745617\n",
      "Iteration 8027, loss = 2459.56926446\n",
      "Iteration 8028, loss = 2459.56106997\n",
      "Iteration 8029, loss = 2459.55287253\n",
      "Iteration 8030, loss = 2459.54467197\n",
      "Iteration 8031, loss = 2459.53646824\n",
      "Iteration 8032, loss = 2459.52826142\n",
      "Iteration 8033, loss = 2459.52005156\n",
      "Iteration 8034, loss = 2459.51183855\n",
      "Iteration 8035, loss = 2459.50362227\n",
      "Iteration 8036, loss = 2459.49540267\n",
      "Iteration 8037, loss = 2459.48717976\n",
      "Iteration 8038, loss = 2459.47895357\n",
      "Iteration 8039, loss = 2459.47072404\n",
      "Iteration 8040, loss = 2459.46249108\n",
      "Iteration 8041, loss = 2459.45425462\n",
      "Iteration 8042, loss = 2459.44601466\n",
      "Iteration 8043, loss = 2459.43777119\n",
      "Iteration 8044, loss = 2459.42952418\n",
      "Iteration 8045, loss = 2459.42127356\n",
      "Iteration 8046, loss = 2459.41301927\n",
      "Iteration 8047, loss = 2459.40476127\n",
      "Iteration 8048, loss = 2459.39649956\n",
      "Iteration 8049, loss = 2459.38823409\n",
      "Iteration 8050, loss = 2459.37996483\n",
      "Iteration 8051, loss = 2459.37169172\n",
      "Iteration 8052, loss = 2459.36341472\n",
      "Iteration 8053, loss = 2459.35513379\n",
      "Iteration 8054, loss = 2459.34684890\n",
      "Iteration 8055, loss = 2459.33856002\n",
      "Iteration 8056, loss = 2459.33026710\n",
      "Iteration 8057, loss = 2459.32197010\n",
      "Iteration 8058, loss = 2459.31366897\n",
      "Iteration 8059, loss = 2459.30536368\n",
      "Iteration 8060, loss = 2459.29705419\n",
      "Iteration 8061, loss = 2459.28874047\n",
      "Iteration 8062, loss = 2459.28042247\n",
      "Iteration 8063, loss = 2459.27210015\n",
      "Iteration 8064, loss = 2459.26377347\n",
      "Iteration 8065, loss = 2459.25544239\n",
      "Iteration 8066, loss = 2459.24710688\n",
      "Iteration 8067, loss = 2459.23876688\n",
      "Iteration 8068, loss = 2459.23042237\n",
      "Iteration 8069, loss = 2459.22207330\n",
      "Iteration 8070, loss = 2459.21371963\n",
      "Iteration 8071, loss = 2459.20536133\n",
      "Iteration 8072, loss = 2459.19699834\n",
      "Iteration 8073, loss = 2459.18863063\n",
      "Iteration 8074, loss = 2459.18025816\n",
      "Iteration 8075, loss = 2459.17188090\n",
      "Iteration 8076, loss = 2459.16349879\n",
      "Iteration 8077, loss = 2459.15511180\n",
      "Iteration 8078, loss = 2459.14671989\n",
      "Iteration 8079, loss = 2459.13832302\n",
      "Iteration 8080, loss = 2459.12992114\n",
      "Iteration 8081, loss = 2459.12151422\n",
      "Iteration 8082, loss = 2459.11310222\n",
      "Iteration 8083, loss = 2459.10468509\n",
      "Iteration 8084, loss = 2459.09626279\n",
      "Iteration 8085, loss = 2459.08783529\n",
      "Iteration 8086, loss = 2459.07940253\n",
      "Iteration 8087, loss = 2459.07096449\n",
      "Iteration 8088, loss = 2459.06252112\n",
      "Iteration 8089, loss = 2459.05407238\n",
      "Iteration 8090, loss = 2459.04561822\n",
      "Iteration 8091, loss = 2459.03715861\n",
      "Iteration 8092, loss = 2459.02869350\n",
      "Iteration 8093, loss = 2459.02022286\n",
      "Iteration 8094, loss = 2459.01174664\n",
      "Iteration 8095, loss = 2459.00326480\n",
      "Iteration 8096, loss = 2458.99477729\n",
      "Iteration 8097, loss = 2458.98628409\n",
      "Iteration 8098, loss = 2458.97778514\n",
      "Iteration 8099, loss = 2458.96928040\n",
      "Iteration 8100, loss = 2458.96076984\n",
      "Iteration 8101, loss = 2458.95225341\n",
      "Iteration 8102, loss = 2458.94373106\n",
      "Iteration 8103, loss = 2458.93520276\n",
      "Iteration 8104, loss = 2458.92666847\n",
      "Iteration 8105, loss = 2458.91812814\n",
      "Iteration 8106, loss = 2458.90958173\n",
      "Iteration 8107, loss = 2458.90102920\n",
      "Iteration 8108, loss = 2458.89247050\n",
      "Iteration 8109, loss = 2458.88390560\n",
      "Iteration 8110, loss = 2458.87533445\n",
      "Iteration 8111, loss = 2458.86675701\n",
      "Iteration 8112, loss = 2458.85817323\n",
      "Iteration 8113, loss = 2458.84958309\n",
      "Iteration 8114, loss = 2458.84098652\n",
      "Iteration 8115, loss = 2458.83238349\n",
      "Iteration 8116, loss = 2458.82377396\n",
      "Iteration 8117, loss = 2458.81515788\n",
      "Iteration 8118, loss = 2458.80653522\n",
      "Iteration 8119, loss = 2458.79790592\n",
      "Iteration 8120, loss = 2458.78926995\n",
      "Iteration 8121, loss = 2458.78062726\n",
      "Iteration 8122, loss = 2458.77197782\n",
      "Iteration 8123, loss = 2458.76332157\n",
      "Iteration 8124, loss = 2458.75465847\n",
      "Iteration 8125, loss = 2458.74598849\n",
      "Iteration 8126, loss = 2458.73731158\n",
      "Iteration 8127, loss = 2458.72862769\n",
      "Iteration 8128, loss = 2458.71993679\n",
      "Iteration 8129, loss = 2458.71123884\n",
      "Iteration 8130, loss = 2458.70253380\n",
      "Iteration 8131, loss = 2458.69382165\n",
      "Iteration 8132, loss = 2458.68510236\n",
      "Iteration 8133, loss = 2458.67637594\n",
      "Iteration 8134, loss = 2458.66764243\n",
      "Iteration 8135, loss = 2458.65890188\n",
      "Iteration 8136, loss = 2458.65015439\n",
      "Iteration 8137, loss = 2458.64139992\n",
      "Iteration 8138, loss = 2458.63263803\n",
      "Iteration 8139, loss = 2458.62386767\n",
      "Iteration 8140, loss = 2458.61508796\n",
      "Iteration 8141, loss = 2458.60629975\n",
      "Iteration 8142, loss = 2458.59750543\n",
      "Iteration 8143, loss = 2458.58870598\n",
      "Iteration 8144, loss = 2458.57989948\n",
      "Iteration 8145, loss = 2458.57108278\n",
      "Iteration 8146, loss = 2458.56225489\n",
      "Iteration 8147, loss = 2458.55341868\n",
      "Iteration 8148, loss = 2458.54457755\n",
      "Iteration 8149, loss = 2458.53573121\n",
      "Iteration 8150, loss = 2458.52687647\n",
      "Iteration 8151, loss = 2458.51801120\n",
      "Iteration 8152, loss = 2458.50913656\n",
      "Iteration 8153, loss = 2458.50025510\n",
      "Iteration 8154, loss = 2458.49136733\n",
      "Iteration 8155, loss = 2458.48247133\n",
      "Iteration 8156, loss = 2458.47356562\n",
      "Iteration 8157, loss = 2458.46465085\n",
      "Iteration 8158, loss = 2458.45572855\n",
      "Iteration 8159, loss = 2458.44679889\n",
      "Iteration 8160, loss = 2458.43786068\n",
      "Iteration 8161, loss = 2458.42891309\n",
      "Iteration 8162, loss = 2458.41995665\n",
      "Iteration 8163, loss = 2458.41099221\n",
      "Iteration 8164, loss = 2458.40201971\n",
      "Iteration 8165, loss = 2458.39303835\n",
      "Iteration 8166, loss = 2458.38404777\n",
      "Iteration 8167, loss = 2458.37504831\n",
      "Iteration 8168, loss = 2458.36604044\n",
      "Iteration 8169, loss = 2458.35702400\n",
      "Iteration 8170, loss = 2458.34799853\n",
      "Iteration 8171, loss = 2458.33896381\n",
      "Iteration 8172, loss = 2458.32992006\n",
      "Iteration 8173, loss = 2458.32086752\n",
      "Iteration 8174, loss = 2458.31180607\n",
      "Iteration 8175, loss = 2458.30273540\n",
      "Iteration 8176, loss = 2458.29365538\n",
      "Iteration 8177, loss = 2458.28456612\n",
      "Iteration 8178, loss = 2458.27546773\n",
      "Iteration 8179, loss = 2458.26636014\n",
      "Iteration 8180, loss = 2458.25724316\n",
      "Iteration 8181, loss = 2458.24811667\n",
      "Iteration 8182, loss = 2458.23898070\n",
      "Iteration 8183, loss = 2458.22983529\n",
      "Iteration 8184, loss = 2458.22068043\n",
      "Iteration 8185, loss = 2458.21151598\n",
      "Iteration 8186, loss = 2458.20234184\n",
      "Iteration 8187, loss = 2458.19315797\n",
      "Iteration 8188, loss = 2458.18396440\n",
      "Iteration 8189, loss = 2458.17476110\n",
      "Iteration 8190, loss = 2458.16554800\n",
      "Iteration 8191, loss = 2458.15632502\n",
      "Iteration 8192, loss = 2458.14709208\n",
      "Iteration 8193, loss = 2458.13784917\n",
      "Iteration 8194, loss = 2458.12859628\n",
      "Iteration 8195, loss = 2458.11933335\n",
      "Iteration 8196, loss = 2458.11006032\n",
      "Iteration 8197, loss = 2458.10077712\n",
      "Iteration 8198, loss = 2458.09148371\n",
      "Iteration 8199, loss = 2458.08218005\n",
      "Iteration 8200, loss = 2458.07286610\n",
      "Iteration 8201, loss = 2458.06354183\n",
      "Iteration 8202, loss = 2458.05420716\n",
      "Iteration 8203, loss = 2458.04486206\n",
      "Iteration 8204, loss = 2458.03550645\n",
      "Iteration 8205, loss = 2458.02614031\n",
      "Iteration 8206, loss = 2458.01676359\n",
      "Iteration 8207, loss = 2458.00737625\n",
      "Iteration 8208, loss = 2457.99797823\n",
      "Iteration 8209, loss = 2457.98856948\n",
      "Iteration 8210, loss = 2457.97914996\n",
      "Iteration 8211, loss = 2457.96971960\n",
      "Iteration 8212, loss = 2457.96027837\n",
      "Iteration 8213, loss = 2457.95082623\n",
      "Iteration 8214, loss = 2457.94136311\n",
      "Iteration 8215, loss = 2457.93188898\n",
      "Iteration 8216, loss = 2457.92240378\n",
      "Iteration 8217, loss = 2457.91290747\n",
      "Iteration 8218, loss = 2457.90339999\n",
      "Iteration 8219, loss = 2457.89388129\n",
      "Iteration 8220, loss = 2457.88435133\n",
      "Iteration 8221, loss = 2457.87481006\n",
      "Iteration 8222, loss = 2457.86525743\n",
      "Iteration 8223, loss = 2457.85569339\n",
      "Iteration 8224, loss = 2457.84611789\n",
      "Iteration 8225, loss = 2457.83653088\n",
      "Iteration 8226, loss = 2457.82693231\n",
      "Iteration 8227, loss = 2457.81732213\n",
      "Iteration 8228, loss = 2457.80770029\n",
      "Iteration 8229, loss = 2457.79806675\n",
      "Iteration 8230, loss = 2457.78842145\n",
      "Iteration 8231, loss = 2457.77876434\n",
      "Iteration 8232, loss = 2457.76909538\n",
      "Iteration 8233, loss = 2457.75941451\n",
      "Iteration 8234, loss = 2457.74972169\n",
      "Iteration 8235, loss = 2457.74001685\n",
      "Iteration 8236, loss = 2457.73029996\n",
      "Iteration 8237, loss = 2457.72057097\n",
      "Iteration 8238, loss = 2457.71082981\n",
      "Iteration 8239, loss = 2457.70107645\n",
      "Iteration 8240, loss = 2457.69131084\n",
      "Iteration 8241, loss = 2457.68153291\n",
      "Iteration 8242, loss = 2457.67174262\n",
      "Iteration 8243, loss = 2457.66193993\n",
      "Iteration 8244, loss = 2457.65212477\n",
      "Iteration 8245, loss = 2457.64229711\n",
      "Iteration 8246, loss = 2457.63245688\n",
      "Iteration 8247, loss = 2457.62260404\n",
      "Iteration 8248, loss = 2457.61273854\n",
      "Iteration 8249, loss = 2457.60286032\n",
      "Iteration 8250, loss = 2457.59296933\n",
      "Iteration 8251, loss = 2457.58306553\n",
      "Iteration 8252, loss = 2457.57314887\n",
      "Iteration 8253, loss = 2457.56321928\n",
      "Iteration 8254, loss = 2457.55327672\n",
      "Iteration 8255, loss = 2457.54332115\n",
      "Iteration 8256, loss = 2457.53335249\n",
      "Iteration 8257, loss = 2457.52337072\n",
      "Iteration 8258, loss = 2457.51337576\n",
      "Iteration 8259, loss = 2457.50336758\n",
      "Iteration 8260, loss = 2457.49334612\n",
      "Iteration 8261, loss = 2457.48331134\n",
      "Iteration 8262, loss = 2457.47326317\n",
      "Iteration 8263, loss = 2457.46320157\n",
      "Iteration 8264, loss = 2457.45312650\n",
      "Iteration 8265, loss = 2457.44303791\n",
      "Iteration 8266, loss = 2457.43293578\n",
      "Iteration 8267, loss = 2457.42282009\n",
      "Iteration 8268, loss = 2457.41269085\n",
      "Iteration 8269, loss = 2457.40254815\n",
      "Iteration 8270, loss = 2457.39239212\n",
      "Iteration 8271, loss = 2457.38222292\n",
      "Iteration 8272, loss = 2457.37204054\n",
      "Iteration 8273, loss = 2457.36184432\n",
      "Iteration 8274, loss = 2457.35163303\n",
      "Iteration 8275, loss = 2457.34140641\n",
      "Iteration 8276, loss = 2457.33116576\n",
      "Iteration 8277, loss = 2457.32091049\n",
      "Iteration 8278, loss = 2457.31063779\n",
      "Iteration 8279, loss = 2457.30034969\n",
      "Iteration 8280, loss = 2457.29005099\n",
      "Iteration 8281, loss = 2457.27974097\n",
      "Iteration 8282, loss = 2457.26941456\n",
      "Iteration 8283, loss = 2457.25907035\n",
      "Iteration 8284, loss = 2457.24871303\n",
      "Iteration 8285, loss = 2457.23834430\n",
      "Iteration 8286, loss = 2457.22795975\n",
      "Iteration 8287, loss = 2457.21755763\n",
      "Iteration 8288, loss = 2457.20714203\n",
      "Iteration 8289, loss = 2457.19671437\n",
      "Iteration 8290, loss = 2457.18627055\n",
      "Iteration 8291, loss = 2457.17580930\n",
      "Iteration 8292, loss = 2457.16533440\n",
      "Iteration 8293, loss = 2457.15484677\n",
      "Iteration 8294, loss = 2457.14434287\n",
      "Iteration 8295, loss = 2457.13382187\n",
      "Iteration 8296, loss = 2457.12328675\n",
      "Iteration 8297, loss = 2457.11273799\n",
      "Iteration 8298, loss = 2457.10217307\n",
      "Iteration 8299, loss = 2457.09159161\n",
      "Iteration 8300, loss = 2457.08099543\n",
      "Iteration 8301, loss = 2457.07038462\n",
      "Iteration 8302, loss = 2457.05975774\n",
      "Iteration 8303, loss = 2457.04911481\n",
      "Iteration 8304, loss = 2457.03845673\n",
      "Iteration 8305, loss = 2457.02778319\n",
      "Iteration 8306, loss = 2457.01709350\n",
      "Iteration 8307, loss = 2457.00638796\n",
      "Iteration 8308, loss = 2456.99566698\n",
      "Iteration 8309, loss = 2456.98493008\n",
      "Iteration 8310, loss = 2456.97417682\n",
      "Iteration 8311, loss = 2456.96340760\n",
      "Iteration 8312, loss = 2456.95262268\n",
      "Iteration 8313, loss = 2456.94182161\n",
      "Iteration 8314, loss = 2456.93100406\n",
      "Iteration 8315, loss = 2456.92017026\n",
      "Iteration 8316, loss = 2456.90932041\n",
      "Iteration 8317, loss = 2456.89845424\n",
      "Iteration 8318, loss = 2456.88757150\n",
      "Iteration 8319, loss = 2456.87667228\n",
      "Iteration 8320, loss = 2456.86575666\n",
      "Iteration 8321, loss = 2456.85482448\n",
      "Iteration 8322, loss = 2456.84387559\n",
      "Iteration 8323, loss = 2456.83291002\n",
      "Iteration 8324, loss = 2456.82192778\n",
      "Iteration 8325, loss = 2456.81092875\n",
      "Iteration 8326, loss = 2456.79991278\n",
      "Iteration 8327, loss = 2456.78887991\n",
      "Iteration 8328, loss = 2456.77783014\n",
      "Iteration 8329, loss = 2456.76676336\n",
      "Iteration 8330, loss = 2456.75567946\n",
      "Iteration 8331, loss = 2456.74457839\n",
      "Iteration 8332, loss = 2456.73346016\n",
      "Iteration 8333, loss = 2456.72232471\n",
      "Iteration 8334, loss = 2456.71117194\n",
      "Iteration 8335, loss = 2456.70000178\n",
      "Iteration 8336, loss = 2456.68881421\n",
      "Iteration 8337, loss = 2456.67760918\n",
      "Iteration 8338, loss = 2456.66638661\n",
      "Iteration 8339, loss = 2456.65514643\n",
      "Iteration 8340, loss = 2456.64388860\n",
      "Iteration 8341, loss = 2456.63261307\n",
      "Iteration 8342, loss = 2456.62131979\n",
      "Iteration 8343, loss = 2456.61000868\n",
      "Iteration 8344, loss = 2456.59867967\n",
      "Iteration 8345, loss = 2456.58733273\n",
      "Iteration 8346, loss = 2456.57596781\n",
      "Iteration 8347, loss = 2456.56458483\n",
      "Iteration 8348, loss = 2456.55318373\n",
      "Iteration 8349, loss = 2456.54176446\n",
      "Iteration 8350, loss = 2456.53032696\n",
      "Iteration 8351, loss = 2456.51887119\n",
      "Iteration 8352, loss = 2456.50739706\n",
      "Iteration 8353, loss = 2456.49590453\n",
      "Iteration 8354, loss = 2456.48439353\n",
      "Iteration 8355, loss = 2456.47286402\n",
      "Iteration 8356, loss = 2456.46131593\n",
      "Iteration 8357, loss = 2456.44974920\n",
      "Iteration 8358, loss = 2456.43816377\n",
      "Iteration 8359, loss = 2456.42655959\n",
      "Iteration 8360, loss = 2456.41493660\n",
      "Iteration 8361, loss = 2456.40329473\n",
      "Iteration 8362, loss = 2456.39163393\n",
      "Iteration 8363, loss = 2456.37995414\n",
      "Iteration 8364, loss = 2456.36825530\n",
      "Iteration 8365, loss = 2456.35653735\n",
      "Iteration 8366, loss = 2456.34480023\n",
      "Iteration 8367, loss = 2456.33304388\n",
      "Iteration 8368, loss = 2456.32126825\n",
      "Iteration 8369, loss = 2456.30947326\n",
      "Iteration 8370, loss = 2456.29765888\n",
      "Iteration 8371, loss = 2456.28582502\n",
      "Iteration 8372, loss = 2456.27397164\n",
      "Iteration 8373, loss = 2456.26209868\n",
      "Iteration 8374, loss = 2456.25020606\n",
      "Iteration 8375, loss = 2456.23829375\n",
      "Iteration 8376, loss = 2456.22636166\n",
      "Iteration 8377, loss = 2456.21440975\n",
      "Iteration 8378, loss = 2456.20243796\n",
      "Iteration 8379, loss = 2456.19044622\n",
      "Iteration 8380, loss = 2456.17843447\n",
      "Iteration 8381, loss = 2456.16640266\n",
      "Iteration 8382, loss = 2456.15435072\n",
      "Iteration 8383, loss = 2456.14227859\n",
      "Iteration 8384, loss = 2456.13018622\n",
      "Iteration 8385, loss = 2456.11807353\n",
      "Iteration 8386, loss = 2456.10594048\n",
      "Iteration 8387, loss = 2456.09378701\n",
      "Iteration 8388, loss = 2456.08161304\n",
      "Iteration 8389, loss = 2456.06941854\n",
      "Iteration 8390, loss = 2456.05720344\n",
      "Iteration 8391, loss = 2456.04496770\n",
      "Iteration 8392, loss = 2456.03271129\n",
      "Iteration 8393, loss = 2456.02043418\n",
      "Iteration 8394, loss = 2456.00813641\n",
      "Iteration 8395, loss = 2455.99581802\n",
      "Iteration 8396, loss = 2455.98347913\n",
      "Iteration 8397, loss = 2455.97111973\n",
      "Iteration 8398, loss = 2455.95873941\n",
      "Iteration 8399, loss = 2455.94633695\n",
      "Iteration 8400, loss = 2455.93391087\n",
      "Iteration 8401, loss = 2455.92146156\n",
      "Iteration 8402, loss = 2455.90899178\n",
      "Iteration 8403, loss = 2455.89650347\n",
      "Iteration 8404, loss = 2455.88399536\n",
      "Iteration 8405, loss = 2455.87146461\n",
      "Iteration 8406, loss = 2455.85890997\n",
      "Iteration 8407, loss = 2455.84633310\n",
      "Iteration 8408, loss = 2455.83373620\n",
      "Iteration 8409, loss = 2455.82111899\n",
      "Iteration 8410, loss = 2455.80847938\n",
      "Iteration 8411, loss = 2455.79581634\n",
      "Iteration 8412, loss = 2455.78313102\n",
      "Iteration 8413, loss = 2455.77042479\n",
      "Iteration 8414, loss = 2455.75769727\n",
      "Iteration 8415, loss = 2455.74494704\n",
      "Iteration 8416, loss = 2455.73217370\n",
      "Iteration 8417, loss = 2455.71937809\n",
      "Iteration 8418, loss = 2455.70656090\n",
      "Iteration 8419, loss = 2455.69372163\n",
      "Iteration 8420, loss = 2455.68085943\n",
      "Iteration 8421, loss = 2455.66797421\n",
      "Iteration 8422, loss = 2455.65506654\n",
      "Iteration 8423, loss = 2455.64213668\n",
      "Iteration 8424, loss = 2455.62918419\n",
      "Iteration 8425, loss = 2455.61620859\n",
      "Iteration 8426, loss = 2455.60320989\n",
      "Iteration 8427, loss = 2455.59018842\n",
      "Iteration 8428, loss = 2455.57714424\n",
      "Iteration 8429, loss = 2455.56407704\n",
      "Iteration 8430, loss = 2455.55098653\n",
      "Iteration 8431, loss = 2455.53787272\n",
      "Iteration 8432, loss = 2455.52473576\n",
      "Iteration 8433, loss = 2455.51157566\n",
      "Iteration 8434, loss = 2455.49839222\n",
      "Iteration 8435, loss = 2455.48518525\n",
      "Iteration 8436, loss = 2455.47195471\n",
      "Iteration 8437, loss = 2455.45870067\n",
      "Iteration 8438, loss = 2455.44542314\n",
      "Iteration 8439, loss = 2455.43212202\n",
      "Iteration 8440, loss = 2455.41879723\n",
      "Iteration 8441, loss = 2455.40544879\n",
      "Iteration 8442, loss = 2455.39207687\n",
      "Iteration 8443, loss = 2455.37868169\n",
      "Iteration 8444, loss = 2455.36526333\n",
      "Iteration 8445, loss = 2455.35182131\n",
      "Iteration 8446, loss = 2455.33835394\n",
      "Iteration 8447, loss = 2455.32485898\n",
      "Iteration 8448, loss = 2455.31133680\n",
      "Iteration 8449, loss = 2455.29779160\n",
      "Iteration 8450, loss = 2455.28422628\n",
      "Iteration 8451, loss = 2455.27063869\n",
      "Iteration 8452, loss = 2455.25702452\n",
      "Iteration 8453, loss = 2455.24338247\n",
      "Iteration 8454, loss = 2455.22971569\n",
      "Iteration 8455, loss = 2455.21602704\n",
      "Iteration 8456, loss = 2455.20231502\n",
      "Iteration 8457, loss = 2455.18857646\n",
      "Iteration 8458, loss = 2455.17481111\n",
      "Iteration 8459, loss = 2455.16102150\n",
      "Iteration 8460, loss = 2455.14720865\n",
      "Iteration 8461, loss = 2455.13337075\n",
      "Iteration 8462, loss = 2455.11950621\n",
      "Iteration 8463, loss = 2455.10561588\n",
      "Iteration 8464, loss = 2455.09170128\n",
      "Iteration 8465, loss = 2455.07776211\n",
      "Iteration 8466, loss = 2455.06379693\n",
      "Iteration 8467, loss = 2455.04980538\n",
      "Iteration 8468, loss = 2455.03578843\n",
      "Iteration 8469, loss = 2455.02174659\n",
      "Iteration 8470, loss = 2455.00767916\n",
      "Iteration 8471, loss = 2454.99358540\n",
      "Iteration 8472, loss = 2454.97946551\n",
      "Iteration 8473, loss = 2454.96532006\n",
      "Iteration 8474, loss = 2454.95114901\n",
      "Iteration 8475, loss = 2454.93695176\n",
      "Iteration 8476, loss = 2454.92272805\n",
      "Iteration 8477, loss = 2454.90847814\n",
      "Iteration 8478, loss = 2454.89420226\n",
      "Iteration 8479, loss = 2454.87990021\n",
      "Iteration 8480, loss = 2454.86557162\n",
      "Iteration 8481, loss = 2454.85121642\n",
      "Iteration 8482, loss = 2454.83683474\n",
      "Iteration 8483, loss = 2454.82242666\n",
      "Iteration 8484, loss = 2454.80799198\n",
      "Iteration 8485, loss = 2454.79353048\n",
      "Iteration 8486, loss = 2454.77904210\n",
      "Iteration 8487, loss = 2454.76452691\n",
      "Iteration 8488, loss = 2454.74998490\n",
      "Iteration 8489, loss = 2454.73541593\n",
      "Iteration 8490, loss = 2454.72081986\n",
      "Iteration 8491, loss = 2454.70619661\n",
      "Iteration 8492, loss = 2454.69154619\n",
      "Iteration 8493, loss = 2454.67686857\n",
      "Iteration 8494, loss = 2454.66216366\n",
      "Iteration 8495, loss = 2454.64743133\n",
      "Iteration 8496, loss = 2454.63267151\n",
      "Iteration 8497, loss = 2454.61788416\n",
      "Iteration 8498, loss = 2454.60306925\n",
      "Iteration 8499, loss = 2454.58822670\n",
      "Iteration 8500, loss = 2454.57335642\n",
      "Iteration 8501, loss = 2454.55845832\n",
      "Iteration 8502, loss = 2454.54353235\n",
      "Iteration 8503, loss = 2454.52857844\n",
      "Iteration 8504, loss = 2454.51359656\n",
      "Iteration 8505, loss = 2454.49858661\n",
      "Iteration 8506, loss = 2454.48354852\n",
      "Iteration 8507, loss = 2454.46848222\n",
      "Iteration 8508, loss = 2454.45338763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8509, loss = 2454.43826471\n",
      "Iteration 8510, loss = 2454.42311338\n",
      "Iteration 8511, loss = 2454.40793357\n",
      "Iteration 8512, loss = 2454.39272522\n",
      "Iteration 8513, loss = 2454.37748825\n",
      "Iteration 8514, loss = 2454.36222258\n",
      "Iteration 8515, loss = 2454.34692817\n",
      "Iteration 8516, loss = 2454.33160495\n",
      "Iteration 8517, loss = 2454.31625285\n",
      "Iteration 8518, loss = 2454.30087185\n",
      "Iteration 8519, loss = 2454.28546192\n",
      "Iteration 8520, loss = 2454.27002310\n",
      "Iteration 8521, loss = 2454.25455558\n",
      "Iteration 8522, loss = 2454.23905976\n",
      "Iteration 8523, loss = 2454.22353624\n",
      "Iteration 8524, loss = 2454.20798515\n",
      "Iteration 8525, loss = 2454.19240386\n",
      "Iteration 8526, loss = 2454.17678629\n",
      "Iteration 8527, loss = 2454.16113219\n",
      "Iteration 8528, loss = 2454.14545273\n",
      "Iteration 8529, loss = 2454.12975303\n",
      "Iteration 8530, loss = 2454.11402330\n",
      "Iteration 8531, loss = 2454.09825538\n",
      "Iteration 8532, loss = 2454.08245660\n",
      "Iteration 8533, loss = 2454.06663515\n",
      "Iteration 8534, loss = 2454.05078445\n",
      "Iteration 8535, loss = 2454.03489755\n",
      "Iteration 8536, loss = 2454.01898045\n",
      "Iteration 8537, loss = 2454.00303817\n",
      "Iteration 8538, loss = 2453.98706466\n",
      "Iteration 8539, loss = 2453.97105672\n",
      "Iteration 8540, loss = 2453.95501993\n",
      "Iteration 8541, loss = 2453.93895549\n",
      "Iteration 8542, loss = 2453.92285836\n",
      "Iteration 8543, loss = 2453.90672872\n",
      "Iteration 8544, loss = 2453.89057050\n",
      "Iteration 8545, loss = 2453.87438234\n",
      "Iteration 8546, loss = 2453.85816124\n",
      "Iteration 8547, loss = 2453.84190902\n",
      "Iteration 8548, loss = 2453.82562745\n",
      "Iteration 8549, loss = 2453.80931440\n",
      "Iteration 8550, loss = 2453.79296887\n",
      "Iteration 8551, loss = 2453.77659274\n",
      "Iteration 8552, loss = 2453.76018612\n",
      "Iteration 8553, loss = 2453.74374735\n",
      "Iteration 8554, loss = 2453.72727661\n",
      "Iteration 8555, loss = 2453.71077506\n",
      "Iteration 8556, loss = 2453.69424212\n",
      "Iteration 8557, loss = 2453.67767686\n",
      "Iteration 8558, loss = 2453.66107982\n",
      "Iteration 8559, loss = 2453.64445153\n",
      "Iteration 8560, loss = 2453.62779132\n",
      "Iteration 8561, loss = 2453.61109882\n",
      "Iteration 8562, loss = 2453.59437459\n",
      "Iteration 8563, loss = 2453.57761880\n",
      "Iteration 8564, loss = 2453.56083100\n",
      "Iteration 8565, loss = 2453.54401105\n",
      "Iteration 8566, loss = 2453.52715903\n",
      "Iteration 8567, loss = 2453.51027421\n",
      "Iteration 8568, loss = 2453.49335529\n",
      "Iteration 8569, loss = 2453.47640201\n",
      "Iteration 8570, loss = 2453.45941576\n",
      "Iteration 8571, loss = 2453.44239820\n",
      "Iteration 8572, loss = 2453.42534970\n",
      "Iteration 8573, loss = 2453.40826930\n",
      "Iteration 8574, loss = 2453.39115555\n",
      "Iteration 8575, loss = 2453.37400742\n",
      "Iteration 8576, loss = 2453.35682517\n",
      "Iteration 8577, loss = 2453.33961010\n",
      "Iteration 8578, loss = 2453.32236308\n",
      "Iteration 8579, loss = 2453.30508361\n",
      "Iteration 8580, loss = 2453.28777051\n",
      "Iteration 8581, loss = 2453.27042311\n",
      "Iteration 8582, loss = 2453.25304168\n",
      "Iteration 8583, loss = 2453.23562696\n",
      "Iteration 8584, loss = 2453.21817924\n",
      "Iteration 8585, loss = 2453.20069821\n",
      "Iteration 8586, loss = 2453.18318326\n",
      "Iteration 8587, loss = 2453.16563402\n",
      "Iteration 8588, loss = 2453.14805055\n",
      "Iteration 8589, loss = 2453.13043320\n",
      "Iteration 8590, loss = 2453.11278214\n",
      "Iteration 8591, loss = 2453.09509720\n",
      "Iteration 8592, loss = 2453.07737798\n",
      "Iteration 8593, loss = 2453.05962423\n",
      "Iteration 8594, loss = 2453.04183595\n",
      "Iteration 8595, loss = 2453.02401327\n",
      "Iteration 8596, loss = 2453.00615627\n",
      "Iteration 8597, loss = 2452.98826484\n",
      "Iteration 8598, loss = 2452.97033879\n",
      "Iteration 8599, loss = 2452.95237793\n",
      "Iteration 8600, loss = 2452.93438217\n",
      "Iteration 8601, loss = 2452.91635151\n",
      "Iteration 8602, loss = 2452.89828595\n",
      "Iteration 8603, loss = 2452.88018547\n",
      "Iteration 8604, loss = 2452.86204997\n",
      "Iteration 8605, loss = 2452.84387933\n",
      "Iteration 8606, loss = 2452.82567342\n",
      "Iteration 8607, loss = 2452.80743216\n",
      "Iteration 8608, loss = 2452.78915550\n",
      "Iteration 8609, loss = 2452.77084340\n",
      "Iteration 8610, loss = 2452.75249582\n",
      "Iteration 8611, loss = 2452.73411269\n",
      "Iteration 8612, loss = 2452.71569390\n",
      "Iteration 8613, loss = 2452.69723938\n",
      "Iteration 8614, loss = 2452.67874904\n",
      "Iteration 8615, loss = 2452.66022280\n",
      "Iteration 8616, loss = 2452.64166059\n",
      "Iteration 8617, loss = 2452.62306234\n",
      "Iteration 8618, loss = 2452.60442800\n",
      "Iteration 8619, loss = 2452.58575749\n",
      "Iteration 8620, loss = 2452.56705075\n",
      "Iteration 8621, loss = 2452.54830769\n",
      "Iteration 8622, loss = 2452.52952823\n",
      "Iteration 8623, loss = 2452.51071231\n",
      "Iteration 8624, loss = 2452.49185985\n",
      "Iteration 8625, loss = 2452.47297076\n",
      "Iteration 8626, loss = 2452.45404498\n",
      "Iteration 8627, loss = 2452.43508244\n",
      "Iteration 8628, loss = 2452.41608305\n",
      "Iteration 8629, loss = 2452.39704676\n",
      "Iteration 8630, loss = 2452.37797348\n",
      "Iteration 8631, loss = 2452.35886315\n",
      "Iteration 8632, loss = 2452.33971568\n",
      "Iteration 8633, loss = 2452.32053102\n",
      "Iteration 8634, loss = 2452.30130907\n",
      "Iteration 8635, loss = 2452.28204977\n",
      "Iteration 8636, loss = 2452.26275305\n",
      "Iteration 8637, loss = 2452.24341882\n",
      "Iteration 8638, loss = 2452.22404703\n",
      "Iteration 8639, loss = 2452.20463758\n",
      "Iteration 8640, loss = 2452.18519042\n",
      "Iteration 8641, loss = 2452.16570546\n",
      "Iteration 8642, loss = 2452.14618263\n",
      "Iteration 8643, loss = 2452.12662187\n",
      "Iteration 8644, loss = 2452.10702310\n",
      "Iteration 8645, loss = 2452.08738625\n",
      "Iteration 8646, loss = 2452.06771126\n",
      "Iteration 8647, loss = 2452.04799808\n",
      "Iteration 8648, loss = 2452.02824668\n",
      "Iteration 8649, loss = 2452.00845706\n",
      "Iteration 8650, loss = 2451.98862927\n",
      "Iteration 8651, loss = 2451.96876344\n",
      "Iteration 8652, loss = 2451.94885978\n",
      "Iteration 8653, loss = 2451.92891837\n",
      "Iteration 8654, loss = 2451.90893863\n",
      "Iteration 8655, loss = 2451.88891863\n",
      "Iteration 8656, loss = 2451.86885579\n",
      "Iteration 8657, loss = 2451.84875056\n",
      "Iteration 8658, loss = 2451.82860765\n",
      "Iteration 8659, loss = 2451.80843042\n",
      "Iteration 8660, loss = 2451.78821669\n",
      "Iteration 8661, loss = 2451.76796165\n",
      "Iteration 8662, loss = 2451.74766342\n",
      "Iteration 8663, loss = 2451.72732508\n",
      "Iteration 8664, loss = 2451.70695018\n",
      "Iteration 8665, loss = 2451.68653791\n",
      "Iteration 8666, loss = 2451.66608473\n",
      "Iteration 8667, loss = 2451.64558934\n",
      "Iteration 8668, loss = 2451.62505401\n",
      "Iteration 8669, loss = 2451.60448087\n",
      "Iteration 8670, loss = 2451.58386887\n",
      "Iteration 8671, loss = 2451.56321575\n",
      "Iteration 8672, loss = 2451.54252115\n",
      "Iteration 8673, loss = 2451.52178672\n",
      "Iteration 8674, loss = 2451.50101335\n",
      "Iteration 8675, loss = 2451.48019996\n",
      "Iteration 8676, loss = 2451.45934529\n",
      "Iteration 8677, loss = 2451.43844949\n",
      "Iteration 8678, loss = 2451.41751359\n",
      "Iteration 8679, loss = 2451.39653783\n",
      "Iteration 8680, loss = 2451.37552142\n",
      "Iteration 8681, loss = 2451.35446372\n",
      "Iteration 8682, loss = 2451.33336499\n",
      "Iteration 8683, loss = 2451.31222582\n",
      "Iteration 8684, loss = 2451.29104631\n",
      "Iteration 8685, loss = 2451.26982597\n",
      "Iteration 8686, loss = 2451.24856444\n",
      "Iteration 8687, loss = 2451.22726163\n",
      "Iteration 8688, loss = 2451.20591734\n",
      "Iteration 8689, loss = 2451.18453094\n",
      "Iteration 8690, loss = 2451.16310194\n",
      "Iteration 8691, loss = 2451.14163092\n",
      "Iteration 8692, loss = 2451.12011930\n",
      "Iteration 8693, loss = 2451.09856793\n",
      "Iteration 8694, loss = 2451.07697613\n",
      "Iteration 8695, loss = 2451.05534195\n",
      "Iteration 8696, loss = 2451.03366336\n",
      "Iteration 8697, loss = 2451.01193989\n",
      "Iteration 8698, loss = 2450.99017344\n",
      "Iteration 8699, loss = 2450.96836672\n",
      "Iteration 8700, loss = 2450.94652075\n",
      "Iteration 8701, loss = 2450.92463414\n",
      "Iteration 8702, loss = 2450.90270459\n",
      "Iteration 8703, loss = 2450.88073063\n",
      "Iteration 8704, loss = 2450.85871258\n",
      "Iteration 8705, loss = 2450.83665202\n",
      "Iteration 8706, loss = 2450.81455026\n",
      "Iteration 8707, loss = 2450.79240713\n",
      "Iteration 8708, loss = 2450.77022143\n",
      "Iteration 8709, loss = 2450.74799199\n",
      "Iteration 8710, loss = 2450.72571855\n",
      "Iteration 8711, loss = 2450.70340176\n",
      "Iteration 8712, loss = 2450.68104240\n",
      "Iteration 8713, loss = 2450.65864065\n",
      "Iteration 8714, loss = 2450.63619606\n",
      "Iteration 8715, loss = 2450.61370794\n",
      "Iteration 8716, loss = 2450.59117590\n",
      "Iteration 8717, loss = 2450.56860002\n",
      "Iteration 8718, loss = 2450.54598061\n",
      "Iteration 8719, loss = 2450.52331789\n",
      "Iteration 8720, loss = 2450.50061177\n",
      "Iteration 8721, loss = 2450.47786198\n",
      "Iteration 8722, loss = 2450.45506823\n",
      "Iteration 8723, loss = 2450.43223036\n",
      "Iteration 8724, loss = 2450.40934836\n",
      "Iteration 8725, loss = 2450.38642231\n",
      "Iteration 8726, loss = 2450.36345222\n",
      "Iteration 8727, loss = 2450.34043801\n",
      "Iteration 8728, loss = 2450.31737955\n",
      "Iteration 8729, loss = 2450.29427668\n",
      "Iteration 8730, loss = 2450.27112929\n",
      "Iteration 8731, loss = 2450.24793731\n",
      "Iteration 8732, loss = 2450.22470072\n",
      "Iteration 8733, loss = 2450.20141948\n",
      "Iteration 8734, loss = 2450.17809355\n",
      "Iteration 8735, loss = 2450.15472284\n",
      "Iteration 8736, loss = 2450.13130726\n",
      "Iteration 8737, loss = 2450.10784669\n",
      "Iteration 8738, loss = 2450.08434105\n",
      "Iteration 8739, loss = 2450.06079025\n",
      "Iteration 8740, loss = 2450.03719423\n",
      "Iteration 8741, loss = 2450.01355292\n",
      "Iteration 8742, loss = 2449.98986627\n",
      "Iteration 8743, loss = 2449.96613420\n",
      "Iteration 8744, loss = 2449.94235666\n",
      "Iteration 8745, loss = 2449.91853358\n",
      "Iteration 8746, loss = 2449.89466488\n",
      "Iteration 8747, loss = 2449.87075052\n",
      "Iteration 8748, loss = 2449.84679043\n",
      "Iteration 8749, loss = 2449.82278460\n",
      "Iteration 8750, loss = 2449.79873303\n",
      "Iteration 8751, loss = 2449.77463578\n",
      "Iteration 8752, loss = 2449.75049293\n",
      "Iteration 8753, loss = 2449.72630461\n",
      "Iteration 8754, loss = 2449.70207083\n",
      "Iteration 8755, loss = 2449.67779127\n",
      "Iteration 8756, loss = 2449.65346514\n",
      "Iteration 8757, loss = 2449.62909141\n",
      "Iteration 8758, loss = 2449.60466951\n",
      "Iteration 8759, loss = 2449.58019955\n",
      "Iteration 8760, loss = 2449.55568219\n",
      "Iteration 8761, loss = 2449.53111817\n",
      "Iteration 8762, loss = 2449.50650709\n",
      "Iteration 8763, loss = 2449.48184766\n",
      "Iteration 8764, loss = 2449.45714043\n",
      "Iteration 8765, loss = 2449.43238772\n",
      "Iteration 8766, loss = 2449.40759056\n",
      "Iteration 8767, loss = 2449.38274764\n",
      "Iteration 8768, loss = 2449.35785639\n",
      "Iteration 8769, loss = 2449.33291541\n",
      "Iteration 8770, loss = 2449.30792614\n",
      "Iteration 8771, loss = 2449.28289079\n",
      "Iteration 8772, loss = 2449.25780939\n",
      "Iteration 8773, loss = 2449.23268003\n",
      "Iteration 8774, loss = 2449.20750144\n",
      "Iteration 8775, loss = 2449.18227448\n",
      "Iteration 8776, loss = 2449.15700081\n",
      "Iteration 8777, loss = 2449.13168052\n",
      "Iteration 8778, loss = 2449.10631200\n",
      "Iteration 8779, loss = 2449.08089399\n",
      "Iteration 8780, loss = 2449.05542694\n",
      "Iteration 8781, loss = 2449.02991226\n",
      "Iteration 8782, loss = 2449.00435040\n",
      "Iteration 8783, loss = 2448.97874038\n",
      "Iteration 8784, loss = 2448.95308104\n",
      "Iteration 8785, loss = 2448.92737229\n",
      "Iteration 8786, loss = 2448.90161496\n",
      "Iteration 8787, loss = 2448.87580967\n",
      "Iteration 8788, loss = 2448.84995609\n",
      "Iteration 8789, loss = 2448.82405341\n",
      "Iteration 8790, loss = 2448.79810122\n",
      "Iteration 8791, loss = 2448.77209976\n",
      "Iteration 8792, loss = 2448.74604947\n",
      "Iteration 8793, loss = 2448.71995042\n",
      "Iteration 8794, loss = 2448.69380225\n",
      "Iteration 8795, loss = 2448.66760455\n",
      "Iteration 8796, loss = 2448.64135718\n",
      "Iteration 8797, loss = 2448.61506029\n",
      "Iteration 8798, loss = 2448.58871403\n",
      "Iteration 8799, loss = 2448.56231835\n",
      "Iteration 8800, loss = 2448.53587309\n",
      "Iteration 8801, loss = 2448.50937810\n",
      "Iteration 8802, loss = 2448.48283337\n",
      "Iteration 8803, loss = 2448.45623902\n",
      "Iteration 8804, loss = 2448.42959512\n",
      "Iteration 8805, loss = 2448.40290159\n",
      "Iteration 8806, loss = 2448.37615812\n",
      "Iteration 8807, loss = 2448.34936408\n",
      "Iteration 8808, loss = 2448.32251874\n",
      "Iteration 8809, loss = 2448.29562170\n",
      "Iteration 8810, loss = 2448.26867336\n",
      "Iteration 8811, loss = 2448.24167469\n",
      "Iteration 8812, loss = 2448.21462612\n",
      "Iteration 8813, loss = 2448.18752704\n",
      "Iteration 8814, loss = 2448.16037655\n",
      "Iteration 8815, loss = 2448.13317448\n",
      "Iteration 8816, loss = 2448.10592148\n",
      "Iteration 8817, loss = 2448.07861834\n",
      "Iteration 8818, loss = 2448.05126527\n",
      "Iteration 8819, loss = 2448.02386182\n",
      "Iteration 8820, loss = 2447.99640715\n",
      "Iteration 8821, loss = 2447.96890055\n",
      "Iteration 8822, loss = 2447.94134187\n",
      "Iteration 8823, loss = 2447.91373153\n",
      "Iteration 8824, loss = 2447.88606997\n",
      "Iteration 8825, loss = 2447.85835730\n",
      "Iteration 8826, loss = 2447.83059322\n",
      "Iteration 8827, loss = 2447.80277729\n",
      "Iteration 8828, loss = 2447.77490921\n",
      "Iteration 8829, loss = 2447.74698896\n",
      "Iteration 8830, loss = 2447.71901667\n",
      "Iteration 8831, loss = 2447.69099251\n",
      "Iteration 8832, loss = 2447.66291650\n",
      "Iteration 8833, loss = 2447.63478851\n",
      "Iteration 8834, loss = 2447.60660834\n",
      "Iteration 8835, loss = 2447.57837579\n",
      "Iteration 8836, loss = 2447.55009074\n",
      "Iteration 8837, loss = 2447.52175315\n",
      "Iteration 8838, loss = 2447.49336302\n",
      "Iteration 8839, loss = 2447.46492036\n",
      "Iteration 8840, loss = 2447.43642510\n",
      "Iteration 8841, loss = 2447.40787716\n",
      "Iteration 8842, loss = 2447.37927641\n",
      "Iteration 8843, loss = 2447.35062276\n",
      "Iteration 8844, loss = 2447.32191611\n",
      "Iteration 8845, loss = 2447.29315643\n",
      "Iteration 8846, loss = 2447.26434371\n",
      "Iteration 8847, loss = 2447.23547798\n",
      "Iteration 8848, loss = 2447.20655933\n",
      "Iteration 8849, loss = 2447.17758787\n",
      "Iteration 8850, loss = 2447.14856374\n",
      "Iteration 8851, loss = 2447.11948709\n",
      "Iteration 8852, loss = 2447.09035796\n",
      "Iteration 8853, loss = 2447.06117625\n",
      "Iteration 8854, loss = 2447.03194164\n",
      "Iteration 8855, loss = 2447.00265318\n",
      "Iteration 8856, loss = 2446.97330806\n",
      "Iteration 8857, loss = 2446.94390197\n",
      "Iteration 8858, loss = 2446.91443450\n",
      "Iteration 8859, loss = 2446.88491293\n",
      "Iteration 8860, loss = 2446.85534438\n",
      "Iteration 8861, loss = 2446.82572776\n",
      "Iteration 8862, loss = 2446.79605693\n",
      "Iteration 8863, loss = 2446.76632830\n",
      "Iteration 8864, loss = 2446.73654378\n",
      "Iteration 8865, loss = 2446.70670631\n",
      "Iteration 8866, loss = 2446.67681499\n",
      "Iteration 8867, loss = 2446.64686725\n",
      "Iteration 8868, loss = 2446.61686364\n",
      "Iteration 8869, loss = 2446.58680711\n",
      "Iteration 8870, loss = 2446.55669824\n",
      "Iteration 8871, loss = 2446.52653412\n",
      "Iteration 8872, loss = 2446.49631230\n",
      "Iteration 8873, loss = 2446.46603379\n",
      "Iteration 8874, loss = 2446.43570146\n",
      "Iteration 8875, loss = 2446.40531609\n",
      "Iteration 8876, loss = 2446.37487565\n",
      "Iteration 8877, loss = 2446.34437817\n",
      "Iteration 8878, loss = 2446.31382398\n",
      "Iteration 8879, loss = 2446.28321479\n",
      "Iteration 8880, loss = 2446.25255136\n",
      "Iteration 8881, loss = 2446.22183272\n",
      "Iteration 8882, loss = 2446.19105751\n",
      "Iteration 8883, loss = 2446.16022547\n",
      "Iteration 8884, loss = 2446.12933735\n",
      "Iteration 8885, loss = 2446.09839382\n",
      "Iteration 8886, loss = 2446.06739475\n",
      "Iteration 8887, loss = 2446.03633951\n",
      "Iteration 8888, loss = 2446.00522768\n",
      "Iteration 8889, loss = 2445.97405932\n",
      "Iteration 8890, loss = 2445.94283462\n",
      "Iteration 8891, loss = 2445.91155364\n",
      "Iteration 8892, loss = 2445.88021622\n",
      "Iteration 8893, loss = 2445.84882219\n",
      "Iteration 8894, loss = 2445.81737145\n",
      "Iteration 8895, loss = 2445.78586398\n",
      "Iteration 8896, loss = 2445.75429970\n",
      "Iteration 8897, loss = 2445.72267850\n",
      "Iteration 8898, loss = 2445.69100026\n",
      "Iteration 8899, loss = 2445.65926498\n",
      "Iteration 8900, loss = 2445.62747267\n",
      "Iteration 8901, loss = 2445.59562332\n",
      "Iteration 8902, loss = 2445.56371685\n",
      "Iteration 8903, loss = 2445.53175314\n",
      "Iteration 8904, loss = 2445.49973211\n",
      "Iteration 8905, loss = 2445.46765373\n",
      "Iteration 8906, loss = 2445.43551800\n",
      "Iteration 8907, loss = 2445.40332485\n",
      "Iteration 8908, loss = 2445.37107407\n",
      "Iteration 8909, loss = 2445.33876527\n",
      "Iteration 8910, loss = 2445.30639796\n",
      "Iteration 8911, loss = 2445.27397187\n",
      "Iteration 8912, loss = 2445.24148713\n",
      "Iteration 8913, loss = 2445.20894428\n",
      "Iteration 8914, loss = 2445.17634381\n",
      "Iteration 8915, loss = 2445.14368577\n",
      "Iteration 8916, loss = 2445.11096974\n",
      "Iteration 8917, loss = 2445.07819517\n",
      "Iteration 8918, loss = 2445.04536170\n",
      "Iteration 8919, loss = 2445.01246931\n",
      "Iteration 8920, loss = 2444.97951825\n",
      "Iteration 8921, loss = 2444.94650881\n",
      "Iteration 8922, loss = 2444.91344113\n",
      "Iteration 8923, loss = 2444.88031513\n",
      "Iteration 8924, loss = 2444.84713056\n",
      "Iteration 8925, loss = 2444.81388713\n",
      "Iteration 8926, loss = 2444.78058458\n",
      "Iteration 8927, loss = 2444.74722274\n",
      "Iteration 8928, loss = 2444.71380154\n",
      "Iteration 8929, loss = 2444.68032099\n",
      "Iteration 8930, loss = 2444.64678112\n",
      "Iteration 8931, loss = 2444.61318200\n",
      "Iteration 8932, loss = 2444.57952364\n",
      "Iteration 8933, loss = 2444.54580606\n",
      "Iteration 8934, loss = 2444.51202923\n",
      "Iteration 8935, loss = 2444.47819313\n",
      "Iteration 8936, loss = 2444.44429771\n",
      "Iteration 8937, loss = 2444.41034290\n",
      "Iteration 8938, loss = 2444.37632857\n",
      "Iteration 8939, loss = 2444.34225449\n",
      "Iteration 8940, loss = 2444.30812029\n",
      "Iteration 8941, loss = 2444.27392549\n",
      "Iteration 8942, loss = 2444.23966953\n",
      "Iteration 8943, loss = 2444.20535186\n",
      "Iteration 8944, loss = 2444.17097207\n",
      "Iteration 8945, loss = 2444.13653006\n",
      "Iteration 8946, loss = 2444.10202643\n",
      "Iteration 8947, loss = 2444.06746266\n",
      "Iteration 8948, loss = 2444.03284046\n",
      "Iteration 8949, loss = 2443.99816057\n",
      "Iteration 8950, loss = 2443.96342213\n",
      "Iteration 8951, loss = 2443.92862333\n",
      "Iteration 8952, loss = 2443.89376242\n",
      "Iteration 8953, loss = 2443.85883853\n",
      "Iteration 8954, loss = 2443.82385209\n",
      "Iteration 8955, loss = 2443.78880430\n",
      "Iteration 8956, loss = 2443.75369612\n",
      "Iteration 8957, loss = 2443.71852754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8958, loss = 2443.68329795\n",
      "Iteration 8959, loss = 2443.64800680\n",
      "Iteration 8960, loss = 2443.61265402\n",
      "Iteration 8961, loss = 2443.57723987\n",
      "Iteration 8962, loss = 2443.54176463\n",
      "Iteration 8963, loss = 2443.50622819\n",
      "Iteration 8964, loss = 2443.47063016\n",
      "Iteration 8965, loss = 2443.43497006\n",
      "Iteration 8966, loss = 2443.39924760\n",
      "Iteration 8967, loss = 2443.36346273\n",
      "Iteration 8968, loss = 2443.32761562\n",
      "Iteration 8969, loss = 2443.29170645\n",
      "Iteration 8970, loss = 2443.25573528\n",
      "Iteration 8971, loss = 2443.21970204\n",
      "Iteration 8972, loss = 2443.18360657\n",
      "Iteration 8973, loss = 2443.14744872\n",
      "Iteration 8974, loss = 2443.11122835\n",
      "Iteration 8975, loss = 2443.07494545\n",
      "Iteration 8976, loss = 2443.03859997\n",
      "Iteration 8977, loss = 2443.00219189\n",
      "Iteration 8978, loss = 2442.96572115\n",
      "Iteration 8979, loss = 2442.92918763\n",
      "Iteration 8980, loss = 2442.89259123\n",
      "Iteration 8981, loss = 2442.85593184\n",
      "Iteration 8982, loss = 2442.81920939\n",
      "Iteration 8983, loss = 2442.78242383\n",
      "Iteration 8984, loss = 2442.74557509\n",
      "Iteration 8985, loss = 2442.70866314\n",
      "Iteration 8986, loss = 2442.67168791\n",
      "Iteration 8987, loss = 2442.63464935\n",
      "Iteration 8988, loss = 2442.59754739\n",
      "Iteration 8989, loss = 2442.56038197\n",
      "Iteration 8990, loss = 2442.52315305\n",
      "Iteration 8991, loss = 2442.48586062\n",
      "Iteration 8992, loss = 2442.44850475\n",
      "Iteration 8993, loss = 2442.41108563\n",
      "Iteration 8994, loss = 2442.37360371\n",
      "Iteration 8995, loss = 2442.33605991\n",
      "Iteration 8996, loss = 2442.29845588\n",
      "Iteration 8997, loss = 2442.26079406\n",
      "Iteration 8998, loss = 2442.22307628\n",
      "Iteration 8999, loss = 2442.18529897\n",
      "Iteration 9000, loss = 2442.14744709\n",
      "Iteration 9001, loss = 2442.10950069\n",
      "Iteration 9002, loss = 2442.07146269\n",
      "Iteration 9003, loss = 2442.03336871\n",
      "Iteration 9004, loss = 2441.99524521\n",
      "Iteration 9005, loss = 2441.95707445\n",
      "Iteration 9006, loss = 2441.91882190\n",
      "Iteration 9007, loss = 2441.88048404\n",
      "Iteration 9008, loss = 2441.84208602\n",
      "Iteration 9009, loss = 2441.80363859\n",
      "Iteration 9010, loss = 2441.76512908\n",
      "Iteration 9011, loss = 2441.72654655\n",
      "Iteration 9012, loss = 2441.68789408\n",
      "Iteration 9013, loss = 2441.64917820\n",
      "Iteration 9014, loss = 2441.61040299\n",
      "Iteration 9015, loss = 2441.57156545\n",
      "Iteration 9016, loss = 2441.53265698\n",
      "Iteration 9017, loss = 2441.49367718\n",
      "Iteration 9018, loss = 2441.45463719\n",
      "Iteration 9019, loss = 2441.41553903\n",
      "Iteration 9020, loss = 2441.37637062\n",
      "Iteration 9021, loss = 2441.33712885\n",
      "Iteration 9022, loss = 2441.29782518\n",
      "Iteration 9023, loss = 2441.25846257\n",
      "Iteration 9024, loss = 2441.21903100\n",
      "Iteration 9025, loss = 2441.17952784\n",
      "Iteration 9026, loss = 2441.13996086\n",
      "Iteration 9027, loss = 2441.10033167\n",
      "Iteration 9028, loss = 2441.06063458\n",
      "Iteration 9029, loss = 2441.02086886\n",
      "Iteration 9030, loss = 2440.98103814\n",
      "Iteration 9031, loss = 2440.94114193\n",
      "Iteration 9032, loss = 2440.90117791\n",
      "Iteration 9033, loss = 2440.86114728\n",
      "Iteration 9034, loss = 2440.82105139\n",
      "Iteration 9035, loss = 2440.78088832\n",
      "Iteration 9036, loss = 2440.74065694\n",
      "Iteration 9037, loss = 2440.70035920\n",
      "Iteration 9038, loss = 2440.65999604\n",
      "Iteration 9039, loss = 2440.61956554\n",
      "Iteration 9040, loss = 2440.57906660\n",
      "Iteration 9041, loss = 2440.53850061\n",
      "Iteration 9042, loss = 2440.49786844\n",
      "Iteration 9043, loss = 2440.45716901\n",
      "Iteration 9044, loss = 2440.41640153\n",
      "Iteration 9045, loss = 2440.37556658\n",
      "Iteration 9046, loss = 2440.33466457\n",
      "Iteration 9047, loss = 2440.29369496\n",
      "Iteration 9048, loss = 2440.25265735\n",
      "Iteration 9049, loss = 2440.21155213\n",
      "Iteration 9050, loss = 2440.17037949\n",
      "Iteration 9051, loss = 2440.12913894\n",
      "Iteration 9052, loss = 2440.08783010\n",
      "Iteration 9053, loss = 2440.04645324\n",
      "Iteration 9054, loss = 2440.00500863\n",
      "Iteration 9055, loss = 2439.96349601\n",
      "Iteration 9056, loss = 2439.92191501\n",
      "Iteration 9057, loss = 2439.88026562\n",
      "Iteration 9058, loss = 2439.83854798\n",
      "Iteration 9059, loss = 2439.79676204\n",
      "Iteration 9060, loss = 2439.75490757\n",
      "Iteration 9061, loss = 2439.71298448\n",
      "Iteration 9062, loss = 2439.67099284\n",
      "Iteration 9063, loss = 2439.62893261\n",
      "Iteration 9064, loss = 2439.58680362\n",
      "Iteration 9065, loss = 2439.54460572\n",
      "Iteration 9066, loss = 2439.50233890\n",
      "Iteration 9067, loss = 2439.46000318\n",
      "Iteration 9068, loss = 2439.41759850\n",
      "Iteration 9069, loss = 2439.37512471\n",
      "Iteration 9070, loss = 2439.33258173\n",
      "Iteration 9071, loss = 2439.28996952\n",
      "Iteration 9072, loss = 2439.24728804\n",
      "Iteration 9073, loss = 2439.20453720\n",
      "Iteration 9074, loss = 2439.16171691\n",
      "Iteration 9075, loss = 2439.11882709\n",
      "Iteration 9076, loss = 2439.07586771\n",
      "Iteration 9077, loss = 2439.03283871\n",
      "Iteration 9078, loss = 2438.98974002\n",
      "Iteration 9079, loss = 2438.94657154\n",
      "Iteration 9080, loss = 2438.90333320\n",
      "Iteration 9081, loss = 2438.86002496\n",
      "Iteration 9082, loss = 2438.81664674\n",
      "Iteration 9083, loss = 2438.77319848\n",
      "Iteration 9084, loss = 2438.72968010\n",
      "Iteration 9085, loss = 2438.68609152\n",
      "Iteration 9086, loss = 2438.64243269\n",
      "Iteration 9087, loss = 2438.59870354\n",
      "Iteration 9088, loss = 2438.55490401\n",
      "Iteration 9089, loss = 2438.51103401\n",
      "Iteration 9090, loss = 2438.46709349\n",
      "Iteration 9091, loss = 2438.42308237\n",
      "Iteration 9092, loss = 2438.37900058\n",
      "Iteration 9093, loss = 2438.33484808\n",
      "Iteration 9094, loss = 2438.29062478\n",
      "Iteration 9095, loss = 2438.24633061\n",
      "Iteration 9096, loss = 2438.20196552\n",
      "Iteration 9097, loss = 2438.15752945\n",
      "Iteration 9098, loss = 2438.11302234\n",
      "Iteration 9099, loss = 2438.06844414\n",
      "Iteration 9100, loss = 2438.02379483\n",
      "Iteration 9101, loss = 2437.97907443\n",
      "Iteration 9102, loss = 2437.93428299\n",
      "Iteration 9103, loss = 2437.88942071\n",
      "Iteration 9104, loss = 2437.84448792\n",
      "Iteration 9105, loss = 2437.79948525\n",
      "Iteration 9106, loss = 2437.75441345\n",
      "Iteration 9107, loss = 2437.70927298\n",
      "Iteration 9108, loss = 2437.66406266\n",
      "Iteration 9109, loss = 2437.61877850\n",
      "Iteration 9110, loss = 2437.57341547\n",
      "Iteration 9111, loss = 2437.52797189\n",
      "Iteration 9112, loss = 2437.48245149\n",
      "Iteration 9113, loss = 2437.43686034\n",
      "Iteration 9114, loss = 2437.39120123\n",
      "Iteration 9115, loss = 2437.34547235\n",
      "Iteration 9116, loss = 2437.29967211\n",
      "Iteration 9117, loss = 2437.25380154\n",
      "Iteration 9118, loss = 2437.20786175\n",
      "Iteration 9119, loss = 2437.16184997\n",
      "Iteration 9120, loss = 2437.11576057\n",
      "Iteration 9121, loss = 2437.06959289\n",
      "Iteration 9122, loss = 2437.02335358\n",
      "Iteration 9123, loss = 2436.97704829\n",
      "Iteration 9124, loss = 2436.93067457\n",
      "Iteration 9125, loss = 2436.88422537\n",
      "Iteration 9126, loss = 2436.83769765\n",
      "Iteration 9127, loss = 2436.79109524\n",
      "Iteration 9128, loss = 2436.74442298\n",
      "Iteration 9129, loss = 2436.69768086\n",
      "Iteration 9130, loss = 2436.65086517\n",
      "Iteration 9131, loss = 2436.60397371\n",
      "Iteration 9132, loss = 2436.55700790\n",
      "Iteration 9133, loss = 2436.50996990\n",
      "Iteration 9134, loss = 2436.46285972\n",
      "Iteration 9135, loss = 2436.41567565\n",
      "Iteration 9136, loss = 2436.36841669\n",
      "Iteration 9137, loss = 2436.32108362\n",
      "Iteration 9138, loss = 2436.27367768\n",
      "Iteration 9139, loss = 2436.22619887\n",
      "Iteration 9140, loss = 2436.17864612\n",
      "Iteration 9141, loss = 2436.13101853\n",
      "Iteration 9142, loss = 2436.08331626\n",
      "Iteration 9143, loss = 2436.03554001\n",
      "Iteration 9144, loss = 2435.98769019\n",
      "Iteration 9145, loss = 2435.93976650\n",
      "Iteration 9146, loss = 2435.89176840\n",
      "Iteration 9147, loss = 2435.84369563\n",
      "Iteration 9148, loss = 2435.79554828\n",
      "Iteration 9149, loss = 2435.74732648\n",
      "Iteration 9150, loss = 2435.69903018\n",
      "Iteration 9151, loss = 2435.65065920\n",
      "Iteration 9152, loss = 2435.60221342\n",
      "Iteration 9153, loss = 2435.55369281\n",
      "Iteration 9154, loss = 2435.50509741\n",
      "Iteration 9155, loss = 2435.45642722\n",
      "Iteration 9156, loss = 2435.40768209\n",
      "Iteration 9157, loss = 2435.35886188\n",
      "Iteration 9158, loss = 2435.30996645\n",
      "Iteration 9159, loss = 2435.26099579\n",
      "Iteration 9160, loss = 2435.21194987\n",
      "Iteration 9161, loss = 2435.16282868\n",
      "Iteration 9162, loss = 2435.11363212\n",
      "Iteration 9163, loss = 2435.06436010\n",
      "Iteration 9164, loss = 2435.01501251\n",
      "Iteration 9165, loss = 2434.96558930\n",
      "Iteration 9166, loss = 2434.91609040\n",
      "Iteration 9167, loss = 2434.86651580\n",
      "Iteration 9168, loss = 2434.81686541\n",
      "Iteration 9169, loss = 2434.76713919\n",
      "Iteration 9170, loss = 2434.71733705\n",
      "Iteration 9171, loss = 2434.66745891\n",
      "Iteration 9172, loss = 2434.61750471\n",
      "Iteration 9173, loss = 2434.56747438\n",
      "Iteration 9174, loss = 2434.51736789\n",
      "Iteration 9175, loss = 2434.46718518\n",
      "Iteration 9176, loss = 2434.41692622\n",
      "Iteration 9177, loss = 2434.36659099\n",
      "Iteration 9178, loss = 2434.31617952\n",
      "Iteration 9179, loss = 2434.26569190\n",
      "Iteration 9180, loss = 2434.21512835\n",
      "Iteration 9181, loss = 2434.16448932\n",
      "Iteration 9182, loss = 2434.11377559\n",
      "Iteration 9183, loss = 2434.06298841\n",
      "Iteration 9184, loss = 2434.01212928\n",
      "Iteration 9185, loss = 2433.96119892\n",
      "Iteration 9186, loss = 2433.91019434\n",
      "Iteration 9187, loss = 2433.85910557\n",
      "Iteration 9188, loss = 2433.80791906\n",
      "Iteration 9189, loss = 2433.75663245\n",
      "Iteration 9190, loss = 2433.70526388\n",
      "Iteration 9191, loss = 2433.65383668\n",
      "Iteration 9192, loss = 2433.60235654\n",
      "Iteration 9193, loss = 2433.55080794\n",
      "Iteration 9194, loss = 2433.49916999\n",
      "Iteration 9195, loss = 2433.44743507\n",
      "Iteration 9196, loss = 2433.39561611\n",
      "Iteration 9197, loss = 2433.34373268\n",
      "Iteration 9198, loss = 2433.29178769\n",
      "Iteration 9199, loss = 2433.23976491\n",
      "Iteration 9200, loss = 2433.18764991\n",
      "Iteration 9201, loss = 2433.13544753\n",
      "Iteration 9202, loss = 2433.08317397\n",
      "Iteration 9203, loss = 2433.03083416\n",
      "Iteration 9204, loss = 2432.97841737\n",
      "Iteration 9205, loss = 2432.92591388\n",
      "Iteration 9206, loss = 2432.87332671\n",
      "Iteration 9207, loss = 2432.82066436\n",
      "Iteration 9208, loss = 2432.76792878\n",
      "Iteration 9209, loss = 2432.71511552\n",
      "Iteration 9210, loss = 2432.66222126\n",
      "Iteration 9211, loss = 2432.60924648\n",
      "Iteration 9212, loss = 2432.55619262\n",
      "Iteration 9213, loss = 2432.50306054\n",
      "Iteration 9214, loss = 2432.44985094\n",
      "Iteration 9215, loss = 2432.39656363\n",
      "Iteration 9216, loss = 2432.34319691\n",
      "Iteration 9217, loss = 2432.28974919\n",
      "Iteration 9218, loss = 2432.23622120\n",
      "Iteration 9219, loss = 2432.18261511\n",
      "Iteration 9220, loss = 2432.12893162\n",
      "Iteration 9221, loss = 2432.07516912\n",
      "Iteration 9222, loss = 2432.02132585\n",
      "Iteration 9223, loss = 2431.96740188\n",
      "Iteration 9224, loss = 2431.91339856\n",
      "Iteration 9225, loss = 2431.85931661\n",
      "Iteration 9226, loss = 2431.80515553\n",
      "Iteration 9227, loss = 2431.75091445\n",
      "Iteration 9228, loss = 2431.69659306\n",
      "Iteration 9229, loss = 2431.64219154\n",
      "Iteration 9230, loss = 2431.58771009\n",
      "Iteration 9231, loss = 2431.53314870\n",
      "Iteration 9232, loss = 2431.47850735\n",
      "Iteration 9233, loss = 2431.42378599\n",
      "Iteration 9234, loss = 2431.36898446\n",
      "Iteration 9235, loss = 2431.31410254\n",
      "Iteration 9236, loss = 2431.25914001\n",
      "Iteration 9237, loss = 2431.20409689\n",
      "Iteration 9238, loss = 2431.14897331\n",
      "Iteration 9239, loss = 2431.09376932\n",
      "Iteration 9240, loss = 2431.03848482\n",
      "Iteration 9241, loss = 2430.98311963\n",
      "Iteration 9242, loss = 2430.92767358\n",
      "Iteration 9243, loss = 2430.87214659\n",
      "Iteration 9244, loss = 2430.81653863\n",
      "Iteration 9245, loss = 2430.76084966\n",
      "Iteration 9246, loss = 2430.70507965\n",
      "Iteration 9247, loss = 2430.64922854\n",
      "Iteration 9248, loss = 2430.59329628\n",
      "Iteration 9249, loss = 2430.53728279\n",
      "Iteration 9250, loss = 2430.48118798\n",
      "Iteration 9251, loss = 2430.42501175\n",
      "Iteration 9252, loss = 2430.36875404\n",
      "Iteration 9253, loss = 2430.31241478\n",
      "Iteration 9254, loss = 2430.25599389\n",
      "Iteration 9255, loss = 2430.19949133\n",
      "Iteration 9256, loss = 2430.14290702\n",
      "Iteration 9257, loss = 2430.08624090\n",
      "Iteration 9258, loss = 2430.02949290\n",
      "Iteration 9259, loss = 2429.97266296\n",
      "Iteration 9260, loss = 2429.91575102\n",
      "Iteration 9261, loss = 2429.85875699\n",
      "Iteration 9262, loss = 2429.80168082\n",
      "Iteration 9263, loss = 2429.74452242\n",
      "Iteration 9264, loss = 2429.68728173\n",
      "Iteration 9265, loss = 2429.62995868\n",
      "Iteration 9266, loss = 2429.57255321\n",
      "Iteration 9267, loss = 2429.51506524\n",
      "Iteration 9268, loss = 2429.45749471\n",
      "Iteration 9269, loss = 2429.39984155\n",
      "Iteration 9270, loss = 2429.34210570\n",
      "Iteration 9271, loss = 2429.28428708\n",
      "Iteration 9272, loss = 2429.22638565\n",
      "Iteration 9273, loss = 2429.16840136\n",
      "Iteration 9274, loss = 2429.11033417\n",
      "Iteration 9275, loss = 2429.05218406\n",
      "Iteration 9276, loss = 2428.99395108\n",
      "Iteration 9277, loss = 2428.93563531\n",
      "Iteration 9278, loss = 2428.87723702\n",
      "Iteration 9279, loss = 2428.81875663\n",
      "Iteration 9280, loss = 2428.76019500\n",
      "Iteration 9281, loss = 2428.70155339\n",
      "Iteration 9282, loss = 2428.64283350\n",
      "Iteration 9283, loss = 2428.58403646\n",
      "Iteration 9284, loss = 2428.52516035\n",
      "Iteration 9285, loss = 2428.46619644\n",
      "Iteration 9286, loss = 2428.40712958\n",
      "Iteration 9287, loss = 2428.34795017\n",
      "Iteration 9288, loss = 2428.28867076\n",
      "Iteration 9289, loss = 2428.22932152\n",
      "Iteration 9290, loss = 2428.16992056\n",
      "Iteration 9291, loss = 2428.11045620\n",
      "Iteration 9292, loss = 2428.05090001\n",
      "Iteration 9293, loss = 2427.99123355\n",
      "Iteration 9294, loss = 2427.93146664\n",
      "Iteration 9295, loss = 2427.87162604\n",
      "Iteration 9296, loss = 2427.81172301\n",
      "Iteration 9297, loss = 2427.75174287\n",
      "Iteration 9298, loss = 2427.69166607\n",
      "Iteration 9299, loss = 2427.63149027\n",
      "Iteration 9300, loss = 2427.57122920\n",
      "Iteration 9301, loss = 2427.51089351\n",
      "Iteration 9302, loss = 2427.45048049\n",
      "Iteration 9303, loss = 2427.38998108\n",
      "Iteration 9304, loss = 2427.32939019\n",
      "Iteration 9305, loss = 2427.26870974\n",
      "Iteration 9306, loss = 2427.20794502\n",
      "Iteration 9307, loss = 2427.14709988\n",
      "Iteration 9308, loss = 2427.08617321\n",
      "Iteration 9309, loss = 2427.02515999\n",
      "Iteration 9310, loss = 2426.96405666\n",
      "Iteration 9311, loss = 2426.90286498\n",
      "Iteration 9312, loss = 2426.84158978\n",
      "Iteration 9313, loss = 2426.78023287\n",
      "Iteration 9314, loss = 2426.71879128\n",
      "Iteration 9315, loss = 2426.65726147\n",
      "Iteration 9316, loss = 2426.59564320\n",
      "Iteration 9317, loss = 2426.53393883\n",
      "Iteration 9318, loss = 2426.47215001\n",
      "Iteration 9319, loss = 2426.41027627\n",
      "Iteration 9320, loss = 2426.34831632\n",
      "Iteration 9321, loss = 2426.28626939\n",
      "Iteration 9322, loss = 2426.22413539\n",
      "Iteration 9323, loss = 2426.16191452\n",
      "Iteration 9324, loss = 2426.09960720\n",
      "Iteration 9325, loss = 2426.03721386\n",
      "Iteration 9326, loss = 2425.97473448\n",
      "Iteration 9327, loss = 2425.91216847\n",
      "Iteration 9328, loss = 2425.84951508\n",
      "Iteration 9329, loss = 2425.78677416\n",
      "Iteration 9330, loss = 2425.72394610\n",
      "Iteration 9331, loss = 2425.66103133\n",
      "Iteration 9332, loss = 2425.59802986\n",
      "Iteration 9333, loss = 2425.53494135\n",
      "Iteration 9334, loss = 2425.47176544\n",
      "Iteration 9335, loss = 2425.40850198\n",
      "Iteration 9336, loss = 2425.34515094\n",
      "Iteration 9337, loss = 2425.28171233\n",
      "Iteration 9338, loss = 2425.21818613\n",
      "Iteration 9339, loss = 2425.15457232\n",
      "Iteration 9340, loss = 2425.09087088\n",
      "Iteration 9341, loss = 2425.02708175\n",
      "Iteration 9342, loss = 2424.96320477\n",
      "Iteration 9343, loss = 2424.89923978\n",
      "Iteration 9344, loss = 2424.83518664\n",
      "Iteration 9345, loss = 2424.77104530\n",
      "Iteration 9346, loss = 2424.70681575\n",
      "Iteration 9347, loss = 2424.64249795\n",
      "Iteration 9348, loss = 2424.57809183\n",
      "Iteration 9349, loss = 2424.51359731\n",
      "Iteration 9350, loss = 2424.44901431\n",
      "Iteration 9351, loss = 2424.38434275\n",
      "Iteration 9352, loss = 2424.31958255\n",
      "Iteration 9353, loss = 2424.25473362\n",
      "Iteration 9354, loss = 2424.18979588\n",
      "Iteration 9355, loss = 2424.12476922\n",
      "Iteration 9356, loss = 2424.05965358\n",
      "Iteration 9357, loss = 2423.99444888\n",
      "Iteration 9358, loss = 2423.92915505\n",
      "Iteration 9359, loss = 2423.86377202\n",
      "Iteration 9360, loss = 2423.79829971\n",
      "Iteration 9361, loss = 2423.73273803\n",
      "Iteration 9362, loss = 2423.66708692\n",
      "Iteration 9363, loss = 2423.60134628\n",
      "Iteration 9364, loss = 2423.53551605\n",
      "Iteration 9365, loss = 2423.46959615\n",
      "Iteration 9366, loss = 2423.40358650\n",
      "Iteration 9367, loss = 2423.33748702\n",
      "Iteration 9368, loss = 2423.27129764\n",
      "Iteration 9369, loss = 2423.20501828\n",
      "Iteration 9370, loss = 2423.13864888\n",
      "Iteration 9371, loss = 2423.07218938\n",
      "Iteration 9372, loss = 2423.00563974\n",
      "Iteration 9373, loss = 2422.93899994\n",
      "Iteration 9374, loss = 2422.87227003\n",
      "Iteration 9375, loss = 2422.80545010\n",
      "Iteration 9376, loss = 2422.73854046\n",
      "Iteration 9377, loss = 2422.67154160\n",
      "Iteration 9378, loss = 2422.60445450\n",
      "Iteration 9379, loss = 2422.53728071\n",
      "Iteration 9380, loss = 2422.47002258\n",
      "Iteration 9381, loss = 2422.40268253\n",
      "Iteration 9382, loss = 2422.33526089\n",
      "Iteration 9383, loss = 2422.26775007\n",
      "Iteration 9384, loss = 2422.20013024\n",
      "Iteration 9385, loss = 2422.13237821\n",
      "Iteration 9386, loss = 2422.06449640\n",
      "Iteration 9387, loss = 2421.99652418\n",
      "Iteration 9388, loss = 2421.92850237\n",
      "Iteration 9389, loss = 2421.86043273\n",
      "Iteration 9390, loss = 2421.79228043\n",
      "Iteration 9391, loss = 2421.72400721\n",
      "Iteration 9392, loss = 2421.65560593\n",
      "Iteration 9393, loss = 2421.58710756\n",
      "Iteration 9394, loss = 2421.51854451\n",
      "Iteration 9395, loss = 2421.44991529\n",
      "Iteration 9396, loss = 2421.38119275\n",
      "Iteration 9397, loss = 2421.31235651\n",
      "Iteration 9398, loss = 2421.24341175\n",
      "Iteration 9399, loss = 2421.17437904\n",
      "Iteration 9400, loss = 2421.10527085\n",
      "Iteration 9401, loss = 2421.03608020\n",
      "Iteration 9402, loss = 2420.96679081\n",
      "Iteration 9403, loss = 2420.89739528\n",
      "Iteration 9404, loss = 2420.82790146\n",
      "Iteration 9405, loss = 2420.75832176\n",
      "Iteration 9406, loss = 2420.68865864\n",
      "Iteration 9407, loss = 2420.61890409\n",
      "Iteration 9408, loss = 2420.54905021\n",
      "Iteration 9409, loss = 2420.47909675\n",
      "Iteration 9410, loss = 2420.40904944\n",
      "Iteration 9411, loss = 2420.33891306\n",
      "Iteration 9412, loss = 2420.26868734\n",
      "Iteration 9413, loss = 2420.19836809\n",
      "Iteration 9414, loss = 2420.12795154\n",
      "Iteration 9415, loss = 2420.05743781\n",
      "Iteration 9416, loss = 2419.98683001\n",
      "Iteration 9417, loss = 2419.91613070\n",
      "Iteration 9418, loss = 2419.84533949\n",
      "Iteration 9419, loss = 2419.77445399\n",
      "Iteration 9420, loss = 2419.70347240\n",
      "Iteration 9421, loss = 2419.63239462\n",
      "Iteration 9422, loss = 2419.56122188\n",
      "Iteration 9423, loss = 2419.48995537\n",
      "Iteration 9424, loss = 2419.41859533\n",
      "Iteration 9425, loss = 2419.34714097\n",
      "Iteration 9426, loss = 2419.27559117\n",
      "Iteration 9427, loss = 2419.20394534\n",
      "Iteration 9428, loss = 2419.13220365\n",
      "Iteration 9429, loss = 2419.06036672\n",
      "Iteration 9430, loss = 2418.98843492\n",
      "Iteration 9431, loss = 2418.91640818\n",
      "Iteration 9432, loss = 2418.84428607\n",
      "Iteration 9433, loss = 2418.77206808\n",
      "Iteration 9434, loss = 2418.69975392\n",
      "Iteration 9435, loss = 2418.62734352\n",
      "Iteration 9436, loss = 2418.55483702\n",
      "Iteration 9437, loss = 2418.48223455\n",
      "Iteration 9438, loss = 2418.40953612\n",
      "Iteration 9439, loss = 2418.33674157\n",
      "Iteration 9440, loss = 2418.26385067\n",
      "Iteration 9441, loss = 2418.19086319\n",
      "Iteration 9442, loss = 2418.11777895\n",
      "Iteration 9443, loss = 2418.04459785\n",
      "Iteration 9444, loss = 2417.97131983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9445, loss = 2417.89794488\n",
      "Iteration 9446, loss = 2417.82447294\n",
      "Iteration 9447, loss = 2417.75090393\n",
      "Iteration 9448, loss = 2417.67723772\n",
      "Iteration 9449, loss = 2417.60347417\n",
      "Iteration 9450, loss = 2417.52961317\n",
      "Iteration 9451, loss = 2417.45565456\n",
      "Iteration 9452, loss = 2417.38159822\n",
      "Iteration 9453, loss = 2417.30744404\n",
      "Iteration 9454, loss = 2417.23319193\n",
      "Iteration 9455, loss = 2417.15884177\n",
      "Iteration 9456, loss = 2417.08439348\n",
      "Iteration 9457, loss = 2417.00984694\n",
      "Iteration 9458, loss = 2416.93520205\n",
      "Iteration 9459, loss = 2416.86045870\n",
      "Iteration 9460, loss = 2416.78561678\n",
      "Iteration 9461, loss = 2416.71067617\n",
      "Iteration 9462, loss = 2416.63563674\n",
      "Iteration 9463, loss = 2416.56049840\n",
      "Iteration 9464, loss = 2416.48526101\n",
      "Iteration 9465, loss = 2416.40992447\n",
      "Iteration 9466, loss = 2416.33448865\n",
      "Iteration 9467, loss = 2416.25895343\n",
      "Iteration 9468, loss = 2416.18331870\n",
      "Iteration 9469, loss = 2416.10758435\n",
      "Iteration 9470, loss = 2416.03175026\n",
      "Iteration 9471, loss = 2415.95581631\n",
      "Iteration 9472, loss = 2415.87978239\n",
      "Iteration 9473, loss = 2415.80364840\n",
      "Iteration 9474, loss = 2415.72741423\n",
      "Iteration 9475, loss = 2415.65107983\n",
      "Iteration 9476, loss = 2415.57464511\n",
      "Iteration 9477, loss = 2415.49811011\n",
      "Iteration 9478, loss = 2415.42147489\n",
      "Iteration 9479, loss = 2415.34473973\n",
      "Iteration 9480, loss = 2415.26790512\n",
      "Iteration 9481, loss = 2415.19097211\n",
      "Iteration 9482, loss = 2415.11394235\n",
      "Iteration 9483, loss = 2415.03681864\n",
      "Iteration 9484, loss = 2414.95960442\n",
      "Iteration 9485, loss = 2414.88230242\n",
      "Iteration 9486, loss = 2414.80490872\n",
      "Iteration 9487, loss = 2414.72740494\n",
      "Iteration 9488, loss = 2414.64975669\n",
      "Iteration 9489, loss = 2414.57194256\n",
      "Iteration 9490, loss = 2414.49399254\n",
      "Iteration 9491, loss = 2414.41597544\n",
      "Iteration 9492, loss = 2414.33792776\n",
      "Iteration 9493, loss = 2414.25981903\n",
      "Iteration 9494, loss = 2414.18158668\n",
      "Iteration 9495, loss = 2414.10319498\n",
      "Iteration 9496, loss = 2414.02466995\n",
      "Iteration 9497, loss = 2413.94606671\n",
      "Iteration 9498, loss = 2413.86740507\n",
      "Iteration 9499, loss = 2413.78865449\n",
      "Iteration 9500, loss = 2413.70977517\n",
      "Iteration 9501, loss = 2413.63076085\n",
      "Iteration 9502, loss = 2413.55164050\n",
      "Iteration 9503, loss = 2413.47244142\n",
      "Iteration 9504, loss = 2413.39315790\n",
      "Iteration 9505, loss = 2413.31376318\n",
      "Iteration 9506, loss = 2413.23424330\n",
      "Iteration 9507, loss = 2413.15461001\n",
      "Iteration 9508, loss = 2413.07488266\n",
      "Iteration 9509, loss = 2412.99506484\n",
      "Iteration 9510, loss = 2412.91514385\n",
      "Iteration 9511, loss = 2412.83510749\n",
      "Iteration 9512, loss = 2412.75495650\n",
      "Iteration 9513, loss = 2412.67470160\n",
      "Iteration 9514, loss = 2412.59434973\n",
      "Iteration 9515, loss = 2412.51389709\n",
      "Iteration 9516, loss = 2412.43333518\n",
      "Iteration 9517, loss = 2412.35266049\n",
      "Iteration 9518, loss = 2412.27187710\n",
      "Iteration 9519, loss = 2412.19099042\n",
      "Iteration 9520, loss = 2412.11000152\n",
      "Iteration 9521, loss = 2412.02890682\n",
      "Iteration 9522, loss = 2411.94770231\n",
      "Iteration 9523, loss = 2411.86638744\n",
      "Iteration 9524, loss = 2411.78496468\n",
      "Iteration 9525, loss = 2411.70343653\n",
      "Iteration 9526, loss = 2411.62180288\n",
      "Iteration 9527, loss = 2411.54006152\n",
      "Iteration 9528, loss = 2411.45821054\n",
      "Iteration 9529, loss = 2411.37624969\n",
      "Iteration 9530, loss = 2411.29418018\n",
      "Iteration 9531, loss = 2411.21200308\n",
      "Iteration 9532, loss = 2411.12971835\n",
      "Iteration 9533, loss = 2411.04732497\n",
      "Iteration 9534, loss = 2410.96482179\n",
      "Iteration 9535, loss = 2410.88220841\n",
      "Iteration 9536, loss = 2410.79948509\n",
      "Iteration 9537, loss = 2410.71665236\n",
      "Iteration 9538, loss = 2410.63371035\n",
      "Iteration 9539, loss = 2410.55065864\n",
      "Iteration 9540, loss = 2410.46749662\n",
      "Iteration 9541, loss = 2410.38422374\n",
      "Iteration 9542, loss = 2410.30083984\n",
      "Iteration 9543, loss = 2410.21734494\n",
      "Iteration 9544, loss = 2410.13373914\n",
      "Iteration 9545, loss = 2410.05002235\n",
      "Iteration 9546, loss = 2409.96619431\n",
      "Iteration 9547, loss = 2409.88225464\n",
      "Iteration 9548, loss = 2409.79820297\n",
      "Iteration 9549, loss = 2409.71403908\n",
      "Iteration 9550, loss = 2409.62976281\n",
      "Iteration 9551, loss = 2409.54537407\n",
      "Iteration 9552, loss = 2409.46087274\n",
      "Iteration 9553, loss = 2409.37625862\n",
      "Iteration 9554, loss = 2409.29153147\n",
      "Iteration 9555, loss = 2409.20669102\n",
      "Iteration 9556, loss = 2409.12173700\n",
      "Iteration 9557, loss = 2409.03666917\n",
      "Iteration 9558, loss = 2408.95148733\n",
      "Iteration 9559, loss = 2408.86619127\n",
      "Iteration 9560, loss = 2408.78078081\n",
      "Iteration 9561, loss = 2408.69525575\n",
      "Iteration 9562, loss = 2408.60961586\n",
      "Iteration 9563, loss = 2408.52386091\n",
      "Iteration 9564, loss = 2408.43799067\n",
      "Iteration 9565, loss = 2408.35200487\n",
      "Iteration 9566, loss = 2408.26590328\n",
      "Iteration 9567, loss = 2408.17968566\n",
      "Iteration 9568, loss = 2408.09335177\n",
      "Iteration 9569, loss = 2408.00690137\n",
      "Iteration 9570, loss = 2407.92033423\n",
      "Iteration 9571, loss = 2407.83365012\n",
      "Iteration 9572, loss = 2407.74684878\n",
      "Iteration 9573, loss = 2407.65992997\n",
      "Iteration 9574, loss = 2407.57289344\n",
      "Iteration 9575, loss = 2407.48573894\n",
      "Iteration 9576, loss = 2407.39846622\n",
      "Iteration 9577, loss = 2407.31107501\n",
      "Iteration 9578, loss = 2407.22356506\n",
      "Iteration 9579, loss = 2407.13593610\n",
      "Iteration 9580, loss = 2407.04818788\n",
      "Iteration 9581, loss = 2406.96032011\n",
      "Iteration 9582, loss = 2406.87233255\n",
      "Iteration 9583, loss = 2406.78422490\n",
      "Iteration 9584, loss = 2406.69599692\n",
      "Iteration 9585, loss = 2406.60764831\n",
      "Iteration 9586, loss = 2406.51917881\n",
      "Iteration 9587, loss = 2406.43058813\n",
      "Iteration 9588, loss = 2406.34187600\n",
      "Iteration 9589, loss = 2406.25304213\n",
      "Iteration 9590, loss = 2406.16408626\n",
      "Iteration 9591, loss = 2406.07500811\n",
      "Iteration 9592, loss = 2405.98580741\n",
      "Iteration 9593, loss = 2405.89648391\n",
      "Iteration 9594, loss = 2405.80703739\n",
      "Iteration 9595, loss = 2405.71746767\n",
      "Iteration 9596, loss = 2405.62777469\n",
      "Iteration 9597, loss = 2405.53795847\n",
      "Iteration 9598, loss = 2405.44801938\n",
      "Iteration 9599, loss = 2405.35795808\n",
      "Iteration 9600, loss = 2405.26777608\n",
      "Iteration 9601, loss = 2405.17747555\n",
      "Iteration 9602, loss = 2405.08705981\n",
      "Iteration 9603, loss = 2404.99653143\n",
      "Iteration 9604, loss = 2404.90588903\n",
      "Iteration 9605, loss = 2404.81511852\n",
      "Iteration 9606, loss = 2404.72418974\n",
      "Iteration 9607, loss = 2404.63307132\n",
      "Iteration 9608, loss = 2404.54177251\n",
      "Iteration 9609, loss = 2404.45035375\n",
      "Iteration 9610, loss = 2404.35887292\n",
      "Iteration 9611, loss = 2404.26732660\n",
      "Iteration 9612, loss = 2404.17565947\n",
      "Iteration 9613, loss = 2404.08381770\n",
      "Iteration 9614, loss = 2403.99179494\n",
      "Iteration 9615, loss = 2403.89963659\n",
      "Iteration 9616, loss = 2403.80738745\n",
      "Iteration 9617, loss = 2403.71504525\n",
      "Iteration 9618, loss = 2403.62257066\n",
      "Iteration 9619, loss = 2403.52993207\n",
      "Iteration 9620, loss = 2403.43713693\n",
      "Iteration 9621, loss = 2403.34421763\n",
      "Iteration 9622, loss = 2403.25119235\n",
      "Iteration 9623, loss = 2403.15804752\n",
      "Iteration 9624, loss = 2403.06475794\n",
      "Iteration 9625, loss = 2402.97131500\n",
      "Iteration 9626, loss = 2402.87773190\n",
      "Iteration 9627, loss = 2402.78402579\n",
      "Iteration 9628, loss = 2402.69019808\n",
      "Iteration 9629, loss = 2402.59623560\n",
      "Iteration 9630, loss = 2402.50212687\n",
      "Iteration 9631, loss = 2402.40787299\n",
      "Iteration 9632, loss = 2402.31348388\n",
      "Iteration 9633, loss = 2402.21896562\n",
      "Iteration 9634, loss = 2402.12431474\n",
      "Iteration 9635, loss = 2402.02952324\n",
      "Iteration 9636, loss = 2401.93458686\n",
      "Iteration 9637, loss = 2401.83950827\n",
      "Iteration 9638, loss = 2401.74429245\n",
      "Iteration 9639, loss = 2401.64894105\n",
      "Iteration 9640, loss = 2401.55345093\n",
      "Iteration 9641, loss = 2401.45781773\n",
      "Iteration 9642, loss = 2401.36203983\n",
      "Iteration 9643, loss = 2401.26611869\n",
      "Iteration 9644, loss = 2401.17005658\n",
      "Iteration 9645, loss = 2401.07385377\n",
      "Iteration 9646, loss = 2400.97750836\n",
      "Iteration 9647, loss = 2400.88101796\n",
      "Iteration 9648, loss = 2400.78438134\n",
      "Iteration 9649, loss = 2400.68759896\n",
      "Iteration 9650, loss = 2400.59067160\n",
      "Iteration 9651, loss = 2400.49359935\n",
      "Iteration 9652, loss = 2400.39638117\n",
      "Iteration 9653, loss = 2400.29901557\n",
      "Iteration 9654, loss = 2400.20150149\n",
      "Iteration 9655, loss = 2400.10383851\n",
      "Iteration 9656, loss = 2400.00602675\n",
      "Iteration 9657, loss = 2399.90806611\n",
      "Iteration 9658, loss = 2399.80995604\n",
      "Iteration 9659, loss = 2399.71169563\n",
      "Iteration 9660, loss = 2399.61328389\n",
      "Iteration 9661, loss = 2399.51472011\n",
      "Iteration 9662, loss = 2399.41600379\n",
      "Iteration 9663, loss = 2399.31713463\n",
      "Iteration 9664, loss = 2399.21811222\n",
      "Iteration 9665, loss = 2399.11893595\n",
      "Iteration 9666, loss = 2399.01960507\n",
      "Iteration 9667, loss = 2398.92011877\n",
      "Iteration 9668, loss = 2398.82047635\n",
      "Iteration 9669, loss = 2398.72067716\n",
      "Iteration 9670, loss = 2398.62072068\n",
      "Iteration 9671, loss = 2398.52060634\n",
      "Iteration 9672, loss = 2398.42033351\n",
      "Iteration 9673, loss = 2398.31990153\n",
      "Iteration 9674, loss = 2398.21930964\n",
      "Iteration 9675, loss = 2398.11855711\n",
      "Iteration 9676, loss = 2398.01764321\n",
      "Iteration 9677, loss = 2397.91656726\n",
      "Iteration 9678, loss = 2397.81532855\n",
      "Iteration 9679, loss = 2397.71392643\n",
      "Iteration 9680, loss = 2397.61236017\n",
      "Iteration 9681, loss = 2397.51062907\n",
      "Iteration 9682, loss = 2397.40873235\n",
      "Iteration 9683, loss = 2397.30666926\n",
      "Iteration 9684, loss = 2397.20443902\n",
      "Iteration 9685, loss = 2397.10204086\n",
      "Iteration 9686, loss = 2396.99947398\n",
      "Iteration 9687, loss = 2396.89673762\n",
      "Iteration 9688, loss = 2396.79383099\n",
      "Iteration 9689, loss = 2396.69075329\n",
      "Iteration 9690, loss = 2396.58750371\n",
      "Iteration 9691, loss = 2396.48408143\n",
      "Iteration 9692, loss = 2396.38048562\n",
      "Iteration 9693, loss = 2396.27671543\n",
      "Iteration 9694, loss = 2396.17277001\n",
      "Iteration 9695, loss = 2396.06864849\n",
      "Iteration 9696, loss = 2395.96434999\n",
      "Iteration 9697, loss = 2395.85987364\n",
      "Iteration 9698, loss = 2395.75521853\n",
      "Iteration 9699, loss = 2395.65038377\n",
      "Iteration 9700, loss = 2395.54536844\n",
      "Iteration 9701, loss = 2395.44017161\n",
      "Iteration 9702, loss = 2395.33479235\n",
      "Iteration 9703, loss = 2395.22922971\n",
      "Iteration 9704, loss = 2395.12348272\n",
      "Iteration 9705, loss = 2395.01755043\n",
      "Iteration 9706, loss = 2394.91143184\n",
      "Iteration 9707, loss = 2394.80512596\n",
      "Iteration 9708, loss = 2394.69863178\n",
      "Iteration 9709, loss = 2394.59194829\n",
      "Iteration 9710, loss = 2394.48507444\n",
      "Iteration 9711, loss = 2394.37800920\n",
      "Iteration 9712, loss = 2394.27075150\n",
      "Iteration 9713, loss = 2394.16330028\n",
      "Iteration 9714, loss = 2394.05565445\n",
      "Iteration 9715, loss = 2393.94781291\n",
      "Iteration 9716, loss = 2393.83977456\n",
      "Iteration 9717, loss = 2393.73153827\n",
      "Iteration 9718, loss = 2393.62310289\n",
      "Iteration 9719, loss = 2393.51446729\n",
      "Iteration 9720, loss = 2393.40563028\n",
      "Iteration 9721, loss = 2393.29659069\n",
      "Iteration 9722, loss = 2393.18734733\n",
      "Iteration 9723, loss = 2393.07789899\n",
      "Iteration 9724, loss = 2392.96824444\n",
      "Iteration 9725, loss = 2392.85838246\n",
      "Iteration 9726, loss = 2392.74831180\n",
      "Iteration 9727, loss = 2392.63803123\n",
      "Iteration 9728, loss = 2392.52753950\n",
      "Iteration 9729, loss = 2392.41683543\n",
      "Iteration 9730, loss = 2392.30591784\n",
      "Iteration 9731, loss = 2392.19478577\n",
      "Iteration 9732, loss = 2392.08343838\n",
      "Iteration 9733, loss = 2391.97187543\n",
      "Iteration 9734, loss = 2391.86009728\n",
      "Iteration 9735, loss = 2391.74810580\n",
      "Iteration 9736, loss = 2391.63590436\n",
      "Iteration 9737, loss = 2391.52349806\n",
      "Iteration 9738, loss = 2391.41088931\n",
      "Iteration 9739, loss = 2391.29806757\n",
      "Iteration 9740, loss = 2391.18499318\n",
      "Iteration 9741, loss = 2391.07160533\n",
      "Iteration 9742, loss = 2390.95788622\n",
      "Iteration 9743, loss = 2390.84391872\n",
      "Iteration 9744, loss = 2390.72981274\n",
      "Iteration 9745, loss = 2390.61557898\n",
      "Iteration 9746, loss = 2390.50112261\n",
      "Iteration 9747, loss = 2390.38634678\n",
      "Iteration 9748, loss = 2390.27125301\n",
      "Iteration 9749, loss = 2390.15593123\n",
      "Iteration 9750, loss = 2390.04044239\n",
      "Iteration 9751, loss = 2389.92474671\n",
      "Iteration 9752, loss = 2389.80876480\n",
      "Iteration 9753, loss = 2389.69247703\n",
      "Iteration 9754, loss = 2389.57593743\n",
      "Iteration 9755, loss = 2389.45919199\n",
      "Iteration 9756, loss = 2389.34221810\n",
      "Iteration 9757, loss = 2389.22496368\n",
      "Iteration 9758, loss = 2389.10741625\n",
      "Iteration 9759, loss = 2388.98960900\n",
      "Iteration 9760, loss = 2388.87156805\n",
      "Iteration 9761, loss = 2388.75327687\n",
      "Iteration 9762, loss = 2388.63470287\n",
      "Iteration 9763, loss = 2388.51584021\n",
      "Iteration 9764, loss = 2388.39670934\n",
      "Iteration 9765, loss = 2388.27732320\n",
      "Iteration 9766, loss = 2388.15766903\n",
      "Iteration 9767, loss = 2388.03772700\n",
      "Iteration 9768, loss = 2387.91749431\n",
      "Iteration 9769, loss = 2387.79698233\n",
      "Iteration 9770, loss = 2387.67619692\n",
      "Iteration 9771, loss = 2387.55512900\n",
      "Iteration 9772, loss = 2387.43376593\n",
      "Iteration 9773, loss = 2387.31210544\n",
      "Iteration 9774, loss = 2387.19015317\n",
      "Iteration 9775, loss = 2387.06791133\n",
      "Iteration 9776, loss = 2386.94537358\n",
      "Iteration 9777, loss = 2386.82253142\n",
      "Iteration 9778, loss = 2386.69938213\n",
      "Iteration 9779, loss = 2386.57592758\n",
      "Iteration 9780, loss = 2386.45216822\n",
      "Iteration 9781, loss = 2386.32809957\n",
      "Iteration 9782, loss = 2386.20371535\n",
      "Iteration 9783, loss = 2386.07901229\n",
      "Iteration 9784, loss = 2385.95398990\n",
      "Iteration 9785, loss = 2385.82864750\n",
      "Iteration 9786, loss = 2385.70298169\n",
      "Iteration 9787, loss = 2385.57698755\n",
      "Iteration 9788, loss = 2385.45066136\n",
      "Iteration 9789, loss = 2385.32400108\n",
      "Iteration 9790, loss = 2385.19700517\n",
      "Iteration 9791, loss = 2385.06967071\n",
      "Iteration 9792, loss = 2384.94199360\n",
      "Iteration 9793, loss = 2384.81396991\n",
      "Iteration 9794, loss = 2384.68559661\n",
      "Iteration 9795, loss = 2384.55687132\n",
      "Iteration 9796, loss = 2384.42779117\n",
      "Iteration 9797, loss = 2384.29835251\n",
      "Iteration 9798, loss = 2384.16855141\n",
      "Iteration 9799, loss = 2384.03838420\n",
      "Iteration 9800, loss = 2383.90784777\n",
      "Iteration 9801, loss = 2383.77693894\n",
      "Iteration 9802, loss = 2383.64565420\n",
      "Iteration 9803, loss = 2383.51398968\n",
      "Iteration 9804, loss = 2383.38194136\n",
      "Iteration 9805, loss = 2383.24950553\n",
      "Iteration 9806, loss = 2383.11667854\n",
      "Iteration 9807, loss = 2382.98345672\n",
      "Iteration 9808, loss = 2382.84983613\n",
      "Iteration 9809, loss = 2382.71581261\n",
      "Iteration 9810, loss = 2382.58138202\n",
      "Iteration 9811, loss = 2382.44654021\n",
      "Iteration 9812, loss = 2382.31128313\n",
      "Iteration 9813, loss = 2382.17560661\n",
      "Iteration 9814, loss = 2382.03950634\n",
      "Iteration 9815, loss = 2381.90297786\n",
      "Iteration 9816, loss = 2381.76601665\n",
      "Iteration 9817, loss = 2381.62861819\n",
      "Iteration 9818, loss = 2381.49077792\n",
      "Iteration 9819, loss = 2381.35249122\n",
      "Iteration 9820, loss = 2381.21375337\n",
      "Iteration 9821, loss = 2381.07455950\n",
      "Iteration 9822, loss = 2380.93490469\n",
      "Iteration 9823, loss = 2380.79478393\n",
      "Iteration 9824, loss = 2380.65419219\n",
      "Iteration 9825, loss = 2380.51312434\n",
      "Iteration 9826, loss = 2380.37157516\n",
      "Iteration 9827, loss = 2380.22953934\n",
      "Iteration 9828, loss = 2380.08701145\n",
      "Iteration 9829, loss = 2379.94398600\n",
      "Iteration 9830, loss = 2379.80045738\n",
      "Iteration 9831, loss = 2379.65641992\n",
      "Iteration 9832, loss = 2379.51186787\n",
      "Iteration 9833, loss = 2379.36679534\n",
      "Iteration 9834, loss = 2379.22119636\n",
      "Iteration 9835, loss = 2379.07506485\n",
      "Iteration 9836, loss = 2378.92839462\n",
      "Iteration 9837, loss = 2378.78117937\n",
      "Iteration 9838, loss = 2378.63341271\n",
      "Iteration 9839, loss = 2378.48508812\n",
      "Iteration 9840, loss = 2378.33619900\n",
      "Iteration 9841, loss = 2378.18673859\n",
      "Iteration 9842, loss = 2378.03670002\n",
      "Iteration 9843, loss = 2377.88607631\n",
      "Iteration 9844, loss = 2377.73486034\n",
      "Iteration 9845, loss = 2377.58304487\n",
      "Iteration 9846, loss = 2377.43062252\n",
      "Iteration 9847, loss = 2377.27758579\n",
      "Iteration 9848, loss = 2377.12392701\n",
      "Iteration 9849, loss = 2376.96963841\n",
      "Iteration 9850, loss = 2376.81471204\n",
      "Iteration 9851, loss = 2376.65913980\n",
      "Iteration 9852, loss = 2376.50291345\n",
      "Iteration 9853, loss = 2376.34602457\n",
      "Iteration 9854, loss = 2376.18846461\n",
      "Iteration 9855, loss = 2376.03022482\n",
      "Iteration 9856, loss = 2375.87129628\n",
      "Iteration 9857, loss = 2375.71166991\n",
      "Iteration 9858, loss = 2375.55133642\n",
      "Iteration 9859, loss = 2375.39028634\n",
      "Iteration 9860, loss = 2375.22851001\n",
      "Iteration 9861, loss = 2375.06599755\n",
      "Iteration 9862, loss = 2374.90273888\n",
      "Iteration 9863, loss = 2374.73872371\n",
      "Iteration 9864, loss = 2374.57394148\n",
      "Iteration 9865, loss = 2374.40838145\n",
      "Iteration 9866, loss = 2374.24203260\n",
      "Iteration 9867, loss = 2374.07488367\n",
      "Iteration 9868, loss = 2373.90692311\n",
      "Iteration 9869, loss = 2373.73813913\n",
      "Iteration 9870, loss = 2373.56851962\n",
      "Iteration 9871, loss = 2373.39805218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9872, loss = 2373.22672408\n",
      "Iteration 9873, loss = 2373.05452227\n",
      "Iteration 9874, loss = 2372.88143333\n",
      "Iteration 9875, loss = 2372.70744349\n",
      "Iteration 9876, loss = 2372.53253856\n",
      "Iteration 9877, loss = 2372.35670394\n",
      "Iteration 9878, loss = 2372.17992461\n",
      "Iteration 9879, loss = 2372.00218504\n",
      "Iteration 9880, loss = 2371.82346922\n",
      "Iteration 9881, loss = 2371.64376058\n",
      "Iteration 9882, loss = 2371.46304199\n",
      "Iteration 9883, loss = 2371.28129565\n",
      "Iteration 9884, loss = 2371.09850310\n",
      "Iteration 9885, loss = 2370.91464514\n",
      "Iteration 9886, loss = 2370.72970172\n",
      "Iteration 9887, loss = 2370.54365192\n",
      "Iteration 9888, loss = 2370.35647380\n",
      "Iteration 9889, loss = 2370.16814433\n",
      "Iteration 9890, loss = 2369.97863923\n",
      "Iteration 9891, loss = 2369.78793281\n",
      "Iteration 9892, loss = 2369.59599781\n",
      "Iteration 9893, loss = 2369.40280514\n",
      "Iteration 9894, loss = 2369.20832360\n",
      "Iteration 9895, loss = 2369.01251957\n",
      "Iteration 9896, loss = 2368.81535653\n",
      "Iteration 9897, loss = 2368.61679456\n",
      "Iteration 9898, loss = 2368.41678961\n",
      "Iteration 9899, loss = 2368.21529264\n",
      "Iteration 9900, loss = 2368.01224844\n",
      "Iteration 9901, loss = 2367.80759409\n",
      "Iteration 9902, loss = 2367.60125690\n",
      "Iteration 9903, loss = 2367.39315164\n",
      "Iteration 9904, loss = 2367.18317676\n",
      "Iteration 9905, loss = 2366.97120924\n",
      "Iteration 9906, loss = 2366.75709755\n",
      "Iteration 9907, loss = 2366.54065240\n",
      "Iteration 9908, loss = 2366.32163472\n",
      "Iteration 9909, loss = 2366.09974160\n",
      "Iteration 9910, loss = 2365.87459210\n",
      "Iteration 9911, loss = 2365.64571818\n",
      "Iteration 9912, loss = 2365.41256978\n",
      "Iteration 9913, loss = 2365.17454119\n",
      "Iteration 9914, loss = 2364.93102401\n",
      "Iteration 9915, loss = 2364.68146654\n",
      "Iteration 9916, loss = 2364.42542977\n",
      "Iteration 9917, loss = 2364.16260547\n",
      "Iteration 9918, loss = 2363.89282720\n",
      "Iteration 9919, loss = 2363.61604447\n",
      "Iteration 9920, loss = 2363.33232607\n",
      "Iteration 9921, loss = 2363.04182461\n",
      "Iteration 9922, loss = 2362.74479359\n",
      "Iteration 9923, loss = 2362.44154352\n",
      "Iteration 9924, loss = 2362.13247206\n",
      "Iteration 9925, loss = 2361.81799542\n",
      "Iteration 9926, loss = 2361.49858282\n",
      "Iteration 9927, loss = 2361.17464428\n",
      "Iteration 9928, loss = 2360.84665006\n",
      "Iteration 9929, loss = 2360.51513322\n",
      "Iteration 9930, loss = 2360.18078765\n",
      "Iteration 9931, loss = 2359.84422819\n",
      "Iteration 9932, loss = 2359.50588591\n",
      "Iteration 9933, loss = 2359.16609994\n",
      "Iteration 9934, loss = 2358.82527696\n",
      "Iteration 9935, loss = 2358.48396214\n",
      "Iteration 9936, loss = 2358.14266906\n",
      "Iteration 9937, loss = 2357.80173472\n",
      "Iteration 9938, loss = 2357.46138682\n",
      "Iteration 9939, loss = 2357.12190473\n",
      "Iteration 9940, loss = 2356.78364887\n",
      "Iteration 9941, loss = 2356.44692183\n",
      "Iteration 9942, loss = 2356.11188927\n",
      "Iteration 9943, loss = 2355.77866846\n",
      "Iteration 9944, loss = 2355.44743120\n",
      "Iteration 9945, loss = 2355.11837045\n",
      "Iteration 9946, loss = 2354.79160483\n",
      "Iteration 9947, loss = 2354.46717487\n",
      "Iteration 9948, loss = 2354.14512326\n",
      "Iteration 9949, loss = 2353.82553019\n",
      "Iteration 9950, loss = 2353.50845737\n",
      "Iteration 9951, loss = 2353.19390701\n",
      "Iteration 9952, loss = 2352.88185551\n",
      "Iteration 9953, loss = 2352.57229902\n",
      "Iteration 9954, loss = 2352.26524549\n",
      "Iteration 9955, loss = 2351.96067318\n",
      "Iteration 9956, loss = 2351.65852921\n",
      "Iteration 9957, loss = 2351.35876349\n",
      "Iteration 9958, loss = 2351.06134077\n",
      "Iteration 9959, loss = 2350.76622108\n",
      "Iteration 9960, loss = 2350.47334243\n",
      "Iteration 9961, loss = 2350.18263384\n",
      "Iteration 9962, loss = 2349.89403478\n",
      "Iteration 9963, loss = 2349.60748999\n",
      "Iteration 9964, loss = 2349.32293535\n",
      "Iteration 9965, loss = 2349.04029646\n",
      "Iteration 9966, loss = 2348.75950058\n",
      "Iteration 9967, loss = 2348.48048328\n",
      "Iteration 9968, loss = 2348.20317980\n",
      "Iteration 9969, loss = 2347.92751891\n",
      "Iteration 9970, loss = 2347.65342724\n",
      "Iteration 9971, loss = 2347.38083580\n",
      "Iteration 9972, loss = 2347.10968017\n",
      "Iteration 9973, loss = 2346.83989415\n",
      "Iteration 9974, loss = 2346.57140863\n",
      "Iteration 9975, loss = 2346.30415607\n",
      "Iteration 9976, loss = 2346.03807269\n",
      "Iteration 9977, loss = 2345.77309688\n",
      "Iteration 9978, loss = 2345.50916575\n",
      "Iteration 9979, loss = 2345.24621597\n",
      "Iteration 9980, loss = 2344.98418671\n",
      "Iteration 9981, loss = 2344.72301971\n",
      "Iteration 9982, loss = 2344.46265776\n",
      "Iteration 9983, loss = 2344.20304332\n",
      "Iteration 9984, loss = 2343.94411950\n",
      "Iteration 9985, loss = 2343.68583173\n",
      "Iteration 9986, loss = 2343.42812709\n",
      "Iteration 9987, loss = 2343.17095336\n",
      "Iteration 9988, loss = 2342.91425861\n",
      "Iteration 9989, loss = 2342.65799188\n",
      "Iteration 9990, loss = 2342.40210404\n",
      "Iteration 9991, loss = 2342.14654709\n",
      "Iteration 9992, loss = 2341.89127360\n",
      "Iteration 9993, loss = 2341.63623673\n",
      "Iteration 9994, loss = 2341.38139057\n",
      "Iteration 9995, loss = 2341.12669060\n",
      "Iteration 9996, loss = 2340.87209308\n",
      "Iteration 9997, loss = 2340.61755484\n",
      "Iteration 9998, loss = 2340.36303334\n",
      "Iteration 9999, loss = 2340.10848681\n",
      "Iteration 10000, loss = 2339.85387453\n",
      "Iteration 10001, loss = 2339.59915637\n",
      "Iteration 10002, loss = 2339.34429271\n",
      "Iteration 10003, loss = 2339.08924451\n",
      "Iteration 10004, loss = 2338.83397335\n",
      "Iteration 10005, loss = 2338.57844158\n",
      "Iteration 10006, loss = 2338.32261202\n",
      "Iteration 10007, loss = 2338.06644793\n",
      "Iteration 10008, loss = 2337.80991307\n",
      "Iteration 10009, loss = 2337.55297166\n",
      "Iteration 10010, loss = 2337.29558850\n",
      "Iteration 10011, loss = 2337.03772878\n",
      "Iteration 10012, loss = 2336.77935806\n",
      "Iteration 10013, loss = 2336.52044227\n",
      "Iteration 10014, loss = 2336.26094770\n",
      "Iteration 10015, loss = 2336.00084108\n",
      "Iteration 10016, loss = 2335.74008944\n",
      "Iteration 10017, loss = 2335.47866010\n",
      "Iteration 10018, loss = 2335.21652067\n",
      "Iteration 10019, loss = 2334.95363901\n",
      "Iteration 10020, loss = 2334.68998331\n",
      "Iteration 10021, loss = 2334.42552195\n",
      "Iteration 10022, loss = 2334.16022353\n",
      "Iteration 10023, loss = 2333.89405685\n",
      "Iteration 10024, loss = 2333.62699084\n",
      "Iteration 10025, loss = 2333.35899463\n",
      "Iteration 10026, loss = 2333.09003744\n",
      "Iteration 10027, loss = 2332.82008859\n",
      "Iteration 10028, loss = 2332.54911741\n",
      "Iteration 10029, loss = 2332.27709327\n",
      "Iteration 10030, loss = 2332.00398547\n",
      "Iteration 10031, loss = 2331.72976323\n",
      "Iteration 10032, loss = 2331.45439559\n",
      "Iteration 10033, loss = 2331.17785134\n",
      "Iteration 10034, loss = 2330.90009887\n",
      "Iteration 10035, loss = 2330.62110613\n",
      "Iteration 10036, loss = 2330.34084041\n",
      "Iteration 10037, loss = 2330.05926815\n",
      "Iteration 10038, loss = 2329.77635474\n",
      "Iteration 10039, loss = 2329.49206413\n",
      "Iteration 10040, loss = 2329.20635852\n",
      "Iteration 10041, loss = 2328.91919782\n",
      "Iteration 10042, loss = 2328.63053900\n",
      "Iteration 10043, loss = 2328.34033530\n",
      "Iteration 10044, loss = 2328.04853514\n",
      "Iteration 10045, loss = 2327.75508081\n",
      "Iteration 10046, loss = 2327.45990675\n",
      "Iteration 10047, loss = 2327.16293751\n",
      "Iteration 10048, loss = 2326.86408528\n",
      "Iteration 10049, loss = 2326.56324720\n",
      "Iteration 10050, loss = 2326.26030285\n",
      "Iteration 10051, loss = 2325.95511243\n",
      "Iteration 10052, loss = 2325.64751705\n",
      "Iteration 10053, loss = 2325.33734232\n",
      "Iteration 10054, loss = 2325.02440660\n",
      "Iteration 10055, loss = 2324.70853416\n",
      "Iteration 10056, loss = 2324.38957145\n",
      "Iteration 10057, loss = 2324.06740309\n",
      "Iteration 10058, loss = 2323.74196403\n",
      "Iteration 10059, loss = 2323.41324519\n",
      "Iteration 10060, loss = 2323.08129332\n",
      "Iteration 10061, loss = 2322.74620632\n",
      "Iteration 10062, loss = 2322.40812659\n",
      "Iteration 10063, loss = 2322.06723367\n",
      "Iteration 10064, loss = 2321.72373709\n",
      "Iteration 10065, loss = 2321.37786978\n",
      "Iteration 10066, loss = 2321.02988196\n",
      "Iteration 10067, loss = 2320.68003556\n",
      "Iteration 10068, loss = 2320.32859908\n",
      "Iteration 10069, loss = 2319.97584296\n",
      "Iteration 10070, loss = 2319.62203548\n",
      "Iteration 10071, loss = 2319.26743907\n",
      "Iteration 10072, loss = 2318.91230723\n",
      "Iteration 10073, loss = 2318.55688195\n",
      "Iteration 10074, loss = 2318.20139163\n",
      "Iteration 10075, loss = 2317.84604949\n",
      "Iteration 10076, loss = 2317.49105239\n",
      "Iteration 10077, loss = 2317.13658015\n",
      "Iteration 10078, loss = 2316.78279512\n",
      "Iteration 10079, loss = 2316.42984216\n",
      "Iteration 10080, loss = 2316.07784878\n",
      "Iteration 10081, loss = 2315.72692561\n",
      "Iteration 10082, loss = 2315.37716697\n",
      "Iteration 10083, loss = 2315.02865162\n",
      "Iteration 10084, loss = 2314.68144356\n",
      "Iteration 10085, loss = 2314.33559300\n",
      "Iteration 10086, loss = 2313.99113724\n",
      "Iteration 10087, loss = 2313.64810171\n",
      "Iteration 10088, loss = 2313.30650093\n",
      "Iteration 10089, loss = 2312.96633945\n",
      "Iteration 10090, loss = 2312.62761285\n",
      "Iteration 10091, loss = 2312.29030861\n",
      "Iteration 10092, loss = 2311.95440700\n",
      "Iteration 10093, loss = 2311.61988190\n",
      "Iteration 10094, loss = 2311.28670161\n",
      "Iteration 10095, loss = 2310.95482953\n",
      "Iteration 10096, loss = 2310.62422487\n",
      "Iteration 10097, loss = 2310.29484328\n",
      "Iteration 10098, loss = 2309.96663742\n",
      "Iteration 10099, loss = 2309.63955746\n",
      "Iteration 10100, loss = 2309.31355162\n",
      "Iteration 10101, loss = 2308.98856658\n",
      "Iteration 10102, loss = 2308.66454785\n",
      "Iteration 10103, loss = 2308.34144018\n",
      "Iteration 10104, loss = 2308.01918786\n",
      "Iteration 10105, loss = 2307.69773500\n",
      "Iteration 10106, loss = 2307.37702580\n",
      "Iteration 10107, loss = 2307.05700480\n",
      "Iteration 10108, loss = 2306.73761703\n",
      "Iteration 10109, loss = 2306.41880825\n",
      "Iteration 10110, loss = 2306.10052509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10111, loss = 2305.78271517\n",
      "Iteration 10112, loss = 2305.46532726\n",
      "Iteration 10113, loss = 2305.14831134\n",
      "Iteration 10114, loss = 2304.83161876\n",
      "Iteration 10115, loss = 2304.51520225\n",
      "Iteration 10116, loss = 2304.19901603\n",
      "Iteration 10117, loss = 2303.88301587\n",
      "Iteration 10118, loss = 2303.56715913\n",
      "Iteration 10119, loss = 2303.25140478\n",
      "Iteration 10120, loss = 2302.93571348\n",
      "Iteration 10121, loss = 2302.62004755\n",
      "Iteration 10122, loss = 2302.30437106\n",
      "Iteration 10123, loss = 2301.98864976\n",
      "Iteration 10124, loss = 2301.67285117\n",
      "Iteration 10125, loss = 2301.35694452\n",
      "Iteration 10126, loss = 2301.04090079\n",
      "Iteration 10127, loss = 2300.72469268\n",
      "Iteration 10128, loss = 2300.40829462\n",
      "Iteration 10129, loss = 2300.09168274\n",
      "Iteration 10130, loss = 2299.77483484\n",
      "Iteration 10131, loss = 2299.45773040\n",
      "Iteration 10132, loss = 2299.14035052\n",
      "Iteration 10133, loss = 2298.82267791\n",
      "Iteration 10134, loss = 2298.50469682\n",
      "Iteration 10135, loss = 2298.18639306\n",
      "Iteration 10136, loss = 2297.86775389\n",
      "Iteration 10137, loss = 2297.54876799\n",
      "Iteration 10138, loss = 2297.22942542\n",
      "Iteration 10139, loss = 2296.90971755\n",
      "Iteration 10140, loss = 2296.58963699\n",
      "Iteration 10141, loss = 2296.26917751\n",
      "Iteration 10142, loss = 2295.94833399\n",
      "Iteration 10143, loss = 2295.62710233\n",
      "Iteration 10144, loss = 2295.30547936\n",
      "Iteration 10145, loss = 2294.98346274\n",
      "Iteration 10146, loss = 2294.66105091\n",
      "Iteration 10147, loss = 2294.33824295\n",
      "Iteration 10148, loss = 2294.01503848\n",
      "Iteration 10149, loss = 2293.69143761\n",
      "Iteration 10150, loss = 2293.36744077\n",
      "Iteration 10151, loss = 2293.04304865\n",
      "Iteration 10152, loss = 2292.71826207\n",
      "Iteration 10153, loss = 2292.39308188\n",
      "Iteration 10154, loss = 2292.06750886\n",
      "Iteration 10155, loss = 2291.74154362\n",
      "Iteration 10156, loss = 2291.41518647\n",
      "Iteration 10157, loss = 2291.08843737\n",
      "Iteration 10158, loss = 2290.76129581\n",
      "Iteration 10159, loss = 2290.43376072\n",
      "Iteration 10160, loss = 2290.10583040\n",
      "Iteration 10161, loss = 2289.77750246\n",
      "Iteration 10162, loss = 2289.44877372\n",
      "Iteration 10163, loss = 2289.11964020\n",
      "Iteration 10164, loss = 2288.79009704\n",
      "Iteration 10165, loss = 2288.46013847\n",
      "Iteration 10166, loss = 2288.12975778\n",
      "Iteration 10167, loss = 2287.79894730\n",
      "Iteration 10168, loss = 2287.46769840\n",
      "Iteration 10169, loss = 2287.13600144\n",
      "Iteration 10170, loss = 2286.80384584\n",
      "Iteration 10171, loss = 2286.47122003\n",
      "Iteration 10172, loss = 2286.13811147\n",
      "Iteration 10173, loss = 2285.80450670\n",
      "Iteration 10174, loss = 2285.47039133\n",
      "Iteration 10175, loss = 2285.13575011\n",
      "Iteration 10176, loss = 2284.80056688\n",
      "Iteration 10177, loss = 2284.46482467\n",
      "Iteration 10178, loss = 2284.12850573\n",
      "Iteration 10179, loss = 2283.79159150\n",
      "Iteration 10180, loss = 2283.45406273\n",
      "Iteration 10181, loss = 2283.11589945\n",
      "Iteration 10182, loss = 2282.77708103\n",
      "Iteration 10183, loss = 2282.43758624\n",
      "Iteration 10184, loss = 2282.09739324\n",
      "Iteration 10185, loss = 2281.75647964\n",
      "Iteration 10186, loss = 2281.41482254\n",
      "Iteration 10187, loss = 2281.07239855\n",
      "Iteration 10188, loss = 2280.72918384\n",
      "Iteration 10189, loss = 2280.38515415\n",
      "Iteration 10190, loss = 2280.04028485\n",
      "Iteration 10191, loss = 2279.69455094\n",
      "Iteration 10192, loss = 2279.34792711\n",
      "Iteration 10193, loss = 2279.00038775\n",
      "Iteration 10194, loss = 2278.65190699\n",
      "Iteration 10195, loss = 2278.30245871\n",
      "Iteration 10196, loss = 2277.95201658\n",
      "Iteration 10197, loss = 2277.60055411\n",
      "Iteration 10198, loss = 2277.24804461\n",
      "Iteration 10199, loss = 2276.89446129\n",
      "Iteration 10200, loss = 2276.53977724\n",
      "Iteration 10201, loss = 2276.18396546\n",
      "Iteration 10202, loss = 2275.82699892\n",
      "Iteration 10203, loss = 2275.46885051\n",
      "Iteration 10204, loss = 2275.10949316\n",
      "Iteration 10205, loss = 2274.74889979\n",
      "Iteration 10206, loss = 2274.38704335\n",
      "Iteration 10207, loss = 2274.02389688\n",
      "Iteration 10208, loss = 2273.65943350\n",
      "Iteration 10209, loss = 2273.29362644\n",
      "Iteration 10210, loss = 2272.92644910\n",
      "Iteration 10211, loss = 2272.55787501\n",
      "Iteration 10212, loss = 2272.18787792\n",
      "Iteration 10213, loss = 2271.81643181\n",
      "Iteration 10214, loss = 2271.44351090\n",
      "Iteration 10215, loss = 2271.06908968\n",
      "Iteration 10216, loss = 2270.69314299\n",
      "Iteration 10217, loss = 2270.31564595\n",
      "Iteration 10218, loss = 2269.93657413\n",
      "Iteration 10219, loss = 2269.55590343\n",
      "Iteration 10220, loss = 2269.17361029\n",
      "Iteration 10221, loss = 2268.78967151\n",
      "Iteration 10222, loss = 2268.40406460\n",
      "Iteration 10223, loss = 2268.01676744\n",
      "Iteration 10224, loss = 2267.62775889\n",
      "Iteration 10225, loss = 2267.23701823\n",
      "Iteration 10226, loss = 2266.84452611\n",
      "Iteration 10227, loss = 2266.45026376\n",
      "Iteration 10228, loss = 2266.05421428\n",
      "Iteration 10229, loss = 2265.65636110\n",
      "Iteration 10230, loss = 2265.25668802\n",
      "Iteration 10231, loss = 2264.85517575\n",
      "Iteration 10232, loss = 2264.45179784\n",
      "Iteration 10233, loss = 2264.04652489\n",
      "Iteration 10234, loss = 2263.63933265\n",
      "Iteration 10235, loss = 2263.23022134\n",
      "Iteration 10236, loss = 2262.81920977\n",
      "Iteration 10237, loss = 2262.40631037\n",
      "Iteration 10238, loss = 2261.99150869\n",
      "Iteration 10239, loss = 2261.57476929\n",
      "Iteration 10240, loss = 2261.15605997\n",
      "Iteration 10241, loss = 2260.73537681\n",
      "Iteration 10242, loss = 2260.31273932\n",
      "Iteration 10243, loss = 2259.88816547\n",
      "Iteration 10244, loss = 2259.46165130\n",
      "Iteration 10245, loss = 2259.03317947\n",
      "Iteration 10246, loss = 2258.60274009\n",
      "Iteration 10247, loss = 2258.17033961\n",
      "Iteration 10248, loss = 2257.73599883\n",
      "Iteration 10249, loss = 2257.29973509\n",
      "Iteration 10250, loss = 2256.86155348\n",
      "Iteration 10251, loss = 2256.42145426\n",
      "Iteration 10252, loss = 2255.97944603\n",
      "Iteration 10253, loss = 2255.53555280\n",
      "Iteration 10254, loss = 2255.08980168\n",
      "Iteration 10255, loss = 2254.64221427\n",
      "Iteration 10256, loss = 2254.19280809\n",
      "Iteration 10257, loss = 2253.74160422\n",
      "Iteration 10258, loss = 2253.28863378\n",
      "Iteration 10259, loss = 2252.83393299\n",
      "Iteration 10260, loss = 2252.37753957\n",
      "Iteration 10261, loss = 2251.91948964\n",
      "Iteration 10262, loss = 2251.45982026\n",
      "Iteration 10263, loss = 2250.99857541\n",
      "Iteration 10264, loss = 2250.53580527\n",
      "Iteration 10265, loss = 2250.07156444\n",
      "Iteration 10266, loss = 2249.60590798\n",
      "Iteration 10267, loss = 2249.13889258\n",
      "Iteration 10268, loss = 2248.67058064\n",
      "Iteration 10269, loss = 2248.20104016\n",
      "Iteration 10270, loss = 2247.73034461\n",
      "Iteration 10271, loss = 2247.25857008\n",
      "Iteration 10272, loss = 2246.78579574\n",
      "Iteration 10273, loss = 2246.31210539\n",
      "Iteration 10274, loss = 2245.83758758\n",
      "Iteration 10275, loss = 2245.36233663\n",
      "Iteration 10276, loss = 2244.88645054\n",
      "Iteration 10277, loss = 2244.41003057\n",
      "Iteration 10278, loss = 2243.93318146\n",
      "Iteration 10279, loss = 2243.45601155\n",
      "Iteration 10280, loss = 2242.97863350\n",
      "Iteration 10281, loss = 2242.50116239\n",
      "Iteration 10282, loss = 2242.02371499\n",
      "Iteration 10283, loss = 2241.54640910\n",
      "Iteration 10284, loss = 2241.06936282\n",
      "Iteration 10285, loss = 2240.59269446\n",
      "Iteration 10286, loss = 2240.11652056\n",
      "Iteration 10287, loss = 2239.64095489\n",
      "Iteration 10288, loss = 2239.16610661\n",
      "Iteration 10289, loss = 2238.69207889\n",
      "Iteration 10290, loss = 2238.21896783\n",
      "Iteration 10291, loss = 2237.74686046\n",
      "Iteration 10292, loss = 2237.27583324\n",
      "Iteration 10293, loss = 2236.80594994\n",
      "Iteration 10294, loss = 2236.33726011\n",
      "Iteration 10295, loss = 2235.86979796\n",
      "Iteration 10296, loss = 2235.40358093\n",
      "Iteration 10297, loss = 2234.93860906\n",
      "Iteration 10298, loss = 2234.47486409\n",
      "Iteration 10299, loss = 2234.01230955\n",
      "Iteration 10300, loss = 2233.55089137\n",
      "Iteration 10301, loss = 2233.09053883\n",
      "Iteration 10302, loss = 2232.63116654\n",
      "Iteration 10303, loss = 2232.17267642\n",
      "Iteration 10304, loss = 2231.71496063\n",
      "Iteration 10305, loss = 2231.25790470\n",
      "Iteration 10306, loss = 2230.80139104\n",
      "Iteration 10307, loss = 2230.34530273\n",
      "Iteration 10308, loss = 2229.88952693\n",
      "Iteration 10309, loss = 2229.43395829\n",
      "Iteration 10310, loss = 2228.97850173\n",
      "Iteration 10311, loss = 2228.52307486\n",
      "Iteration 10312, loss = 2228.06760965\n",
      "Iteration 10313, loss = 2227.61205339\n",
      "Iteration 10314, loss = 2227.15636895\n",
      "Iteration 10315, loss = 2226.70053426\n",
      "Iteration 10316, loss = 2226.24454136\n",
      "Iteration 10317, loss = 2225.78839493\n",
      "Iteration 10318, loss = 2225.33211046\n",
      "Iteration 10319, loss = 2224.87571234\n",
      "Iteration 10320, loss = 2224.41923176\n",
      "Iteration 10321, loss = 2223.96270481\n",
      "Iteration 10322, loss = 2223.50617063\n",
      "Iteration 10323, loss = 2223.04966983\n",
      "Iteration 10324, loss = 2222.59324327\n",
      "Iteration 10325, loss = 2222.13693096\n",
      "Iteration 10326, loss = 2221.68077134\n",
      "Iteration 10327, loss = 2221.22480083\n",
      "Iteration 10328, loss = 2220.76905356\n",
      "Iteration 10329, loss = 2220.31356139\n",
      "Iteration 10330, loss = 2219.85835398\n",
      "Iteration 10331, loss = 2219.40345904\n",
      "Iteration 10332, loss = 2218.94890263\n",
      "Iteration 10333, loss = 2218.49470950\n",
      "Iteration 10334, loss = 2218.04090349\n",
      "Iteration 10335, loss = 2217.58750781\n",
      "Iteration 10336, loss = 2217.13454539\n",
      "Iteration 10337, loss = 2216.68203908\n",
      "Iteration 10338, loss = 2216.23001189\n",
      "Iteration 10339, loss = 2215.77848709\n",
      "Iteration 10340, loss = 2215.32748826\n",
      "Iteration 10341, loss = 2214.87703927\n",
      "Iteration 10342, loss = 2214.42716420\n",
      "Iteration 10343, loss = 2213.97788721\n",
      "Iteration 10344, loss = 2213.52923232\n",
      "Iteration 10345, loss = 2213.08122317\n",
      "Iteration 10346, loss = 2212.63388274\n",
      "Iteration 10347, loss = 2212.18723305\n",
      "Iteration 10348, loss = 2211.74129476\n",
      "Iteration 10349, loss = 2211.29608690\n",
      "Iteration 10350, loss = 2210.85162643\n",
      "Iteration 10351, loss = 2210.40792791\n",
      "Iteration 10352, loss = 2209.96500317\n",
      "Iteration 10353, loss = 2209.52286091\n",
      "Iteration 10354, loss = 2209.08150647\n",
      "Iteration 10355, loss = 2208.64094147\n",
      "Iteration 10356, loss = 2208.20116362\n",
      "Iteration 10357, loss = 2207.76216645\n",
      "Iteration 10358, loss = 2207.32393925\n",
      "Iteration 10359, loss = 2206.88646685\n",
      "Iteration 10360, loss = 2206.44972965\n",
      "Iteration 10361, loss = 2206.01370359\n",
      "Iteration 10362, loss = 2205.57836023\n",
      "Iteration 10363, loss = 2205.14366687\n",
      "Iteration 10364, loss = 2204.70958673\n",
      "Iteration 10365, loss = 2204.27607920\n",
      "Iteration 10366, loss = 2203.84310015\n",
      "Iteration 10367, loss = 2203.41060226\n",
      "Iteration 10368, loss = 2202.97853546\n",
      "Iteration 10369, loss = 2202.54684729\n",
      "Iteration 10370, loss = 2202.11548343\n",
      "Iteration 10371, loss = 2201.68438819\n",
      "Iteration 10372, loss = 2201.25350496\n",
      "Iteration 10373, loss = 2200.82277676\n",
      "Iteration 10374, loss = 2200.39214671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10375, loss = 2199.96155854\n",
      "Iteration 10376, loss = 2199.53095700\n",
      "Iteration 10377, loss = 2199.10028833\n",
      "Iteration 10378, loss = 2198.66950059\n",
      "Iteration 10379, loss = 2198.23854403\n",
      "Iteration 10380, loss = 2197.80737134\n",
      "Iteration 10381, loss = 2197.37593788\n",
      "Iteration 10382, loss = 2196.94420187\n",
      "Iteration 10383, loss = 2196.51212445\n",
      "Iteration 10384, loss = 2196.07966980\n",
      "Iteration 10385, loss = 2195.64680510\n",
      "Iteration 10386, loss = 2195.21350050\n",
      "Iteration 10387, loss = 2194.77972906\n",
      "Iteration 10388, loss = 2194.34546662\n",
      "Iteration 10389, loss = 2193.91069166\n",
      "Iteration 10390, loss = 2193.47538512\n",
      "Iteration 10391, loss = 2193.03953029\n",
      "Iteration 10392, loss = 2192.60311253\n",
      "Iteration 10393, loss = 2192.16611916\n",
      "Iteration 10394, loss = 2191.72853924\n",
      "Iteration 10395, loss = 2191.29036339\n",
      "Iteration 10396, loss = 2190.85158366\n",
      "Iteration 10397, loss = 2190.41219334\n",
      "Iteration 10398, loss = 2189.97218684\n",
      "Iteration 10399, loss = 2189.53155959\n",
      "Iteration 10400, loss = 2189.09030791\n",
      "Iteration 10401, loss = 2188.64842898\n",
      "Iteration 10402, loss = 2188.20592073\n",
      "Iteration 10403, loss = 2187.76278181\n",
      "Iteration 10404, loss = 2187.31901159\n",
      "Iteration 10405, loss = 2186.87461013\n",
      "Iteration 10406, loss = 2186.42957815\n",
      "Iteration 10407, loss = 2185.98391713\n",
      "Iteration 10408, loss = 2185.53762922\n",
      "Iteration 10409, loss = 2185.09071736\n",
      "Iteration 10410, loss = 2184.64318527\n",
      "Iteration 10411, loss = 2184.19503750\n",
      "Iteration 10412, loss = 2183.74627948\n",
      "Iteration 10413, loss = 2183.29691754\n",
      "Iteration 10414, loss = 2182.84695899\n",
      "Iteration 10415, loss = 2182.39641211\n",
      "Iteration 10416, loss = 2181.94528624\n",
      "Iteration 10417, loss = 2181.49359176\n",
      "Iteration 10418, loss = 2181.04134019\n",
      "Iteration 10419, loss = 2180.58854412\n",
      "Iteration 10420, loss = 2180.13521732\n",
      "Iteration 10421, loss = 2179.68137469\n",
      "Iteration 10422, loss = 2179.22703230\n",
      "Iteration 10423, loss = 2178.77220734\n",
      "Iteration 10424, loss = 2178.31691818\n",
      "Iteration 10425, loss = 2177.86118431\n",
      "Iteration 10426, loss = 2177.40502629\n",
      "Iteration 10427, loss = 2176.94846581\n",
      "Iteration 10428, loss = 2176.49152555\n",
      "Iteration 10429, loss = 2176.03422920\n",
      "Iteration 10430, loss = 2175.57660140\n",
      "Iteration 10431, loss = 2175.11866766\n",
      "Iteration 10432, loss = 2174.66045433\n",
      "Iteration 10433, loss = 2174.20198852\n",
      "Iteration 10434, loss = 2173.74329801\n",
      "Iteration 10435, loss = 2173.28441123\n",
      "Iteration 10436, loss = 2172.82535710\n",
      "Iteration 10437, loss = 2172.36616503\n",
      "Iteration 10438, loss = 2171.90686480\n",
      "Iteration 10439, loss = 2171.44748646\n",
      "Iteration 10440, loss = 2170.98806028\n",
      "Iteration 10441, loss = 2170.52861664\n",
      "Iteration 10442, loss = 2170.06918594\n",
      "Iteration 10443, loss = 2169.60979856\n",
      "Iteration 10444, loss = 2169.15048472\n",
      "Iteration 10445, loss = 2168.69127442\n",
      "Iteration 10446, loss = 2168.23219740\n",
      "Iteration 10447, loss = 2167.77328300\n",
      "Iteration 10448, loss = 2167.31456015\n",
      "Iteration 10449, loss = 2166.85605727\n",
      "Iteration 10450, loss = 2166.39780221\n",
      "Iteration 10451, loss = 2165.93982222\n",
      "Iteration 10452, loss = 2165.48214386\n",
      "Iteration 10453, loss = 2165.02479297\n",
      "Iteration 10454, loss = 2164.56779466\n",
      "Iteration 10455, loss = 2164.11117322\n",
      "Iteration 10456, loss = 2163.65495212\n",
      "Iteration 10457, loss = 2163.19915400\n",
      "Iteration 10458, loss = 2162.74380059\n",
      "Iteration 10459, loss = 2162.28891277\n",
      "Iteration 10460, loss = 2161.83451050\n",
      "Iteration 10461, loss = 2161.38061287\n",
      "Iteration 10462, loss = 2160.92723803\n",
      "Iteration 10463, loss = 2160.47440325\n",
      "Iteration 10464, loss = 2160.02212489\n",
      "Iteration 10465, loss = 2159.57041842\n",
      "Iteration 10466, loss = 2159.11929846\n",
      "Iteration 10467, loss = 2158.66877874\n",
      "Iteration 10468, loss = 2158.21887216\n",
      "Iteration 10469, loss = 2157.76959079\n",
      "Iteration 10470, loss = 2157.32094590\n",
      "Iteration 10471, loss = 2156.87294798\n",
      "Iteration 10472, loss = 2156.42560675\n",
      "Iteration 10473, loss = 2155.97893121\n",
      "Iteration 10474, loss = 2155.53292964\n",
      "Iteration 10475, loss = 2155.08760966\n",
      "Iteration 10476, loss = 2154.64297821\n",
      "Iteration 10477, loss = 2154.19904162\n",
      "Iteration 10478, loss = 2153.75580560\n",
      "Iteration 10479, loss = 2153.31327530\n",
      "Iteration 10480, loss = 2152.87145531\n",
      "Iteration 10481, loss = 2152.43034971\n",
      "Iteration 10482, loss = 2151.98996206\n",
      "Iteration 10483, loss = 2151.55029548\n",
      "Iteration 10484, loss = 2151.11135261\n",
      "Iteration 10485, loss = 2150.67313569\n",
      "Iteration 10486, loss = 2150.23564654\n",
      "Iteration 10487, loss = 2149.79888661\n",
      "Iteration 10488, loss = 2149.36285700\n",
      "Iteration 10489, loss = 2148.92755845\n",
      "Iteration 10490, loss = 2148.49299141\n",
      "Iteration 10491, loss = 2148.05915602\n",
      "Iteration 10492, loss = 2147.62605215\n",
      "Iteration 10493, loss = 2147.19367939\n",
      "Iteration 10494, loss = 2146.76203711\n",
      "Iteration 10495, loss = 2146.33112445\n",
      "Iteration 10496, loss = 2145.90094031\n",
      "Iteration 10497, loss = 2145.47148343\n",
      "Iteration 10498, loss = 2145.04275234\n",
      "Iteration 10499, loss = 2144.61474541\n",
      "Iteration 10500, loss = 2144.18746085\n",
      "Iteration 10501, loss = 2143.76089672\n",
      "Iteration 10502, loss = 2143.33505096\n",
      "Iteration 10503, loss = 2142.90992137\n",
      "Iteration 10504, loss = 2142.48550565\n",
      "Iteration 10505, loss = 2142.06180137\n",
      "Iteration 10506, loss = 2141.63880603\n",
      "Iteration 10507, loss = 2141.21651703\n",
      "Iteration 10508, loss = 2140.79493170\n",
      "Iteration 10509, loss = 2140.37404729\n",
      "Iteration 10510, loss = 2139.95386098\n",
      "Iteration 10511, loss = 2139.53436990\n",
      "Iteration 10512, loss = 2139.11557113\n",
      "Iteration 10513, loss = 2138.69746169\n",
      "Iteration 10514, loss = 2138.28003858\n",
      "Iteration 10515, loss = 2137.86329873\n",
      "Iteration 10516, loss = 2137.44723907\n",
      "Iteration 10517, loss = 2137.03185650\n",
      "Iteration 10518, loss = 2136.61714786\n",
      "Iteration 10519, loss = 2136.20311003\n",
      "Iteration 10520, loss = 2135.78973981\n",
      "Iteration 10521, loss = 2135.37703404\n",
      "Iteration 10522, loss = 2134.96498953\n",
      "Iteration 10523, loss = 2134.55360307\n",
      "Iteration 10524, loss = 2134.14287146\n",
      "Iteration 10525, loss = 2133.73279150\n",
      "Iteration 10526, loss = 2133.32335999\n",
      "Iteration 10527, loss = 2132.91457372\n",
      "Iteration 10528, loss = 2132.50642951\n",
      "Iteration 10529, loss = 2132.09892415\n",
      "Iteration 10530, loss = 2131.69205447\n",
      "Iteration 10531, loss = 2131.28581730\n",
      "Iteration 10532, loss = 2130.88020947\n",
      "Iteration 10533, loss = 2130.47522784\n",
      "Iteration 10534, loss = 2130.07086927\n",
      "Iteration 10535, loss = 2129.66713064\n",
      "Iteration 10536, loss = 2129.26400884\n",
      "Iteration 10537, loss = 2128.86150079\n",
      "Iteration 10538, loss = 2128.45960341\n",
      "Iteration 10539, loss = 2128.05831364\n",
      "Iteration 10540, loss = 2127.65762847\n",
      "Iteration 10541, loss = 2127.25754485\n",
      "Iteration 10542, loss = 2126.85805981\n",
      "Iteration 10543, loss = 2126.45917036\n",
      "Iteration 10544, loss = 2126.06087356\n",
      "Iteration 10545, loss = 2125.66316645\n",
      "Iteration 10546, loss = 2125.26604613\n",
      "Iteration 10547, loss = 2124.86950972\n",
      "Iteration 10548, loss = 2124.47355433\n",
      "Iteration 10549, loss = 2124.07817712\n",
      "Iteration 10550, loss = 2123.68337527\n",
      "Iteration 10551, loss = 2123.28914598\n",
      "Iteration 10552, loss = 2122.89548645\n",
      "Iteration 10553, loss = 2122.50239394\n",
      "Iteration 10554, loss = 2122.10986570\n",
      "Iteration 10555, loss = 2121.71789904\n",
      "Iteration 10556, loss = 2121.32649125\n",
      "Iteration 10557, loss = 2120.93563967\n",
      "Iteration 10558, loss = 2120.54534165\n",
      "Iteration 10559, loss = 2120.15559458\n",
      "Iteration 10560, loss = 2119.76639584\n",
      "Iteration 10561, loss = 2119.37774288\n",
      "Iteration 10562, loss = 2118.98963313\n",
      "Iteration 10563, loss = 2118.60206405\n",
      "Iteration 10564, loss = 2118.21503315\n",
      "Iteration 10565, loss = 2117.82853793\n",
      "Iteration 10566, loss = 2117.44257592\n",
      "Iteration 10567, loss = 2117.05714469\n",
      "Iteration 10568, loss = 2116.67224180\n",
      "Iteration 10569, loss = 2116.28786486\n",
      "Iteration 10570, loss = 2115.90401149\n",
      "Iteration 10571, loss = 2115.52067932\n",
      "Iteration 10572, loss = 2115.13786603\n",
      "Iteration 10573, loss = 2114.75556930\n",
      "Iteration 10574, loss = 2114.37378682\n",
      "Iteration 10575, loss = 2113.99251632\n",
      "Iteration 10576, loss = 2113.61175555\n",
      "Iteration 10577, loss = 2113.23150227\n",
      "Iteration 10578, loss = 2112.85175427\n",
      "Iteration 10579, loss = 2112.47250935\n",
      "Iteration 10580, loss = 2112.09376533\n",
      "Iteration 10581, loss = 2111.71552005\n",
      "Iteration 10582, loss = 2111.33777139\n",
      "Iteration 10583, loss = 2110.96051722\n",
      "Iteration 10584, loss = 2110.58375543\n",
      "Iteration 10585, loss = 2110.20748396\n",
      "Iteration 10586, loss = 2109.83170072\n",
      "Iteration 10587, loss = 2109.45640369\n",
      "Iteration 10588, loss = 2109.08159083\n",
      "Iteration 10589, loss = 2108.70726012\n",
      "Iteration 10590, loss = 2108.33340959\n",
      "Iteration 10591, loss = 2107.96003726\n",
      "Iteration 10592, loss = 2107.58714116\n",
      "Iteration 10593, loss = 2107.21471935\n",
      "Iteration 10594, loss = 2106.84276992\n",
      "Iteration 10595, loss = 2106.47129095\n",
      "Iteration 10596, loss = 2106.10028056\n",
      "Iteration 10597, loss = 2105.72973687\n",
      "Iteration 10598, loss = 2105.35965801\n",
      "Iteration 10599, loss = 2104.99004216\n",
      "Iteration 10600, loss = 2104.62088747\n",
      "Iteration 10601, loss = 2104.25219214\n",
      "Iteration 10602, loss = 2103.88395437\n",
      "Iteration 10603, loss = 2103.51617238\n",
      "Iteration 10604, loss = 2103.14884441\n",
      "Iteration 10605, loss = 2102.78196870\n",
      "Iteration 10606, loss = 2102.41554351\n",
      "Iteration 10607, loss = 2102.04956712\n",
      "Iteration 10608, loss = 2101.68403782\n",
      "Iteration 10609, loss = 2101.31895392\n",
      "Iteration 10610, loss = 2100.95431374\n",
      "Iteration 10611, loss = 2100.59011561\n",
      "Iteration 10612, loss = 2100.22635787\n",
      "Iteration 10613, loss = 2099.86303890\n",
      "Iteration 10614, loss = 2099.50015705\n",
      "Iteration 10615, loss = 2099.13771071\n",
      "Iteration 10616, loss = 2098.77569830\n",
      "Iteration 10617, loss = 2098.41411821\n",
      "Iteration 10618, loss = 2098.05296887\n",
      "Iteration 10619, loss = 2097.69224873\n",
      "Iteration 10620, loss = 2097.33195622\n",
      "Iteration 10621, loss = 2096.97208981\n",
      "Iteration 10622, loss = 2096.61264798\n",
      "Iteration 10623, loss = 2096.25362921\n",
      "Iteration 10624, loss = 2095.89503200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10625, loss = 2095.53685486\n",
      "Iteration 10626, loss = 2095.17909630\n",
      "Iteration 10627, loss = 2094.82175486\n",
      "Iteration 10628, loss = 2094.46482909\n",
      "Iteration 10629, loss = 2094.10831754\n",
      "Iteration 10630, loss = 2093.75221877\n",
      "Iteration 10631, loss = 2093.39653136\n",
      "Iteration 10632, loss = 2093.04125389\n",
      "Iteration 10633, loss = 2092.68638497\n",
      "Iteration 10634, loss = 2092.33192320\n",
      "Iteration 10635, loss = 2091.97786721\n",
      "Iteration 10636, loss = 2091.62421561\n",
      "Iteration 10637, loss = 2091.27096705\n",
      "Iteration 10638, loss = 2090.91812018\n",
      "Iteration 10639, loss = 2090.56567365\n",
      "Iteration 10640, loss = 2090.21362614\n",
      "Iteration 10641, loss = 2089.86197632\n",
      "Iteration 10642, loss = 2089.51072288\n",
      "Iteration 10643, loss = 2089.15986452\n",
      "Iteration 10644, loss = 2088.80939995\n",
      "Iteration 10645, loss = 2088.45932787\n",
      "Iteration 10646, loss = 2088.10964702\n",
      "Iteration 10647, loss = 2087.76035613\n",
      "Iteration 10648, loss = 2087.41145393\n",
      "Iteration 10649, loss = 2087.06293920\n",
      "Iteration 10650, loss = 2086.71481067\n",
      "Iteration 10651, loss = 2086.36706713\n",
      "Iteration 10652, loss = 2086.01970736\n",
      "Iteration 10653, loss = 2085.67273013\n",
      "Iteration 10654, loss = 2085.32613424\n",
      "Iteration 10655, loss = 2084.97991849\n",
      "Iteration 10656, loss = 2084.63408170\n",
      "Iteration 10657, loss = 2084.28862269\n",
      "Iteration 10658, loss = 2083.94354028\n",
      "Iteration 10659, loss = 2083.59883330\n",
      "Iteration 10660, loss = 2083.25450061\n",
      "Iteration 10661, loss = 2082.91054104\n",
      "Iteration 10662, loss = 2082.56695347\n",
      "Iteration 10663, loss = 2082.22373675\n",
      "Iteration 10664, loss = 2081.88088975\n",
      "Iteration 10665, loss = 2081.53841137\n",
      "Iteration 10666, loss = 2081.19630049\n",
      "Iteration 10667, loss = 2080.85455599\n",
      "Iteration 10668, loss = 2080.51317679\n",
      "Iteration 10669, loss = 2080.17216180\n",
      "Iteration 10670, loss = 2079.83150993\n",
      "Iteration 10671, loss = 2079.49122011\n",
      "Iteration 10672, loss = 2079.15129126\n",
      "Iteration 10673, loss = 2078.81172232\n",
      "Iteration 10674, loss = 2078.47251225\n",
      "Iteration 10675, loss = 2078.13365998\n",
      "Iteration 10676, loss = 2077.79516448\n",
      "Iteration 10677, loss = 2077.45702471\n",
      "Iteration 10678, loss = 2077.11923965\n",
      "Iteration 10679, loss = 2076.78180826\n",
      "Iteration 10680, loss = 2076.44472953\n",
      "Iteration 10681, loss = 2076.10800246\n",
      "Iteration 10682, loss = 2075.77162603\n",
      "Iteration 10683, loss = 2075.43559925\n",
      "Iteration 10684, loss = 2075.09992113\n",
      "Iteration 10685, loss = 2074.76459069\n",
      "Iteration 10686, loss = 2074.42960693\n",
      "Iteration 10687, loss = 2074.09496890\n",
      "Iteration 10688, loss = 2073.76067561\n",
      "Iteration 10689, loss = 2073.42672611\n",
      "Iteration 10690, loss = 2073.09311945\n",
      "Iteration 10691, loss = 2072.75985466\n",
      "Iteration 10692, loss = 2072.42693082\n",
      "Iteration 10693, loss = 2072.09434697\n",
      "Iteration 10694, loss = 2071.76210218\n",
      "Iteration 10695, loss = 2071.43019552\n",
      "Iteration 10696, loss = 2071.09862608\n",
      "Iteration 10697, loss = 2070.76739293\n",
      "Iteration 10698, loss = 2070.43649516\n",
      "Iteration 10699, loss = 2070.10593186\n",
      "Iteration 10700, loss = 2069.77570213\n",
      "Iteration 10701, loss = 2069.44580508\n",
      "Iteration 10702, loss = 2069.11623982\n",
      "Iteration 10703, loss = 2068.78700544\n",
      "Iteration 10704, loss = 2068.45810109\n",
      "Iteration 10705, loss = 2068.12952587\n",
      "Iteration 10706, loss = 2067.80127892\n",
      "Iteration 10707, loss = 2067.47335937\n",
      "Iteration 10708, loss = 2067.14576635\n",
      "Iteration 10709, loss = 2066.81849902\n",
      "Iteration 10710, loss = 2066.49155652\n",
      "Iteration 10711, loss = 2066.16493799\n",
      "Iteration 10712, loss = 2065.83864261\n",
      "Iteration 10713, loss = 2065.51266952\n",
      "Iteration 10714, loss = 2065.18701790\n",
      "Iteration 10715, loss = 2064.86168691\n",
      "Iteration 10716, loss = 2064.53667574\n",
      "Iteration 10717, loss = 2064.21198356\n",
      "Iteration 10718, loss = 2063.88760955\n",
      "Iteration 10719, loss = 2063.56355290\n",
      "Iteration 10720, loss = 2063.23981281\n",
      "Iteration 10721, loss = 2062.91638848\n",
      "Iteration 10722, loss = 2062.59327910\n",
      "Iteration 10723, loss = 2062.27048387\n",
      "Iteration 10724, loss = 2061.94800202\n",
      "Iteration 10725, loss = 2061.62583275\n",
      "Iteration 10726, loss = 2061.30397529\n",
      "Iteration 10727, loss = 2060.98242884\n",
      "Iteration 10728, loss = 2060.66119265\n",
      "Iteration 10729, loss = 2060.34026593\n",
      "Iteration 10730, loss = 2060.01964793\n",
      "Iteration 10731, loss = 2059.69933788\n",
      "Iteration 10732, loss = 2059.37933503\n",
      "Iteration 10733, loss = 2059.05963861\n",
      "Iteration 10734, loss = 2058.74024788\n",
      "Iteration 10735, loss = 2058.42116209\n",
      "Iteration 10736, loss = 2058.10238051\n",
      "Iteration 10737, loss = 2057.78390238\n",
      "Iteration 10738, loss = 2057.46572698\n",
      "Iteration 10739, loss = 2057.14785357\n",
      "Iteration 10740, loss = 2056.83028142\n",
      "Iteration 10741, loss = 2056.51300982\n",
      "Iteration 10742, loss = 2056.19603803\n",
      "Iteration 10743, loss = 2055.87936535\n",
      "Iteration 10744, loss = 2055.56299106\n",
      "Iteration 10745, loss = 2055.24691444\n",
      "Iteration 10746, loss = 2054.93113479\n",
      "Iteration 10747, loss = 2054.61565141\n",
      "Iteration 10748, loss = 2054.30046360\n",
      "Iteration 10749, loss = 2053.98557066\n",
      "Iteration 10750, loss = 2053.67097189\n",
      "Iteration 10751, loss = 2053.35666661\n",
      "Iteration 10752, loss = 2053.04265414\n",
      "Iteration 10753, loss = 2052.72893377\n",
      "Iteration 10754, loss = 2052.41550485\n",
      "Iteration 10755, loss = 2052.10236669\n",
      "Iteration 10756, loss = 2051.78951861\n",
      "Iteration 10757, loss = 2051.47695995\n",
      "Iteration 10758, loss = 2051.16469003\n",
      "Iteration 10759, loss = 2050.85270820\n",
      "Iteration 10760, loss = 2050.54101379\n",
      "Iteration 10761, loss = 2050.22960614\n",
      "Iteration 10762, loss = 2049.91848461\n",
      "Iteration 10763, loss = 2049.60764852\n",
      "Iteration 10764, loss = 2049.29709725\n",
      "Iteration 10765, loss = 2048.98683014\n",
      "Iteration 10766, loss = 2048.67684654\n",
      "Iteration 10767, loss = 2048.36714583\n",
      "Iteration 10768, loss = 2048.05772735\n",
      "Iteration 10769, loss = 2047.74859048\n",
      "Iteration 10770, loss = 2047.43973458\n",
      "Iteration 10771, loss = 2047.13115902\n",
      "Iteration 10772, loss = 2046.82286319\n",
      "Iteration 10773, loss = 2046.51484645\n",
      "Iteration 10774, loss = 2046.20710819\n",
      "Iteration 10775, loss = 2045.89964778\n",
      "Iteration 10776, loss = 2045.59246461\n",
      "Iteration 10777, loss = 2045.28555808\n",
      "Iteration 10778, loss = 2044.97892757\n",
      "Iteration 10779, loss = 2044.67257246\n",
      "Iteration 10780, loss = 2044.36649217\n",
      "Iteration 10781, loss = 2044.06068609\n",
      "Iteration 10782, loss = 2043.75515361\n",
      "Iteration 10783, loss = 2043.44989415\n",
      "Iteration 10784, loss = 2043.14490710\n",
      "Iteration 10785, loss = 2042.84019188\n",
      "Iteration 10786, loss = 2042.53574790\n",
      "Iteration 10787, loss = 2042.23157457\n",
      "Iteration 10788, loss = 2041.92767130\n",
      "Iteration 10789, loss = 2041.62403752\n",
      "Iteration 10790, loss = 2041.32067265\n",
      "Iteration 10791, loss = 2041.01757611\n",
      "Iteration 10792, loss = 2040.71474733\n",
      "Iteration 10793, loss = 2040.41218573\n",
      "Iteration 10794, loss = 2040.10989075\n",
      "Iteration 10795, loss = 2039.80786182\n",
      "Iteration 10796, loss = 2039.50609837\n",
      "Iteration 10797, loss = 2039.20459985\n",
      "Iteration 10798, loss = 2038.90336568\n",
      "Iteration 10799, loss = 2038.60239533\n",
      "Iteration 10800, loss = 2038.30168822\n",
      "Iteration 10801, loss = 2038.00124381\n",
      "Iteration 10802, loss = 2037.70106154\n",
      "Iteration 10803, loss = 2037.40114087\n",
      "Iteration 10804, loss = 2037.10148125\n",
      "Iteration 10805, loss = 2036.80208214\n",
      "Iteration 10806, loss = 2036.50294300\n",
      "Iteration 10807, loss = 2036.20406328\n",
      "Iteration 10808, loss = 2035.90544245\n",
      "Iteration 10809, loss = 2035.60707997\n",
      "Iteration 10810, loss = 2035.30897531\n",
      "Iteration 10811, loss = 2035.01112794\n",
      "Iteration 10812, loss = 2034.71353733\n",
      "Iteration 10813, loss = 2034.41620295\n",
      "Iteration 10814, loss = 2034.11912428\n",
      "Iteration 10815, loss = 2033.82230079\n",
      "Iteration 10816, loss = 2033.52573197\n",
      "Iteration 10817, loss = 2033.22941729\n",
      "Iteration 10818, loss = 2032.93335624\n",
      "Iteration 10819, loss = 2032.63754830\n",
      "Iteration 10820, loss = 2032.34199297\n",
      "Iteration 10821, loss = 2032.04668972\n",
      "Iteration 10822, loss = 2031.75163806\n",
      "Iteration 10823, loss = 2031.45683747\n",
      "Iteration 10824, loss = 2031.16228745\n",
      "Iteration 10825, loss = 2030.86798750\n",
      "Iteration 10826, loss = 2030.57393712\n",
      "Iteration 10827, loss = 2030.28013580\n",
      "Iteration 10828, loss = 2029.98658305\n",
      "Iteration 10829, loss = 2029.69327837\n",
      "Iteration 10830, loss = 2029.40022128\n",
      "Iteration 10831, loss = 2029.10741127\n",
      "Iteration 10832, loss = 2028.81484787\n",
      "Iteration 10833, loss = 2028.52253057\n",
      "Iteration 10834, loss = 2028.23045890\n",
      "Iteration 10835, loss = 2027.93863237\n",
      "Iteration 10836, loss = 2027.64705050\n",
      "Iteration 10837, loss = 2027.35571281\n",
      "Iteration 10838, loss = 2027.06461881\n",
      "Iteration 10839, loss = 2026.77376804\n",
      "Iteration 10840, loss = 2026.48316001\n",
      "Iteration 10841, loss = 2026.19279426\n",
      "Iteration 10842, loss = 2025.90267030\n",
      "Iteration 10843, loss = 2025.61278767\n",
      "Iteration 10844, loss = 2025.32314591\n",
      "Iteration 10845, loss = 2025.03374454\n",
      "Iteration 10846, loss = 2024.74458309\n",
      "Iteration 10847, loss = 2024.45566112\n",
      "Iteration 10848, loss = 2024.16697814\n",
      "Iteration 10849, loss = 2023.87853371\n",
      "Iteration 10850, loss = 2023.59032737\n",
      "Iteration 10851, loss = 2023.30235865\n",
      "Iteration 10852, loss = 2023.01462710\n",
      "Iteration 10853, loss = 2022.72713227\n",
      "Iteration 10854, loss = 2022.43987371\n",
      "Iteration 10855, loss = 2022.15285097\n",
      "Iteration 10856, loss = 2021.86606359\n",
      "Iteration 10857, loss = 2021.57951113\n",
      "Iteration 10858, loss = 2021.29319314\n",
      "Iteration 10859, loss = 2021.00710919\n",
      "Iteration 10860, loss = 2020.72125882\n",
      "Iteration 10861, loss = 2020.43564159\n",
      "Iteration 10862, loss = 2020.15025708\n",
      "Iteration 10863, loss = 2019.86510483\n",
      "Iteration 10864, loss = 2019.58018441\n",
      "Iteration 10865, loss = 2019.29549538\n",
      "Iteration 10866, loss = 2019.01103732\n",
      "Iteration 10867, loss = 2018.72680979\n",
      "Iteration 10868, loss = 2018.44281236\n",
      "Iteration 10869, loss = 2018.15904459\n",
      "Iteration 10870, loss = 2017.87550607\n",
      "Iteration 10871, loss = 2017.59219637\n",
      "Iteration 10872, loss = 2017.30911506\n",
      "Iteration 10873, loss = 2017.02626171\n",
      "Iteration 10874, loss = 2016.74363591\n",
      "Iteration 10875, loss = 2016.46123723\n",
      "Iteration 10876, loss = 2016.17906526\n",
      "Iteration 10877, loss = 2015.89711958\n",
      "Iteration 10878, loss = 2015.61539977\n",
      "Iteration 10879, loss = 2015.33390542\n",
      "Iteration 10880, loss = 2015.05263611\n",
      "Iteration 10881, loss = 2014.77159143\n",
      "Iteration 10882, loss = 2014.49077096\n",
      "Iteration 10883, loss = 2014.21017431\n",
      "Iteration 10884, loss = 2013.92980106\n",
      "Iteration 10885, loss = 2013.64965080\n",
      "Iteration 10886, loss = 2013.36972314\n",
      "Iteration 10887, loss = 2013.09001765\n",
      "Iteration 10888, loss = 2012.81053395\n",
      "Iteration 10889, loss = 2012.53127163\n",
      "Iteration 10890, loss = 2012.25223029\n",
      "Iteration 10891, loss = 2011.97340953\n",
      "Iteration 10892, loss = 2011.69480895\n",
      "Iteration 10893, loss = 2011.41642816\n",
      "Iteration 10894, loss = 2011.13826677\n",
      "Iteration 10895, loss = 2010.86032438\n",
      "Iteration 10896, loss = 2010.58260060\n",
      "Iteration 10897, loss = 2010.30509504\n",
      "Iteration 10898, loss = 2010.02780734\n",
      "Iteration 10899, loss = 2009.75073712\n",
      "Iteration 10900, loss = 2009.47388402\n",
      "Iteration 10901, loss = 2009.19724771\n",
      "Iteration 10902, loss = 2008.92082791\n",
      "Iteration 10903, loss = 2008.64462438\n",
      "Iteration 10904, loss = 2008.36863698\n",
      "Iteration 10905, loss = 2008.09286570\n",
      "Iteration 10906, loss = 2007.81731064\n",
      "Iteration 10907, loss = 2007.54197175\n",
      "Iteration 10908, loss = 2007.26684845\n",
      "Iteration 10909, loss = 2006.99193843\n",
      "Iteration 10910, loss = 2006.71723757\n",
      "Iteration 10911, loss = 2006.44274147\n",
      "Iteration 10912, loss = 2006.16845106\n",
      "Iteration 10913, loss = 2005.89437306\n",
      "Iteration 10914, loss = 2005.62051409\n",
      "Iteration 10915, loss = 2005.34687404\n",
      "Iteration 10916, loss = 2005.07344737\n",
      "Iteration 10917, loss = 2004.80022830\n",
      "Iteration 10918, loss = 2004.52721472\n",
      "Iteration 10919, loss = 2004.25440866\n",
      "Iteration 10920, loss = 2003.98181319\n",
      "Iteration 10921, loss = 2003.70942963\n",
      "Iteration 10922, loss = 2003.43725708\n",
      "Iteration 10923, loss = 2003.16529345\n",
      "Iteration 10924, loss = 2002.89353661\n",
      "Iteration 10925, loss = 2002.62198548\n",
      "Iteration 10926, loss = 2002.35064068\n",
      "Iteration 10927, loss = 2002.07950379\n",
      "Iteration 10928, loss = 2001.80857560\n",
      "Iteration 10929, loss = 2001.53785489\n",
      "Iteration 10930, loss = 2001.26733933\n",
      "Iteration 10931, loss = 2000.99702758\n",
      "Iteration 10932, loss = 2000.72692023\n",
      "Iteration 10933, loss = 2000.45701864\n",
      "Iteration 10934, loss = 2000.18732305\n",
      "Iteration 10935, loss = 1999.91783214\n",
      "Iteration 10936, loss = 1999.64854432\n",
      "Iteration 10937, loss = 1999.37945905\n",
      "Iteration 10938, loss = 1999.11057675\n",
      "Iteration 10939, loss = 1998.84189783\n",
      "Iteration 10940, loss = 1998.57342196\n",
      "Iteration 10941, loss = 1998.30514829\n",
      "Iteration 10942, loss = 1998.03707608\n",
      "Iteration 10943, loss = 1997.76920503\n",
      "Iteration 10944, loss = 1997.50153501\n",
      "Iteration 10945, loss = 1997.23406589\n",
      "Iteration 10946, loss = 1996.96679737\n",
      "Iteration 10947, loss = 1996.69972905\n",
      "Iteration 10948, loss = 1996.43286048\n",
      "Iteration 10949, loss = 1996.16619120\n",
      "Iteration 10950, loss = 1995.89972086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10951, loss = 1995.63344925\n",
      "Iteration 10952, loss = 1995.36737618\n",
      "Iteration 10953, loss = 1995.10150135\n",
      "Iteration 10954, loss = 1994.83582430\n",
      "Iteration 10955, loss = 1994.57034457\n",
      "Iteration 10956, loss = 1994.30506181\n",
      "Iteration 10957, loss = 1994.03997583\n",
      "Iteration 10958, loss = 1993.77508638\n",
      "Iteration 10959, loss = 1993.51039315\n",
      "Iteration 10960, loss = 1993.24589570\n",
      "Iteration 10961, loss = 1992.98159366\n",
      "Iteration 10962, loss = 1992.71748671\n",
      "Iteration 10963, loss = 1992.45357460\n",
      "Iteration 10964, loss = 1992.18985703\n",
      "Iteration 10965, loss = 1991.92633369\n",
      "Iteration 10966, loss = 1991.66300420\n",
      "Iteration 10967, loss = 1991.39986824\n",
      "Iteration 10968, loss = 1991.13692550\n",
      "Iteration 10969, loss = 1990.87417566\n",
      "Iteration 10970, loss = 1990.61161842\n",
      "Iteration 10971, loss = 1990.34925348\n",
      "Iteration 10972, loss = 1990.08708051\n",
      "Iteration 10973, loss = 1989.82509920\n",
      "Iteration 10974, loss = 1989.56330922\n",
      "Iteration 10975, loss = 1989.30171026\n",
      "Iteration 10976, loss = 1989.04030201\n",
      "Iteration 10977, loss = 1988.77908418\n",
      "Iteration 10978, loss = 1988.51805646\n",
      "Iteration 10979, loss = 1988.25721853\n",
      "Iteration 10980, loss = 1987.99657008\n",
      "Iteration 10981, loss = 1987.73611080\n",
      "Iteration 10982, loss = 1987.47584038\n",
      "Iteration 10983, loss = 1987.21575854\n",
      "Iteration 10984, loss = 1986.95586496\n",
      "Iteration 10985, loss = 1986.69615934\n",
      "Iteration 10986, loss = 1986.43664137\n",
      "Iteration 10987, loss = 1986.17731076\n",
      "Iteration 10988, loss = 1985.91816719\n",
      "Iteration 10989, loss = 1985.65921037\n",
      "Iteration 10990, loss = 1985.40044001\n",
      "Iteration 10991, loss = 1985.14185580\n",
      "Iteration 10992, loss = 1984.88345745\n",
      "Iteration 10993, loss = 1984.62524465\n",
      "Iteration 10994, loss = 1984.36721711\n",
      "Iteration 10995, loss = 1984.10937454\n",
      "Iteration 10996, loss = 1983.85171664\n",
      "Iteration 10997, loss = 1983.59424312\n",
      "Iteration 10998, loss = 1983.33695368\n",
      "Iteration 10999, loss = 1983.07984803\n",
      "Iteration 11000, loss = 1982.82292588\n",
      "Iteration 11001, loss = 1982.56618693\n",
      "Iteration 11002, loss = 1982.30963091\n",
      "Iteration 11003, loss = 1982.05325751\n",
      "Iteration 11004, loss = 1981.79706645\n",
      "Iteration 11005, loss = 1981.54105744\n",
      "Iteration 11006, loss = 1981.28523019\n",
      "Iteration 11007, loss = 1981.02958442\n",
      "Iteration 11008, loss = 1980.77411984\n",
      "Iteration 11009, loss = 1980.51883616\n",
      "Iteration 11010, loss = 1980.26373311\n",
      "Iteration 11011, loss = 1980.00881039\n",
      "Iteration 11012, loss = 1979.75406773\n",
      "Iteration 11013, loss = 1979.49950483\n",
      "Iteration 11014, loss = 1979.24512143\n",
      "Iteration 11015, loss = 1978.99091724\n",
      "Iteration 11016, loss = 1978.73689197\n",
      "Iteration 11017, loss = 1978.48304535\n",
      "Iteration 11018, loss = 1978.22937710\n",
      "Iteration 11019, loss = 1977.97588695\n",
      "Iteration 11020, loss = 1977.72257461\n",
      "Iteration 11021, loss = 1977.46943980\n",
      "Iteration 11022, loss = 1977.21648226\n",
      "Iteration 11023, loss = 1976.96370171\n",
      "Iteration 11024, loss = 1976.71109786\n",
      "Iteration 11025, loss = 1976.45867045\n",
      "Iteration 11026, loss = 1976.20641921\n",
      "Iteration 11027, loss = 1975.95434386\n",
      "Iteration 11028, loss = 1975.70244412\n",
      "Iteration 11029, loss = 1975.45071974\n",
      "Iteration 11030, loss = 1975.19917043\n",
      "Iteration 11031, loss = 1974.94779593\n",
      "Iteration 11032, loss = 1974.69659596\n",
      "Iteration 11033, loss = 1974.44557027\n",
      "Iteration 11034, loss = 1974.19471857\n",
      "Iteration 11035, loss = 1973.94404061\n",
      "Iteration 11036, loss = 1973.69353611\n",
      "Iteration 11037, loss = 1973.44320482\n",
      "Iteration 11038, loss = 1973.19304646\n",
      "Iteration 11039, loss = 1972.94306077\n",
      "Iteration 11040, loss = 1972.69324748\n",
      "Iteration 11041, loss = 1972.44360634\n",
      "Iteration 11042, loss = 1972.19413707\n",
      "Iteration 11043, loss = 1971.94483943\n",
      "Iteration 11044, loss = 1971.69571313\n",
      "Iteration 11045, loss = 1971.44675794\n",
      "Iteration 11046, loss = 1971.19797357\n",
      "Iteration 11047, loss = 1970.94935978\n",
      "Iteration 11048, loss = 1970.70091630\n",
      "Iteration 11049, loss = 1970.45264288\n",
      "Iteration 11050, loss = 1970.20453926\n",
      "Iteration 11051, loss = 1969.95660517\n",
      "Iteration 11052, loss = 1969.70884037\n",
      "Iteration 11053, loss = 1969.46124460\n",
      "Iteration 11054, loss = 1969.21381760\n",
      "Iteration 11055, loss = 1968.96655911\n",
      "Iteration 11056, loss = 1968.71946889\n",
      "Iteration 11057, loss = 1968.47254668\n",
      "Iteration 11058, loss = 1968.22579222\n",
      "Iteration 11059, loss = 1967.97920527\n",
      "Iteration 11060, loss = 1967.73278556\n",
      "Iteration 11061, loss = 1967.48653286\n",
      "Iteration 11062, loss = 1967.24044690\n",
      "Iteration 11063, loss = 1966.99452744\n",
      "Iteration 11064, loss = 1966.74877423\n",
      "Iteration 11065, loss = 1966.50318702\n",
      "Iteration 11066, loss = 1966.25776556\n",
      "Iteration 11067, loss = 1966.01250960\n",
      "Iteration 11068, loss = 1965.76741890\n",
      "Iteration 11069, loss = 1965.52249321\n",
      "Iteration 11070, loss = 1965.27773227\n",
      "Iteration 11071, loss = 1965.03313586\n",
      "Iteration 11072, loss = 1964.78870372\n",
      "Iteration 11073, loss = 1964.54443560\n",
      "Iteration 11074, loss = 1964.30033127\n",
      "Iteration 11075, loss = 1964.05639048\n",
      "Iteration 11076, loss = 1963.81261298\n",
      "Iteration 11077, loss = 1963.56899854\n",
      "Iteration 11078, loss = 1963.32554690\n",
      "Iteration 11079, loss = 1963.08225785\n",
      "Iteration 11080, loss = 1962.83913112\n",
      "Iteration 11081, loss = 1962.59616648\n",
      "Iteration 11082, loss = 1962.35336369\n",
      "Iteration 11083, loss = 1962.11072251\n",
      "Iteration 11084, loss = 1961.86824271\n",
      "Iteration 11085, loss = 1961.62592404\n",
      "Iteration 11086, loss = 1961.38376627\n",
      "Iteration 11087, loss = 1961.14176916\n",
      "Iteration 11088, loss = 1960.89993247\n",
      "Iteration 11089, loss = 1960.65825597\n",
      "Iteration 11090, loss = 1960.41673943\n",
      "Iteration 11091, loss = 1960.17538260\n",
      "Iteration 11092, loss = 1959.93418525\n",
      "Iteration 11093, loss = 1959.69314716\n",
      "Iteration 11094, loss = 1959.45226808\n",
      "Iteration 11095, loss = 1959.21154779\n",
      "Iteration 11096, loss = 1958.97098604\n",
      "Iteration 11097, loss = 1958.73058262\n",
      "Iteration 11098, loss = 1958.49033729\n",
      "Iteration 11099, loss = 1958.25024981\n",
      "Iteration 11100, loss = 1958.01031996\n",
      "Iteration 11101, loss = 1957.77054751\n",
      "Iteration 11102, loss = 1957.53093222\n",
      "Iteration 11103, loss = 1957.29147388\n",
      "Iteration 11104, loss = 1957.05217225\n",
      "Iteration 11105, loss = 1956.81302710\n",
      "Iteration 11106, loss = 1956.57403821\n",
      "Iteration 11107, loss = 1956.33520535\n",
      "Iteration 11108, loss = 1956.09652829\n",
      "Iteration 11109, loss = 1955.85800682\n",
      "Iteration 11110, loss = 1955.61964069\n",
      "Iteration 11111, loss = 1955.38142969\n",
      "Iteration 11112, loss = 1955.14337360\n",
      "Iteration 11113, loss = 1954.90547218\n",
      "Iteration 11114, loss = 1954.66772523\n",
      "Iteration 11115, loss = 1954.43013250\n",
      "Iteration 11116, loss = 1954.19269379\n",
      "Iteration 11117, loss = 1953.95540887\n",
      "Iteration 11118, loss = 1953.71827751\n",
      "Iteration 11119, loss = 1953.48129951\n",
      "Iteration 11120, loss = 1953.24447463\n",
      "Iteration 11121, loss = 1953.00780265\n",
      "Iteration 11122, loss = 1952.77128337\n",
      "Iteration 11123, loss = 1952.53491655\n",
      "Iteration 11124, loss = 1952.29870198\n",
      "Iteration 11125, loss = 1952.06263945\n",
      "Iteration 11126, loss = 1951.82672872\n",
      "Iteration 11127, loss = 1951.59096960\n",
      "Iteration 11128, loss = 1951.35536185\n",
      "Iteration 11129, loss = 1951.11990527\n",
      "Iteration 11130, loss = 1950.88459964\n",
      "Iteration 11131, loss = 1950.64944474\n",
      "Iteration 11132, loss = 1950.41444035\n",
      "Iteration 11133, loss = 1950.17958627\n",
      "Iteration 11134, loss = 1949.94488228\n",
      "Iteration 11135, loss = 1949.71032817\n",
      "Iteration 11136, loss = 1949.47592371\n",
      "Iteration 11137, loss = 1949.24166871\n",
      "Iteration 11138, loss = 1949.00756294\n",
      "Iteration 11139, loss = 1948.77360620\n",
      "Iteration 11140, loss = 1948.53979828\n",
      "Iteration 11141, loss = 1948.30613896\n",
      "Iteration 11142, loss = 1948.07262803\n",
      "Iteration 11143, loss = 1947.83926529\n",
      "Iteration 11144, loss = 1947.60605052\n",
      "Iteration 11145, loss = 1947.37298351\n",
      "Iteration 11146, loss = 1947.14006406\n",
      "Iteration 11147, loss = 1946.90729195\n",
      "Iteration 11148, loss = 1946.67466699\n",
      "Iteration 11149, loss = 1946.44218896\n",
      "Iteration 11150, loss = 1946.20985765\n",
      "Iteration 11151, loss = 1945.97767286\n",
      "Iteration 11152, loss = 1945.74563439\n",
      "Iteration 11153, loss = 1945.51374202\n",
      "Iteration 11154, loss = 1945.28199555\n",
      "Iteration 11155, loss = 1945.05039478\n",
      "Iteration 11156, loss = 1944.81893950\n",
      "Iteration 11157, loss = 1944.58762951\n",
      "Iteration 11158, loss = 1944.35646460\n",
      "Iteration 11159, loss = 1944.12544458\n",
      "Iteration 11160, loss = 1943.89456923\n",
      "Iteration 11161, loss = 1943.66383836\n",
      "Iteration 11162, loss = 1943.43325176\n",
      "Iteration 11163, loss = 1943.20280924\n",
      "Iteration 11164, loss = 1942.97251058\n",
      "Iteration 11165, loss = 1942.74235560\n",
      "Iteration 11166, loss = 1942.51234409\n",
      "Iteration 11167, loss = 1942.28247584\n",
      "Iteration 11168, loss = 1942.05275067\n",
      "Iteration 11169, loss = 1941.82316837\n",
      "Iteration 11170, loss = 1941.59372874\n",
      "Iteration 11171, loss = 1941.36443158\n",
      "Iteration 11172, loss = 1941.13527671\n",
      "Iteration 11173, loss = 1940.90626391\n",
      "Iteration 11174, loss = 1940.67739299\n",
      "Iteration 11175, loss = 1940.44866376\n",
      "Iteration 11176, loss = 1940.22007601\n",
      "Iteration 11177, loss = 1939.99162956\n",
      "Iteration 11178, loss = 1939.76332421\n",
      "Iteration 11179, loss = 1939.53515975\n",
      "Iteration 11180, loss = 1939.30713601\n",
      "Iteration 11181, loss = 1939.07925277\n",
      "Iteration 11182, loss = 1938.85150986\n",
      "Iteration 11183, loss = 1938.62390707\n",
      "Iteration 11184, loss = 1938.39644421\n",
      "Iteration 11185, loss = 1938.16912109\n",
      "Iteration 11186, loss = 1937.94193751\n",
      "Iteration 11187, loss = 1937.71489329\n",
      "Iteration 11188, loss = 1937.48798823\n",
      "Iteration 11189, loss = 1937.26122215\n",
      "Iteration 11190, loss = 1937.03459484\n",
      "Iteration 11191, loss = 1936.80810612\n",
      "Iteration 11192, loss = 1936.58175580\n",
      "Iteration 11193, loss = 1936.35554369\n",
      "Iteration 11194, loss = 1936.12946960\n",
      "Iteration 11195, loss = 1935.90353334\n",
      "Iteration 11196, loss = 1935.67773472\n",
      "Iteration 11197, loss = 1935.45207356\n",
      "Iteration 11198, loss = 1935.22654965\n",
      "Iteration 11199, loss = 1935.00116283\n",
      "Iteration 11200, loss = 1934.77591290\n",
      "Iteration 11201, loss = 1934.55079967\n",
      "Iteration 11202, loss = 1934.32582296\n",
      "Iteration 11203, loss = 1934.10098257\n",
      "Iteration 11204, loss = 1933.87627834\n",
      "Iteration 11205, loss = 1933.65171006\n",
      "Iteration 11206, loss = 1933.42727755\n",
      "Iteration 11207, loss = 1933.20298064\n",
      "Iteration 11208, loss = 1932.97881913\n",
      "Iteration 11209, loss = 1932.75479284\n",
      "Iteration 11210, loss = 1932.53090158\n",
      "Iteration 11211, loss = 1932.30714518\n",
      "Iteration 11212, loss = 1932.08352345\n",
      "Iteration 11213, loss = 1931.86003621\n",
      "Iteration 11214, loss = 1931.63668328\n",
      "Iteration 11215, loss = 1931.41346447\n",
      "Iteration 11216, loss = 1931.19037960\n",
      "Iteration 11217, loss = 1930.96742849\n",
      "Iteration 11218, loss = 1930.74461096\n",
      "Iteration 11219, loss = 1930.52192683\n",
      "Iteration 11220, loss = 1930.29937592\n",
      "Iteration 11221, loss = 1930.07695804\n",
      "Iteration 11222, loss = 1929.85467303\n",
      "Iteration 11223, loss = 1929.63252070\n",
      "Iteration 11224, loss = 1929.41050087\n",
      "Iteration 11225, loss = 1929.18861336\n",
      "Iteration 11226, loss = 1928.96685800\n",
      "Iteration 11227, loss = 1928.74523460\n",
      "Iteration 11228, loss = 1928.52374299\n",
      "Iteration 11229, loss = 1928.30238300\n",
      "Iteration 11230, loss = 1928.08115444\n",
      "Iteration 11231, loss = 1927.86005714\n",
      "Iteration 11232, loss = 1927.63909092\n",
      "Iteration 11233, loss = 1927.41825560\n",
      "Iteration 11234, loss = 1927.19755102\n",
      "Iteration 11235, loss = 1926.97697700\n",
      "Iteration 11236, loss = 1926.75653336\n",
      "Iteration 11237, loss = 1926.53621992\n",
      "Iteration 11238, loss = 1926.31603651\n",
      "Iteration 11239, loss = 1926.09598297\n",
      "Iteration 11240, loss = 1925.87605910\n",
      "Iteration 11241, loss = 1925.65626475\n",
      "Iteration 11242, loss = 1925.43659974\n",
      "Iteration 11243, loss = 1925.21706390\n",
      "Iteration 11244, loss = 1924.99765705\n",
      "Iteration 11245, loss = 1924.77837902\n",
      "Iteration 11246, loss = 1924.55922963\n",
      "Iteration 11247, loss = 1924.34020873\n",
      "Iteration 11248, loss = 1924.12131614\n",
      "Iteration 11249, loss = 1923.90255168\n",
      "Iteration 11250, loss = 1923.68391519\n",
      "Iteration 11251, loss = 1923.46540650\n",
      "Iteration 11252, loss = 1923.24702543\n",
      "Iteration 11253, loss = 1923.02877183\n",
      "Iteration 11254, loss = 1922.81064551\n",
      "Iteration 11255, loss = 1922.59264630\n",
      "Iteration 11256, loss = 1922.37477405\n",
      "Iteration 11257, loss = 1922.15702859\n",
      "Iteration 11258, loss = 1921.93940973\n",
      "Iteration 11259, loss = 1921.72191733\n",
      "Iteration 11260, loss = 1921.50455121\n",
      "Iteration 11261, loss = 1921.28731119\n",
      "Iteration 11262, loss = 1921.07019713\n",
      "Iteration 11263, loss = 1920.85320884\n",
      "Iteration 11264, loss = 1920.63634617\n",
      "Iteration 11265, loss = 1920.41960895\n",
      "Iteration 11266, loss = 1920.20299702\n",
      "Iteration 11267, loss = 1919.98651020\n",
      "Iteration 11268, loss = 1919.77014835\n",
      "Iteration 11269, loss = 1919.55391129\n",
      "Iteration 11270, loss = 1919.33779888\n",
      "Iteration 11271, loss = 1919.12181097\n",
      "Iteration 11272, loss = 1918.90594741\n",
      "Iteration 11273, loss = 1918.69020809\n",
      "Iteration 11274, loss = 1918.47459293\n",
      "Iteration 11275, loss = 1918.25910191\n",
      "Iteration 11276, loss = 1918.04373511\n",
      "Iteration 11277, loss = 1917.82849280\n",
      "Iteration 11278, loss = 1917.61337548\n",
      "Iteration 11279, loss = 1917.39838397\n",
      "Iteration 11280, loss = 1917.18351929\n",
      "Iteration 11281, loss = 1916.96878182\n",
      "Iteration 11282, loss = 1916.75416987\n",
      "Iteration 11283, loss = 1916.53967731\n",
      "Iteration 11284, loss = 1916.32529574\n",
      "Iteration 11285, loss = 1916.11101950\n",
      "Iteration 11286, loss = 1915.89685327\n",
      "Iteration 11287, loss = 1915.68280995\n",
      "Iteration 11288, loss = 1915.46890345\n",
      "Iteration 11289, loss = 1915.25513657\n",
      "Iteration 11290, loss = 1915.04149781\n",
      "Iteration 11291, loss = 1914.82797068\n",
      "Iteration 11292, loss = 1914.61454810\n",
      "Iteration 11293, loss = 1914.40124076\n",
      "Iteration 11294, loss = 1914.18806538\n",
      "Iteration 11295, loss = 1913.97502448\n",
      "Iteration 11296, loss = 1913.76210464\n",
      "Iteration 11297, loss = 1913.54929399\n",
      "Iteration 11298, loss = 1913.33659573\n",
      "Iteration 11299, loss = 1913.12402168\n",
      "Iteration 11300, loss = 1912.91157604\n",
      "Iteration 11301, loss = 1912.69925202\n",
      "Iteration 11302, loss = 1912.48704262\n",
      "Iteration 11303, loss = 1912.27494861\n",
      "Iteration 11304, loss = 1912.06297487\n",
      "Iteration 11305, loss = 1911.85112323\n",
      "Iteration 11306, loss = 1911.63939162\n",
      "Iteration 11307, loss = 1911.42777795\n",
      "Iteration 11308, loss = 1911.21628185\n",
      "Iteration 11309, loss = 1911.00490363\n",
      "Iteration 11310, loss = 1910.79364365\n",
      "Iteration 11311, loss = 1910.58250256\n",
      "Iteration 11312, loss = 1910.37148053\n",
      "Iteration 11313, loss = 1910.16057642\n",
      "Iteration 11314, loss = 1909.94978877\n",
      "Iteration 11315, loss = 1909.73911770\n",
      "Iteration 11316, loss = 1909.52856468\n",
      "Iteration 11317, loss = 1909.31813026\n",
      "Iteration 11318, loss = 1909.10781313\n",
      "Iteration 11319, loss = 1908.89761179\n",
      "Iteration 11320, loss = 1908.68752642\n",
      "Iteration 11321, loss = 1908.47755822\n",
      "Iteration 11322, loss = 1908.26770745\n",
      "Iteration 11323, loss = 1908.05797310\n",
      "Iteration 11324, loss = 1907.84835423\n",
      "Iteration 11325, loss = 1907.63885097\n",
      "Iteration 11326, loss = 1907.42946388\n",
      "Iteration 11327, loss = 1907.22019296\n",
      "Iteration 11328, loss = 1907.01103766\n",
      "Iteration 11329, loss = 1906.80199753\n",
      "Iteration 11330, loss = 1906.59307255\n",
      "Iteration 11331, loss = 1906.38426277\n",
      "Iteration 11332, loss = 1906.17556809\n",
      "Iteration 11333, loss = 1905.96698828\n",
      "Iteration 11334, loss = 1905.75852316\n",
      "Iteration 11335, loss = 1905.55017258\n",
      "Iteration 11336, loss = 1905.34193637\n",
      "Iteration 11337, loss = 1905.13381436\n",
      "Iteration 11338, loss = 1904.92580649\n",
      "Iteration 11339, loss = 1904.71791267\n",
      "Iteration 11340, loss = 1904.51013271\n",
      "Iteration 11341, loss = 1904.30246637\n",
      "Iteration 11342, loss = 1904.09491348\n",
      "Iteration 11343, loss = 1903.88747398\n",
      "Iteration 11344, loss = 1903.68014780\n",
      "Iteration 11345, loss = 1903.47293477\n",
      "Iteration 11346, loss = 1903.26583466\n",
      "Iteration 11347, loss = 1903.05884730\n",
      "Iteration 11348, loss = 1902.85197259\n",
      "Iteration 11349, loss = 1902.64521046\n",
      "Iteration 11350, loss = 1902.43856075\n",
      "Iteration 11351, loss = 1902.23202326\n",
      "Iteration 11352, loss = 1902.02559784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11353, loss = 1901.81928436\n",
      "Iteration 11354, loss = 1901.61308272\n",
      "Iteration 11355, loss = 1901.40699276\n",
      "Iteration 11356, loss = 1901.20101433\n",
      "Iteration 11357, loss = 1900.99514728\n",
      "Iteration 11358, loss = 1900.78939148\n",
      "Iteration 11359, loss = 1900.58374679\n",
      "Iteration 11360, loss = 1900.37821307\n",
      "Iteration 11361, loss = 1900.17279017\n",
      "Iteration 11362, loss = 1899.96747797\n",
      "Iteration 11363, loss = 1899.76227632\n",
      "Iteration 11364, loss = 1899.55718508\n",
      "Iteration 11365, loss = 1899.35220410\n",
      "Iteration 11366, loss = 1899.14733324\n",
      "Iteration 11367, loss = 1898.94257239\n",
      "Iteration 11368, loss = 1898.73792139\n",
      "Iteration 11369, loss = 1898.53338011\n",
      "Iteration 11370, loss = 1898.32894840\n",
      "Iteration 11371, loss = 1898.12462613\n",
      "Iteration 11372, loss = 1897.92041316\n",
      "Iteration 11373, loss = 1897.71630935\n",
      "Iteration 11374, loss = 1897.51231458\n",
      "Iteration 11375, loss = 1897.30842869\n",
      "Iteration 11376, loss = 1897.10465156\n",
      "Iteration 11377, loss = 1896.90098304\n",
      "Iteration 11378, loss = 1896.69742301\n",
      "Iteration 11379, loss = 1896.49397132\n",
      "Iteration 11380, loss = 1896.29062784\n",
      "Iteration 11381, loss = 1896.08739243\n",
      "Iteration 11382, loss = 1895.88426496\n",
      "Iteration 11383, loss = 1895.68124530\n",
      "Iteration 11384, loss = 1895.47833330\n",
      "Iteration 11385, loss = 1895.27552884\n",
      "Iteration 11386, loss = 1895.07283177\n",
      "Iteration 11387, loss = 1894.87024197\n",
      "Iteration 11388, loss = 1894.66775931\n",
      "Iteration 11389, loss = 1894.46538363\n",
      "Iteration 11390, loss = 1894.26311483\n",
      "Iteration 11391, loss = 1894.06095275\n",
      "Iteration 11392, loss = 1893.85889727\n",
      "Iteration 11393, loss = 1893.65694825\n",
      "Iteration 11394, loss = 1893.45510557\n",
      "Iteration 11395, loss = 1893.25336909\n",
      "Iteration 11396, loss = 1893.05173867\n",
      "Iteration 11397, loss = 1892.85021418\n",
      "Iteration 11398, loss = 1892.64879551\n",
      "Iteration 11399, loss = 1892.44748250\n",
      "Iteration 11400, loss = 1892.24627503\n",
      "Iteration 11401, loss = 1892.04517297\n",
      "Iteration 11402, loss = 1891.84417619\n",
      "Iteration 11403, loss = 1891.64328456\n",
      "Iteration 11404, loss = 1891.44249794\n",
      "Iteration 11405, loss = 1891.24181621\n",
      "Iteration 11406, loss = 1891.04123924\n",
      "Iteration 11407, loss = 1890.84076689\n",
      "Iteration 11408, loss = 1890.64039904\n",
      "Iteration 11409, loss = 1890.44013556\n",
      "Iteration 11410, loss = 1890.23997632\n",
      "Iteration 11411, loss = 1890.03992118\n",
      "Iteration 11412, loss = 1889.83997003\n",
      "Iteration 11413, loss = 1889.64012273\n",
      "Iteration 11414, loss = 1889.44037915\n",
      "Iteration 11415, loss = 1889.24073916\n",
      "Iteration 11416, loss = 1889.04120265\n",
      "Iteration 11417, loss = 1888.84176947\n",
      "Iteration 11418, loss = 1888.64243951\n",
      "Iteration 11419, loss = 1888.44321262\n",
      "Iteration 11420, loss = 1888.24408870\n",
      "Iteration 11421, loss = 1888.04506761\n",
      "Iteration 11422, loss = 1887.84614922\n",
      "Iteration 11423, loss = 1887.64733340\n",
      "Iteration 11424, loss = 1887.44862004\n",
      "Iteration 11425, loss = 1887.25000901\n",
      "Iteration 11426, loss = 1887.05150017\n",
      "Iteration 11427, loss = 1886.85309340\n",
      "Iteration 11428, loss = 1886.65478858\n",
      "Iteration 11429, loss = 1886.45658558\n",
      "Iteration 11430, loss = 1886.25848428\n",
      "Iteration 11431, loss = 1886.06048456\n",
      "Iteration 11432, loss = 1885.86258627\n",
      "Iteration 11433, loss = 1885.66478932\n",
      "Iteration 11434, loss = 1885.46709356\n",
      "Iteration 11435, loss = 1885.26949887\n",
      "Iteration 11436, loss = 1885.07200513\n",
      "Iteration 11437, loss = 1884.87461222\n",
      "Iteration 11438, loss = 1884.67732002\n",
      "Iteration 11439, loss = 1884.48012839\n",
      "Iteration 11440, loss = 1884.28303722\n",
      "Iteration 11441, loss = 1884.08604638\n",
      "Iteration 11442, loss = 1883.88915576\n",
      "Iteration 11443, loss = 1883.69236522\n",
      "Iteration 11444, loss = 1883.49567465\n",
      "Iteration 11445, loss = 1883.29908392\n",
      "Iteration 11446, loss = 1883.10259291\n",
      "Iteration 11447, loss = 1882.90620150\n",
      "Iteration 11448, loss = 1882.70990958\n",
      "Iteration 11449, loss = 1882.51371700\n",
      "Iteration 11450, loss = 1882.31762367\n",
      "Iteration 11451, loss = 1882.12162944\n",
      "Iteration 11452, loss = 1881.92573422\n",
      "Iteration 11453, loss = 1881.72993786\n",
      "Iteration 11454, loss = 1881.53424026\n",
      "Iteration 11455, loss = 1881.33864129\n",
      "Iteration 11456, loss = 1881.14314083\n",
      "Iteration 11457, loss = 1880.94773877\n",
      "Iteration 11458, loss = 1880.75243498\n",
      "Iteration 11459, loss = 1880.55722934\n",
      "Iteration 11460, loss = 1880.36212174\n",
      "Iteration 11461, loss = 1880.16711205\n",
      "Iteration 11462, loss = 1879.97220015\n",
      "Iteration 11463, loss = 1879.77738594\n",
      "Iteration 11464, loss = 1879.58266928\n",
      "Iteration 11465, loss = 1879.38805006\n",
      "Iteration 11466, loss = 1879.19352817\n",
      "Iteration 11467, loss = 1878.99910348\n",
      "Iteration 11468, loss = 1878.80477588\n",
      "Iteration 11469, loss = 1878.61054524\n",
      "Iteration 11470, loss = 1878.41641146\n",
      "Iteration 11471, loss = 1878.22237441\n",
      "Iteration 11472, loss = 1878.02843397\n",
      "Iteration 11473, loss = 1877.83459004\n",
      "Iteration 11474, loss = 1877.64084249\n",
      "Iteration 11475, loss = 1877.44719121\n",
      "Iteration 11476, loss = 1877.25363608\n",
      "Iteration 11477, loss = 1877.06017698\n",
      "Iteration 11478, loss = 1876.86681380\n",
      "Iteration 11479, loss = 1876.67354643\n",
      "Iteration 11480, loss = 1876.48037474\n",
      "Iteration 11481, loss = 1876.28729862\n",
      "Iteration 11482, loss = 1876.09431796\n",
      "Iteration 11483, loss = 1875.90143264\n",
      "Iteration 11484, loss = 1875.70864254\n",
      "Iteration 11485, loss = 1875.51594756\n",
      "Iteration 11486, loss = 1875.32334757\n",
      "Iteration 11487, loss = 1875.13084247\n",
      "Iteration 11488, loss = 1874.93843214\n",
      "Iteration 11489, loss = 1874.74611646\n",
      "Iteration 11490, loss = 1874.55389532\n",
      "Iteration 11491, loss = 1874.36176860\n",
      "Iteration 11492, loss = 1874.16973620\n",
      "Iteration 11493, loss = 1873.97779800\n",
      "Iteration 11494, loss = 1873.78595389\n",
      "Iteration 11495, loss = 1873.59420375\n",
      "Iteration 11496, loss = 1873.40254748\n",
      "Iteration 11497, loss = 1873.21098495\n",
      "Iteration 11498, loss = 1873.01951606\n",
      "Iteration 11499, loss = 1872.82814069\n",
      "Iteration 11500, loss = 1872.63685873\n",
      "Iteration 11501, loss = 1872.44567008\n",
      "Iteration 11502, loss = 1872.25457461\n",
      "Iteration 11503, loss = 1872.06357221\n",
      "Iteration 11504, loss = 1871.87266279\n",
      "Iteration 11505, loss = 1871.68184622\n",
      "Iteration 11506, loss = 1871.49112239\n",
      "Iteration 11507, loss = 1871.30049119\n",
      "Iteration 11508, loss = 1871.10995251\n",
      "Iteration 11509, loss = 1870.91950625\n",
      "Iteration 11510, loss = 1870.72915228\n",
      "Iteration 11511, loss = 1870.53889051\n",
      "Iteration 11512, loss = 1870.34872081\n",
      "Iteration 11513, loss = 1870.15864309\n",
      "Iteration 11514, loss = 1869.96865722\n",
      "Iteration 11515, loss = 1869.77876311\n",
      "Iteration 11516, loss = 1869.58896064\n",
      "Iteration 11517, loss = 1869.39924970\n",
      "Iteration 11518, loss = 1869.20963018\n",
      "Iteration 11519, loss = 1869.02010198\n",
      "Iteration 11520, loss = 1868.83066498\n",
      "Iteration 11521, loss = 1868.64131909\n",
      "Iteration 11522, loss = 1868.45206418\n",
      "Iteration 11523, loss = 1868.26290015\n",
      "Iteration 11524, loss = 1868.07382689\n",
      "Iteration 11525, loss = 1867.88484430\n",
      "Iteration 11526, loss = 1867.69595227\n",
      "Iteration 11527, loss = 1867.50715068\n",
      "Iteration 11528, loss = 1867.31843944\n",
      "Iteration 11529, loss = 1867.12981843\n",
      "Iteration 11530, loss = 1866.94128755\n",
      "Iteration 11531, loss = 1866.75284669\n",
      "Iteration 11532, loss = 1866.56449575\n",
      "Iteration 11533, loss = 1866.37623461\n",
      "Iteration 11534, loss = 1866.18806318\n",
      "Iteration 11535, loss = 1865.99998133\n",
      "Iteration 11536, loss = 1865.81198898\n",
      "Iteration 11537, loss = 1865.62408601\n",
      "Iteration 11538, loss = 1865.43627232\n",
      "Iteration 11539, loss = 1865.24854780\n",
      "Iteration 11540, loss = 1865.06091235\n",
      "Iteration 11541, loss = 1864.87336585\n",
      "Iteration 11542, loss = 1864.68590822\n",
      "Iteration 11543, loss = 1864.49853933\n",
      "Iteration 11544, loss = 1864.31125909\n",
      "Iteration 11545, loss = 1864.12406739\n",
      "Iteration 11546, loss = 1863.93696412\n",
      "Iteration 11547, loss = 1863.74994919\n",
      "Iteration 11548, loss = 1863.56302249\n",
      "Iteration 11549, loss = 1863.37618391\n",
      "Iteration 11550, loss = 1863.18943335\n",
      "Iteration 11551, loss = 1863.00277071\n",
      "Iteration 11552, loss = 1862.81619588\n",
      "Iteration 11553, loss = 1862.62970877\n",
      "Iteration 11554, loss = 1862.44330925\n",
      "Iteration 11555, loss = 1862.25699724\n",
      "Iteration 11556, loss = 1862.07077264\n",
      "Iteration 11557, loss = 1861.88463532\n",
      "Iteration 11558, loss = 1861.69858521\n",
      "Iteration 11559, loss = 1861.51262218\n",
      "Iteration 11560, loss = 1861.32674615\n",
      "Iteration 11561, loss = 1861.14095700\n",
      "Iteration 11562, loss = 1860.95525464\n",
      "Iteration 11563, loss = 1860.76963897\n",
      "Iteration 11564, loss = 1860.58410987\n",
      "Iteration 11565, loss = 1860.39866726\n",
      "Iteration 11566, loss = 1860.21331103\n",
      "Iteration 11567, loss = 1860.02804107\n",
      "Iteration 11568, loss = 1859.84285730\n",
      "Iteration 11569, loss = 1859.65775959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11570, loss = 1859.47274787\n",
      "Iteration 11571, loss = 1859.28782202\n",
      "Iteration 11572, loss = 1859.10298194\n",
      "Iteration 11573, loss = 1858.91822754\n",
      "Iteration 11574, loss = 1858.73355872\n",
      "Iteration 11575, loss = 1858.54897537\n",
      "Iteration 11576, loss = 1858.36447741\n",
      "Iteration 11577, loss = 1858.18006474\n",
      "Iteration 11578, loss = 1857.99573728\n",
      "Iteration 11579, loss = 1857.81149495\n",
      "Iteration 11580, loss = 1857.62733772\n",
      "Iteration 11581, loss = 1857.44326558\n",
      "Iteration 11582, loss = 1857.25927863\n",
      "Iteration 11583, loss = 1857.07537712\n",
      "Iteration 11584, loss = 1856.89156161\n",
      "Iteration 11585, loss = 1856.70783317\n",
      "Iteration 11586, loss = 1856.52419356\n",
      "Iteration 11587, loss = 1856.34064522\n",
      "Iteration 11588, loss = 1856.15718977\n",
      "Iteration 11589, loss = 1855.97382445\n",
      "Iteration 11590, loss = 1855.79053630\n",
      "Iteration 11591, loss = 1855.60730682\n",
      "Iteration 11592, loss = 1855.42412730\n",
      "Iteration 11593, loss = 1855.24101649\n",
      "Iteration 11594, loss = 1855.05800827\n",
      "Iteration 11595, loss = 1854.87512015\n",
      "Iteration 11596, loss = 1854.69233534\n",
      "Iteration 11597, loss = 1854.50962056\n",
      "Iteration 11598, loss = 1854.32695996\n",
      "Iteration 11599, loss = 1854.14437179\n",
      "Iteration 11600, loss = 1853.96188503\n",
      "Iteration 11601, loss = 1853.77950265\n",
      "Iteration 11602, loss = 1853.59720192\n",
      "Iteration 11603, loss = 1853.41496603\n",
      "Iteration 11604, loss = 1853.23280325\n",
      "Iteration 11605, loss = 1853.05073244\n",
      "Iteration 11606, loss = 1852.86875713\n",
      "Iteration 11607, loss = 1852.68686370\n",
      "Iteration 11608, loss = 1852.50504221\n",
      "Iteration 11609, loss = 1852.32329839\n",
      "Iteration 11610, loss = 1852.14164242\n",
      "Iteration 11611, loss = 1851.96007423\n",
      "Iteration 11612, loss = 1851.77858678\n",
      "Iteration 11613, loss = 1851.59717703\n",
      "Iteration 11614, loss = 1851.41584757\n",
      "Iteration 11615, loss = 1851.23460116\n",
      "Iteration 11616, loss = 1851.05343842\n",
      "Iteration 11617, loss = 1850.87235821\n",
      "Iteration 11618, loss = 1850.69135799\n",
      "Iteration 11619, loss = 1850.51043646\n",
      "Iteration 11620, loss = 1850.32959607\n",
      "Iteration 11621, loss = 1850.14883958\n",
      "Iteration 11622, loss = 1849.96816533\n",
      "Iteration 11623, loss = 1849.78756967\n",
      "Iteration 11624, loss = 1849.60705279\n",
      "Iteration 11625, loss = 1849.42661789\n",
      "Iteration 11626, loss = 1849.24626561\n",
      "Iteration 11627, loss = 1849.06599342\n",
      "Iteration 11628, loss = 1848.88580002\n",
      "Iteration 11629, loss = 1848.70568672\n",
      "Iteration 11630, loss = 1848.52565459\n",
      "Iteration 11631, loss = 1848.34570292\n",
      "Iteration 11632, loss = 1848.16583090\n",
      "Iteration 11633, loss = 1847.98603859\n",
      "Iteration 11634, loss = 1847.80632611\n",
      "Iteration 11635, loss = 1847.62669332\n",
      "Iteration 11636, loss = 1847.44714025\n",
      "Iteration 11637, loss = 1847.26766704\n",
      "Iteration 11638, loss = 1847.08827331\n",
      "Iteration 11639, loss = 1846.90895855\n",
      "Iteration 11640, loss = 1846.72972289\n",
      "Iteration 11641, loss = 1846.55056676\n",
      "Iteration 11642, loss = 1846.37149003\n",
      "Iteration 11643, loss = 1846.19249212\n",
      "Iteration 11644, loss = 1846.01357280\n",
      "Iteration 11645, loss = 1845.83473233\n",
      "Iteration 11646, loss = 1845.65597086\n",
      "Iteration 11647, loss = 1845.47728810\n",
      "Iteration 11648, loss = 1845.29868376\n",
      "Iteration 11649, loss = 1845.12015778\n",
      "Iteration 11650, loss = 1844.94171023\n",
      "Iteration 11651, loss = 1844.76334101\n",
      "Iteration 11652, loss = 1844.58505000\n",
      "Iteration 11653, loss = 1844.40683710\n",
      "Iteration 11654, loss = 1844.22870220\n",
      "Iteration 11655, loss = 1844.05064520\n",
      "Iteration 11656, loss = 1843.87266602\n",
      "Iteration 11657, loss = 1843.69476463\n",
      "Iteration 11658, loss = 1843.51694094\n",
      "Iteration 11659, loss = 1843.33919481\n",
      "Iteration 11660, loss = 1843.16152613\n",
      "Iteration 11661, loss = 1842.98393482\n",
      "Iteration 11662, loss = 1842.80642085\n",
      "Iteration 11663, loss = 1842.62898413\n",
      "Iteration 11664, loss = 1842.45162453\n",
      "Iteration 11665, loss = 1842.27434196\n",
      "Iteration 11666, loss = 1842.09713634\n",
      "Iteration 11667, loss = 1841.92000759\n",
      "Iteration 11668, loss = 1841.74295564\n",
      "Iteration 11669, loss = 1841.56598039\n",
      "Iteration 11670, loss = 1841.38908174\n",
      "Iteration 11671, loss = 1841.21225961\n",
      "Iteration 11672, loss = 1841.03551390\n",
      "Iteration 11673, loss = 1840.85884455\n",
      "Iteration 11674, loss = 1840.68225146\n",
      "Iteration 11675, loss = 1840.50573455\n",
      "Iteration 11676, loss = 1840.32929372\n",
      "Iteration 11677, loss = 1840.15292890\n",
      "Iteration 11678, loss = 1839.97663998\n",
      "Iteration 11679, loss = 1839.80042690\n",
      "Iteration 11680, loss = 1839.62428957\n",
      "Iteration 11681, loss = 1839.44822789\n",
      "Iteration 11682, loss = 1839.27224179\n",
      "Iteration 11683, loss = 1839.09633117\n",
      "Iteration 11684, loss = 1838.92049595\n",
      "Iteration 11685, loss = 1838.74473605\n",
      "Iteration 11686, loss = 1838.56905138\n",
      "Iteration 11687, loss = 1838.39344186\n",
      "Iteration 11688, loss = 1838.21790740\n",
      "Iteration 11689, loss = 1838.04244791\n",
      "Iteration 11690, loss = 1837.86706331\n",
      "Iteration 11691, loss = 1837.69175353\n",
      "Iteration 11692, loss = 1837.51651847\n",
      "Iteration 11693, loss = 1837.34135804\n",
      "Iteration 11694, loss = 1837.16627217\n",
      "Iteration 11695, loss = 1836.99126077\n",
      "Iteration 11696, loss = 1836.81632376\n",
      "Iteration 11697, loss = 1836.64146105\n",
      "Iteration 11698, loss = 1836.46667256\n",
      "Iteration 11699, loss = 1836.29195820\n",
      "Iteration 11700, loss = 1836.11731790\n",
      "Iteration 11701, loss = 1835.94275156\n",
      "Iteration 11702, loss = 1835.76825911\n",
      "Iteration 11703, loss = 1835.59384047\n",
      "Iteration 11704, loss = 1835.41949554\n",
      "Iteration 11705, loss = 1835.24522425\n",
      "Iteration 11706, loss = 1835.07102651\n",
      "Iteration 11707, loss = 1834.89690224\n",
      "Iteration 11708, loss = 1834.72285137\n",
      "Iteration 11709, loss = 1834.54887380\n",
      "Iteration 11710, loss = 1834.37496945\n",
      "Iteration 11711, loss = 1834.20113824\n",
      "Iteration 11712, loss = 1834.02738010\n",
      "Iteration 11713, loss = 1833.85369493\n",
      "Iteration 11714, loss = 1833.68008266\n",
      "Iteration 11715, loss = 1833.50654320\n",
      "Iteration 11716, loss = 1833.33307648\n",
      "Iteration 11717, loss = 1833.15968241\n",
      "Iteration 11718, loss = 1832.98636091\n",
      "Iteration 11719, loss = 1832.81311189\n",
      "Iteration 11720, loss = 1832.63993529\n",
      "Iteration 11721, loss = 1832.46683101\n",
      "Iteration 11722, loss = 1832.29379898\n",
      "Iteration 11723, loss = 1832.12083911\n",
      "Iteration 11724, loss = 1831.94795133\n",
      "Iteration 11725, loss = 1831.77513555\n",
      "Iteration 11726, loss = 1831.60239169\n",
      "Iteration 11727, loss = 1831.42971968\n",
      "Iteration 11728, loss = 1831.25711943\n",
      "Iteration 11729, loss = 1831.08459086\n",
      "Iteration 11730, loss = 1830.91213390\n",
      "Iteration 11731, loss = 1830.73974845\n",
      "Iteration 11732, loss = 1830.56743446\n",
      "Iteration 11733, loss = 1830.39519182\n",
      "Iteration 11734, loss = 1830.22302047\n",
      "Iteration 11735, loss = 1830.05092033\n",
      "Iteration 11736, loss = 1829.87889131\n",
      "Iteration 11737, loss = 1829.70693333\n",
      "Iteration 11738, loss = 1829.53504632\n",
      "Iteration 11739, loss = 1829.36323021\n",
      "Iteration 11740, loss = 1829.19148490\n",
      "Iteration 11741, loss = 1829.01981032\n",
      "Iteration 11742, loss = 1828.84820639\n",
      "Iteration 11743, loss = 1828.67667304\n",
      "Iteration 11744, loss = 1828.50521018\n",
      "Iteration 11745, loss = 1828.33381773\n",
      "Iteration 11746, loss = 1828.16249563\n",
      "Iteration 11747, loss = 1827.99124379\n",
      "Iteration 11748, loss = 1827.82006212\n",
      "Iteration 11749, loss = 1827.64895057\n",
      "Iteration 11750, loss = 1827.47790904\n",
      "Iteration 11751, loss = 1827.30693746\n",
      "Iteration 11752, loss = 1827.13603575\n",
      "Iteration 11753, loss = 1826.96520383\n",
      "Iteration 11754, loss = 1826.79444163\n",
      "Iteration 11755, loss = 1826.62374907\n",
      "Iteration 11756, loss = 1826.45312608\n",
      "Iteration 11757, loss = 1826.28257256\n",
      "Iteration 11758, loss = 1826.11208846\n",
      "Iteration 11759, loss = 1825.94167369\n",
      "Iteration 11760, loss = 1825.77132817\n",
      "Iteration 11761, loss = 1825.60105184\n",
      "Iteration 11762, loss = 1825.43084460\n",
      "Iteration 11763, loss = 1825.26070639\n",
      "Iteration 11764, loss = 1825.09063713\n",
      "Iteration 11765, loss = 1824.92063674\n",
      "Iteration 11766, loss = 1824.75070515\n",
      "Iteration 11767, loss = 1824.58084228\n",
      "Iteration 11768, loss = 1824.41104806\n",
      "Iteration 11769, loss = 1824.24132240\n",
      "Iteration 11770, loss = 1824.07166524\n",
      "Iteration 11771, loss = 1823.90207650\n",
      "Iteration 11772, loss = 1823.73255610\n",
      "Iteration 11773, loss = 1823.56310397\n",
      "Iteration 11774, loss = 1823.39372004\n",
      "Iteration 11775, loss = 1823.22440422\n",
      "Iteration 11776, loss = 1823.05515644\n",
      "Iteration 11777, loss = 1822.88597663\n",
      "Iteration 11778, loss = 1822.71686471\n",
      "Iteration 11779, loss = 1822.54782061\n",
      "Iteration 11780, loss = 1822.37884426\n",
      "Iteration 11781, loss = 1822.20993557\n",
      "Iteration 11782, loss = 1822.04109448\n",
      "Iteration 11783, loss = 1821.87232091\n",
      "Iteration 11784, loss = 1821.70361479\n",
      "Iteration 11785, loss = 1821.53497604\n",
      "Iteration 11786, loss = 1821.36640458\n",
      "Iteration 11787, loss = 1821.19790036\n",
      "Iteration 11788, loss = 1821.02946328\n",
      "Iteration 11789, loss = 1820.86109328\n",
      "Iteration 11790, loss = 1820.69279028\n",
      "Iteration 11791, loss = 1820.52455421\n",
      "Iteration 11792, loss = 1820.35638500\n",
      "Iteration 11793, loss = 1820.18828258\n",
      "Iteration 11794, loss = 1820.02024686\n",
      "Iteration 11795, loss = 1819.85227778\n",
      "Iteration 11796, loss = 1819.68437527\n",
      "Iteration 11797, loss = 1819.51653925\n",
      "Iteration 11798, loss = 1819.34876964\n",
      "Iteration 11799, loss = 1819.18106639\n",
      "Iteration 11800, loss = 1819.01342940\n",
      "Iteration 11801, loss = 1818.84585862\n",
      "Iteration 11802, loss = 1818.67835397\n",
      "Iteration 11803, loss = 1818.51091537\n",
      "Iteration 11804, loss = 1818.34354276\n",
      "Iteration 11805, loss = 1818.17623606\n",
      "Iteration 11806, loss = 1818.00899520\n",
      "Iteration 11807, loss = 1817.84182011\n",
      "Iteration 11808, loss = 1817.67471072\n",
      "Iteration 11809, loss = 1817.50766695\n",
      "Iteration 11810, loss = 1817.34068874\n",
      "Iteration 11811, loss = 1817.17377601\n",
      "Iteration 11812, loss = 1817.00692869\n",
      "Iteration 11813, loss = 1816.84014671\n",
      "Iteration 11814, loss = 1816.67343000\n",
      "Iteration 11815, loss = 1816.50677849\n",
      "Iteration 11816, loss = 1816.34019210\n",
      "Iteration 11817, loss = 1816.17367077\n",
      "Iteration 11818, loss = 1816.00721443\n",
      "Iteration 11819, loss = 1815.84082300\n",
      "Iteration 11820, loss = 1815.67449641\n",
      "Iteration 11821, loss = 1815.50823460\n",
      "Iteration 11822, loss = 1815.34203749\n",
      "Iteration 11823, loss = 1815.17590501\n",
      "Iteration 11824, loss = 1815.00983710\n",
      "Iteration 11825, loss = 1814.84383368\n",
      "Iteration 11826, loss = 1814.67789468\n",
      "Iteration 11827, loss = 1814.51202003\n",
      "Iteration 11828, loss = 1814.34620967\n",
      "Iteration 11829, loss = 1814.18046352\n",
      "Iteration 11830, loss = 1814.01478152\n",
      "Iteration 11831, loss = 1813.84916359\n",
      "Iteration 11832, loss = 1813.68360966\n",
      "Iteration 11833, loss = 1813.51811967\n",
      "Iteration 11834, loss = 1813.35269356\n",
      "Iteration 11835, loss = 1813.18733124\n",
      "Iteration 11836, loss = 1813.02203265\n",
      "Iteration 11837, loss = 1812.85679774\n",
      "Iteration 11838, loss = 1812.69162644\n",
      "Iteration 11839, loss = 1812.52651870\n",
      "Iteration 11840, loss = 1812.36147447\n",
      "Iteration 11841, loss = 1812.19649375\n",
      "Iteration 11842, loss = 1812.03157655\n",
      "Iteration 11843, loss = 1811.86672299\n",
      "Iteration 11844, loss = 1811.70193333\n",
      "Iteration 11845, loss = 1811.53720806\n",
      "Iteration 11846, loss = 1811.37254816\n",
      "Iteration 11847, loss = 1811.20795534\n",
      "Iteration 11848, loss = 1811.04343226\n",
      "Iteration 11849, loss = 1810.87898231\n",
      "Iteration 11850, loss = 1810.71460721\n",
      "Iteration 11851, loss = 1810.55030161\n",
      "Iteration 11852, loss = 1810.38604535\n",
      "Iteration 11853, loss = 1810.22181058\n",
      "Iteration 11854, loss = 1810.05758856\n",
      "Iteration 11855, loss = 1809.89341456\n",
      "Iteration 11856, loss = 1809.72934151\n",
      "Iteration 11857, loss = 1809.56538723\n",
      "Iteration 11858, loss = 1809.40151717\n",
      "Iteration 11859, loss = 1809.23767916\n",
      "Iteration 11860, loss = 1809.07385667\n",
      "Iteration 11861, loss = 1808.91008829\n",
      "Iteration 11862, loss = 1808.74641803\n",
      "Iteration 11863, loss = 1808.58283983\n",
      "Iteration 11864, loss = 1808.41931412\n",
      "Iteration 11865, loss = 1808.25582133\n",
      "Iteration 11866, loss = 1808.09238002\n",
      "Iteration 11867, loss = 1807.92901617\n",
      "Iteration 11868, loss = 1807.76573200\n",
      "Iteration 11869, loss = 1807.60250935\n",
      "Iteration 11870, loss = 1807.43933356\n",
      "Iteration 11871, loss = 1807.27620918\n",
      "Iteration 11872, loss = 1807.11315280\n",
      "Iteration 11873, loss = 1806.95017087\n",
      "Iteration 11874, loss = 1806.78725186\n",
      "Iteration 11875, loss = 1806.62438356\n",
      "Iteration 11876, loss = 1806.46156963\n",
      "Iteration 11877, loss = 1806.29882206\n",
      "Iteration 11878, loss = 1806.13614334\n",
      "Iteration 11879, loss = 1805.97352533\n",
      "Iteration 11880, loss = 1805.81096220\n",
      "Iteration 11881, loss = 1805.64845682\n",
      "Iteration 11882, loss = 1805.48601477\n",
      "Iteration 11883, loss = 1805.32363721\n",
      "Iteration 11884, loss = 1805.16132066\n",
      "Iteration 11885, loss = 1804.99906179\n",
      "Iteration 11886, loss = 1804.83686105\n",
      "Iteration 11887, loss = 1804.67472156\n",
      "Iteration 11888, loss = 1804.51264499\n",
      "Iteration 11889, loss = 1804.35062948\n",
      "Iteration 11890, loss = 1804.18867231\n",
      "Iteration 11891, loss = 1804.02677350\n",
      "Iteration 11892, loss = 1803.86493524\n",
      "Iteration 11893, loss = 1803.70315865\n",
      "Iteration 11894, loss = 1803.54144246\n",
      "Iteration 11895, loss = 1803.37978509\n",
      "Iteration 11896, loss = 1803.21818654\n",
      "Iteration 11897, loss = 1803.05664785\n",
      "Iteration 11898, loss = 1802.89516956\n",
      "Iteration 11899, loss = 1802.73375128\n",
      "Iteration 11900, loss = 1802.57239225\n",
      "Iteration 11901, loss = 1802.41109209\n",
      "Iteration 11902, loss = 1802.24985108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11903, loss = 1802.08866972\n",
      "Iteration 11904, loss = 1801.92754809\n",
      "Iteration 11905, loss = 1801.76648567\n",
      "Iteration 11906, loss = 1801.60548197\n",
      "Iteration 11907, loss = 1801.44453707\n",
      "Iteration 11908, loss = 1801.28365133\n",
      "Iteration 11909, loss = 1801.12282483\n",
      "Iteration 11910, loss = 1800.96205727\n",
      "Iteration 11911, loss = 1800.80134838\n",
      "Iteration 11912, loss = 1800.64069807\n",
      "Iteration 11913, loss = 1800.48010643\n",
      "Iteration 11914, loss = 1800.31957352\n",
      "Iteration 11915, loss = 1800.15909929\n",
      "Iteration 11916, loss = 1799.99868358\n",
      "Iteration 11917, loss = 1799.83832622\n",
      "Iteration 11918, loss = 1799.67802713\n",
      "Iteration 11919, loss = 1799.51778638\n",
      "Iteration 11920, loss = 1799.35760397\n",
      "Iteration 11921, loss = 1799.19747982\n",
      "Iteration 11922, loss = 1799.03741376\n",
      "Iteration 11923, loss = 1798.87740571\n",
      "Iteration 11924, loss = 1798.71745565\n",
      "Iteration 11925, loss = 1798.55756356\n",
      "Iteration 11926, loss = 1798.39772939\n",
      "Iteration 11927, loss = 1798.23795307\n",
      "Iteration 11928, loss = 1798.07823451\n",
      "Iteration 11929, loss = 1797.91857362\n",
      "Iteration 11930, loss = 1797.75897035\n",
      "Iteration 11931, loss = 1797.59942468\n",
      "Iteration 11932, loss = 1797.43993655\n",
      "Iteration 11933, loss = 1797.28050590\n",
      "Iteration 11934, loss = 1797.12113265\n",
      "Iteration 11935, loss = 1796.96181671\n",
      "Iteration 11936, loss = 1796.80255805\n",
      "Iteration 11937, loss = 1796.64335662\n",
      "Iteration 11938, loss = 1796.48421236\n",
      "Iteration 11939, loss = 1796.32512520\n",
      "Iteration 11940, loss = 1796.16609508\n",
      "Iteration 11941, loss = 1796.00712194\n",
      "Iteration 11942, loss = 1795.84820572\n",
      "Iteration 11943, loss = 1795.68934635\n",
      "Iteration 11944, loss = 1795.53054379\n",
      "Iteration 11945, loss = 1795.37179798\n",
      "Iteration 11946, loss = 1795.21310886\n",
      "Iteration 11947, loss = 1795.05447635\n",
      "Iteration 11948, loss = 1794.89590041\n",
      "Iteration 11949, loss = 1794.73738097\n",
      "Iteration 11950, loss = 1794.57891797\n",
      "Iteration 11951, loss = 1794.42051137\n",
      "Iteration 11952, loss = 1794.26216109\n",
      "Iteration 11953, loss = 1794.10386709\n",
      "Iteration 11954, loss = 1793.94562929\n",
      "Iteration 11955, loss = 1793.78744765\n",
      "Iteration 11956, loss = 1793.62932209\n",
      "Iteration 11957, loss = 1793.47125257\n",
      "Iteration 11958, loss = 1793.31323903\n",
      "Iteration 11959, loss = 1793.15528141\n",
      "Iteration 11960, loss = 1792.99737965\n",
      "Iteration 11961, loss = 1792.83953369\n",
      "Iteration 11962, loss = 1792.68174347\n",
      "Iteration 11963, loss = 1792.52400893\n",
      "Iteration 11964, loss = 1792.36633002\n",
      "Iteration 11965, loss = 1792.20870668\n",
      "Iteration 11966, loss = 1792.05113885\n",
      "Iteration 11967, loss = 1791.89362648\n",
      "Iteration 11968, loss = 1791.73616950\n",
      "Iteration 11969, loss = 1791.57876786\n",
      "Iteration 11970, loss = 1791.42142150\n",
      "Iteration 11971, loss = 1791.26413036\n",
      "Iteration 11972, loss = 1791.10689439\n",
      "Iteration 11973, loss = 1790.94971352\n",
      "Iteration 11974, loss = 1790.79258771\n",
      "Iteration 11975, loss = 1790.63551689\n",
      "Iteration 11976, loss = 1790.47850101\n",
      "Iteration 11977, loss = 1790.32154000\n",
      "Iteration 11978, loss = 1790.16463382\n",
      "Iteration 11979, loss = 1790.00778241\n",
      "Iteration 11980, loss = 1789.85098570\n",
      "Iteration 11981, loss = 1789.69424365\n",
      "Iteration 11982, loss = 1789.53755620\n",
      "Iteration 11983, loss = 1789.38092328\n",
      "Iteration 11984, loss = 1789.22434484\n",
      "Iteration 11985, loss = 1789.06782084\n",
      "Iteration 11986, loss = 1788.91135120\n",
      "Iteration 11987, loss = 1788.75493587\n",
      "Iteration 11988, loss = 1788.59857481\n",
      "Iteration 11989, loss = 1788.44226794\n",
      "Iteration 11990, loss = 1788.28601522\n",
      "Iteration 11991, loss = 1788.12981659\n",
      "Iteration 11992, loss = 1787.97367200\n",
      "Iteration 11993, loss = 1787.81758138\n",
      "Iteration 11994, loss = 1787.66154469\n",
      "Iteration 11995, loss = 1787.50556186\n",
      "Iteration 11996, loss = 1787.34963284\n",
      "Iteration 11997, loss = 1787.19375758\n",
      "Iteration 11998, loss = 1787.03793601\n",
      "Iteration 11999, loss = 1786.88216810\n",
      "Iteration 12000, loss = 1786.72645377\n",
      "Iteration 12001, loss = 1786.57079297\n",
      "Iteration 12002, loss = 1786.41518566\n",
      "Iteration 12003, loss = 1786.25963177\n",
      "Iteration 12004, loss = 1786.10413125\n",
      "Iteration 12005, loss = 1785.94868404\n",
      "Iteration 12006, loss = 1785.79329009\n",
      "Iteration 12007, loss = 1785.63794935\n",
      "Iteration 12008, loss = 1785.48266175\n",
      "Iteration 12009, loss = 1785.32742726\n",
      "Iteration 12010, loss = 1785.17224580\n",
      "Iteration 12011, loss = 1785.01711733\n",
      "Iteration 12012, loss = 1784.86204179\n",
      "Iteration 12013, loss = 1784.70701912\n",
      "Iteration 12014, loss = 1784.55204929\n",
      "Iteration 12015, loss = 1784.39713222\n",
      "Iteration 12016, loss = 1784.24226786\n",
      "Iteration 12017, loss = 1784.08745617\n",
      "Iteration 12018, loss = 1783.93269708\n",
      "Iteration 12019, loss = 1783.77799055\n",
      "Iteration 12020, loss = 1783.62333651\n",
      "Iteration 12021, loss = 1783.46873492\n",
      "Iteration 12022, loss = 1783.31418572\n",
      "Iteration 12023, loss = 1783.15968887\n",
      "Iteration 12024, loss = 1783.00524429\n",
      "Iteration 12025, loss = 1782.85085195\n",
      "Iteration 12026, loss = 1782.69651178\n",
      "Iteration 12027, loss = 1782.54222374\n",
      "Iteration 12028, loss = 1782.38798777\n",
      "Iteration 12029, loss = 1782.23380382\n",
      "Iteration 12030, loss = 1782.07967183\n",
      "Iteration 12031, loss = 1781.92559176\n",
      "Iteration 12032, loss = 1781.77156354\n",
      "Iteration 12033, loss = 1781.61758713\n",
      "Iteration 12034, loss = 1781.46366247\n",
      "Iteration 12035, loss = 1781.30978952\n",
      "Iteration 12036, loss = 1781.15596821\n",
      "Iteration 12037, loss = 1781.00219849\n",
      "Iteration 12038, loss = 1780.84848032\n",
      "Iteration 12039, loss = 1780.69481364\n",
      "Iteration 12040, loss = 1780.54119840\n",
      "Iteration 12041, loss = 1780.38763454\n",
      "Iteration 12042, loss = 1780.23412201\n",
      "Iteration 12043, loss = 1780.08066077\n",
      "Iteration 12044, loss = 1779.92725075\n",
      "Iteration 12045, loss = 1779.77389192\n",
      "Iteration 12046, loss = 1779.62058420\n",
      "Iteration 12047, loss = 1779.46732756\n",
      "Iteration 12048, loss = 1779.31412194\n",
      "Iteration 12049, loss = 1779.16096729\n",
      "Iteration 12050, loss = 1779.00786356\n",
      "Iteration 12051, loss = 1778.85481069\n",
      "Iteration 12052, loss = 1778.70180864\n",
      "Iteration 12053, loss = 1778.54885736\n",
      "Iteration 12054, loss = 1778.39595679\n",
      "Iteration 12055, loss = 1778.24310689\n",
      "Iteration 12056, loss = 1778.09030761\n",
      "Iteration 12057, loss = 1777.93755890\n",
      "Iteration 12058, loss = 1777.78486075\n",
      "Iteration 12059, loss = 1777.63221311\n",
      "Iteration 12060, loss = 1777.47961599\n",
      "Iteration 12061, loss = 1777.32706943\n",
      "Iteration 12062, loss = 1777.17457352\n",
      "Iteration 12063, loss = 1777.02212850\n",
      "Iteration 12064, loss = 1776.86973481\n",
      "Iteration 12065, loss = 1776.71739328\n",
      "Iteration 12066, loss = 1776.56510536\n",
      "Iteration 12067, loss = 1776.41287351\n",
      "Iteration 12068, loss = 1776.26070127\n",
      "Iteration 12069, loss = 1776.10859267\n",
      "Iteration 12070, loss = 1775.95654802\n",
      "Iteration 12071, loss = 1775.80455581\n",
      "Iteration 12072, loss = 1775.65258385\n",
      "Iteration 12073, loss = 1775.50059712\n",
      "Iteration 12074, loss = 1775.34860588\n",
      "Iteration 12075, loss = 1775.19668085\n",
      "Iteration 12076, loss = 1775.04488034\n",
      "Iteration 12077, loss = 1774.89318561\n",
      "Iteration 12078, loss = 1774.74152689\n",
      "Iteration 12079, loss = 1774.58985683\n",
      "Iteration 12080, loss = 1774.43820093\n",
      "Iteration 12081, loss = 1774.28662442\n",
      "Iteration 12082, loss = 1774.13514744\n",
      "Iteration 12083, loss = 1773.98372661\n",
      "Iteration 12084, loss = 1773.83231816\n",
      "Iteration 12085, loss = 1773.68093189\n",
      "Iteration 12086, loss = 1773.52961060\n",
      "Iteration 12087, loss = 1773.37836933\n",
      "Iteration 12088, loss = 1773.22718111\n",
      "Iteration 12089, loss = 1773.07601905\n",
      "Iteration 12090, loss = 1772.92489079\n",
      "Iteration 12091, loss = 1772.77382271\n",
      "Iteration 12092, loss = 1772.62282183\n",
      "Iteration 12093, loss = 1772.47186969\n",
      "Iteration 12094, loss = 1772.32095126\n",
      "Iteration 12095, loss = 1772.17007440\n",
      "Iteration 12096, loss = 1772.01925525\n",
      "Iteration 12097, loss = 1771.86849482\n",
      "Iteration 12098, loss = 1771.71778046\n",
      "Iteration 12099, loss = 1771.56710531\n",
      "Iteration 12100, loss = 1771.41647624\n",
      "Iteration 12101, loss = 1771.26590188\n",
      "Iteration 12102, loss = 1771.11538088\n",
      "Iteration 12103, loss = 1770.96490566\n",
      "Iteration 12104, loss = 1770.81447339\n",
      "Iteration 12105, loss = 1770.66408867\n",
      "Iteration 12106, loss = 1770.51375608\n",
      "Iteration 12107, loss = 1770.36347421\n",
      "Iteration 12108, loss = 1770.21323851\n",
      "Iteration 12109, loss = 1770.06304769\n",
      "Iteration 12110, loss = 1769.91290474\n",
      "Iteration 12111, loss = 1769.76281220\n",
      "Iteration 12112, loss = 1769.61276889\n",
      "Iteration 12113, loss = 1769.46277212\n",
      "Iteration 12114, loss = 1769.31282132\n",
      "Iteration 12115, loss = 1769.16291827\n",
      "Iteration 12116, loss = 1769.01306432\n",
      "Iteration 12117, loss = 1768.86325877\n",
      "Iteration 12118, loss = 1768.71350010\n",
      "Iteration 12119, loss = 1768.56378791\n",
      "Iteration 12120, loss = 1768.41412311\n",
      "Iteration 12121, loss = 1768.26450653\n",
      "Iteration 12122, loss = 1768.11493788\n",
      "Iteration 12123, loss = 1767.96541625\n",
      "Iteration 12124, loss = 1767.81594124\n",
      "Iteration 12125, loss = 1767.66651332\n",
      "Iteration 12126, loss = 1767.51713301\n",
      "Iteration 12127, loss = 1767.36780023\n",
      "Iteration 12128, loss = 1767.21851444\n",
      "Iteration 12129, loss = 1767.06927533\n",
      "Iteration 12130, loss = 1766.92008304\n",
      "Iteration 12131, loss = 1766.77093788\n",
      "Iteration 12132, loss = 1766.62183988\n",
      "Iteration 12133, loss = 1766.47278877\n",
      "Iteration 12134, loss = 1766.32378429\n",
      "Iteration 12135, loss = 1766.17482641\n",
      "Iteration 12136, loss = 1766.02591528\n",
      "Iteration 12137, loss = 1765.87705098\n",
      "Iteration 12138, loss = 1765.72823338\n",
      "Iteration 12139, loss = 1765.57946230\n",
      "Iteration 12140, loss = 1765.43073764\n",
      "Iteration 12141, loss = 1765.28205943\n",
      "Iteration 12142, loss = 1765.13342772\n",
      "Iteration 12143, loss = 1764.98484248\n",
      "Iteration 12144, loss = 1764.83630360\n",
      "Iteration 12145, loss = 1764.68781097\n",
      "Iteration 12146, loss = 1764.53936454\n",
      "Iteration 12147, loss = 1764.39096433\n",
      "Iteration 12148, loss = 1764.24261033\n",
      "Iteration 12149, loss = 1764.09430248\n",
      "Iteration 12150, loss = 1763.94604069\n",
      "Iteration 12151, loss = 1763.79782491\n",
      "Iteration 12152, loss = 1763.64965509\n",
      "Iteration 12153, loss = 1763.50153121\n",
      "Iteration 12154, loss = 1763.35345325\n",
      "Iteration 12155, loss = 1763.20542115\n",
      "Iteration 12156, loss = 1763.05743485\n",
      "Iteration 12157, loss = 1762.90949430\n",
      "Iteration 12158, loss = 1762.76159944\n",
      "Iteration 12159, loss = 1762.61375026\n",
      "Iteration 12160, loss = 1762.46594672\n",
      "Iteration 12161, loss = 1762.31818876\n",
      "Iteration 12162, loss = 1762.17047634\n",
      "Iteration 12163, loss = 1762.02280940\n",
      "Iteration 12164, loss = 1761.87518789\n",
      "Iteration 12165, loss = 1761.72761179\n",
      "Iteration 12166, loss = 1761.58008105\n",
      "Iteration 12167, loss = 1761.43259563\n",
      "Iteration 12168, loss = 1761.28515548\n",
      "Iteration 12169, loss = 1761.13776055\n",
      "Iteration 12170, loss = 1760.99041079\n",
      "Iteration 12171, loss = 1760.84310616\n",
      "Iteration 12172, loss = 1760.69584663\n",
      "Iteration 12173, loss = 1760.54863215\n",
      "Iteration 12174, loss = 1760.40146268\n",
      "Iteration 12175, loss = 1760.25433816\n",
      "Iteration 12176, loss = 1760.10725856\n",
      "Iteration 12177, loss = 1759.96022383\n",
      "Iteration 12178, loss = 1759.81323392\n",
      "Iteration 12179, loss = 1759.66628880\n",
      "Iteration 12180, loss = 1759.51938842\n",
      "Iteration 12181, loss = 1759.37253274\n",
      "Iteration 12182, loss = 1759.22572171\n",
      "Iteration 12183, loss = 1759.07895529\n",
      "Iteration 12184, loss = 1758.93223344\n",
      "Iteration 12185, loss = 1758.78555611\n",
      "Iteration 12186, loss = 1758.63892326\n",
      "Iteration 12187, loss = 1758.49233485\n",
      "Iteration 12188, loss = 1758.34579083\n",
      "Iteration 12189, loss = 1758.19929116\n",
      "Iteration 12190, loss = 1758.05283580\n",
      "Iteration 12191, loss = 1757.90642471\n",
      "Iteration 12192, loss = 1757.76005783\n",
      "Iteration 12193, loss = 1757.61373513\n",
      "Iteration 12194, loss = 1757.46745657\n",
      "Iteration 12195, loss = 1757.32122210\n",
      "Iteration 12196, loss = 1757.17503168\n",
      "Iteration 12197, loss = 1757.02888527\n",
      "Iteration 12198, loss = 1756.88278282\n",
      "Iteration 12199, loss = 1756.73672430\n",
      "Iteration 12200, loss = 1756.59070965\n",
      "Iteration 12201, loss = 1756.44473884\n",
      "Iteration 12202, loss = 1756.29881183\n",
      "Iteration 12203, loss = 1756.15292857\n",
      "Iteration 12204, loss = 1756.00708902\n",
      "Iteration 12205, loss = 1755.86129313\n",
      "Iteration 12206, loss = 1755.71554087\n",
      "Iteration 12207, loss = 1755.56983220\n",
      "Iteration 12208, loss = 1755.42416706\n",
      "Iteration 12209, loss = 1755.27854543\n",
      "Iteration 12210, loss = 1755.13296725\n",
      "Iteration 12211, loss = 1754.98743249\n",
      "Iteration 12212, loss = 1754.84194110\n",
      "Iteration 12213, loss = 1754.69649304\n",
      "Iteration 12214, loss = 1754.55108827\n",
      "Iteration 12215, loss = 1754.40572675\n",
      "Iteration 12216, loss = 1754.26040844\n",
      "Iteration 12217, loss = 1754.11513329\n",
      "Iteration 12218, loss = 1753.96990126\n",
      "Iteration 12219, loss = 1753.82471232\n",
      "Iteration 12220, loss = 1753.67956641\n",
      "Iteration 12221, loss = 1753.53446351\n",
      "Iteration 12222, loss = 1753.38940356\n",
      "Iteration 12223, loss = 1753.24438653\n",
      "Iteration 12224, loss = 1753.09941237\n",
      "Iteration 12225, loss = 1752.95448105\n",
      "Iteration 12226, loss = 1752.80959251\n",
      "Iteration 12227, loss = 1752.66474673\n",
      "Iteration 12228, loss = 1752.51994366\n",
      "Iteration 12229, loss = 1752.37518326\n",
      "Iteration 12230, loss = 1752.23046549\n",
      "Iteration 12231, loss = 1752.08579031\n",
      "Iteration 12232, loss = 1751.94115767\n",
      "Iteration 12233, loss = 1751.79656754\n",
      "Iteration 12234, loss = 1751.65201987\n",
      "Iteration 12235, loss = 1751.50751463\n",
      "Iteration 12236, loss = 1751.36305177\n",
      "Iteration 12237, loss = 1751.21863126\n",
      "Iteration 12238, loss = 1751.07425305\n",
      "Iteration 12239, loss = 1750.92991710\n",
      "Iteration 12240, loss = 1750.78562337\n",
      "Iteration 12241, loss = 1750.64137182\n",
      "Iteration 12242, loss = 1750.49716242\n",
      "Iteration 12243, loss = 1750.35299511\n",
      "Iteration 12244, loss = 1750.20886987\n",
      "Iteration 12245, loss = 1750.06478664\n",
      "Iteration 12246, loss = 1749.92074540\n",
      "Iteration 12247, loss = 1749.77674610\n",
      "Iteration 12248, loss = 1749.63278869\n",
      "Iteration 12249, loss = 1749.48887315\n",
      "Iteration 12250, loss = 1749.34499943\n",
      "Iteration 12251, loss = 1749.20116749\n",
      "Iteration 12252, loss = 1749.05737729\n",
      "Iteration 12253, loss = 1748.91362879\n",
      "Iteration 12254, loss = 1748.76992195\n",
      "Iteration 12255, loss = 1748.62625673\n",
      "Iteration 12256, loss = 1748.48263309\n",
      "Iteration 12257, loss = 1748.33905100\n",
      "Iteration 12258, loss = 1748.19551041\n",
      "Iteration 12259, loss = 1748.05201128\n",
      "Iteration 12260, loss = 1747.90855358\n",
      "Iteration 12261, loss = 1747.76513726\n",
      "Iteration 12262, loss = 1747.62176228\n",
      "Iteration 12263, loss = 1747.47842861\n",
      "Iteration 12264, loss = 1747.33513621\n",
      "Iteration 12265, loss = 1747.19188504\n",
      "Iteration 12266, loss = 1747.04867505\n",
      "Iteration 12267, loss = 1746.90550621\n",
      "Iteration 12268, loss = 1746.76237849\n",
      "Iteration 12269, loss = 1746.61929183\n",
      "Iteration 12270, loss = 1746.47624621\n",
      "Iteration 12271, loss = 1746.33324158\n",
      "Iteration 12272, loss = 1746.19027791\n",
      "Iteration 12273, loss = 1746.04735515\n",
      "Iteration 12274, loss = 1745.90447327\n",
      "Iteration 12275, loss = 1745.76163224\n",
      "Iteration 12276, loss = 1745.61883201\n",
      "Iteration 12277, loss = 1745.47607255\n",
      "Iteration 12278, loss = 1745.33335384\n",
      "Iteration 12279, loss = 1745.19067585\n",
      "Iteration 12280, loss = 1745.04803857\n",
      "Iteration 12281, loss = 1744.90544200\n",
      "Iteration 12282, loss = 1744.76288620\n",
      "Iteration 12283, loss = 1744.62037128\n",
      "Iteration 12284, loss = 1744.47789749\n",
      "Iteration 12285, loss = 1744.33546530\n",
      "Iteration 12286, loss = 1744.19307560\n",
      "Iteration 12287, loss = 1744.05072998\n",
      "Iteration 12288, loss = 1743.90843113\n",
      "Iteration 12289, loss = 1743.76618323\n",
      "Iteration 12290, loss = 1743.62399117\n",
      "Iteration 12291, loss = 1743.48185682\n",
      "Iteration 12292, loss = 1743.33976824\n",
      "Iteration 12293, loss = 1743.19768935\n",
      "Iteration 12294, loss = 1743.05557513\n",
      "Iteration 12295, loss = 1742.91343369\n",
      "Iteration 12296, loss = 1742.77134965\n",
      "Iteration 12297, loss = 1742.62939573\n",
      "Iteration 12298, loss = 1742.48754799\n",
      "Iteration 12299, loss = 1742.34571942\n",
      "Iteration 12300, loss = 1742.20385604\n",
      "Iteration 12301, loss = 1742.06199728\n",
      "Iteration 12302, loss = 1741.92022265\n",
      "Iteration 12303, loss = 1741.77854463\n",
      "Iteration 12304, loss = 1741.63690282\n",
      "Iteration 12305, loss = 1741.49525233\n",
      "Iteration 12306, loss = 1741.35361922\n",
      "Iteration 12307, loss = 1741.21205529\n",
      "Iteration 12308, loss = 1741.07056390\n",
      "Iteration 12309, loss = 1740.92910410\n",
      "Iteration 12310, loss = 1740.78765330\n",
      "Iteration 12311, loss = 1740.64623485\n",
      "Iteration 12312, loss = 1740.50487830\n",
      "Iteration 12313, loss = 1740.36357697\n",
      "Iteration 12314, loss = 1740.22230351\n",
      "Iteration 12315, loss = 1740.08105178\n",
      "Iteration 12316, loss = 1739.93984168\n",
      "Iteration 12317, loss = 1739.79868628\n",
      "Iteration 12318, loss = 1739.65757462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12319, loss = 1739.51649173\n",
      "Iteration 12320, loss = 1739.37544013\n",
      "Iteration 12321, loss = 1739.23443284\n",
      "Iteration 12322, loss = 1739.09347322\n",
      "Iteration 12323, loss = 1738.95255226\n",
      "Iteration 12324, loss = 1738.81166322\n",
      "Iteration 12325, loss = 1738.67081043\n",
      "Iteration 12326, loss = 1738.53000118\n",
      "Iteration 12327, loss = 1738.38923515\n",
      "Iteration 12328, loss = 1738.24850618\n",
      "Iteration 12329, loss = 1738.10781174\n",
      "Iteration 12330, loss = 1737.96715566\n",
      "Iteration 12331, loss = 1737.82654164\n",
      "Iteration 12332, loss = 1737.68596820\n",
      "Iteration 12333, loss = 1737.54543169\n",
      "Iteration 12334, loss = 1737.40493151\n",
      "Iteration 12335, loss = 1737.26447024\n",
      "Iteration 12336, loss = 1737.12404954\n",
      "Iteration 12337, loss = 1736.98366815\n",
      "Iteration 12338, loss = 1736.84332407\n",
      "Iteration 12339, loss = 1736.70301719\n",
      "Iteration 12340, loss = 1736.56274906\n",
      "Iteration 12341, loss = 1736.42252052\n",
      "Iteration 12342, loss = 1736.28233071\n",
      "Iteration 12343, loss = 1736.14217847\n",
      "Iteration 12344, loss = 1736.00206378\n",
      "Iteration 12345, loss = 1735.86198755\n",
      "Iteration 12346, loss = 1735.72195025\n",
      "Iteration 12347, loss = 1735.58195133\n",
      "Iteration 12348, loss = 1735.44199013\n",
      "Iteration 12349, loss = 1735.30206661\n",
      "Iteration 12350, loss = 1735.16218123\n",
      "Iteration 12351, loss = 1735.02233429\n",
      "Iteration 12352, loss = 1734.88252552\n",
      "Iteration 12353, loss = 1734.74275450\n",
      "Iteration 12354, loss = 1734.60302113\n",
      "Iteration 12355, loss = 1734.46332565\n",
      "Iteration 12356, loss = 1734.32366824\n",
      "Iteration 12357, loss = 1734.18404880\n",
      "Iteration 12358, loss = 1734.04446706\n",
      "Iteration 12359, loss = 1733.90492290\n",
      "Iteration 12360, loss = 1733.76541641\n",
      "Iteration 12361, loss = 1733.62594769\n",
      "Iteration 12362, loss = 1733.48651673\n",
      "Iteration 12363, loss = 1733.34712338\n",
      "Iteration 12364, loss = 1733.20776752\n",
      "Iteration 12365, loss = 1733.06844912\n",
      "Iteration 12366, loss = 1732.92916826\n",
      "Iteration 12367, loss = 1732.78992494\n",
      "Iteration 12368, loss = 1732.65071909\n",
      "Iteration 12369, loss = 1732.51155061\n",
      "Iteration 12370, loss = 1732.37241944\n",
      "Iteration 12371, loss = 1732.23332559\n",
      "Iteration 12372, loss = 1732.09426907\n",
      "Iteration 12373, loss = 1731.95524984\n",
      "Iteration 12374, loss = 1731.81626785\n",
      "Iteration 12375, loss = 1731.67732302\n",
      "Iteration 12376, loss = 1731.53841533\n",
      "Iteration 12377, loss = 1731.39954477\n",
      "Iteration 12378, loss = 1731.26071132\n",
      "Iteration 12379, loss = 1731.12191494\n",
      "Iteration 12380, loss = 1730.98315558\n",
      "Iteration 12381, loss = 1730.84443319\n",
      "Iteration 12382, loss = 1730.70574775\n",
      "Iteration 12383, loss = 1730.56709923\n",
      "Iteration 12384, loss = 1730.42848760\n",
      "Iteration 12385, loss = 1730.28991284\n",
      "Iteration 12386, loss = 1730.15137489\n",
      "Iteration 12387, loss = 1730.01287371\n",
      "Iteration 12388, loss = 1729.87440929\n",
      "Iteration 12389, loss = 1729.73598157\n",
      "Iteration 12390, loss = 1729.59759055\n",
      "Iteration 12391, loss = 1729.45923618\n",
      "Iteration 12392, loss = 1729.32091842\n",
      "Iteration 12393, loss = 1729.18263724\n",
      "Iteration 12394, loss = 1729.04439261\n",
      "Iteration 12395, loss = 1728.90618449\n",
      "Iteration 12396, loss = 1728.76801285\n",
      "Iteration 12397, loss = 1728.62987766\n",
      "Iteration 12398, loss = 1728.49177889\n",
      "Iteration 12399, loss = 1728.35371649\n",
      "Iteration 12400, loss = 1728.21569044\n",
      "Iteration 12401, loss = 1728.07770070\n",
      "Iteration 12402, loss = 1727.93974724\n",
      "Iteration 12403, loss = 1727.80183002\n",
      "Iteration 12404, loss = 1727.66394902\n",
      "Iteration 12405, loss = 1727.52610420\n",
      "Iteration 12406, loss = 1727.38829553\n",
      "Iteration 12407, loss = 1727.25052297\n",
      "Iteration 12408, loss = 1727.11278649\n",
      "Iteration 12409, loss = 1726.97508605\n",
      "Iteration 12410, loss = 1726.83742163\n",
      "Iteration 12411, loss = 1726.69979319\n",
      "Iteration 12412, loss = 1726.56220070\n",
      "Iteration 12413, loss = 1726.42464412\n",
      "Iteration 12414, loss = 1726.28712343\n",
      "Iteration 12415, loss = 1726.14963858\n",
      "Iteration 12416, loss = 1726.01218955\n",
      "Iteration 12417, loss = 1725.87477630\n",
      "Iteration 12418, loss = 1725.73739880\n",
      "Iteration 12419, loss = 1725.60005702\n",
      "Iteration 12420, loss = 1725.46275093\n",
      "Iteration 12421, loss = 1725.32548048\n",
      "Iteration 12422, loss = 1725.18824566\n",
      "Iteration 12423, loss = 1725.05104642\n",
      "Iteration 12424, loss = 1724.91388274\n",
      "Iteration 12425, loss = 1724.77675458\n",
      "Iteration 12426, loss = 1724.63966191\n",
      "Iteration 12427, loss = 1724.50260469\n",
      "Iteration 12428, loss = 1724.36558290\n",
      "Iteration 12429, loss = 1724.22859650\n",
      "Iteration 12430, loss = 1724.09164546\n",
      "Iteration 12431, loss = 1723.95472975\n",
      "Iteration 12432, loss = 1723.81784933\n",
      "Iteration 12433, loss = 1723.68100417\n",
      "Iteration 12434, loss = 1723.54419425\n",
      "Iteration 12435, loss = 1723.40741952\n",
      "Iteration 12436, loss = 1723.27067996\n",
      "Iteration 12437, loss = 1723.13397553\n",
      "Iteration 12438, loss = 1722.99730620\n",
      "Iteration 12439, loss = 1722.86067194\n",
      "Iteration 12440, loss = 1722.72407272\n",
      "Iteration 12441, loss = 1722.58750850\n",
      "Iteration 12442, loss = 1722.45097926\n",
      "Iteration 12443, loss = 1722.31448495\n",
      "Iteration 12444, loss = 1722.17802556\n",
      "Iteration 12445, loss = 1722.04160104\n",
      "Iteration 12446, loss = 1721.90521137\n",
      "Iteration 12447, loss = 1721.76885651\n",
      "Iteration 12448, loss = 1721.63253644\n",
      "Iteration 12449, loss = 1721.49625111\n",
      "Iteration 12450, loss = 1721.36000050\n",
      "Iteration 12451, loss = 1721.22378458\n",
      "Iteration 12452, loss = 1721.08760332\n",
      "Iteration 12453, loss = 1720.95145667\n",
      "Iteration 12454, loss = 1720.81534462\n",
      "Iteration 12455, loss = 1720.67926713\n",
      "Iteration 12456, loss = 1720.54322416\n",
      "Iteration 12457, loss = 1720.40721570\n",
      "Iteration 12458, loss = 1720.27124169\n",
      "Iteration 12459, loss = 1720.13530212\n",
      "Iteration 12460, loss = 1719.99939696\n",
      "Iteration 12461, loss = 1719.86352616\n",
      "Iteration 12462, loss = 1719.72768970\n",
      "Iteration 12463, loss = 1719.59188756\n",
      "Iteration 12464, loss = 1719.45611968\n",
      "Iteration 12465, loss = 1719.32038606\n",
      "Iteration 12466, loss = 1719.18468665\n",
      "Iteration 12467, loss = 1719.04902142\n",
      "Iteration 12468, loss = 1718.91339034\n",
      "Iteration 12469, loss = 1718.77779338\n",
      "Iteration 12470, loss = 1718.64223052\n",
      "Iteration 12471, loss = 1718.50670171\n",
      "Iteration 12472, loss = 1718.37120693\n",
      "Iteration 12473, loss = 1718.23574614\n",
      "Iteration 12474, loss = 1718.10031932\n",
      "Iteration 12475, loss = 1717.96492643\n",
      "Iteration 12476, loss = 1717.82956745\n",
      "Iteration 12477, loss = 1717.69424234\n",
      "Iteration 12478, loss = 1717.55895107\n",
      "Iteration 12479, loss = 1717.42369361\n",
      "Iteration 12480, loss = 1717.28846992\n",
      "Iteration 12481, loss = 1717.15327999\n",
      "Iteration 12482, loss = 1717.01812378\n",
      "Iteration 12483, loss = 1716.88300125\n",
      "Iteration 12484, loss = 1716.74791238\n",
      "Iteration 12485, loss = 1716.61285713\n",
      "Iteration 12486, loss = 1716.47783548\n",
      "Iteration 12487, loss = 1716.34284739\n",
      "Iteration 12488, loss = 1716.20789284\n",
      "Iteration 12489, loss = 1716.07297179\n",
      "Iteration 12490, loss = 1715.93808421\n",
      "Iteration 12491, loss = 1715.80323008\n",
      "Iteration 12492, loss = 1715.66840935\n",
      "Iteration 12493, loss = 1715.53362201\n",
      "Iteration 12494, loss = 1715.39886801\n",
      "Iteration 12495, loss = 1715.26414734\n",
      "Iteration 12496, loss = 1715.12945995\n",
      "Iteration 12497, loss = 1714.99480583\n",
      "Iteration 12498, loss = 1714.86018494\n",
      "Iteration 12499, loss = 1714.72559725\n",
      "Iteration 12500, loss = 1714.59104274\n",
      "Iteration 12501, loss = 1714.45652139\n",
      "Iteration 12502, loss = 1714.32203317\n",
      "Iteration 12503, loss = 1714.18757808\n",
      "Iteration 12504, loss = 1714.05315614\n",
      "Iteration 12505, loss = 1713.91876738\n",
      "Iteration 12506, loss = 1713.78441191\n",
      "Iteration 12507, loss = 1713.65008996\n",
      "Iteration 12508, loss = 1713.51580197\n",
      "Iteration 12509, loss = 1713.38154874\n",
      "Iteration 12510, loss = 1713.24733181\n",
      "Iteration 12511, loss = 1713.11315379\n",
      "Iteration 12512, loss = 1712.97901903\n",
      "Iteration 12513, loss = 1712.84493325\n",
      "Iteration 12514, loss = 1712.71090073\n",
      "Iteration 12515, loss = 1712.57691402\n",
      "Iteration 12516, loss = 1712.44293916\n",
      "Iteration 12517, loss = 1712.30892105\n",
      "Iteration 12518, loss = 1712.17484676\n",
      "Iteration 12519, loss = 1712.04079847\n",
      "Iteration 12520, loss = 1711.90687639\n",
      "Iteration 12521, loss = 1711.77307770\n",
      "Iteration 12522, loss = 1711.63930644\n",
      "Iteration 12523, loss = 1711.50548441\n",
      "Iteration 12524, loss = 1711.37164104\n",
      "Iteration 12525, loss = 1711.23787170\n",
      "Iteration 12526, loss = 1711.10420464\n",
      "Iteration 12527, loss = 1710.97057406\n",
      "Iteration 12528, loss = 1710.83692106\n",
      "Iteration 12529, loss = 1710.70326995\n",
      "Iteration 12530, loss = 1710.56968312\n",
      "Iteration 12531, loss = 1710.43616856\n",
      "Iteration 12532, loss = 1710.30267793\n",
      "Iteration 12533, loss = 1710.16918320\n",
      "Iteration 12534, loss = 1710.03571294\n",
      "Iteration 12535, loss = 1709.90230217\n",
      "Iteration 12536, loss = 1709.76894053\n",
      "Iteration 12537, loss = 1709.63559542\n",
      "Iteration 12538, loss = 1709.50226283\n",
      "Iteration 12539, loss = 1709.36896785\n",
      "Iteration 12540, loss = 1709.23572294\n",
      "Iteration 12541, loss = 1709.10251232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12542, loss = 1708.96932001\n",
      "Iteration 12543, loss = 1708.83615272\n",
      "Iteration 12544, loss = 1708.70302589\n",
      "Iteration 12545, loss = 1708.56993977\n",
      "Iteration 12546, loss = 1708.43688199\n",
      "Iteration 12547, loss = 1708.30384755\n",
      "Iteration 12548, loss = 1708.17084445\n",
      "Iteration 12549, loss = 1708.03787982\n",
      "Iteration 12550, loss = 1707.90494994\n",
      "Iteration 12551, loss = 1707.77204751\n",
      "Iteration 12552, loss = 1707.63917255\n",
      "Iteration 12553, loss = 1707.50633098\n",
      "Iteration 12554, loss = 1707.37352510\n",
      "Iteration 12555, loss = 1707.24075104\n",
      "Iteration 12556, loss = 1707.10800535\n",
      "Iteration 12557, loss = 1706.97528958\n",
      "Iteration 12558, loss = 1706.84260711\n",
      "Iteration 12559, loss = 1706.70995817\n",
      "Iteration 12560, loss = 1706.57734012\n",
      "Iteration 12561, loss = 1706.44475151\n",
      "Iteration 12562, loss = 1706.31219374\n",
      "Iteration 12563, loss = 1706.17966862\n",
      "Iteration 12564, loss = 1706.04717584\n",
      "Iteration 12565, loss = 1705.91471373\n",
      "Iteration 12566, loss = 1705.78228171\n",
      "Iteration 12567, loss = 1705.64988080\n",
      "Iteration 12568, loss = 1705.51751191\n",
      "Iteration 12569, loss = 1705.38517466\n",
      "Iteration 12570, loss = 1705.25286810\n",
      "Iteration 12571, loss = 1705.12059200\n",
      "Iteration 12572, loss = 1704.98834691\n",
      "Iteration 12573, loss = 1704.85613335\n",
      "Iteration 12574, loss = 1704.72395107\n",
      "Iteration 12575, loss = 1704.59179952\n",
      "Iteration 12576, loss = 1704.45967851\n",
      "Iteration 12577, loss = 1704.32758838\n",
      "Iteration 12578, loss = 1704.19552941\n",
      "Iteration 12579, loss = 1704.06350148\n",
      "Iteration 12580, loss = 1703.93150424\n",
      "Iteration 12581, loss = 1703.79953757\n",
      "Iteration 12582, loss = 1703.66760160\n",
      "Iteration 12583, loss = 1703.53569651\n",
      "Iteration 12584, loss = 1703.40382225\n",
      "Iteration 12585, loss = 1703.27197863\n",
      "Iteration 12586, loss = 1703.14016552\n",
      "Iteration 12587, loss = 1703.00838296\n",
      "Iteration 12588, loss = 1702.87663105\n",
      "Iteration 12589, loss = 1702.74490978\n",
      "Iteration 12590, loss = 1702.61321906\n",
      "Iteration 12591, loss = 1702.48155876\n",
      "Iteration 12592, loss = 1702.34992888\n",
      "Iteration 12593, loss = 1702.21832945\n",
      "Iteration 12594, loss = 1702.08676049\n",
      "Iteration 12595, loss = 1701.95522193\n",
      "Iteration 12596, loss = 1701.82371372\n",
      "Iteration 12597, loss = 1701.69223578\n",
      "Iteration 12598, loss = 1701.56078813\n",
      "Iteration 12599, loss = 1701.42937077\n",
      "Iteration 12600, loss = 1701.29798368\n",
      "Iteration 12601, loss = 1701.16662681\n",
      "Iteration 12602, loss = 1701.03530010\n",
      "Iteration 12603, loss = 1700.90400352\n",
      "Iteration 12604, loss = 1700.77273707\n",
      "Iteration 12605, loss = 1700.64150074\n",
      "Iteration 12606, loss = 1700.51029448\n",
      "Iteration 12607, loss = 1700.37911827\n",
      "Iteration 12608, loss = 1700.24797206\n",
      "Iteration 12609, loss = 1700.11685582\n",
      "Iteration 12610, loss = 1699.98576954\n",
      "Iteration 12611, loss = 1699.85471319\n",
      "Iteration 12612, loss = 1699.72368676\n",
      "Iteration 12613, loss = 1699.59269019\n",
      "Iteration 12614, loss = 1699.46172345\n",
      "Iteration 12615, loss = 1699.33078653\n",
      "Iteration 12616, loss = 1699.19987939\n",
      "Iteration 12617, loss = 1699.06900201\n",
      "Iteration 12618, loss = 1698.93815437\n",
      "Iteration 12619, loss = 1698.80733642\n",
      "Iteration 12620, loss = 1698.67654815\n",
      "Iteration 12621, loss = 1698.54578952\n",
      "Iteration 12622, loss = 1698.41506050\n",
      "Iteration 12623, loss = 1698.28436107\n",
      "Iteration 12624, loss = 1698.15369120\n",
      "Iteration 12625, loss = 1698.02305087\n",
      "Iteration 12626, loss = 1697.89244003\n",
      "Iteration 12627, loss = 1697.76185867\n",
      "Iteration 12628, loss = 1697.63130676\n",
      "Iteration 12629, loss = 1697.50078426\n",
      "Iteration 12630, loss = 1697.37029115\n",
      "Iteration 12631, loss = 1697.23982741\n",
      "Iteration 12632, loss = 1697.10939300\n",
      "Iteration 12633, loss = 1696.97898789\n",
      "Iteration 12634, loss = 1696.84861206\n",
      "Iteration 12635, loss = 1696.71826547\n",
      "Iteration 12636, loss = 1696.58794811\n",
      "Iteration 12637, loss = 1696.45765994\n",
      "Iteration 12638, loss = 1696.32740093\n",
      "Iteration 12639, loss = 1696.19717106\n",
      "Iteration 12640, loss = 1696.06697030\n",
      "Iteration 12641, loss = 1695.93679861\n",
      "Iteration 12642, loss = 1695.80665598\n",
      "Iteration 12643, loss = 1695.67654237\n",
      "Iteration 12644, loss = 1695.54645775\n",
      "Iteration 12645, loss = 1695.41640210\n",
      "Iteration 12646, loss = 1695.28637539\n",
      "Iteration 12647, loss = 1695.15637758\n",
      "Iteration 12648, loss = 1695.02640866\n",
      "Iteration 12649, loss = 1694.89646860\n",
      "Iteration 12650, loss = 1694.76655736\n",
      "Iteration 12651, loss = 1694.63667491\n",
      "Iteration 12652, loss = 1694.50682123\n",
      "Iteration 12653, loss = 1694.37699630\n",
      "Iteration 12654, loss = 1694.24720008\n",
      "Iteration 12655, loss = 1694.11743254\n",
      "Iteration 12656, loss = 1693.98769366\n",
      "Iteration 12657, loss = 1693.85798340\n",
      "Iteration 12658, loss = 1693.72830175\n",
      "Iteration 12659, loss = 1693.59864867\n",
      "Iteration 12660, loss = 1693.46902413\n",
      "Iteration 12661, loss = 1693.33942810\n",
      "Iteration 12662, loss = 1693.20986056\n",
      "Iteration 12663, loss = 1693.08032149\n",
      "Iteration 12664, loss = 1692.95081084\n",
      "Iteration 12665, loss = 1692.82132859\n",
      "Iteration 12666, loss = 1692.69187472\n",
      "Iteration 12667, loss = 1692.56244919\n",
      "Iteration 12668, loss = 1692.43305198\n",
      "Iteration 12669, loss = 1692.30368306\n",
      "Iteration 12670, loss = 1692.17434241\n",
      "Iteration 12671, loss = 1692.04502998\n",
      "Iteration 12672, loss = 1691.91574576\n",
      "Iteration 12673, loss = 1691.78648972\n",
      "Iteration 12674, loss = 1691.65726182\n",
      "Iteration 12675, loss = 1691.52806204\n",
      "Iteration 12676, loss = 1691.39889036\n",
      "Iteration 12677, loss = 1691.26974674\n",
      "Iteration 12678, loss = 1691.14063115\n",
      "Iteration 12679, loss = 1691.01154357\n",
      "Iteration 12680, loss = 1690.88248397\n",
      "Iteration 12681, loss = 1690.75345232\n",
      "Iteration 12682, loss = 1690.62444859\n",
      "Iteration 12683, loss = 1690.49547275\n",
      "Iteration 12684, loss = 1690.36652478\n",
      "Iteration 12685, loss = 1690.23760464\n",
      "Iteration 12686, loss = 1690.10871231\n",
      "Iteration 12687, loss = 1689.97984777\n",
      "Iteration 12688, loss = 1689.85101097\n",
      "Iteration 12689, loss = 1689.72220190\n",
      "Iteration 12690, loss = 1689.59342052\n",
      "Iteration 12691, loss = 1689.46466681\n",
      "Iteration 12692, loss = 1689.33594074\n",
      "Iteration 12693, loss = 1689.20724228\n",
      "Iteration 12694, loss = 1689.07857139\n",
      "Iteration 12695, loss = 1688.94992806\n",
      "Iteration 12696, loss = 1688.82131226\n",
      "Iteration 12697, loss = 1688.69272395\n",
      "Iteration 12698, loss = 1688.56416311\n",
      "Iteration 12699, loss = 1688.43562970\n",
      "Iteration 12700, loss = 1688.30712371\n",
      "Iteration 12701, loss = 1688.17864510\n",
      "Iteration 12702, loss = 1688.05019384\n",
      "Iteration 12703, loss = 1687.92176990\n",
      "Iteration 12704, loss = 1687.79337327\n",
      "Iteration 12705, loss = 1687.66500389\n",
      "Iteration 12706, loss = 1687.53666176\n",
      "Iteration 12707, loss = 1687.40834684\n",
      "Iteration 12708, loss = 1687.28005910\n",
      "Iteration 12709, loss = 1687.15179851\n",
      "Iteration 12710, loss = 1687.02356505\n",
      "Iteration 12711, loss = 1686.89535868\n",
      "Iteration 12712, loss = 1686.76717937\n",
      "Iteration 12713, loss = 1686.63902711\n",
      "Iteration 12714, loss = 1686.51090186\n",
      "Iteration 12715, loss = 1686.38280358\n",
      "Iteration 12716, loss = 1686.25473226\n",
      "Iteration 12717, loss = 1686.12668786\n",
      "Iteration 12718, loss = 1685.99867035\n",
      "Iteration 12719, loss = 1685.87067971\n",
      "Iteration 12720, loss = 1685.74271591\n",
      "Iteration 12721, loss = 1685.61477891\n",
      "Iteration 12722, loss = 1685.48686869\n",
      "Iteration 12723, loss = 1685.35898522\n",
      "Iteration 12724, loss = 1685.23112847\n",
      "Iteration 12725, loss = 1685.10329842\n",
      "Iteration 12726, loss = 1684.97549502\n",
      "Iteration 12727, loss = 1684.84771827\n",
      "Iteration 12728, loss = 1684.71996812\n",
      "Iteration 12729, loss = 1684.59224455\n",
      "Iteration 12730, loss = 1684.46454753\n",
      "Iteration 12731, loss = 1684.33687705\n",
      "Iteration 12732, loss = 1684.20923308\n",
      "Iteration 12733, loss = 1684.08161562\n",
      "Iteration 12734, loss = 1683.95402467\n",
      "Iteration 12735, loss = 1683.82646028\n",
      "Iteration 12736, loss = 1683.69892254\n",
      "Iteration 12737, loss = 1683.57141168\n",
      "Iteration 12738, loss = 1683.44392812\n",
      "Iteration 12739, loss = 1683.31647267\n",
      "Iteration 12740, loss = 1683.18904689\n",
      "Iteration 12741, loss = 1683.06165353\n",
      "Iteration 12742, loss = 1682.93429732\n",
      "Iteration 12743, loss = 1682.80698499\n",
      "Iteration 12744, loss = 1682.67972282\n",
      "Iteration 12745, loss = 1682.55250581\n",
      "Iteration 12746, loss = 1682.42529890\n",
      "Iteration 12747, loss = 1682.29803577\n",
      "Iteration 12748, loss = 1682.17068948\n",
      "Iteration 12749, loss = 1682.04334937\n",
      "Iteration 12750, loss = 1681.91614140\n",
      "Iteration 12751, loss = 1681.78907084\n",
      "Iteration 12752, loss = 1681.66202295\n",
      "Iteration 12753, loss = 1681.53490127\n",
      "Iteration 12754, loss = 1681.40774326\n",
      "Iteration 12755, loss = 1681.28066533\n",
      "Iteration 12756, loss = 1681.15369462\n",
      "Iteration 12757, loss = 1681.02674557\n",
      "Iteration 12758, loss = 1680.89975380\n",
      "Iteration 12759, loss = 1680.77276137\n",
      "Iteration 12760, loss = 1680.64584183\n",
      "Iteration 12761, loss = 1680.51898865\n",
      "Iteration 12762, loss = 1680.39213799\n",
      "Iteration 12763, loss = 1680.26527129\n",
      "Iteration 12764, loss = 1680.13843551\n",
      "Iteration 12765, loss = 1680.01166164\n",
      "Iteration 12766, loss = 1679.88492081\n",
      "Iteration 12767, loss = 1679.75817850\n",
      "Iteration 12768, loss = 1679.63144734\n",
      "Iteration 12769, loss = 1679.50475944\n",
      "Iteration 12770, loss = 1679.37811412\n",
      "Iteration 12771, loss = 1679.25148505\n",
      "Iteration 12772, loss = 1679.12486473\n",
      "Iteration 12773, loss = 1678.99827226\n",
      "Iteration 12774, loss = 1678.87171930\n",
      "Iteration 12775, loss = 1678.74519397\n",
      "Iteration 12776, loss = 1678.61868318\n",
      "Iteration 12777, loss = 1678.49219227\n",
      "Iteration 12778, loss = 1678.36573359\n",
      "Iteration 12779, loss = 1678.23930664\n",
      "Iteration 12780, loss = 1678.11290111\n",
      "Iteration 12781, loss = 1677.98651410\n",
      "Iteration 12782, loss = 1677.86015303\n",
      "Iteration 12783, loss = 1677.73382249\n",
      "Iteration 12784, loss = 1677.60751801\n",
      "Iteration 12785, loss = 1677.48123441\n",
      "Iteration 12786, loss = 1677.35497339\n",
      "Iteration 12787, loss = 1677.22873963\n",
      "Iteration 12788, loss = 1677.10253345\n",
      "Iteration 12789, loss = 1676.97635115\n",
      "Iteration 12790, loss = 1676.85019099\n",
      "Iteration 12791, loss = 1676.72405530\n",
      "Iteration 12792, loss = 1676.59794634\n",
      "Iteration 12793, loss = 1676.47186301\n",
      "Iteration 12794, loss = 1676.34580304\n",
      "Iteration 12795, loss = 1676.21976638\n",
      "Iteration 12796, loss = 1676.09375475\n",
      "Iteration 12797, loss = 1675.96776886\n",
      "Iteration 12798, loss = 1675.84180762\n",
      "Iteration 12799, loss = 1675.71586991\n",
      "Iteration 12800, loss = 1675.58995609\n",
      "Iteration 12801, loss = 1675.46406716\n",
      "Iteration 12802, loss = 1675.33820326\n",
      "Iteration 12803, loss = 1675.21236358\n",
      "Iteration 12804, loss = 1675.08654760\n",
      "Iteration 12805, loss = 1674.96075570\n",
      "Iteration 12806, loss = 1674.83498839\n",
      "Iteration 12807, loss = 1674.70924562\n",
      "Iteration 12808, loss = 1674.58352687\n",
      "Iteration 12809, loss = 1674.45783192\n",
      "Iteration 12810, loss = 1674.33216099\n",
      "Iteration 12811, loss = 1674.20651435\n",
      "Iteration 12812, loss = 1674.08089193\n",
      "Iteration 12813, loss = 1673.95529341\n",
      "Iteration 12814, loss = 1673.82971866\n",
      "Iteration 12815, loss = 1673.70416779\n",
      "Iteration 12816, loss = 1673.57864096\n",
      "Iteration 12817, loss = 1673.45313810\n",
      "Iteration 12818, loss = 1673.32765902\n",
      "Iteration 12819, loss = 1673.20220362\n",
      "Iteration 12820, loss = 1673.07677195\n",
      "Iteration 12821, loss = 1672.95136408\n",
      "Iteration 12822, loss = 1672.82597997\n",
      "Iteration 12823, loss = 1672.70061951\n",
      "Iteration 12824, loss = 1672.57528260\n",
      "Iteration 12825, loss = 1672.44996926\n",
      "Iteration 12826, loss = 1672.32467951\n",
      "Iteration 12827, loss = 1672.19941332\n",
      "Iteration 12828, loss = 1672.07417063\n",
      "Iteration 12829, loss = 1671.94895136\n",
      "Iteration 12830, loss = 1671.82375547\n",
      "Iteration 12831, loss = 1671.69858299\n",
      "Iteration 12832, loss = 1671.57343388\n",
      "Iteration 12833, loss = 1671.44830810\n",
      "Iteration 12834, loss = 1671.32320558\n",
      "Iteration 12835, loss = 1671.19812629\n",
      "Iteration 12836, loss = 1671.07307021\n",
      "Iteration 12837, loss = 1670.94803732\n",
      "Iteration 12838, loss = 1670.82302758\n",
      "Iteration 12839, loss = 1670.69804094\n",
      "Iteration 12840, loss = 1670.57307737\n",
      "Iteration 12841, loss = 1670.44813681\n",
      "Iteration 12842, loss = 1670.32321926\n",
      "Iteration 12843, loss = 1670.19832468\n",
      "Iteration 12844, loss = 1670.07345303\n",
      "Iteration 12845, loss = 1669.94860427\n",
      "Iteration 12846, loss = 1669.82377836\n",
      "Iteration 12847, loss = 1669.69897526\n",
      "Iteration 12848, loss = 1669.57419495\n",
      "Iteration 12849, loss = 1669.44943738\n",
      "Iteration 12850, loss = 1669.32470253\n",
      "Iteration 12851, loss = 1669.19999035\n",
      "Iteration 12852, loss = 1669.07530080\n",
      "Iteration 12853, loss = 1668.95063385\n",
      "Iteration 12854, loss = 1668.82598946\n",
      "Iteration 12855, loss = 1668.70136760\n",
      "Iteration 12856, loss = 1668.57676823\n",
      "Iteration 12857, loss = 1668.45219130\n",
      "Iteration 12858, loss = 1668.32763679\n",
      "Iteration 12859, loss = 1668.20310465\n",
      "Iteration 12860, loss = 1668.07859485\n",
      "Iteration 12861, loss = 1667.95410735\n",
      "Iteration 12862, loss = 1667.82964211\n",
      "Iteration 12863, loss = 1667.70519910\n",
      "Iteration 12864, loss = 1667.58077827\n",
      "Iteration 12865, loss = 1667.45637959\n",
      "Iteration 12866, loss = 1667.33200301\n",
      "Iteration 12867, loss = 1667.20764851\n",
      "Iteration 12868, loss = 1667.08331604\n",
      "Iteration 12869, loss = 1666.95900556\n",
      "Iteration 12870, loss = 1666.83471703\n",
      "Iteration 12871, loss = 1666.71045041\n",
      "Iteration 12872, loss = 1666.58620568\n",
      "Iteration 12873, loss = 1666.46198277\n",
      "Iteration 12874, loss = 1666.33778166\n",
      "Iteration 12875, loss = 1666.21360231\n",
      "Iteration 12876, loss = 1666.08944467\n",
      "Iteration 12877, loss = 1665.96530871\n",
      "Iteration 12878, loss = 1665.84119439\n",
      "Iteration 12879, loss = 1665.71710166\n",
      "Iteration 12880, loss = 1665.59303048\n",
      "Iteration 12881, loss = 1665.46898082\n",
      "Iteration 12882, loss = 1665.34495263\n",
      "Iteration 12883, loss = 1665.22094587\n",
      "Iteration 12884, loss = 1665.09696050\n",
      "Iteration 12885, loss = 1664.97299649\n",
      "Iteration 12886, loss = 1664.84905378\n",
      "Iteration 12887, loss = 1664.72513234\n",
      "Iteration 12888, loss = 1664.60123212\n",
      "Iteration 12889, loss = 1664.47735308\n",
      "Iteration 12890, loss = 1664.35349519\n",
      "Iteration 12891, loss = 1664.22965839\n",
      "Iteration 12892, loss = 1664.10584265\n",
      "Iteration 12893, loss = 1663.98204792\n",
      "Iteration 12894, loss = 1663.85827416\n",
      "Iteration 12895, loss = 1663.73452133\n",
      "Iteration 12896, loss = 1663.61078938\n",
      "Iteration 12897, loss = 1663.48707827\n",
      "Iteration 12898, loss = 1663.36338795\n",
      "Iteration 12899, loss = 1663.23971839\n",
      "Iteration 12900, loss = 1663.11606954\n",
      "Iteration 12901, loss = 1662.99244135\n",
      "Iteration 12902, loss = 1662.86883378\n",
      "Iteration 12903, loss = 1662.74524679\n",
      "Iteration 12904, loss = 1662.62168032\n",
      "Iteration 12905, loss = 1662.49813434\n",
      "Iteration 12906, loss = 1662.37460881\n",
      "Iteration 12907, loss = 1662.25110366\n",
      "Iteration 12908, loss = 1662.12761887\n",
      "Iteration 12909, loss = 1662.00415437\n",
      "Iteration 12910, loss = 1661.88071014\n",
      "Iteration 12911, loss = 1661.75728611\n",
      "Iteration 12912, loss = 1661.63388225\n",
      "Iteration 12913, loss = 1661.51049851\n",
      "Iteration 12914, loss = 1661.38713484\n",
      "Iteration 12915, loss = 1661.26379119\n",
      "Iteration 12916, loss = 1661.14046751\n",
      "Iteration 12917, loss = 1661.01716377\n",
      "Iteration 12918, loss = 1660.89387990\n",
      "Iteration 12919, loss = 1660.77061587\n",
      "Iteration 12920, loss = 1660.64737162\n",
      "Iteration 12921, loss = 1660.52414710\n",
      "Iteration 12922, loss = 1660.40094227\n",
      "Iteration 12923, loss = 1660.27775708\n",
      "Iteration 12924, loss = 1660.15459147\n",
      "Iteration 12925, loss = 1660.03144541\n",
      "Iteration 12926, loss = 1659.90831883\n",
      "Iteration 12927, loss = 1659.78521169\n",
      "Iteration 12928, loss = 1659.66212394\n",
      "Iteration 12929, loss = 1659.53905552\n",
      "Iteration 12930, loss = 1659.41600639\n",
      "Iteration 12931, loss = 1659.29297650\n",
      "Iteration 12932, loss = 1659.16996579\n",
      "Iteration 12933, loss = 1659.04697421\n",
      "Iteration 12934, loss = 1658.92400171\n",
      "Iteration 12935, loss = 1658.80104823\n",
      "Iteration 12936, loss = 1658.67811374\n",
      "Iteration 12937, loss = 1658.55519816\n",
      "Iteration 12938, loss = 1658.43230145\n",
      "Iteration 12939, loss = 1658.30942356\n",
      "Iteration 12940, loss = 1658.18656443\n",
      "Iteration 12941, loss = 1658.06372401\n",
      "Iteration 12942, loss = 1657.94090223\n",
      "Iteration 12943, loss = 1657.81809906\n",
      "Iteration 12944, loss = 1657.69531443\n",
      "Iteration 12945, loss = 1657.57254829\n",
      "Iteration 12946, loss = 1657.44980058\n",
      "Iteration 12947, loss = 1657.32707125\n",
      "Iteration 12948, loss = 1657.20436024\n",
      "Iteration 12949, loss = 1657.08166749\n",
      "Iteration 12950, loss = 1656.95899295\n",
      "Iteration 12951, loss = 1656.83633656\n",
      "Iteration 12952, loss = 1656.71369825\n",
      "Iteration 12953, loss = 1656.59107799\n",
      "Iteration 12954, loss = 1656.46847570\n",
      "Iteration 12955, loss = 1656.34589132\n",
      "Iteration 12956, loss = 1656.22332480\n",
      "Iteration 12957, loss = 1656.10077608\n",
      "Iteration 12958, loss = 1655.97824510\n",
      "Iteration 12959, loss = 1655.85573180\n",
      "Iteration 12960, loss = 1655.73323611\n",
      "Iteration 12961, loss = 1655.61075798\n",
      "Iteration 12962, loss = 1655.48829735\n",
      "Iteration 12963, loss = 1655.36585415\n",
      "Iteration 12964, loss = 1655.24342833\n",
      "Iteration 12965, loss = 1655.12101981\n",
      "Iteration 12966, loss = 1654.99862854\n",
      "Iteration 12967, loss = 1654.87625445\n",
      "Iteration 12968, loss = 1654.75389749\n",
      "Iteration 12969, loss = 1654.63155758\n",
      "Iteration 12970, loss = 1654.50923466\n",
      "Iteration 12971, loss = 1654.38692867\n",
      "Iteration 12972, loss = 1654.26463953\n",
      "Iteration 12973, loss = 1654.14236720\n",
      "Iteration 12974, loss = 1654.02011159\n",
      "Iteration 12975, loss = 1653.89787265\n",
      "Iteration 12976, loss = 1653.77565030\n",
      "Iteration 12977, loss = 1653.65344448\n",
      "Iteration 12978, loss = 1653.53125512\n",
      "Iteration 12979, loss = 1653.40908215\n",
      "Iteration 12980, loss = 1653.28692551\n",
      "Iteration 12981, loss = 1653.16478513\n",
      "Iteration 12982, loss = 1653.04266094\n",
      "Iteration 12983, loss = 1652.92055288\n",
      "Iteration 12984, loss = 1652.79846088\n",
      "Iteration 12985, loss = 1652.67638490\n",
      "Iteration 12986, loss = 1652.55432489\n",
      "Iteration 12987, loss = 1652.43228086\n",
      "Iteration 12988, loss = 1652.31025283\n",
      "Iteration 12989, loss = 1652.18824095\n",
      "Iteration 12990, loss = 1652.06624554\n",
      "Iteration 12991, loss = 1651.94426720\n",
      "Iteration 12992, loss = 1651.82230717\n",
      "Iteration 12993, loss = 1651.70036760\n",
      "Iteration 12994, loss = 1651.57845226\n",
      "Iteration 12995, loss = 1651.45656664\n",
      "Iteration 12996, loss = 1651.33471689\n",
      "Iteration 12997, loss = 1651.21290269\n",
      "Iteration 12998, loss = 1651.09110340\n",
      "Iteration 12999, loss = 1650.96926631\n",
      "Iteration 13000, loss = 1650.84734428\n",
      "Iteration 13001, loss = 1650.72537242\n",
      "Iteration 13002, loss = 1650.60346734\n",
      "Iteration 13003, loss = 1650.48169375\n",
      "Iteration 13004, loss = 1650.35999110\n",
      "Iteration 13005, loss = 1650.23824891\n",
      "Iteration 13006, loss = 1650.11642985\n",
      "Iteration 13007, loss = 1649.99461247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13008, loss = 1649.87288141\n",
      "Iteration 13009, loss = 1649.75121701\n",
      "Iteration 13010, loss = 1649.62953750\n",
      "Iteration 13011, loss = 1649.50781273\n",
      "Iteration 13012, loss = 1649.38609698\n",
      "Iteration 13013, loss = 1649.26444298\n",
      "Iteration 13014, loss = 1649.14282895\n",
      "Iteration 13015, loss = 1649.02120103\n",
      "Iteration 13016, loss = 1648.89955339\n",
      "Iteration 13017, loss = 1648.77792867\n",
      "Iteration 13018, loss = 1648.65634841\n",
      "Iteration 13019, loss = 1648.53478626\n",
      "Iteration 13020, loss = 1648.41321425\n",
      "Iteration 13021, loss = 1648.29164237\n",
      "Iteration 13022, loss = 1648.17009746\n",
      "Iteration 13023, loss = 1648.04858143\n",
      "Iteration 13024, loss = 1647.92707302\n",
      "Iteration 13025, loss = 1647.80556241\n",
      "Iteration 13026, loss = 1647.68406297\n",
      "Iteration 13027, loss = 1647.56258766\n",
      "Iteration 13028, loss = 1647.44113035\n",
      "Iteration 13029, loss = 1647.31967807\n",
      "Iteration 13030, loss = 1647.19823066\n",
      "Iteration 13031, loss = 1647.07679839\n",
      "Iteration 13032, loss = 1646.95538522\n",
      "Iteration 13033, loss = 1646.83398425\n",
      "Iteration 13034, loss = 1646.71258941\n",
      "Iteration 13035, loss = 1646.59120373\n",
      "Iteration 13036, loss = 1646.46983308\n",
      "Iteration 13037, loss = 1646.34847733\n",
      "Iteration 13038, loss = 1646.22713155\n",
      "Iteration 13039, loss = 1646.10579355\n",
      "Iteration 13040, loss = 1645.98446631\n",
      "Iteration 13041, loss = 1645.86315269\n",
      "Iteration 13042, loss = 1645.74185132\n",
      "Iteration 13043, loss = 1645.62055921\n",
      "Iteration 13044, loss = 1645.49927593\n",
      "Iteration 13045, loss = 1645.37800359\n",
      "Iteration 13046, loss = 1645.25674327\n",
      "Iteration 13047, loss = 1645.13549366\n",
      "Iteration 13048, loss = 1645.01425312\n",
      "Iteration 13049, loss = 1644.89302173\n",
      "Iteration 13050, loss = 1644.77180074\n",
      "Iteration 13051, loss = 1644.65059049\n",
      "Iteration 13052, loss = 1644.52938999\n",
      "Iteration 13053, loss = 1644.40819833\n",
      "Iteration 13054, loss = 1644.28701566\n",
      "Iteration 13055, loss = 1644.16584266\n",
      "Iteration 13056, loss = 1644.04467935\n",
      "Iteration 13057, loss = 1643.92352507\n",
      "Iteration 13058, loss = 1643.80237927\n",
      "Iteration 13059, loss = 1643.68124202\n",
      "Iteration 13060, loss = 1643.56011364\n",
      "Iteration 13061, loss = 1643.43899408\n",
      "Iteration 13062, loss = 1643.31788289\n",
      "Iteration 13063, loss = 1643.19677967\n",
      "Iteration 13064, loss = 1643.07568443\n",
      "Iteration 13065, loss = 1642.95459727\n",
      "Iteration 13066, loss = 1642.83351812\n",
      "Iteration 13067, loss = 1642.71244665\n",
      "Iteration 13068, loss = 1642.59138257\n",
      "Iteration 13069, loss = 1642.47032579\n",
      "Iteration 13070, loss = 1642.34927631\n",
      "Iteration 13071, loss = 1642.22823404\n",
      "Iteration 13072, loss = 1642.10719874\n",
      "Iteration 13073, loss = 1641.98617016\n",
      "Iteration 13074, loss = 1641.86514816\n",
      "Iteration 13075, loss = 1641.74413267\n",
      "Iteration 13076, loss = 1641.62312358\n",
      "Iteration 13077, loss = 1641.50212069\n",
      "Iteration 13078, loss = 1641.38112379\n",
      "Iteration 13079, loss = 1641.26013270\n",
      "Iteration 13080, loss = 1641.13914731\n",
      "Iteration 13081, loss = 1641.01816749\n",
      "Iteration 13082, loss = 1640.89719306\n",
      "Iteration 13083, loss = 1640.77622383\n",
      "Iteration 13084, loss = 1640.65525960\n",
      "Iteration 13085, loss = 1640.53430023\n",
      "Iteration 13086, loss = 1640.41334556\n",
      "Iteration 13087, loss = 1640.29239543\n",
      "Iteration 13088, loss = 1640.17144964\n",
      "Iteration 13089, loss = 1640.05050800\n",
      "Iteration 13090, loss = 1639.92957034\n",
      "Iteration 13091, loss = 1639.80863648\n",
      "Iteration 13092, loss = 1639.68770625\n",
      "Iteration 13093, loss = 1639.56677946\n",
      "Iteration 13094, loss = 1639.44585592\n",
      "Iteration 13095, loss = 1639.32493543\n",
      "Iteration 13096, loss = 1639.20401780\n",
      "Iteration 13097, loss = 1639.08310284\n",
      "Iteration 13098, loss = 1638.96219037\n",
      "Iteration 13099, loss = 1638.84128018\n",
      "Iteration 13100, loss = 1638.72037207\n",
      "Iteration 13101, loss = 1638.59946583\n",
      "Iteration 13102, loss = 1638.47856126\n",
      "Iteration 13103, loss = 1638.35765816\n",
      "Iteration 13104, loss = 1638.23675631\n",
      "Iteration 13105, loss = 1638.11585552\n",
      "Iteration 13106, loss = 1637.99495555\n",
      "Iteration 13107, loss = 1637.87405620\n",
      "Iteration 13108, loss = 1637.75315724\n",
      "Iteration 13109, loss = 1637.63225846\n",
      "Iteration 13110, loss = 1637.51135963\n",
      "Iteration 13111, loss = 1637.39046052\n",
      "Iteration 13112, loss = 1637.26956091\n",
      "Iteration 13113, loss = 1637.14866057\n",
      "Iteration 13114, loss = 1637.02775925\n",
      "Iteration 13115, loss = 1636.90685673\n",
      "Iteration 13116, loss = 1636.78595277\n",
      "Iteration 13117, loss = 1636.66504711\n",
      "Iteration 13118, loss = 1636.54413952\n",
      "Iteration 13119, loss = 1636.42322975\n",
      "Iteration 13120, loss = 1636.30231755\n",
      "Iteration 13121, loss = 1636.18140265\n",
      "Iteration 13122, loss = 1636.06048482\n",
      "Iteration 13123, loss = 1635.93956377\n",
      "Iteration 13124, loss = 1635.81863926\n",
      "Iteration 13125, loss = 1635.69771102\n",
      "Iteration 13126, loss = 1635.57677877\n",
      "Iteration 13127, loss = 1635.45584224\n",
      "Iteration 13128, loss = 1635.33490115\n",
      "Iteration 13129, loss = 1635.21395524\n",
      "Iteration 13130, loss = 1635.09300420\n",
      "Iteration 13131, loss = 1634.97204777\n",
      "Iteration 13132, loss = 1634.85108564\n",
      "Iteration 13133, loss = 1634.73011752\n",
      "Iteration 13134, loss = 1634.60914312\n",
      "Iteration 13135, loss = 1634.48816213\n",
      "Iteration 13136, loss = 1634.36717425\n",
      "Iteration 13137, loss = 1634.24617917\n",
      "Iteration 13138, loss = 1634.12517658\n",
      "Iteration 13139, loss = 1634.00416617\n",
      "Iteration 13140, loss = 1633.88314760\n",
      "Iteration 13141, loss = 1633.76212056\n",
      "Iteration 13142, loss = 1633.64108473\n",
      "Iteration 13143, loss = 1633.52003975\n",
      "Iteration 13144, loss = 1633.39898531\n",
      "Iteration 13145, loss = 1633.27792106\n",
      "Iteration 13146, loss = 1633.15684664\n",
      "Iteration 13147, loss = 1633.03576172\n",
      "Iteration 13148, loss = 1632.91466594\n",
      "Iteration 13149, loss = 1632.79355893\n",
      "Iteration 13150, loss = 1632.67244034\n",
      "Iteration 13151, loss = 1632.55130980\n",
      "Iteration 13152, loss = 1632.43016692\n",
      "Iteration 13153, loss = 1632.30901134\n",
      "Iteration 13154, loss = 1632.18784267\n",
      "Iteration 13155, loss = 1632.06666052\n",
      "Iteration 13156, loss = 1631.94546449\n",
      "Iteration 13157, loss = 1631.82425420\n",
      "Iteration 13158, loss = 1631.70302922\n",
      "Iteration 13159, loss = 1631.58178917\n",
      "Iteration 13160, loss = 1631.46053361\n",
      "Iteration 13161, loss = 1631.33926213\n",
      "Iteration 13162, loss = 1631.21797429\n",
      "Iteration 13163, loss = 1631.09666968\n",
      "Iteration 13164, loss = 1630.97534785\n",
      "Iteration 13165, loss = 1630.85400836\n",
      "Iteration 13166, loss = 1630.73265075\n",
      "Iteration 13167, loss = 1630.61127457\n",
      "Iteration 13168, loss = 1630.48987935\n",
      "Iteration 13169, loss = 1630.36846464\n",
      "Iteration 13170, loss = 1630.24702994\n",
      "Iteration 13171, loss = 1630.12557478\n",
      "Iteration 13172, loss = 1630.00409867\n",
      "Iteration 13173, loss = 1629.88260112\n",
      "Iteration 13174, loss = 1629.76108161\n",
      "Iteration 13175, loss = 1629.63953965\n",
      "Iteration 13176, loss = 1629.51797470\n",
      "Iteration 13177, loss = 1629.39638625\n",
      "Iteration 13178, loss = 1629.27477377\n",
      "Iteration 13179, loss = 1629.15313672\n",
      "Iteration 13180, loss = 1629.03147454\n",
      "Iteration 13181, loss = 1628.90978668\n",
      "Iteration 13182, loss = 1628.78807258\n",
      "Iteration 13183, loss = 1628.66633167\n",
      "Iteration 13184, loss = 1628.54456336\n",
      "Iteration 13185, loss = 1628.42276707\n",
      "Iteration 13186, loss = 1628.30094221\n",
      "Iteration 13187, loss = 1628.17908815\n",
      "Iteration 13188, loss = 1628.05720430\n",
      "Iteration 13189, loss = 1627.93529003\n",
      "Iteration 13190, loss = 1627.81334469\n",
      "Iteration 13191, loss = 1627.69136766\n",
      "Iteration 13192, loss = 1627.56935828\n",
      "Iteration 13193, loss = 1627.44731588\n",
      "Iteration 13194, loss = 1627.32523979\n",
      "Iteration 13195, loss = 1627.20312934\n",
      "Iteration 13196, loss = 1627.08098383\n",
      "Iteration 13197, loss = 1626.95880256\n",
      "Iteration 13198, loss = 1626.83658481\n",
      "Iteration 13199, loss = 1626.71432986\n",
      "Iteration 13200, loss = 1626.59203698\n",
      "Iteration 13201, loss = 1626.46970541\n",
      "Iteration 13202, loss = 1626.34733440\n",
      "Iteration 13203, loss = 1626.22492318\n",
      "Iteration 13204, loss = 1626.10247097\n",
      "Iteration 13205, loss = 1625.97997698\n",
      "Iteration 13206, loss = 1625.85744039\n",
      "Iteration 13207, loss = 1625.73486039\n",
      "Iteration 13208, loss = 1625.61223615\n",
      "Iteration 13209, loss = 1625.48956682\n",
      "Iteration 13210, loss = 1625.36685154\n",
      "Iteration 13211, loss = 1625.24408945\n",
      "Iteration 13212, loss = 1625.12127965\n",
      "Iteration 13213, loss = 1624.99842125\n",
      "Iteration 13214, loss = 1624.87551333\n",
      "Iteration 13215, loss = 1624.75255496\n",
      "Iteration 13216, loss = 1624.62954521\n",
      "Iteration 13217, loss = 1624.50648310\n",
      "Iteration 13218, loss = 1624.38336768\n",
      "Iteration 13219, loss = 1624.26019794\n",
      "Iteration 13220, loss = 1624.13697288\n",
      "Iteration 13221, loss = 1624.01369147\n",
      "Iteration 13222, loss = 1623.89035269\n",
      "Iteration 13223, loss = 1623.76695546\n",
      "Iteration 13224, loss = 1623.64349872\n",
      "Iteration 13225, loss = 1623.51998138\n",
      "Iteration 13226, loss = 1623.39640232\n",
      "Iteration 13227, loss = 1623.27276041\n",
      "Iteration 13228, loss = 1623.14905452\n",
      "Iteration 13229, loss = 1623.02528346\n",
      "Iteration 13230, loss = 1622.90144606\n",
      "Iteration 13231, loss = 1622.77754112\n",
      "Iteration 13232, loss = 1622.65356739\n",
      "Iteration 13233, loss = 1622.52952364\n",
      "Iteration 13234, loss = 1622.40540860\n",
      "Iteration 13235, loss = 1622.28122098\n",
      "Iteration 13236, loss = 1622.15695946\n",
      "Iteration 13237, loss = 1622.03262271\n",
      "Iteration 13238, loss = 1621.90820937\n",
      "Iteration 13239, loss = 1621.78371807\n",
      "Iteration 13240, loss = 1621.65914738\n",
      "Iteration 13241, loss = 1621.53449590\n",
      "Iteration 13242, loss = 1621.40976216\n",
      "Iteration 13243, loss = 1621.28494468\n",
      "Iteration 13244, loss = 1621.16004195\n",
      "Iteration 13245, loss = 1621.03505245\n",
      "Iteration 13246, loss = 1620.90997461\n",
      "Iteration 13247, loss = 1620.78480685\n",
      "Iteration 13248, loss = 1620.65954756\n",
      "Iteration 13249, loss = 1620.53419508\n",
      "Iteration 13250, loss = 1620.40874774\n",
      "Iteration 13251, loss = 1620.28320385\n",
      "Iteration 13252, loss = 1620.15756167\n",
      "Iteration 13253, loss = 1620.03181943\n",
      "Iteration 13254, loss = 1619.90597533\n",
      "Iteration 13255, loss = 1619.78002756\n",
      "Iteration 13256, loss = 1619.65397424\n",
      "Iteration 13257, loss = 1619.52781347\n",
      "Iteration 13258, loss = 1619.40154334\n",
      "Iteration 13259, loss = 1619.27516186\n",
      "Iteration 13260, loss = 1619.14866705\n",
      "Iteration 13261, loss = 1619.02205685\n",
      "Iteration 13262, loss = 1618.89532919\n",
      "Iteration 13263, loss = 1618.76848196\n",
      "Iteration 13264, loss = 1618.64151301\n",
      "Iteration 13265, loss = 1618.51442012\n",
      "Iteration 13266, loss = 1618.38720108\n",
      "Iteration 13267, loss = 1618.25985360\n",
      "Iteration 13268, loss = 1618.13237536\n",
      "Iteration 13269, loss = 1618.00476400\n",
      "Iteration 13270, loss = 1617.87701711\n",
      "Iteration 13271, loss = 1617.74913223\n",
      "Iteration 13272, loss = 1617.62110686\n",
      "Iteration 13273, loss = 1617.49293846\n",
      "Iteration 13274, loss = 1617.36462442\n",
      "Iteration 13275, loss = 1617.23616210\n",
      "Iteration 13276, loss = 1617.10754881\n",
      "Iteration 13277, loss = 1616.97878179\n",
      "Iteration 13278, loss = 1616.84985823\n",
      "Iteration 13279, loss = 1616.72077529\n",
      "Iteration 13280, loss = 1616.59153005\n",
      "Iteration 13281, loss = 1616.46211955\n",
      "Iteration 13282, loss = 1616.33254075\n",
      "Iteration 13283, loss = 1616.20279057\n",
      "Iteration 13284, loss = 1616.07286587\n",
      "Iteration 13285, loss = 1615.94276344\n",
      "Iteration 13286, loss = 1615.81248002\n",
      "Iteration 13287, loss = 1615.68201226\n",
      "Iteration 13288, loss = 1615.55135678\n",
      "Iteration 13289, loss = 1615.42051010\n",
      "Iteration 13290, loss = 1615.28946871\n",
      "Iteration 13291, loss = 1615.15822899\n",
      "Iteration 13292, loss = 1615.02678733\n",
      "Iteration 13293, loss = 1614.89513996\n",
      "Iteration 13294, loss = 1614.76328318\n",
      "Iteration 13295, loss = 1614.63121313\n",
      "Iteration 13296, loss = 1614.49892610\n",
      "Iteration 13297, loss = 1614.36641826\n",
      "Iteration 13298, loss = 1614.23368620\n",
      "Iteration 13299, loss = 1614.10072647\n",
      "Iteration 13300, loss = 1613.96753661\n",
      "Iteration 13301, loss = 1613.83411432\n",
      "Iteration 13302, loss = 1613.70045863\n",
      "Iteration 13303, loss = 1613.56656685\n",
      "Iteration 13304, loss = 1613.43243253\n",
      "Iteration 13305, loss = 1613.29803613\n",
      "Iteration 13306, loss = 1613.16334607\n",
      "Iteration 13307, loss = 1613.02833436\n",
      "Iteration 13308, loss = 1612.89301427\n",
      "Iteration 13309, loss = 1612.75743548\n",
      "Iteration 13310, loss = 1612.62163435\n",
      "Iteration 13311, loss = 1612.48559131\n",
      "Iteration 13312, loss = 1612.34924880\n",
      "Iteration 13313, loss = 1612.21256256\n",
      "Iteration 13314, loss = 1612.07553622\n",
      "Iteration 13315, loss = 1611.93821163\n",
      "Iteration 13316, loss = 1611.80061016\n",
      "Iteration 13317, loss = 1611.66270640\n",
      "Iteration 13318, loss = 1611.52445761\n",
      "Iteration 13319, loss = 1611.38584486\n",
      "Iteration 13320, loss = 1611.24688528\n",
      "Iteration 13321, loss = 1611.10759826\n",
      "Iteration 13322, loss = 1610.96797546\n",
      "Iteration 13323, loss = 1610.82798716\n",
      "Iteration 13324, loss = 1610.68761207\n",
      "Iteration 13325, loss = 1610.54685453\n",
      "Iteration 13326, loss = 1610.40572497\n",
      "Iteration 13327, loss = 1610.26421792\n",
      "Iteration 13328, loss = 1610.12231257\n",
      "Iteration 13329, loss = 1609.97999124\n",
      "Iteration 13330, loss = 1609.83725174\n",
      "Iteration 13331, loss = 1609.69409658\n",
      "Iteration 13332, loss = 1609.55052001\n",
      "Iteration 13333, loss = 1609.40650640\n",
      "Iteration 13334, loss = 1609.26204054\n",
      "Iteration 13335, loss = 1609.11711664\n",
      "Iteration 13336, loss = 1608.97173230\n",
      "Iteration 13337, loss = 1608.82588047\n",
      "Iteration 13338, loss = 1608.67954774\n",
      "Iteration 13339, loss = 1608.53272062\n",
      "Iteration 13340, loss = 1608.38539120\n",
      "Iteration 13341, loss = 1608.23755343\n",
      "Iteration 13342, loss = 1608.08919886\n",
      "Iteration 13343, loss = 1607.94031527\n",
      "Iteration 13344, loss = 1607.79088980\n",
      "Iteration 13345, loss = 1607.64091279\n",
      "Iteration 13346, loss = 1607.49037578\n",
      "Iteration 13347, loss = 1607.33926912\n",
      "Iteration 13348, loss = 1607.18758071\n",
      "Iteration 13349, loss = 1607.03529772\n",
      "Iteration 13350, loss = 1606.88240926\n",
      "Iteration 13351, loss = 1606.72890500\n",
      "Iteration 13352, loss = 1606.57477407\n",
      "Iteration 13353, loss = 1606.42000409\n",
      "Iteration 13354, loss = 1606.26458201\n",
      "Iteration 13355, loss = 1606.10849576\n",
      "Iteration 13356, loss = 1605.95173358\n",
      "Iteration 13357, loss = 1605.79428353\n",
      "Iteration 13358, loss = 1605.63613270\n",
      "Iteration 13359, loss = 1605.47726757\n",
      "Iteration 13360, loss = 1605.31767512\n",
      "Iteration 13361, loss = 1605.15734247\n",
      "Iteration 13362, loss = 1604.99625671\n",
      "Iteration 13363, loss = 1604.83440429\n",
      "Iteration 13364, loss = 1604.67177124\n",
      "Iteration 13365, loss = 1604.50834379\n",
      "Iteration 13366, loss = 1604.34410816\n",
      "Iteration 13367, loss = 1604.17905068\n",
      "Iteration 13368, loss = 1604.01315728\n",
      "Iteration 13369, loss = 1603.84641360\n",
      "Iteration 13370, loss = 1603.67880533\n",
      "Iteration 13371, loss = 1603.51031817\n",
      "Iteration 13372, loss = 1603.34093794\n",
      "Iteration 13373, loss = 1603.17065027\n",
      "Iteration 13374, loss = 1602.99944064\n",
      "Iteration 13375, loss = 1602.82729459\n",
      "Iteration 13376, loss = 1602.65419764\n",
      "Iteration 13377, loss = 1602.48013554\n",
      "Iteration 13378, loss = 1602.30509400\n",
      "Iteration 13379, loss = 1602.12905874\n",
      "Iteration 13380, loss = 1601.95201559\n",
      "Iteration 13381, loss = 1601.77395046\n",
      "Iteration 13382, loss = 1601.59484957\n",
      "Iteration 13383, loss = 1601.41469924\n",
      "Iteration 13384, loss = 1601.23348602\n",
      "Iteration 13385, loss = 1601.05119666\n",
      "Iteration 13386, loss = 1600.86781814\n",
      "Iteration 13387, loss = 1600.68333787\n",
      "Iteration 13388, loss = 1600.49774354\n",
      "Iteration 13389, loss = 1600.31102325\n",
      "Iteration 13390, loss = 1600.12316548\n",
      "Iteration 13391, loss = 1599.93415913\n",
      "Iteration 13392, loss = 1599.74399369\n",
      "Iteration 13393, loss = 1599.55265912\n",
      "Iteration 13394, loss = 1599.36014599\n",
      "Iteration 13395, loss = 1599.16644547\n",
      "Iteration 13396, loss = 1598.97154939\n",
      "Iteration 13397, loss = 1598.77545031\n",
      "Iteration 13398, loss = 1598.57814149\n",
      "Iteration 13399, loss = 1598.37961704\n",
      "Iteration 13400, loss = 1598.17987189\n",
      "Iteration 13401, loss = 1597.97890180\n",
      "Iteration 13402, loss = 1597.77670352\n",
      "Iteration 13403, loss = 1597.57327470\n",
      "Iteration 13404, loss = 1597.36861403\n",
      "Iteration 13405, loss = 1597.16272122\n",
      "Iteration 13406, loss = 1596.95559706\n",
      "Iteration 13407, loss = 1596.74724345\n",
      "Iteration 13408, loss = 1596.53766339\n",
      "Iteration 13409, loss = 1596.32686112\n",
      "Iteration 13410, loss = 1596.11484200\n",
      "Iteration 13411, loss = 1595.90161265\n",
      "Iteration 13412, loss = 1595.68718091\n",
      "Iteration 13413, loss = 1595.47155586\n",
      "Iteration 13414, loss = 1595.25474785\n",
      "Iteration 13415, loss = 1595.03676847\n",
      "Iteration 13416, loss = 1594.81763060\n",
      "Iteration 13417, loss = 1594.59734837\n",
      "Iteration 13418, loss = 1594.37593715\n",
      "Iteration 13419, loss = 1594.15341357\n",
      "Iteration 13420, loss = 1593.92979544\n",
      "Iteration 13421, loss = 1593.70510182\n",
      "Iteration 13422, loss = 1593.47935287\n",
      "Iteration 13423, loss = 1593.25256994\n",
      "Iteration 13424, loss = 1593.02477544\n",
      "Iteration 13425, loss = 1592.79599284\n",
      "Iteration 13426, loss = 1592.56624660\n",
      "Iteration 13427, loss = 1592.33556215\n",
      "Iteration 13428, loss = 1592.10396578\n",
      "Iteration 13429, loss = 1591.87148466\n",
      "Iteration 13430, loss = 1591.63814668\n",
      "Iteration 13431, loss = 1591.40398048\n",
      "Iteration 13432, loss = 1591.16901530\n",
      "Iteration 13433, loss = 1590.93328099\n",
      "Iteration 13434, loss = 1590.69680785\n",
      "Iteration 13435, loss = 1590.45962664\n",
      "Iteration 13436, loss = 1590.22176846\n",
      "Iteration 13437, loss = 1589.98326469\n",
      "Iteration 13438, loss = 1589.74414692\n",
      "Iteration 13439, loss = 1589.50444687\n",
      "Iteration 13440, loss = 1589.26419633\n",
      "Iteration 13441, loss = 1589.02342708\n",
      "Iteration 13442, loss = 1588.78217083\n",
      "Iteration 13443, loss = 1588.54045917\n",
      "Iteration 13444, loss = 1588.29832347\n",
      "Iteration 13445, loss = 1588.05579485\n",
      "Iteration 13446, loss = 1587.81290413\n",
      "Iteration 13447, loss = 1587.56968174\n",
      "Iteration 13448, loss = 1587.32615772\n",
      "Iteration 13449, loss = 1587.08236162\n",
      "Iteration 13450, loss = 1586.83832251\n",
      "Iteration 13451, loss = 1586.59406889\n",
      "Iteration 13452, loss = 1586.34962871\n",
      "Iteration 13453, loss = 1586.10502927\n",
      "Iteration 13454, loss = 1585.86029727\n",
      "Iteration 13455, loss = 1585.61545871\n",
      "Iteration 13456, loss = 1585.37053894\n",
      "Iteration 13457, loss = 1585.12556257\n",
      "Iteration 13458, loss = 1584.88055351\n",
      "Iteration 13459, loss = 1584.63553494\n",
      "Iteration 13460, loss = 1584.39052930\n",
      "Iteration 13461, loss = 1584.14555827\n",
      "Iteration 13462, loss = 1583.90064280\n",
      "Iteration 13463, loss = 1583.65580308\n",
      "Iteration 13464, loss = 1583.41105856\n",
      "Iteration 13465, loss = 1583.16642793\n",
      "Iteration 13466, loss = 1582.92192916\n",
      "Iteration 13467, loss = 1582.67757948\n",
      "Iteration 13468, loss = 1582.43339539\n",
      "Iteration 13469, loss = 1582.18939269\n",
      "Iteration 13470, loss = 1581.94558646\n",
      "Iteration 13471, loss = 1581.70199112\n",
      "Iteration 13472, loss = 1581.45862039\n",
      "Iteration 13473, loss = 1581.21548735\n",
      "Iteration 13474, loss = 1580.97260441\n",
      "Iteration 13475, loss = 1580.72998338\n",
      "Iteration 13476, loss = 1580.48763545\n",
      "Iteration 13477, loss = 1580.24557120\n",
      "Iteration 13478, loss = 1580.00380065\n",
      "Iteration 13479, loss = 1579.76233326\n",
      "Iteration 13480, loss = 1579.52117794\n",
      "Iteration 13481, loss = 1579.28034307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13482, loss = 1579.03983655\n",
      "Iteration 13483, loss = 1578.79966577\n",
      "Iteration 13484, loss = 1578.55983764\n",
      "Iteration 13485, loss = 1578.32035865\n",
      "Iteration 13486, loss = 1578.08123481\n",
      "Iteration 13487, loss = 1577.84247176\n",
      "Iteration 13488, loss = 1577.60407468\n",
      "Iteration 13489, loss = 1577.36604842\n",
      "Iteration 13490, loss = 1577.12839743\n",
      "Iteration 13491, loss = 1576.89112579\n",
      "Iteration 13492, loss = 1576.65423728\n",
      "Iteration 13493, loss = 1576.41773532\n",
      "Iteration 13494, loss = 1576.18162304\n",
      "Iteration 13495, loss = 1575.94590327\n",
      "Iteration 13496, loss = 1575.71057855\n",
      "Iteration 13497, loss = 1575.47565115\n",
      "Iteration 13498, loss = 1575.24112309\n",
      "Iteration 13499, loss = 1575.00699615\n",
      "Iteration 13500, loss = 1574.77327186\n",
      "Iteration 13501, loss = 1574.53995155\n",
      "Iteration 13502, loss = 1574.30703631\n",
      "Iteration 13503, loss = 1574.07452707\n",
      "Iteration 13504, loss = 1573.84242454\n",
      "Iteration 13505, loss = 1573.61072925\n",
      "Iteration 13506, loss = 1573.37944159\n",
      "Iteration 13507, loss = 1573.14856175\n",
      "Iteration 13508, loss = 1572.91808979\n",
      "Iteration 13509, loss = 1572.68802563\n",
      "Iteration 13510, loss = 1572.45836904\n",
      "Iteration 13511, loss = 1572.22911967\n",
      "Iteration 13512, loss = 1572.00027704\n",
      "Iteration 13513, loss = 1571.77184057\n",
      "Iteration 13514, loss = 1571.54380955\n",
      "Iteration 13515, loss = 1571.31618320\n",
      "Iteration 13516, loss = 1571.08896062\n",
      "Iteration 13517, loss = 1570.86214083\n",
      "Iteration 13518, loss = 1570.63572276\n",
      "Iteration 13519, loss = 1570.40970528\n",
      "Iteration 13520, loss = 1570.18408715\n",
      "Iteration 13521, loss = 1569.95886711\n",
      "Iteration 13522, loss = 1569.73404379\n",
      "Iteration 13523, loss = 1569.50961578\n",
      "Iteration 13524, loss = 1569.28558163\n",
      "Iteration 13525, loss = 1569.06193982\n",
      "Iteration 13526, loss = 1568.83868877\n",
      "Iteration 13527, loss = 1568.61582689\n",
      "Iteration 13528, loss = 1568.39335251\n",
      "Iteration 13529, loss = 1568.17126395\n",
      "Iteration 13530, loss = 1567.94955949\n",
      "Iteration 13531, loss = 1567.72823737\n",
      "Iteration 13532, loss = 1567.50729580\n",
      "Iteration 13533, loss = 1567.28673298\n",
      "Iteration 13534, loss = 1567.06654706\n",
      "Iteration 13535, loss = 1566.84673620\n",
      "Iteration 13536, loss = 1566.62729850\n",
      "Iteration 13537, loss = 1566.40823209\n",
      "Iteration 13538, loss = 1566.18953503\n",
      "Iteration 13539, loss = 1565.97120542\n",
      "Iteration 13540, loss = 1565.75324131\n",
      "Iteration 13541, loss = 1565.53564075\n",
      "Iteration 13542, loss = 1565.31840180\n",
      "Iteration 13543, loss = 1565.10152248\n",
      "Iteration 13544, loss = 1564.88500082\n",
      "Iteration 13545, loss = 1564.66883485\n",
      "Iteration 13546, loss = 1564.45302260\n",
      "Iteration 13547, loss = 1564.23756208\n",
      "Iteration 13548, loss = 1564.02245131\n",
      "Iteration 13549, loss = 1563.80768831\n",
      "Iteration 13550, loss = 1563.59327110\n",
      "Iteration 13551, loss = 1563.37919770\n",
      "Iteration 13552, loss = 1563.16546613\n",
      "Iteration 13553, loss = 1562.95207443\n",
      "Iteration 13554, loss = 1562.73902062\n",
      "Iteration 13555, loss = 1562.52630274\n",
      "Iteration 13556, loss = 1562.31391883\n",
      "Iteration 13557, loss = 1562.10186694\n",
      "Iteration 13558, loss = 1561.89014512\n",
      "Iteration 13559, loss = 1561.67875144\n",
      "Iteration 13560, loss = 1561.46768397\n",
      "Iteration 13561, loss = 1561.25694079\n",
      "Iteration 13562, loss = 1561.04651998\n",
      "Iteration 13563, loss = 1560.83641963\n",
      "Iteration 13564, loss = 1560.62663787\n",
      "Iteration 13565, loss = 1560.41717279\n",
      "Iteration 13566, loss = 1560.20802253\n",
      "Iteration 13567, loss = 1559.99918522\n",
      "Iteration 13568, loss = 1559.79065902\n",
      "Iteration 13569, loss = 1559.58244207\n",
      "Iteration 13570, loss = 1559.37453256\n",
      "Iteration 13571, loss = 1559.16692865\n",
      "Iteration 13572, loss = 1558.95962855\n",
      "Iteration 13573, loss = 1558.75263045\n",
      "Iteration 13574, loss = 1558.54593258\n",
      "Iteration 13575, loss = 1558.33953316\n",
      "Iteration 13576, loss = 1558.13343043\n",
      "Iteration 13577, loss = 1557.92762265\n",
      "Iteration 13578, loss = 1557.72210808\n",
      "Iteration 13579, loss = 1557.51688500\n",
      "Iteration 13580, loss = 1557.31195170\n",
      "Iteration 13581, loss = 1557.10730649\n",
      "Iteration 13582, loss = 1556.90294768\n",
      "Iteration 13583, loss = 1556.69887360\n",
      "Iteration 13584, loss = 1556.49508260\n",
      "Iteration 13585, loss = 1556.29157302\n",
      "Iteration 13586, loss = 1556.08834323\n",
      "Iteration 13587, loss = 1555.88539163\n",
      "Iteration 13588, loss = 1555.68271659\n",
      "Iteration 13589, loss = 1555.48031652\n",
      "Iteration 13590, loss = 1555.27818985\n",
      "Iteration 13591, loss = 1555.07633500\n",
      "Iteration 13592, loss = 1554.87475042\n",
      "Iteration 13593, loss = 1554.67343457\n",
      "Iteration 13594, loss = 1554.47238592\n",
      "Iteration 13595, loss = 1554.27160294\n",
      "Iteration 13596, loss = 1554.07108414\n",
      "Iteration 13597, loss = 1553.87082802\n",
      "Iteration 13598, loss = 1553.67083310\n",
      "Iteration 13599, loss = 1553.47109792\n",
      "Iteration 13600, loss = 1553.27162102\n",
      "Iteration 13601, loss = 1553.07240095\n",
      "Iteration 13602, loss = 1552.87343629\n",
      "Iteration 13603, loss = 1552.67472561\n",
      "Iteration 13604, loss = 1552.47626752\n",
      "Iteration 13605, loss = 1552.27806061\n",
      "Iteration 13606, loss = 1552.08010351\n",
      "Iteration 13607, loss = 1551.88239484\n",
      "Iteration 13608, loss = 1551.68493325\n",
      "Iteration 13609, loss = 1551.48771740\n",
      "Iteration 13610, loss = 1551.29074594\n",
      "Iteration 13611, loss = 1551.09401757\n",
      "Iteration 13612, loss = 1550.89753098\n",
      "Iteration 13613, loss = 1550.70128490\n",
      "Iteration 13614, loss = 1550.50527808\n",
      "Iteration 13615, loss = 1550.30950933\n",
      "Iteration 13616, loss = 1550.11397753\n",
      "Iteration 13617, loss = 1549.91868174\n",
      "Iteration 13618, loss = 1549.72362124\n",
      "Iteration 13619, loss = 1549.52879582\n",
      "Iteration 13620, loss = 1549.33420584\n",
      "Iteration 13621, loss = 1549.13985266\n",
      "Iteration 13622, loss = 1548.94573716\n",
      "Iteration 13623, loss = 1548.75185750\n",
      "Iteration 13624, loss = 1548.55820024\n",
      "Iteration 13625, loss = 1548.36474295\n",
      "Iteration 13626, loss = 1548.17147123\n",
      "Iteration 13627, loss = 1547.97840956\n",
      "Iteration 13628, loss = 1547.78559710\n",
      "Iteration 13629, loss = 1547.59304471\n",
      "Iteration 13630, loss = 1547.40072702\n",
      "Iteration 13631, loss = 1547.20860790\n",
      "Iteration 13632, loss = 1547.01667563\n",
      "Iteration 13633, loss = 1546.82495448\n",
      "Iteration 13634, loss = 1546.63347313\n",
      "Iteration 13635, loss = 1546.44222732\n",
      "Iteration 13636, loss = 1546.25118860\n",
      "Iteration 13637, loss = 1546.06034155\n",
      "Iteration 13638, loss = 1545.86969830\n",
      "Iteration 13639, loss = 1545.67927755\n",
      "Iteration 13640, loss = 1545.48907978\n",
      "Iteration 13641, loss = 1545.29908908\n",
      "Iteration 13642, loss = 1545.10929367\n",
      "Iteration 13643, loss = 1544.91969825\n",
      "Iteration 13644, loss = 1544.73031486\n",
      "Iteration 13645, loss = 1544.54114477\n",
      "Iteration 13646, loss = 1544.35217723\n",
      "Iteration 13647, loss = 1544.16340442\n",
      "Iteration 13648, loss = 1543.97482961\n",
      "Iteration 13649, loss = 1543.78645946\n",
      "Iteration 13650, loss = 1543.59829372\n",
      "Iteration 13651, loss = 1543.41032595\n",
      "Iteration 13652, loss = 1543.22255148\n",
      "Iteration 13653, loss = 1543.03497163\n",
      "Iteration 13654, loss = 1542.84758998\n",
      "Iteration 13655, loss = 1542.66040626\n",
      "Iteration 13656, loss = 1542.47341609\n",
      "Iteration 13657, loss = 1542.28661622\n",
      "Iteration 13658, loss = 1542.10000741\n",
      "Iteration 13659, loss = 1541.91359146\n",
      "Iteration 13660, loss = 1541.72736762\n",
      "Iteration 13661, loss = 1541.54133303\n",
      "Iteration 13662, loss = 1541.35548563\n",
      "Iteration 13663, loss = 1541.16982538\n",
      "Iteration 13664, loss = 1540.98435293\n",
      "Iteration 13665, loss = 1540.79906770\n",
      "Iteration 13666, loss = 1540.61396771\n",
      "Iteration 13667, loss = 1540.42905131\n",
      "Iteration 13668, loss = 1540.24431810\n",
      "Iteration 13669, loss = 1540.05976825\n",
      "Iteration 13670, loss = 1539.87540111\n",
      "Iteration 13671, loss = 1539.69121522\n",
      "Iteration 13672, loss = 1539.50720930\n",
      "Iteration 13673, loss = 1539.32338277\n",
      "Iteration 13674, loss = 1539.13973537\n",
      "Iteration 13675, loss = 1538.95626649\n",
      "Iteration 13676, loss = 1538.77297506\n",
      "Iteration 13677, loss = 1538.58985997\n",
      "Iteration 13678, loss = 1538.40692050\n",
      "Iteration 13679, loss = 1538.22415624\n",
      "Iteration 13680, loss = 1538.04156659\n",
      "Iteration 13681, loss = 1537.85915066\n",
      "Iteration 13682, loss = 1537.67690749\n",
      "Iteration 13683, loss = 1537.49483636\n",
      "Iteration 13684, loss = 1537.31293670\n",
      "Iteration 13685, loss = 1537.13120790\n",
      "Iteration 13686, loss = 1536.94964924\n",
      "Iteration 13687, loss = 1536.76825986\n",
      "Iteration 13688, loss = 1536.58703903\n",
      "Iteration 13689, loss = 1536.40598612\n",
      "Iteration 13690, loss = 1536.22510053\n",
      "Iteration 13691, loss = 1536.04438159\n",
      "Iteration 13692, loss = 1535.86382855\n",
      "Iteration 13693, loss = 1535.68344069\n",
      "Iteration 13694, loss = 1535.50321737\n",
      "Iteration 13695, loss = 1535.32315797\n",
      "Iteration 13696, loss = 1535.14326186\n",
      "Iteration 13697, loss = 1534.96352838\n",
      "Iteration 13698, loss = 1534.78395682\n",
      "Iteration 13699, loss = 1534.60454655\n",
      "Iteration 13700, loss = 1534.42529695\n",
      "Iteration 13701, loss = 1534.24620742\n",
      "Iteration 13702, loss = 1534.06727733\n",
      "Iteration 13703, loss = 1533.88850603\n",
      "Iteration 13704, loss = 1533.70989288\n",
      "Iteration 13705, loss = 1533.53143729\n",
      "Iteration 13706, loss = 1533.35313867\n",
      "Iteration 13707, loss = 1533.17499640\n",
      "Iteration 13708, loss = 1532.99700989\n",
      "Iteration 13709, loss = 1532.81917853\n",
      "Iteration 13710, loss = 1532.64150172\n",
      "Iteration 13711, loss = 1532.46397889\n",
      "Iteration 13712, loss = 1532.28660945\n",
      "Iteration 13713, loss = 1532.10939283\n",
      "Iteration 13714, loss = 1531.93232845\n",
      "Iteration 13715, loss = 1531.75541573\n",
      "Iteration 13716, loss = 1531.57865411\n",
      "Iteration 13717, loss = 1531.40204303\n",
      "Iteration 13718, loss = 1531.22558194\n",
      "Iteration 13719, loss = 1531.04927027\n",
      "Iteration 13720, loss = 1530.87310747\n",
      "Iteration 13721, loss = 1530.69709300\n",
      "Iteration 13722, loss = 1530.52122631\n",
      "Iteration 13723, loss = 1530.34550687\n",
      "Iteration 13724, loss = 1530.16993414\n",
      "Iteration 13725, loss = 1529.99450759\n",
      "Iteration 13726, loss = 1529.81922669\n",
      "Iteration 13727, loss = 1529.64409091\n",
      "Iteration 13728, loss = 1529.46909973\n",
      "Iteration 13729, loss = 1529.29425264\n",
      "Iteration 13730, loss = 1529.11954912\n",
      "Iteration 13731, loss = 1528.94498867\n",
      "Iteration 13732, loss = 1528.77057077\n",
      "Iteration 13733, loss = 1528.59629492\n",
      "Iteration 13734, loss = 1528.42216062\n",
      "Iteration 13735, loss = 1528.24816737\n",
      "Iteration 13736, loss = 1528.07431469\n",
      "Iteration 13737, loss = 1527.90060208\n",
      "Iteration 13738, loss = 1527.72702906\n",
      "Iteration 13739, loss = 1527.55359513\n",
      "Iteration 13740, loss = 1527.38029983\n",
      "Iteration 13741, loss = 1527.20714267\n",
      "Iteration 13742, loss = 1527.03412317\n",
      "Iteration 13743, loss = 1526.86124088\n",
      "Iteration 13744, loss = 1526.68849532\n",
      "Iteration 13745, loss = 1526.51588602\n",
      "Iteration 13746, loss = 1526.34341253\n",
      "Iteration 13747, loss = 1526.17107438\n",
      "Iteration 13748, loss = 1525.99887112\n",
      "Iteration 13749, loss = 1525.82680230\n",
      "Iteration 13750, loss = 1525.65486747\n",
      "Iteration 13751, loss = 1525.48306617\n",
      "Iteration 13752, loss = 1525.31139797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13753, loss = 1525.13986243\n",
      "Iteration 13754, loss = 1524.96845910\n",
      "Iteration 13755, loss = 1524.79718755\n",
      "Iteration 13756, loss = 1524.62604735\n",
      "Iteration 13757, loss = 1524.45503807\n",
      "Iteration 13758, loss = 1524.28415928\n",
      "Iteration 13759, loss = 1524.11341055\n",
      "Iteration 13760, loss = 1523.94279147\n",
      "Iteration 13761, loss = 1523.77230161\n",
      "Iteration 13762, loss = 1523.60194056\n",
      "Iteration 13763, loss = 1523.43170790\n",
      "Iteration 13764, loss = 1523.26160322\n",
      "Iteration 13765, loss = 1523.09162611\n",
      "Iteration 13766, loss = 1522.92177617\n",
      "Iteration 13767, loss = 1522.75205299\n",
      "Iteration 13768, loss = 1522.58245617\n",
      "Iteration 13769, loss = 1522.41298531\n",
      "Iteration 13770, loss = 1522.24364002\n",
      "Iteration 13771, loss = 1522.07441989\n",
      "Iteration 13772, loss = 1521.90532455\n",
      "Iteration 13773, loss = 1521.73635359\n",
      "Iteration 13774, loss = 1521.56750663\n",
      "Iteration 13775, loss = 1521.39878329\n",
      "Iteration 13776, loss = 1521.23018318\n",
      "Iteration 13777, loss = 1521.06170592\n",
      "Iteration 13778, loss = 1520.89335115\n",
      "Iteration 13779, loss = 1520.72511847\n",
      "Iteration 13780, loss = 1520.55700752\n",
      "Iteration 13781, loss = 1520.38901792\n",
      "Iteration 13782, loss = 1520.22114931\n",
      "Iteration 13783, loss = 1520.05340132\n",
      "Iteration 13784, loss = 1519.88577358\n",
      "Iteration 13785, loss = 1519.71826574\n",
      "Iteration 13786, loss = 1519.55087742\n",
      "Iteration 13787, loss = 1519.38360828\n",
      "Iteration 13788, loss = 1519.21645796\n",
      "Iteration 13789, loss = 1519.04942610\n",
      "Iteration 13790, loss = 1518.88251235\n",
      "Iteration 13791, loss = 1518.71571636\n",
      "Iteration 13792, loss = 1518.54903779\n",
      "Iteration 13793, loss = 1518.38247627\n",
      "Iteration 13794, loss = 1518.21603149\n",
      "Iteration 13795, loss = 1518.04970308\n",
      "Iteration 13796, loss = 1517.88349071\n",
      "Iteration 13797, loss = 1517.71739404\n",
      "Iteration 13798, loss = 1517.55141274\n",
      "Iteration 13799, loss = 1517.38554646\n",
      "Iteration 13800, loss = 1517.21979489\n",
      "Iteration 13801, loss = 1517.05415768\n",
      "Iteration 13802, loss = 1516.88863451\n",
      "Iteration 13803, loss = 1516.72322505\n",
      "Iteration 13804, loss = 1516.55792898\n",
      "Iteration 13805, loss = 1516.39274597\n",
      "Iteration 13806, loss = 1516.22767570\n",
      "Iteration 13807, loss = 1516.06271785\n",
      "Iteration 13808, loss = 1515.89787210\n",
      "Iteration 13809, loss = 1515.73313814\n",
      "Iteration 13810, loss = 1515.56851565\n",
      "Iteration 13811, loss = 1515.40400432\n",
      "Iteration 13812, loss = 1515.23960384\n",
      "Iteration 13813, loss = 1515.07531390\n",
      "Iteration 13814, loss = 1514.91113419\n",
      "Iteration 13815, loss = 1514.74706440\n",
      "Iteration 13816, loss = 1514.58310423\n",
      "Iteration 13817, loss = 1514.41925338\n",
      "Iteration 13818, loss = 1514.25551154\n",
      "Iteration 13819, loss = 1514.09187843\n",
      "Iteration 13820, loss = 1513.92835372\n",
      "Iteration 13821, loss = 1513.76493715\n",
      "Iteration 13822, loss = 1513.60162839\n",
      "Iteration 13823, loss = 1513.43842717\n",
      "Iteration 13824, loss = 1513.27533320\n",
      "Iteration 13825, loss = 1513.11234617\n",
      "Iteration 13826, loss = 1512.94946581\n",
      "Iteration 13827, loss = 1512.78669182\n",
      "Iteration 13828, loss = 1512.62402393\n",
      "Iteration 13829, loss = 1512.46146184\n",
      "Iteration 13830, loss = 1512.29900527\n",
      "Iteration 13831, loss = 1512.13665394\n",
      "Iteration 13832, loss = 1511.97440758\n",
      "Iteration 13833, loss = 1511.81226590\n",
      "Iteration 13834, loss = 1511.65022863\n",
      "Iteration 13835, loss = 1511.48829549\n",
      "Iteration 13836, loss = 1511.32646621\n",
      "Iteration 13837, loss = 1511.16474051\n",
      "Iteration 13838, loss = 1511.00311813\n",
      "Iteration 13839, loss = 1510.84159879\n",
      "Iteration 13840, loss = 1510.68018223\n",
      "Iteration 13841, loss = 1510.51886817\n",
      "Iteration 13842, loss = 1510.35765636\n",
      "Iteration 13843, loss = 1510.19654652\n",
      "Iteration 13844, loss = 1510.03553840\n",
      "Iteration 13845, loss = 1509.87463174\n",
      "Iteration 13846, loss = 1509.71382626\n",
      "Iteration 13847, loss = 1509.55312172\n",
      "Iteration 13848, loss = 1509.39251786\n",
      "Iteration 13849, loss = 1509.23201441\n",
      "Iteration 13850, loss = 1509.07161113\n",
      "Iteration 13851, loss = 1508.91130776\n",
      "Iteration 13852, loss = 1508.75110404\n",
      "Iteration 13853, loss = 1508.59099973\n",
      "Iteration 13854, loss = 1508.43099457\n",
      "Iteration 13855, loss = 1508.27108832\n",
      "Iteration 13856, loss = 1508.11128073\n",
      "Iteration 13857, loss = 1507.95157154\n",
      "Iteration 13858, loss = 1507.79196053\n",
      "Iteration 13859, loss = 1507.63244743\n",
      "Iteration 13860, loss = 1507.47303201\n",
      "Iteration 13861, loss = 1507.31371403\n",
      "Iteration 13862, loss = 1507.15449325\n",
      "Iteration 13863, loss = 1506.99536941\n",
      "Iteration 13864, loss = 1506.83634230\n",
      "Iteration 13865, loss = 1506.67741167\n",
      "Iteration 13866, loss = 1506.51857727\n",
      "Iteration 13867, loss = 1506.35983889\n",
      "Iteration 13868, loss = 1506.20119628\n",
      "Iteration 13869, loss = 1506.04264922\n",
      "Iteration 13870, loss = 1505.88419746\n",
      "Iteration 13871, loss = 1505.72584078\n",
      "Iteration 13872, loss = 1505.56757895\n",
      "Iteration 13873, loss = 1505.40941175\n",
      "Iteration 13874, loss = 1505.25133893\n",
      "Iteration 13875, loss = 1505.09336029\n",
      "Iteration 13876, loss = 1504.93547558\n",
      "Iteration 13877, loss = 1504.77768459\n",
      "Iteration 13878, loss = 1504.61998710\n",
      "Iteration 13879, loss = 1504.46238287\n",
      "Iteration 13880, loss = 1504.30487170\n",
      "Iteration 13881, loss = 1504.14745336\n",
      "Iteration 13882, loss = 1503.99012763\n",
      "Iteration 13883, loss = 1503.83289429\n",
      "Iteration 13884, loss = 1503.67575313\n",
      "Iteration 13885, loss = 1503.51870393\n",
      "Iteration 13886, loss = 1503.36174647\n",
      "Iteration 13887, loss = 1503.20488055\n",
      "Iteration 13888, loss = 1503.04810594\n",
      "Iteration 13889, loss = 1502.89142243\n",
      "Iteration 13890, loss = 1502.73482982\n",
      "Iteration 13891, loss = 1502.57832789\n",
      "Iteration 13892, loss = 1502.42191643\n",
      "Iteration 13893, loss = 1502.26559524\n",
      "Iteration 13894, loss = 1502.10936411\n",
      "Iteration 13895, loss = 1501.95322283\n",
      "Iteration 13896, loss = 1501.79717119\n",
      "Iteration 13897, loss = 1501.64120899\n",
      "Iteration 13898, loss = 1501.48533603\n",
      "Iteration 13899, loss = 1501.32955210\n",
      "Iteration 13900, loss = 1501.17385701\n",
      "Iteration 13901, loss = 1501.01825054\n",
      "Iteration 13902, loss = 1500.86273251\n",
      "Iteration 13903, loss = 1500.70730270\n",
      "Iteration 13904, loss = 1500.55196093\n",
      "Iteration 13905, loss = 1500.39670699\n",
      "Iteration 13906, loss = 1500.24154070\n",
      "Iteration 13907, loss = 1500.08646185\n",
      "Iteration 13908, loss = 1499.93147027\n",
      "Iteration 13909, loss = 1499.77656577\n",
      "Iteration 13910, loss = 1499.62174816\n",
      "Iteration 13911, loss = 1499.46701732\n",
      "Iteration 13912, loss = 1499.31237309\n",
      "Iteration 13913, loss = 1499.15781542\n",
      "Iteration 13914, loss = 1499.00334433\n",
      "Iteration 13915, loss = 1498.84896002\n",
      "Iteration 13916, loss = 1498.69466298\n",
      "Iteration 13917, loss = 1498.54045422\n",
      "Iteration 13918, loss = 1498.38633526\n",
      "Iteration 13919, loss = 1498.23230843\n",
      "Iteration 13920, loss = 1498.07837489\n",
      "Iteration 13921, loss = 1497.92453257\n",
      "Iteration 13922, loss = 1497.77076827\n",
      "Iteration 13923, loss = 1497.61706344\n",
      "Iteration 13924, loss = 1497.46340675\n",
      "Iteration 13925, loss = 1497.30981732\n",
      "Iteration 13926, loss = 1497.15632862\n",
      "Iteration 13927, loss = 1497.00295994\n",
      "Iteration 13928, loss = 1496.84970108\n",
      "Iteration 13929, loss = 1496.69652113\n",
      "Iteration 13930, loss = 1496.54339542\n",
      "Iteration 13931, loss = 1496.39033007\n",
      "Iteration 13932, loss = 1496.23735457\n",
      "Iteration 13933, loss = 1496.08448615\n",
      "Iteration 13934, loss = 1495.93171380\n",
      "Iteration 13935, loss = 1495.77901623\n",
      "Iteration 13936, loss = 1495.62638400\n",
      "Iteration 13937, loss = 1495.47382574\n",
      "Iteration 13938, loss = 1495.32135710\n",
      "Iteration 13939, loss = 1495.16898372\n",
      "Iteration 13940, loss = 1495.01669544\n",
      "Iteration 13941, loss = 1494.86447941\n",
      "Iteration 13942, loss = 1494.71233539\n",
      "Iteration 13943, loss = 1494.56027347\n",
      "Iteration 13944, loss = 1494.40830013\n",
      "Iteration 13945, loss = 1494.25641198\n",
      "Iteration 13946, loss = 1494.10460182\n",
      "Iteration 13947, loss = 1493.95286644\n",
      "Iteration 13948, loss = 1493.80120875\n",
      "Iteration 13949, loss = 1493.64963395\n",
      "Iteration 13950, loss = 1493.49814328\n",
      "Iteration 13951, loss = 1493.34673279\n",
      "Iteration 13952, loss = 1493.19539849\n",
      "Iteration 13953, loss = 1493.04414089\n",
      "Iteration 13954, loss = 1492.89296318\n",
      "Iteration 13955, loss = 1492.74186689\n",
      "Iteration 13956, loss = 1492.59085062\n",
      "Iteration 13957, loss = 1492.43991209\n",
      "Iteration 13958, loss = 1492.28905026\n",
      "Iteration 13959, loss = 1492.13826606\n",
      "Iteration 13960, loss = 1491.98756103\n",
      "Iteration 13961, loss = 1491.83693536\n",
      "Iteration 13962, loss = 1491.68638765\n",
      "Iteration 13963, loss = 1491.53591662\n",
      "Iteration 13964, loss = 1491.38552232\n",
      "Iteration 13965, loss = 1491.23520556\n",
      "Iteration 13966, loss = 1491.08496673\n",
      "Iteration 13967, loss = 1490.93480542\n",
      "Iteration 13968, loss = 1490.78472085\n",
      "Iteration 13969, loss = 1490.63471248\n",
      "Iteration 13970, loss = 1490.48478039\n",
      "Iteration 13971, loss = 1490.33492498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13972, loss = 1490.18514630\n",
      "Iteration 13973, loss = 1490.03544393\n",
      "Iteration 13974, loss = 1489.88581733\n",
      "Iteration 13975, loss = 1489.73626630\n",
      "Iteration 13976, loss = 1489.58679090\n",
      "Iteration 13977, loss = 1489.43739120\n",
      "Iteration 13978, loss = 1489.28806712\n",
      "Iteration 13979, loss = 1489.13881834\n",
      "Iteration 13980, loss = 1488.98964456\n",
      "Iteration 13981, loss = 1488.84054558\n",
      "Iteration 13982, loss = 1488.69152140\n",
      "Iteration 13983, loss = 1488.54257200\n",
      "Iteration 13984, loss = 1488.39369724\n",
      "Iteration 13985, loss = 1488.24489687\n",
      "Iteration 13986, loss = 1488.09617069\n",
      "Iteration 13987, loss = 1487.94751853\n",
      "Iteration 13988, loss = 1487.79894033\n",
      "Iteration 13989, loss = 1487.65043598\n",
      "Iteration 13990, loss = 1487.50200538\n",
      "Iteration 13991, loss = 1487.35364833\n",
      "Iteration 13992, loss = 1487.20536464\n",
      "Iteration 13993, loss = 1487.05715417\n",
      "Iteration 13994, loss = 1486.90901681\n",
      "Iteration 13995, loss = 1486.76095246\n",
      "Iteration 13996, loss = 1486.61296098\n",
      "Iteration 13997, loss = 1486.46504221\n",
      "Iteration 13998, loss = 1486.31719601\n",
      "Iteration 13999, loss = 1486.16942222\n",
      "Iteration 14000, loss = 1486.02172071\n",
      "Iteration 14001, loss = 1485.87409138\n",
      "Iteration 14002, loss = 1485.72653409\n",
      "Iteration 14003, loss = 1485.57904870\n",
      "Iteration 14004, loss = 1485.43163507\n",
      "Iteration 14005, loss = 1485.28429305\n",
      "Iteration 14006, loss = 1485.13702252\n",
      "Iteration 14007, loss = 1484.98982335\n",
      "Iteration 14008, loss = 1484.84269542\n",
      "Iteration 14009, loss = 1484.69563859\n",
      "Iteration 14010, loss = 1484.54865273\n",
      "Iteration 14011, loss = 1484.40173770\n",
      "Iteration 14012, loss = 1484.25489337\n",
      "Iteration 14013, loss = 1484.10811961\n",
      "Iteration 14014, loss = 1483.96141631\n",
      "Iteration 14015, loss = 1483.81478332\n",
      "Iteration 14016, loss = 1483.66822052\n",
      "Iteration 14017, loss = 1483.52172779\n",
      "Iteration 14018, loss = 1483.37530499\n",
      "Iteration 14019, loss = 1483.22895200\n",
      "Iteration 14020, loss = 1483.08266868\n",
      "Iteration 14021, loss = 1482.93645492\n",
      "Iteration 14022, loss = 1482.79031059\n",
      "Iteration 14023, loss = 1482.64423557\n",
      "Iteration 14024, loss = 1482.49822972\n",
      "Iteration 14025, loss = 1482.35229293\n",
      "Iteration 14026, loss = 1482.20642507\n",
      "Iteration 14027, loss = 1482.06062601\n",
      "Iteration 14028, loss = 1481.91489564\n",
      "Iteration 14029, loss = 1481.76923382\n",
      "Iteration 14030, loss = 1481.62364045\n",
      "Iteration 14031, loss = 1481.47811540\n",
      "Iteration 14032, loss = 1481.33265854\n",
      "Iteration 14033, loss = 1481.18726975\n",
      "Iteration 14034, loss = 1481.04194892\n",
      "Iteration 14035, loss = 1480.89669592\n",
      "Iteration 14036, loss = 1480.75151064\n",
      "Iteration 14037, loss = 1480.60639295\n",
      "Iteration 14038, loss = 1480.46134274\n",
      "Iteration 14039, loss = 1480.31635988\n",
      "Iteration 14040, loss = 1480.17144426\n",
      "Iteration 14041, loss = 1480.02659576\n",
      "Iteration 14042, loss = 1479.88181427\n",
      "Iteration 14043, loss = 1479.73709966\n",
      "Iteration 14044, loss = 1479.59245182\n",
      "Iteration 14045, loss = 1479.44787063\n",
      "Iteration 14046, loss = 1479.30335599\n",
      "Iteration 14047, loss = 1479.15890776\n",
      "Iteration 14048, loss = 1479.01452584\n",
      "Iteration 14049, loss = 1478.87021012\n",
      "Iteration 14050, loss = 1478.72596047\n",
      "Iteration 14051, loss = 1478.58177678\n",
      "Iteration 14052, loss = 1478.43765895\n",
      "Iteration 14053, loss = 1478.29360685\n",
      "Iteration 14054, loss = 1478.14962038\n",
      "Iteration 14055, loss = 1478.00569942\n",
      "Iteration 14056, loss = 1477.86184385\n",
      "Iteration 14057, loss = 1477.71805358\n",
      "Iteration 14058, loss = 1477.57432848\n",
      "Iteration 14059, loss = 1477.43066845\n",
      "Iteration 14060, loss = 1477.28707337\n",
      "Iteration 14061, loss = 1477.14354314\n",
      "Iteration 14062, loss = 1477.00007764\n",
      "Iteration 14063, loss = 1476.85667677\n",
      "Iteration 14064, loss = 1476.71334041\n",
      "Iteration 14065, loss = 1476.57006846\n",
      "Iteration 14066, loss = 1476.42686081\n",
      "Iteration 14067, loss = 1476.28371735\n",
      "Iteration 14068, loss = 1476.14063796\n",
      "Iteration 14069, loss = 1475.99762256\n",
      "Iteration 14070, loss = 1475.85467102\n",
      "Iteration 14071, loss = 1475.71178324\n",
      "Iteration 14072, loss = 1475.56895912\n",
      "Iteration 14073, loss = 1475.42619854\n",
      "Iteration 14074, loss = 1475.28350141\n",
      "Iteration 14075, loss = 1475.14086761\n",
      "Iteration 14076, loss = 1474.99829705\n",
      "Iteration 14077, loss = 1474.85578961\n",
      "Iteration 14078, loss = 1474.71334519\n",
      "Iteration 14079, loss = 1474.57096369\n",
      "Iteration 14080, loss = 1474.42864501\n",
      "Iteration 14081, loss = 1474.28638904\n",
      "Iteration 14082, loss = 1474.14419567\n",
      "Iteration 14083, loss = 1474.00206481\n",
      "Iteration 14084, loss = 1473.85999635\n",
      "Iteration 14085, loss = 1473.71799019\n",
      "Iteration 14086, loss = 1473.57604623\n",
      "Iteration 14087, loss = 1473.43416437\n",
      "Iteration 14088, loss = 1473.29234450\n",
      "Iteration 14089, loss = 1473.15058652\n",
      "Iteration 14090, loss = 1473.00889034\n",
      "Iteration 14091, loss = 1472.86725586\n",
      "Iteration 14092, loss = 1472.72568296\n",
      "Iteration 14093, loss = 1472.58417156\n",
      "Iteration 14094, loss = 1472.44272155\n",
      "Iteration 14095, loss = 1472.30133284\n",
      "Iteration 14096, loss = 1472.16000533\n",
      "Iteration 14097, loss = 1472.01873891\n",
      "Iteration 14098, loss = 1471.87753349\n",
      "Iteration 14099, loss = 1471.73638897\n",
      "Iteration 14100, loss = 1471.59530526\n",
      "Iteration 14101, loss = 1471.45428225\n",
      "Iteration 14102, loss = 1471.31331985\n",
      "Iteration 14103, loss = 1471.17241797\n",
      "Iteration 14104, loss = 1471.03157650\n",
      "Iteration 14105, loss = 1470.89079536\n",
      "Iteration 14106, loss = 1470.75007443\n",
      "Iteration 14107, loss = 1470.60941364\n",
      "Iteration 14108, loss = 1470.46881288\n",
      "Iteration 14109, loss = 1470.32827206\n",
      "Iteration 14110, loss = 1470.18779108\n",
      "Iteration 14111, loss = 1470.04736985\n",
      "Iteration 14112, loss = 1469.90700828\n",
      "Iteration 14113, loss = 1469.76670627\n",
      "Iteration 14114, loss = 1469.62646373\n",
      "Iteration 14115, loss = 1469.48628056\n",
      "Iteration 14116, loss = 1469.34615667\n",
      "Iteration 14117, loss = 1469.20609197\n",
      "Iteration 14118, loss = 1469.06608637\n",
      "Iteration 14119, loss = 1468.92613978\n",
      "Iteration 14120, loss = 1468.78625209\n",
      "Iteration 14121, loss = 1468.64642323\n",
      "Iteration 14122, loss = 1468.50665309\n",
      "Iteration 14123, loss = 1468.36694160\n",
      "Iteration 14124, loss = 1468.22728865\n",
      "Iteration 14125, loss = 1468.08769416\n",
      "Iteration 14126, loss = 1467.94815803\n",
      "Iteration 14127, loss = 1467.80868018\n",
      "Iteration 14128, loss = 1467.66926052\n",
      "Iteration 14129, loss = 1467.52989895\n",
      "Iteration 14130, loss = 1467.39059539\n",
      "Iteration 14131, loss = 1467.25134976\n",
      "Iteration 14132, loss = 1467.11216195\n",
      "Iteration 14133, loss = 1466.97303188\n",
      "Iteration 14134, loss = 1466.83395946\n",
      "Iteration 14135, loss = 1466.69494462\n",
      "Iteration 14136, loss = 1466.55598725\n",
      "Iteration 14137, loss = 1466.41708726\n",
      "Iteration 14138, loss = 1466.27824459\n",
      "Iteration 14139, loss = 1466.13945912\n",
      "Iteration 14140, loss = 1466.00073079\n",
      "Iteration 14141, loss = 1465.86205950\n",
      "Iteration 14142, loss = 1465.72344517\n",
      "Iteration 14143, loss = 1465.58488771\n",
      "Iteration 14144, loss = 1465.44638704\n",
      "Iteration 14145, loss = 1465.30794307\n",
      "Iteration 14146, loss = 1465.16955571\n",
      "Iteration 14147, loss = 1465.03122490\n",
      "Iteration 14148, loss = 1464.89295054\n",
      "Iteration 14149, loss = 1464.75473256\n",
      "Iteration 14150, loss = 1464.61657089\n",
      "Iteration 14151, loss = 1464.47846548\n",
      "Iteration 14152, loss = 1464.34041628\n",
      "Iteration 14153, loss = 1464.20242328\n",
      "Iteration 14154, loss = 1464.06448653\n",
      "Iteration 14155, loss = 1463.92660618\n",
      "Iteration 14156, loss = 1463.78878253\n",
      "Iteration 14157, loss = 1463.65101616\n",
      "Iteration 14158, loss = 1463.51330815\n",
      "Iteration 14159, loss = 1463.37566016\n",
      "Iteration 14160, loss = 1463.23807479\n",
      "Iteration 14161, loss = 1463.10055473\n",
      "Iteration 14162, loss = 1462.96310118\n",
      "Iteration 14163, loss = 1462.82570736\n",
      "Iteration 14164, loss = 1462.68835417\n",
      "Iteration 14165, loss = 1462.55101259\n",
      "Iteration 14166, loss = 1462.41367615\n",
      "Iteration 14167, loss = 1462.27638300\n",
      "Iteration 14168, loss = 1462.13918807\n",
      "Iteration 14169, loss = 1462.00210480\n",
      "Iteration 14170, loss = 1461.86509529\n",
      "Iteration 14171, loss = 1461.72811010\n",
      "Iteration 14172, loss = 1461.59113467\n",
      "Iteration 14173, loss = 1461.45420354\n",
      "Iteration 14174, loss = 1461.31735836\n",
      "Iteration 14175, loss = 1461.18059967\n",
      "Iteration 14176, loss = 1461.04389289\n",
      "Iteration 14177, loss = 1460.90721219\n",
      "Iteration 14178, loss = 1460.77056823\n",
      "Iteration 14179, loss = 1460.63399023\n",
      "Iteration 14180, loss = 1460.49748847\n",
      "Iteration 14181, loss = 1460.36104528\n",
      "Iteration 14182, loss = 1460.22464063\n",
      "Iteration 14183, loss = 1460.08827628\n",
      "Iteration 14184, loss = 1459.95196996\n",
      "Iteration 14185, loss = 1459.81573095\n",
      "Iteration 14186, loss = 1459.67955008\n",
      "Iteration 14187, loss = 1459.54341423\n",
      "Iteration 14188, loss = 1459.40732295\n",
      "Iteration 14189, loss = 1459.27128650\n",
      "Iteration 14190, loss = 1459.13531122\n",
      "Iteration 14191, loss = 1458.99939251\n",
      "Iteration 14192, loss = 1458.86352243\n",
      "Iteration 14193, loss = 1458.72769977\n",
      "Iteration 14194, loss = 1458.59193019\n",
      "Iteration 14195, loss = 1458.45621796\n",
      "Iteration 14196, loss = 1458.32056101\n",
      "Iteration 14197, loss = 1458.18495449\n",
      "Iteration 14198, loss = 1458.04939706\n",
      "Iteration 14199, loss = 1457.91389174\n",
      "Iteration 14200, loss = 1457.77844136\n",
      "Iteration 14201, loss = 1457.64304512\n",
      "Iteration 14202, loss = 1457.50770018\n",
      "Iteration 14203, loss = 1457.37240533\n",
      "Iteration 14204, loss = 1457.23716198\n",
      "Iteration 14205, loss = 1457.10197190\n",
      "Iteration 14206, loss = 1456.96683504\n",
      "Iteration 14207, loss = 1456.83174984\n",
      "Iteration 14208, loss = 1456.69671525\n",
      "Iteration 14209, loss = 1456.56173172\n",
      "Iteration 14210, loss = 1456.42680036\n",
      "Iteration 14211, loss = 1456.29192142\n",
      "Iteration 14212, loss = 1456.15709412\n",
      "Iteration 14213, loss = 1456.02231763\n",
      "Iteration 14214, loss = 1455.88759197\n",
      "Iteration 14215, loss = 1455.75291768\n",
      "Iteration 14216, loss = 1455.61829509\n",
      "Iteration 14217, loss = 1455.48372390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14218, loss = 1455.34920356\n",
      "Iteration 14219, loss = 1455.21473384\n",
      "Iteration 14220, loss = 1455.08031494\n",
      "Iteration 14221, loss = 1454.94594711\n",
      "Iteration 14222, loss = 1454.81163030\n",
      "Iteration 14223, loss = 1454.67736421\n",
      "Iteration 14224, loss = 1454.54314856\n",
      "Iteration 14225, loss = 1454.40898333\n",
      "Iteration 14226, loss = 1454.27486865\n",
      "Iteration 14227, loss = 1454.14080456\n",
      "Iteration 14228, loss = 1454.00679091\n",
      "Iteration 14229, loss = 1453.87282751\n",
      "Iteration 14230, loss = 1453.73891422\n",
      "Iteration 14231, loss = 1453.60505105\n",
      "Iteration 14232, loss = 1453.47123802\n",
      "Iteration 14233, loss = 1453.33747511\n",
      "Iteration 14234, loss = 1453.20376217\n",
      "Iteration 14235, loss = 1453.07009908\n",
      "Iteration 14236, loss = 1452.93648575\n",
      "Iteration 14237, loss = 1452.80292217\n",
      "Iteration 14238, loss = 1452.66940832\n",
      "Iteration 14239, loss = 1452.53594414\n",
      "Iteration 14240, loss = 1452.40252952\n",
      "Iteration 14241, loss = 1452.26916436\n",
      "Iteration 14242, loss = 1452.13584859\n",
      "Iteration 14243, loss = 1452.00258219\n",
      "Iteration 14244, loss = 1451.86936510\n",
      "Iteration 14245, loss = 1451.73619726\n",
      "Iteration 14246, loss = 1451.60307859\n",
      "Iteration 14247, loss = 1451.47000900\n",
      "Iteration 14248, loss = 1451.33698843\n",
      "Iteration 14249, loss = 1451.20401682\n",
      "Iteration 14250, loss = 1451.07109414\n",
      "Iteration 14251, loss = 1450.93822030\n",
      "Iteration 14252, loss = 1450.80539524\n",
      "Iteration 14253, loss = 1450.67261888\n",
      "Iteration 14254, loss = 1450.53989116\n",
      "Iteration 14255, loss = 1450.40721203\n",
      "Iteration 14256, loss = 1450.27458141\n",
      "Iteration 14257, loss = 1450.14199926\n",
      "Iteration 14258, loss = 1450.00946551\n",
      "Iteration 14259, loss = 1449.87698008\n",
      "Iteration 14260, loss = 1449.74454292\n",
      "Iteration 14261, loss = 1449.61215396\n",
      "Iteration 14262, loss = 1449.47981313\n",
      "Iteration 14263, loss = 1449.34752040\n",
      "Iteration 14264, loss = 1449.21527567\n",
      "Iteration 14265, loss = 1449.08307891\n",
      "Iteration 14266, loss = 1448.95093003\n",
      "Iteration 14267, loss = 1448.81882898\n",
      "Iteration 14268, loss = 1448.68677570\n",
      "Iteration 14269, loss = 1448.55477013\n",
      "Iteration 14270, loss = 1448.42281220\n",
      "Iteration 14271, loss = 1448.29090185\n",
      "Iteration 14272, loss = 1448.15903903\n",
      "Iteration 14273, loss = 1448.02722367\n",
      "Iteration 14274, loss = 1447.89545571\n",
      "Iteration 14275, loss = 1447.76373509\n",
      "Iteration 14276, loss = 1447.63206174\n",
      "Iteration 14277, loss = 1447.50043562\n",
      "Iteration 14278, loss = 1447.36885665\n",
      "Iteration 14279, loss = 1447.23732479\n",
      "Iteration 14280, loss = 1447.10583996\n",
      "Iteration 14281, loss = 1446.97440211\n",
      "Iteration 14282, loss = 1446.84301117\n",
      "Iteration 14283, loss = 1446.71166710\n",
      "Iteration 14284, loss = 1446.58036982\n",
      "Iteration 14285, loss = 1446.44911929\n",
      "Iteration 14286, loss = 1446.31791543\n",
      "Iteration 14287, loss = 1446.18675820\n",
      "Iteration 14288, loss = 1446.05564753\n",
      "Iteration 14289, loss = 1445.92458337\n",
      "Iteration 14290, loss = 1445.79356565\n",
      "Iteration 14291, loss = 1445.66259431\n",
      "Iteration 14292, loss = 1445.53166931\n",
      "Iteration 14293, loss = 1445.40079058\n",
      "Iteration 14294, loss = 1445.26995806\n",
      "Iteration 14295, loss = 1445.13917169\n",
      "Iteration 14296, loss = 1445.00843142\n",
      "Iteration 14297, loss = 1444.87773719\n",
      "Iteration 14298, loss = 1444.74708894\n",
      "Iteration 14299, loss = 1444.61648662\n",
      "Iteration 14300, loss = 1444.48593016\n",
      "Iteration 14301, loss = 1444.35541952\n",
      "Iteration 14302, loss = 1444.22495462\n",
      "Iteration 14303, loss = 1444.09453543\n",
      "Iteration 14304, loss = 1443.96416187\n",
      "Iteration 14305, loss = 1443.83383390\n",
      "Iteration 14306, loss = 1443.70355145\n",
      "Iteration 14307, loss = 1443.57331447\n",
      "Iteration 14308, loss = 1443.44312291\n",
      "Iteration 14309, loss = 1443.31297671\n",
      "Iteration 14310, loss = 1443.18287581\n",
      "Iteration 14311, loss = 1443.05282015\n",
      "Iteration 14312, loss = 1442.92280969\n",
      "Iteration 14313, loss = 1442.79284436\n",
      "Iteration 14314, loss = 1442.66292411\n",
      "Iteration 14315, loss = 1442.53304888\n",
      "Iteration 14316, loss = 1442.40321863\n",
      "Iteration 14317, loss = 1442.27343329\n",
      "Iteration 14318, loss = 1442.14369281\n",
      "Iteration 14319, loss = 1442.01399714\n",
      "Iteration 14320, loss = 1441.88434621\n",
      "Iteration 14321, loss = 1441.75473999\n",
      "Iteration 14322, loss = 1441.62517840\n",
      "Iteration 14323, loss = 1441.49566140\n",
      "Iteration 14324, loss = 1441.36618894\n",
      "Iteration 14325, loss = 1441.23676095\n",
      "Iteration 14326, loss = 1441.10737739\n",
      "Iteration 14327, loss = 1440.97803820\n",
      "Iteration 14328, loss = 1440.84874333\n",
      "Iteration 14329, loss = 1440.71949273\n",
      "Iteration 14330, loss = 1440.59028633\n",
      "Iteration 14331, loss = 1440.46112410\n",
      "Iteration 14332, loss = 1440.33200597\n",
      "Iteration 14333, loss = 1440.20293189\n",
      "Iteration 14334, loss = 1440.07390181\n",
      "Iteration 14335, loss = 1439.94491567\n",
      "Iteration 14336, loss = 1439.81597343\n",
      "Iteration 14337, loss = 1439.68707504\n",
      "Iteration 14338, loss = 1439.55822043\n",
      "Iteration 14339, loss = 1439.42940955\n",
      "Iteration 14340, loss = 1439.30064237\n",
      "Iteration 14341, loss = 1439.17191881\n",
      "Iteration 14342, loss = 1439.04323883\n",
      "Iteration 14343, loss = 1438.91460239\n",
      "Iteration 14344, loss = 1438.78600942\n",
      "Iteration 14345, loss = 1438.65745987\n",
      "Iteration 14346, loss = 1438.52895370\n",
      "Iteration 14347, loss = 1438.40049085\n",
      "Iteration 14348, loss = 1438.27207128\n",
      "Iteration 14349, loss = 1438.14369492\n",
      "Iteration 14350, loss = 1438.01536173\n",
      "Iteration 14351, loss = 1437.88707167\n",
      "Iteration 14352, loss = 1437.75882467\n",
      "Iteration 14353, loss = 1437.63062068\n",
      "Iteration 14354, loss = 1437.50245967\n",
      "Iteration 14355, loss = 1437.37434156\n",
      "Iteration 14356, loss = 1437.24626633\n",
      "Iteration 14357, loss = 1437.11823391\n",
      "Iteration 14358, loss = 1436.99024425\n",
      "Iteration 14359, loss = 1436.86229732\n",
      "Iteration 14360, loss = 1436.73439304\n",
      "Iteration 14361, loss = 1436.60653139\n",
      "Iteration 14362, loss = 1436.47871229\n",
      "Iteration 14363, loss = 1436.35093572\n",
      "Iteration 14364, loss = 1436.22320161\n",
      "Iteration 14365, loss = 1436.09550993\n",
      "Iteration 14366, loss = 1435.96786061\n",
      "Iteration 14367, loss = 1435.84025361\n",
      "Iteration 14368, loss = 1435.71268888\n",
      "Iteration 14369, loss = 1435.58516637\n",
      "Iteration 14370, loss = 1435.45768603\n",
      "Iteration 14371, loss = 1435.33024782\n",
      "Iteration 14372, loss = 1435.20285169\n",
      "Iteration 14373, loss = 1435.07549758\n",
      "Iteration 14374, loss = 1434.94818545\n",
      "Iteration 14375, loss = 1434.82091526\n",
      "Iteration 14376, loss = 1434.69368694\n",
      "Iteration 14377, loss = 1434.56650046\n",
      "Iteration 14378, loss = 1434.43935577\n",
      "Iteration 14379, loss = 1434.31225282\n",
      "Iteration 14380, loss = 1434.18519156\n",
      "Iteration 14381, loss = 1434.05817194\n",
      "Iteration 14382, loss = 1433.93119392\n",
      "Iteration 14383, loss = 1433.80425744\n",
      "Iteration 14384, loss = 1433.67736247\n",
      "Iteration 14385, loss = 1433.55050895\n",
      "Iteration 14386, loss = 1433.42369684\n",
      "Iteration 14387, loss = 1433.29692609\n",
      "Iteration 14388, loss = 1433.17019666\n",
      "Iteration 14389, loss = 1433.04350849\n",
      "Iteration 14390, loss = 1432.91686154\n",
      "Iteration 14391, loss = 1432.79025577\n",
      "Iteration 14392, loss = 1432.66369112\n",
      "Iteration 14393, loss = 1432.53716756\n",
      "Iteration 14394, loss = 1432.41068503\n",
      "Iteration 14395, loss = 1432.28424351\n",
      "Iteration 14396, loss = 1432.15784294\n",
      "Iteration 14397, loss = 1432.03148329\n",
      "Iteration 14398, loss = 1431.90516454\n",
      "Iteration 14399, loss = 1431.77888667\n",
      "Iteration 14400, loss = 1431.65264971\n",
      "Iteration 14401, loss = 1431.52645370\n",
      "Iteration 14402, loss = 1431.40029880\n",
      "Iteration 14403, loss = 1431.27418533\n",
      "Iteration 14404, loss = 1431.14811385\n",
      "Iteration 14405, loss = 1431.02208542\n",
      "Iteration 14406, loss = 1430.89610187\n",
      "Iteration 14407, loss = 1430.77016614\n",
      "Iteration 14408, loss = 1430.64428216\n",
      "Iteration 14409, loss = 1430.51845333\n",
      "Iteration 14410, loss = 1430.39267640\n",
      "Iteration 14411, loss = 1430.26693230\n",
      "Iteration 14412, loss = 1430.14118301\n",
      "Iteration 14413, loss = 1430.01540526\n",
      "Iteration 14414, loss = 1429.88963528\n",
      "Iteration 14415, loss = 1429.76395111\n",
      "Iteration 14416, loss = 1429.63838519\n",
      "Iteration 14417, loss = 1429.51289160\n",
      "Iteration 14418, loss = 1429.38739939\n",
      "Iteration 14419, loss = 1429.26188654\n",
      "Iteration 14420, loss = 1429.13640353\n",
      "Iteration 14421, loss = 1429.01100652\n",
      "Iteration 14422, loss = 1428.88568793\n",
      "Iteration 14423, loss = 1428.76039612\n",
      "Iteration 14424, loss = 1428.63510417\n",
      "Iteration 14425, loss = 1428.50983963\n",
      "Iteration 14426, loss = 1428.38464169\n",
      "Iteration 14427, loss = 1428.25950838\n",
      "Iteration 14428, loss = 1428.13440589\n",
      "Iteration 14429, loss = 1428.00931794\n",
      "Iteration 14430, loss = 1427.88426435\n",
      "Iteration 14431, loss = 1427.75926834\n",
      "Iteration 14432, loss = 1427.63432477\n",
      "Iteration 14433, loss = 1427.50941233\n",
      "Iteration 14434, loss = 1427.38452467\n",
      "Iteration 14435, loss = 1427.25967613\n",
      "Iteration 14436, loss = 1427.13487864\n",
      "Iteration 14437, loss = 1427.01012610\n",
      "Iteration 14438, loss = 1426.88540590\n",
      "Iteration 14439, loss = 1426.76071691\n",
      "Iteration 14440, loss = 1426.63606878\n",
      "Iteration 14441, loss = 1426.51146693\n",
      "Iteration 14442, loss = 1426.38690607\n",
      "Iteration 14443, loss = 1426.26237924\n",
      "Iteration 14444, loss = 1426.13788724\n",
      "Iteration 14445, loss = 1426.01343614\n",
      "Iteration 14446, loss = 1425.88902808\n",
      "Iteration 14447, loss = 1425.76465919\n",
      "Iteration 14448, loss = 1425.64032577\n",
      "Iteration 14449, loss = 1425.51602908\n",
      "Iteration 14450, loss = 1425.39177261\n",
      "Iteration 14451, loss = 1425.26755708\n",
      "Iteration 14452, loss = 1425.14338003\n",
      "Iteration 14453, loss = 1425.01923952\n",
      "Iteration 14454, loss = 1424.89513644\n",
      "Iteration 14455, loss = 1424.77107284\n",
      "Iteration 14456, loss = 1424.64704897\n",
      "Iteration 14457, loss = 1424.52306329\n",
      "Iteration 14458, loss = 1424.39911472\n",
      "Iteration 14459, loss = 1424.27520383\n",
      "Iteration 14460, loss = 1424.15133179\n",
      "Iteration 14461, loss = 1424.02749869\n",
      "Iteration 14462, loss = 1423.90370364\n",
      "Iteration 14463, loss = 1423.77994600\n",
      "Iteration 14464, loss = 1423.65622603\n",
      "Iteration 14465, loss = 1423.53254439\n",
      "Iteration 14466, loss = 1423.40890119\n",
      "Iteration 14467, loss = 1423.28529592\n",
      "Iteration 14468, loss = 1423.16172814\n",
      "Iteration 14469, loss = 1423.03819794\n",
      "Iteration 14470, loss = 1422.91470569\n",
      "Iteration 14471, loss = 1422.79125148\n",
      "Iteration 14472, loss = 1422.66783505\n",
      "Iteration 14473, loss = 1422.54445609\n",
      "Iteration 14474, loss = 1422.42111459\n",
      "Iteration 14475, loss = 1422.29781072\n",
      "Iteration 14476, loss = 1422.17454458\n",
      "Iteration 14477, loss = 1422.05131603\n",
      "Iteration 14478, loss = 1421.92812488\n",
      "Iteration 14479, loss = 1421.80497105\n",
      "Iteration 14480, loss = 1421.68185459\n",
      "Iteration 14481, loss = 1421.55877559\n",
      "Iteration 14482, loss = 1421.43573397\n",
      "Iteration 14483, loss = 1421.31272963\n",
      "Iteration 14484, loss = 1421.18976246\n",
      "Iteration 14485, loss = 1421.06683245\n",
      "Iteration 14486, loss = 1420.94393964\n",
      "Iteration 14487, loss = 1420.82108402\n",
      "Iteration 14488, loss = 1420.69826550\n",
      "Iteration 14489, loss = 1420.57548401\n",
      "Iteration 14490, loss = 1420.45273949\n",
      "Iteration 14491, loss = 1420.33003195\n",
      "Iteration 14492, loss = 1420.20736138\n",
      "Iteration 14493, loss = 1420.08472773\n",
      "Iteration 14494, loss = 1419.96213094\n",
      "Iteration 14495, loss = 1419.83957096\n",
      "Iteration 14496, loss = 1419.71704775\n",
      "Iteration 14497, loss = 1419.59456131\n",
      "Iteration 14498, loss = 1419.47211159\n",
      "Iteration 14499, loss = 1419.34969856\n",
      "Iteration 14500, loss = 1419.22732216\n",
      "Iteration 14501, loss = 1419.10498235\n",
      "Iteration 14502, loss = 1418.98267911\n",
      "Iteration 14503, loss = 1418.86041239\n",
      "Iteration 14504, loss = 1418.73818218\n",
      "Iteration 14505, loss = 1418.61598843\n",
      "Iteration 14506, loss = 1418.49383110\n",
      "Iteration 14507, loss = 1418.37171013\n",
      "Iteration 14508, loss = 1418.24962552\n",
      "Iteration 14509, loss = 1418.12757721\n",
      "Iteration 14510, loss = 1418.00556518\n",
      "Iteration 14511, loss = 1417.88358939\n",
      "Iteration 14512, loss = 1417.76164979\n",
      "Iteration 14513, loss = 1417.63974636\n",
      "Iteration 14514, loss = 1417.51787905\n",
      "Iteration 14515, loss = 1417.39604784\n",
      "Iteration 14516, loss = 1417.27425268\n",
      "Iteration 14517, loss = 1417.15249354\n",
      "Iteration 14518, loss = 1417.03077038\n",
      "Iteration 14519, loss = 1416.90908317\n",
      "Iteration 14520, loss = 1416.78743187\n",
      "Iteration 14521, loss = 1416.66581645\n",
      "Iteration 14522, loss = 1416.54423687\n",
      "Iteration 14523, loss = 1416.42269310\n",
      "Iteration 14524, loss = 1416.30118509\n",
      "Iteration 14525, loss = 1416.17971282\n",
      "Iteration 14526, loss = 1416.05827624\n",
      "Iteration 14527, loss = 1415.93687533\n",
      "Iteration 14528, loss = 1415.81551005\n",
      "Iteration 14529, loss = 1415.69418036\n",
      "Iteration 14530, loss = 1415.57288623\n",
      "Iteration 14531, loss = 1415.45162762\n",
      "Iteration 14532, loss = 1415.33040450\n",
      "Iteration 14533, loss = 1415.20921683\n",
      "Iteration 14534, loss = 1415.08806458\n",
      "Iteration 14535, loss = 1414.96694772\n",
      "Iteration 14536, loss = 1414.84586620\n",
      "Iteration 14537, loss = 1414.72482000\n",
      "Iteration 14538, loss = 1414.60380908\n",
      "Iteration 14539, loss = 1414.48283340\n",
      "Iteration 14540, loss = 1414.36189293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14541, loss = 1414.24098765\n",
      "Iteration 14542, loss = 1414.12011750\n",
      "Iteration 14543, loss = 1413.99928246\n",
      "Iteration 14544, loss = 1413.87848250\n",
      "Iteration 14545, loss = 1413.75771758\n",
      "Iteration 14546, loss = 1413.63698766\n",
      "Iteration 14547, loss = 1413.51629271\n",
      "Iteration 14548, loss = 1413.39563271\n",
      "Iteration 14549, loss = 1413.27500760\n",
      "Iteration 14550, loss = 1413.15441737\n",
      "Iteration 14551, loss = 1413.03386198\n",
      "Iteration 14552, loss = 1412.91334139\n",
      "Iteration 14553, loss = 1412.79285557\n",
      "Iteration 14554, loss = 1412.67240448\n",
      "Iteration 14555, loss = 1412.55198810\n",
      "Iteration 14556, loss = 1412.43160639\n",
      "Iteration 14557, loss = 1412.31125931\n",
      "Iteration 14558, loss = 1412.19094684\n",
      "Iteration 14559, loss = 1412.07066894\n",
      "Iteration 14560, loss = 1411.95042557\n",
      "Iteration 14561, loss = 1411.83021671\n",
      "Iteration 14562, loss = 1411.71004232\n",
      "Iteration 14563, loss = 1411.58990236\n",
      "Iteration 14564, loss = 1411.46979682\n",
      "Iteration 14565, loss = 1411.34972564\n",
      "Iteration 14566, loss = 1411.22968880\n",
      "Iteration 14567, loss = 1411.10968627\n",
      "Iteration 14568, loss = 1410.98971802\n",
      "Iteration 14569, loss = 1410.86978400\n",
      "Iteration 14570, loss = 1410.74988420\n",
      "Iteration 14571, loss = 1410.63001857\n",
      "Iteration 14572, loss = 1410.51018709\n",
      "Iteration 14573, loss = 1410.39038972\n",
      "Iteration 14574, loss = 1410.27062643\n",
      "Iteration 14575, loss = 1410.15089718\n",
      "Iteration 14576, loss = 1410.03120195\n",
      "Iteration 14577, loss = 1409.91154071\n",
      "Iteration 14578, loss = 1409.79191341\n",
      "Iteration 14579, loss = 1409.67232004\n",
      "Iteration 14580, loss = 1409.55276055\n",
      "Iteration 14581, loss = 1409.43323492\n",
      "Iteration 14582, loss = 1409.31374312\n",
      "Iteration 14583, loss = 1409.19428510\n",
      "Iteration 14584, loss = 1409.07486085\n",
      "Iteration 14585, loss = 1408.95547033\n",
      "Iteration 14586, loss = 1408.83611350\n",
      "Iteration 14587, loss = 1408.71679034\n",
      "Iteration 14588, loss = 1408.59750081\n",
      "Iteration 14589, loss = 1408.47824489\n",
      "Iteration 14590, loss = 1408.35902254\n",
      "Iteration 14591, loss = 1408.23983373\n",
      "Iteration 14592, loss = 1408.12067843\n",
      "Iteration 14593, loss = 1408.00155661\n",
      "Iteration 14594, loss = 1407.88246823\n",
      "Iteration 14595, loss = 1407.76341327\n",
      "Iteration 14596, loss = 1407.64439170\n",
      "Iteration 14597, loss = 1407.52540348\n",
      "Iteration 14598, loss = 1407.40644859\n",
      "Iteration 14599, loss = 1407.28752699\n",
      "Iteration 14600, loss = 1407.16863865\n",
      "Iteration 14601, loss = 1407.04978354\n",
      "Iteration 14602, loss = 1406.93096163\n",
      "Iteration 14603, loss = 1406.81217290\n",
      "Iteration 14604, loss = 1406.69341730\n",
      "Iteration 14605, loss = 1406.57469481\n",
      "Iteration 14606, loss = 1406.45600540\n",
      "Iteration 14607, loss = 1406.33734904\n",
      "Iteration 14608, loss = 1406.21872570\n",
      "Iteration 14609, loss = 1406.10013535\n",
      "Iteration 14610, loss = 1405.98157795\n",
      "Iteration 14611, loss = 1405.86305348\n",
      "Iteration 14612, loss = 1405.74456191\n",
      "Iteration 14613, loss = 1405.62610321\n",
      "Iteration 14614, loss = 1405.50767735\n",
      "Iteration 14615, loss = 1405.38928429\n",
      "Iteration 14616, loss = 1405.27092401\n",
      "Iteration 14617, loss = 1405.15259648\n",
      "Iteration 14618, loss = 1405.03430167\n",
      "Iteration 14619, loss = 1404.91603955\n",
      "Iteration 14620, loss = 1404.79781009\n",
      "Iteration 14621, loss = 1404.67961326\n",
      "Iteration 14622, loss = 1404.56144902\n",
      "Iteration 14623, loss = 1404.44331736\n",
      "Iteration 14624, loss = 1404.32521824\n",
      "Iteration 14625, loss = 1404.20715163\n",
      "Iteration 14626, loss = 1404.08911750\n",
      "Iteration 14627, loss = 1403.97111583\n",
      "Iteration 14628, loss = 1403.85314658\n",
      "Iteration 14629, loss = 1403.73520973\n",
      "Iteration 14630, loss = 1403.61730524\n",
      "Iteration 14631, loss = 1403.49943309\n",
      "Iteration 14632, loss = 1403.38159325\n",
      "Iteration 14633, loss = 1403.26378569\n",
      "Iteration 14634, loss = 1403.14601037\n",
      "Iteration 14635, loss = 1403.02826728\n",
      "Iteration 14636, loss = 1402.91055638\n",
      "Iteration 14637, loss = 1402.79287764\n",
      "Iteration 14638, loss = 1402.67523104\n",
      "Iteration 14639, loss = 1402.55761655\n",
      "Iteration 14640, loss = 1402.44003413\n",
      "Iteration 14641, loss = 1402.32248377\n",
      "Iteration 14642, loss = 1402.20496542\n",
      "Iteration 14643, loss = 1402.08747907\n",
      "Iteration 14644, loss = 1401.97002468\n",
      "Iteration 14645, loss = 1401.85260222\n",
      "Iteration 14646, loss = 1401.73521168\n",
      "Iteration 14647, loss = 1401.61785301\n",
      "Iteration 14648, loss = 1401.50052619\n",
      "Iteration 14649, loss = 1401.38323120\n",
      "Iteration 14650, loss = 1401.26596800\n",
      "Iteration 14651, loss = 1401.14873657\n",
      "Iteration 14652, loss = 1401.03153688\n",
      "Iteration 14653, loss = 1400.91436890\n",
      "Iteration 14654, loss = 1400.79723261\n",
      "Iteration 14655, loss = 1400.68012797\n",
      "Iteration 14656, loss = 1400.56305496\n",
      "Iteration 14657, loss = 1400.44601356\n",
      "Iteration 14658, loss = 1400.32900375\n",
      "Iteration 14659, loss = 1400.21202550\n",
      "Iteration 14660, loss = 1400.09507880\n",
      "Iteration 14661, loss = 1399.97816365\n",
      "Iteration 14662, loss = 1399.86128010\n",
      "Iteration 14663, loss = 1399.74442820\n",
      "Iteration 14664, loss = 1399.62760814\n",
      "Iteration 14665, loss = 1399.51082024\n",
      "Iteration 14666, loss = 1399.39406516\n",
      "Iteration 14667, loss = 1399.27734413\n",
      "Iteration 14668, loss = 1399.16065937\n",
      "Iteration 14669, loss = 1399.04401468\n",
      "Iteration 14670, loss = 1398.92741558\n",
      "Iteration 14671, loss = 1398.81086764\n",
      "Iteration 14672, loss = 1398.69436832\n",
      "Iteration 14673, loss = 1398.57789223\n",
      "Iteration 14674, loss = 1398.46138594\n",
      "Iteration 14675, loss = 1398.34481817\n",
      "Iteration 14676, loss = 1398.22824662\n",
      "Iteration 14677, loss = 1398.11177987\n",
      "Iteration 14678, loss = 1397.99544618\n",
      "Iteration 14679, loss = 1397.87916394\n",
      "Iteration 14680, loss = 1397.76283995\n",
      "Iteration 14681, loss = 1397.64647781\n",
      "Iteration 14682, loss = 1397.53016981\n",
      "Iteration 14683, loss = 1397.41396484\n",
      "Iteration 14684, loss = 1397.29781074\n",
      "Iteration 14685, loss = 1397.18163937\n",
      "Iteration 14686, loss = 1397.06545838\n",
      "Iteration 14687, loss = 1396.94933095\n",
      "Iteration 14688, loss = 1396.83327861\n",
      "Iteration 14689, loss = 1396.71725660\n",
      "Iteration 14690, loss = 1396.60122891\n",
      "Iteration 14691, loss = 1396.48521900\n",
      "Iteration 14692, loss = 1396.36926522\n",
      "Iteration 14693, loss = 1396.25336178\n",
      "Iteration 14694, loss = 1396.13747577\n",
      "Iteration 14695, loss = 1396.02159985\n",
      "Iteration 14696, loss = 1395.90575825\n",
      "Iteration 14697, loss = 1395.78996553\n",
      "Iteration 14698, loss = 1395.67420659\n",
      "Iteration 14699, loss = 1395.55846438\n",
      "Iteration 14700, loss = 1395.44274561\n",
      "Iteration 14701, loss = 1395.32706619\n",
      "Iteration 14702, loss = 1395.21142591\n",
      "Iteration 14703, loss = 1395.09581190\n",
      "Iteration 14704, loss = 1394.98021982\n",
      "Iteration 14705, loss = 1394.86465860\n",
      "Iteration 14706, loss = 1394.74913481\n",
      "Iteration 14707, loss = 1394.63364336\n",
      "Iteration 14708, loss = 1394.51817714\n",
      "Iteration 14709, loss = 1394.40273781\n",
      "Iteration 14710, loss = 1394.28733160\n",
      "Iteration 14711, loss = 1394.17195930\n",
      "Iteration 14712, loss = 1394.05661624\n",
      "Iteration 14713, loss = 1393.94129998\n",
      "Iteration 14714, loss = 1393.82601329\n",
      "Iteration 14715, loss = 1393.71075924\n",
      "Iteration 14716, loss = 1393.59553667\n",
      "Iteration 14717, loss = 1393.48034259\n",
      "Iteration 14718, loss = 1393.36517679\n",
      "Iteration 14719, loss = 1393.25004156\n",
      "Iteration 14720, loss = 1393.13493788\n",
      "Iteration 14721, loss = 1393.01986432\n",
      "Iteration 14722, loss = 1392.90481949\n",
      "Iteration 14723, loss = 1392.78980386\n",
      "Iteration 14724, loss = 1392.67481875\n",
      "Iteration 14725, loss = 1392.55986433\n",
      "Iteration 14726, loss = 1392.44493953\n",
      "Iteration 14727, loss = 1392.33004374\n",
      "Iteration 14728, loss = 1392.21517752\n",
      "Iteration 14729, loss = 1392.10034155\n",
      "Iteration 14730, loss = 1391.98553569\n",
      "Iteration 14731, loss = 1391.87075926\n",
      "Iteration 14732, loss = 1391.75601207\n",
      "Iteration 14733, loss = 1391.64129448\n",
      "Iteration 14734, loss = 1391.52660684\n",
      "Iteration 14735, loss = 1391.41194897\n",
      "Iteration 14736, loss = 1391.29732047\n",
      "Iteration 14737, loss = 1391.18272126\n",
      "Iteration 14738, loss = 1391.06815158\n",
      "Iteration 14739, loss = 1390.95361160\n",
      "Iteration 14740, loss = 1390.83910116\n",
      "Iteration 14741, loss = 1390.72462005\n",
      "Iteration 14742, loss = 1390.61016821\n",
      "Iteration 14743, loss = 1390.49574577\n",
      "Iteration 14744, loss = 1390.38135283\n",
      "Iteration 14745, loss = 1390.26698927\n",
      "Iteration 14746, loss = 1390.15265497\n",
      "Iteration 14747, loss = 1390.03834987\n",
      "Iteration 14748, loss = 1389.92407405\n",
      "Iteration 14749, loss = 1389.80982755\n",
      "Iteration 14750, loss = 1389.69561030\n",
      "Iteration 14751, loss = 1389.58142222\n",
      "Iteration 14752, loss = 1389.46726326\n",
      "Iteration 14753, loss = 1389.35313345\n",
      "Iteration 14754, loss = 1389.23903280\n",
      "Iteration 14755, loss = 1389.12496129\n",
      "Iteration 14756, loss = 1389.01091884\n",
      "Iteration 14757, loss = 1388.89690541\n",
      "Iteration 14758, loss = 1388.78292102\n",
      "Iteration 14759, loss = 1388.66896565\n",
      "Iteration 14760, loss = 1388.55503929\n",
      "Iteration 14761, loss = 1388.44114189\n",
      "Iteration 14762, loss = 1388.32727341\n",
      "Iteration 14763, loss = 1388.21343384\n",
      "Iteration 14764, loss = 1388.09962317\n",
      "Iteration 14765, loss = 1387.98584139\n",
      "Iteration 14766, loss = 1387.87208845\n",
      "Iteration 14767, loss = 1387.75836434\n",
      "Iteration 14768, loss = 1387.64466902\n",
      "Iteration 14769, loss = 1387.53100247\n",
      "Iteration 14770, loss = 1387.41736470\n",
      "Iteration 14771, loss = 1387.30375566\n",
      "Iteration 14772, loss = 1387.19017533\n",
      "Iteration 14773, loss = 1387.07662368\n",
      "Iteration 14774, loss = 1386.96310069\n",
      "Iteration 14775, loss = 1386.84960636\n",
      "Iteration 14776, loss = 1386.73614064\n",
      "Iteration 14777, loss = 1386.62270352\n",
      "Iteration 14778, loss = 1386.50929498\n",
      "Iteration 14779, loss = 1386.39591499\n",
      "Iteration 14780, loss = 1386.28256352\n",
      "Iteration 14781, loss = 1386.16924057\n",
      "Iteration 14782, loss = 1386.05594610\n",
      "Iteration 14783, loss = 1385.94268010\n",
      "Iteration 14784, loss = 1385.82944253\n",
      "Iteration 14785, loss = 1385.71623339\n",
      "Iteration 14786, loss = 1385.60305263\n",
      "Iteration 14787, loss = 1385.48990026\n",
      "Iteration 14788, loss = 1385.37677623\n",
      "Iteration 14789, loss = 1385.26368054\n",
      "Iteration 14790, loss = 1385.15061315\n",
      "Iteration 14791, loss = 1385.03757404\n",
      "Iteration 14792, loss = 1384.92456320\n",
      "Iteration 14793, loss = 1384.81158060\n",
      "Iteration 14794, loss = 1384.69862622\n",
      "Iteration 14795, loss = 1384.58570004\n",
      "Iteration 14796, loss = 1384.47280203\n",
      "Iteration 14797, loss = 1384.35993218\n",
      "Iteration 14798, loss = 1384.24709046\n",
      "Iteration 14799, loss = 1384.13427685\n",
      "Iteration 14800, loss = 1384.02149132\n",
      "Iteration 14801, loss = 1383.90873386\n",
      "Iteration 14802, loss = 1383.79600445\n",
      "Iteration 14803, loss = 1383.68330306\n",
      "Iteration 14804, loss = 1383.57062967\n",
      "Iteration 14805, loss = 1383.45798426\n",
      "Iteration 14806, loss = 1383.34536681\n",
      "Iteration 14807, loss = 1383.23277730\n",
      "Iteration 14808, loss = 1383.12021570\n",
      "Iteration 14809, loss = 1383.00768200\n",
      "Iteration 14810, loss = 1382.89517617\n",
      "Iteration 14811, loss = 1382.78269819\n",
      "Iteration 14812, loss = 1382.67024803\n",
      "Iteration 14813, loss = 1382.55782569\n",
      "Iteration 14814, loss = 1382.44543114\n",
      "Iteration 14815, loss = 1382.33306435\n",
      "Iteration 14816, loss = 1382.22072530\n",
      "Iteration 14817, loss = 1382.10841398\n",
      "Iteration 14818, loss = 1381.99613036\n",
      "Iteration 14819, loss = 1381.88387443\n",
      "Iteration 14820, loss = 1381.77164615\n",
      "Iteration 14821, loss = 1381.65944551\n",
      "Iteration 14822, loss = 1381.54727249\n",
      "Iteration 14823, loss = 1381.43512707\n",
      "Iteration 14824, loss = 1381.32300923\n",
      "Iteration 14825, loss = 1381.21091894\n",
      "Iteration 14826, loss = 1381.09885618\n",
      "Iteration 14827, loss = 1380.98682094\n",
      "Iteration 14828, loss = 1380.87481319\n",
      "Iteration 14829, loss = 1380.76283291\n",
      "Iteration 14830, loss = 1380.65088009\n",
      "Iteration 14831, loss = 1380.53895470\n",
      "Iteration 14832, loss = 1380.42705671\n",
      "Iteration 14833, loss = 1380.31518612\n",
      "Iteration 14834, loss = 1380.20334289\n",
      "Iteration 14835, loss = 1380.09152701\n",
      "Iteration 14836, loss = 1379.97973846\n",
      "Iteration 14837, loss = 1379.86797722\n",
      "Iteration 14838, loss = 1379.75624327\n",
      "Iteration 14839, loss = 1379.64453658\n",
      "Iteration 14840, loss = 1379.53285713\n",
      "Iteration 14841, loss = 1379.42120492\n",
      "Iteration 14842, loss = 1379.30957990\n",
      "Iteration 14843, loss = 1379.19798208\n",
      "Iteration 14844, loss = 1379.08641141\n",
      "Iteration 14845, loss = 1378.97486790\n",
      "Iteration 14846, loss = 1378.86335150\n",
      "Iteration 14847, loss = 1378.75186221\n",
      "Iteration 14848, loss = 1378.64040001\n",
      "Iteration 14849, loss = 1378.52896486\n",
      "Iteration 14850, loss = 1378.41755677\n",
      "Iteration 14851, loss = 1378.30617569\n",
      "Iteration 14852, loss = 1378.19482162\n",
      "Iteration 14853, loss = 1378.08349453\n",
      "Iteration 14854, loss = 1377.97219441\n",
      "Iteration 14855, loss = 1377.86092123\n",
      "Iteration 14856, loss = 1377.74967497\n",
      "Iteration 14857, loss = 1377.63845562\n",
      "Iteration 14858, loss = 1377.52726315\n",
      "Iteration 14859, loss = 1377.41609755\n",
      "Iteration 14860, loss = 1377.30495879\n",
      "Iteration 14861, loss = 1377.19384685\n",
      "Iteration 14862, loss = 1377.08276172\n",
      "Iteration 14863, loss = 1376.97170338\n",
      "Iteration 14864, loss = 1376.86067180\n",
      "Iteration 14865, loss = 1376.74966697\n",
      "Iteration 14866, loss = 1376.63868887\n",
      "Iteration 14867, loss = 1376.52773747\n",
      "Iteration 14868, loss = 1376.41681276\n",
      "Iteration 14869, loss = 1376.30591472\n",
      "Iteration 14870, loss = 1376.19504332\n",
      "Iteration 14871, loss = 1376.08419856\n",
      "Iteration 14872, loss = 1375.97338040\n",
      "Iteration 14873, loss = 1375.86258884\n",
      "Iteration 14874, loss = 1375.75182384\n",
      "Iteration 14875, loss = 1375.64108540\n",
      "Iteration 14876, loss = 1375.53037349\n",
      "Iteration 14877, loss = 1375.41968810\n",
      "Iteration 14878, loss = 1375.30902919\n",
      "Iteration 14879, loss = 1375.19839677\n",
      "Iteration 14880, loss = 1375.08779080\n",
      "Iteration 14881, loss = 1374.97721126\n",
      "Iteration 14882, loss = 1374.86665814\n",
      "Iteration 14883, loss = 1374.75613142\n",
      "Iteration 14884, loss = 1374.64563108\n",
      "Iteration 14885, loss = 1374.53515710\n",
      "Iteration 14886, loss = 1374.42470947\n",
      "Iteration 14887, loss = 1374.31428815\n",
      "Iteration 14888, loss = 1374.20389314\n",
      "Iteration 14889, loss = 1374.09352441\n",
      "Iteration 14890, loss = 1373.98318194\n",
      "Iteration 14891, loss = 1373.87286573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14892, loss = 1373.76257574\n",
      "Iteration 14893, loss = 1373.65231196\n",
      "Iteration 14894, loss = 1373.54207437\n",
      "Iteration 14895, loss = 1373.43186296\n",
      "Iteration 14896, loss = 1373.32167769\n",
      "Iteration 14897, loss = 1373.21151856\n",
      "Iteration 14898, loss = 1373.10138555\n",
      "Iteration 14899, loss = 1372.99127863\n",
      "Iteration 14900, loss = 1372.88119780\n",
      "Iteration 14901, loss = 1372.77114302\n",
      "Iteration 14902, loss = 1372.66111428\n",
      "Iteration 14903, loss = 1372.55111157\n",
      "Iteration 14904, loss = 1372.44113486\n",
      "Iteration 14905, loss = 1372.33118414\n",
      "Iteration 14906, loss = 1372.22125938\n",
      "Iteration 14907, loss = 1372.11136058\n",
      "Iteration 14908, loss = 1372.00148770\n",
      "Iteration 14909, loss = 1371.89164074\n",
      "Iteration 14910, loss = 1371.78181967\n",
      "Iteration 14911, loss = 1371.67202448\n",
      "Iteration 14912, loss = 1371.56225514\n",
      "Iteration 14913, loss = 1371.45251165\n",
      "Iteration 14914, loss = 1371.34279398\n",
      "Iteration 14915, loss = 1371.23310211\n",
      "Iteration 14916, loss = 1371.12343602\n",
      "Iteration 14917, loss = 1371.01379570\n",
      "Iteration 14918, loss = 1370.90418114\n",
      "Iteration 14919, loss = 1370.79459230\n",
      "Iteration 14920, loss = 1370.68502917\n",
      "Iteration 14921, loss = 1370.57549174\n",
      "Iteration 14922, loss = 1370.46597999\n",
      "Iteration 14923, loss = 1370.35649389\n",
      "Iteration 14924, loss = 1370.24703344\n",
      "Iteration 14925, loss = 1370.13759861\n",
      "Iteration 14926, loss = 1370.02818939\n",
      "Iteration 14927, loss = 1369.91880575\n",
      "Iteration 14928, loss = 1369.80944768\n",
      "Iteration 14929, loss = 1369.70011517\n",
      "Iteration 14930, loss = 1369.59080818\n",
      "Iteration 14931, loss = 1369.48152672\n",
      "Iteration 14932, loss = 1369.37227075\n",
      "Iteration 14933, loss = 1369.26304027\n",
      "Iteration 14934, loss = 1369.15383525\n",
      "Iteration 14935, loss = 1369.04465568\n",
      "Iteration 14936, loss = 1368.93550153\n",
      "Iteration 14937, loss = 1368.82637280\n",
      "Iteration 14938, loss = 1368.71726947\n",
      "Iteration 14939, loss = 1368.60819152\n",
      "Iteration 14940, loss = 1368.49913895\n",
      "Iteration 14941, loss = 1368.39011175\n",
      "Iteration 14942, loss = 1368.28110993\n",
      "Iteration 14943, loss = 1368.17213352\n",
      "Iteration 14944, loss = 1368.06318258\n",
      "Iteration 14945, loss = 1367.95425727\n",
      "Iteration 14946, loss = 1367.84535785\n",
      "Iteration 14947, loss = 1367.73648486\n",
      "Iteration 14948, loss = 1367.62763933\n",
      "Iteration 14949, loss = 1367.51882309\n",
      "Iteration 14950, loss = 1367.41003939\n",
      "Iteration 14951, loss = 1367.30129332\n",
      "Iteration 14952, loss = 1367.19259127\n",
      "Iteration 14953, loss = 1367.08393580\n",
      "Iteration 14954, loss = 1366.97531286\n",
      "Iteration 14955, loss = 1366.86667677\n",
      "Iteration 14956, loss = 1366.75797457\n",
      "Iteration 14957, loss = 1366.64922001\n",
      "Iteration 14958, loss = 1366.54051935\n",
      "Iteration 14959, loss = 1366.43195422\n",
      "Iteration 14960, loss = 1366.32348484\n",
      "Iteration 14961, loss = 1366.21500237\n",
      "Iteration 14962, loss = 1366.10645400\n",
      "Iteration 14963, loss = 1365.99790527\n",
      "Iteration 14964, loss = 1365.88944573\n",
      "Iteration 14965, loss = 1365.78106887\n",
      "Iteration 14966, loss = 1365.67269627\n",
      "Iteration 14967, loss = 1365.56428968\n",
      "Iteration 14968, loss = 1365.45589745\n",
      "Iteration 14969, loss = 1365.34757583\n",
      "Iteration 14970, loss = 1365.23930751\n",
      "Iteration 14971, loss = 1365.13103865\n",
      "Iteration 14972, loss = 1365.02276160\n",
      "Iteration 14973, loss = 1364.91451773\n",
      "Iteration 14974, loss = 1364.80632895\n",
      "Iteration 14975, loss = 1364.69816990\n",
      "Iteration 14976, loss = 1364.59001296\n",
      "Iteration 14977, loss = 1364.48186854\n",
      "Iteration 14978, loss = 1364.37376346\n",
      "Iteration 14979, loss = 1364.26569821\n",
      "Iteration 14980, loss = 1364.15765122\n",
      "Iteration 14981, loss = 1364.04961463\n",
      "Iteration 14982, loss = 1363.94160297\n",
      "Iteration 14983, loss = 1363.83362775\n",
      "Iteration 14984, loss = 1363.72568125\n",
      "Iteration 14985, loss = 1363.61775123\n",
      "Iteration 14986, loss = 1363.50983971\n",
      "Iteration 14987, loss = 1363.40195732\n",
      "Iteration 14988, loss = 1363.29410603\n",
      "Iteration 14989, loss = 1363.18627804\n",
      "Iteration 14990, loss = 1363.07846891\n",
      "Iteration 14991, loss = 1362.97068321\n",
      "Iteration 14992, loss = 1362.86292621\n",
      "Iteration 14993, loss = 1362.75519624\n",
      "Iteration 14994, loss = 1362.64748826\n",
      "Iteration 14995, loss = 1362.53980174\n",
      "Iteration 14996, loss = 1362.43214055\n",
      "Iteration 14997, loss = 1362.32450652\n",
      "Iteration 14998, loss = 1362.21689725\n",
      "Iteration 14999, loss = 1362.10931035\n",
      "Iteration 15000, loss = 1362.00174667\n",
      "Iteration 15001, loss = 1361.89420849\n",
      "Iteration 15002, loss = 1361.78669607\n",
      "Iteration 15003, loss = 1361.67920765\n",
      "Iteration 15004, loss = 1361.57174222\n",
      "Iteration 15005, loss = 1361.46430078\n",
      "Iteration 15006, loss = 1361.35688453\n",
      "Iteration 15007, loss = 1361.24949317\n",
      "Iteration 15008, loss = 1361.14212560\n",
      "Iteration 15009, loss = 1361.03478153\n",
      "Iteration 15010, loss = 1360.92746167\n",
      "Iteration 15011, loss = 1360.82016659\n",
      "Iteration 15012, loss = 1360.71289596\n",
      "Iteration 15013, loss = 1360.60564913\n",
      "Iteration 15014, loss = 1360.49842604\n",
      "Iteration 15015, loss = 1360.39122717\n",
      "Iteration 15016, loss = 1360.28405275\n",
      "Iteration 15017, loss = 1360.17690254\n",
      "Iteration 15018, loss = 1360.06977617\n",
      "Iteration 15019, loss = 1359.96267365\n",
      "Iteration 15020, loss = 1359.85559524\n",
      "Iteration 15021, loss = 1359.74854107\n",
      "Iteration 15022, loss = 1359.64151096\n",
      "Iteration 15023, loss = 1359.53450471\n",
      "Iteration 15024, loss = 1359.42752232\n",
      "Iteration 15025, loss = 1359.32056393\n",
      "Iteration 15026, loss = 1359.21362962\n",
      "Iteration 15027, loss = 1359.10671927\n",
      "Iteration 15028, loss = 1358.99983277\n",
      "Iteration 15029, loss = 1358.89297009\n",
      "Iteration 15030, loss = 1358.78613131\n",
      "Iteration 15031, loss = 1358.67931648\n",
      "Iteration 15032, loss = 1358.57252553\n",
      "Iteration 15033, loss = 1358.46575838\n",
      "Iteration 15034, loss = 1358.35901502\n",
      "Iteration 15035, loss = 1358.25229546\n",
      "Iteration 15036, loss = 1358.14559973\n",
      "Iteration 15037, loss = 1358.03892781\n",
      "Iteration 15038, loss = 1357.93227964\n",
      "Iteration 15039, loss = 1357.82565519\n",
      "Iteration 15040, loss = 1357.71905447\n",
      "Iteration 15041, loss = 1357.61247748\n",
      "Iteration 15042, loss = 1357.50592421\n",
      "Iteration 15043, loss = 1357.39939464\n",
      "Iteration 15044, loss = 1357.29288872\n",
      "Iteration 15045, loss = 1357.18640644\n",
      "Iteration 15046, loss = 1357.07994782\n",
      "Iteration 15047, loss = 1356.97351284\n",
      "Iteration 15048, loss = 1356.86710148\n",
      "Iteration 15049, loss = 1356.76071371\n",
      "Iteration 15050, loss = 1356.65434952\n",
      "Iteration 15051, loss = 1356.54800889\n",
      "Iteration 15052, loss = 1356.44169183\n",
      "Iteration 15053, loss = 1356.33539831\n",
      "Iteration 15054, loss = 1356.22912831\n",
      "Iteration 15055, loss = 1356.12288182\n",
      "Iteration 15056, loss = 1356.01665882\n",
      "Iteration 15057, loss = 1355.91045931\n",
      "Iteration 15058, loss = 1355.80428326\n",
      "Iteration 15059, loss = 1355.69813066\n",
      "Iteration 15060, loss = 1355.59200150\n",
      "Iteration 15061, loss = 1355.48589576\n",
      "Iteration 15062, loss = 1355.37981343\n",
      "Iteration 15063, loss = 1355.27375449\n",
      "Iteration 15064, loss = 1355.16771893\n",
      "Iteration 15065, loss = 1355.06170673\n",
      "Iteration 15066, loss = 1354.95571788\n",
      "Iteration 15067, loss = 1354.84975237\n",
      "Iteration 15068, loss = 1354.74381017\n",
      "Iteration 15069, loss = 1354.63789128\n",
      "Iteration 15070, loss = 1354.53199568\n",
      "Iteration 15071, loss = 1354.42612336\n",
      "Iteration 15072, loss = 1354.32027430\n",
      "Iteration 15073, loss = 1354.21444848\n",
      "Iteration 15074, loss = 1354.10864590\n",
      "Iteration 15075, loss = 1354.00286654\n",
      "Iteration 15076, loss = 1353.89711038\n",
      "Iteration 15077, loss = 1353.79137741\n",
      "Iteration 15078, loss = 1353.68566762\n",
      "Iteration 15079, loss = 1353.57998099\n",
      "Iteration 15080, loss = 1353.47431751\n",
      "Iteration 15081, loss = 1353.36867715\n",
      "Iteration 15082, loss = 1353.26305992\n",
      "Iteration 15083, loss = 1353.15746579\n",
      "Iteration 15084, loss = 1353.05189476\n",
      "Iteration 15085, loss = 1352.94634680\n",
      "Iteration 15086, loss = 1352.84082190\n",
      "Iteration 15087, loss = 1352.73532005\n",
      "Iteration 15088, loss = 1352.62984123\n",
      "Iteration 15089, loss = 1352.52438543\n",
      "Iteration 15090, loss = 1352.41895264\n",
      "Iteration 15091, loss = 1352.31354284\n",
      "Iteration 15092, loss = 1352.20815601\n",
      "Iteration 15093, loss = 1352.10279215\n",
      "Iteration 15094, loss = 1351.99745124\n",
      "Iteration 15095, loss = 1351.89213326\n",
      "Iteration 15096, loss = 1351.78683821\n",
      "Iteration 15097, loss = 1351.68156606\n",
      "Iteration 15098, loss = 1351.57631681\n",
      "Iteration 15099, loss = 1351.47109044\n",
      "Iteration 15100, loss = 1351.36588693\n",
      "Iteration 15101, loss = 1351.26070628\n",
      "Iteration 15102, loss = 1351.15554846\n",
      "Iteration 15103, loss = 1351.05041347\n",
      "Iteration 15104, loss = 1350.94530129\n",
      "Iteration 15105, loss = 1350.84021190\n",
      "Iteration 15106, loss = 1350.73514530\n",
      "Iteration 15107, loss = 1350.63010147\n",
      "Iteration 15108, loss = 1350.52508039\n",
      "Iteration 15109, loss = 1350.42008205\n",
      "Iteration 15110, loss = 1350.31510645\n",
      "Iteration 15111, loss = 1350.21015355\n",
      "Iteration 15112, loss = 1350.10522336\n",
      "Iteration 15113, loss = 1350.00031586\n",
      "Iteration 15114, loss = 1349.89543103\n",
      "Iteration 15115, loss = 1349.79056885\n",
      "Iteration 15116, loss = 1349.68572933\n",
      "Iteration 15117, loss = 1349.58091244\n",
      "Iteration 15118, loss = 1349.47611817\n",
      "Iteration 15119, loss = 1349.37134650\n",
      "Iteration 15120, loss = 1349.26659742\n",
      "Iteration 15121, loss = 1349.16187093\n",
      "Iteration 15122, loss = 1349.05716700\n",
      "Iteration 15123, loss = 1348.95248562\n",
      "Iteration 15124, loss = 1348.84782678\n",
      "Iteration 15125, loss = 1348.74319047\n",
      "Iteration 15126, loss = 1348.63857666\n",
      "Iteration 15127, loss = 1348.53398536\n",
      "Iteration 15128, loss = 1348.42941654\n",
      "Iteration 15129, loss = 1348.32487019\n",
      "Iteration 15130, loss = 1348.22034630\n",
      "Iteration 15131, loss = 1348.11584486\n",
      "Iteration 15132, loss = 1348.01136584\n",
      "Iteration 15133, loss = 1347.90690925\n",
      "Iteration 15134, loss = 1347.80247506\n",
      "Iteration 15135, loss = 1347.69806326\n",
      "Iteration 15136, loss = 1347.59367384\n",
      "Iteration 15137, loss = 1347.48930679\n",
      "Iteration 15138, loss = 1347.38496209\n",
      "Iteration 15139, loss = 1347.28063973\n",
      "Iteration 15140, loss = 1347.17633969\n",
      "Iteration 15141, loss = 1347.07206197\n",
      "Iteration 15142, loss = 1346.96780655\n",
      "Iteration 15143, loss = 1346.86357341\n",
      "Iteration 15144, loss = 1346.75936255\n",
      "Iteration 15145, loss = 1346.65517395\n",
      "Iteration 15146, loss = 1346.55100760\n",
      "Iteration 15147, loss = 1346.44686348\n",
      "Iteration 15148, loss = 1346.34274158\n",
      "Iteration 15149, loss = 1346.23864190\n",
      "Iteration 15150, loss = 1346.13456440\n",
      "Iteration 15151, loss = 1346.03050910\n",
      "Iteration 15152, loss = 1345.92647596\n",
      "Iteration 15153, loss = 1345.82246497\n",
      "Iteration 15154, loss = 1345.71847614\n",
      "Iteration 15155, loss = 1345.61450943\n",
      "Iteration 15156, loss = 1345.51056484\n",
      "Iteration 15157, loss = 1345.40664236\n",
      "Iteration 15158, loss = 1345.30274197\n",
      "Iteration 15159, loss = 1345.19886365\n",
      "Iteration 15160, loss = 1345.09500741\n",
      "Iteration 15161, loss = 1344.99117322\n",
      "Iteration 15162, loss = 1344.88736107\n",
      "Iteration 15163, loss = 1344.78357096\n",
      "Iteration 15164, loss = 1344.67980285\n",
      "Iteration 15165, loss = 1344.57605675\n",
      "Iteration 15166, loss = 1344.47233265\n",
      "Iteration 15167, loss = 1344.36863052\n",
      "Iteration 15168, loss = 1344.26495035\n",
      "Iteration 15169, loss = 1344.16129214\n",
      "Iteration 15170, loss = 1344.05765587\n",
      "Iteration 15171, loss = 1343.95404152\n",
      "Iteration 15172, loss = 1343.85044909\n",
      "Iteration 15173, loss = 1343.74687857\n",
      "Iteration 15174, loss = 1343.64332993\n",
      "Iteration 15175, loss = 1343.53980317\n",
      "Iteration 15176, loss = 1343.43629827\n",
      "Iteration 15177, loss = 1343.33281523\n",
      "Iteration 15178, loss = 1343.22935403\n",
      "Iteration 15179, loss = 1343.12591465\n",
      "Iteration 15180, loss = 1343.02249709\n",
      "Iteration 15181, loss = 1342.91910134\n",
      "Iteration 15182, loss = 1342.81572737\n",
      "Iteration 15183, loss = 1342.71237518\n",
      "Iteration 15184, loss = 1342.60904476\n",
      "Iteration 15185, loss = 1342.50573608\n",
      "Iteration 15186, loss = 1342.40244915\n",
      "Iteration 15187, loss = 1342.29918395\n",
      "Iteration 15188, loss = 1342.19594046\n",
      "Iteration 15189, loss = 1342.09271868\n",
      "Iteration 15190, loss = 1341.98951859\n",
      "Iteration 15191, loss = 1341.88634018\n",
      "Iteration 15192, loss = 1341.78318343\n",
      "Iteration 15193, loss = 1341.68004834\n",
      "Iteration 15194, loss = 1341.57693489\n",
      "Iteration 15195, loss = 1341.47384307\n",
      "Iteration 15196, loss = 1341.37077287\n",
      "Iteration 15197, loss = 1341.26772428\n",
      "Iteration 15198, loss = 1341.16469728\n",
      "Iteration 15199, loss = 1341.06169186\n",
      "Iteration 15200, loss = 1340.95870801\n",
      "Iteration 15201, loss = 1340.85574572\n",
      "Iteration 15202, loss = 1340.75280497\n",
      "Iteration 15203, loss = 1340.64988575\n",
      "Iteration 15204, loss = 1340.54698806\n",
      "Iteration 15205, loss = 1340.44411188\n",
      "Iteration 15206, loss = 1340.34125719\n",
      "Iteration 15207, loss = 1340.23842399\n",
      "Iteration 15208, loss = 1340.13561226\n",
      "Iteration 15209, loss = 1340.03282199\n",
      "Iteration 15210, loss = 1339.93005317\n",
      "Iteration 15211, loss = 1339.82730579\n",
      "Iteration 15212, loss = 1339.72457984\n",
      "Iteration 15213, loss = 1339.62187529\n",
      "Iteration 15214, loss = 1339.51919215\n",
      "Iteration 15215, loss = 1339.41653040\n",
      "Iteration 15216, loss = 1339.31389003\n",
      "Iteration 15217, loss = 1339.21127102\n",
      "Iteration 15218, loss = 1339.10867337\n",
      "Iteration 15219, loss = 1339.00609707\n",
      "Iteration 15220, loss = 1338.90354210\n",
      "Iteration 15221, loss = 1338.80100846\n",
      "Iteration 15222, loss = 1338.69849615\n",
      "Iteration 15223, loss = 1338.59600517\n",
      "Iteration 15224, loss = 1338.49353554\n",
      "Iteration 15225, loss = 1338.39108729\n",
      "Iteration 15226, loss = 1338.28866052\n",
      "Iteration 15227, loss = 1338.18625538\n",
      "Iteration 15228, loss = 1338.08387219\n",
      "Iteration 15229, loss = 1337.98151154\n",
      "Iteration 15230, loss = 1337.87917452\n",
      "Iteration 15231, loss = 1337.77686309\n",
      "Iteration 15232, loss = 1337.67458063\n",
      "Iteration 15233, loss = 1337.57233239\n",
      "Iteration 15234, loss = 1337.47012462\n",
      "Iteration 15235, loss = 1337.36795966\n",
      "Iteration 15236, loss = 1337.26582195\n",
      "Iteration 15237, loss = 1337.16366569\n",
      "Iteration 15238, loss = 1337.06143613\n",
      "Iteration 15239, loss = 1336.95915012\n",
      "Iteration 15240, loss = 1336.85691497\n",
      "Iteration 15241, loss = 1336.75481383\n",
      "Iteration 15242, loss = 1336.65280648\n",
      "Iteration 15243, loss = 1336.55078278\n",
      "Iteration 15244, loss = 1336.44868849\n",
      "Iteration 15245, loss = 1336.34658573\n",
      "Iteration 15246, loss = 1336.24456683\n",
      "Iteration 15247, loss = 1336.14263073\n",
      "Iteration 15248, loss = 1336.04069871\n",
      "Iteration 15249, loss = 1335.93872733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15250, loss = 1335.83676170\n",
      "Iteration 15251, loss = 1335.73486148\n",
      "Iteration 15252, loss = 1335.63301468\n",
      "Iteration 15253, loss = 1335.53116708\n",
      "Iteration 15254, loss = 1335.42930505\n",
      "Iteration 15255, loss = 1335.32746761\n",
      "Iteration 15256, loss = 1335.22568201\n",
      "Iteration 15257, loss = 1335.12392670\n",
      "Iteration 15258, loss = 1335.02217082\n",
      "Iteration 15259, loss = 1334.92042036\n",
      "Iteration 15260, loss = 1334.81870275\n",
      "Iteration 15261, loss = 1334.71702313\n",
      "Iteration 15262, loss = 1334.61536122\n",
      "Iteration 15263, loss = 1334.51370519\n",
      "Iteration 15264, loss = 1334.41206716\n",
      "Iteration 15265, loss = 1334.31046127\n",
      "Iteration 15266, loss = 1334.20888270\n",
      "Iteration 15267, loss = 1334.10731823\n",
      "Iteration 15268, loss = 1334.00576694\n",
      "Iteration 15269, loss = 1333.90423906\n",
      "Iteration 15270, loss = 1333.80273914\n",
      "Iteration 15271, loss = 1333.70126067\n",
      "Iteration 15272, loss = 1333.59979742\n",
      "Iteration 15273, loss = 1333.49835222\n",
      "Iteration 15274, loss = 1333.39693129\n",
      "Iteration 15275, loss = 1333.29553461\n",
      "Iteration 15276, loss = 1333.19415719\n",
      "Iteration 15277, loss = 1333.09279709\n",
      "Iteration 15278, loss = 1332.99145746\n",
      "Iteration 15279, loss = 1332.89014115\n",
      "Iteration 15280, loss = 1332.78884680\n",
      "Iteration 15281, loss = 1332.68757151\n",
      "Iteration 15282, loss = 1332.58631512\n",
      "Iteration 15283, loss = 1332.48507992\n",
      "Iteration 15284, loss = 1332.38386697\n",
      "Iteration 15285, loss = 1332.28267490\n",
      "Iteration 15286, loss = 1332.18150222\n",
      "Iteration 15287, loss = 1332.08034937\n",
      "Iteration 15288, loss = 1331.97921770\n",
      "Iteration 15289, loss = 1331.87810749\n",
      "Iteration 15290, loss = 1331.77701775\n",
      "Iteration 15291, loss = 1331.67594778\n",
      "Iteration 15292, loss = 1331.57489803\n",
      "Iteration 15293, loss = 1331.47386926\n",
      "Iteration 15294, loss = 1331.37286147\n",
      "Iteration 15295, loss = 1331.27187403\n",
      "Iteration 15296, loss = 1331.17090662\n",
      "Iteration 15297, loss = 1331.06995955\n",
      "Iteration 15298, loss = 1330.96903324\n",
      "Iteration 15299, loss = 1330.86812764\n",
      "Iteration 15300, loss = 1330.76724236\n",
      "Iteration 15301, loss = 1330.66637724\n",
      "Iteration 15302, loss = 1330.56553248\n",
      "Iteration 15303, loss = 1330.46470831\n",
      "Iteration 15304, loss = 1330.36390467\n",
      "Iteration 15305, loss = 1330.26312135\n",
      "Iteration 15306, loss = 1330.16235825\n",
      "Iteration 15307, loss = 1330.06161547\n",
      "Iteration 15308, loss = 1329.96089314\n",
      "Iteration 15309, loss = 1329.86019124\n",
      "Iteration 15310, loss = 1329.75950964\n",
      "Iteration 15311, loss = 1329.65884827\n",
      "Iteration 15312, loss = 1329.55820717\n",
      "Iteration 15313, loss = 1329.45758642\n",
      "Iteration 15314, loss = 1329.35698602\n",
      "Iteration 15315, loss = 1329.25640588\n",
      "Iteration 15316, loss = 1329.15584596\n",
      "Iteration 15317, loss = 1329.05530627\n",
      "Iteration 15318, loss = 1328.95478684\n",
      "Iteration 15319, loss = 1328.85428769\n",
      "Iteration 15320, loss = 1328.75380876\n",
      "Iteration 15321, loss = 1328.65335002\n",
      "Iteration 15322, loss = 1328.55291146\n",
      "Iteration 15323, loss = 1328.45249310\n",
      "Iteration 15324, loss = 1328.35209494\n",
      "Iteration 15325, loss = 1328.25171697\n",
      "Iteration 15326, loss = 1328.15135914\n",
      "Iteration 15327, loss = 1328.05102145\n",
      "Iteration 15328, loss = 1327.95070389\n",
      "Iteration 15329, loss = 1327.85040648\n",
      "Iteration 15330, loss = 1327.75012920\n",
      "Iteration 15331, loss = 1327.64987202\n",
      "Iteration 15332, loss = 1327.54963494\n",
      "Iteration 15333, loss = 1327.44941793\n",
      "Iteration 15334, loss = 1327.34922101\n",
      "Iteration 15335, loss = 1327.24904417\n",
      "Iteration 15336, loss = 1327.14888738\n",
      "Iteration 15337, loss = 1327.04875064\n",
      "Iteration 15338, loss = 1326.94863394\n",
      "Iteration 15339, loss = 1326.84853726\n",
      "Iteration 15340, loss = 1326.74846060\n",
      "Iteration 15341, loss = 1326.64840395\n",
      "Iteration 15342, loss = 1326.54836730\n",
      "Iteration 15343, loss = 1326.44835064\n",
      "Iteration 15344, loss = 1326.34835395\n",
      "Iteration 15345, loss = 1326.24837722\n",
      "Iteration 15346, loss = 1326.14842046\n",
      "Iteration 15347, loss = 1326.04848364\n",
      "Iteration 15348, loss = 1325.94856676\n",
      "Iteration 15349, loss = 1325.84866981\n",
      "Iteration 15350, loss = 1325.74879277\n",
      "Iteration 15351, loss = 1325.64893564\n",
      "Iteration 15352, loss = 1325.54909841\n",
      "Iteration 15353, loss = 1325.44928106\n",
      "Iteration 15354, loss = 1325.34948360\n",
      "Iteration 15355, loss = 1325.24970600\n",
      "Iteration 15356, loss = 1325.14994825\n",
      "Iteration 15357, loss = 1325.05021035\n",
      "Iteration 15358, loss = 1324.95049229\n",
      "Iteration 15359, loss = 1324.85079406\n",
      "Iteration 15360, loss = 1324.75111565\n",
      "Iteration 15361, loss = 1324.65145704\n",
      "Iteration 15362, loss = 1324.55181823\n",
      "Iteration 15363, loss = 1324.45219921\n",
      "Iteration 15364, loss = 1324.35259996\n",
      "Iteration 15365, loss = 1324.25302049\n",
      "Iteration 15366, loss = 1324.15346077\n",
      "Iteration 15367, loss = 1324.05392080\n",
      "Iteration 15368, loss = 1323.95440057\n",
      "Iteration 15369, loss = 1323.85490007\n",
      "Iteration 15370, loss = 1323.75541928\n",
      "Iteration 15371, loss = 1323.65595821\n",
      "Iteration 15372, loss = 1323.55651684\n",
      "Iteration 15373, loss = 1323.45709516\n",
      "Iteration 15374, loss = 1323.35769315\n",
      "Iteration 15375, loss = 1323.25831082\n",
      "Iteration 15376, loss = 1323.15894815\n",
      "Iteration 15377, loss = 1323.05960513\n",
      "Iteration 15378, loss = 1322.96028175\n",
      "Iteration 15379, loss = 1322.86097800\n",
      "Iteration 15380, loss = 1322.76169388\n",
      "Iteration 15381, loss = 1322.66242936\n",
      "Iteration 15382, loss = 1322.56318445\n",
      "Iteration 15383, loss = 1322.46395914\n",
      "Iteration 15384, loss = 1322.36475340\n",
      "Iteration 15385, loss = 1322.26556724\n",
      "Iteration 15386, loss = 1322.16640065\n",
      "Iteration 15387, loss = 1322.06725361\n",
      "Iteration 15388, loss = 1321.96812611\n",
      "Iteration 15389, loss = 1321.86901815\n",
      "Iteration 15390, loss = 1321.76992972\n",
      "Iteration 15391, loss = 1321.67086081\n",
      "Iteration 15392, loss = 1321.57181140\n",
      "Iteration 15393, loss = 1321.47278148\n",
      "Iteration 15394, loss = 1321.37377106\n",
      "Iteration 15395, loss = 1321.27478012\n",
      "Iteration 15396, loss = 1321.17580864\n",
      "Iteration 15397, loss = 1321.07685663\n",
      "Iteration 15398, loss = 1320.97792406\n",
      "Iteration 15399, loss = 1320.87901094\n",
      "Iteration 15400, loss = 1320.78011724\n",
      "Iteration 15401, loss = 1320.68124297\n",
      "Iteration 15402, loss = 1320.58238811\n",
      "Iteration 15403, loss = 1320.48355266\n",
      "Iteration 15404, loss = 1320.38473660\n",
      "Iteration 15405, loss = 1320.28593992\n",
      "Iteration 15406, loss = 1320.18716262\n",
      "Iteration 15407, loss = 1320.08840468\n",
      "Iteration 15408, loss = 1319.98966610\n",
      "Iteration 15409, loss = 1319.89094687\n",
      "Iteration 15410, loss = 1319.79224697\n",
      "Iteration 15411, loss = 1319.69356641\n",
      "Iteration 15412, loss = 1319.59490516\n",
      "Iteration 15413, loss = 1319.49626322\n",
      "Iteration 15414, loss = 1319.39764058\n",
      "Iteration 15415, loss = 1319.29903724\n",
      "Iteration 15416, loss = 1319.20045318\n",
      "Iteration 15417, loss = 1319.10188839\n",
      "Iteration 15418, loss = 1319.00334286\n",
      "Iteration 15419, loss = 1318.90481659\n",
      "Iteration 15420, loss = 1318.80630956\n",
      "Iteration 15421, loss = 1318.70782177\n",
      "Iteration 15422, loss = 1318.60935320\n",
      "Iteration 15423, loss = 1318.51090386\n",
      "Iteration 15424, loss = 1318.41247372\n",
      "Iteration 15425, loss = 1318.31406278\n",
      "Iteration 15426, loss = 1318.21567103\n",
      "Iteration 15427, loss = 1318.11729847\n",
      "Iteration 15428, loss = 1318.01894507\n",
      "Iteration 15429, loss = 1317.92061084\n",
      "Iteration 15430, loss = 1317.82229576\n",
      "Iteration 15431, loss = 1317.72399983\n",
      "Iteration 15432, loss = 1317.62572303\n",
      "Iteration 15433, loss = 1317.52746536\n",
      "Iteration 15434, loss = 1317.42922681\n",
      "Iteration 15435, loss = 1317.33100736\n",
      "Iteration 15436, loss = 1317.23280701\n",
      "Iteration 15437, loss = 1317.13462576\n",
      "Iteration 15438, loss = 1317.03646359\n",
      "Iteration 15439, loss = 1316.93832048\n",
      "Iteration 15440, loss = 1316.84019645\n",
      "Iteration 15441, loss = 1316.74209146\n",
      "Iteration 15442, loss = 1316.64400553\n",
      "Iteration 15443, loss = 1316.54593862\n",
      "Iteration 15444, loss = 1316.44789075\n",
      "Iteration 15445, loss = 1316.34986190\n",
      "Iteration 15446, loss = 1316.25185205\n",
      "Iteration 15447, loss = 1316.15386121\n",
      "Iteration 15448, loss = 1316.05588935\n",
      "Iteration 15449, loss = 1315.95793648\n",
      "Iteration 15450, loss = 1315.86000259\n",
      "Iteration 15451, loss = 1315.76208766\n",
      "Iteration 15452, loss = 1315.66419169\n",
      "Iteration 15453, loss = 1315.56631466\n",
      "Iteration 15454, loss = 1315.46845657\n",
      "Iteration 15455, loss = 1315.37061742\n",
      "Iteration 15456, loss = 1315.27279718\n",
      "Iteration 15457, loss = 1315.17499586\n",
      "Iteration 15458, loss = 1315.07721343\n",
      "Iteration 15459, loss = 1314.97944991\n",
      "Iteration 15460, loss = 1314.88170527\n",
      "Iteration 15461, loss = 1314.78397951\n",
      "Iteration 15462, loss = 1314.68627261\n",
      "Iteration 15463, loss = 1314.58858458\n",
      "Iteration 15464, loss = 1314.49091539\n",
      "Iteration 15465, loss = 1314.39326505\n",
      "Iteration 15466, loss = 1314.29563354\n",
      "Iteration 15467, loss = 1314.19802086\n",
      "Iteration 15468, loss = 1314.10042699\n",
      "Iteration 15469, loss = 1314.00285193\n",
      "Iteration 15470, loss = 1313.90529567\n",
      "Iteration 15471, loss = 1313.80775820\n",
      "Iteration 15472, loss = 1313.71023951\n",
      "Iteration 15473, loss = 1313.61273959\n",
      "Iteration 15474, loss = 1313.51525844\n",
      "Iteration 15475, loss = 1313.41779604\n",
      "Iteration 15476, loss = 1313.32035239\n",
      "Iteration 15477, loss = 1313.22292747\n",
      "Iteration 15478, loss = 1313.12552129\n",
      "Iteration 15479, loss = 1313.02813383\n",
      "Iteration 15480, loss = 1312.93076508\n",
      "Iteration 15481, loss = 1312.83341503\n",
      "Iteration 15482, loss = 1312.73608368\n",
      "Iteration 15483, loss = 1312.63877102\n",
      "Iteration 15484, loss = 1312.54147703\n",
      "Iteration 15485, loss = 1312.44420172\n",
      "Iteration 15486, loss = 1312.34694506\n",
      "Iteration 15487, loss = 1312.24970706\n",
      "Iteration 15488, loss = 1312.15248770\n",
      "Iteration 15489, loss = 1312.05528698\n",
      "Iteration 15490, loss = 1311.95810488\n",
      "Iteration 15491, loss = 1311.86094140\n",
      "Iteration 15492, loss = 1311.76379654\n",
      "Iteration 15493, loss = 1311.66667027\n",
      "Iteration 15494, loss = 1311.56956260\n",
      "Iteration 15495, loss = 1311.47247351\n",
      "Iteration 15496, loss = 1311.37540300\n",
      "Iteration 15497, loss = 1311.27835106\n",
      "Iteration 15498, loss = 1311.18131768\n",
      "Iteration 15499, loss = 1311.08430285\n",
      "Iteration 15500, loss = 1310.98730656\n",
      "Iteration 15501, loss = 1310.89032881\n",
      "Iteration 15502, loss = 1310.79336958\n",
      "Iteration 15503, loss = 1310.69642887\n",
      "Iteration 15504, loss = 1310.59950667\n",
      "Iteration 15505, loss = 1310.50260298\n",
      "Iteration 15506, loss = 1310.40571777\n",
      "Iteration 15507, loss = 1310.30885106\n",
      "Iteration 15508, loss = 1310.21200282\n",
      "Iteration 15509, loss = 1310.11517307\n",
      "Iteration 15510, loss = 1310.01836178\n",
      "Iteration 15511, loss = 1309.92156897\n",
      "Iteration 15512, loss = 1309.82479466\n",
      "Iteration 15513, loss = 1309.72803886\n",
      "Iteration 15514, loss = 1309.63130164\n",
      "Iteration 15515, loss = 1309.53458312\n",
      "Iteration 15516, loss = 1309.43788355\n",
      "Iteration 15517, loss = 1309.34120334\n",
      "Iteration 15518, loss = 1309.24454333\n",
      "Iteration 15519, loss = 1309.14790502\n",
      "Iteration 15520, loss = 1309.05129111\n",
      "Iteration 15521, loss = 1308.95470606\n",
      "Iteration 15522, loss = 1308.85815644\n",
      "Iteration 15523, loss = 1308.76164833\n",
      "Iteration 15524, loss = 1308.66517870\n",
      "Iteration 15525, loss = 1308.56871626\n",
      "Iteration 15526, loss = 1308.47219959\n",
      "Iteration 15527, loss = 1308.37559124\n",
      "Iteration 15528, loss = 1308.27896363\n",
      "Iteration 15529, loss = 1308.18244389\n",
      "Iteration 15530, loss = 1308.08606147\n",
      "Iteration 15531, loss = 1307.98971822\n",
      "Iteration 15532, loss = 1307.89330659\n",
      "Iteration 15533, loss = 1307.79683429\n",
      "Iteration 15534, loss = 1307.70040827\n",
      "Iteration 15535, loss = 1307.60408527\n",
      "Iteration 15536, loss = 1307.50780357\n",
      "Iteration 15537, loss = 1307.41148196\n",
      "Iteration 15538, loss = 1307.31513162\n",
      "Iteration 15539, loss = 1307.21882824\n",
      "Iteration 15540, loss = 1307.12259462\n",
      "Iteration 15541, loss = 1307.02637723\n",
      "Iteration 15542, loss = 1306.93013540\n",
      "Iteration 15543, loss = 1306.83389749\n",
      "Iteration 15544, loss = 1306.73770804\n",
      "Iteration 15545, loss = 1306.64155961\n",
      "Iteration 15546, loss = 1306.54541301\n",
      "Iteration 15547, loss = 1306.44926055\n",
      "Iteration 15548, loss = 1306.35313170\n",
      "Iteration 15549, loss = 1306.25704259\n",
      "Iteration 15550, loss = 1306.16097463\n",
      "Iteration 15551, loss = 1306.06490839\n",
      "Iteration 15552, loss = 1305.96885256\n",
      "Iteration 15553, loss = 1305.87282588\n",
      "Iteration 15554, loss = 1305.77682724\n",
      "Iteration 15555, loss = 1305.68084116\n",
      "Iteration 15556, loss = 1305.58486345\n",
      "Iteration 15557, loss = 1305.48890510\n",
      "Iteration 15558, loss = 1305.39297326\n",
      "Iteration 15559, loss = 1305.29706139\n",
      "Iteration 15560, loss = 1305.20116140\n",
      "Iteration 15561, loss = 1305.10527591\n",
      "Iteration 15562, loss = 1305.00941231\n",
      "Iteration 15563, loss = 1304.91357096\n",
      "Iteration 15564, loss = 1304.81774610\n",
      "Iteration 15565, loss = 1304.72193533\n",
      "Iteration 15566, loss = 1304.62614242\n",
      "Iteration 15567, loss = 1304.53037069\n",
      "Iteration 15568, loss = 1304.43461826\n",
      "Iteration 15569, loss = 1304.33888177\n",
      "Iteration 15570, loss = 1304.24316146\n",
      "Iteration 15571, loss = 1304.14746010\n",
      "Iteration 15572, loss = 1304.05177856\n",
      "Iteration 15573, loss = 1303.95611493\n",
      "Iteration 15574, loss = 1303.86046775\n",
      "Iteration 15575, loss = 1303.76483796\n",
      "Iteration 15576, loss = 1303.66922709\n",
      "Iteration 15577, loss = 1303.57363502\n",
      "Iteration 15578, loss = 1303.47806044\n",
      "Iteration 15579, loss = 1303.38250290\n",
      "Iteration 15580, loss = 1303.28696323\n",
      "Iteration 15581, loss = 1303.19144216\n",
      "Iteration 15582, loss = 1303.09593931\n",
      "Iteration 15583, loss = 1303.00045394\n",
      "Iteration 15584, loss = 1302.90498598\n",
      "Iteration 15585, loss = 1302.80953601\n",
      "Iteration 15586, loss = 1302.71410433\n",
      "Iteration 15587, loss = 1302.61869060\n",
      "Iteration 15588, loss = 1302.52329441\n",
      "Iteration 15589, loss = 1302.42791584\n",
      "Iteration 15590, loss = 1302.33255522\n",
      "Iteration 15591, loss = 1302.23721267\n",
      "Iteration 15592, loss = 1302.14188795\n",
      "Iteration 15593, loss = 1302.04658085\n",
      "Iteration 15594, loss = 1301.95129143\n",
      "Iteration 15595, loss = 1301.85601989\n",
      "Iteration 15596, loss = 1301.76076628\n",
      "Iteration 15597, loss = 1301.66553043\n",
      "Iteration 15598, loss = 1301.57031224\n",
      "Iteration 15599, loss = 1301.47511175\n",
      "Iteration 15600, loss = 1301.37992906\n",
      "Iteration 15601, loss = 1301.28476421\n",
      "Iteration 15602, loss = 1301.18961708\n",
      "Iteration 15603, loss = 1301.09448762\n",
      "Iteration 15604, loss = 1300.99937584\n",
      "Iteration 15605, loss = 1300.90428181\n",
      "Iteration 15606, loss = 1300.80920553\n",
      "Iteration 15607, loss = 1300.71414695\n",
      "Iteration 15608, loss = 1300.61910602\n",
      "Iteration 15609, loss = 1300.52408276\n",
      "Iteration 15610, loss = 1300.42907718\n",
      "Iteration 15611, loss = 1300.33408930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15612, loss = 1300.23911909\n",
      "Iteration 15613, loss = 1300.14416652\n",
      "Iteration 15614, loss = 1300.04923157\n",
      "Iteration 15615, loss = 1299.95431426\n",
      "Iteration 15616, loss = 1299.85941461\n",
      "Iteration 15617, loss = 1299.76453258\n",
      "Iteration 15618, loss = 1299.66966817\n",
      "Iteration 15619, loss = 1299.57482135\n",
      "Iteration 15620, loss = 1299.47999213\n",
      "Iteration 15621, loss = 1299.38518052\n",
      "Iteration 15622, loss = 1299.29038650\n",
      "Iteration 15623, loss = 1299.19561006\n",
      "Iteration 15624, loss = 1299.10085118\n",
      "Iteration 15625, loss = 1299.00610986\n",
      "Iteration 15626, loss = 1298.91138611\n",
      "Iteration 15627, loss = 1298.81667991\n",
      "Iteration 15628, loss = 1298.72199126\n",
      "Iteration 15629, loss = 1298.62732014\n",
      "Iteration 15630, loss = 1298.53266655\n",
      "Iteration 15631, loss = 1298.43803047\n",
      "Iteration 15632, loss = 1298.34341192\n",
      "Iteration 15633, loss = 1298.24881087\n",
      "Iteration 15634, loss = 1298.15422733\n",
      "Iteration 15635, loss = 1298.05966127\n",
      "Iteration 15636, loss = 1297.96511270\n",
      "Iteration 15637, loss = 1297.87058161\n",
      "Iteration 15638, loss = 1297.77606799\n",
      "Iteration 15639, loss = 1297.68157183\n",
      "Iteration 15640, loss = 1297.58709314\n",
      "Iteration 15641, loss = 1297.49263189\n",
      "Iteration 15642, loss = 1297.39818808\n",
      "Iteration 15643, loss = 1297.30376171\n",
      "Iteration 15644, loss = 1297.20935276\n",
      "Iteration 15645, loss = 1297.11496124\n",
      "Iteration 15646, loss = 1297.02058713\n",
      "Iteration 15647, loss = 1296.92623043\n",
      "Iteration 15648, loss = 1296.83189113\n",
      "Iteration 15649, loss = 1296.73756922\n",
      "Iteration 15650, loss = 1296.64326469\n",
      "Iteration 15651, loss = 1296.54897755\n",
      "Iteration 15652, loss = 1296.45470777\n",
      "Iteration 15653, loss = 1296.36045536\n",
      "Iteration 15654, loss = 1296.26622031\n",
      "Iteration 15655, loss = 1296.17200260\n",
      "Iteration 15656, loss = 1296.07780224\n",
      "Iteration 15657, loss = 1295.98361922\n",
      "Iteration 15658, loss = 1295.88945352\n",
      "Iteration 15659, loss = 1295.79530514\n",
      "Iteration 15660, loss = 1295.70117408\n",
      "Iteration 15661, loss = 1295.60706033\n",
      "Iteration 15662, loss = 1295.51296388\n",
      "Iteration 15663, loss = 1295.41888472\n",
      "Iteration 15664, loss = 1295.32482285\n",
      "Iteration 15665, loss = 1295.23077826\n",
      "Iteration 15666, loss = 1295.13675094\n",
      "Iteration 15667, loss = 1295.04274089\n",
      "Iteration 15668, loss = 1294.94874809\n",
      "Iteration 15669, loss = 1294.85477255\n",
      "Iteration 15670, loss = 1294.76081425\n",
      "Iteration 15671, loss = 1294.66687319\n",
      "Iteration 15672, loss = 1294.57294936\n",
      "Iteration 15673, loss = 1294.47904276\n",
      "Iteration 15674, loss = 1294.38515337\n",
      "Iteration 15675, loss = 1294.29128119\n",
      "Iteration 15676, loss = 1294.19742622\n",
      "Iteration 15677, loss = 1294.10358844\n",
      "Iteration 15678, loss = 1294.00976785\n",
      "Iteration 15679, loss = 1293.91596444\n",
      "Iteration 15680, loss = 1293.82217821\n",
      "Iteration 15681, loss = 1293.72840915\n",
      "Iteration 15682, loss = 1293.63465725\n",
      "Iteration 15683, loss = 1293.54092251\n",
      "Iteration 15684, loss = 1293.44720491\n",
      "Iteration 15685, loss = 1293.35350445\n",
      "Iteration 15686, loss = 1293.25982113\n",
      "Iteration 15687, loss = 1293.16615494\n",
      "Iteration 15688, loss = 1293.07250586\n",
      "Iteration 15689, loss = 1292.97887391\n",
      "Iteration 15690, loss = 1292.88525905\n",
      "Iteration 15691, loss = 1292.79166130\n",
      "Iteration 15692, loss = 1292.69808064\n",
      "Iteration 15693, loss = 1292.60451707\n",
      "Iteration 15694, loss = 1292.51097058\n",
      "Iteration 15695, loss = 1292.41744116\n",
      "Iteration 15696, loss = 1292.32392881\n",
      "Iteration 15697, loss = 1292.23043352\n",
      "Iteration 15698, loss = 1292.13695528\n",
      "Iteration 15699, loss = 1292.04349409\n",
      "Iteration 15700, loss = 1291.95004994\n",
      "Iteration 15701, loss = 1291.85662282\n",
      "Iteration 15702, loss = 1291.76321272\n",
      "Iteration 15703, loss = 1291.66981964\n",
      "Iteration 15704, loss = 1291.57644358\n",
      "Iteration 15705, loss = 1291.48308452\n",
      "Iteration 15706, loss = 1291.38974247\n",
      "Iteration 15707, loss = 1291.29641740\n",
      "Iteration 15708, loss = 1291.20310932\n",
      "Iteration 15709, loss = 1291.10981822\n",
      "Iteration 15710, loss = 1291.01654409\n",
      "Iteration 15711, loss = 1290.92328693\n",
      "Iteration 15712, loss = 1290.83004672\n",
      "Iteration 15713, loss = 1290.73682347\n",
      "Iteration 15714, loss = 1290.64361717\n",
      "Iteration 15715, loss = 1290.55042780\n",
      "Iteration 15716, loss = 1290.45725536\n",
      "Iteration 15717, loss = 1290.36409986\n",
      "Iteration 15718, loss = 1290.27096127\n",
      "Iteration 15719, loss = 1290.17783959\n",
      "Iteration 15720, loss = 1290.08473482\n",
      "Iteration 15721, loss = 1289.99164695\n",
      "Iteration 15722, loss = 1289.89857597\n",
      "Iteration 15723, loss = 1289.80552187\n",
      "Iteration 15724, loss = 1289.71248466\n",
      "Iteration 15725, loss = 1289.61946432\n",
      "Iteration 15726, loss = 1289.52646085\n",
      "Iteration 15727, loss = 1289.43347423\n",
      "Iteration 15728, loss = 1289.34050447\n",
      "Iteration 15729, loss = 1289.24755156\n",
      "Iteration 15730, loss = 1289.15461549\n",
      "Iteration 15731, loss = 1289.06169625\n",
      "Iteration 15732, loss = 1288.96879384\n",
      "Iteration 15733, loss = 1288.87590824\n",
      "Iteration 15734, loss = 1288.78303947\n",
      "Iteration 15735, loss = 1288.69018750\n",
      "Iteration 15736, loss = 1288.59735233\n",
      "Iteration 15737, loss = 1288.50453395\n",
      "Iteration 15738, loss = 1288.41173237\n",
      "Iteration 15739, loss = 1288.31894756\n",
      "Iteration 15740, loss = 1288.22617954\n",
      "Iteration 15741, loss = 1288.13342828\n",
      "Iteration 15742, loss = 1288.04069378\n",
      "Iteration 15743, loss = 1287.94797604\n",
      "Iteration 15744, loss = 1287.85527504\n",
      "Iteration 15745, loss = 1287.76259079\n",
      "Iteration 15746, loss = 1287.66992328\n",
      "Iteration 15747, loss = 1287.57727250\n",
      "Iteration 15748, loss = 1287.48463844\n",
      "Iteration 15749, loss = 1287.39202110\n",
      "Iteration 15750, loss = 1287.29942046\n",
      "Iteration 15751, loss = 1287.20683654\n",
      "Iteration 15752, loss = 1287.11426931\n",
      "Iteration 15753, loss = 1287.02171877\n",
      "Iteration 15754, loss = 1286.92918492\n",
      "Iteration 15755, loss = 1286.83666775\n",
      "Iteration 15756, loss = 1286.74416725\n",
      "Iteration 15757, loss = 1286.65168341\n",
      "Iteration 15758, loss = 1286.55921624\n",
      "Iteration 15759, loss = 1286.46676572\n",
      "Iteration 15760, loss = 1286.37433184\n",
      "Iteration 15761, loss = 1286.28191461\n",
      "Iteration 15762, loss = 1286.18951401\n",
      "Iteration 15763, loss = 1286.09713004\n",
      "Iteration 15764, loss = 1286.00476269\n",
      "Iteration 15765, loss = 1285.91241196\n",
      "Iteration 15766, loss = 1285.82007783\n",
      "Iteration 15767, loss = 1285.72776031\n",
      "Iteration 15768, loss = 1285.63545939\n",
      "Iteration 15769, loss = 1285.54317505\n",
      "Iteration 15770, loss = 1285.45090730\n",
      "Iteration 15771, loss = 1285.35865613\n",
      "Iteration 15772, loss = 1285.26642153\n",
      "Iteration 15773, loss = 1285.17420349\n",
      "Iteration 15774, loss = 1285.08200202\n",
      "Iteration 15775, loss = 1284.98981709\n",
      "Iteration 15776, loss = 1284.89764871\n",
      "Iteration 15777, loss = 1284.80549687\n",
      "Iteration 15778, loss = 1284.71336157\n",
      "Iteration 15779, loss = 1284.62124279\n",
      "Iteration 15780, loss = 1284.52914054\n",
      "Iteration 15781, loss = 1284.43705480\n",
      "Iteration 15782, loss = 1284.34498557\n",
      "Iteration 15783, loss = 1284.25293284\n",
      "Iteration 15784, loss = 1284.16089661\n",
      "Iteration 15785, loss = 1284.06887687\n",
      "Iteration 15786, loss = 1283.97687362\n",
      "Iteration 15787, loss = 1283.88488684\n",
      "Iteration 15788, loss = 1283.79291653\n",
      "Iteration 15789, loss = 1283.70096269\n",
      "Iteration 15790, loss = 1283.60902531\n",
      "Iteration 15791, loss = 1283.51710438\n",
      "Iteration 15792, loss = 1283.42519990\n",
      "Iteration 15793, loss = 1283.33331187\n",
      "Iteration 15794, loss = 1283.24144026\n",
      "Iteration 15795, loss = 1283.14958509\n",
      "Iteration 15796, loss = 1283.05774634\n",
      "Iteration 15797, loss = 1282.96592400\n",
      "Iteration 15798, loss = 1282.87411808\n",
      "Iteration 15799, loss = 1282.78232856\n",
      "Iteration 15800, loss = 1282.69055544\n",
      "Iteration 15801, loss = 1282.59879871\n",
      "Iteration 15802, loss = 1282.50705837\n",
      "Iteration 15803, loss = 1282.41533440\n",
      "Iteration 15804, loss = 1282.32362681\n",
      "Iteration 15805, loss = 1282.23193559\n",
      "Iteration 15806, loss = 1282.14026073\n",
      "Iteration 15807, loss = 1282.04860223\n",
      "Iteration 15808, loss = 1281.95696008\n",
      "Iteration 15809, loss = 1281.86533427\n",
      "Iteration 15810, loss = 1281.77372480\n",
      "Iteration 15811, loss = 1281.68213166\n",
      "Iteration 15812, loss = 1281.59055484\n",
      "Iteration 15813, loss = 1281.49899435\n",
      "Iteration 15814, loss = 1281.40745017\n",
      "Iteration 15815, loss = 1281.31592230\n",
      "Iteration 15816, loss = 1281.22441073\n",
      "Iteration 15817, loss = 1281.13291546\n",
      "Iteration 15818, loss = 1281.04143649\n",
      "Iteration 15819, loss = 1280.94997381\n",
      "Iteration 15820, loss = 1280.85852743\n",
      "Iteration 15821, loss = 1280.76709735\n",
      "Iteration 15822, loss = 1280.67568360\n",
      "Iteration 15823, loss = 1280.58428622\n",
      "Iteration 15824, loss = 1280.49290531\n",
      "Iteration 15825, loss = 1280.40154104\n",
      "Iteration 15826, loss = 1280.31019374\n",
      "Iteration 15827, loss = 1280.21886402\n",
      "Iteration 15828, loss = 1280.12755306\n",
      "Iteration 15829, loss = 1280.03626296\n",
      "Iteration 15830, loss = 1279.94499745\n",
      "Iteration 15831, loss = 1279.85376238\n",
      "Iteration 15832, loss = 1279.76256543\n",
      "Iteration 15833, loss = 1279.67141020\n",
      "Iteration 15834, loss = 1279.58028216\n",
      "Iteration 15835, loss = 1279.48912804\n",
      "Iteration 15836, loss = 1279.39788226\n",
      "Iteration 15837, loss = 1279.30655676\n",
      "Iteration 15838, loss = 1279.21528070\n",
      "Iteration 15839, loss = 1279.12415448\n",
      "Iteration 15840, loss = 1279.03312766\n",
      "Iteration 15841, loss = 1278.94206796\n",
      "Iteration 15842, loss = 1278.85091575\n",
      "Iteration 15843, loss = 1278.75975489\n",
      "Iteration 15844, loss = 1278.66869198\n",
      "Iteration 15845, loss = 1278.57771000\n",
      "Iteration 15846, loss = 1278.48670954\n",
      "Iteration 15847, loss = 1278.39565495\n",
      "Iteration 15848, loss = 1278.30461594\n",
      "Iteration 15849, loss = 1278.21365207\n",
      "Iteration 15850, loss = 1278.12272810\n",
      "Iteration 15851, loss = 1278.03178137\n",
      "Iteration 15852, loss = 1277.94081742\n",
      "Iteration 15853, loss = 1277.84989078\n",
      "Iteration 15854, loss = 1277.75901486\n",
      "Iteration 15855, loss = 1277.66814926\n",
      "Iteration 15856, loss = 1277.57727005\n",
      "Iteration 15857, loss = 1277.48640254\n",
      "Iteration 15858, loss = 1277.39557433\n",
      "Iteration 15859, loss = 1277.30477295\n",
      "Iteration 15860, loss = 1277.21397210\n",
      "Iteration 15861, loss = 1277.12317414\n",
      "Iteration 15862, loss = 1277.03240116\n",
      "Iteration 15863, loss = 1276.94165759\n",
      "Iteration 15864, loss = 1276.85092694\n",
      "Iteration 15865, loss = 1276.76020062\n",
      "Iteration 15866, loss = 1276.66948948\n",
      "Iteration 15867, loss = 1276.57880370\n",
      "Iteration 15868, loss = 1276.48813746\n",
      "Iteration 15869, loss = 1276.39748077\n",
      "Iteration 15870, loss = 1276.30683534\n",
      "Iteration 15871, loss = 1276.21620971\n",
      "Iteration 15872, loss = 1276.12560512\n",
      "Iteration 15873, loss = 1276.03501505\n",
      "Iteration 15874, loss = 1275.94443644\n",
      "Iteration 15875, loss = 1275.85387355\n",
      "Iteration 15876, loss = 1275.76333024\n",
      "Iteration 15877, loss = 1275.67280427\n",
      "Iteration 15878, loss = 1275.58229180\n",
      "Iteration 15879, loss = 1275.49179336\n",
      "Iteration 15880, loss = 1275.40131218\n",
      "Iteration 15881, loss = 1275.31084896\n",
      "Iteration 15882, loss = 1275.22040131\n",
      "Iteration 15883, loss = 1275.12996782\n",
      "Iteration 15884, loss = 1275.03954991\n",
      "Iteration 15885, loss = 1274.94914921\n",
      "Iteration 15886, loss = 1274.85876516\n",
      "Iteration 15887, loss = 1274.76839624\n",
      "Iteration 15888, loss = 1274.67804231\n",
      "Iteration 15889, loss = 1274.58770455\n",
      "Iteration 15890, loss = 1274.49738350\n",
      "Iteration 15891, loss = 1274.40707842\n",
      "Iteration 15892, loss = 1274.31678858\n",
      "Iteration 15893, loss = 1274.22651425\n",
      "Iteration 15894, loss = 1274.13625616\n",
      "Iteration 15895, loss = 1274.04601433\n",
      "Iteration 15896, loss = 1273.95578823\n",
      "Iteration 15897, loss = 1273.86557757\n",
      "Iteration 15898, loss = 1273.77538267\n",
      "Iteration 15899, loss = 1273.68520388\n",
      "Iteration 15900, loss = 1273.59504109\n",
      "Iteration 15901, loss = 1273.50489397\n",
      "Iteration 15902, loss = 1273.41476244\n",
      "Iteration 15903, loss = 1273.32464673\n",
      "Iteration 15904, loss = 1273.23454700\n",
      "Iteration 15905, loss = 1273.14446313\n",
      "Iteration 15906, loss = 1273.05439493\n",
      "Iteration 15907, loss = 1272.96434240\n",
      "Iteration 15908, loss = 1272.87430568\n",
      "Iteration 15909, loss = 1272.78428484\n",
      "Iteration 15910, loss = 1272.69427978\n",
      "Iteration 15911, loss = 1272.60429040\n",
      "Iteration 15912, loss = 1272.51431672\n",
      "Iteration 15913, loss = 1272.42435881\n",
      "Iteration 15914, loss = 1272.33441671\n",
      "Iteration 15915, loss = 1272.24449035\n",
      "Iteration 15916, loss = 1272.15457967\n",
      "Iteration 15917, loss = 1272.06468468\n",
      "Iteration 15918, loss = 1271.97480543\n",
      "Iteration 15919, loss = 1271.88494193\n",
      "Iteration 15920, loss = 1271.79509415\n",
      "Iteration 15921, loss = 1271.70526203\n",
      "Iteration 15922, loss = 1271.61544560\n",
      "Iteration 15923, loss = 1271.52564486\n",
      "Iteration 15924, loss = 1271.43585983\n",
      "Iteration 15925, loss = 1271.34609049\n",
      "Iteration 15926, loss = 1271.25633681\n",
      "Iteration 15927, loss = 1271.16659878\n",
      "Iteration 15928, loss = 1271.07687642\n",
      "Iteration 15929, loss = 1270.98716973\n",
      "Iteration 15930, loss = 1270.89747870\n",
      "Iteration 15931, loss = 1270.80780331\n",
      "Iteration 15932, loss = 1270.71814355\n",
      "Iteration 15933, loss = 1270.62849943\n",
      "Iteration 15934, loss = 1270.53887094\n",
      "Iteration 15935, loss = 1270.44925809\n",
      "Iteration 15936, loss = 1270.35966085\n",
      "Iteration 15937, loss = 1270.27007923\n",
      "Iteration 15938, loss = 1270.18051321\n",
      "Iteration 15939, loss = 1270.09096280\n",
      "Iteration 15940, loss = 1270.00142799\n",
      "Iteration 15941, loss = 1269.91190878\n",
      "Iteration 15942, loss = 1269.82240515\n",
      "Iteration 15943, loss = 1269.73291710\n",
      "Iteration 15944, loss = 1269.64344463\n",
      "Iteration 15945, loss = 1269.55398773\n",
      "Iteration 15946, loss = 1269.46454641\n",
      "Iteration 15947, loss = 1269.37512064\n",
      "Iteration 15948, loss = 1269.28571043\n",
      "Iteration 15949, loss = 1269.19631576\n",
      "Iteration 15950, loss = 1269.10693665\n",
      "Iteration 15951, loss = 1269.01757308\n",
      "Iteration 15952, loss = 1268.92822504\n",
      "Iteration 15953, loss = 1268.83889253\n",
      "Iteration 15954, loss = 1268.74957554\n",
      "Iteration 15955, loss = 1268.66027407\n",
      "Iteration 15956, loss = 1268.57098812\n",
      "Iteration 15957, loss = 1268.48171768\n",
      "Iteration 15958, loss = 1268.39246274\n",
      "Iteration 15959, loss = 1268.30322329\n",
      "Iteration 15960, loss = 1268.21399934\n",
      "Iteration 15961, loss = 1268.12479088\n",
      "Iteration 15962, loss = 1268.03559790\n",
      "Iteration 15963, loss = 1267.94642040\n",
      "Iteration 15964, loss = 1267.85725837\n",
      "Iteration 15965, loss = 1267.76811180\n",
      "Iteration 15966, loss = 1267.67898070\n",
      "Iteration 15967, loss = 1267.58986505\n",
      "Iteration 15968, loss = 1267.50076485\n",
      "Iteration 15969, loss = 1267.41168010\n",
      "Iteration 15970, loss = 1267.32261079\n",
      "Iteration 15971, loss = 1267.23355692\n",
      "Iteration 15972, loss = 1267.14451847\n",
      "Iteration 15973, loss = 1267.05549545\n",
      "Iteration 15974, loss = 1266.96648785\n",
      "Iteration 15975, loss = 1266.87749567\n",
      "Iteration 15976, loss = 1266.78851889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15977, loss = 1266.69955752\n",
      "Iteration 15978, loss = 1266.61061154\n",
      "Iteration 15979, loss = 1266.52168096\n",
      "Iteration 15980, loss = 1266.43276577\n",
      "Iteration 15981, loss = 1266.34386596\n",
      "Iteration 15982, loss = 1266.25498153\n",
      "Iteration 15983, loss = 1266.16611247\n",
      "Iteration 15984, loss = 1266.07725879\n",
      "Iteration 15985, loss = 1265.98842046\n",
      "Iteration 15986, loss = 1265.89959749\n",
      "Iteration 15987, loss = 1265.81078987\n",
      "Iteration 15988, loss = 1265.72199761\n",
      "Iteration 15989, loss = 1265.63322068\n",
      "Iteration 15990, loss = 1265.54445909\n",
      "Iteration 15991, loss = 1265.45571283\n",
      "Iteration 15992, loss = 1265.36698190\n",
      "Iteration 15993, loss = 1265.27826629\n",
      "Iteration 15994, loss = 1265.18956600\n",
      "Iteration 15995, loss = 1265.10088102\n",
      "Iteration 15996, loss = 1265.01221134\n",
      "Iteration 15997, loss = 1264.92355697\n",
      "Iteration 15998, loss = 1264.83491789\n",
      "Iteration 15999, loss = 1264.74629411\n",
      "Iteration 16000, loss = 1264.65768561\n",
      "Iteration 16001, loss = 1264.56909239\n",
      "Iteration 16002, loss = 1264.48051445\n",
      "Iteration 16003, loss = 1264.39195177\n",
      "Iteration 16004, loss = 1264.30340437\n",
      "Iteration 16005, loss = 1264.21487222\n",
      "Iteration 16006, loss = 1264.12635533\n",
      "Iteration 16007, loss = 1264.03785369\n",
      "Iteration 16008, loss = 1263.94936730\n",
      "Iteration 16009, loss = 1263.86089615\n",
      "Iteration 16010, loss = 1263.77244023\n",
      "Iteration 16011, loss = 1263.68399954\n",
      "Iteration 16012, loss = 1263.59557408\n",
      "Iteration 16013, loss = 1263.50716384\n",
      "Iteration 16014, loss = 1263.41876881\n",
      "Iteration 16015, loss = 1263.33038900\n",
      "Iteration 16016, loss = 1263.24202439\n",
      "Iteration 16017, loss = 1263.15367498\n",
      "Iteration 16018, loss = 1263.06534076\n",
      "Iteration 16019, loss = 1262.97702174\n",
      "Iteration 16020, loss = 1262.88871790\n",
      "Iteration 16021, loss = 1262.80042924\n",
      "Iteration 16022, loss = 1262.71215575\n",
      "Iteration 16023, loss = 1262.62389744\n",
      "Iteration 16024, loss = 1262.53565429\n",
      "Iteration 16025, loss = 1262.44742630\n",
      "Iteration 16026, loss = 1262.35921347\n",
      "Iteration 16027, loss = 1262.27101579\n",
      "Iteration 16028, loss = 1262.18283325\n",
      "Iteration 16029, loss = 1262.09466586\n",
      "Iteration 16030, loss = 1262.00651360\n",
      "Iteration 16031, loss = 1261.91837647\n",
      "Iteration 16032, loss = 1261.83025446\n",
      "Iteration 16033, loss = 1261.74214758\n",
      "Iteration 16034, loss = 1261.65405581\n",
      "Iteration 16035, loss = 1261.56597915\n",
      "Iteration 16036, loss = 1261.47791760\n",
      "Iteration 16037, loss = 1261.38987115\n",
      "Iteration 16038, loss = 1261.30183980\n",
      "Iteration 16039, loss = 1261.21382353\n",
      "Iteration 16040, loss = 1261.12582236\n",
      "Iteration 16041, loss = 1261.03783626\n",
      "Iteration 16042, loss = 1260.94986524\n",
      "Iteration 16043, loss = 1260.86190929\n",
      "Iteration 16044, loss = 1260.77396841\n",
      "Iteration 16045, loss = 1260.68604259\n",
      "Iteration 16046, loss = 1260.59813183\n",
      "Iteration 16047, loss = 1260.51023612\n",
      "Iteration 16048, loss = 1260.42235545\n",
      "Iteration 16049, loss = 1260.33448983\n",
      "Iteration 16050, loss = 1260.24663925\n",
      "Iteration 16051, loss = 1260.15880369\n",
      "Iteration 16052, loss = 1260.07098317\n",
      "Iteration 16053, loss = 1259.98317766\n",
      "Iteration 16054, loss = 1259.89538718\n",
      "Iteration 16055, loss = 1259.80761171\n",
      "Iteration 16056, loss = 1259.71985124\n",
      "Iteration 16057, loss = 1259.63210578\n",
      "Iteration 16058, loss = 1259.54437532\n",
      "Iteration 16059, loss = 1259.45665985\n",
      "Iteration 16060, loss = 1259.36895937\n",
      "Iteration 16061, loss = 1259.28127387\n",
      "Iteration 16062, loss = 1259.19360335\n",
      "Iteration 16063, loss = 1259.10594781\n",
      "Iteration 16064, loss = 1259.01830723\n",
      "Iteration 16065, loss = 1258.93068162\n",
      "Iteration 16066, loss = 1258.84307097\n",
      "Iteration 16067, loss = 1258.75547528\n",
      "Iteration 16068, loss = 1258.66789453\n",
      "Iteration 16069, loss = 1258.58032873\n",
      "Iteration 16070, loss = 1258.49277787\n",
      "Iteration 16071, loss = 1258.40524194\n",
      "Iteration 16072, loss = 1258.31772095\n",
      "Iteration 16073, loss = 1258.23021488\n",
      "Iteration 16074, loss = 1258.14272374\n",
      "Iteration 16075, loss = 1258.05524751\n",
      "Iteration 16076, loss = 1257.96778619\n",
      "Iteration 16077, loss = 1257.88033978\n",
      "Iteration 16078, loss = 1257.79290827\n",
      "Iteration 16079, loss = 1257.70549165\n",
      "Iteration 16080, loss = 1257.61808993\n",
      "Iteration 16081, loss = 1257.53070310\n",
      "Iteration 16082, loss = 1257.44333115\n",
      "Iteration 16083, loss = 1257.35597408\n",
      "Iteration 16084, loss = 1257.26863189\n",
      "Iteration 16085, loss = 1257.18130456\n",
      "Iteration 16086, loss = 1257.09399209\n",
      "Iteration 16087, loss = 1257.00669449\n",
      "Iteration 16088, loss = 1256.91941174\n",
      "Iteration 16089, loss = 1256.83214384\n",
      "Iteration 16090, loss = 1256.74489078\n",
      "Iteration 16091, loss = 1256.65765257\n",
      "Iteration 16092, loss = 1256.57042919\n",
      "Iteration 16093, loss = 1256.48322064\n",
      "Iteration 16094, loss = 1256.39602692\n",
      "Iteration 16095, loss = 1256.30884801\n",
      "Iteration 16096, loss = 1256.22168393\n",
      "Iteration 16097, loss = 1256.13453466\n",
      "Iteration 16098, loss = 1256.04740019\n",
      "Iteration 16099, loss = 1255.96028053\n",
      "Iteration 16100, loss = 1255.87317567\n",
      "Iteration 16101, loss = 1255.78608560\n",
      "Iteration 16102, loss = 1255.69901032\n",
      "Iteration 16103, loss = 1255.61194982\n",
      "Iteration 16104, loss = 1255.52490410\n",
      "Iteration 16105, loss = 1255.43787315\n",
      "Iteration 16106, loss = 1255.35085698\n",
      "Iteration 16107, loss = 1255.26385557\n",
      "Iteration 16108, loss = 1255.17686892\n",
      "Iteration 16109, loss = 1255.08989703\n",
      "Iteration 16110, loss = 1255.00293989\n",
      "Iteration 16111, loss = 1254.91599749\n",
      "Iteration 16112, loss = 1254.82906984\n",
      "Iteration 16113, loss = 1254.74215692\n",
      "Iteration 16114, loss = 1254.65525874\n",
      "Iteration 16115, loss = 1254.56837528\n",
      "Iteration 16116, loss = 1254.48150655\n",
      "Iteration 16117, loss = 1254.39465254\n",
      "Iteration 16118, loss = 1254.30781324\n",
      "Iteration 16119, loss = 1254.22098865\n",
      "Iteration 16120, loss = 1254.13417877\n",
      "Iteration 16121, loss = 1254.04738358\n",
      "Iteration 16122, loss = 1253.96060309\n",
      "Iteration 16123, loss = 1253.87383729\n",
      "Iteration 16124, loss = 1253.78708618\n",
      "Iteration 16125, loss = 1253.70034975\n",
      "Iteration 16126, loss = 1253.61362800\n",
      "Iteration 16127, loss = 1253.52692092\n",
      "Iteration 16128, loss = 1253.44022850\n",
      "Iteration 16129, loss = 1253.35355075\n",
      "Iteration 16130, loss = 1253.26688766\n",
      "Iteration 16131, loss = 1253.18023923\n",
      "Iteration 16132, loss = 1253.09360544\n",
      "Iteration 16133, loss = 1253.00698630\n",
      "Iteration 16134, loss = 1252.92038179\n",
      "Iteration 16135, loss = 1252.83379193\n",
      "Iteration 16136, loss = 1252.74721669\n",
      "Iteration 16137, loss = 1252.66065608\n",
      "Iteration 16138, loss = 1252.57411010\n",
      "Iteration 16139, loss = 1252.48757873\n",
      "Iteration 16140, loss = 1252.40106197\n",
      "Iteration 16141, loss = 1252.31455983\n",
      "Iteration 16142, loss = 1252.22807228\n",
      "Iteration 16143, loss = 1252.14159934\n",
      "Iteration 16144, loss = 1252.05514099\n",
      "Iteration 16145, loss = 1251.96869723\n",
      "Iteration 16146, loss = 1251.88226805\n",
      "Iteration 16147, loss = 1251.79585346\n",
      "Iteration 16148, loss = 1251.70945345\n",
      "Iteration 16149, loss = 1251.62306800\n",
      "Iteration 16150, loss = 1251.53669713\n",
      "Iteration 16151, loss = 1251.45034082\n",
      "Iteration 16152, loss = 1251.36399907\n",
      "Iteration 16153, loss = 1251.27767187\n",
      "Iteration 16154, loss = 1251.19135924\n",
      "Iteration 16155, loss = 1251.10506116\n",
      "Iteration 16156, loss = 1251.01877764\n",
      "Iteration 16157, loss = 1250.93250870\n",
      "Iteration 16158, loss = 1250.84625437\n",
      "Iteration 16159, loss = 1250.76001469\n",
      "Iteration 16160, loss = 1250.67378979\n",
      "Iteration 16161, loss = 1250.58757985\n",
      "Iteration 16162, loss = 1250.50138528\n",
      "Iteration 16163, loss = 1250.41520678\n",
      "Iteration 16164, loss = 1250.32904568\n",
      "Iteration 16165, loss = 1250.24290433\n",
      "Iteration 16166, loss = 1250.15678684\n",
      "Iteration 16167, loss = 1250.07069937\n",
      "Iteration 16168, loss = 1249.98464935\n",
      "Iteration 16169, loss = 1249.89863803\n",
      "Iteration 16170, loss = 1249.81264539\n",
      "Iteration 16171, loss = 1249.72661250\n",
      "Iteration 16172, loss = 1249.64048141\n",
      "Iteration 16173, loss = 1249.55428538\n",
      "Iteration 16174, loss = 1249.46815952\n",
      "Iteration 16175, loss = 1249.38218229\n",
      "Iteration 16176, loss = 1249.29628383\n",
      "Iteration 16177, loss = 1249.21033614\n",
      "Iteration 16178, loss = 1249.12429959\n",
      "Iteration 16179, loss = 1249.03826872\n",
      "Iteration 16180, loss = 1248.95233815\n",
      "Iteration 16181, loss = 1248.86647630\n",
      "Iteration 16182, loss = 1248.78058639\n",
      "Iteration 16183, loss = 1248.69464513\n",
      "Iteration 16184, loss = 1248.60872542\n",
      "Iteration 16185, loss = 1248.52287854\n",
      "Iteration 16186, loss = 1248.43706423\n",
      "Iteration 16187, loss = 1248.35122410\n",
      "Iteration 16188, loss = 1248.26536860\n",
      "Iteration 16189, loss = 1248.17955052\n",
      "Iteration 16190, loss = 1248.09377950\n",
      "Iteration 16191, loss = 1248.00801565\n",
      "Iteration 16192, loss = 1247.92223738\n",
      "Iteration 16193, loss = 1247.83647019\n",
      "Iteration 16194, loss = 1247.75074018\n",
      "Iteration 16195, loss = 1247.66503459\n",
      "Iteration 16196, loss = 1247.57932824\n",
      "Iteration 16197, loss = 1247.49362355\n",
      "Iteration 16198, loss = 1247.40794169\n",
      "Iteration 16199, loss = 1247.32228729\n",
      "Iteration 16200, loss = 1247.23664458\n",
      "Iteration 16201, loss = 1247.15100483\n",
      "Iteration 16202, loss = 1247.06537817\n",
      "Iteration 16203, loss = 1246.97977479\n",
      "Iteration 16204, loss = 1246.89418961\n",
      "Iteration 16205, loss = 1246.80861283\n",
      "Iteration 16206, loss = 1246.72304542\n",
      "Iteration 16207, loss = 1246.63749560\n",
      "Iteration 16208, loss = 1246.55196522\n",
      "Iteration 16209, loss = 1246.46644820\n",
      "Iteration 16210, loss = 1246.38094108\n",
      "Iteration 16211, loss = 1246.29544759\n",
      "Iteration 16212, loss = 1246.20997178\n",
      "Iteration 16213, loss = 1246.12451197\n",
      "Iteration 16214, loss = 1246.03906433\n",
      "Iteration 16215, loss = 1245.95362887\n",
      "Iteration 16216, loss = 1245.86820870\n",
      "Iteration 16217, loss = 1245.78280486\n",
      "Iteration 16218, loss = 1245.69741524\n",
      "Iteration 16219, loss = 1245.61203820\n",
      "Iteration 16220, loss = 1245.52667487\n",
      "Iteration 16221, loss = 1245.44132695\n",
      "Iteration 16222, loss = 1245.35599418\n",
      "Iteration 16223, loss = 1245.27067507\n",
      "Iteration 16224, loss = 1245.18536926\n",
      "Iteration 16225, loss = 1245.10007780\n",
      "Iteration 16226, loss = 1245.01480138\n",
      "Iteration 16227, loss = 1244.92953943\n",
      "Iteration 16228, loss = 1244.84429115\n",
      "Iteration 16229, loss = 1244.75905668\n",
      "Iteration 16230, loss = 1244.67383669\n",
      "Iteration 16231, loss = 1244.58863138\n",
      "Iteration 16232, loss = 1244.50344024\n",
      "Iteration 16233, loss = 1244.41826293\n",
      "Iteration 16234, loss = 1244.33309968\n",
      "Iteration 16235, loss = 1244.24795086\n",
      "Iteration 16236, loss = 1244.16281646\n",
      "Iteration 16237, loss = 1244.07769614\n",
      "Iteration 16238, loss = 1243.99258979\n",
      "Iteration 16239, loss = 1243.90749758\n",
      "Iteration 16240, loss = 1243.82241972\n",
      "Iteration 16241, loss = 1243.73735613\n",
      "Iteration 16242, loss = 1243.65230660\n",
      "Iteration 16243, loss = 1243.56727112\n",
      "Iteration 16244, loss = 1243.48224980\n",
      "Iteration 16245, loss = 1243.39724274\n",
      "Iteration 16246, loss = 1243.31224987\n",
      "Iteration 16247, loss = 1243.22727107\n",
      "Iteration 16248, loss = 1243.14230634\n",
      "Iteration 16249, loss = 1243.05735577\n",
      "Iteration 16250, loss = 1242.97241938\n",
      "Iteration 16251, loss = 1242.88749714\n",
      "Iteration 16252, loss = 1242.80258898\n",
      "Iteration 16253, loss = 1242.71769490\n",
      "Iteration 16254, loss = 1242.63281494\n",
      "Iteration 16255, loss = 1242.54794913\n",
      "Iteration 16256, loss = 1242.46309743\n",
      "Iteration 16257, loss = 1242.37825980\n",
      "Iteration 16258, loss = 1242.29343625\n",
      "Iteration 16259, loss = 1242.20862679\n",
      "Iteration 16260, loss = 1242.12383144\n",
      "Iteration 16261, loss = 1242.03905018\n",
      "Iteration 16262, loss = 1241.95428298\n",
      "Iteration 16263, loss = 1241.86952984\n",
      "Iteration 16264, loss = 1241.78479078\n",
      "Iteration 16265, loss = 1241.70006579\n",
      "Iteration 16266, loss = 1241.61535487\n",
      "Iteration 16267, loss = 1241.53065799\n",
      "Iteration 16268, loss = 1241.44597516\n",
      "Iteration 16269, loss = 1241.36130638\n",
      "Iteration 16270, loss = 1241.27665165\n",
      "Iteration 16271, loss = 1241.19201096\n",
      "Iteration 16272, loss = 1241.10738430\n",
      "Iteration 16273, loss = 1241.02277167\n",
      "Iteration 16274, loss = 1240.93817306\n",
      "Iteration 16275, loss = 1240.85358848\n",
      "Iteration 16276, loss = 1240.76901792\n",
      "Iteration 16277, loss = 1240.68446138\n",
      "Iteration 16278, loss = 1240.59991884\n",
      "Iteration 16279, loss = 1240.51539030\n",
      "Iteration 16280, loss = 1240.43087577\n",
      "Iteration 16281, loss = 1240.34637524\n",
      "Iteration 16282, loss = 1240.26188870\n",
      "Iteration 16283, loss = 1240.17741614\n",
      "Iteration 16284, loss = 1240.09295757\n",
      "Iteration 16285, loss = 1240.00851298\n",
      "Iteration 16286, loss = 1239.92408237\n",
      "Iteration 16287, loss = 1239.83966573\n",
      "Iteration 16288, loss = 1239.75526305\n",
      "Iteration 16289, loss = 1239.67087434\n",
      "Iteration 16290, loss = 1239.58649959\n",
      "Iteration 16291, loss = 1239.50213879\n",
      "Iteration 16292, loss = 1239.41779195\n",
      "Iteration 16293, loss = 1239.33345905\n",
      "Iteration 16294, loss = 1239.24914009\n",
      "Iteration 16295, loss = 1239.16483507\n",
      "Iteration 16296, loss = 1239.08054399\n",
      "Iteration 16297, loss = 1238.99626683\n",
      "Iteration 16298, loss = 1238.91200360\n",
      "Iteration 16299, loss = 1238.82775430\n",
      "Iteration 16300, loss = 1238.74351891\n",
      "Iteration 16301, loss = 1238.65929743\n",
      "Iteration 16302, loss = 1238.57508986\n",
      "Iteration 16303, loss = 1238.49089620\n",
      "Iteration 16304, loss = 1238.40671644\n",
      "Iteration 16305, loss = 1238.32255057\n",
      "Iteration 16306, loss = 1238.23839860\n",
      "Iteration 16307, loss = 1238.15426051\n",
      "Iteration 16308, loss = 1238.07013631\n",
      "Iteration 16309, loss = 1237.98602599\n",
      "Iteration 16310, loss = 1237.90192954\n",
      "Iteration 16311, loss = 1237.81784697\n",
      "Iteration 16312, loss = 1237.73377826\n",
      "Iteration 16313, loss = 1237.64972342\n",
      "Iteration 16314, loss = 1237.56568243\n",
      "Iteration 16315, loss = 1237.48165530\n",
      "Iteration 16316, loss = 1237.39764203\n",
      "Iteration 16317, loss = 1237.31364259\n",
      "Iteration 16318, loss = 1237.22965700\n",
      "Iteration 16319, loss = 1237.14568525\n",
      "Iteration 16320, loss = 1237.06172734\n",
      "Iteration 16321, loss = 1236.97778325\n",
      "Iteration 16322, loss = 1236.89385299\n",
      "Iteration 16323, loss = 1236.80993655\n",
      "Iteration 16324, loss = 1236.72603393\n",
      "Iteration 16325, loss = 1236.64214512\n",
      "Iteration 16326, loss = 1236.55827012\n",
      "Iteration 16327, loss = 1236.47440893\n",
      "Iteration 16328, loss = 1236.39056154\n",
      "Iteration 16329, loss = 1236.30672794\n",
      "Iteration 16330, loss = 1236.22290814\n",
      "Iteration 16331, loss = 1236.13910213\n",
      "Iteration 16332, loss = 1236.05530990\n",
      "Iteration 16333, loss = 1235.97153145\n",
      "Iteration 16334, loss = 1235.88776678\n",
      "Iteration 16335, loss = 1235.80401588\n",
      "Iteration 16336, loss = 1235.72027874\n",
      "Iteration 16337, loss = 1235.63655538\n",
      "Iteration 16338, loss = 1235.55284577\n",
      "Iteration 16339, loss = 1235.46914991\n",
      "Iteration 16340, loss = 1235.38546781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16341, loss = 1235.30179946\n",
      "Iteration 16342, loss = 1235.21814485\n",
      "Iteration 16343, loss = 1235.13450398\n",
      "Iteration 16344, loss = 1235.05087684\n",
      "Iteration 16345, loss = 1234.96726344\n",
      "Iteration 16346, loss = 1234.88366376\n",
      "Iteration 16347, loss = 1234.80007781\n",
      "Iteration 16348, loss = 1234.71650557\n",
      "Iteration 16349, loss = 1234.63294705\n",
      "Iteration 16350, loss = 1234.54940224\n",
      "Iteration 16351, loss = 1234.46587113\n",
      "Iteration 16352, loss = 1234.38235373\n",
      "Iteration 16353, loss = 1234.29885003\n",
      "Iteration 16354, loss = 1234.21536002\n",
      "Iteration 16355, loss = 1234.13188369\n",
      "Iteration 16356, loss = 1234.04842106\n",
      "Iteration 16357, loss = 1233.96497211\n",
      "Iteration 16358, loss = 1233.88153683\n",
      "Iteration 16359, loss = 1233.79811523\n",
      "Iteration 16360, loss = 1233.71470730\n",
      "Iteration 16361, loss = 1233.63131303\n",
      "Iteration 16362, loss = 1233.54793242\n",
      "Iteration 16363, loss = 1233.46456548\n",
      "Iteration 16364, loss = 1233.38121218\n",
      "Iteration 16365, loss = 1233.29787253\n",
      "Iteration 16366, loss = 1233.21454653\n",
      "Iteration 16367, loss = 1233.13123417\n",
      "Iteration 16368, loss = 1233.04793544\n",
      "Iteration 16369, loss = 1232.96465035\n",
      "Iteration 16370, loss = 1232.88137889\n",
      "Iteration 16371, loss = 1232.79812105\n",
      "Iteration 16372, loss = 1232.71487683\n",
      "Iteration 16373, loss = 1232.63164623\n",
      "Iteration 16374, loss = 1232.54842924\n",
      "Iteration 16375, loss = 1232.46522585\n",
      "Iteration 16376, loss = 1232.38203607\n",
      "Iteration 16377, loss = 1232.29885989\n",
      "Iteration 16378, loss = 1232.21569731\n",
      "Iteration 16379, loss = 1232.13254832\n",
      "Iteration 16380, loss = 1232.04941291\n",
      "Iteration 16381, loss = 1231.96629109\n",
      "Iteration 16382, loss = 1231.88318285\n",
      "Iteration 16383, loss = 1231.80008818\n",
      "Iteration 16384, loss = 1231.71700709\n",
      "Iteration 16385, loss = 1231.63393956\n",
      "Iteration 16386, loss = 1231.55088560\n",
      "Iteration 16387, loss = 1231.46784519\n",
      "Iteration 16388, loss = 1231.38481834\n",
      "Iteration 16389, loss = 1231.30180504\n",
      "Iteration 16390, loss = 1231.21880528\n",
      "Iteration 16391, loss = 1231.13581907\n",
      "Iteration 16392, loss = 1231.05284640\n",
      "Iteration 16393, loss = 1230.96988726\n",
      "Iteration 16394, loss = 1230.88694165\n",
      "Iteration 16395, loss = 1230.80400957\n",
      "Iteration 16396, loss = 1230.72109101\n",
      "Iteration 16397, loss = 1230.63818597\n",
      "Iteration 16398, loss = 1230.55529444\n",
      "Iteration 16399, loss = 1230.47241642\n",
      "Iteration 16400, loss = 1230.38955191\n",
      "Iteration 16401, loss = 1230.30670090\n",
      "Iteration 16402, loss = 1230.22386338\n",
      "Iteration 16403, loss = 1230.14103936\n",
      "Iteration 16404, loss = 1230.05822883\n",
      "Iteration 16405, loss = 1229.97543179\n",
      "Iteration 16406, loss = 1229.89264822\n",
      "Iteration 16407, loss = 1229.80987814\n",
      "Iteration 16408, loss = 1229.72712152\n",
      "Iteration 16409, loss = 1229.64437838\n",
      "Iteration 16410, loss = 1229.56164870\n",
      "Iteration 16411, loss = 1229.47893248\n",
      "Iteration 16412, loss = 1229.39622972\n",
      "Iteration 16413, loss = 1229.31354041\n",
      "Iteration 16414, loss = 1229.23086455\n",
      "Iteration 16415, loss = 1229.14820213\n",
      "Iteration 16416, loss = 1229.06555316\n",
      "Iteration 16417, loss = 1228.98291762\n",
      "Iteration 16418, loss = 1228.90029551\n",
      "Iteration 16419, loss = 1228.81768683\n",
      "Iteration 16420, loss = 1228.73509158\n",
      "Iteration 16421, loss = 1228.65250974\n",
      "Iteration 16422, loss = 1228.56994132\n",
      "Iteration 16423, loss = 1228.48738631\n",
      "Iteration 16424, loss = 1228.40484471\n",
      "Iteration 16425, loss = 1228.32231652\n",
      "Iteration 16426, loss = 1228.23980172\n",
      "Iteration 16427, loss = 1228.15730032\n",
      "Iteration 16428, loss = 1228.07481231\n",
      "Iteration 16429, loss = 1227.99233769\n",
      "Iteration 16430, loss = 1227.90987645\n",
      "Iteration 16431, loss = 1227.82742859\n",
      "Iteration 16432, loss = 1227.74499410\n",
      "Iteration 16433, loss = 1227.66257299\n",
      "Iteration 16434, loss = 1227.58016524\n",
      "Iteration 16435, loss = 1227.49777086\n",
      "Iteration 16436, loss = 1227.41538983\n",
      "Iteration 16437, loss = 1227.33302216\n",
      "Iteration 16438, loss = 1227.25066784\n",
      "Iteration 16439, loss = 1227.16832686\n",
      "Iteration 16440, loss = 1227.08599923\n",
      "Iteration 16441, loss = 1227.00368493\n",
      "Iteration 16442, loss = 1226.92138397\n",
      "Iteration 16443, loss = 1226.83909634\n",
      "Iteration 16444, loss = 1226.75682203\n",
      "Iteration 16445, loss = 1226.67456105\n",
      "Iteration 16446, loss = 1226.59231338\n",
      "Iteration 16447, loss = 1226.51007903\n",
      "Iteration 16448, loss = 1226.42785798\n",
      "Iteration 16449, loss = 1226.34565025\n",
      "Iteration 16450, loss = 1226.26345581\n",
      "Iteration 16451, loss = 1226.18127467\n",
      "Iteration 16452, loss = 1226.09910682\n",
      "Iteration 16453, loss = 1226.01695226\n",
      "Iteration 16454, loss = 1225.93481099\n",
      "Iteration 16455, loss = 1225.85268299\n",
      "Iteration 16456, loss = 1225.77056827\n",
      "Iteration 16457, loss = 1225.68846683\n",
      "Iteration 16458, loss = 1225.60637865\n",
      "Iteration 16459, loss = 1225.52430374\n",
      "Iteration 16460, loss = 1225.44224209\n",
      "Iteration 16461, loss = 1225.36019369\n",
      "Iteration 16462, loss = 1225.27815854\n",
      "Iteration 16463, loss = 1225.19613664\n",
      "Iteration 16464, loss = 1225.11412799\n",
      "Iteration 16465, loss = 1225.03213257\n",
      "Iteration 16466, loss = 1224.95015039\n",
      "Iteration 16467, loss = 1224.86818144\n",
      "Iteration 16468, loss = 1224.78622572\n",
      "Iteration 16469, loss = 1224.70428322\n",
      "Iteration 16470, loss = 1224.62235394\n",
      "Iteration 16471, loss = 1224.54043787\n",
      "Iteration 16472, loss = 1224.45853502\n",
      "Iteration 16473, loss = 1224.37664537\n",
      "Iteration 16474, loss = 1224.29476892\n",
      "Iteration 16475, loss = 1224.21290567\n",
      "Iteration 16476, loss = 1224.13105561\n",
      "Iteration 16477, loss = 1224.04921874\n",
      "Iteration 16478, loss = 1223.96739506\n",
      "Iteration 16479, loss = 1223.88558456\n",
      "Iteration 16480, loss = 1223.80378723\n",
      "Iteration 16481, loss = 1223.72200308\n",
      "Iteration 16482, loss = 1223.64023210\n",
      "Iteration 16483, loss = 1223.55847428\n",
      "Iteration 16484, loss = 1223.47672963\n",
      "Iteration 16485, loss = 1223.39499812\n",
      "Iteration 16486, loss = 1223.31327977\n",
      "Iteration 16487, loss = 1223.23157457\n",
      "Iteration 16488, loss = 1223.14988252\n",
      "Iteration 16489, loss = 1223.06820360\n",
      "Iteration 16490, loss = 1222.98653782\n",
      "Iteration 16491, loss = 1222.90488516\n",
      "Iteration 16492, loss = 1222.82324564\n",
      "Iteration 16493, loss = 1222.74161924\n",
      "Iteration 16494, loss = 1222.66000595\n",
      "Iteration 16495, loss = 1222.57840578\n",
      "Iteration 16496, loss = 1222.49681873\n",
      "Iteration 16497, loss = 1222.41524477\n",
      "Iteration 16498, loss = 1222.33368392\n",
      "Iteration 16499, loss = 1222.25213617\n",
      "Iteration 16500, loss = 1222.17060151\n",
      "Iteration 16501, loss = 1222.08907994\n",
      "Iteration 16502, loss = 1222.00757145\n",
      "Iteration 16503, loss = 1221.92607604\n",
      "Iteration 16504, loss = 1221.84459371\n",
      "Iteration 16505, loss = 1221.76312446\n",
      "Iteration 16506, loss = 1221.68166827\n",
      "Iteration 16507, loss = 1221.60022514\n",
      "Iteration 16508, loss = 1221.51879508\n",
      "Iteration 16509, loss = 1221.43737807\n",
      "Iteration 16510, loss = 1221.35597411\n",
      "Iteration 16511, loss = 1221.27458320\n",
      "Iteration 16512, loss = 1221.19320533\n",
      "Iteration 16513, loss = 1221.11184050\n",
      "Iteration 16514, loss = 1221.03048870\n",
      "Iteration 16515, loss = 1220.94914993\n",
      "Iteration 16516, loss = 1220.86782420\n",
      "Iteration 16517, loss = 1220.78651148\n",
      "Iteration 16518, loss = 1220.70521178\n",
      "Iteration 16519, loss = 1220.62392511\n",
      "Iteration 16520, loss = 1220.54265145\n",
      "Iteration 16521, loss = 1220.46139081\n",
      "Iteration 16522, loss = 1220.38014321\n",
      "Iteration 16523, loss = 1220.29890866\n",
      "Iteration 16524, loss = 1220.21768721\n",
      "Iteration 16525, loss = 1220.13647895\n",
      "Iteration 16526, loss = 1220.05528402\n",
      "Iteration 16527, loss = 1219.97410274\n",
      "Iteration 16528, loss = 1219.89293563\n",
      "Iteration 16529, loss = 1219.81178372\n",
      "Iteration 16530, loss = 1219.73064877\n",
      "Iteration 16531, loss = 1219.64953392\n",
      "Iteration 16532, loss = 1219.56844406\n",
      "Iteration 16533, loss = 1219.48738594\n",
      "Iteration 16534, loss = 1219.40636398\n",
      "Iteration 16535, loss = 1219.32537075\n",
      "Iteration 16536, loss = 1219.24436687\n",
      "Iteration 16537, loss = 1219.16329143\n",
      "Iteration 16538, loss = 1219.08212433\n",
      "Iteration 16539, loss = 1219.00095716\n",
      "Iteration 16540, loss = 1218.91990690\n",
      "Iteration 16541, loss = 1218.83897771\n",
      "Iteration 16542, loss = 1218.75806370\n",
      "Iteration 16543, loss = 1218.67707066\n",
      "Iteration 16544, loss = 1218.59602254\n",
      "Iteration 16545, loss = 1218.51502545\n",
      "Iteration 16546, loss = 1218.43412319\n",
      "Iteration 16547, loss = 1218.35324882\n",
      "Iteration 16548, loss = 1218.27232779\n",
      "Iteration 16549, loss = 1218.19137739\n",
      "Iteration 16550, loss = 1218.11047045\n",
      "Iteration 16551, loss = 1218.02962576\n",
      "Iteration 16552, loss = 1217.94879092\n",
      "Iteration 16553, loss = 1217.86792750\n",
      "Iteration 16554, loss = 1217.78706292\n",
      "Iteration 16555, loss = 1217.70624013\n",
      "Iteration 16556, loss = 1217.62545314\n",
      "Iteration 16557, loss = 1217.54466442\n",
      "Iteration 16558, loss = 1217.46386456\n",
      "Iteration 16559, loss = 1217.38308108\n",
      "Iteration 16560, loss = 1217.30233143\n",
      "Iteration 16561, loss = 1217.22159937\n",
      "Iteration 16562, loss = 1217.14086502\n",
      "Iteration 16563, loss = 1217.06013439\n",
      "Iteration 16564, loss = 1216.97942590\n",
      "Iteration 16565, loss = 1216.89874098\n",
      "Iteration 16566, loss = 1216.81806513\n",
      "Iteration 16567, loss = 1216.73739219\n",
      "Iteration 16568, loss = 1216.65673174\n",
      "Iteration 16569, loss = 1216.57609207\n",
      "Iteration 16570, loss = 1216.49546833\n",
      "Iteration 16571, loss = 1216.41485206\n",
      "Iteration 16572, loss = 1216.33424422\n",
      "Iteration 16573, loss = 1216.25365198\n",
      "Iteration 16574, loss = 1216.17307709\n",
      "Iteration 16575, loss = 1216.09251436\n",
      "Iteration 16576, loss = 1216.01196053\n",
      "Iteration 16577, loss = 1215.93141856\n",
      "Iteration 16578, loss = 1215.85089217\n",
      "Iteration 16579, loss = 1215.77038034\n",
      "Iteration 16580, loss = 1215.68987966\n",
      "Iteration 16581, loss = 1215.60938968\n",
      "Iteration 16582, loss = 1215.52891298\n",
      "Iteration 16583, loss = 1215.44845087\n",
      "Iteration 16584, loss = 1215.36800179\n",
      "Iteration 16585, loss = 1215.28756406\n",
      "Iteration 16586, loss = 1215.20713827\n",
      "Iteration 16587, loss = 1215.12672600\n",
      "Iteration 16588, loss = 1215.04632741\n",
      "Iteration 16589, loss = 1214.96594126\n",
      "Iteration 16590, loss = 1214.88556693\n",
      "Iteration 16591, loss = 1214.80520514\n",
      "Iteration 16592, loss = 1214.72485669\n",
      "Iteration 16593, loss = 1214.64452133\n",
      "Iteration 16594, loss = 1214.56419830\n",
      "Iteration 16595, loss = 1214.48388747\n",
      "Iteration 16596, loss = 1214.40358939\n",
      "Iteration 16597, loss = 1214.32330439\n",
      "Iteration 16598, loss = 1214.24303218\n",
      "Iteration 16599, loss = 1214.16277233\n",
      "Iteration 16600, loss = 1214.08252491\n",
      "Iteration 16601, loss = 1214.00229027\n",
      "Iteration 16602, loss = 1213.92206850\n",
      "Iteration 16603, loss = 1213.84185939\n",
      "Iteration 16604, loss = 1213.76166271\n",
      "Iteration 16605, loss = 1213.68147856\n",
      "Iteration 16606, loss = 1213.60130714\n",
      "Iteration 16607, loss = 1213.52114846\n",
      "Iteration 16608, loss = 1213.44100238\n",
      "Iteration 16609, loss = 1213.36086878\n",
      "Iteration 16610, loss = 1213.28074775\n",
      "Iteration 16611, loss = 1213.20063938\n",
      "Iteration 16612, loss = 1213.12054368\n",
      "Iteration 16613, loss = 1213.04046054\n",
      "Iteration 16614, loss = 1212.96038991\n",
      "Iteration 16615, loss = 1212.88033184\n",
      "Iteration 16616, loss = 1212.80028639\n",
      "Iteration 16617, loss = 1212.72025354\n",
      "Iteration 16618, loss = 1212.64023324\n",
      "Iteration 16619, loss = 1212.56022545\n",
      "Iteration 16620, loss = 1212.48023020\n",
      "Iteration 16621, loss = 1212.40024754\n",
      "Iteration 16622, loss = 1212.32027743\n",
      "Iteration 16623, loss = 1212.24031985\n",
      "Iteration 16624, loss = 1212.16037477\n",
      "Iteration 16625, loss = 1212.08044222\n",
      "Iteration 16626, loss = 1212.00052221\n",
      "Iteration 16627, loss = 1211.92061472\n",
      "Iteration 16628, loss = 1211.84071974\n",
      "Iteration 16629, loss = 1211.76083725\n",
      "Iteration 16630, loss = 1211.68096726\n",
      "Iteration 16631, loss = 1211.60110977\n",
      "Iteration 16632, loss = 1211.52126478\n",
      "Iteration 16633, loss = 1211.44143227\n",
      "Iteration 16634, loss = 1211.36161223\n",
      "Iteration 16635, loss = 1211.28180467\n",
      "Iteration 16636, loss = 1211.20200958\n",
      "Iteration 16637, loss = 1211.12222696\n",
      "Iteration 16638, loss = 1211.04245679\n",
      "Iteration 16639, loss = 1210.96269908\n",
      "Iteration 16640, loss = 1210.88295381\n",
      "Iteration 16641, loss = 1210.80322099\n",
      "Iteration 16642, loss = 1210.72350061\n",
      "Iteration 16643, loss = 1210.64379266\n",
      "Iteration 16644, loss = 1210.56409713\n",
      "Iteration 16645, loss = 1210.48441403\n",
      "Iteration 16646, loss = 1210.40474334\n",
      "Iteration 16647, loss = 1210.32508506\n",
      "Iteration 16648, loss = 1210.24543919\n",
      "Iteration 16649, loss = 1210.16580572\n",
      "Iteration 16650, loss = 1210.08618465\n",
      "Iteration 16651, loss = 1210.00657596\n",
      "Iteration 16652, loss = 1209.92697966\n",
      "Iteration 16653, loss = 1209.84739574\n",
      "Iteration 16654, loss = 1209.76782419\n",
      "Iteration 16655, loss = 1209.68826500\n",
      "Iteration 16656, loss = 1209.60871818\n",
      "Iteration 16657, loss = 1209.52918371\n",
      "Iteration 16658, loss = 1209.44966160\n",
      "Iteration 16659, loss = 1209.37015183\n",
      "Iteration 16660, loss = 1209.29065440\n",
      "Iteration 16661, loss = 1209.21116930\n",
      "Iteration 16662, loss = 1209.13169653\n",
      "Iteration 16663, loss = 1209.05223609\n",
      "Iteration 16664, loss = 1208.97278796\n",
      "Iteration 16665, loss = 1208.89335214\n",
      "Iteration 16666, loss = 1208.81392863\n",
      "Iteration 16667, loss = 1208.73451741\n",
      "Iteration 16668, loss = 1208.65511850\n",
      "Iteration 16669, loss = 1208.57573187\n",
      "Iteration 16670, loss = 1208.49635752\n",
      "Iteration 16671, loss = 1208.41699545\n",
      "Iteration 16672, loss = 1208.33764565\n",
      "Iteration 16673, loss = 1208.25830811\n",
      "Iteration 16674, loss = 1208.17898283\n",
      "Iteration 16675, loss = 1208.09966981\n",
      "Iteration 16676, loss = 1208.02036903\n",
      "Iteration 16677, loss = 1207.94108050\n",
      "Iteration 16678, loss = 1207.86180420\n",
      "Iteration 16679, loss = 1207.78254012\n",
      "Iteration 16680, loss = 1207.70328828\n",
      "Iteration 16681, loss = 1207.62404865\n",
      "Iteration 16682, loss = 1207.54482123\n",
      "Iteration 16683, loss = 1207.46560601\n",
      "Iteration 16684, loss = 1207.38640299\n",
      "Iteration 16685, loss = 1207.30721217\n",
      "Iteration 16686, loss = 1207.22803353\n",
      "Iteration 16687, loss = 1207.14886708\n",
      "Iteration 16688, loss = 1207.06971280\n",
      "Iteration 16689, loss = 1206.99057068\n",
      "Iteration 16690, loss = 1206.91144073\n",
      "Iteration 16691, loss = 1206.83232293\n",
      "Iteration 16692, loss = 1206.75321728\n",
      "Iteration 16693, loss = 1206.67412377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16694, loss = 1206.59504240\n",
      "Iteration 16695, loss = 1206.51597316\n",
      "Iteration 16696, loss = 1206.43691605\n",
      "Iteration 16697, loss = 1206.35787105\n",
      "Iteration 16698, loss = 1206.27883816\n",
      "Iteration 16699, loss = 1206.19981737\n",
      "Iteration 16700, loss = 1206.12080868\n",
      "Iteration 16701, loss = 1206.04181208\n",
      "Iteration 16702, loss = 1205.96282757\n",
      "Iteration 16703, loss = 1205.88385513\n",
      "Iteration 16704, loss = 1205.80489477\n",
      "Iteration 16705, loss = 1205.72594647\n",
      "Iteration 16706, loss = 1205.64701022\n",
      "Iteration 16707, loss = 1205.56808603\n",
      "Iteration 16708, loss = 1205.48917388\n",
      "Iteration 16709, loss = 1205.41027376\n",
      "Iteration 16710, loss = 1205.33138568\n",
      "Iteration 16711, loss = 1205.25250962\n",
      "Iteration 16712, loss = 1205.17364558\n",
      "Iteration 16713, loss = 1205.09479354\n",
      "Iteration 16714, loss = 1205.01595351\n",
      "Iteration 16715, loss = 1204.93712547\n",
      "Iteration 16716, loss = 1204.85830942\n",
      "Iteration 16717, loss = 1204.77950535\n",
      "Iteration 16718, loss = 1204.70071326\n",
      "Iteration 16719, loss = 1204.62193313\n",
      "Iteration 16720, loss = 1204.54316496\n",
      "Iteration 16721, loss = 1204.46440874\n",
      "Iteration 16722, loss = 1204.38566447\n",
      "Iteration 16723, loss = 1204.30693213\n",
      "Iteration 16724, loss = 1204.22821173\n",
      "Iteration 16725, loss = 1204.14950325\n",
      "Iteration 16726, loss = 1204.07080668\n",
      "Iteration 16727, loss = 1203.99212202\n",
      "Iteration 16728, loss = 1203.91344926\n",
      "Iteration 16729, loss = 1203.83478839\n",
      "Iteration 16730, loss = 1203.75613941\n",
      "Iteration 16731, loss = 1203.67750230\n",
      "Iteration 16732, loss = 1203.59887707\n",
      "Iteration 16733, loss = 1203.52026369\n",
      "Iteration 16734, loss = 1203.44166217\n",
      "Iteration 16735, loss = 1203.36307250\n",
      "Iteration 16736, loss = 1203.28449466\n",
      "Iteration 16737, loss = 1203.20592865\n",
      "Iteration 16738, loss = 1203.12737447\n",
      "Iteration 16739, loss = 1203.04883210\n",
      "Iteration 16740, loss = 1202.97030153\n",
      "Iteration 16741, loss = 1202.89178276\n",
      "Iteration 16742, loss = 1202.81327579\n",
      "Iteration 16743, loss = 1202.73478059\n",
      "Iteration 16744, loss = 1202.65629716\n",
      "Iteration 16745, loss = 1202.57782551\n",
      "Iteration 16746, loss = 1202.49936560\n",
      "Iteration 16747, loss = 1202.42091745\n",
      "Iteration 16748, loss = 1202.34248103\n",
      "Iteration 16749, loss = 1202.26405635\n",
      "Iteration 16750, loss = 1202.18564338\n",
      "Iteration 16751, loss = 1202.10724213\n",
      "Iteration 16752, loss = 1202.02885259\n",
      "Iteration 16753, loss = 1201.95047474\n",
      "Iteration 16754, loss = 1201.87210857\n",
      "Iteration 16755, loss = 1201.79375409\n",
      "Iteration 16756, loss = 1201.71541127\n",
      "Iteration 16757, loss = 1201.63708011\n",
      "Iteration 16758, loss = 1201.55876061\n",
      "Iteration 16759, loss = 1201.48045275\n",
      "Iteration 16760, loss = 1201.40215651\n",
      "Iteration 16761, loss = 1201.32387191\n",
      "Iteration 16762, loss = 1201.24559891\n",
      "Iteration 16763, loss = 1201.16733752\n",
      "Iteration 16764, loss = 1201.08908773\n",
      "Iteration 16765, loss = 1201.01084952\n",
      "Iteration 16766, loss = 1200.93262288\n",
      "Iteration 16767, loss = 1200.85440782\n",
      "Iteration 16768, loss = 1200.77620430\n",
      "Iteration 16769, loss = 1200.69801234\n",
      "Iteration 16770, loss = 1200.61983191\n",
      "Iteration 16771, loss = 1200.54166301\n",
      "Iteration 16772, loss = 1200.46350562\n",
      "Iteration 16773, loss = 1200.38535974\n",
      "Iteration 16774, loss = 1200.30722535\n",
      "Iteration 16775, loss = 1200.22910246\n",
      "Iteration 16776, loss = 1200.15099103\n",
      "Iteration 16777, loss = 1200.07289107\n",
      "Iteration 16778, loss = 1199.99480257\n",
      "Iteration 16779, loss = 1199.91672551\n",
      "Iteration 16780, loss = 1199.83865988\n",
      "Iteration 16781, loss = 1199.76060567\n",
      "Iteration 16782, loss = 1199.68256288\n",
      "Iteration 16783, loss = 1199.60453149\n",
      "Iteration 16784, loss = 1199.52651148\n",
      "Iteration 16785, loss = 1199.44850285\n",
      "Iteration 16786, loss = 1199.37050559\n",
      "Iteration 16787, loss = 1199.29251969\n",
      "Iteration 16788, loss = 1199.21454513\n",
      "Iteration 16789, loss = 1199.13658190\n",
      "Iteration 16790, loss = 1199.05862999\n",
      "Iteration 16791, loss = 1198.98068939\n",
      "Iteration 16792, loss = 1198.90276009\n",
      "Iteration 16793, loss = 1198.82484208\n",
      "Iteration 16794, loss = 1198.74693533\n",
      "Iteration 16795, loss = 1198.66903985\n",
      "Iteration 16796, loss = 1198.59115562\n",
      "Iteration 16797, loss = 1198.51328262\n",
      "Iteration 16798, loss = 1198.43542085\n",
      "Iteration 16799, loss = 1198.35757029\n",
      "Iteration 16800, loss = 1198.27973093\n",
      "Iteration 16801, loss = 1198.20190275\n",
      "Iteration 16802, loss = 1198.12408575\n",
      "Iteration 16803, loss = 1198.04627991\n",
      "Iteration 16804, loss = 1197.96848521\n",
      "Iteration 16805, loss = 1197.89070165\n",
      "Iteration 16806, loss = 1197.81292921\n",
      "Iteration 16807, loss = 1197.73516787\n",
      "Iteration 16808, loss = 1197.65741763\n",
      "Iteration 16809, loss = 1197.57967846\n",
      "Iteration 16810, loss = 1197.50195037\n",
      "Iteration 16811, loss = 1197.42423332\n",
      "Iteration 16812, loss = 1197.34652731\n",
      "Iteration 16813, loss = 1197.26883232\n",
      "Iteration 16814, loss = 1197.19114834\n",
      "Iteration 16815, loss = 1197.11347535\n",
      "Iteration 16816, loss = 1197.03581334\n",
      "Iteration 16817, loss = 1196.95816230\n",
      "Iteration 16818, loss = 1196.88052220\n",
      "Iteration 16819, loss = 1196.80289304\n",
      "Iteration 16820, loss = 1196.72527480\n",
      "Iteration 16821, loss = 1196.64766746\n",
      "Iteration 16822, loss = 1196.57007100\n",
      "Iteration 16823, loss = 1196.49248542\n",
      "Iteration 16824, loss = 1196.41491069\n",
      "Iteration 16825, loss = 1196.33734679\n",
      "Iteration 16826, loss = 1196.25979373\n",
      "Iteration 16827, loss = 1196.18225146\n",
      "Iteration 16828, loss = 1196.10471999\n",
      "Iteration 16829, loss = 1196.02719929\n",
      "Iteration 16830, loss = 1195.94968934\n",
      "Iteration 16831, loss = 1195.87219013\n",
      "Iteration 16832, loss = 1195.79470164\n",
      "Iteration 16833, loss = 1195.71722385\n",
      "Iteration 16834, loss = 1195.63975675\n",
      "Iteration 16835, loss = 1195.56230031\n",
      "Iteration 16836, loss = 1195.48485453\n",
      "Iteration 16837, loss = 1195.40741937\n",
      "Iteration 16838, loss = 1195.32999482\n",
      "Iteration 16839, loss = 1195.25258087\n",
      "Iteration 16840, loss = 1195.17517749\n",
      "Iteration 16841, loss = 1195.09778466\n",
      "Iteration 16842, loss = 1195.02040237\n",
      "Iteration 16843, loss = 1194.94303059\n",
      "Iteration 16844, loss = 1194.86566930\n",
      "Iteration 16845, loss = 1194.78831849\n",
      "Iteration 16846, loss = 1194.71097813\n",
      "Iteration 16847, loss = 1194.63364821\n",
      "Iteration 16848, loss = 1194.55632870\n",
      "Iteration 16849, loss = 1194.47901958\n",
      "Iteration 16850, loss = 1194.40172082\n",
      "Iteration 16851, loss = 1194.32443242\n",
      "Iteration 16852, loss = 1194.24715434\n",
      "Iteration 16853, loss = 1194.16988656\n",
      "Iteration 16854, loss = 1194.09262906\n",
      "Iteration 16855, loss = 1194.01538182\n",
      "Iteration 16856, loss = 1193.93814482\n",
      "Iteration 16857, loss = 1193.86091802\n",
      "Iteration 16858, loss = 1193.78370141\n",
      "Iteration 16859, loss = 1193.70649496\n",
      "Iteration 16860, loss = 1193.62929866\n",
      "Iteration 16861, loss = 1193.55211246\n",
      "Iteration 16862, loss = 1193.47493635\n",
      "Iteration 16863, loss = 1193.39777031\n",
      "Iteration 16864, loss = 1193.32061431\n",
      "Iteration 16865, loss = 1193.24346831\n",
      "Iteration 16866, loss = 1193.16633230\n",
      "Iteration 16867, loss = 1193.08920625\n",
      "Iteration 16868, loss = 1193.01209013\n",
      "Iteration 16869, loss = 1192.93498391\n",
      "Iteration 16870, loss = 1192.85788757\n",
      "Iteration 16871, loss = 1192.78080107\n",
      "Iteration 16872, loss = 1192.70372439\n",
      "Iteration 16873, loss = 1192.62665750\n",
      "Iteration 16874, loss = 1192.54960038\n",
      "Iteration 16875, loss = 1192.47255298\n",
      "Iteration 16876, loss = 1192.39551528\n",
      "Iteration 16877, loss = 1192.31848725\n",
      "Iteration 16878, loss = 1192.24146886\n",
      "Iteration 16879, loss = 1192.16446007\n",
      "Iteration 16880, loss = 1192.08746086\n",
      "Iteration 16881, loss = 1192.01047118\n",
      "Iteration 16882, loss = 1191.93349102\n",
      "Iteration 16883, loss = 1191.85652033\n",
      "Iteration 16884, loss = 1191.77955908\n",
      "Iteration 16885, loss = 1191.70260724\n",
      "Iteration 16886, loss = 1191.62566476\n",
      "Iteration 16887, loss = 1191.54873162\n",
      "Iteration 16888, loss = 1191.47180778\n",
      "Iteration 16889, loss = 1191.39489320\n",
      "Iteration 16890, loss = 1191.31798785\n",
      "Iteration 16891, loss = 1191.24109168\n",
      "Iteration 16892, loss = 1191.16420466\n",
      "Iteration 16893, loss = 1191.08732675\n",
      "Iteration 16894, loss = 1191.01045791\n",
      "Iteration 16895, loss = 1190.93359809\n",
      "Iteration 16896, loss = 1190.85674726\n",
      "Iteration 16897, loss = 1190.77990538\n",
      "Iteration 16898, loss = 1190.70307241\n",
      "Iteration 16899, loss = 1190.62624829\n",
      "Iteration 16900, loss = 1190.54943299\n",
      "Iteration 16901, loss = 1190.47262646\n",
      "Iteration 16902, loss = 1190.39582866\n",
      "Iteration 16903, loss = 1190.31903953\n",
      "Iteration 16904, loss = 1190.24225905\n",
      "Iteration 16905, loss = 1190.16548714\n",
      "Iteration 16906, loss = 1190.08872378\n",
      "Iteration 16907, loss = 1190.01196890\n",
      "Iteration 16908, loss = 1189.93522247\n",
      "Iteration 16909, loss = 1189.85848442\n",
      "Iteration 16910, loss = 1189.78175470\n",
      "Iteration 16911, loss = 1189.70503327\n",
      "Iteration 16912, loss = 1189.62832007\n",
      "Iteration 16913, loss = 1189.55161504\n",
      "Iteration 16914, loss = 1189.47491813\n",
      "Iteration 16915, loss = 1189.39822928\n",
      "Iteration 16916, loss = 1189.32154844\n",
      "Iteration 16917, loss = 1189.24487554\n",
      "Iteration 16918, loss = 1189.16821052\n",
      "Iteration 16919, loss = 1189.09155334\n",
      "Iteration 16920, loss = 1189.01490391\n",
      "Iteration 16921, loss = 1188.93826219\n",
      "Iteration 16922, loss = 1188.86162809\n",
      "Iteration 16923, loss = 1188.78500157\n",
      "Iteration 16924, loss = 1188.70838255\n",
      "Iteration 16925, loss = 1188.63177097\n",
      "Iteration 16926, loss = 1188.55516675\n",
      "Iteration 16927, loss = 1188.47856982\n",
      "Iteration 16928, loss = 1188.40198012\n",
      "Iteration 16929, loss = 1188.32539756\n",
      "Iteration 16930, loss = 1188.24882208\n",
      "Iteration 16931, loss = 1188.17225359\n",
      "Iteration 16932, loss = 1188.09569202\n",
      "Iteration 16933, loss = 1188.01913729\n",
      "Iteration 16934, loss = 1187.94258932\n",
      "Iteration 16935, loss = 1187.86604802\n",
      "Iteration 16936, loss = 1187.78951331\n",
      "Iteration 16937, loss = 1187.71298510\n",
      "Iteration 16938, loss = 1187.63646331\n",
      "Iteration 16939, loss = 1187.55994784\n",
      "Iteration 16940, loss = 1187.48343861\n",
      "Iteration 16941, loss = 1187.40693551\n",
      "Iteration 16942, loss = 1187.33043845\n",
      "Iteration 16943, loss = 1187.25394734\n",
      "Iteration 16944, loss = 1187.17746207\n",
      "Iteration 16945, loss = 1187.10098255\n",
      "Iteration 16946, loss = 1187.02450866\n",
      "Iteration 16947, loss = 1186.94804030\n",
      "Iteration 16948, loss = 1186.87157736\n",
      "Iteration 16949, loss = 1186.79511973\n",
      "Iteration 16950, loss = 1186.71866730\n",
      "Iteration 16951, loss = 1186.64221994\n",
      "Iteration 16952, loss = 1186.56577754\n",
      "Iteration 16953, loss = 1186.48933998\n",
      "Iteration 16954, loss = 1186.41290712\n",
      "Iteration 16955, loss = 1186.33647885\n",
      "Iteration 16956, loss = 1186.26005503\n",
      "Iteration 16957, loss = 1186.18363553\n",
      "Iteration 16958, loss = 1186.10722021\n",
      "Iteration 16959, loss = 1186.03080892\n",
      "Iteration 16960, loss = 1185.95440153\n",
      "Iteration 16961, loss = 1185.87799789\n",
      "Iteration 16962, loss = 1185.80159784\n",
      "Iteration 16963, loss = 1185.72520123\n",
      "Iteration 16964, loss = 1185.64880791\n",
      "Iteration 16965, loss = 1185.57241770\n",
      "Iteration 16966, loss = 1185.49603045\n",
      "Iteration 16967, loss = 1185.41964597\n",
      "Iteration 16968, loss = 1185.34326411\n",
      "Iteration 16969, loss = 1185.26688466\n",
      "Iteration 16970, loss = 1185.19050746\n",
      "Iteration 16971, loss = 1185.11413231\n",
      "Iteration 16972, loss = 1185.03775901\n",
      "Iteration 16973, loss = 1184.96138737\n",
      "Iteration 16974, loss = 1184.88501718\n",
      "Iteration 16975, loss = 1184.80864823\n",
      "Iteration 16976, loss = 1184.73228031\n",
      "Iteration 16977, loss = 1184.65591319\n",
      "Iteration 16978, loss = 1184.57954665\n",
      "Iteration 16979, loss = 1184.50318044\n",
      "Iteration 16980, loss = 1184.42681434\n",
      "Iteration 16981, loss = 1184.35044809\n",
      "Iteration 16982, loss = 1184.27408145\n",
      "Iteration 16983, loss = 1184.19771415\n",
      "Iteration 16984, loss = 1184.12134596\n",
      "Iteration 16985, loss = 1184.04497660\n",
      "Iteration 16986, loss = 1183.96860585\n",
      "Iteration 16987, loss = 1183.89223346\n",
      "Iteration 16988, loss = 1183.81585927\n",
      "Iteration 16989, loss = 1183.73948314\n",
      "Iteration 16990, loss = 1183.66310516\n",
      "Iteration 16991, loss = 1183.58672549\n",
      "Iteration 16992, loss = 1183.51034485\n",
      "Iteration 16993, loss = 1183.43396424\n",
      "Iteration 16994, loss = 1183.35758568\n",
      "Iteration 16995, loss = 1183.28121099\n",
      "Iteration 16996, loss = 1183.20484201\n",
      "Iteration 16997, loss = 1183.12847461\n",
      "Iteration 16998, loss = 1183.05209714\n",
      "Iteration 16999, loss = 1182.97568401\n",
      "Iteration 17000, loss = 1182.89921815\n",
      "Iteration 17001, loss = 1182.82271041\n",
      "Iteration 17002, loss = 1182.74620789\n",
      "Iteration 17003, loss = 1182.66974764\n",
      "Iteration 17004, loss = 1182.59332296\n",
      "Iteration 17005, loss = 1182.51689295\n",
      "Iteration 17006, loss = 1182.44041891\n",
      "Iteration 17007, loss = 1182.36389900\n",
      "Iteration 17008, loss = 1182.28736567\n",
      "Iteration 17009, loss = 1182.21085080\n",
      "Iteration 17010, loss = 1182.13435105\n",
      "Iteration 17011, loss = 1182.05783626\n",
      "Iteration 17012, loss = 1181.98128450\n",
      "Iteration 17013, loss = 1181.90470220\n",
      "Iteration 17014, loss = 1181.82811349\n",
      "Iteration 17015, loss = 1181.75152914\n",
      "Iteration 17016, loss = 1181.67493638\n",
      "Iteration 17017, loss = 1181.59831641\n",
      "Iteration 17018, loss = 1181.52166496\n",
      "Iteration 17019, loss = 1181.44499448\n",
      "Iteration 17020, loss = 1181.36831536\n",
      "Iteration 17021, loss = 1181.29162365\n",
      "Iteration 17022, loss = 1181.21490717\n",
      "Iteration 17023, loss = 1181.13815950\n",
      "Iteration 17024, loss = 1181.06138577\n",
      "Iteration 17025, loss = 1180.98459284\n",
      "Iteration 17026, loss = 1180.90777998\n",
      "Iteration 17027, loss = 1180.83093971\n",
      "Iteration 17028, loss = 1180.75406622\n",
      "Iteration 17029, loss = 1180.67716078\n",
      "Iteration 17030, loss = 1180.60022701\n",
      "Iteration 17031, loss = 1180.52326482\n",
      "Iteration 17032, loss = 1180.44626948\n",
      "Iteration 17033, loss = 1180.36923614\n",
      "Iteration 17034, loss = 1180.29216411\n",
      "Iteration 17035, loss = 1180.21505459\n",
      "Iteration 17036, loss = 1180.13790716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17037, loss = 1180.06071838\n",
      "Iteration 17038, loss = 1179.98348413\n",
      "Iteration 17039, loss = 1179.90620259\n",
      "Iteration 17040, loss = 1179.82887321\n",
      "Iteration 17041, loss = 1179.75149488\n",
      "Iteration 17042, loss = 1179.67406452\n",
      "Iteration 17043, loss = 1179.59657830\n",
      "Iteration 17044, loss = 1179.51903360\n",
      "Iteration 17045, loss = 1179.44142852\n",
      "Iteration 17046, loss = 1179.36376102\n",
      "Iteration 17047, loss = 1179.28602782\n",
      "Iteration 17048, loss = 1179.20822494\n",
      "Iteration 17049, loss = 1179.13034892\n",
      "Iteration 17050, loss = 1179.05239667\n",
      "Iteration 17051, loss = 1178.97436505\n",
      "Iteration 17052, loss = 1178.89625011\n",
      "Iteration 17053, loss = 1178.81804724\n",
      "Iteration 17054, loss = 1178.73975200\n",
      "Iteration 17055, loss = 1178.66135996\n",
      "Iteration 17056, loss = 1178.58286667\n",
      "Iteration 17057, loss = 1178.50426702\n",
      "Iteration 17058, loss = 1178.42555529\n",
      "Iteration 17059, loss = 1178.34672570\n",
      "Iteration 17060, loss = 1178.26777217\n",
      "Iteration 17061, loss = 1178.18868853\n",
      "Iteration 17062, loss = 1178.10946797\n",
      "Iteration 17063, loss = 1178.03010307\n",
      "Iteration 17064, loss = 1177.95058608\n",
      "Iteration 17065, loss = 1177.87090878\n",
      "Iteration 17066, loss = 1177.79106264\n",
      "Iteration 17067, loss = 1177.71103841\n",
      "Iteration 17068, loss = 1177.63082614\n",
      "Iteration 17069, loss = 1177.55041531\n",
      "Iteration 17070, loss = 1177.46979464\n",
      "Iteration 17071, loss = 1177.38895234\n",
      "Iteration 17072, loss = 1177.30787565\n",
      "Iteration 17073, loss = 1177.22655093\n",
      "Iteration 17074, loss = 1177.14496365\n",
      "Iteration 17075, loss = 1177.06309821\n",
      "Iteration 17076, loss = 1176.98093810\n",
      "Iteration 17077, loss = 1176.89846556\n",
      "Iteration 17078, loss = 1176.81566157\n",
      "Iteration 17079, loss = 1176.73250581\n",
      "Iteration 17080, loss = 1176.64897643\n",
      "Iteration 17081, loss = 1176.56505018\n",
      "Iteration 17082, loss = 1176.48070206\n",
      "Iteration 17083, loss = 1176.39590529\n",
      "Iteration 17084, loss = 1176.31063118\n",
      "Iteration 17085, loss = 1176.22484890\n",
      "Iteration 17086, loss = 1176.13852555\n",
      "Iteration 17087, loss = 1176.05162578\n",
      "Iteration 17088, loss = 1175.96411169\n",
      "Iteration 17089, loss = 1175.87594274\n",
      "Iteration 17090, loss = 1175.78707539\n",
      "Iteration 17091, loss = 1175.69746317\n",
      "Iteration 17092, loss = 1175.60705622\n",
      "Iteration 17093, loss = 1175.51580131\n",
      "Iteration 17094, loss = 1175.42364152\n",
      "Iteration 17095, loss = 1175.33051603\n",
      "Iteration 17096, loss = 1175.23636012\n",
      "Iteration 17097, loss = 1175.14110472\n",
      "Iteration 17098, loss = 1175.04467646\n",
      "Iteration 17099, loss = 1174.94699744\n",
      "Iteration 17100, loss = 1174.84798506\n",
      "Iteration 17101, loss = 1174.74755210\n",
      "Iteration 17102, loss = 1174.64560648\n",
      "Iteration 17103, loss = 1174.54205141\n",
      "Iteration 17104, loss = 1174.43678543\n",
      "Iteration 17105, loss = 1174.32970248\n",
      "Iteration 17106, loss = 1174.22069229\n",
      "Iteration 17107, loss = 1174.10964053\n",
      "Iteration 17108, loss = 1173.99642933\n",
      "Iteration 17109, loss = 1173.88093785\n",
      "Iteration 17110, loss = 1173.76304284\n",
      "Iteration 17111, loss = 1173.64261957\n",
      "Iteration 17112, loss = 1173.51954261\n",
      "Iteration 17113, loss = 1173.39368697\n",
      "Iteration 17114, loss = 1173.26492925\n",
      "Iteration 17115, loss = 1173.13314884\n",
      "Iteration 17116, loss = 1172.99822942\n",
      "Iteration 17117, loss = 1172.86006020\n",
      "Iteration 17118, loss = 1172.71853753\n",
      "Iteration 17119, loss = 1172.57356629\n",
      "Iteration 17120, loss = 1172.42506131\n",
      "Iteration 17121, loss = 1172.27294878\n",
      "Iteration 17122, loss = 1172.11716742\n",
      "Iteration 17123, loss = 1171.95766964\n",
      "Iteration 17124, loss = 1171.79442244\n",
      "Iteration 17125, loss = 1171.62740810\n",
      "Iteration 17126, loss = 1171.45662471\n",
      "Iteration 17127, loss = 1171.28208636\n",
      "Iteration 17128, loss = 1171.10382318\n",
      "Iteration 17129, loss = 1170.92188105\n",
      "Iteration 17130, loss = 1170.73632114\n",
      "Iteration 17131, loss = 1170.54721922\n",
      "Iteration 17132, loss = 1170.35466473\n",
      "Iteration 17133, loss = 1170.15875977\n",
      "Iteration 17134, loss = 1169.95961788\n",
      "Iteration 17135, loss = 1169.75736276\n",
      "Iteration 17136, loss = 1169.55212693\n",
      "Iteration 17137, loss = 1169.34405032\n",
      "Iteration 17138, loss = 1169.13327888\n",
      "Iteration 17139, loss = 1168.91996321\n",
      "Iteration 17140, loss = 1168.70425724\n",
      "Iteration 17141, loss = 1168.48631696\n",
      "Iteration 17142, loss = 1168.26629920\n",
      "Iteration 17143, loss = 1168.04436059\n",
      "Iteration 17144, loss = 1167.82065652\n",
      "Iteration 17145, loss = 1167.59534029\n",
      "Iteration 17146, loss = 1167.36856228\n",
      "Iteration 17147, loss = 1167.14046930\n",
      "Iteration 17148, loss = 1166.91120399\n",
      "Iteration 17149, loss = 1166.68090436\n",
      "Iteration 17150, loss = 1166.44970338\n",
      "Iteration 17151, loss = 1166.21772870\n",
      "Iteration 17152, loss = 1165.98510240\n",
      "Iteration 17153, loss = 1165.75194085\n",
      "Iteration 17154, loss = 1165.51835463\n",
      "Iteration 17155, loss = 1165.28444848\n",
      "Iteration 17156, loss = 1165.05032131\n",
      "Iteration 17157, loss = 1164.81606628\n",
      "Iteration 17158, loss = 1164.58177088\n",
      "Iteration 17159, loss = 1164.34751706\n",
      "Iteration 17160, loss = 1164.11338137\n",
      "Iteration 17161, loss = 1163.87943514\n",
      "Iteration 17162, loss = 1163.64574465\n",
      "Iteration 17163, loss = 1163.41237135\n",
      "Iteration 17164, loss = 1163.17937204\n",
      "Iteration 17165, loss = 1162.94679908\n",
      "Iteration 17166, loss = 1162.71470063\n",
      "Iteration 17167, loss = 1162.48312083\n",
      "Iteration 17168, loss = 1162.25210003\n",
      "Iteration 17169, loss = 1162.02167500\n",
      "Iteration 17170, loss = 1161.79187912\n",
      "Iteration 17171, loss = 1161.56274259\n",
      "Iteration 17172, loss = 1161.33429262\n",
      "Iteration 17173, loss = 1161.10655362\n",
      "Iteration 17174, loss = 1160.87954740\n",
      "Iteration 17175, loss = 1160.65329328\n",
      "Iteration 17176, loss = 1160.42780832\n",
      "Iteration 17177, loss = 1160.20310745\n",
      "Iteration 17178, loss = 1159.97920363\n",
      "Iteration 17179, loss = 1159.75610796\n",
      "Iteration 17180, loss = 1159.53382986\n",
      "Iteration 17181, loss = 1159.31237717\n",
      "Iteration 17182, loss = 1159.09175627\n",
      "Iteration 17183, loss = 1158.87197218\n",
      "Iteration 17184, loss = 1158.65302872\n",
      "Iteration 17185, loss = 1158.43492854\n",
      "Iteration 17186, loss = 1158.21767325\n",
      "Iteration 17187, loss = 1158.00126350\n",
      "Iteration 17188, loss = 1157.78569908\n",
      "Iteration 17189, loss = 1157.57097895\n",
      "Iteration 17190, loss = 1157.35710135\n",
      "Iteration 17191, loss = 1157.14406386\n",
      "Iteration 17192, loss = 1156.93186346\n",
      "Iteration 17193, loss = 1156.72049656\n",
      "Iteration 17194, loss = 1156.50995909\n",
      "Iteration 17195, loss = 1156.30024654\n",
      "Iteration 17196, loss = 1156.09135399\n",
      "Iteration 17197, loss = 1155.88327617\n",
      "Iteration 17198, loss = 1155.67600748\n",
      "Iteration 17199, loss = 1155.46954204\n",
      "Iteration 17200, loss = 1155.26387373\n",
      "Iteration 17201, loss = 1155.05899621\n",
      "Iteration 17202, loss = 1154.85490293\n",
      "Iteration 17203, loss = 1154.65158719\n",
      "Iteration 17204, loss = 1154.44904215\n",
      "Iteration 17205, loss = 1154.24726085\n",
      "Iteration 17206, loss = 1154.04623622\n",
      "Iteration 17207, loss = 1153.84596113\n",
      "Iteration 17208, loss = 1153.64642838\n",
      "Iteration 17209, loss = 1153.44763069\n",
      "Iteration 17210, loss = 1153.24956080\n",
      "Iteration 17211, loss = 1153.05221139\n",
      "Iteration 17212, loss = 1152.85557513\n",
      "Iteration 17213, loss = 1152.65964473\n",
      "Iteration 17214, loss = 1152.46441286\n",
      "Iteration 17215, loss = 1152.26987224\n",
      "Iteration 17216, loss = 1152.07601562\n",
      "Iteration 17217, loss = 1151.88283576\n",
      "Iteration 17218, loss = 1151.69032549\n",
      "Iteration 17219, loss = 1151.49847767\n",
      "Iteration 17220, loss = 1151.30728521\n",
      "Iteration 17221, loss = 1151.11674108\n",
      "Iteration 17222, loss = 1150.92683832\n",
      "Iteration 17223, loss = 1150.73757002\n",
      "Iteration 17224, loss = 1150.54892934\n",
      "Iteration 17225, loss = 1150.36090953\n",
      "Iteration 17226, loss = 1150.17350387\n",
      "Iteration 17227, loss = 1149.98670576\n",
      "Iteration 17228, loss = 1149.80050865\n",
      "Iteration 17229, loss = 1149.61490607\n",
      "Iteration 17230, loss = 1149.42989164\n",
      "Iteration 17231, loss = 1149.24545904\n",
      "Iteration 17232, loss = 1149.06160204\n",
      "Iteration 17233, loss = 1148.87831451\n",
      "Iteration 17234, loss = 1148.69559037\n",
      "Iteration 17235, loss = 1148.51342364\n",
      "Iteration 17236, loss = 1148.33180842\n",
      "Iteration 17237, loss = 1148.15073888\n",
      "Iteration 17238, loss = 1147.97020928\n",
      "Iteration 17239, loss = 1147.79021397\n",
      "Iteration 17240, loss = 1147.61074737\n",
      "Iteration 17241, loss = 1147.43180397\n",
      "Iteration 17242, loss = 1147.25337836\n",
      "Iteration 17243, loss = 1147.07546519\n",
      "Iteration 17244, loss = 1146.89805921\n",
      "Iteration 17245, loss = 1146.72115523\n",
      "Iteration 17246, loss = 1146.54474814\n",
      "Iteration 17247, loss = 1146.36883291\n",
      "Iteration 17248, loss = 1146.19340457\n",
      "Iteration 17249, loss = 1146.01845825\n",
      "Iteration 17250, loss = 1145.84398914\n",
      "Iteration 17251, loss = 1145.66999249\n",
      "Iteration 17252, loss = 1145.49646363\n",
      "Iteration 17253, loss = 1145.32339798\n",
      "Iteration 17254, loss = 1145.15079099\n",
      "Iteration 17255, loss = 1144.97863822\n",
      "Iteration 17256, loss = 1144.80693526\n",
      "Iteration 17257, loss = 1144.63567779\n",
      "Iteration 17258, loss = 1144.46486154\n",
      "Iteration 17259, loss = 1144.29448232\n",
      "Iteration 17260, loss = 1144.12453598\n",
      "Iteration 17261, loss = 1143.95501847\n",
      "Iteration 17262, loss = 1143.78592575\n",
      "Iteration 17263, loss = 1143.61725389\n",
      "Iteration 17264, loss = 1143.44899898\n",
      "Iteration 17265, loss = 1143.28115719\n",
      "Iteration 17266, loss = 1143.11372473\n",
      "Iteration 17267, loss = 1142.94669790\n",
      "Iteration 17268, loss = 1142.78007300\n",
      "Iteration 17269, loss = 1142.61384644\n",
      "Iteration 17270, loss = 1142.44801465\n",
      "Iteration 17271, loss = 1142.28257412\n",
      "Iteration 17272, loss = 1142.11752139\n",
      "Iteration 17273, loss = 1141.95285305\n",
      "Iteration 17274, loss = 1141.78856575\n",
      "Iteration 17275, loss = 1141.62465618\n",
      "Iteration 17276, loss = 1141.46112106\n",
      "Iteration 17277, loss = 1141.29795719\n",
      "Iteration 17278, loss = 1141.13516140\n",
      "Iteration 17279, loss = 1140.97273056\n",
      "Iteration 17280, loss = 1140.81066160\n",
      "Iteration 17281, loss = 1140.64895146\n",
      "Iteration 17282, loss = 1140.48759717\n",
      "Iteration 17283, loss = 1140.32659578\n",
      "Iteration 17284, loss = 1140.16594436\n",
      "Iteration 17285, loss = 1140.00564004\n",
      "Iteration 17286, loss = 1139.84568001\n",
      "Iteration 17287, loss = 1139.68606147\n",
      "Iteration 17288, loss = 1139.52678166\n",
      "Iteration 17289, loss = 1139.36783787\n",
      "Iteration 17290, loss = 1139.20922743\n",
      "Iteration 17291, loss = 1139.05094768\n",
      "Iteration 17292, loss = 1138.89299603\n",
      "Iteration 17293, loss = 1138.73536990\n",
      "Iteration 17294, loss = 1138.57806676\n",
      "Iteration 17295, loss = 1138.42108410\n",
      "Iteration 17296, loss = 1138.26441946\n",
      "Iteration 17297, loss = 1138.10807039\n",
      "Iteration 17298, loss = 1137.95203450\n",
      "Iteration 17299, loss = 1137.79630941\n",
      "Iteration 17300, loss = 1137.64089278\n",
      "Iteration 17301, loss = 1137.48578229\n",
      "Iteration 17302, loss = 1137.33097567\n",
      "Iteration 17303, loss = 1137.17647066\n",
      "Iteration 17304, loss = 1137.02226504\n",
      "Iteration 17305, loss = 1136.86835661\n",
      "Iteration 17306, loss = 1136.71474321\n",
      "Iteration 17307, loss = 1136.56142270\n",
      "Iteration 17308, loss = 1136.40839296\n",
      "Iteration 17309, loss = 1136.25565190\n",
      "Iteration 17310, loss = 1136.10319747\n",
      "Iteration 17311, loss = 1135.95102763\n",
      "Iteration 17312, loss = 1135.79914037\n",
      "Iteration 17313, loss = 1135.64753371\n",
      "Iteration 17314, loss = 1135.49620569\n",
      "Iteration 17315, loss = 1135.34515436\n",
      "Iteration 17316, loss = 1135.19437782\n",
      "Iteration 17317, loss = 1135.04387417\n",
      "Iteration 17318, loss = 1134.89364155\n",
      "Iteration 17319, loss = 1134.74367811\n",
      "Iteration 17320, loss = 1134.59398204\n",
      "Iteration 17321, loss = 1134.44455151\n",
      "Iteration 17322, loss = 1134.29538477\n",
      "Iteration 17323, loss = 1134.14648004\n",
      "Iteration 17324, loss = 1133.99783559\n",
      "Iteration 17325, loss = 1133.84944970\n",
      "Iteration 17326, loss = 1133.70132067\n",
      "Iteration 17327, loss = 1133.55344682\n",
      "Iteration 17328, loss = 1133.40582650\n",
      "Iteration 17329, loss = 1133.25845805\n",
      "Iteration 17330, loss = 1133.11133987\n",
      "Iteration 17331, loss = 1132.96447034\n",
      "Iteration 17332, loss = 1132.81784788\n",
      "Iteration 17333, loss = 1132.67147092\n",
      "Iteration 17334, loss = 1132.52533791\n",
      "Iteration 17335, loss = 1132.37944732\n",
      "Iteration 17336, loss = 1132.23379763\n",
      "Iteration 17337, loss = 1132.08838734\n",
      "Iteration 17338, loss = 1131.94321497\n",
      "Iteration 17339, loss = 1131.79827906\n",
      "Iteration 17340, loss = 1131.65357814\n",
      "Iteration 17341, loss = 1131.50911079\n",
      "Iteration 17342, loss = 1131.36487559\n",
      "Iteration 17343, loss = 1131.22087113\n",
      "Iteration 17344, loss = 1131.07709602\n",
      "Iteration 17345, loss = 1130.93354889\n",
      "Iteration 17346, loss = 1130.79022838\n",
      "Iteration 17347, loss = 1130.64713314\n",
      "Iteration 17348, loss = 1130.50426184\n",
      "Iteration 17349, loss = 1130.36161316\n",
      "Iteration 17350, loss = 1130.21918580\n",
      "Iteration 17351, loss = 1130.07697847\n",
      "Iteration 17352, loss = 1129.93498989\n",
      "Iteration 17353, loss = 1129.79321879\n",
      "Iteration 17354, loss = 1129.65166394\n",
      "Iteration 17355, loss = 1129.51032408\n",
      "Iteration 17356, loss = 1129.36919799\n",
      "Iteration 17357, loss = 1129.22828446\n",
      "Iteration 17358, loss = 1129.08758229\n",
      "Iteration 17359, loss = 1128.94709029\n",
      "Iteration 17360, loss = 1128.80680728\n",
      "Iteration 17361, loss = 1128.66673209\n",
      "Iteration 17362, loss = 1128.52686357\n",
      "Iteration 17363, loss = 1128.38720059\n",
      "Iteration 17364, loss = 1128.24774200\n",
      "Iteration 17365, loss = 1128.10848668\n",
      "Iteration 17366, loss = 1127.96943354\n",
      "Iteration 17367, loss = 1127.83058146\n",
      "Iteration 17368, loss = 1127.69192936\n",
      "Iteration 17369, loss = 1127.55347617\n",
      "Iteration 17370, loss = 1127.41522081\n",
      "Iteration 17371, loss = 1127.27716222\n",
      "Iteration 17372, loss = 1127.13929937\n",
      "Iteration 17373, loss = 1127.00163122\n",
      "Iteration 17374, loss = 1126.86415672\n",
      "Iteration 17375, loss = 1126.72687488\n",
      "Iteration 17376, loss = 1126.58978467\n",
      "Iteration 17377, loss = 1126.45288511\n",
      "Iteration 17378, loss = 1126.31617520\n",
      "Iteration 17379, loss = 1126.17965395\n",
      "Iteration 17380, loss = 1126.04332041\n",
      "Iteration 17381, loss = 1125.90717360\n",
      "Iteration 17382, loss = 1125.77121258\n",
      "Iteration 17383, loss = 1125.63543639\n",
      "Iteration 17384, loss = 1125.49984410\n",
      "Iteration 17385, loss = 1125.36443478\n",
      "Iteration 17386, loss = 1125.22920751\n",
      "Iteration 17387, loss = 1125.09416139\n",
      "Iteration 17388, loss = 1124.95929550\n",
      "Iteration 17389, loss = 1124.82460895\n",
      "Iteration 17390, loss = 1124.69010086\n",
      "Iteration 17391, loss = 1124.55577034\n",
      "Iteration 17392, loss = 1124.42161652\n",
      "Iteration 17393, loss = 1124.28763854\n",
      "Iteration 17394, loss = 1124.15383553\n",
      "Iteration 17395, loss = 1124.02020666\n",
      "Iteration 17396, loss = 1123.88675108\n",
      "Iteration 17397, loss = 1123.75346795\n",
      "Iteration 17398, loss = 1123.62035645\n",
      "Iteration 17399, loss = 1123.48741576\n",
      "Iteration 17400, loss = 1123.35464506\n",
      "Iteration 17401, loss = 1123.22204356\n",
      "Iteration 17402, loss = 1123.08961045\n",
      "Iteration 17403, loss = 1122.95734495\n",
      "Iteration 17404, loss = 1122.82524631\n",
      "Iteration 17405, loss = 1122.69331378\n",
      "Iteration 17406, loss = 1122.56154665\n",
      "Iteration 17407, loss = 1122.42994431\n",
      "Iteration 17408, loss = 1122.29850625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17409, loss = 1122.16723223\n",
      "Iteration 17410, loss = 1122.03612237\n",
      "Iteration 17411, loss = 1121.90517761\n",
      "Iteration 17412, loss = 1121.77439980\n",
      "Iteration 17413, loss = 1121.64379219\n",
      "Iteration 17414, loss = 1121.51335647\n",
      "Iteration 17415, loss = 1121.38308894\n",
      "Iteration 17416, loss = 1121.25296537\n",
      "Iteration 17417, loss = 1121.12295276\n",
      "Iteration 17418, loss = 1120.99304006\n",
      "Iteration 17419, loss = 1120.86328210\n",
      "Iteration 17420, loss = 1120.73373906\n",
      "Iteration 17421, loss = 1120.60440437\n",
      "Iteration 17422, loss = 1120.47521582\n",
      "Iteration 17423, loss = 1120.34612725\n",
      "Iteration 17424, loss = 1120.21716280\n",
      "Iteration 17425, loss = 1120.08837965\n",
      "Iteration 17426, loss = 1119.95978870\n",
      "Iteration 17427, loss = 1119.83134562\n",
      "Iteration 17428, loss = 1119.70301683\n",
      "Iteration 17429, loss = 1119.57482320\n",
      "Iteration 17430, loss = 1119.44680165\n",
      "Iteration 17431, loss = 1119.31894972\n",
      "Iteration 17432, loss = 1119.19123477\n",
      "Iteration 17433, loss = 1119.06364453\n",
      "Iteration 17434, loss = 1118.93620078\n",
      "Iteration 17435, loss = 1118.80892062\n",
      "Iteration 17436, loss = 1118.68179142\n",
      "Iteration 17437, loss = 1118.55479387\n",
      "Iteration 17438, loss = 1118.42793051\n",
      "Iteration 17439, loss = 1118.30121733\n",
      "Iteration 17440, loss = 1118.17465656\n",
      "Iteration 17441, loss = 1118.04823506\n",
      "Iteration 17442, loss = 1117.92194583\n",
      "Iteration 17443, loss = 1117.79579637\n",
      "Iteration 17444, loss = 1117.66979398\n",
      "Iteration 17445, loss = 1117.54393401\n",
      "Iteration 17446, loss = 1117.41820820\n",
      "Iteration 17447, loss = 1117.29261683\n",
      "Iteration 17448, loss = 1117.16716581\n",
      "Iteration 17449, loss = 1117.04185602\n",
      "Iteration 17450, loss = 1116.91668212\n",
      "Iteration 17451, loss = 1116.79164082\n",
      "Iteration 17452, loss = 1116.66673459\n",
      "Iteration 17453, loss = 1116.54196607\n",
      "Iteration 17454, loss = 1116.41733334\n",
      "Iteration 17455, loss = 1116.29283285\n",
      "Iteration 17456, loss = 1116.16846416\n",
      "Iteration 17457, loss = 1116.04422923\n",
      "Iteration 17458, loss = 1115.92012830\n",
      "Iteration 17459, loss = 1115.79615911\n",
      "Iteration 17460, loss = 1115.67231995\n",
      "Iteration 17461, loss = 1115.54861125\n",
      "Iteration 17462, loss = 1115.42503386\n",
      "Iteration 17463, loss = 1115.30158695\n",
      "Iteration 17464, loss = 1115.17826885\n",
      "Iteration 17465, loss = 1115.05507887\n",
      "Iteration 17466, loss = 1114.93201742\n",
      "Iteration 17467, loss = 1114.80908447\n",
      "Iteration 17468, loss = 1114.68627901\n",
      "Iteration 17469, loss = 1114.56359997\n",
      "Iteration 17470, loss = 1114.44104708\n",
      "Iteration 17471, loss = 1114.31862041\n",
      "Iteration 17472, loss = 1114.19631954\n",
      "Iteration 17473, loss = 1114.07414358\n",
      "Iteration 17474, loss = 1113.95209184\n",
      "Iteration 17475, loss = 1113.83016413\n",
      "Iteration 17476, loss = 1113.70836027\n",
      "Iteration 17477, loss = 1113.58667968\n",
      "Iteration 17478, loss = 1113.46512168\n",
      "Iteration 17479, loss = 1113.34368576\n",
      "Iteration 17480, loss = 1113.22237168\n",
      "Iteration 17481, loss = 1113.10117910\n",
      "Iteration 17482, loss = 1112.98010748\n",
      "Iteration 17483, loss = 1112.85915623\n",
      "Iteration 17484, loss = 1112.73832495\n",
      "Iteration 17485, loss = 1112.61761333\n",
      "Iteration 17486, loss = 1112.49702096\n",
      "Iteration 17487, loss = 1112.37654734\n",
      "Iteration 17488, loss = 1112.25619198\n",
      "Iteration 17489, loss = 1112.13595450\n",
      "Iteration 17490, loss = 1112.01583453\n",
      "Iteration 17491, loss = 1111.89583168\n",
      "Iteration 17492, loss = 1111.77594546\n",
      "Iteration 17493, loss = 1111.65617544\n",
      "Iteration 17494, loss = 1111.53652125\n",
      "Iteration 17495, loss = 1111.41698250\n",
      "Iteration 17496, loss = 1111.29755880\n",
      "Iteration 17497, loss = 1111.17824971\n",
      "Iteration 17498, loss = 1111.05905481\n",
      "Iteration 17499, loss = 1110.93997373\n",
      "Iteration 17500, loss = 1110.82100610\n",
      "Iteration 17501, loss = 1110.70215152\n",
      "Iteration 17502, loss = 1110.58340958\n",
      "Iteration 17503, loss = 1110.46477988\n",
      "Iteration 17504, loss = 1110.34626207\n",
      "Iteration 17505, loss = 1110.22785576\n",
      "Iteration 17506, loss = 1110.10956057\n",
      "Iteration 17507, loss = 1109.99137612\n",
      "Iteration 17508, loss = 1109.87330202\n",
      "Iteration 17509, loss = 1109.75533792\n",
      "Iteration 17510, loss = 1109.63748344\n",
      "Iteration 17511, loss = 1109.51973821\n",
      "Iteration 17512, loss = 1109.40210187\n",
      "Iteration 17513, loss = 1109.28457405\n",
      "Iteration 17514, loss = 1109.16715439\n",
      "Iteration 17515, loss = 1109.04984253\n",
      "Iteration 17516, loss = 1108.93263812\n",
      "Iteration 17517, loss = 1108.81554079\n",
      "Iteration 17518, loss = 1108.69855020\n",
      "Iteration 17519, loss = 1108.58166599\n",
      "Iteration 17520, loss = 1108.46488782\n",
      "Iteration 17521, loss = 1108.34821533\n",
      "Iteration 17522, loss = 1108.23164819\n",
      "Iteration 17523, loss = 1108.11518605\n",
      "Iteration 17524, loss = 1107.99882856\n",
      "Iteration 17525, loss = 1107.88257540\n",
      "Iteration 17526, loss = 1107.76642622\n",
      "Iteration 17527, loss = 1107.65038069\n",
      "Iteration 17528, loss = 1107.53443847\n",
      "Iteration 17529, loss = 1107.41859924\n",
      "Iteration 17530, loss = 1107.30286266\n",
      "Iteration 17531, loss = 1107.18722841\n",
      "Iteration 17532, loss = 1107.07169616\n",
      "Iteration 17533, loss = 1106.95626558\n",
      "Iteration 17534, loss = 1106.84093636\n",
      "Iteration 17535, loss = 1106.72570818\n",
      "Iteration 17536, loss = 1106.61058072\n",
      "Iteration 17537, loss = 1106.49555366\n",
      "Iteration 17538, loss = 1106.38062668\n",
      "Iteration 17539, loss = 1106.26579948\n",
      "Iteration 17540, loss = 1106.15107174\n",
      "Iteration 17541, loss = 1106.03644315\n",
      "Iteration 17542, loss = 1105.92191341\n",
      "Iteration 17543, loss = 1105.80748221\n",
      "Iteration 17544, loss = 1105.69314924\n",
      "Iteration 17545, loss = 1105.57891420\n",
      "Iteration 17546, loss = 1105.46477680\n",
      "Iteration 17547, loss = 1105.35073673\n",
      "Iteration 17548, loss = 1105.23679370\n",
      "Iteration 17549, loss = 1105.12294740\n",
      "Iteration 17550, loss = 1105.00919755\n",
      "Iteration 17551, loss = 1104.89554385\n",
      "Iteration 17552, loss = 1104.78198601\n",
      "Iteration 17553, loss = 1104.66852374\n",
      "Iteration 17554, loss = 1104.55515675\n",
      "Iteration 17555, loss = 1104.44188476\n",
      "Iteration 17556, loss = 1104.32870748\n",
      "Iteration 17557, loss = 1104.21562463\n",
      "Iteration 17558, loss = 1104.10263593\n",
      "Iteration 17559, loss = 1103.98974109\n",
      "Iteration 17560, loss = 1103.87693984\n",
      "Iteration 17561, loss = 1103.76423190\n",
      "Iteration 17562, loss = 1103.65161699\n",
      "Iteration 17563, loss = 1103.53909484\n",
      "Iteration 17564, loss = 1103.42666518\n",
      "Iteration 17565, loss = 1103.31432773\n",
      "Iteration 17566, loss = 1103.20208223\n",
      "Iteration 17567, loss = 1103.08992840\n",
      "Iteration 17568, loss = 1102.97786599\n",
      "Iteration 17569, loss = 1102.86589471\n",
      "Iteration 17570, loss = 1102.75401431\n",
      "Iteration 17571, loss = 1102.64222453\n",
      "Iteration 17572, loss = 1102.53052510\n",
      "Iteration 17573, loss = 1102.41891577\n",
      "Iteration 17574, loss = 1102.30739627\n",
      "Iteration 17575, loss = 1102.19596634\n",
      "Iteration 17576, loss = 1102.08462573\n",
      "Iteration 17577, loss = 1101.97337419\n",
      "Iteration 17578, loss = 1101.86221146\n",
      "Iteration 17579, loss = 1101.75113729\n",
      "Iteration 17580, loss = 1101.64015142\n",
      "Iteration 17581, loss = 1101.52925362\n",
      "Iteration 17582, loss = 1101.41844362\n",
      "Iteration 17583, loss = 1101.30772118\n",
      "Iteration 17584, loss = 1101.19708606\n",
      "Iteration 17585, loss = 1101.08653800\n",
      "Iteration 17586, loss = 1100.97607678\n",
      "Iteration 17587, loss = 1100.86570214\n",
      "Iteration 17588, loss = 1100.75541384\n",
      "Iteration 17589, loss = 1100.64521164\n",
      "Iteration 17590, loss = 1100.53509531\n",
      "Iteration 17591, loss = 1100.42506460\n",
      "Iteration 17592, loss = 1100.31511929\n",
      "Iteration 17593, loss = 1100.20525913\n",
      "Iteration 17594, loss = 1100.09548389\n",
      "Iteration 17595, loss = 1099.98579334\n",
      "Iteration 17596, loss = 1099.87618724\n",
      "Iteration 17597, loss = 1099.76666537\n",
      "Iteration 17598, loss = 1099.65722749\n",
      "Iteration 17599, loss = 1099.54787338\n",
      "Iteration 17600, loss = 1099.43860282\n",
      "Iteration 17601, loss = 1099.32941556\n",
      "Iteration 17602, loss = 1099.22031140\n",
      "Iteration 17603, loss = 1099.11129010\n",
      "Iteration 17604, loss = 1099.00235144\n",
      "Iteration 17605, loss = 1098.89349520\n",
      "Iteration 17606, loss = 1098.78472116\n",
      "Iteration 17607, loss = 1098.67602910\n",
      "Iteration 17608, loss = 1098.56741880\n",
      "Iteration 17609, loss = 1098.45889005\n",
      "Iteration 17610, loss = 1098.35044262\n",
      "Iteration 17611, loss = 1098.24207630\n",
      "Iteration 17612, loss = 1098.13379088\n",
      "Iteration 17613, loss = 1098.02558614\n",
      "Iteration 17614, loss = 1097.91746188\n",
      "Iteration 17615, loss = 1097.80941787\n",
      "Iteration 17616, loss = 1097.70145391\n",
      "Iteration 17617, loss = 1097.59356980\n",
      "Iteration 17618, loss = 1097.48576531\n",
      "Iteration 17619, loss = 1097.37804025\n",
      "Iteration 17620, loss = 1097.27039440\n",
      "Iteration 17621, loss = 1097.16282757\n",
      "Iteration 17622, loss = 1097.05533954\n",
      "Iteration 17623, loss = 1096.94793012\n",
      "Iteration 17624, loss = 1096.84059909\n",
      "Iteration 17625, loss = 1096.73334627\n",
      "Iteration 17626, loss = 1096.62617145\n",
      "Iteration 17627, loss = 1096.51907442\n",
      "Iteration 17628, loss = 1096.41205499\n",
      "Iteration 17629, loss = 1096.30511296\n",
      "Iteration 17630, loss = 1096.19824814\n",
      "Iteration 17631, loss = 1096.09146032\n",
      "Iteration 17632, loss = 1095.98474932\n",
      "Iteration 17633, loss = 1095.87811494\n",
      "Iteration 17634, loss = 1095.77155698\n",
      "Iteration 17635, loss = 1095.66507525\n",
      "Iteration 17636, loss = 1095.55866956\n",
      "Iteration 17637, loss = 1095.45233972\n",
      "Iteration 17638, loss = 1095.34608554\n",
      "Iteration 17639, loss = 1095.23990684\n",
      "Iteration 17640, loss = 1095.13380341\n",
      "Iteration 17641, loss = 1095.02777507\n",
      "Iteration 17642, loss = 1094.92182165\n",
      "Iteration 17643, loss = 1094.81594294\n",
      "Iteration 17644, loss = 1094.71013877\n",
      "Iteration 17645, loss = 1094.60440896\n",
      "Iteration 17646, loss = 1094.49875331\n",
      "Iteration 17647, loss = 1094.39317165\n",
      "Iteration 17648, loss = 1094.28766379\n",
      "Iteration 17649, loss = 1094.18222956\n",
      "Iteration 17650, loss = 1094.07686878\n",
      "Iteration 17651, loss = 1093.97158125\n",
      "Iteration 17652, loss = 1093.86636681\n",
      "Iteration 17653, loss = 1093.76122528\n",
      "Iteration 17654, loss = 1093.65615649\n",
      "Iteration 17655, loss = 1093.55116024\n",
      "Iteration 17656, loss = 1093.44623638\n",
      "Iteration 17657, loss = 1093.34138472\n",
      "Iteration 17658, loss = 1093.23660509\n",
      "Iteration 17659, loss = 1093.13189732\n",
      "Iteration 17660, loss = 1093.02726124\n",
      "Iteration 17661, loss = 1092.92269667\n",
      "Iteration 17662, loss = 1092.81820344\n",
      "Iteration 17663, loss = 1092.71378138\n",
      "Iteration 17664, loss = 1092.60943033\n",
      "Iteration 17665, loss = 1092.50515011\n",
      "Iteration 17666, loss = 1092.40094056\n",
      "Iteration 17667, loss = 1092.29680151\n",
      "Iteration 17668, loss = 1092.19273279\n",
      "Iteration 17669, loss = 1092.08873424\n",
      "Iteration 17670, loss = 1091.98480569\n",
      "Iteration 17671, loss = 1091.88094698\n",
      "Iteration 17672, loss = 1091.77715794\n",
      "Iteration 17673, loss = 1091.67343841\n",
      "Iteration 17674, loss = 1091.56978823\n",
      "Iteration 17675, loss = 1091.46620724\n",
      "Iteration 17676, loss = 1091.36269527\n",
      "Iteration 17677, loss = 1091.25925217\n",
      "Iteration 17678, loss = 1091.15587778\n",
      "Iteration 17679, loss = 1091.05257193\n",
      "Iteration 17680, loss = 1090.94933447\n",
      "Iteration 17681, loss = 1090.84616524\n",
      "Iteration 17682, loss = 1090.74306408\n",
      "Iteration 17683, loss = 1090.64003084\n",
      "Iteration 17684, loss = 1090.53706536\n",
      "Iteration 17685, loss = 1090.43416749\n",
      "Iteration 17686, loss = 1090.33133708\n",
      "Iteration 17687, loss = 1090.22857396\n",
      "Iteration 17688, loss = 1090.12587798\n",
      "Iteration 17689, loss = 1090.02324900\n",
      "Iteration 17690, loss = 1089.92068687\n",
      "Iteration 17691, loss = 1089.81819142\n",
      "Iteration 17692, loss = 1089.71576251\n",
      "Iteration 17693, loss = 1089.61339999\n",
      "Iteration 17694, loss = 1089.51110371\n",
      "Iteration 17695, loss = 1089.40887352\n",
      "Iteration 17696, loss = 1089.30670927\n",
      "Iteration 17697, loss = 1089.20461082\n",
      "Iteration 17698, loss = 1089.10257802\n",
      "Iteration 17699, loss = 1089.00061072\n",
      "Iteration 17700, loss = 1088.89870877\n",
      "Iteration 17701, loss = 1088.79687204\n",
      "Iteration 17702, loss = 1088.69510037\n",
      "Iteration 17703, loss = 1088.59339363\n",
      "Iteration 17704, loss = 1088.49175166\n",
      "Iteration 17705, loss = 1088.39017433\n",
      "Iteration 17706, loss = 1088.28866150\n",
      "Iteration 17707, loss = 1088.18721302\n",
      "Iteration 17708, loss = 1088.08582874\n",
      "Iteration 17709, loss = 1087.98450854\n",
      "Iteration 17710, loss = 1087.88325227\n",
      "Iteration 17711, loss = 1087.78205979\n",
      "Iteration 17712, loss = 1087.68093096\n",
      "Iteration 17713, loss = 1087.57986564\n",
      "Iteration 17714, loss = 1087.47886370\n",
      "Iteration 17715, loss = 1087.37792499\n",
      "Iteration 17716, loss = 1087.27704939\n",
      "Iteration 17717, loss = 1087.17623675\n",
      "Iteration 17718, loss = 1087.07548695\n",
      "Iteration 17719, loss = 1086.97479983\n",
      "Iteration 17720, loss = 1086.87417528\n",
      "Iteration 17721, loss = 1086.77361315\n",
      "Iteration 17722, loss = 1086.67311331\n",
      "Iteration 17723, loss = 1086.57267563\n",
      "Iteration 17724, loss = 1086.47229998\n",
      "Iteration 17725, loss = 1086.37198622\n",
      "Iteration 17726, loss = 1086.27173422\n",
      "Iteration 17727, loss = 1086.17154386\n",
      "Iteration 17728, loss = 1086.07141499\n",
      "Iteration 17729, loss = 1085.97134750\n",
      "Iteration 17730, loss = 1085.87134125\n",
      "Iteration 17731, loss = 1085.77139611\n",
      "Iteration 17732, loss = 1085.67151195\n",
      "Iteration 17733, loss = 1085.57168865\n",
      "Iteration 17734, loss = 1085.47192608\n",
      "Iteration 17735, loss = 1085.37222411\n",
      "Iteration 17736, loss = 1085.27258261\n",
      "Iteration 17737, loss = 1085.17300146\n",
      "Iteration 17738, loss = 1085.07348053\n",
      "Iteration 17739, loss = 1084.97401971\n",
      "Iteration 17740, loss = 1084.87461885\n",
      "Iteration 17741, loss = 1084.77527784\n",
      "Iteration 17742, loss = 1084.67599656\n",
      "Iteration 17743, loss = 1084.57677488\n",
      "Iteration 17744, loss = 1084.47761267\n",
      "Iteration 17745, loss = 1084.37850983\n",
      "Iteration 17746, loss = 1084.27946622\n",
      "Iteration 17747, loss = 1084.18048172\n",
      "Iteration 17748, loss = 1084.08155621\n",
      "Iteration 17749, loss = 1083.98268957\n",
      "Iteration 17750, loss = 1083.88388169\n",
      "Iteration 17751, loss = 1083.78513244\n",
      "Iteration 17752, loss = 1083.68644170\n",
      "Iteration 17753, loss = 1083.58780935\n",
      "Iteration 17754, loss = 1083.48923528\n",
      "Iteration 17755, loss = 1083.39071936\n",
      "Iteration 17756, loss = 1083.29226149\n",
      "Iteration 17757, loss = 1083.19386153\n",
      "Iteration 17758, loss = 1083.09551939\n",
      "Iteration 17759, loss = 1082.99723493\n",
      "Iteration 17760, loss = 1082.89900805\n",
      "Iteration 17761, loss = 1082.80083863\n",
      "Iteration 17762, loss = 1082.70272655\n",
      "Iteration 17763, loss = 1082.60467170\n",
      "Iteration 17764, loss = 1082.50667397\n",
      "Iteration 17765, loss = 1082.40873324\n",
      "Iteration 17766, loss = 1082.31084939\n",
      "Iteration 17767, loss = 1082.21302233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17768, loss = 1082.11525192\n",
      "Iteration 17769, loss = 1082.01753807\n",
      "Iteration 17770, loss = 1081.91988066\n",
      "Iteration 17771, loss = 1081.82227957\n",
      "Iteration 17772, loss = 1081.72473470\n",
      "Iteration 17773, loss = 1081.62724594\n",
      "Iteration 17774, loss = 1081.52981318\n",
      "Iteration 17775, loss = 1081.43243631\n",
      "Iteration 17776, loss = 1081.33511521\n",
      "Iteration 17777, loss = 1081.23784978\n",
      "Iteration 17778, loss = 1081.14063991\n",
      "Iteration 17779, loss = 1081.04348550\n",
      "Iteration 17780, loss = 1080.94638643\n",
      "Iteration 17781, loss = 1080.84934260\n",
      "Iteration 17782, loss = 1080.75235390\n",
      "Iteration 17783, loss = 1080.65542022\n",
      "Iteration 17784, loss = 1080.55854146\n",
      "Iteration 17785, loss = 1080.46171751\n",
      "Iteration 17786, loss = 1080.36494827\n",
      "Iteration 17787, loss = 1080.26823364\n",
      "Iteration 17788, loss = 1080.17157349\n",
      "Iteration 17789, loss = 1080.07496775\n",
      "Iteration 17790, loss = 1079.97841629\n",
      "Iteration 17791, loss = 1079.88191901\n",
      "Iteration 17792, loss = 1079.78547582\n",
      "Iteration 17793, loss = 1079.68908660\n",
      "Iteration 17794, loss = 1079.59275127\n",
      "Iteration 17795, loss = 1079.49646970\n",
      "Iteration 17796, loss = 1079.40024181\n",
      "Iteration 17797, loss = 1079.30406749\n",
      "Iteration 17798, loss = 1079.20794664\n",
      "Iteration 17799, loss = 1079.11187916\n",
      "Iteration 17800, loss = 1079.01586495\n",
      "Iteration 17801, loss = 1078.91990391\n",
      "Iteration 17802, loss = 1078.82399594\n",
      "Iteration 17803, loss = 1078.72814096\n",
      "Iteration 17804, loss = 1078.63233885\n",
      "Iteration 17805, loss = 1078.53658955\n",
      "Iteration 17806, loss = 1078.44089298\n",
      "Iteration 17807, loss = 1078.34524908\n",
      "Iteration 17808, loss = 1078.24965786\n",
      "Iteration 17809, loss = 1078.15411937\n",
      "Iteration 17810, loss = 1078.05863385\n",
      "Iteration 17811, loss = 1077.96320180\n",
      "Iteration 17812, loss = 1077.86782423\n",
      "Iteration 17813, loss = 1077.77250308\n",
      "Iteration 17814, loss = 1077.67724152\n",
      "Iteration 17815, loss = 1077.58204464\n",
      "Iteration 17816, loss = 1077.48691631\n",
      "Iteration 17817, loss = 1077.39185483\n",
      "Iteration 17818, loss = 1077.29683362\n",
      "Iteration 17819, loss = 1077.20180966\n",
      "Iteration 17820, loss = 1077.10675676\n",
      "Iteration 17821, loss = 1077.01173440\n",
      "Iteration 17822, loss = 1076.91683160\n",
      "Iteration 17823, loss = 1076.82206309\n",
      "Iteration 17824, loss = 1076.72735560\n",
      "Iteration 17825, loss = 1076.63263437\n",
      "Iteration 17826, loss = 1076.53791042\n",
      "Iteration 17827, loss = 1076.44326024\n",
      "Iteration 17828, loss = 1076.34872092\n",
      "Iteration 17829, loss = 1076.25424655\n",
      "Iteration 17830, loss = 1076.15978016\n",
      "Iteration 17831, loss = 1076.06533168\n",
      "Iteration 17832, loss = 1075.97095438\n",
      "Iteration 17833, loss = 1075.87666360\n",
      "Iteration 17834, loss = 1075.78242169\n",
      "Iteration 17835, loss = 1075.68819966\n",
      "Iteration 17836, loss = 1075.59401668\n",
      "Iteration 17837, loss = 1075.49990440\n",
      "Iteration 17838, loss = 1075.40585878\n",
      "Iteration 17839, loss = 1075.31185219\n",
      "Iteration 17840, loss = 1075.21787761\n",
      "Iteration 17841, loss = 1075.12395506\n",
      "Iteration 17842, loss = 1075.03009712\n",
      "Iteration 17843, loss = 1074.93629189\n",
      "Iteration 17844, loss = 1074.84252476\n",
      "Iteration 17845, loss = 1074.74880012\n",
      "Iteration 17846, loss = 1074.65513139\n",
      "Iteration 17847, loss = 1074.56151934\n",
      "Iteration 17848, loss = 1074.46795328\n",
      "Iteration 17849, loss = 1074.37442881\n",
      "Iteration 17850, loss = 1074.28095281\n",
      "Iteration 17851, loss = 1074.18753122\n",
      "Iteration 17852, loss = 1074.09416036\n",
      "Iteration 17853, loss = 1074.00083399\n",
      "Iteration 17854, loss = 1073.90755280\n",
      "Iteration 17855, loss = 1073.81432192\n",
      "Iteration 17856, loss = 1073.72114251\n",
      "Iteration 17857, loss = 1073.62801073\n",
      "Iteration 17858, loss = 1073.53492411\n",
      "Iteration 17859, loss = 1073.44188473\n",
      "Iteration 17860, loss = 1073.34889522\n",
      "Iteration 17861, loss = 1073.25595478\n",
      "Iteration 17862, loss = 1073.16306086\n",
      "Iteration 17863, loss = 1073.07021302\n",
      "Iteration 17864, loss = 1072.97741301\n",
      "Iteration 17865, loss = 1072.88466177\n",
      "Iteration 17866, loss = 1072.79195814\n",
      "Iteration 17867, loss = 1072.69930077\n",
      "Iteration 17868, loss = 1072.60668996\n",
      "Iteration 17869, loss = 1072.51412679\n",
      "Iteration 17870, loss = 1072.42161135\n",
      "Iteration 17871, loss = 1072.32914271\n",
      "Iteration 17872, loss = 1072.23672028\n",
      "Iteration 17873, loss = 1072.14434446\n",
      "Iteration 17874, loss = 1072.05201577\n",
      "Iteration 17875, loss = 1071.95973403\n",
      "Iteration 17876, loss = 1071.86749861\n",
      "Iteration 17877, loss = 1071.77530929\n",
      "Iteration 17878, loss = 1071.68316635\n",
      "Iteration 17879, loss = 1071.59107001\n",
      "Iteration 17880, loss = 1071.49902003\n",
      "Iteration 17881, loss = 1071.40701601\n",
      "Iteration 17882, loss = 1071.31505787\n",
      "Iteration 17883, loss = 1071.22314577\n",
      "Iteration 17884, loss = 1071.13127977\n",
      "Iteration 17885, loss = 1071.03945965\n",
      "Iteration 17886, loss = 1070.94768518\n",
      "Iteration 17887, loss = 1070.85595629\n",
      "Iteration 17888, loss = 1070.76427306\n",
      "Iteration 17889, loss = 1070.67263547\n",
      "Iteration 17890, loss = 1070.58104336\n",
      "Iteration 17891, loss = 1070.48949655\n",
      "Iteration 17892, loss = 1070.39799500\n",
      "Iteration 17893, loss = 1070.30653873\n",
      "Iteration 17894, loss = 1070.21512767\n",
      "Iteration 17895, loss = 1070.12376171\n",
      "Iteration 17896, loss = 1070.03244071\n",
      "Iteration 17897, loss = 1069.94116463\n",
      "Iteration 17898, loss = 1069.84993343\n",
      "Iteration 17899, loss = 1069.75874706\n",
      "Iteration 17900, loss = 1069.66760542\n",
      "Iteration 17901, loss = 1069.57650840\n",
      "Iteration 17902, loss = 1069.48545593\n",
      "Iteration 17903, loss = 1069.39444798\n",
      "Iteration 17904, loss = 1069.30348448\n",
      "Iteration 17905, loss = 1069.21256535\n",
      "Iteration 17906, loss = 1069.12169048\n",
      "Iteration 17907, loss = 1069.03085982\n",
      "Iteration 17908, loss = 1068.94007331\n",
      "Iteration 17909, loss = 1068.84933089\n",
      "Iteration 17910, loss = 1068.75863247\n",
      "Iteration 17911, loss = 1068.66797798\n",
      "Iteration 17912, loss = 1068.57736734\n",
      "Iteration 17913, loss = 1068.48680050\n",
      "Iteration 17914, loss = 1068.39627738\n",
      "Iteration 17915, loss = 1068.30579792\n",
      "Iteration 17916, loss = 1068.21536204\n",
      "Iteration 17917, loss = 1068.12496967\n",
      "Iteration 17918, loss = 1068.03462074\n",
      "Iteration 17919, loss = 1067.94431519\n",
      "Iteration 17920, loss = 1067.85405295\n",
      "Iteration 17921, loss = 1067.76383395\n",
      "Iteration 17922, loss = 1067.67365811\n",
      "Iteration 17923, loss = 1067.58352538\n",
      "Iteration 17924, loss = 1067.49343567\n",
      "Iteration 17925, loss = 1067.40338894\n",
      "Iteration 17926, loss = 1067.31338510\n",
      "Iteration 17927, loss = 1067.22342409\n",
      "Iteration 17928, loss = 1067.13350585\n",
      "Iteration 17929, loss = 1067.04363030\n",
      "Iteration 17930, loss = 1066.95379738\n",
      "Iteration 17931, loss = 1066.86400703\n",
      "Iteration 17932, loss = 1066.77425917\n",
      "Iteration 17933, loss = 1066.68455374\n",
      "Iteration 17934, loss = 1066.59489068\n",
      "Iteration 17935, loss = 1066.50526991\n",
      "Iteration 17936, loss = 1066.41569138\n",
      "Iteration 17937, loss = 1066.32615502\n",
      "Iteration 17938, loss = 1066.23666075\n",
      "Iteration 17939, loss = 1066.14720853\n",
      "Iteration 17940, loss = 1066.05779827\n",
      "Iteration 17941, loss = 1065.96842993\n",
      "Iteration 17942, loss = 1065.87910342\n",
      "Iteration 17943, loss = 1065.78981870\n",
      "Iteration 17944, loss = 1065.70057568\n",
      "Iteration 17945, loss = 1065.61137432\n",
      "Iteration 17946, loss = 1065.52221454\n",
      "Iteration 17947, loss = 1065.43309629\n",
      "Iteration 17948, loss = 1065.34401950\n",
      "Iteration 17949, loss = 1065.25498410\n",
      "Iteration 17950, loss = 1065.16599003\n",
      "Iteration 17951, loss = 1065.07703723\n",
      "Iteration 17952, loss = 1064.98812564\n",
      "Iteration 17953, loss = 1064.89925520\n",
      "Iteration 17954, loss = 1064.81042583\n",
      "Iteration 17955, loss = 1064.72163749\n",
      "Iteration 17956, loss = 1064.63289010\n",
      "Iteration 17957, loss = 1064.54418361\n",
      "Iteration 17958, loss = 1064.45551795\n",
      "Iteration 17959, loss = 1064.36689306\n",
      "Iteration 17960, loss = 1064.27830888\n",
      "Iteration 17961, loss = 1064.18976536\n",
      "Iteration 17962, loss = 1064.10126242\n",
      "Iteration 17963, loss = 1064.01280001\n",
      "Iteration 17964, loss = 1063.92437806\n",
      "Iteration 17965, loss = 1063.83599653\n",
      "Iteration 17966, loss = 1063.74765533\n",
      "Iteration 17967, loss = 1063.65935443\n",
      "Iteration 17968, loss = 1063.57109374\n",
      "Iteration 17969, loss = 1063.48287323\n",
      "Iteration 17970, loss = 1063.39469281\n",
      "Iteration 17971, loss = 1063.30655245\n",
      "Iteration 17972, loss = 1063.21845207\n",
      "Iteration 17973, loss = 1063.13039162\n",
      "Iteration 17974, loss = 1063.04237103\n",
      "Iteration 17975, loss = 1062.95439026\n",
      "Iteration 17976, loss = 1062.86644924\n",
      "Iteration 17977, loss = 1062.77854790\n",
      "Iteration 17978, loss = 1062.69068620\n",
      "Iteration 17979, loss = 1062.60286408\n",
      "Iteration 17980, loss = 1062.51508147\n",
      "Iteration 17981, loss = 1062.42733832\n",
      "Iteration 17982, loss = 1062.33963457\n",
      "Iteration 17983, loss = 1062.25197016\n",
      "Iteration 17984, loss = 1062.16434504\n",
      "Iteration 17985, loss = 1062.07675915\n",
      "Iteration 17986, loss = 1061.98921243\n",
      "Iteration 17987, loss = 1061.90170482\n",
      "Iteration 17988, loss = 1061.81423627\n",
      "Iteration 17989, loss = 1061.72680672\n",
      "Iteration 17990, loss = 1061.63941611\n",
      "Iteration 17991, loss = 1061.55206439\n",
      "Iteration 17992, loss = 1061.46475149\n",
      "Iteration 17993, loss = 1061.37747738\n",
      "Iteration 17994, loss = 1061.29024197\n",
      "Iteration 17995, loss = 1061.20304524\n",
      "Iteration 17996, loss = 1061.11588710\n",
      "Iteration 17997, loss = 1061.02876752\n",
      "Iteration 17998, loss = 1060.94168644\n",
      "Iteration 17999, loss = 1060.85464379\n",
      "Iteration 18000, loss = 1060.76763953\n",
      "Iteration 18001, loss = 1060.68067360\n",
      "Iteration 18002, loss = 1060.59374594\n",
      "Iteration 18003, loss = 1060.50685650\n",
      "Iteration 18004, loss = 1060.42000523\n",
      "Iteration 18005, loss = 1060.33319206\n",
      "Iteration 18006, loss = 1060.24641696\n",
      "Iteration 18007, loss = 1060.15967985\n",
      "Iteration 18008, loss = 1060.07298070\n",
      "Iteration 18009, loss = 1059.98631944\n",
      "Iteration 18010, loss = 1059.89969601\n",
      "Iteration 18011, loss = 1059.81311038\n",
      "Iteration 18012, loss = 1059.72656248\n",
      "Iteration 18013, loss = 1059.64005225\n",
      "Iteration 18014, loss = 1059.55357966\n",
      "Iteration 18015, loss = 1059.46714463\n",
      "Iteration 18016, loss = 1059.38074713\n",
      "Iteration 18017, loss = 1059.29438709\n",
      "Iteration 18018, loss = 1059.20806447\n",
      "Iteration 18019, loss = 1059.12177922\n",
      "Iteration 18020, loss = 1059.03553127\n",
      "Iteration 18021, loss = 1058.94932057\n",
      "Iteration 18022, loss = 1058.86314709\n",
      "Iteration 18023, loss = 1058.77701075\n",
      "Iteration 18024, loss = 1058.69091152\n",
      "Iteration 18025, loss = 1058.60484934\n",
      "Iteration 18026, loss = 1058.51882415\n",
      "Iteration 18027, loss = 1058.43283591\n",
      "Iteration 18028, loss = 1058.34688457\n",
      "Iteration 18029, loss = 1058.26097007\n",
      "Iteration 18030, loss = 1058.17509236\n",
      "Iteration 18031, loss = 1058.08925139\n",
      "Iteration 18032, loss = 1058.00344712\n",
      "Iteration 18033, loss = 1057.91767948\n",
      "Iteration 18034, loss = 1057.83194843\n",
      "Iteration 18035, loss = 1057.74625392\n",
      "Iteration 18036, loss = 1057.66059590\n",
      "Iteration 18037, loss = 1057.57497431\n",
      "Iteration 18038, loss = 1057.48938911\n",
      "Iteration 18039, loss = 1057.40384025\n",
      "Iteration 18040, loss = 1057.31832768\n",
      "Iteration 18041, loss = 1057.23285135\n",
      "Iteration 18042, loss = 1057.14741120\n",
      "Iteration 18043, loss = 1057.06200719\n",
      "Iteration 18044, loss = 1056.97663927\n",
      "Iteration 18045, loss = 1056.89130739\n",
      "Iteration 18046, loss = 1056.80601150\n",
      "Iteration 18047, loss = 1056.72075156\n",
      "Iteration 18048, loss = 1056.63552750\n",
      "Iteration 18049, loss = 1056.55033929\n",
      "Iteration 18050, loss = 1056.46518687\n",
      "Iteration 18051, loss = 1056.38007020\n",
      "Iteration 18052, loss = 1056.29498923\n",
      "Iteration 18053, loss = 1056.20994391\n",
      "Iteration 18054, loss = 1056.12493419\n",
      "Iteration 18055, loss = 1056.03996002\n",
      "Iteration 18056, loss = 1055.95502136\n",
      "Iteration 18057, loss = 1055.87011815\n",
      "Iteration 18058, loss = 1055.78525036\n",
      "Iteration 18059, loss = 1055.70041793\n",
      "Iteration 18060, loss = 1055.61562081\n",
      "Iteration 18061, loss = 1055.53085895\n",
      "Iteration 18062, loss = 1055.44613232\n",
      "Iteration 18063, loss = 1055.36144086\n",
      "Iteration 18064, loss = 1055.27678452\n",
      "Iteration 18065, loss = 1055.19216326\n",
      "Iteration 18066, loss = 1055.10757704\n",
      "Iteration 18067, loss = 1055.02302579\n",
      "Iteration 18068, loss = 1054.93850949\n",
      "Iteration 18069, loss = 1054.85402807\n",
      "Iteration 18070, loss = 1054.76958150\n",
      "Iteration 18071, loss = 1054.68516973\n",
      "Iteration 18072, loss = 1054.60079271\n",
      "Iteration 18073, loss = 1054.51645040\n",
      "Iteration 18074, loss = 1054.43214275\n",
      "Iteration 18075, loss = 1054.34786971\n",
      "Iteration 18076, loss = 1054.26363124\n",
      "Iteration 18077, loss = 1054.17942729\n",
      "Iteration 18078, loss = 1054.09525782\n",
      "Iteration 18079, loss = 1054.01112278\n",
      "Iteration 18080, loss = 1053.92702212\n",
      "Iteration 18081, loss = 1053.84295581\n",
      "Iteration 18082, loss = 1053.75892379\n",
      "Iteration 18083, loss = 1053.67492602\n",
      "Iteration 18084, loss = 1053.59096246\n",
      "Iteration 18085, loss = 1053.50703306\n",
      "Iteration 18086, loss = 1053.42313777\n",
      "Iteration 18087, loss = 1053.33927656\n",
      "Iteration 18088, loss = 1053.25544937\n",
      "Iteration 18089, loss = 1053.17165616\n",
      "Iteration 18090, loss = 1053.08789689\n",
      "Iteration 18091, loss = 1053.00417152\n",
      "Iteration 18092, loss = 1052.92047999\n",
      "Iteration 18093, loss = 1052.83682227\n",
      "Iteration 18094, loss = 1052.75319831\n",
      "Iteration 18095, loss = 1052.66960807\n",
      "Iteration 18096, loss = 1052.58605150\n",
      "Iteration 18097, loss = 1052.50252856\n",
      "Iteration 18098, loss = 1052.41903921\n",
      "Iteration 18099, loss = 1052.33558340\n",
      "Iteration 18100, loss = 1052.25216109\n",
      "Iteration 18101, loss = 1052.16877223\n",
      "Iteration 18102, loss = 1052.08541679\n",
      "Iteration 18103, loss = 1052.00209472\n",
      "Iteration 18104, loss = 1051.91880597\n",
      "Iteration 18105, loss = 1051.83555051\n",
      "Iteration 18106, loss = 1051.75232829\n",
      "Iteration 18107, loss = 1051.66913927\n",
      "Iteration 18108, loss = 1051.58598341\n",
      "Iteration 18109, loss = 1051.50286065\n",
      "Iteration 18110, loss = 1051.41977097\n",
      "Iteration 18111, loss = 1051.33671432\n",
      "Iteration 18112, loss = 1051.25369065\n",
      "Iteration 18113, loss = 1051.17069993\n",
      "Iteration 18114, loss = 1051.08774211\n",
      "Iteration 18115, loss = 1051.00481715\n",
      "Iteration 18116, loss = 1050.92192501\n",
      "Iteration 18117, loss = 1050.83906564\n",
      "Iteration 18118, loss = 1050.75623901\n",
      "Iteration 18119, loss = 1050.67344507\n",
      "Iteration 18120, loss = 1050.59068378\n",
      "Iteration 18121, loss = 1050.50795511\n",
      "Iteration 18122, loss = 1050.42525900\n",
      "Iteration 18123, loss = 1050.34259542\n",
      "Iteration 18124, loss = 1050.25996433\n",
      "Iteration 18125, loss = 1050.17736569\n",
      "Iteration 18126, loss = 1050.09479945\n",
      "Iteration 18127, loss = 1050.01226559\n",
      "Iteration 18128, loss = 1049.92976406\n",
      "Iteration 18129, loss = 1049.84729484\n",
      "Iteration 18130, loss = 1049.76485792\n",
      "Iteration 18131, loss = 1049.68245329\n",
      "Iteration 18132, loss = 1049.60008101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18133, loss = 1049.51774120\n",
      "Iteration 18134, loss = 1049.43543413\n",
      "Iteration 18135, loss = 1049.35316037\n",
      "Iteration 18136, loss = 1049.27092103\n",
      "Iteration 18137, loss = 1049.18871818\n",
      "Iteration 18138, loss = 1049.10655558\n",
      "Iteration 18139, loss = 1049.02443901\n",
      "Iteration 18140, loss = 1048.94237551\n",
      "Iteration 18141, loss = 1048.86036540\n",
      "Iteration 18142, loss = 1048.77838745\n",
      "Iteration 18143, loss = 1048.69638344\n",
      "Iteration 18144, loss = 1048.61430868\n",
      "Iteration 18145, loss = 1048.53221134\n",
      "Iteration 18146, loss = 1048.45021757\n",
      "Iteration 18147, loss = 1048.36837248\n",
      "Iteration 18148, loss = 1048.28658815\n",
      "Iteration 18149, loss = 1048.20475710\n",
      "Iteration 18150, loss = 1048.12287942\n",
      "Iteration 18151, loss = 1048.04105824\n",
      "Iteration 18152, loss = 1047.95934962\n",
      "Iteration 18153, loss = 1047.87769168\n",
      "Iteration 18154, loss = 1047.79600668\n",
      "Iteration 18155, loss = 1047.71431248\n",
      "Iteration 18156, loss = 1047.63268358\n",
      "Iteration 18157, loss = 1047.55113187\n",
      "Iteration 18158, loss = 1047.46960049\n",
      "Iteration 18159, loss = 1047.38805902\n",
      "Iteration 18160, loss = 1047.30654442\n",
      "Iteration 18161, loss = 1047.22509427\n",
      "Iteration 18162, loss = 1047.14368845\n",
      "Iteration 18163, loss = 1047.06229062\n",
      "Iteration 18164, loss = 1046.98090666\n",
      "Iteration 18165, loss = 1046.89956758\n",
      "Iteration 18166, loss = 1046.81827745\n",
      "Iteration 18167, loss = 1046.73701183\n",
      "Iteration 18168, loss = 1046.65576059\n",
      "Iteration 18169, loss = 1046.57454115\n",
      "Iteration 18170, loss = 1046.49336602\n",
      "Iteration 18171, loss = 1046.41222441\n",
      "Iteration 18172, loss = 1046.33110333\n",
      "Iteration 18173, loss = 1046.25000778\n",
      "Iteration 18174, loss = 1046.16894977\n",
      "Iteration 18175, loss = 1046.08792830\n",
      "Iteration 18176, loss = 1046.00693328\n",
      "Iteration 18177, loss = 1045.92596284\n",
      "Iteration 18178, loss = 1045.84502441\n",
      "Iteration 18179, loss = 1045.76412158\n",
      "Iteration 18180, loss = 1045.68324933\n",
      "Iteration 18181, loss = 1045.60240317\n",
      "Iteration 18182, loss = 1045.52158589\n",
      "Iteration 18183, loss = 1045.44080182\n",
      "Iteration 18184, loss = 1045.36004993\n",
      "Iteration 18185, loss = 1045.27932641\n",
      "Iteration 18186, loss = 1045.19863082\n",
      "Iteration 18187, loss = 1045.11796605\n",
      "Iteration 18188, loss = 1045.03733332\n",
      "Iteration 18189, loss = 1044.95673063\n",
      "Iteration 18190, loss = 1044.87615627\n",
      "Iteration 18191, loss = 1044.79561129\n",
      "Iteration 18192, loss = 1044.71509728\n",
      "Iteration 18193, loss = 1044.63461396\n",
      "Iteration 18194, loss = 1044.55415986\n",
      "Iteration 18195, loss = 1044.47373464\n",
      "Iteration 18196, loss = 1044.39333931\n",
      "Iteration 18197, loss = 1044.31297448\n",
      "Iteration 18198, loss = 1044.23263946\n",
      "Iteration 18199, loss = 1044.15233350\n",
      "Iteration 18200, loss = 1044.07205680\n",
      "Iteration 18201, loss = 1043.99180997\n",
      "Iteration 18202, loss = 1043.91159307\n",
      "Iteration 18203, loss = 1043.83140557\n",
      "Iteration 18204, loss = 1043.75124714\n",
      "Iteration 18205, loss = 1043.67111807\n",
      "Iteration 18206, loss = 1043.59101863\n",
      "Iteration 18207, loss = 1043.51094872\n",
      "Iteration 18208, loss = 1043.43090798\n",
      "Iteration 18209, loss = 1043.35089631\n",
      "Iteration 18210, loss = 1043.27091391\n",
      "Iteration 18211, loss = 1043.19096089\n",
      "Iteration 18212, loss = 1043.11103709\n",
      "Iteration 18213, loss = 1043.03114233\n",
      "Iteration 18214, loss = 1042.95127656\n",
      "Iteration 18215, loss = 1042.87143990\n",
      "Iteration 18216, loss = 1042.79163238\n",
      "Iteration 18217, loss = 1042.71185387\n",
      "Iteration 18218, loss = 1042.63210426\n",
      "Iteration 18219, loss = 1042.55238352\n",
      "Iteration 18220, loss = 1042.47269171\n",
      "Iteration 18221, loss = 1042.39302883\n",
      "Iteration 18222, loss = 1042.31339477\n",
      "Iteration 18223, loss = 1042.23378946\n",
      "Iteration 18224, loss = 1042.15421289\n",
      "Iteration 18225, loss = 1042.07466506\n",
      "Iteration 18226, loss = 1041.99514596\n",
      "Iteration 18227, loss = 1041.91565552\n",
      "Iteration 18228, loss = 1041.83619367\n",
      "Iteration 18229, loss = 1041.75676040\n",
      "Iteration 18230, loss = 1041.67735570\n",
      "Iteration 18231, loss = 1041.59797954\n",
      "Iteration 18232, loss = 1041.51863188\n",
      "Iteration 18233, loss = 1041.43931265\n",
      "Iteration 18234, loss = 1041.36002184\n",
      "Iteration 18235, loss = 1041.28075943\n",
      "Iteration 18236, loss = 1041.20152538\n",
      "Iteration 18237, loss = 1041.12231966\n",
      "Iteration 18238, loss = 1041.04314223\n",
      "Iteration 18239, loss = 1040.96399304\n",
      "Iteration 18240, loss = 1040.88487208\n",
      "Iteration 18241, loss = 1040.80577932\n",
      "Iteration 18242, loss = 1040.72671471\n",
      "Iteration 18243, loss = 1040.64767824\n",
      "Iteration 18244, loss = 1040.56866984\n",
      "Iteration 18245, loss = 1040.48968951\n",
      "Iteration 18246, loss = 1040.41073721\n",
      "Iteration 18247, loss = 1040.33181291\n",
      "Iteration 18248, loss = 1040.25291657\n",
      "Iteration 18249, loss = 1040.17404815\n",
      "Iteration 18250, loss = 1040.09520763\n",
      "Iteration 18251, loss = 1040.01639498\n",
      "Iteration 18252, loss = 1039.93761016\n",
      "Iteration 18253, loss = 1039.85885314\n",
      "Iteration 18254, loss = 1039.78012388\n",
      "Iteration 18255, loss = 1039.70142236\n",
      "Iteration 18256, loss = 1039.62274855\n",
      "Iteration 18257, loss = 1039.54410240\n",
      "Iteration 18258, loss = 1039.46548390\n",
      "Iteration 18259, loss = 1039.38689300\n",
      "Iteration 18260, loss = 1039.30832968\n",
      "Iteration 18261, loss = 1039.22979389\n",
      "Iteration 18262, loss = 1039.15128562\n",
      "Iteration 18263, loss = 1039.07280483\n",
      "Iteration 18264, loss = 1038.99435149\n",
      "Iteration 18265, loss = 1038.91592556\n",
      "Iteration 18266, loss = 1038.83752702\n",
      "Iteration 18267, loss = 1038.75915583\n",
      "Iteration 18268, loss = 1038.68081195\n",
      "Iteration 18269, loss = 1038.60249537\n",
      "Iteration 18270, loss = 1038.52420605\n",
      "Iteration 18271, loss = 1038.44594395\n",
      "Iteration 18272, loss = 1038.36770905\n",
      "Iteration 18273, loss = 1038.28950131\n",
      "Iteration 18274, loss = 1038.21132070\n",
      "Iteration 18275, loss = 1038.13316719\n",
      "Iteration 18276, loss = 1038.05504076\n",
      "Iteration 18277, loss = 1037.97694136\n",
      "Iteration 18278, loss = 1037.89886897\n",
      "Iteration 18279, loss = 1037.82082355\n",
      "Iteration 18280, loss = 1037.74280508\n",
      "Iteration 18281, loss = 1037.66481353\n",
      "Iteration 18282, loss = 1037.58684885\n",
      "Iteration 18283, loss = 1037.50891103\n",
      "Iteration 18284, loss = 1037.43100003\n",
      "Iteration 18285, loss = 1037.35311583\n",
      "Iteration 18286, loss = 1037.27525838\n",
      "Iteration 18287, loss = 1037.19742766\n",
      "Iteration 18288, loss = 1037.11962364\n",
      "Iteration 18289, loss = 1037.04184628\n",
      "Iteration 18290, loss = 1036.96409557\n",
      "Iteration 18291, loss = 1036.88637146\n",
      "Iteration 18292, loss = 1036.80867392\n",
      "Iteration 18293, loss = 1036.73100293\n",
      "Iteration 18294, loss = 1036.65335846\n",
      "Iteration 18295, loss = 1036.57574047\n",
      "Iteration 18296, loss = 1036.49814894\n",
      "Iteration 18297, loss = 1036.42058383\n",
      "Iteration 18298, loss = 1036.34304511\n",
      "Iteration 18299, loss = 1036.26553276\n",
      "Iteration 18300, loss = 1036.18804674\n",
      "Iteration 18301, loss = 1036.11058702\n",
      "Iteration 18302, loss = 1036.03315357\n",
      "Iteration 18303, loss = 1035.95574637\n",
      "Iteration 18304, loss = 1035.87836539\n",
      "Iteration 18305, loss = 1035.80101058\n",
      "Iteration 18306, loss = 1035.72368193\n",
      "Iteration 18307, loss = 1035.64637940\n",
      "Iteration 18308, loss = 1035.56910296\n",
      "Iteration 18309, loss = 1035.49185259\n",
      "Iteration 18310, loss = 1035.41462825\n",
      "Iteration 18311, loss = 1035.33742991\n",
      "Iteration 18312, loss = 1035.26025755\n",
      "Iteration 18313, loss = 1035.18311113\n",
      "Iteration 18314, loss = 1035.10599063\n",
      "Iteration 18315, loss = 1035.02889601\n",
      "Iteration 18316, loss = 1034.95182725\n",
      "Iteration 18317, loss = 1034.87478431\n",
      "Iteration 18318, loss = 1034.79776717\n",
      "Iteration 18319, loss = 1034.72077579\n",
      "Iteration 18320, loss = 1034.64381016\n",
      "Iteration 18321, loss = 1034.56687023\n",
      "Iteration 18322, loss = 1034.48995597\n",
      "Iteration 18323, loss = 1034.41306737\n",
      "Iteration 18324, loss = 1034.33620439\n",
      "Iteration 18325, loss = 1034.25936700\n",
      "Iteration 18326, loss = 1034.18255517\n",
      "Iteration 18327, loss = 1034.10576887\n",
      "Iteration 18328, loss = 1034.02900808\n",
      "Iteration 18329, loss = 1033.95227276\n",
      "Iteration 18330, loss = 1033.87556288\n",
      "Iteration 18331, loss = 1033.79887842\n",
      "Iteration 18332, loss = 1033.72221935\n",
      "Iteration 18333, loss = 1033.64558563\n",
      "Iteration 18334, loss = 1033.56897724\n",
      "Iteration 18335, loss = 1033.49239415\n",
      "Iteration 18336, loss = 1033.41583634\n",
      "Iteration 18337, loss = 1033.33930376\n",
      "Iteration 18338, loss = 1033.26279640\n",
      "Iteration 18339, loss = 1033.18631422\n",
      "Iteration 18340, loss = 1033.10985720\n",
      "Iteration 18341, loss = 1033.03342530\n",
      "Iteration 18342, loss = 1032.95701851\n",
      "Iteration 18343, loss = 1032.88063678\n",
      "Iteration 18344, loss = 1032.80428009\n",
      "Iteration 18345, loss = 1032.72794841\n",
      "Iteration 18346, loss = 1032.65164172\n",
      "Iteration 18347, loss = 1032.57535998\n",
      "Iteration 18348, loss = 1032.49910317\n",
      "Iteration 18349, loss = 1032.42287126\n",
      "Iteration 18350, loss = 1032.34666421\n",
      "Iteration 18351, loss = 1032.27048201\n",
      "Iteration 18352, loss = 1032.19432461\n",
      "Iteration 18353, loss = 1032.11819201\n",
      "Iteration 18354, loss = 1032.04208415\n",
      "Iteration 18355, loss = 1031.96600103\n",
      "Iteration 18356, loss = 1031.88994260\n",
      "Iteration 18357, loss = 1031.81390884\n",
      "Iteration 18358, loss = 1031.73789973\n",
      "Iteration 18359, loss = 1031.66191523\n",
      "Iteration 18360, loss = 1031.58595532\n",
      "Iteration 18361, loss = 1031.51001996\n",
      "Iteration 18362, loss = 1031.43410913\n",
      "Iteration 18363, loss = 1031.35822280\n",
      "Iteration 18364, loss = 1031.28236095\n",
      "Iteration 18365, loss = 1031.20652354\n",
      "Iteration 18366, loss = 1031.13071055\n",
      "Iteration 18367, loss = 1031.05492195\n",
      "Iteration 18368, loss = 1030.97915771\n",
      "Iteration 18369, loss = 1030.90341780\n",
      "Iteration 18370, loss = 1030.82770220\n",
      "Iteration 18371, loss = 1030.75201087\n",
      "Iteration 18372, loss = 1030.67634379\n",
      "Iteration 18373, loss = 1030.60070093\n",
      "Iteration 18374, loss = 1030.52508227\n",
      "Iteration 18375, loss = 1030.44948777\n",
      "Iteration 18376, loss = 1030.37391741\n",
      "Iteration 18377, loss = 1030.29837116\n",
      "Iteration 18378, loss = 1030.22284899\n",
      "Iteration 18379, loss = 1030.14735088\n",
      "Iteration 18380, loss = 1030.07187679\n",
      "Iteration 18381, loss = 1029.99642670\n",
      "Iteration 18382, loss = 1029.92100058\n",
      "Iteration 18383, loss = 1029.84559840\n",
      "Iteration 18384, loss = 1029.77022014\n",
      "Iteration 18385, loss = 1029.69486577\n",
      "Iteration 18386, loss = 1029.61953525\n",
      "Iteration 18387, loss = 1029.54422857\n",
      "Iteration 18388, loss = 1029.46894570\n",
      "Iteration 18389, loss = 1029.39368660\n",
      "Iteration 18390, loss = 1029.31845125\n",
      "Iteration 18391, loss = 1029.24323963\n",
      "Iteration 18392, loss = 1029.16805170\n",
      "Iteration 18393, loss = 1029.09288743\n",
      "Iteration 18394, loss = 1029.01774681\n",
      "Iteration 18395, loss = 1028.94262980\n",
      "Iteration 18396, loss = 1028.86753637\n",
      "Iteration 18397, loss = 1028.79246650\n",
      "Iteration 18398, loss = 1028.71742016\n",
      "Iteration 18399, loss = 1028.64239733\n",
      "Iteration 18400, loss = 1028.56739797\n",
      "Iteration 18401, loss = 1028.49242205\n",
      "Iteration 18402, loss = 1028.41746956\n",
      "Iteration 18403, loss = 1028.34254046\n",
      "Iteration 18404, loss = 1028.26763473\n",
      "Iteration 18405, loss = 1028.19275233\n",
      "Iteration 18406, loss = 1028.11789325\n",
      "Iteration 18407, loss = 1028.04305745\n",
      "Iteration 18408, loss = 1027.96824490\n",
      "Iteration 18409, loss = 1027.89345559\n",
      "Iteration 18410, loss = 1027.81868948\n",
      "Iteration 18411, loss = 1027.74394655\n",
      "Iteration 18412, loss = 1027.66922676\n",
      "Iteration 18413, loss = 1027.59453010\n",
      "Iteration 18414, loss = 1027.51985654\n",
      "Iteration 18415, loss = 1027.44520607\n",
      "Iteration 18416, loss = 1027.37057866\n",
      "Iteration 18417, loss = 1027.29597431\n",
      "Iteration 18418, loss = 1027.22139305\n",
      "Iteration 18419, loss = 1027.14683493\n",
      "Iteration 18420, loss = 1027.07230011\n",
      "Iteration 18421, loss = 1026.99778888\n",
      "Iteration 18422, loss = 1026.92330187\n",
      "Iteration 18423, loss = 1026.84884031\n",
      "Iteration 18424, loss = 1026.77440649\n",
      "Iteration 18425, loss = 1026.70000453\n",
      "Iteration 18426, loss = 1026.62564091\n",
      "Iteration 18427, loss = 1026.55132268\n",
      "Iteration 18428, loss = 1026.47704892\n",
      "Iteration 18429, loss = 1026.40279105\n",
      "Iteration 18430, loss = 1026.32848877\n",
      "Iteration 18431, loss = 1026.25410340\n",
      "Iteration 18432, loss = 1026.17970355\n",
      "Iteration 18433, loss = 1026.10541140\n",
      "Iteration 18434, loss = 1026.03125471\n",
      "Iteration 18435, loss = 1025.95713563\n",
      "Iteration 18436, loss = 1025.88295332\n",
      "Iteration 18437, loss = 1025.80872347\n",
      "Iteration 18438, loss = 1025.73454939\n",
      "Iteration 18439, loss = 1025.66047799\n",
      "Iteration 18440, loss = 1025.58644241\n",
      "Iteration 18441, loss = 1025.51236936\n",
      "Iteration 18442, loss = 1025.43828139\n",
      "Iteration 18443, loss = 1025.36424995\n",
      "Iteration 18444, loss = 1025.29028632\n",
      "Iteration 18445, loss = 1025.21633515\n",
      "Iteration 18446, loss = 1025.14236496\n",
      "Iteration 18447, loss = 1025.06841123\n",
      "Iteration 18448, loss = 1024.99451148\n",
      "Iteration 18449, loss = 1024.92064976\n",
      "Iteration 18450, loss = 1024.84679021\n",
      "Iteration 18451, loss = 1024.77293294\n",
      "Iteration 18452, loss = 1024.69910829\n",
      "Iteration 18453, loss = 1024.62532524\n",
      "Iteration 18454, loss = 1024.55156193\n",
      "Iteration 18455, loss = 1024.47780447\n",
      "Iteration 18456, loss = 1024.40406556\n",
      "Iteration 18457, loss = 1024.33036091\n",
      "Iteration 18458, loss = 1024.25668501\n",
      "Iteration 18459, loss = 1024.18302311\n",
      "Iteration 18460, loss = 1024.10937529\n",
      "Iteration 18461, loss = 1024.03575315\n",
      "Iteration 18462, loss = 1023.96216042\n",
      "Iteration 18463, loss = 1023.88858903\n",
      "Iteration 18464, loss = 1023.81503302\n",
      "Iteration 18465, loss = 1023.74149707\n",
      "Iteration 18466, loss = 1023.66798745\n",
      "Iteration 18467, loss = 1023.59450241\n",
      "Iteration 18468, loss = 1023.52103640\n",
      "Iteration 18469, loss = 1023.44758869\n",
      "Iteration 18470, loss = 1023.37416354\n",
      "Iteration 18471, loss = 1023.30076303\n",
      "Iteration 18472, loss = 1023.22738436\n",
      "Iteration 18473, loss = 1023.15402491\n",
      "Iteration 18474, loss = 1023.08068579\n",
      "Iteration 18475, loss = 1023.00736954\n",
      "Iteration 18476, loss = 1022.93407623\n",
      "Iteration 18477, loss = 1022.86080375\n",
      "Iteration 18478, loss = 1022.78755122\n",
      "Iteration 18479, loss = 1022.71431990\n",
      "Iteration 18480, loss = 1022.64111099\n",
      "Iteration 18481, loss = 1022.56792396\n",
      "Iteration 18482, loss = 1022.49475754\n",
      "Iteration 18483, loss = 1022.42161160\n",
      "Iteration 18484, loss = 1022.34848708\n",
      "Iteration 18485, loss = 1022.27538441\n",
      "Iteration 18486, loss = 1022.20230304\n",
      "Iteration 18487, loss = 1022.12924233\n",
      "Iteration 18488, loss = 1022.05620236\n",
      "Iteration 18489, loss = 1021.98318368\n",
      "Iteration 18490, loss = 1021.91018642\n",
      "Iteration 18491, loss = 1021.83721019\n",
      "Iteration 18492, loss = 1021.76425465\n",
      "Iteration 18493, loss = 1021.69131989\n",
      "Iteration 18494, loss = 1021.61840623\n",
      "Iteration 18495, loss = 1021.54551370\n",
      "Iteration 18496, loss = 1021.47264202\n",
      "Iteration 18497, loss = 1021.39979100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18498, loss = 1021.32696072\n",
      "Iteration 18499, loss = 1021.25415134\n",
      "Iteration 18500, loss = 1021.18136284\n",
      "Iteration 18501, loss = 1021.10859508\n",
      "Iteration 18502, loss = 1021.03584791\n",
      "Iteration 18503, loss = 1020.96312139\n",
      "Iteration 18504, loss = 1020.89041557\n",
      "Iteration 18505, loss = 1020.81773045\n",
      "Iteration 18506, loss = 1020.74506594\n",
      "Iteration 18507, loss = 1020.67242194\n",
      "Iteration 18508, loss = 1020.59979845\n",
      "Iteration 18509, loss = 1020.52719550\n",
      "Iteration 18510, loss = 1020.45461309\n",
      "Iteration 18511, loss = 1020.38205116\n",
      "Iteration 18512, loss = 1020.30950962\n",
      "Iteration 18513, loss = 1020.23698847\n",
      "Iteration 18514, loss = 1020.16448770\n",
      "Iteration 18515, loss = 1020.09200732\n",
      "Iteration 18516, loss = 1020.01954727\n",
      "Iteration 18517, loss = 1019.94710750\n",
      "Iteration 18518, loss = 1019.87468798\n",
      "Iteration 18519, loss = 1019.80228871\n",
      "Iteration 18520, loss = 1019.72990966\n",
      "Iteration 18521, loss = 1019.65755081\n",
      "Iteration 18522, loss = 1019.58521211\n",
      "Iteration 18523, loss = 1019.51289353\n",
      "Iteration 18524, loss = 1019.44059505\n",
      "Iteration 18525, loss = 1019.36831665\n",
      "Iteration 18526, loss = 1019.29605830\n",
      "Iteration 18527, loss = 1019.22381997\n",
      "Iteration 18528, loss = 1019.15160162\n",
      "Iteration 18529, loss = 1019.07940324\n",
      "Iteration 18530, loss = 1019.00722478\n",
      "Iteration 18531, loss = 1018.93506624\n",
      "Iteration 18532, loss = 1018.86292757\n",
      "Iteration 18533, loss = 1018.79080876\n",
      "Iteration 18534, loss = 1018.71870976\n",
      "Iteration 18535, loss = 1018.64663055\n",
      "Iteration 18536, loss = 1018.57457111\n",
      "Iteration 18537, loss = 1018.50253140\n",
      "Iteration 18538, loss = 1018.43051140\n",
      "Iteration 18539, loss = 1018.35851109\n",
      "Iteration 18540, loss = 1018.28653042\n",
      "Iteration 18541, loss = 1018.21456937\n",
      "Iteration 18542, loss = 1018.14262791\n",
      "Iteration 18543, loss = 1018.07070602\n",
      "Iteration 18544, loss = 1017.99880367\n",
      "Iteration 18545, loss = 1017.92692082\n",
      "Iteration 18546, loss = 1017.85505745\n",
      "Iteration 18547, loss = 1017.78321353\n",
      "Iteration 18548, loss = 1017.71138903\n",
      "Iteration 18549, loss = 1017.63958393\n",
      "Iteration 18550, loss = 1017.56779818\n",
      "Iteration 18551, loss = 1017.49603177\n",
      "Iteration 18552, loss = 1017.42428467\n",
      "Iteration 18553, loss = 1017.35255684\n",
      "Iteration 18554, loss = 1017.28084826\n",
      "Iteration 18555, loss = 1017.20915889\n",
      "Iteration 18556, loss = 1017.13748872\n",
      "Iteration 18557, loss = 1017.06583770\n",
      "Iteration 18558, loss = 1016.99420581\n",
      "Iteration 18559, loss = 1016.92259303\n",
      "Iteration 18560, loss = 1016.85099931\n",
      "Iteration 18561, loss = 1016.77942463\n",
      "Iteration 18562, loss = 1016.70786897\n",
      "Iteration 18563, loss = 1016.63633229\n",
      "Iteration 18564, loss = 1016.56481457\n",
      "Iteration 18565, loss = 1016.49331576\n",
      "Iteration 18566, loss = 1016.42183585\n",
      "Iteration 18567, loss = 1016.35037480\n",
      "Iteration 18568, loss = 1016.27893259\n",
      "Iteration 18569, loss = 1016.20750918\n",
      "Iteration 18570, loss = 1016.13610454\n",
      "Iteration 18571, loss = 1016.06471865\n",
      "Iteration 18572, loss = 1015.99335147\n",
      "Iteration 18573, loss = 1015.92200297\n",
      "Iteration 18574, loss = 1015.85067313\n",
      "Iteration 18575, loss = 1015.77936191\n",
      "Iteration 18576, loss = 1015.70806928\n",
      "Iteration 18577, loss = 1015.63679521\n",
      "Iteration 18578, loss = 1015.56553968\n",
      "Iteration 18579, loss = 1015.49430264\n",
      "Iteration 18580, loss = 1015.42308408\n",
      "Iteration 18581, loss = 1015.35188395\n",
      "Iteration 18582, loss = 1015.28070224\n",
      "Iteration 18583, loss = 1015.20953890\n",
      "Iteration 18584, loss = 1015.13839391\n",
      "Iteration 18585, loss = 1015.06726723\n",
      "Iteration 18586, loss = 1014.99615884\n",
      "Iteration 18587, loss = 1014.92506870\n",
      "Iteration 18588, loss = 1014.85399678\n",
      "Iteration 18589, loss = 1014.78294306\n",
      "Iteration 18590, loss = 1014.71190749\n",
      "Iteration 18591, loss = 1014.64089005\n",
      "Iteration 18592, loss = 1014.56989071\n",
      "Iteration 18593, loss = 1014.49890944\n",
      "Iteration 18594, loss = 1014.42794619\n",
      "Iteration 18595, loss = 1014.35700095\n",
      "Iteration 18596, loss = 1014.28607367\n",
      "Iteration 18597, loss = 1014.21516434\n",
      "Iteration 18598, loss = 1014.14427291\n",
      "Iteration 18599, loss = 1014.07339935\n",
      "Iteration 18600, loss = 1014.00254363\n",
      "Iteration 18601, loss = 1013.93170572\n",
      "Iteration 18602, loss = 1013.86088559\n",
      "Iteration 18603, loss = 1013.79008320\n",
      "Iteration 18604, loss = 1013.71929852\n",
      "Iteration 18605, loss = 1013.64853152\n",
      "Iteration 18606, loss = 1013.57778217\n",
      "Iteration 18607, loss = 1013.50705042\n",
      "Iteration 18608, loss = 1013.43633626\n",
      "Iteration 18609, loss = 1013.36563964\n",
      "Iteration 18610, loss = 1013.29496053\n",
      "Iteration 18611, loss = 1013.22429891\n",
      "Iteration 18612, loss = 1013.15365473\n",
      "Iteration 18613, loss = 1013.08302796\n",
      "Iteration 18614, loss = 1013.01241857\n",
      "Iteration 18615, loss = 1012.94182653\n",
      "Iteration 18616, loss = 1012.87125180\n",
      "Iteration 18617, loss = 1012.80069434\n",
      "Iteration 18618, loss = 1012.73015413\n",
      "Iteration 18619, loss = 1012.65963113\n",
      "Iteration 18620, loss = 1012.58912530\n",
      "Iteration 18621, loss = 1012.51863661\n",
      "Iteration 18622, loss = 1012.44816503\n",
      "Iteration 18623, loss = 1012.37771052\n",
      "Iteration 18624, loss = 1012.30727304\n",
      "Iteration 18625, loss = 1012.23685257\n",
      "Iteration 18626, loss = 1012.16644906\n",
      "Iteration 18627, loss = 1012.09606248\n",
      "Iteration 18628, loss = 1012.02569280\n",
      "Iteration 18629, loss = 1011.95533998\n",
      "Iteration 18630, loss = 1011.88500398\n",
      "Iteration 18631, loss = 1011.81468477\n",
      "Iteration 18632, loss = 1011.74438232\n",
      "Iteration 18633, loss = 1011.67409658\n",
      "Iteration 18634, loss = 1011.60382752\n",
      "Iteration 18635, loss = 1011.53357511\n",
      "Iteration 18636, loss = 1011.46333930\n",
      "Iteration 18637, loss = 1011.39312007\n",
      "Iteration 18638, loss = 1011.32291737\n",
      "Iteration 18639, loss = 1011.25273117\n",
      "Iteration 18640, loss = 1011.18256143\n",
      "Iteration 18641, loss = 1011.11240811\n",
      "Iteration 18642, loss = 1011.04227118\n",
      "Iteration 18643, loss = 1010.97215060\n",
      "Iteration 18644, loss = 1010.90204633\n",
      "Iteration 18645, loss = 1010.83195834\n",
      "Iteration 18646, loss = 1010.76188658\n",
      "Iteration 18647, loss = 1010.69183102\n",
      "Iteration 18648, loss = 1010.62179162\n",
      "Iteration 18649, loss = 1010.55176834\n",
      "Iteration 18650, loss = 1010.48176114\n",
      "Iteration 18651, loss = 1010.41176999\n",
      "Iteration 18652, loss = 1010.34179484\n",
      "Iteration 18653, loss = 1010.27183565\n",
      "Iteration 18654, loss = 1010.20189240\n",
      "Iteration 18655, loss = 1010.13196503\n",
      "Iteration 18656, loss = 1010.06205351\n",
      "Iteration 18657, loss = 1009.99215779\n",
      "Iteration 18658, loss = 1009.92227784\n",
      "Iteration 18659, loss = 1009.85241362\n",
      "Iteration 18660, loss = 1009.78256509\n",
      "Iteration 18661, loss = 1009.71273220\n",
      "Iteration 18662, loss = 1009.64291492\n",
      "Iteration 18663, loss = 1009.57311321\n",
      "Iteration 18664, loss = 1009.50332701\n",
      "Iteration 18665, loss = 1009.43355630\n",
      "Iteration 18666, loss = 1009.36380103\n",
      "Iteration 18667, loss = 1009.29406116\n",
      "Iteration 18668, loss = 1009.22433664\n",
      "Iteration 18669, loss = 1009.15462744\n",
      "Iteration 18670, loss = 1009.08493351\n",
      "Iteration 18671, loss = 1009.01525481\n",
      "Iteration 18672, loss = 1008.94559129\n",
      "Iteration 18673, loss = 1008.87594292\n",
      "Iteration 18674, loss = 1008.80630965\n",
      "Iteration 18675, loss = 1008.73669144\n",
      "Iteration 18676, loss = 1008.66708823\n",
      "Iteration 18677, loss = 1008.59750000\n",
      "Iteration 18678, loss = 1008.52792669\n",
      "Iteration 18679, loss = 1008.45836826\n",
      "Iteration 18680, loss = 1008.38882467\n",
      "Iteration 18681, loss = 1008.31929587\n",
      "Iteration 18682, loss = 1008.24978181\n",
      "Iteration 18683, loss = 1008.18028247\n",
      "Iteration 18684, loss = 1008.11079778\n",
      "Iteration 18685, loss = 1008.04132772\n",
      "Iteration 18686, loss = 1007.97187227\n",
      "Iteration 18687, loss = 1007.90243140\n",
      "Iteration 18688, loss = 1007.83300513\n",
      "Iteration 18689, loss = 1007.76359355\n",
      "Iteration 18690, loss = 1007.69419683\n",
      "Iteration 18691, loss = 1007.62481540\n",
      "Iteration 18692, loss = 1007.55545007\n",
      "Iteration 18693, loss = 1007.48610247\n",
      "Iteration 18694, loss = 1007.41677560\n",
      "Iteration 18695, loss = 1007.34747464\n",
      "Iteration 18696, loss = 1007.27820713\n",
      "Iteration 18697, loss = 1007.20897953\n",
      "Iteration 18698, loss = 1007.13978453\n",
      "Iteration 18699, loss = 1007.07057934\n",
      "Iteration 18700, loss = 1007.00129494\n",
      "Iteration 18701, loss = 1006.93191613\n",
      "Iteration 18702, loss = 1006.86255153\n",
      "Iteration 18703, loss = 1006.79332093\n",
      "Iteration 18704, loss = 1006.72420558\n",
      "Iteration 18705, loss = 1006.65507942\n",
      "Iteration 18706, loss = 1006.58586125\n",
      "Iteration 18707, loss = 1006.51661099\n",
      "Iteration 18708, loss = 1006.44744220\n",
      "Iteration 18709, loss = 1006.37836171\n",
      "Iteration 18710, loss = 1006.30927574\n",
      "Iteration 18711, loss = 1006.24013231\n",
      "Iteration 18712, loss = 1006.17098819\n",
      "Iteration 18713, loss = 1006.10191160\n",
      "Iteration 18714, loss = 1006.03288062\n",
      "Iteration 18715, loss = 1005.96383106\n",
      "Iteration 18716, loss = 1005.89475673\n",
      "Iteration 18717, loss = 1005.82570910\n",
      "Iteration 18718, loss = 1005.75671051\n",
      "Iteration 18719, loss = 1005.68772516\n",
      "Iteration 18720, loss = 1005.61872382\n",
      "Iteration 18721, loss = 1005.54972626\n",
      "Iteration 18722, loss = 1005.48076238\n",
      "Iteration 18723, loss = 1005.41182505\n",
      "Iteration 18724, loss = 1005.34288742\n",
      "Iteration 18725, loss = 1005.27394744\n",
      "Iteration 18726, loss = 1005.20502619\n",
      "Iteration 18727, loss = 1005.13613133\n",
      "Iteration 18728, loss = 1005.06724799\n",
      "Iteration 18729, loss = 1004.99836539\n",
      "Iteration 18730, loss = 1004.92949240\n",
      "Iteration 18731, loss = 1004.86064017\n",
      "Iteration 18732, loss = 1004.79180481\n",
      "Iteration 18733, loss = 1004.72297598\n",
      "Iteration 18734, loss = 1004.65415361\n",
      "Iteration 18735, loss = 1004.58534597\n",
      "Iteration 18736, loss = 1004.51655548\n",
      "Iteration 18737, loss = 1004.44777619\n",
      "Iteration 18738, loss = 1004.37900412\n",
      "Iteration 18739, loss = 1004.31024271\n",
      "Iteration 18740, loss = 1004.24149620\n",
      "Iteration 18741, loss = 1004.17276306\n",
      "Iteration 18742, loss = 1004.10403929\n",
      "Iteration 18743, loss = 1004.03532467\n",
      "Iteration 18744, loss = 1003.96662223\n",
      "Iteration 18745, loss = 1003.89793311\n",
      "Iteration 18746, loss = 1003.82925514\n",
      "Iteration 18747, loss = 1003.76058655\n",
      "Iteration 18748, loss = 1003.69192832\n",
      "Iteration 18749, loss = 1003.62328217\n",
      "Iteration 18750, loss = 1003.55464777\n",
      "Iteration 18751, loss = 1003.48602358\n",
      "Iteration 18752, loss = 1003.41740912\n",
      "Iteration 18753, loss = 1003.34880536\n",
      "Iteration 18754, loss = 1003.28021297\n",
      "Iteration 18755, loss = 1003.21163129\n",
      "Iteration 18756, loss = 1003.14305944\n",
      "Iteration 18757, loss = 1003.07449747\n",
      "Iteration 18758, loss = 1003.00594599\n",
      "Iteration 18759, loss = 1002.93740512\n",
      "Iteration 18760, loss = 1002.86887430\n",
      "Iteration 18761, loss = 1002.80035309\n",
      "Iteration 18762, loss = 1002.73184163\n",
      "Iteration 18763, loss = 1002.66334023\n",
      "Iteration 18764, loss = 1002.59484879\n",
      "Iteration 18765, loss = 1002.52636692\n",
      "Iteration 18766, loss = 1002.45789438\n",
      "Iteration 18767, loss = 1002.38943130\n",
      "Iteration 18768, loss = 1002.32097777\n",
      "Iteration 18769, loss = 1002.25253365\n",
      "Iteration 18770, loss = 1002.18409867\n",
      "Iteration 18771, loss = 1002.11567268\n",
      "Iteration 18772, loss = 1002.04725574\n",
      "Iteration 18773, loss = 1001.97884785\n",
      "Iteration 18774, loss = 1001.91044885\n",
      "Iteration 18775, loss = 1001.84205856\n",
      "Iteration 18776, loss = 1001.77367685\n",
      "Iteration 18777, loss = 1001.70530373\n",
      "Iteration 18778, loss = 1001.63693915\n",
      "Iteration 18779, loss = 1001.56858296\n",
      "Iteration 18780, loss = 1001.50023502\n",
      "Iteration 18781, loss = 1001.43189521\n",
      "Iteration 18782, loss = 1001.36356348\n",
      "Iteration 18783, loss = 1001.29523977\n",
      "Iteration 18784, loss = 1001.22692395\n",
      "Iteration 18785, loss = 1001.15861588\n",
      "Iteration 18786, loss = 1001.09031544\n",
      "Iteration 18787, loss = 1001.02202257\n",
      "Iteration 18788, loss = 1000.95373718\n",
      "Iteration 18789, loss = 1000.88545914\n",
      "Iteration 18790, loss = 1000.81718831\n",
      "Iteration 18791, loss = 1000.74892460\n",
      "Iteration 18792, loss = 1000.68066791\n",
      "Iteration 18793, loss = 1000.61241812\n",
      "Iteration 18794, loss = 1000.54417512\n",
      "Iteration 18795, loss = 1000.47593879\n",
      "Iteration 18796, loss = 1000.40770900\n",
      "Iteration 18797, loss = 1000.33948564\n",
      "Iteration 18798, loss = 1000.27126860\n",
      "Iteration 18799, loss = 1000.20305776\n",
      "Iteration 18800, loss = 1000.13485299\n",
      "Iteration 18801, loss = 1000.06665415\n",
      "Iteration 18802, loss = 999.99846113\n",
      "Iteration 18803, loss = 999.93027381\n",
      "Iteration 18804, loss = 999.86209206\n",
      "Iteration 18805, loss = 999.79391574\n",
      "Iteration 18806, loss = 999.72574471\n",
      "Iteration 18807, loss = 999.65757886\n",
      "Iteration 18808, loss = 999.58941804\n",
      "Iteration 18809, loss = 999.52126211\n",
      "Iteration 18810, loss = 999.45311095\n",
      "Iteration 18811, loss = 999.38496440\n",
      "Iteration 18812, loss = 999.31682233\n",
      "Iteration 18813, loss = 999.24868459\n",
      "Iteration 18814, loss = 999.18055104\n",
      "Iteration 18815, loss = 999.11242152\n",
      "Iteration 18816, loss = 999.04429590\n",
      "Iteration 18817, loss = 998.97617402\n",
      "Iteration 18818, loss = 998.90805572\n",
      "Iteration 18819, loss = 998.83994085\n",
      "Iteration 18820, loss = 998.77182925\n",
      "Iteration 18821, loss = 998.70372077\n",
      "Iteration 18822, loss = 998.63561524\n",
      "Iteration 18823, loss = 998.56751250\n",
      "Iteration 18824, loss = 998.49941238\n",
      "Iteration 18825, loss = 998.43131472\n",
      "Iteration 18826, loss = 998.36321934\n",
      "Iteration 18827, loss = 998.29512607\n",
      "Iteration 18828, loss = 998.22703474\n",
      "Iteration 18829, loss = 998.15894516\n",
      "Iteration 18830, loss = 998.09085717\n",
      "Iteration 18831, loss = 998.02277057\n",
      "Iteration 18832, loss = 997.95468518\n",
      "Iteration 18833, loss = 997.88660082\n",
      "Iteration 18834, loss = 997.81851729\n",
      "Iteration 18835, loss = 997.75043440\n",
      "Iteration 18836, loss = 997.68235195\n",
      "Iteration 18837, loss = 997.61426975\n",
      "Iteration 18838, loss = 997.54618759\n",
      "Iteration 18839, loss = 997.47810527\n",
      "Iteration 18840, loss = 997.41002258\n",
      "Iteration 18841, loss = 997.34193931\n",
      "Iteration 18842, loss = 997.27385525\n",
      "Iteration 18843, loss = 997.20577018\n",
      "Iteration 18844, loss = 997.13768388\n",
      "Iteration 18845, loss = 997.06959612\n",
      "Iteration 18846, loss = 997.00150669\n",
      "Iteration 18847, loss = 996.93341534\n",
      "Iteration 18848, loss = 996.86532184\n",
      "Iteration 18849, loss = 996.79722597\n",
      "Iteration 18850, loss = 996.72912746\n",
      "Iteration 18851, loss = 996.66102609\n",
      "Iteration 18852, loss = 996.59292160\n",
      "Iteration 18853, loss = 996.52481373\n",
      "Iteration 18854, loss = 996.45670223\n",
      "Iteration 18855, loss = 996.38858685\n",
      "Iteration 18856, loss = 996.32046731\n",
      "Iteration 18857, loss = 996.25234334\n",
      "Iteration 18858, loss = 996.18421467\n",
      "Iteration 18859, loss = 996.11608103\n",
      "Iteration 18860, loss = 996.04794212\n",
      "Iteration 18861, loss = 995.97979766\n",
      "Iteration 18862, loss = 995.91164736\n",
      "Iteration 18863, loss = 995.84349092\n",
      "Iteration 18864, loss = 995.77532804\n",
      "Iteration 18865, loss = 995.70715840\n",
      "Iteration 18866, loss = 995.63898171\n",
      "Iteration 18867, loss = 995.57079763\n",
      "Iteration 18868, loss = 995.50260584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18869, loss = 995.43440602\n",
      "Iteration 18870, loss = 995.36619782\n",
      "Iteration 18871, loss = 995.29798092\n",
      "Iteration 18872, loss = 995.22975495\n",
      "Iteration 18873, loss = 995.16151957\n",
      "Iteration 18874, loss = 995.09327442\n",
      "Iteration 18875, loss = 995.02501912\n",
      "Iteration 18876, loss = 994.95675332\n",
      "Iteration 18877, loss = 994.88847662\n",
      "Iteration 18878, loss = 994.82018864\n",
      "Iteration 18879, loss = 994.75188898\n",
      "Iteration 18880, loss = 994.68357725\n",
      "Iteration 18881, loss = 994.61525304\n",
      "Iteration 18882, loss = 994.54691593\n",
      "Iteration 18883, loss = 994.47856549\n",
      "Iteration 18884, loss = 994.41020129\n",
      "Iteration 18885, loss = 994.34182289\n",
      "Iteration 18886, loss = 994.27342985\n",
      "Iteration 18887, loss = 994.20502170\n",
      "Iteration 18888, loss = 994.13659798\n",
      "Iteration 18889, loss = 994.06815820\n",
      "Iteration 18890, loss = 993.99970190\n",
      "Iteration 18891, loss = 993.93122856\n",
      "Iteration 18892, loss = 993.86273769\n",
      "Iteration 18893, loss = 993.79422876\n",
      "Iteration 18894, loss = 993.72570126\n",
      "Iteration 18895, loss = 993.65715464\n",
      "Iteration 18896, loss = 993.58858837\n",
      "Iteration 18897, loss = 993.52000187\n",
      "Iteration 18898, loss = 993.45139458\n",
      "Iteration 18899, loss = 993.38276591\n",
      "Iteration 18900, loss = 993.31411528\n",
      "Iteration 18901, loss = 993.24544207\n",
      "Iteration 18902, loss = 993.17674566\n",
      "Iteration 18903, loss = 993.10802542\n",
      "Iteration 18904, loss = 993.03928070\n",
      "Iteration 18905, loss = 992.97051083\n",
      "Iteration 18906, loss = 992.90171515\n",
      "Iteration 18907, loss = 992.83289296\n",
      "Iteration 18908, loss = 992.76404355\n",
      "Iteration 18909, loss = 992.69516620\n",
      "Iteration 18910, loss = 992.62626016\n",
      "Iteration 18911, loss = 992.55732470\n",
      "Iteration 18912, loss = 992.48835902\n",
      "Iteration 18913, loss = 992.41936234\n",
      "Iteration 18914, loss = 992.35033386\n",
      "Iteration 18915, loss = 992.28127273\n",
      "Iteration 18916, loss = 992.21217811\n",
      "Iteration 18917, loss = 992.14304914\n",
      "Iteration 18918, loss = 992.07388492\n",
      "Iteration 18919, loss = 992.00468455\n",
      "Iteration 18920, loss = 991.93544708\n",
      "Iteration 18921, loss = 991.86617157\n",
      "Iteration 18922, loss = 991.79685704\n",
      "Iteration 18923, loss = 991.72750247\n",
      "Iteration 18924, loss = 991.65810685\n",
      "Iteration 18925, loss = 991.58866911\n",
      "Iteration 18926, loss = 991.51918818\n",
      "Iteration 18927, loss = 991.44966294\n",
      "Iteration 18928, loss = 991.38009227\n",
      "Iteration 18929, loss = 991.31047498\n",
      "Iteration 18930, loss = 991.24080988\n",
      "Iteration 18931, loss = 991.17109574\n",
      "Iteration 18932, loss = 991.10133129\n",
      "Iteration 18933, loss = 991.03151525\n",
      "Iteration 18934, loss = 990.96164628\n",
      "Iteration 18935, loss = 990.89172300\n",
      "Iteration 18936, loss = 990.82174401\n",
      "Iteration 18937, loss = 990.75170787\n",
      "Iteration 18938, loss = 990.68161310\n",
      "Iteration 18939, loss = 990.61145815\n",
      "Iteration 18940, loss = 990.54124146\n",
      "Iteration 18941, loss = 990.47096141\n",
      "Iteration 18942, loss = 990.40061634\n",
      "Iteration 18943, loss = 990.33020454\n",
      "Iteration 18944, loss = 990.25972424\n",
      "Iteration 18945, loss = 990.18917362\n",
      "Iteration 18946, loss = 990.11855082\n",
      "Iteration 18947, loss = 990.04785391\n",
      "Iteration 18948, loss = 989.97708089\n",
      "Iteration 18949, loss = 989.90622973\n",
      "Iteration 18950, loss = 989.83529831\n",
      "Iteration 18951, loss = 989.76428446\n",
      "Iteration 18952, loss = 989.69318591\n",
      "Iteration 18953, loss = 989.62200037\n",
      "Iteration 18954, loss = 989.55072542\n",
      "Iteration 18955, loss = 989.47935860\n",
      "Iteration 18956, loss = 989.40789735\n",
      "Iteration 18957, loss = 989.33633903\n",
      "Iteration 18958, loss = 989.26468091\n",
      "Iteration 18959, loss = 989.19292016\n",
      "Iteration 18960, loss = 989.12105388\n",
      "Iteration 18961, loss = 989.04907902\n",
      "Iteration 18962, loss = 988.97699248\n",
      "Iteration 18963, loss = 988.90479100\n",
      "Iteration 18964, loss = 988.83247124\n",
      "Iteration 18965, loss = 988.76002971\n",
      "Iteration 18966, loss = 988.68746280\n",
      "Iteration 18967, loss = 988.61476679\n",
      "Iteration 18968, loss = 988.54193779\n",
      "Iteration 18969, loss = 988.46897177\n",
      "Iteration 18970, loss = 988.39586455\n",
      "Iteration 18971, loss = 988.32261178\n",
      "Iteration 18972, loss = 988.24920896\n",
      "Iteration 18973, loss = 988.17565138\n",
      "Iteration 18974, loss = 988.10193416\n",
      "Iteration 18975, loss = 988.02805222\n",
      "Iteration 18976, loss = 987.95400026\n",
      "Iteration 18977, loss = 987.87977276\n",
      "Iteration 18978, loss = 987.80536398\n",
      "Iteration 18979, loss = 987.73076792\n",
      "Iteration 18980, loss = 987.65597832\n",
      "Iteration 18981, loss = 987.58098865\n",
      "Iteration 18982, loss = 987.50579208\n",
      "Iteration 18983, loss = 987.43038148\n",
      "Iteration 18984, loss = 987.35474937\n",
      "Iteration 18985, loss = 987.27888796\n",
      "Iteration 18986, loss = 987.20278906\n",
      "Iteration 18987, loss = 987.12644409\n",
      "Iteration 18988, loss = 987.04984406\n",
      "Iteration 18989, loss = 986.97297954\n",
      "Iteration 18990, loss = 986.89584060\n",
      "Iteration 18991, loss = 986.81841683\n",
      "Iteration 18992, loss = 986.74069728\n",
      "Iteration 18993, loss = 986.66267038\n",
      "Iteration 18994, loss = 986.58432400\n",
      "Iteration 18995, loss = 986.50564530\n",
      "Iteration 18996, loss = 986.42662075\n",
      "Iteration 18997, loss = 986.34723604\n",
      "Iteration 18998, loss = 986.26747605\n",
      "Iteration 18999, loss = 986.18732474\n",
      "Iteration 19000, loss = 986.10676516\n",
      "Iteration 19001, loss = 986.02577928\n",
      "Iteration 19002, loss = 985.94434795\n",
      "Iteration 19003, loss = 985.86245084\n",
      "Iteration 19004, loss = 985.78006624\n",
      "Iteration 19005, loss = 985.69717104\n",
      "Iteration 19006, loss = 985.61374055\n",
      "Iteration 19007, loss = 985.52974833\n",
      "Iteration 19008, loss = 985.44516611\n",
      "Iteration 19009, loss = 985.35996349\n",
      "Iteration 19010, loss = 985.27410785\n",
      "Iteration 19011, loss = 985.18756402\n",
      "Iteration 19012, loss = 985.10029405\n",
      "Iteration 19013, loss = 985.01225690\n",
      "Iteration 19014, loss = 984.92340811\n",
      "Iteration 19015, loss = 984.83369932\n",
      "Iteration 19016, loss = 984.74307791\n",
      "Iteration 19017, loss = 984.65148633\n",
      "Iteration 19018, loss = 984.55886158\n",
      "Iteration 19019, loss = 984.46513434\n",
      "Iteration 19020, loss = 984.37022815\n",
      "Iteration 19021, loss = 984.27405832\n",
      "Iteration 19022, loss = 984.17653062\n",
      "Iteration 19023, loss = 984.07753970\n",
      "Iteration 19024, loss = 983.97696718\n",
      "Iteration 19025, loss = 983.87467921\n",
      "Iteration 19026, loss = 983.77052344\n",
      "Iteration 19027, loss = 983.66432518\n",
      "Iteration 19028, loss = 983.55588231\n",
      "Iteration 19029, loss = 983.44495871\n",
      "Iteration 19030, loss = 983.33127534\n",
      "Iteration 19031, loss = 983.21449803\n",
      "Iteration 19032, loss = 983.09422047\n",
      "Iteration 19033, loss = 982.96994002\n",
      "Iteration 19034, loss = 982.84102297\n",
      "Iteration 19035, loss = 982.70665482\n",
      "Iteration 19036, loss = 982.56577203\n",
      "Iteration 19037, loss = 982.41697906\n",
      "Iteration 19038, loss = 982.25847896\n",
      "Iteration 19039, loss = 982.08809039\n",
      "Iteration 19040, loss = 981.90343982\n",
      "Iteration 19041, loss = 981.70229899\n",
      "Iteration 19042, loss = 981.48286484\n",
      "Iteration 19043, loss = 981.24384556\n",
      "Iteration 19044, loss = 980.98443152\n",
      "Iteration 19045, loss = 980.70426314\n",
      "Iteration 19046, loss = 980.40342277\n",
      "Iteration 19047, loss = 980.08243182\n",
      "Iteration 19048, loss = 979.74223492\n",
      "Iteration 19049, loss = 979.38416569\n",
      "Iteration 19050, loss = 979.00989457\n",
      "Iteration 19051, loss = 978.62136320\n",
      "Iteration 19052, loss = 978.22071062\n",
      "Iteration 19053, loss = 977.81019641\n",
      "Iteration 19054, loss = 977.39212575\n",
      "Iteration 19055, loss = 976.96877996\n",
      "Iteration 19056, loss = 976.54235568\n",
      "Iteration 19057, loss = 976.11491433\n",
      "Iteration 19058, loss = 975.68834297\n",
      "Iteration 19059, loss = 975.26432662\n",
      "Iteration 19060, loss = 974.84433152\n",
      "Iteration 19061, loss = 974.42959823\n",
      "Iteration 19062, loss = 974.02114333\n",
      "Iteration 19063, loss = 973.61976791\n",
      "Iteration 19064, loss = 973.22607154\n",
      "Iteration 19065, loss = 972.84046993\n",
      "Iteration 19066, loss = 972.46321495\n",
      "Iteration 19067, loss = 972.09441585\n",
      "Iteration 19068, loss = 971.73406049\n",
      "Iteration 19069, loss = 971.38203605\n",
      "Iteration 19070, loss = 971.03814831\n",
      "Iteration 19071, loss = 970.70213938\n",
      "Iteration 19072, loss = 970.37370356\n",
      "Iteration 19073, loss = 970.05250112\n",
      "Iteration 19074, loss = 969.73817016\n",
      "Iteration 19075, loss = 969.43033662\n",
      "Iteration 19076, loss = 969.12862241\n",
      "Iteration 19077, loss = 968.83265204\n",
      "Iteration 19078, loss = 968.54205778\n",
      "Iteration 19079, loss = 968.25648368\n",
      "Iteration 19080, loss = 967.97558839\n",
      "Iteration 19081, loss = 967.69904728\n",
      "Iteration 19082, loss = 967.42655369\n",
      "Iteration 19083, loss = 967.15781971\n",
      "Iteration 19084, loss = 966.89257642\n",
      "Iteration 19085, loss = 966.63057377\n",
      "Iteration 19086, loss = 966.37158026\n",
      "Iteration 19087, loss = 966.11538229\n",
      "Iteration 19088, loss = 965.86178347\n",
      "Iteration 19089, loss = 965.61060382\n",
      "Iteration 19090, loss = 965.36167879\n",
      "Iteration 19091, loss = 965.11485844\n",
      "Iteration 19092, loss = 964.87000644\n",
      "Iteration 19093, loss = 964.62699916\n",
      "Iteration 19094, loss = 964.38572478\n",
      "Iteration 19095, loss = 964.14608242\n",
      "Iteration 19096, loss = 963.90798124\n",
      "Iteration 19097, loss = 963.67133973\n",
      "Iteration 19098, loss = 963.43608487\n",
      "Iteration 19099, loss = 963.20215146\n",
      "Iteration 19100, loss = 962.96948139\n",
      "Iteration 19101, loss = 962.73802308\n",
      "Iteration 19102, loss = 962.50773080\n",
      "Iteration 19103, loss = 962.27856416\n",
      "Iteration 19104, loss = 962.05048757\n",
      "Iteration 19105, loss = 961.82346974\n",
      "Iteration 19106, loss = 961.59748324\n",
      "Iteration 19107, loss = 961.37250405\n",
      "Iteration 19108, loss = 961.14851120\n",
      "Iteration 19109, loss = 960.92548634\n",
      "Iteration 19110, loss = 960.70341343\n",
      "Iteration 19111, loss = 960.48227842\n",
      "Iteration 19112, loss = 960.26206895\n",
      "Iteration 19113, loss = 960.04277406\n",
      "Iteration 19114, loss = 959.82438394\n",
      "Iteration 19115, loss = 959.60688971\n",
      "Iteration 19116, loss = 959.39028322\n",
      "Iteration 19117, loss = 959.17455683\n",
      "Iteration 19118, loss = 958.95970325\n",
      "Iteration 19119, loss = 958.74571540\n",
      "Iteration 19120, loss = 958.53258625\n",
      "Iteration 19121, loss = 958.32030876\n",
      "Iteration 19122, loss = 958.10887572\n",
      "Iteration 19123, loss = 957.89827971\n",
      "Iteration 19124, loss = 957.68851302\n",
      "Iteration 19125, loss = 957.47956764\n",
      "Iteration 19126, loss = 957.27143515\n",
      "Iteration 19127, loss = 957.06410682\n",
      "Iteration 19128, loss = 956.85757349\n",
      "Iteration 19129, loss = 956.65182565\n",
      "Iteration 19130, loss = 956.44685344\n",
      "Iteration 19131, loss = 956.24264668\n",
      "Iteration 19132, loss = 956.03919490\n",
      "Iteration 19133, loss = 955.83648740\n",
      "Iteration 19134, loss = 955.63451327\n",
      "Iteration 19135, loss = 955.43326147\n",
      "Iteration 19136, loss = 955.23272087\n",
      "Iteration 19137, loss = 955.03288031\n",
      "Iteration 19138, loss = 954.83372865\n",
      "Iteration 19139, loss = 954.63525482\n",
      "Iteration 19140, loss = 954.43744789\n",
      "Iteration 19141, loss = 954.24029707\n",
      "Iteration 19142, loss = 954.04379181\n",
      "Iteration 19143, loss = 953.84792179\n",
      "Iteration 19144, loss = 953.65267695\n",
      "Iteration 19145, loss = 953.45804757\n",
      "Iteration 19146, loss = 953.26402422\n",
      "Iteration 19147, loss = 953.07059781\n",
      "Iteration 19148, loss = 952.87775957\n",
      "Iteration 19149, loss = 952.68550111\n",
      "Iteration 19150, loss = 952.49381434\n",
      "Iteration 19151, loss = 952.30269150\n",
      "Iteration 19152, loss = 952.11212518\n",
      "Iteration 19153, loss = 951.92210823\n",
      "Iteration 19154, loss = 951.73263383\n",
      "Iteration 19155, loss = 951.54369539\n",
      "Iteration 19156, loss = 951.35528659\n",
      "Iteration 19157, loss = 951.16740133\n",
      "Iteration 19158, loss = 950.98003373\n",
      "Iteration 19159, loss = 950.79317807\n",
      "Iteration 19160, loss = 950.60682884\n",
      "Iteration 19161, loss = 950.42098064\n",
      "Iteration 19162, loss = 950.23562824\n",
      "Iteration 19163, loss = 950.05076649\n",
      "Iteration 19164, loss = 949.86639039\n",
      "Iteration 19165, loss = 949.68249499\n",
      "Iteration 19166, loss = 949.49907547\n",
      "Iteration 19167, loss = 949.31612706\n",
      "Iteration 19168, loss = 949.13364507\n",
      "Iteration 19169, loss = 948.95162487\n",
      "Iteration 19170, loss = 948.77006189\n",
      "Iteration 19171, loss = 948.58895164\n",
      "Iteration 19172, loss = 948.40828966\n",
      "Iteration 19173, loss = 948.22807158\n",
      "Iteration 19174, loss = 948.04829306\n",
      "Iteration 19175, loss = 947.86894983\n",
      "Iteration 19176, loss = 947.69003768\n",
      "Iteration 19177, loss = 947.51155247\n",
      "Iteration 19178, loss = 947.33349009\n",
      "Iteration 19179, loss = 947.15584654\n",
      "Iteration 19180, loss = 946.97861783\n",
      "Iteration 19181, loss = 946.80180008\n",
      "Iteration 19182, loss = 946.62538944\n",
      "Iteration 19183, loss = 946.44938215\n",
      "Iteration 19184, loss = 946.27377449\n",
      "Iteration 19185, loss = 946.09856283\n",
      "Iteration 19186, loss = 945.92374357\n",
      "Iteration 19187, loss = 945.74931320\n",
      "Iteration 19188, loss = 945.57526827\n",
      "Iteration 19189, loss = 945.40160536\n",
      "Iteration 19190, loss = 945.22832115\n",
      "Iteration 19191, loss = 945.05541234\n",
      "Iteration 19192, loss = 944.88287571\n",
      "Iteration 19193, loss = 944.71070808\n",
      "Iteration 19194, loss = 944.53890633\n",
      "Iteration 19195, loss = 944.36746737\n",
      "Iteration 19196, loss = 944.19638819\n",
      "Iteration 19197, loss = 944.02566580\n",
      "Iteration 19198, loss = 943.85529727\n",
      "Iteration 19199, loss = 943.68527971\n",
      "Iteration 19200, loss = 943.51561028\n",
      "Iteration 19201, loss = 943.34628616\n",
      "Iteration 19202, loss = 943.17730460\n",
      "Iteration 19203, loss = 943.00866287\n",
      "Iteration 19204, loss = 942.84035828\n",
      "Iteration 19205, loss = 942.67238819\n",
      "Iteration 19206, loss = 942.50474998\n",
      "Iteration 19207, loss = 942.33744108\n",
      "Iteration 19208, loss = 942.17045896\n",
      "Iteration 19209, loss = 942.00380111\n",
      "Iteration 19210, loss = 941.83746507\n",
      "Iteration 19211, loss = 941.67144840\n",
      "Iteration 19212, loss = 941.50574870\n",
      "Iteration 19213, loss = 941.34036361\n",
      "Iteration 19214, loss = 941.17529080\n",
      "Iteration 19215, loss = 941.01052796\n",
      "Iteration 19216, loss = 940.84607283\n",
      "Iteration 19217, loss = 940.68192317\n",
      "Iteration 19218, loss = 940.51807677\n",
      "Iteration 19219, loss = 940.35453146\n",
      "Iteration 19220, loss = 940.19128509\n",
      "Iteration 19221, loss = 940.02833554\n",
      "Iteration 19222, loss = 939.86568073\n",
      "Iteration 19223, loss = 939.70331859\n",
      "Iteration 19224, loss = 939.54124709\n",
      "Iteration 19225, loss = 939.37946421\n",
      "Iteration 19226, loss = 939.21796800\n",
      "Iteration 19227, loss = 939.05675647\n",
      "Iteration 19228, loss = 938.89582772\n",
      "Iteration 19229, loss = 938.73517982\n",
      "Iteration 19230, loss = 938.57481092\n",
      "Iteration 19231, loss = 938.41471913\n",
      "Iteration 19232, loss = 938.25490264\n",
      "Iteration 19233, loss = 938.09535963\n",
      "Iteration 19234, loss = 937.93608832\n",
      "Iteration 19235, loss = 937.77708693\n",
      "Iteration 19236, loss = 937.61835373\n",
      "Iteration 19237, loss = 937.45988699\n",
      "Iteration 19238, loss = 937.30168502\n",
      "Iteration 19239, loss = 937.14374612\n",
      "Iteration 19240, loss = 936.98606863\n",
      "Iteration 19241, loss = 936.82865093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19242, loss = 936.67149137\n",
      "Iteration 19243, loss = 936.51458837\n",
      "Iteration 19244, loss = 936.35794033\n",
      "Iteration 19245, loss = 936.20154569\n",
      "Iteration 19246, loss = 936.04540291\n",
      "Iteration 19247, loss = 935.88951044\n",
      "Iteration 19248, loss = 935.73386679\n",
      "Iteration 19249, loss = 935.57847046\n",
      "Iteration 19250, loss = 935.42331996\n",
      "Iteration 19251, loss = 935.26841383\n",
      "Iteration 19252, loss = 935.11375064\n",
      "Iteration 19253, loss = 934.95932896\n",
      "Iteration 19254, loss = 934.80514736\n",
      "Iteration 19255, loss = 934.65120445\n",
      "Iteration 19256, loss = 934.49749886\n",
      "Iteration 19257, loss = 934.34402921\n",
      "Iteration 19258, loss = 934.19079416\n",
      "Iteration 19259, loss = 934.03779236\n",
      "Iteration 19260, loss = 933.88502250\n",
      "Iteration 19261, loss = 933.73248326\n",
      "Iteration 19262, loss = 933.58017336\n",
      "Iteration 19263, loss = 933.42809151\n",
      "Iteration 19264, loss = 933.27623644\n",
      "Iteration 19265, loss = 933.12460690\n",
      "Iteration 19266, loss = 932.97320165\n",
      "Iteration 19267, loss = 932.82201947\n",
      "Iteration 19268, loss = 932.67105913\n",
      "Iteration 19269, loss = 932.52031945\n",
      "Iteration 19270, loss = 932.36979921\n",
      "Iteration 19271, loss = 932.21949726\n",
      "Iteration 19272, loss = 932.06941242\n",
      "Iteration 19273, loss = 931.91954355\n",
      "Iteration 19274, loss = 931.76988949\n",
      "Iteration 19275, loss = 931.62044912\n",
      "Iteration 19276, loss = 931.47122132\n",
      "Iteration 19277, loss = 931.32220498\n",
      "Iteration 19278, loss = 931.17339901\n",
      "Iteration 19279, loss = 931.02480232\n",
      "Iteration 19280, loss = 930.87641383\n",
      "Iteration 19281, loss = 930.72823247\n",
      "Iteration 19282, loss = 930.58025721\n",
      "Iteration 19283, loss = 930.43248698\n",
      "Iteration 19284, loss = 930.28492076\n",
      "Iteration 19285, loss = 930.13755752\n",
      "Iteration 19286, loss = 929.99039625\n",
      "Iteration 19287, loss = 929.84343595\n",
      "Iteration 19288, loss = 929.69667561\n",
      "Iteration 19289, loss = 929.55011426\n",
      "Iteration 19290, loss = 929.40375091\n",
      "Iteration 19291, loss = 929.25758460\n",
      "Iteration 19292, loss = 929.11161438\n",
      "Iteration 19293, loss = 928.96583928\n",
      "Iteration 19294, loss = 928.82025838\n",
      "Iteration 19295, loss = 928.67487073\n",
      "Iteration 19296, loss = 928.52967543\n",
      "Iteration 19297, loss = 928.38467154\n",
      "Iteration 19298, loss = 928.23985817\n",
      "Iteration 19299, loss = 928.09523441\n",
      "Iteration 19300, loss = 927.95079938\n",
      "Iteration 19301, loss = 927.80655220\n",
      "Iteration 19302, loss = 927.66249198\n",
      "Iteration 19303, loss = 927.51861787\n",
      "Iteration 19304, loss = 927.37492900\n",
      "Iteration 19305, loss = 927.23142452\n",
      "Iteration 19306, loss = 927.08810359\n",
      "Iteration 19307, loss = 926.94496538\n",
      "Iteration 19308, loss = 926.80200904\n",
      "Iteration 19309, loss = 926.65923377\n",
      "Iteration 19310, loss = 926.51663874\n",
      "Iteration 19311, loss = 926.37422315\n",
      "Iteration 19312, loss = 926.23198619\n",
      "Iteration 19313, loss = 926.08992708\n",
      "Iteration 19314, loss = 925.94804502\n",
      "Iteration 19315, loss = 925.80633923\n",
      "Iteration 19316, loss = 925.66480895\n",
      "Iteration 19317, loss = 925.52345339\n",
      "Iteration 19318, loss = 925.38227181\n",
      "Iteration 19319, loss = 925.24126344\n",
      "Iteration 19320, loss = 925.10042753\n",
      "Iteration 19321, loss = 924.95976336\n",
      "Iteration 19322, loss = 924.81927016\n",
      "Iteration 19323, loss = 924.67894723\n",
      "Iteration 19324, loss = 924.53879383\n",
      "Iteration 19325, loss = 924.39880924\n",
      "Iteration 19326, loss = 924.25899275\n",
      "Iteration 19327, loss = 924.11934366\n",
      "Iteration 19328, loss = 923.97986126\n",
      "Iteration 19329, loss = 923.84054486\n",
      "Iteration 19330, loss = 923.70139376\n",
      "Iteration 19331, loss = 923.56240729\n",
      "Iteration 19332, loss = 923.42358476\n",
      "Iteration 19333, loss = 923.28492550\n",
      "Iteration 19334, loss = 923.14642884\n",
      "Iteration 19335, loss = 923.00809411\n",
      "Iteration 19336, loss = 922.86992067\n",
      "Iteration 19337, loss = 922.73190784\n",
      "Iteration 19338, loss = 922.59405500\n",
      "Iteration 19339, loss = 922.45636149\n",
      "Iteration 19340, loss = 922.31882668\n",
      "Iteration 19341, loss = 922.18144993\n",
      "Iteration 19342, loss = 922.04423061\n",
      "Iteration 19343, loss = 921.90716811\n",
      "Iteration 19344, loss = 921.77026180\n",
      "Iteration 19345, loss = 921.63351106\n",
      "Iteration 19346, loss = 921.49691529\n",
      "Iteration 19347, loss = 921.36047389\n",
      "Iteration 19348, loss = 921.22418624\n",
      "Iteration 19349, loss = 921.08805176\n",
      "Iteration 19350, loss = 920.95206986\n",
      "Iteration 19351, loss = 920.81623994\n",
      "Iteration 19352, loss = 920.68056142\n",
      "Iteration 19353, loss = 920.54503373\n",
      "Iteration 19354, loss = 920.40965629\n",
      "Iteration 19355, loss = 920.27442853\n",
      "Iteration 19356, loss = 920.13934988\n",
      "Iteration 19357, loss = 920.00441978\n",
      "Iteration 19358, loss = 919.86963767\n",
      "Iteration 19359, loss = 919.73500300\n",
      "Iteration 19360, loss = 919.60051522\n",
      "Iteration 19361, loss = 919.46617379\n",
      "Iteration 19362, loss = 919.33197815\n",
      "Iteration 19363, loss = 919.19792777\n",
      "Iteration 19364, loss = 919.06402211\n",
      "Iteration 19365, loss = 918.93026065\n",
      "Iteration 19366, loss = 918.79664286\n",
      "Iteration 19367, loss = 918.66316821\n",
      "Iteration 19368, loss = 918.52983619\n",
      "Iteration 19369, loss = 918.39664627\n",
      "Iteration 19370, loss = 918.26359794\n",
      "Iteration 19371, loss = 918.13069070\n",
      "Iteration 19372, loss = 917.99792404\n",
      "Iteration 19373, loss = 917.86529745\n",
      "Iteration 19374, loss = 917.73281044\n",
      "Iteration 19375, loss = 917.60046251\n",
      "Iteration 19376, loss = 917.46825317\n",
      "Iteration 19377, loss = 917.33618193\n",
      "Iteration 19378, loss = 917.20424830\n",
      "Iteration 19379, loss = 917.07245181\n",
      "Iteration 19380, loss = 916.94079196\n",
      "Iteration 19381, loss = 916.80926829\n",
      "Iteration 19382, loss = 916.67788033\n",
      "Iteration 19383, loss = 916.54662760\n",
      "Iteration 19384, loss = 916.41550963\n",
      "Iteration 19385, loss = 916.28452597\n",
      "Iteration 19386, loss = 916.15367615\n",
      "Iteration 19387, loss = 916.02295971\n",
      "Iteration 19388, loss = 915.89237620\n",
      "Iteration 19389, loss = 915.76192517\n",
      "Iteration 19390, loss = 915.63160617\n",
      "Iteration 19391, loss = 915.50141875\n",
      "Iteration 19392, loss = 915.37136247\n",
      "Iteration 19393, loss = 915.24143690\n",
      "Iteration 19394, loss = 915.11164158\n",
      "Iteration 19395, loss = 914.98197609\n",
      "Iteration 19396, loss = 914.85243999\n",
      "Iteration 19397, loss = 914.72303287\n",
      "Iteration 19398, loss = 914.59375428\n",
      "Iteration 19399, loss = 914.46460380\n",
      "Iteration 19400, loss = 914.33558103\n",
      "Iteration 19401, loss = 914.20668552\n",
      "Iteration 19402, loss = 914.07791688\n",
      "Iteration 19403, loss = 913.94927468\n",
      "Iteration 19404, loss = 913.82075852\n",
      "Iteration 19405, loss = 913.69236799\n",
      "Iteration 19406, loss = 913.56410268\n",
      "Iteration 19407, loss = 913.43596218\n",
      "Iteration 19408, loss = 913.30794610\n",
      "Iteration 19409, loss = 913.18005404\n",
      "Iteration 19410, loss = 913.05228561\n",
      "Iteration 19411, loss = 912.92464040\n",
      "Iteration 19412, loss = 912.79711803\n",
      "Iteration 19413, loss = 912.66971811\n",
      "Iteration 19414, loss = 912.54244025\n",
      "Iteration 19415, loss = 912.41528407\n",
      "Iteration 19416, loss = 912.28824918\n",
      "Iteration 19417, loss = 912.16133521\n",
      "Iteration 19418, loss = 912.03454177\n",
      "Iteration 19419, loss = 911.90786850\n",
      "Iteration 19420, loss = 911.78131502\n",
      "Iteration 19421, loss = 911.65488096\n",
      "Iteration 19422, loss = 911.52856595\n",
      "Iteration 19423, loss = 911.40236962\n",
      "Iteration 19424, loss = 911.27629161\n",
      "Iteration 19425, loss = 911.15033156\n",
      "Iteration 19426, loss = 911.02448910\n",
      "Iteration 19427, loss = 910.89876389\n",
      "Iteration 19428, loss = 910.77315555\n",
      "Iteration 19429, loss = 910.64766374\n",
      "Iteration 19430, loss = 910.52228811\n",
      "Iteration 19431, loss = 910.39702830\n",
      "Iteration 19432, loss = 910.27188397\n",
      "Iteration 19433, loss = 910.14685478\n",
      "Iteration 19434, loss = 910.02194037\n",
      "Iteration 19435, loss = 909.89714040\n",
      "Iteration 19436, loss = 909.77245454\n",
      "Iteration 19437, loss = 909.64788245\n",
      "Iteration 19438, loss = 909.52342378\n",
      "Iteration 19439, loss = 909.39907821\n",
      "Iteration 19440, loss = 909.27484541\n",
      "Iteration 19441, loss = 909.15072503\n",
      "Iteration 19442, loss = 909.02671676\n",
      "Iteration 19443, loss = 908.90282026\n",
      "Iteration 19444, loss = 908.77903521\n",
      "Iteration 19445, loss = 908.65536129\n",
      "Iteration 19446, loss = 908.53179817\n",
      "Iteration 19447, loss = 908.40834554\n",
      "Iteration 19448, loss = 908.28500307\n",
      "Iteration 19449, loss = 908.16177044\n",
      "Iteration 19450, loss = 908.03864735\n",
      "Iteration 19451, loss = 907.91563349\n",
      "Iteration 19452, loss = 907.79272852\n",
      "Iteration 19453, loss = 907.66993216\n",
      "Iteration 19454, loss = 907.54724409\n",
      "Iteration 19455, loss = 907.42466400\n",
      "Iteration 19456, loss = 907.30219159\n",
      "Iteration 19457, loss = 907.17982655\n",
      "Iteration 19458, loss = 907.05756858\n",
      "Iteration 19459, loss = 906.93541739\n",
      "Iteration 19460, loss = 906.81337267\n",
      "Iteration 19461, loss = 906.69143413\n",
      "Iteration 19462, loss = 906.56960146\n",
      "Iteration 19463, loss = 906.44787439\n",
      "Iteration 19464, loss = 906.32625261\n",
      "Iteration 19465, loss = 906.20473583\n",
      "Iteration 19466, loss = 906.08332377\n",
      "Iteration 19467, loss = 905.96201613\n",
      "Iteration 19468, loss = 905.84081263\n",
      "Iteration 19469, loss = 905.71971299\n",
      "Iteration 19470, loss = 905.59871691\n",
      "Iteration 19471, loss = 905.47782413\n",
      "Iteration 19472, loss = 905.35703435\n",
      "Iteration 19473, loss = 905.23634730\n",
      "Iteration 19474, loss = 905.11576271\n",
      "Iteration 19475, loss = 904.99528028\n",
      "Iteration 19476, loss = 904.87489976\n",
      "Iteration 19477, loss = 904.75462086\n",
      "Iteration 19478, loss = 904.63444331\n",
      "Iteration 19479, loss = 904.51436685\n",
      "Iteration 19480, loss = 904.39439120\n",
      "Iteration 19481, loss = 904.27451609\n",
      "Iteration 19482, loss = 904.15474126\n",
      "Iteration 19483, loss = 904.03506645\n",
      "Iteration 19484, loss = 903.91549138\n",
      "Iteration 19485, loss = 903.79601579\n",
      "Iteration 19486, loss = 903.67663943\n",
      "Iteration 19487, loss = 903.55736203\n",
      "Iteration 19488, loss = 903.43818333\n",
      "Iteration 19489, loss = 903.31910308\n",
      "Iteration 19490, loss = 903.20012102\n",
      "Iteration 19491, loss = 903.08123689\n",
      "Iteration 19492, loss = 902.96245044\n",
      "Iteration 19493, loss = 902.84376142\n",
      "Iteration 19494, loss = 902.72516957\n",
      "Iteration 19495, loss = 902.60667465\n",
      "Iteration 19496, loss = 902.48827640\n",
      "Iteration 19497, loss = 902.36997457\n",
      "Iteration 19498, loss = 902.25176893\n",
      "Iteration 19499, loss = 902.13365922\n",
      "Iteration 19500, loss = 902.01564521\n",
      "Iteration 19501, loss = 901.89772663\n",
      "Iteration 19502, loss = 901.77990327\n",
      "Iteration 19503, loss = 901.66217486\n",
      "Iteration 19504, loss = 901.54454118\n",
      "Iteration 19505, loss = 901.42700198\n",
      "Iteration 19506, loss = 901.30955703\n",
      "Iteration 19507, loss = 901.19220609\n",
      "Iteration 19508, loss = 901.07494892\n",
      "Iteration 19509, loss = 900.95778529\n",
      "Iteration 19510, loss = 900.84071497\n",
      "Iteration 19511, loss = 900.72373772\n",
      "Iteration 19512, loss = 900.60685332\n",
      "Iteration 19513, loss = 900.49006153\n",
      "Iteration 19514, loss = 900.37336212\n",
      "Iteration 19515, loss = 900.25675487\n",
      "Iteration 19516, loss = 900.14023955\n",
      "Iteration 19517, loss = 900.02381593\n",
      "Iteration 19518, loss = 899.90748379\n",
      "Iteration 19519, loss = 899.79124290\n",
      "Iteration 19520, loss = 899.67509304\n",
      "Iteration 19521, loss = 899.55903400\n",
      "Iteration 19522, loss = 899.44306554\n",
      "Iteration 19523, loss = 899.32718746\n",
      "Iteration 19524, loss = 899.21139952\n",
      "Iteration 19525, loss = 899.09570151\n",
      "Iteration 19526, loss = 898.98009322\n",
      "Iteration 19527, loss = 898.86457443\n",
      "Iteration 19528, loss = 898.74914493\n",
      "Iteration 19529, loss = 898.63380449\n",
      "Iteration 19530, loss = 898.51855291\n",
      "Iteration 19531, loss = 898.40338998\n",
      "Iteration 19532, loss = 898.28831548\n",
      "Iteration 19533, loss = 898.17332921\n",
      "Iteration 19534, loss = 898.05843095\n",
      "Iteration 19535, loss = 897.94362049\n",
      "Iteration 19536, loss = 897.82889763\n",
      "Iteration 19537, loss = 897.71426217\n",
      "Iteration 19538, loss = 897.59971389\n",
      "Iteration 19539, loss = 897.48525260\n",
      "Iteration 19540, loss = 897.37087808\n",
      "Iteration 19541, loss = 897.25659013\n",
      "Iteration 19542, loss = 897.14238856\n",
      "Iteration 19543, loss = 897.02827316\n",
      "Iteration 19544, loss = 896.91424373\n",
      "Iteration 19545, loss = 896.80030007\n",
      "Iteration 19546, loss = 896.68644199\n",
      "Iteration 19547, loss = 896.57266928\n",
      "Iteration 19548, loss = 896.45898174\n",
      "Iteration 19549, loss = 896.34537919\n",
      "Iteration 19550, loss = 896.23186142\n",
      "Iteration 19551, loss = 896.11842825\n",
      "Iteration 19552, loss = 896.00507947\n",
      "Iteration 19553, loss = 895.89181490\n",
      "Iteration 19554, loss = 895.77863434\n",
      "Iteration 19555, loss = 895.66553761\n",
      "Iteration 19556, loss = 895.55252450\n",
      "Iteration 19557, loss = 895.43959484\n",
      "Iteration 19558, loss = 895.32674843\n",
      "Iteration 19559, loss = 895.21398508\n",
      "Iteration 19560, loss = 895.10130461\n",
      "Iteration 19561, loss = 894.98870684\n",
      "Iteration 19562, loss = 894.87619156\n",
      "Iteration 19563, loss = 894.76375861\n",
      "Iteration 19564, loss = 894.65140780\n",
      "Iteration 19565, loss = 894.53913894\n",
      "Iteration 19566, loss = 894.42695185\n",
      "Iteration 19567, loss = 894.31484634\n",
      "Iteration 19568, loss = 894.20282225\n",
      "Iteration 19569, loss = 894.09087937\n",
      "Iteration 19570, loss = 893.97901755\n",
      "Iteration 19571, loss = 893.86723660\n",
      "Iteration 19572, loss = 893.75553633\n",
      "Iteration 19573, loss = 893.64391658\n",
      "Iteration 19574, loss = 893.53237716\n",
      "Iteration 19575, loss = 893.42091790\n",
      "Iteration 19576, loss = 893.30953863\n",
      "Iteration 19577, loss = 893.19823916\n",
      "Iteration 19578, loss = 893.08701933\n",
      "Iteration 19579, loss = 892.97587896\n",
      "Iteration 19580, loss = 892.86481788\n",
      "Iteration 19581, loss = 892.75383592\n",
      "Iteration 19582, loss = 892.64293290\n",
      "Iteration 19583, loss = 892.53210866\n",
      "Iteration 19584, loss = 892.42136303\n",
      "Iteration 19585, loss = 892.31069583\n",
      "Iteration 19586, loss = 892.20010690\n",
      "Iteration 19587, loss = 892.08959607\n",
      "Iteration 19588, loss = 891.97916317\n",
      "Iteration 19589, loss = 891.86880804\n",
      "Iteration 19590, loss = 891.75853052\n",
      "Iteration 19591, loss = 891.64833042\n",
      "Iteration 19592, loss = 891.53820760\n",
      "Iteration 19593, loss = 891.42816189\n",
      "Iteration 19594, loss = 891.31819313\n",
      "Iteration 19595, loss = 891.20830115\n",
      "Iteration 19596, loss = 891.09848582\n",
      "Iteration 19597, loss = 890.98874698\n",
      "Iteration 19598, loss = 890.87908453\n",
      "Iteration 19599, loss = 890.76949842\n",
      "Iteration 19600, loss = 890.65998871\n",
      "Iteration 19601, loss = 890.55055575\n",
      "Iteration 19602, loss = 890.44120045\n",
      "Iteration 19603, loss = 890.33192498\n",
      "Iteration 19604, loss = 890.22273384\n",
      "Iteration 19605, loss = 890.11363596\n",
      "Iteration 19606, loss = 890.00464344\n",
      "Iteration 19607, loss = 889.89576298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19608, loss = 889.78694947\n",
      "Iteration 19609, loss = 889.67809803\n",
      "Iteration 19610, loss = 889.56916525\n",
      "Iteration 19611, loss = 889.46034518\n",
      "Iteration 19612, loss = 889.35179060\n",
      "Iteration 19613, loss = 889.24336385\n",
      "Iteration 19614, loss = 889.13486568\n",
      "Iteration 19615, loss = 889.02635920\n",
      "Iteration 19616, loss = 888.91804687\n",
      "Iteration 19617, loss = 888.80988514\n",
      "Iteration 19618, loss = 888.70169751\n",
      "Iteration 19619, loss = 888.59352478\n",
      "Iteration 19620, loss = 888.48551441\n",
      "Iteration 19621, loss = 888.37761414\n",
      "Iteration 19622, loss = 888.26970809\n",
      "Iteration 19623, loss = 888.16185937\n",
      "Iteration 19624, loss = 888.05415178\n",
      "Iteration 19625, loss = 887.94651314\n",
      "Iteration 19626, loss = 887.83889165\n",
      "Iteration 19627, loss = 887.73136025\n",
      "Iteration 19628, loss = 887.62394066\n",
      "Iteration 19629, loss = 887.51656650\n",
      "Iteration 19630, loss = 887.40923963\n",
      "Iteration 19631, loss = 887.30201331\n",
      "Iteration 19632, loss = 887.19486882\n",
      "Iteration 19633, loss = 887.08776846\n",
      "Iteration 19634, loss = 886.98073952\n",
      "Iteration 19635, loss = 886.87380329\n",
      "Iteration 19636, loss = 886.76693002\n",
      "Iteration 19637, loss = 886.66011221\n",
      "Iteration 19638, loss = 886.55337633\n",
      "Iteration 19639, loss = 886.44671897\n",
      "Iteration 19640, loss = 886.34011952\n",
      "Iteration 19641, loss = 886.23358762\n",
      "Iteration 19642, loss = 886.12713631\n",
      "Iteration 19643, loss = 886.02075292\n",
      "Iteration 19644, loss = 885.91443100\n",
      "Iteration 19645, loss = 885.80818274\n",
      "Iteration 19646, loss = 885.70200886\n",
      "Iteration 19647, loss = 885.59589892\n",
      "Iteration 19648, loss = 885.48985564\n",
      "Iteration 19649, loss = 885.38388625\n",
      "Iteration 19650, loss = 885.27798579\n",
      "Iteration 19651, loss = 885.17214980\n",
      "Iteration 19652, loss = 885.06638351\n",
      "Iteration 19653, loss = 884.96068849\n",
      "Iteration 19654, loss = 884.85505969\n",
      "Iteration 19655, loss = 884.74949725\n",
      "Iteration 19656, loss = 884.64400491\n",
      "Iteration 19657, loss = 884.53858106\n",
      "Iteration 19658, loss = 884.43322293\n",
      "Iteration 19659, loss = 884.32793240\n",
      "Iteration 19660, loss = 884.22271088\n",
      "Iteration 19661, loss = 884.11755610\n",
      "Iteration 19662, loss = 884.01246738\n",
      "Iteration 19663, loss = 883.90744648\n",
      "Iteration 19664, loss = 883.80249314\n",
      "Iteration 19665, loss = 883.69760575\n",
      "Iteration 19666, loss = 883.59278474\n",
      "Iteration 19667, loss = 883.48803102\n",
      "Iteration 19668, loss = 883.38334371\n",
      "Iteration 19669, loss = 883.27872207\n",
      "Iteration 19670, loss = 883.17416675\n",
      "Iteration 19671, loss = 883.06967792\n",
      "Iteration 19672, loss = 882.96525474\n",
      "Iteration 19673, loss = 882.86089705\n",
      "Iteration 19674, loss = 882.75660533\n",
      "Iteration 19675, loss = 882.65237930\n",
      "Iteration 19676, loss = 882.54821842\n",
      "Iteration 19677, loss = 882.44412278\n",
      "Iteration 19678, loss = 882.34009257\n",
      "Iteration 19679, loss = 882.23612740\n",
      "Iteration 19680, loss = 882.13222698\n",
      "Iteration 19681, loss = 882.02839144\n",
      "Iteration 19682, loss = 881.92462075\n",
      "Iteration 19683, loss = 881.82091455\n",
      "Iteration 19684, loss = 881.71727273\n",
      "Iteration 19685, loss = 881.61369534\n",
      "Iteration 19686, loss = 881.51018225\n",
      "Iteration 19687, loss = 881.40673317\n",
      "Iteration 19688, loss = 881.30334808\n",
      "Iteration 19689, loss = 881.20002693\n",
      "Iteration 19690, loss = 881.09676956\n",
      "Iteration 19691, loss = 880.99357578\n",
      "Iteration 19692, loss = 880.89044554\n",
      "Iteration 19693, loss = 880.78737876\n",
      "Iteration 19694, loss = 880.68437528\n",
      "Iteration 19695, loss = 880.58143495\n",
      "Iteration 19696, loss = 880.47855773\n",
      "Iteration 19697, loss = 880.37574349\n",
      "Iteration 19698, loss = 880.27299208\n",
      "Iteration 19699, loss = 880.17030340\n",
      "Iteration 19700, loss = 880.06767736\n",
      "Iteration 19701, loss = 879.96511385\n",
      "Iteration 19702, loss = 879.86261273\n",
      "Iteration 19703, loss = 879.76017390\n",
      "Iteration 19704, loss = 879.65779727\n",
      "Iteration 19705, loss = 879.55548271\n",
      "Iteration 19706, loss = 879.45323010\n",
      "Iteration 19707, loss = 879.35103935\n",
      "Iteration 19708, loss = 879.24891035\n",
      "Iteration 19709, loss = 879.14684299\n",
      "Iteration 19710, loss = 879.04483714\n",
      "Iteration 19711, loss = 878.94289272\n",
      "Iteration 19712, loss = 878.84100962\n",
      "Iteration 19713, loss = 878.73918772\n",
      "Iteration 19714, loss = 878.63742691\n",
      "Iteration 19715, loss = 878.53572709\n",
      "Iteration 19716, loss = 878.43408816\n",
      "Iteration 19717, loss = 878.33251001\n",
      "Iteration 19718, loss = 878.23099252\n",
      "Iteration 19719, loss = 878.12953561\n",
      "Iteration 19720, loss = 878.02813916\n",
      "Iteration 19721, loss = 877.92680306\n",
      "Iteration 19722, loss = 877.82552721\n",
      "Iteration 19723, loss = 877.72431152\n",
      "Iteration 19724, loss = 877.62315587\n",
      "Iteration 19725, loss = 877.52206016\n",
      "Iteration 19726, loss = 877.42102429\n",
      "Iteration 19727, loss = 877.32004816\n",
      "Iteration 19728, loss = 877.21913166\n",
      "Iteration 19729, loss = 877.11827468\n",
      "Iteration 19730, loss = 877.01747714\n",
      "Iteration 19731, loss = 876.91673893\n",
      "Iteration 19732, loss = 876.81605994\n",
      "Iteration 19733, loss = 876.71544008\n",
      "Iteration 19734, loss = 876.61487924\n",
      "Iteration 19735, loss = 876.51437733\n",
      "Iteration 19736, loss = 876.41393425\n",
      "Iteration 19737, loss = 876.31354989\n",
      "Iteration 19738, loss = 876.21322415\n",
      "Iteration 19739, loss = 876.11295694\n",
      "Iteration 19740, loss = 876.01274816\n",
      "Iteration 19741, loss = 875.91259771\n",
      "Iteration 19742, loss = 875.81250549\n",
      "Iteration 19743, loss = 875.71247141\n",
      "Iteration 19744, loss = 875.61249536\n",
      "Iteration 19745, loss = 875.51257725\n",
      "Iteration 19746, loss = 875.41271699\n",
      "Iteration 19747, loss = 875.31291447\n",
      "Iteration 19748, loss = 875.21316960\n",
      "Iteration 19749, loss = 875.11348228\n",
      "Iteration 19750, loss = 875.01385242\n",
      "Iteration 19751, loss = 874.91427992\n",
      "Iteration 19752, loss = 874.81476469\n",
      "Iteration 19753, loss = 874.71530663\n",
      "Iteration 19754, loss = 874.61590565\n",
      "Iteration 19755, loss = 874.51656165\n",
      "Iteration 19756, loss = 874.41727455\n",
      "Iteration 19757, loss = 874.31804423\n",
      "Iteration 19758, loss = 874.21887062\n",
      "Iteration 19759, loss = 874.11975362\n",
      "Iteration 19760, loss = 874.02069313\n",
      "Iteration 19761, loss = 873.92168907\n",
      "Iteration 19762, loss = 873.82274134\n",
      "Iteration 19763, loss = 873.72384985\n",
      "Iteration 19764, loss = 873.62501450\n",
      "Iteration 19765, loss = 873.52623521\n",
      "Iteration 19766, loss = 873.42751189\n",
      "Iteration 19767, loss = 873.32884443\n",
      "Iteration 19768, loss = 873.23023277\n",
      "Iteration 19769, loss = 873.13167679\n",
      "Iteration 19770, loss = 873.03317641\n",
      "Iteration 19771, loss = 872.93473155\n",
      "Iteration 19772, loss = 872.83634211\n",
      "Iteration 19773, loss = 872.73800800\n",
      "Iteration 19774, loss = 872.63972914\n",
      "Iteration 19775, loss = 872.54150543\n",
      "Iteration 19776, loss = 872.44333679\n",
      "Iteration 19777, loss = 872.34522312\n",
      "Iteration 19778, loss = 872.24716435\n",
      "Iteration 19779, loss = 872.14916038\n",
      "Iteration 19780, loss = 872.05121112\n",
      "Iteration 19781, loss = 871.95331649\n",
      "Iteration 19782, loss = 871.85547640\n",
      "Iteration 19783, loss = 871.75769076\n",
      "Iteration 19784, loss = 871.65995949\n",
      "Iteration 19785, loss = 871.56228251\n",
      "Iteration 19786, loss = 871.46465971\n",
      "Iteration 19787, loss = 871.36709103\n",
      "Iteration 19788, loss = 871.26957636\n",
      "Iteration 19789, loss = 871.17211564\n",
      "Iteration 19790, loss = 871.07470877\n",
      "Iteration 19791, loss = 870.97735566\n",
      "Iteration 19792, loss = 870.88005624\n",
      "Iteration 19793, loss = 870.78281042\n",
      "Iteration 19794, loss = 870.68561811\n",
      "Iteration 19795, loss = 870.58847923\n",
      "Iteration 19796, loss = 870.49139370\n",
      "Iteration 19797, loss = 870.39436144\n",
      "Iteration 19798, loss = 870.29738235\n",
      "Iteration 19799, loss = 870.20045637\n",
      "Iteration 19800, loss = 870.10358339\n",
      "Iteration 19801, loss = 870.00676335\n",
      "Iteration 19802, loss = 869.90999617\n",
      "Iteration 19803, loss = 869.81328175\n",
      "Iteration 19804, loss = 869.71662001\n",
      "Iteration 19805, loss = 869.62001088\n",
      "Iteration 19806, loss = 869.52345428\n",
      "Iteration 19807, loss = 869.42695012\n",
      "Iteration 19808, loss = 869.33049832\n",
      "Iteration 19809, loss = 869.23409880\n",
      "Iteration 19810, loss = 869.13775148\n",
      "Iteration 19811, loss = 869.04145628\n",
      "Iteration 19812, loss = 868.94521313\n",
      "Iteration 19813, loss = 868.84902193\n",
      "Iteration 19814, loss = 868.75288262\n",
      "Iteration 19815, loss = 868.65679511\n",
      "Iteration 19816, loss = 868.56075932\n",
      "Iteration 19817, loss = 868.46477518\n",
      "Iteration 19818, loss = 868.36884260\n",
      "Iteration 19819, loss = 868.27296151\n",
      "Iteration 19820, loss = 868.17713183\n",
      "Iteration 19821, loss = 868.08135348\n",
      "Iteration 19822, loss = 867.98562639\n",
      "Iteration 19823, loss = 867.88995047\n",
      "Iteration 19824, loss = 867.79432565\n",
      "Iteration 19825, loss = 867.69875185\n",
      "Iteration 19826, loss = 867.60322899\n",
      "Iteration 19827, loss = 867.50775701\n",
      "Iteration 19828, loss = 867.41233581\n",
      "Iteration 19829, loss = 867.31696533\n",
      "Iteration 19830, loss = 867.22164549\n",
      "Iteration 19831, loss = 867.12637622\n",
      "Iteration 19832, loss = 867.03115743\n",
      "Iteration 19833, loss = 866.93598905\n",
      "Iteration 19834, loss = 866.84087101\n",
      "Iteration 19835, loss = 866.74580324\n",
      "Iteration 19836, loss = 866.65078565\n",
      "Iteration 19837, loss = 866.55581817\n",
      "Iteration 19838, loss = 866.46090073\n",
      "Iteration 19839, loss = 866.36603325\n",
      "Iteration 19840, loss = 866.27121567\n",
      "Iteration 19841, loss = 866.17644790\n",
      "Iteration 19842, loss = 866.08172987\n",
      "Iteration 19843, loss = 865.98706151\n",
      "Iteration 19844, loss = 865.89244275\n",
      "Iteration 19845, loss = 865.79787351\n",
      "Iteration 19846, loss = 865.70335372\n",
      "Iteration 19847, loss = 865.60888331\n",
      "Iteration 19848, loss = 865.51446220\n",
      "Iteration 19849, loss = 865.42009033\n",
      "Iteration 19850, loss = 865.32576761\n",
      "Iteration 19851, loss = 865.23149399\n",
      "Iteration 19852, loss = 865.13726938\n",
      "Iteration 19853, loss = 865.04309372\n",
      "Iteration 19854, loss = 864.94896693\n",
      "Iteration 19855, loss = 864.85488894\n",
      "Iteration 19856, loss = 864.76085969\n",
      "Iteration 19857, loss = 864.66687910\n",
      "Iteration 19858, loss = 864.57294710\n",
      "Iteration 19859, loss = 864.47906362\n",
      "Iteration 19860, loss = 864.38522859\n",
      "Iteration 19861, loss = 864.29144194\n",
      "Iteration 19862, loss = 864.19770360\n",
      "Iteration 19863, loss = 864.10401350\n",
      "Iteration 19864, loss = 864.01037158\n",
      "Iteration 19865, loss = 863.91677775\n",
      "Iteration 19866, loss = 863.82323196\n",
      "Iteration 19867, loss = 863.72973414\n",
      "Iteration 19868, loss = 863.63628421\n",
      "Iteration 19869, loss = 863.54288210\n",
      "Iteration 19870, loss = 863.44952776\n",
      "Iteration 19871, loss = 863.35622110\n",
      "Iteration 19872, loss = 863.26296207\n",
      "Iteration 19873, loss = 863.16975059\n",
      "Iteration 19874, loss = 863.07658660\n",
      "Iteration 19875, loss = 862.98347003\n",
      "Iteration 19876, loss = 862.89040082\n",
      "Iteration 19877, loss = 862.79737888\n",
      "Iteration 19878, loss = 862.70440417\n",
      "Iteration 19879, loss = 862.61147660\n",
      "Iteration 19880, loss = 862.51859613\n",
      "Iteration 19881, loss = 862.42576267\n",
      "Iteration 19882, loss = 862.33297616\n",
      "Iteration 19883, loss = 862.24023654\n",
      "Iteration 19884, loss = 862.14754373\n",
      "Iteration 19885, loss = 862.05489769\n",
      "Iteration 19886, loss = 861.96229833\n",
      "Iteration 19887, loss = 861.86974559\n",
      "Iteration 19888, loss = 861.77723942\n",
      "Iteration 19889, loss = 861.68477973\n",
      "Iteration 19890, loss = 861.59236648\n",
      "Iteration 19891, loss = 861.49999958\n",
      "Iteration 19892, loss = 861.40767899\n",
      "Iteration 19893, loss = 861.31540463\n",
      "Iteration 19894, loss = 861.22317644\n",
      "Iteration 19895, loss = 861.13099436\n",
      "Iteration 19896, loss = 861.03885832\n",
      "Iteration 19897, loss = 860.94676825\n",
      "Iteration 19898, loss = 860.85472410\n",
      "Iteration 19899, loss = 860.76272581\n",
      "Iteration 19900, loss = 860.67077330\n",
      "Iteration 19901, loss = 860.57886651\n",
      "Iteration 19902, loss = 860.48700539\n",
      "Iteration 19903, loss = 860.39518986\n",
      "Iteration 19904, loss = 860.30341988\n",
      "Iteration 19905, loss = 860.21169536\n",
      "Iteration 19906, loss = 860.12001626\n",
      "Iteration 19907, loss = 860.02838251\n",
      "Iteration 19908, loss = 859.93679404\n",
      "Iteration 19909, loss = 859.84525080\n",
      "Iteration 19910, loss = 859.75375272\n",
      "Iteration 19911, loss = 859.66229975\n",
      "Iteration 19912, loss = 859.57089181\n",
      "Iteration 19913, loss = 859.47952886\n",
      "Iteration 19914, loss = 859.38821082\n",
      "Iteration 19915, loss = 859.29693764\n",
      "Iteration 19916, loss = 859.20570925\n",
      "Iteration 19917, loss = 859.11452561\n",
      "Iteration 19918, loss = 859.02338663\n",
      "Iteration 19919, loss = 858.93229228\n",
      "Iteration 19920, loss = 858.84124247\n",
      "Iteration 19921, loss = 858.75023716\n",
      "Iteration 19922, loss = 858.65927629\n",
      "Iteration 19923, loss = 858.56835979\n",
      "Iteration 19924, loss = 858.47748761\n",
      "Iteration 19925, loss = 858.38665968\n",
      "Iteration 19926, loss = 858.29587595\n",
      "Iteration 19927, loss = 858.20513635\n",
      "Iteration 19928, loss = 858.11444084\n",
      "Iteration 19929, loss = 858.02378934\n",
      "Iteration 19930, loss = 857.93318181\n",
      "Iteration 19931, loss = 857.84261817\n",
      "Iteration 19932, loss = 857.75209838\n",
      "Iteration 19933, loss = 857.66162238\n",
      "Iteration 19934, loss = 857.57119010\n",
      "Iteration 19935, loss = 857.48080149\n",
      "Iteration 19936, loss = 857.39045649\n",
      "Iteration 19937, loss = 857.30015504\n",
      "Iteration 19938, loss = 857.20989709\n",
      "Iteration 19939, loss = 857.11968258\n",
      "Iteration 19940, loss = 857.02951145\n",
      "Iteration 19941, loss = 856.93938364\n",
      "Iteration 19942, loss = 856.84929910\n",
      "Iteration 19943, loss = 856.75925777\n",
      "Iteration 19944, loss = 856.66925959\n",
      "Iteration 19945, loss = 856.57930451\n",
      "Iteration 19946, loss = 856.48939247\n",
      "Iteration 19947, loss = 856.39952341\n",
      "Iteration 19948, loss = 856.30969728\n",
      "Iteration 19949, loss = 856.21991401\n",
      "Iteration 19950, loss = 856.13017357\n",
      "Iteration 19951, loss = 856.04047588\n",
      "Iteration 19952, loss = 855.95082089\n",
      "Iteration 19953, loss = 855.86120856\n",
      "Iteration 19954, loss = 855.77163881\n",
      "Iteration 19955, loss = 855.68211160\n",
      "Iteration 19956, loss = 855.59262688\n",
      "Iteration 19957, loss = 855.50318458\n",
      "Iteration 19958, loss = 855.41378465\n",
      "Iteration 19959, loss = 855.32442704\n",
      "Iteration 19960, loss = 855.23511169\n",
      "Iteration 19961, loss = 855.14583855\n",
      "Iteration 19962, loss = 855.05660756\n",
      "Iteration 19963, loss = 854.96741867\n",
      "Iteration 19964, loss = 854.87827183\n",
      "Iteration 19965, loss = 854.78916698\n",
      "Iteration 19966, loss = 854.70010406\n",
      "Iteration 19967, loss = 854.61108303\n",
      "Iteration 19968, loss = 854.52210382\n",
      "Iteration 19969, loss = 854.43316640\n",
      "Iteration 19970, loss = 854.34427069\n",
      "Iteration 19971, loss = 854.25541666\n",
      "Iteration 19972, loss = 854.16660424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19973, loss = 854.07783338\n",
      "Iteration 19974, loss = 853.98910403\n",
      "Iteration 19975, loss = 853.90041615\n",
      "Iteration 19976, loss = 853.81176966\n",
      "Iteration 19977, loss = 853.72316453\n",
      "Iteration 19978, loss = 853.63460070\n",
      "Iteration 19979, loss = 853.54607811\n",
      "Iteration 19980, loss = 853.45759672\n",
      "Iteration 19981, loss = 853.36915648\n",
      "Iteration 19982, loss = 853.28075732\n",
      "Iteration 19983, loss = 853.19239921\n",
      "Iteration 19984, loss = 853.10408208\n",
      "Iteration 19985, loss = 853.01580589\n",
      "Iteration 19986, loss = 852.92757058\n",
      "Iteration 19987, loss = 852.83937611\n",
      "Iteration 19988, loss = 852.75122242\n",
      "Iteration 19989, loss = 852.66310946\n",
      "Iteration 19990, loss = 852.57503718\n",
      "Iteration 19991, loss = 852.48700553\n",
      "Iteration 19992, loss = 852.39901446\n",
      "Iteration 19993, loss = 852.31106392\n",
      "Iteration 19994, loss = 852.22315385\n",
      "Iteration 19995, loss = 852.13528422\n",
      "Iteration 19996, loss = 852.04745495\n",
      "Iteration 19997, loss = 851.95966602\n",
      "Iteration 19998, loss = 851.87191736\n",
      "Iteration 19999, loss = 851.78420893\n",
      "Iteration 20000, loss = 851.69654067\n",
      "Iteration 20001, loss = 851.60891254\n",
      "Iteration 20002, loss = 851.52132449\n",
      "Iteration 20003, loss = 851.43377647\n",
      "Iteration 20004, loss = 851.34626843\n",
      "Iteration 20005, loss = 851.25880031\n",
      "Iteration 20006, loss = 851.17137208\n",
      "Iteration 20007, loss = 851.08398367\n",
      "Iteration 20008, loss = 850.99663505\n",
      "Iteration 20009, loss = 850.90932616\n",
      "Iteration 20010, loss = 850.82205696\n",
      "Iteration 20011, loss = 850.73482739\n",
      "Iteration 20012, loss = 850.64763741\n",
      "Iteration 20013, loss = 850.56048697\n",
      "Iteration 20014, loss = 850.47337602\n",
      "Iteration 20015, loss = 850.38630451\n",
      "Iteration 20016, loss = 850.29927240\n",
      "Iteration 20017, loss = 850.21227963\n",
      "Iteration 20018, loss = 850.12532616\n",
      "Iteration 20019, loss = 850.03841194\n",
      "Iteration 20020, loss = 849.95153693\n",
      "Iteration 20021, loss = 849.86470107\n",
      "Iteration 20022, loss = 849.77790432\n",
      "Iteration 20023, loss = 849.69114663\n",
      "Iteration 20024, loss = 849.60442796\n",
      "Iteration 20025, loss = 849.51774825\n",
      "Iteration 20026, loss = 849.43110746\n",
      "Iteration 20027, loss = 849.34450555\n",
      "Iteration 20028, loss = 849.25794246\n",
      "Iteration 20029, loss = 849.17141815\n",
      "Iteration 20030, loss = 849.08493257\n",
      "Iteration 20031, loss = 848.99848568\n",
      "Iteration 20032, loss = 848.91207743\n",
      "Iteration 20033, loss = 848.82570777\n",
      "Iteration 20034, loss = 848.73937666\n",
      "Iteration 20035, loss = 848.65308405\n",
      "Iteration 20036, loss = 848.56682990\n",
      "Iteration 20037, loss = 848.48061415\n",
      "Iteration 20038, loss = 848.39443677\n",
      "Iteration 20039, loss = 848.30829771\n",
      "Iteration 20040, loss = 848.22219692\n",
      "Iteration 20041, loss = 848.13613435\n",
      "Iteration 20042, loss = 848.05010997\n",
      "Iteration 20043, loss = 847.96412372\n",
      "Iteration 20044, loss = 847.87817557\n",
      "Iteration 20045, loss = 847.79226546\n",
      "Iteration 20046, loss = 847.70639335\n",
      "Iteration 20047, loss = 847.62055920\n",
      "Iteration 20048, loss = 847.53476296\n",
      "Iteration 20049, loss = 847.44900458\n",
      "Iteration 20050, loss = 847.36328403\n",
      "Iteration 20051, loss = 847.27760125\n",
      "Iteration 20052, loss = 847.19195621\n",
      "Iteration 20053, loss = 847.10634886\n",
      "Iteration 20054, loss = 847.02077915\n",
      "Iteration 20055, loss = 846.93524704\n",
      "Iteration 20056, loss = 846.84975249\n",
      "Iteration 20057, loss = 846.76429545\n",
      "Iteration 20058, loss = 846.67887587\n",
      "Iteration 20059, loss = 846.59349373\n",
      "Iteration 20060, loss = 846.50814896\n",
      "Iteration 20061, loss = 846.42284153\n",
      "Iteration 20062, loss = 846.33757140\n",
      "Iteration 20063, loss = 846.25233851\n",
      "Iteration 20064, loss = 846.16714284\n",
      "Iteration 20065, loss = 846.08198432\n",
      "Iteration 20066, loss = 845.99686293\n",
      "Iteration 20067, loss = 845.91177862\n",
      "Iteration 20068, loss = 845.82673134\n",
      "Iteration 20069, loss = 845.74172105\n",
      "Iteration 20070, loss = 845.65674772\n",
      "Iteration 20071, loss = 845.57181129\n",
      "Iteration 20072, loss = 845.48691172\n",
      "Iteration 20073, loss = 845.40204898\n",
      "Iteration 20074, loss = 845.31722302\n",
      "Iteration 20075, loss = 845.23243379\n",
      "Iteration 20076, loss = 845.14768126\n",
      "Iteration 20077, loss = 845.06296538\n",
      "Iteration 20078, loss = 844.97828611\n",
      "Iteration 20079, loss = 844.89364341\n",
      "Iteration 20080, loss = 844.80903724\n",
      "Iteration 20081, loss = 844.72446756\n",
      "Iteration 20082, loss = 844.63993432\n",
      "Iteration 20083, loss = 844.55543748\n",
      "Iteration 20084, loss = 844.47097700\n",
      "Iteration 20085, loss = 844.38655284\n",
      "Iteration 20086, loss = 844.30216496\n",
      "Iteration 20087, loss = 844.21781331\n",
      "Iteration 20088, loss = 844.13349786\n",
      "Iteration 20089, loss = 844.04921856\n",
      "Iteration 20090, loss = 843.96497538\n",
      "Iteration 20091, loss = 843.88076827\n",
      "Iteration 20092, loss = 843.79659720\n",
      "Iteration 20093, loss = 843.71246211\n",
      "Iteration 20094, loss = 843.62836297\n",
      "Iteration 20095, loss = 843.54429975\n",
      "Iteration 20096, loss = 843.46027239\n",
      "Iteration 20097, loss = 843.37628087\n",
      "Iteration 20098, loss = 843.29232513\n",
      "Iteration 20099, loss = 843.20840514\n",
      "Iteration 20100, loss = 843.12452085\n",
      "Iteration 20101, loss = 843.04067224\n",
      "Iteration 20102, loss = 842.95685926\n",
      "Iteration 20103, loss = 842.87308186\n",
      "Iteration 20104, loss = 842.78934001\n",
      "Iteration 20105, loss = 842.70563367\n",
      "Iteration 20106, loss = 842.62196280\n",
      "Iteration 20107, loss = 842.53832736\n",
      "Iteration 20108, loss = 842.45472731\n",
      "Iteration 20109, loss = 842.37116261\n",
      "Iteration 20110, loss = 842.28763323\n",
      "Iteration 20111, loss = 842.20413911\n",
      "Iteration 20112, loss = 842.12068023\n",
      "Iteration 20113, loss = 842.03725654\n",
      "Iteration 20114, loss = 841.95386801\n",
      "Iteration 20115, loss = 841.87051459\n",
      "Iteration 20116, loss = 841.78719625\n",
      "Iteration 20117, loss = 841.70391295\n",
      "Iteration 20118, loss = 841.62066465\n",
      "Iteration 20119, loss = 841.53745131\n",
      "Iteration 20120, loss = 841.45427289\n",
      "Iteration 20121, loss = 841.37112936\n",
      "Iteration 20122, loss = 841.28802067\n",
      "Iteration 20123, loss = 841.20494679\n",
      "Iteration 20124, loss = 841.12190768\n",
      "Iteration 20125, loss = 841.03890330\n",
      "Iteration 20126, loss = 840.95593361\n",
      "Iteration 20127, loss = 840.87299858\n",
      "Iteration 20128, loss = 840.79009817\n",
      "Iteration 20129, loss = 840.70723233\n",
      "Iteration 20130, loss = 840.62440104\n",
      "Iteration 20131, loss = 840.54160425\n",
      "Iteration 20132, loss = 840.45884193\n",
      "Iteration 20133, loss = 840.37611403\n",
      "Iteration 20134, loss = 840.29342053\n",
      "Iteration 20135, loss = 840.21076138\n",
      "Iteration 20136, loss = 840.12813655\n",
      "Iteration 20137, loss = 840.04554599\n",
      "Iteration 20138, loss = 839.96298968\n",
      "Iteration 20139, loss = 839.88046758\n",
      "Iteration 20140, loss = 839.79797964\n",
      "Iteration 20141, loss = 839.71552583\n",
      "Iteration 20142, loss = 839.63310612\n",
      "Iteration 20143, loss = 839.55072046\n",
      "Iteration 20144, loss = 839.46836883\n",
      "Iteration 20145, loss = 839.38605118\n",
      "Iteration 20146, loss = 839.30376748\n",
      "Iteration 20147, loss = 839.22151768\n",
      "Iteration 20148, loss = 839.13930177\n",
      "Iteration 20149, loss = 839.05711969\n",
      "Iteration 20150, loss = 838.97497141\n",
      "Iteration 20151, loss = 838.89285690\n",
      "Iteration 20152, loss = 838.81077612\n",
      "Iteration 20153, loss = 838.72872903\n",
      "Iteration 20154, loss = 838.64671560\n",
      "Iteration 20155, loss = 838.56473579\n",
      "Iteration 20156, loss = 838.48278956\n",
      "Iteration 20157, loss = 838.40087689\n",
      "Iteration 20158, loss = 838.31899773\n",
      "Iteration 20159, loss = 838.23715204\n",
      "Iteration 20160, loss = 838.15533981\n",
      "Iteration 20161, loss = 838.07356097\n",
      "Iteration 20162, loss = 837.99181551\n",
      "Iteration 20163, loss = 837.91010339\n",
      "Iteration 20164, loss = 837.82842457\n",
      "Iteration 20165, loss = 837.74677901\n",
      "Iteration 20166, loss = 837.66516669\n",
      "Iteration 20167, loss = 837.58358756\n",
      "Iteration 20168, loss = 837.50204159\n",
      "Iteration 20169, loss = 837.42052874\n",
      "Iteration 20170, loss = 837.33904899\n",
      "Iteration 20171, loss = 837.25760229\n",
      "Iteration 20172, loss = 837.17618862\n",
      "Iteration 20173, loss = 837.09480793\n",
      "Iteration 20174, loss = 837.01346019\n",
      "Iteration 20175, loss = 836.93214537\n",
      "Iteration 20176, loss = 836.85086343\n",
      "Iteration 20177, loss = 836.76961434\n",
      "Iteration 20178, loss = 836.68839807\n",
      "Iteration 20179, loss = 836.60721457\n",
      "Iteration 20180, loss = 836.52606382\n",
      "Iteration 20181, loss = 836.44494578\n",
      "Iteration 20182, loss = 836.36386041\n",
      "Iteration 20183, loss = 836.28280769\n",
      "Iteration 20184, loss = 836.20178758\n",
      "Iteration 20185, loss = 836.12080005\n",
      "Iteration 20186, loss = 836.03984505\n",
      "Iteration 20187, loss = 835.95892257\n",
      "Iteration 20188, loss = 835.87803255\n",
      "Iteration 20189, loss = 835.79717498\n",
      "Iteration 20190, loss = 835.71634981\n",
      "Iteration 20191, loss = 835.63555702\n",
      "Iteration 20192, loss = 835.55479656\n",
      "Iteration 20193, loss = 835.47406842\n",
      "Iteration 20194, loss = 835.39337254\n",
      "Iteration 20195, loss = 835.31270890\n",
      "Iteration 20196, loss = 835.23207748\n",
      "Iteration 20197, loss = 835.15147822\n",
      "Iteration 20198, loss = 835.07091111\n",
      "Iteration 20199, loss = 834.99037611\n",
      "Iteration 20200, loss = 834.90987320\n",
      "Iteration 20201, loss = 834.82940236\n",
      "Iteration 20202, loss = 834.74896357\n",
      "Iteration 20203, loss = 834.66855688\n",
      "Iteration 20204, loss = 834.58818237\n",
      "Iteration 20205, loss = 834.50784026\n",
      "Iteration 20206, loss = 834.42753107\n",
      "Iteration 20207, loss = 834.34725588\n",
      "Iteration 20208, loss = 834.26701703\n",
      "Iteration 20209, loss = 834.18681898\n",
      "Iteration 20210, loss = 834.10667010\n",
      "Iteration 20211, loss = 834.02658092\n",
      "Iteration 20212, loss = 833.94655640\n",
      "Iteration 20213, loss = 833.86655658\n",
      "Iteration 20214, loss = 833.78649124\n",
      "Iteration 20215, loss = 833.70631244\n",
      "Iteration 20216, loss = 833.62617452\n",
      "Iteration 20217, loss = 833.54623480\n",
      "Iteration 20218, loss = 833.46641394\n",
      "Iteration 20219, loss = 833.38652226\n",
      "Iteration 20220, loss = 833.30654649\n",
      "Iteration 20221, loss = 833.22666646\n",
      "Iteration 20222, loss = 833.14692910\n",
      "Iteration 20223, loss = 833.06718541\n",
      "Iteration 20224, loss = 832.98737827\n",
      "Iteration 20225, loss = 832.90763083\n",
      "Iteration 20226, loss = 832.82799491\n",
      "Iteration 20227, loss = 832.74836546\n",
      "Iteration 20228, loss = 832.66870282\n",
      "Iteration 20229, loss = 832.58909800\n",
      "Iteration 20230, loss = 832.50957482\n",
      "Iteration 20231, loss = 832.43005566\n",
      "Iteration 20232, loss = 832.35053049\n",
      "Iteration 20233, loss = 832.27106409\n",
      "Iteration 20234, loss = 832.19165518\n",
      "Iteration 20235, loss = 832.11225068\n",
      "Iteration 20236, loss = 832.03286031\n",
      "Iteration 20237, loss = 831.95352595\n",
      "Iteration 20238, loss = 831.87423164\n",
      "Iteration 20239, loss = 831.79494627\n",
      "Iteration 20240, loss = 831.71568876\n",
      "Iteration 20241, loss = 831.63648053\n",
      "Iteration 20242, loss = 831.55730198\n",
      "Iteration 20243, loss = 831.47813950\n",
      "Iteration 20244, loss = 831.39901164\n",
      "Iteration 20245, loss = 831.31992569\n",
      "Iteration 20246, loss = 831.24086498\n",
      "Iteration 20247, loss = 831.16182693\n",
      "Iteration 20248, loss = 831.08282552\n",
      "Iteration 20249, loss = 831.00385990\n",
      "Iteration 20250, loss = 830.92491891\n",
      "Iteration 20251, loss = 830.84600536\n",
      "Iteration 20252, loss = 830.76712765\n",
      "Iteration 20253, loss = 830.68828184\n",
      "Iteration 20254, loss = 830.60946178\n",
      "Iteration 20255, loss = 830.53067180\n",
      "Iteration 20256, loss = 830.45191599\n",
      "Iteration 20257, loss = 830.37319001\n",
      "Iteration 20258, loss = 830.29449129\n",
      "Iteration 20259, loss = 830.21582375\n",
      "Iteration 20260, loss = 830.13718869\n",
      "Iteration 20261, loss = 830.05858268\n",
      "Iteration 20262, loss = 829.98000517\n",
      "Iteration 20263, loss = 829.90145899\n",
      "Iteration 20264, loss = 829.82294404\n",
      "Iteration 20265, loss = 829.74445800\n",
      "Iteration 20266, loss = 829.66600125\n",
      "Iteration 20267, loss = 829.58757554\n",
      "Iteration 20268, loss = 829.50918026\n",
      "Iteration 20269, loss = 829.43081401\n",
      "Iteration 20270, loss = 829.35247744\n",
      "Iteration 20271, loss = 829.27417153\n",
      "Iteration 20272, loss = 829.19589555\n",
      "Iteration 20273, loss = 829.11764877\n",
      "Iteration 20274, loss = 829.03943180\n",
      "Iteration 20275, loss = 828.96124511\n",
      "Iteration 20276, loss = 828.88308808\n",
      "Iteration 20277, loss = 828.80496037\n",
      "Iteration 20278, loss = 828.72686243\n",
      "Iteration 20279, loss = 828.64879446\n",
      "Iteration 20280, loss = 828.57075600\n",
      "Iteration 20281, loss = 828.49274690\n",
      "Iteration 20282, loss = 828.41476747\n",
      "Iteration 20283, loss = 828.33681777\n",
      "Iteration 20284, loss = 828.25889747\n",
      "Iteration 20285, loss = 828.18100651\n",
      "Iteration 20286, loss = 828.10314510\n",
      "Iteration 20287, loss = 828.02531323\n",
      "Iteration 20288, loss = 827.94751066\n",
      "Iteration 20289, loss = 827.86973738\n",
      "Iteration 20290, loss = 827.79199351\n",
      "Iteration 20291, loss = 827.71427902\n",
      "Iteration 20292, loss = 827.63659375\n",
      "Iteration 20293, loss = 827.55893769\n",
      "Iteration 20294, loss = 827.48131091\n",
      "Iteration 20295, loss = 827.40371337\n",
      "Iteration 20296, loss = 827.32614495\n",
      "Iteration 20297, loss = 827.24860565\n",
      "Iteration 20298, loss = 827.17109551\n",
      "Iteration 20299, loss = 827.09361447\n",
      "Iteration 20300, loss = 827.01616247\n",
      "Iteration 20301, loss = 826.93873949\n",
      "Iteration 20302, loss = 826.86134553\n",
      "Iteration 20303, loss = 826.78398058\n",
      "Iteration 20304, loss = 826.70664455\n",
      "Iteration 20305, loss = 826.62933743\n",
      "Iteration 20306, loss = 826.55205923\n",
      "Iteration 20307, loss = 826.47480991\n",
      "Iteration 20308, loss = 826.39758942\n",
      "Iteration 20309, loss = 826.32039774\n",
      "Iteration 20310, loss = 826.24323485\n",
      "Iteration 20311, loss = 826.16610074\n",
      "Iteration 20312, loss = 826.08899535\n",
      "Iteration 20313, loss = 826.01191866\n",
      "Iteration 20314, loss = 825.93487066\n",
      "Iteration 20315, loss = 825.85785132\n",
      "Iteration 20316, loss = 825.78086060\n",
      "Iteration 20317, loss = 825.70389847\n",
      "Iteration 20318, loss = 825.62696492\n",
      "Iteration 20319, loss = 825.55005993\n",
      "Iteration 20320, loss = 825.47318345\n",
      "Iteration 20321, loss = 825.39633546\n",
      "Iteration 20322, loss = 825.31951594\n",
      "Iteration 20323, loss = 825.24272486\n",
      "Iteration 20324, loss = 825.16596220\n",
      "Iteration 20325, loss = 825.08922791\n",
      "Iteration 20326, loss = 825.01252200\n",
      "Iteration 20327, loss = 824.93584441\n",
      "Iteration 20328, loss = 824.85919514\n",
      "Iteration 20329, loss = 824.78257415\n",
      "Iteration 20330, loss = 824.70598141\n",
      "Iteration 20331, loss = 824.62941690\n",
      "Iteration 20332, loss = 824.55288060\n",
      "Iteration 20333, loss = 824.47637247\n",
      "Iteration 20334, loss = 824.39989249\n",
      "Iteration 20335, loss = 824.32344065\n",
      "Iteration 20336, loss = 824.24701689\n",
      "Iteration 20337, loss = 824.17062122\n",
      "Iteration 20338, loss = 824.09425359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20339, loss = 824.01791398\n",
      "Iteration 20340, loss = 823.94160237\n",
      "Iteration 20341, loss = 823.86531873\n",
      "Iteration 20342, loss = 823.78906303\n",
      "Iteration 20343, loss = 823.71283525\n",
      "Iteration 20344, loss = 823.63663536\n",
      "Iteration 20345, loss = 823.56046335\n",
      "Iteration 20346, loss = 823.48431917\n",
      "Iteration 20347, loss = 823.40820281\n",
      "Iteration 20348, loss = 823.33211424\n",
      "Iteration 20349, loss = 823.25605344\n",
      "Iteration 20350, loss = 823.18002038\n",
      "Iteration 20351, loss = 823.10401503\n",
      "Iteration 20352, loss = 823.02803737\n",
      "Iteration 20353, loss = 822.95208738\n",
      "Iteration 20354, loss = 822.87616502\n",
      "Iteration 20355, loss = 822.80027028\n",
      "Iteration 20356, loss = 822.72440313\n",
      "Iteration 20357, loss = 822.64856354\n",
      "Iteration 20358, loss = 822.57275149\n",
      "Iteration 20359, loss = 822.49696696\n",
      "Iteration 20360, loss = 822.42120991\n",
      "Iteration 20361, loss = 822.34548032\n",
      "Iteration 20362, loss = 822.26977818\n",
      "Iteration 20363, loss = 822.19410345\n",
      "Iteration 20364, loss = 822.11845611\n",
      "Iteration 20365, loss = 822.04283613\n",
      "Iteration 20366, loss = 821.96724349\n",
      "Iteration 20367, loss = 821.89167817\n",
      "Iteration 20368, loss = 821.81614014\n",
      "Iteration 20369, loss = 821.74062937\n",
      "Iteration 20370, loss = 821.66514584\n",
      "Iteration 20371, loss = 821.58968954\n",
      "Iteration 20372, loss = 821.51426042\n",
      "Iteration 20373, loss = 821.43885847\n",
      "Iteration 20374, loss = 821.36348366\n",
      "Iteration 20375, loss = 821.28813597\n",
      "Iteration 20376, loss = 821.21281538\n",
      "Iteration 20377, loss = 821.13752186\n",
      "Iteration 20378, loss = 821.06225538\n",
      "Iteration 20379, loss = 820.98701592\n",
      "Iteration 20380, loss = 820.91180346\n",
      "Iteration 20381, loss = 820.83661798\n",
      "Iteration 20382, loss = 820.76145944\n",
      "Iteration 20383, loss = 820.68632783\n",
      "Iteration 20384, loss = 820.61122312\n",
      "Iteration 20385, loss = 820.53614528\n",
      "Iteration 20386, loss = 820.46109430\n",
      "Iteration 20387, loss = 820.38607015\n",
      "Iteration 20388, loss = 820.31107280\n",
      "Iteration 20389, loss = 820.23610224\n",
      "Iteration 20390, loss = 820.16115843\n",
      "Iteration 20391, loss = 820.08624135\n",
      "Iteration 20392, loss = 820.01135099\n",
      "Iteration 20393, loss = 819.93648731\n",
      "Iteration 20394, loss = 819.86165029\n",
      "Iteration 20395, loss = 819.78683992\n",
      "Iteration 20396, loss = 819.71205615\n",
      "Iteration 20397, loss = 819.63729898\n",
      "Iteration 20398, loss = 819.56256838\n",
      "Iteration 20399, loss = 819.48786432\n",
      "Iteration 20400, loss = 819.41318678\n",
      "Iteration 20401, loss = 819.33853574\n",
      "Iteration 20402, loss = 819.26391117\n",
      "Iteration 20403, loss = 819.18931306\n",
      "Iteration 20404, loss = 819.11474137\n",
      "Iteration 20405, loss = 819.04019609\n",
      "Iteration 20406, loss = 818.96567719\n",
      "Iteration 20407, loss = 818.89118464\n",
      "Iteration 20408, loss = 818.81671843\n",
      "Iteration 20409, loss = 818.74227853\n",
      "Iteration 20410, loss = 818.66786492\n",
      "Iteration 20411, loss = 818.59347758\n",
      "Iteration 20412, loss = 818.51911647\n",
      "Iteration 20413, loss = 818.44478159\n",
      "Iteration 20414, loss = 818.37047290\n",
      "Iteration 20415, loss = 818.29619039\n",
      "Iteration 20416, loss = 818.22193402\n",
      "Iteration 20417, loss = 818.14770379\n",
      "Iteration 20418, loss = 818.07349966\n",
      "Iteration 20419, loss = 817.99932161\n",
      "Iteration 20420, loss = 817.92516961\n",
      "Iteration 20421, loss = 817.85104366\n",
      "Iteration 20422, loss = 817.77694372\n",
      "Iteration 20423, loss = 817.70286977\n",
      "Iteration 20424, loss = 817.62882179\n",
      "Iteration 20425, loss = 817.55479975\n",
      "Iteration 20426, loss = 817.48080364\n",
      "Iteration 20427, loss = 817.40683342\n",
      "Iteration 20428, loss = 817.33288909\n",
      "Iteration 20429, loss = 817.25897061\n",
      "Iteration 20430, loss = 817.18507796\n",
      "Iteration 20431, loss = 817.11121113\n",
      "Iteration 20432, loss = 817.03737008\n",
      "Iteration 20433, loss = 816.96355480\n",
      "Iteration 20434, loss = 816.88976526\n",
      "Iteration 20435, loss = 816.81600145\n",
      "Iteration 20436, loss = 816.74226333\n",
      "Iteration 20437, loss = 816.66855089\n",
      "Iteration 20438, loss = 816.59486411\n",
      "Iteration 20439, loss = 816.52120295\n",
      "Iteration 20440, loss = 816.44756741\n",
      "Iteration 20441, loss = 816.37395746\n",
      "Iteration 20442, loss = 816.30037307\n",
      "Iteration 20443, loss = 816.22681423\n",
      "Iteration 20444, loss = 816.15328091\n",
      "Iteration 20445, loss = 816.07977309\n",
      "Iteration 20446, loss = 816.00629075\n",
      "Iteration 20447, loss = 815.93283386\n",
      "Iteration 20448, loss = 815.85940241\n",
      "Iteration 20449, loss = 815.78599638\n",
      "Iteration 20450, loss = 815.71261573\n",
      "Iteration 20451, loss = 815.63926046\n",
      "Iteration 20452, loss = 815.56593053\n",
      "Iteration 20453, loss = 815.49262592\n",
      "Iteration 20454, loss = 815.41934662\n",
      "Iteration 20455, loss = 815.34609261\n",
      "Iteration 20456, loss = 815.27286385\n",
      "Iteration 20457, loss = 815.19966034\n",
      "Iteration 20458, loss = 815.12648204\n",
      "Iteration 20459, loss = 815.05332894\n",
      "Iteration 20460, loss = 814.98020101\n",
      "Iteration 20461, loss = 814.90709824\n",
      "Iteration 20462, loss = 814.83402059\n",
      "Iteration 20463, loss = 814.76096806\n",
      "Iteration 20464, loss = 814.68794062\n",
      "Iteration 20465, loss = 814.61493825\n",
      "Iteration 20466, loss = 814.54196092\n",
      "Iteration 20467, loss = 814.46900862\n",
      "Iteration 20468, loss = 814.39608132\n",
      "Iteration 20469, loss = 814.32317900\n",
      "Iteration 20470, loss = 814.25030165\n",
      "Iteration 20471, loss = 814.17744923\n",
      "Iteration 20472, loss = 814.10462174\n",
      "Iteration 20473, loss = 814.03181914\n",
      "Iteration 20474, loss = 813.95904142\n",
      "Iteration 20475, loss = 813.88628856\n",
      "Iteration 20476, loss = 813.81356053\n",
      "Iteration 20477, loss = 813.74085731\n",
      "Iteration 20478, loss = 813.66817889\n",
      "Iteration 20479, loss = 813.59552524\n",
      "Iteration 20480, loss = 813.52289634\n",
      "Iteration 20481, loss = 813.45029217\n",
      "Iteration 20482, loss = 813.37771271\n",
      "Iteration 20483, loss = 813.30515794\n",
      "Iteration 20484, loss = 813.23262784\n",
      "Iteration 20485, loss = 813.16012238\n",
      "Iteration 20486, loss = 813.08764155\n",
      "Iteration 20487, loss = 813.01518533\n",
      "Iteration 20488, loss = 812.94275369\n",
      "Iteration 20489, loss = 812.87034662\n",
      "Iteration 20490, loss = 812.79796408\n",
      "Iteration 20491, loss = 812.72560608\n",
      "Iteration 20492, loss = 812.65327257\n",
      "Iteration 20493, loss = 812.58096355\n",
      "Iteration 20494, loss = 812.50867898\n",
      "Iteration 20495, loss = 812.43641886\n",
      "Iteration 20496, loss = 812.36418316\n",
      "Iteration 20497, loss = 812.29197186\n",
      "Iteration 20498, loss = 812.21978494\n",
      "Iteration 20499, loss = 812.14762238\n",
      "Iteration 20500, loss = 812.07548416\n",
      "Iteration 20501, loss = 812.00337025\n",
      "Iteration 20502, loss = 811.93128064\n",
      "Iteration 20503, loss = 811.85921532\n",
      "Iteration 20504, loss = 811.78717425\n",
      "Iteration 20505, loss = 811.71515741\n",
      "Iteration 20506, loss = 811.64316480\n",
      "Iteration 20507, loss = 811.57119638\n",
      "Iteration 20508, loss = 811.49925214\n",
      "Iteration 20509, loss = 811.42733205\n",
      "Iteration 20510, loss = 811.35543611\n",
      "Iteration 20511, loss = 811.28356428\n",
      "Iteration 20512, loss = 811.21171654\n",
      "Iteration 20513, loss = 811.13989289\n",
      "Iteration 20514, loss = 811.06809329\n",
      "Iteration 20515, loss = 810.99631772\n",
      "Iteration 20516, loss = 810.92456618\n",
      "Iteration 20517, loss = 810.85283863\n",
      "Iteration 20518, loss = 810.78113505\n",
      "Iteration 20519, loss = 810.70945544\n",
      "Iteration 20520, loss = 810.63779976\n",
      "Iteration 20521, loss = 810.56616800\n",
      "Iteration 20522, loss = 810.49456014\n",
      "Iteration 20523, loss = 810.42297616\n",
      "Iteration 20524, loss = 810.35141603\n",
      "Iteration 20525, loss = 810.27987974\n",
      "Iteration 20526, loss = 810.20836728\n",
      "Iteration 20527, loss = 810.13687861\n",
      "Iteration 20528, loss = 810.06541372\n",
      "Iteration 20529, loss = 809.99397259\n",
      "Iteration 20530, loss = 809.92255520\n",
      "Iteration 20531, loss = 809.85116154\n",
      "Iteration 20532, loss = 809.77979157\n",
      "Iteration 20533, loss = 809.70844529\n",
      "Iteration 20534, loss = 809.63712267\n",
      "Iteration 20535, loss = 809.56582369\n",
      "Iteration 20536, loss = 809.49454834\n",
      "Iteration 20537, loss = 809.42329659\n",
      "Iteration 20538, loss = 809.35206842\n",
      "Iteration 20539, loss = 809.28086382\n",
      "Iteration 20540, loss = 809.20968277\n",
      "Iteration 20541, loss = 809.13852524\n",
      "Iteration 20542, loss = 809.06739123\n",
      "Iteration 20543, loss = 808.99628069\n",
      "Iteration 20544, loss = 808.92519363\n",
      "Iteration 20545, loss = 808.85413002\n",
      "Iteration 20546, loss = 808.78308984\n",
      "Iteration 20547, loss = 808.71207307\n",
      "Iteration 20548, loss = 808.64107970\n",
      "Iteration 20549, loss = 808.57010969\n",
      "Iteration 20550, loss = 808.49916304\n",
      "Iteration 20551, loss = 808.42823973\n",
      "Iteration 20552, loss = 808.35733973\n",
      "Iteration 20553, loss = 808.28646303\n",
      "Iteration 20554, loss = 808.21560961\n",
      "Iteration 20555, loss = 808.14477944\n",
      "Iteration 20556, loss = 808.07397252\n",
      "Iteration 20557, loss = 808.00318882\n",
      "Iteration 20558, loss = 807.93242831\n",
      "Iteration 20559, loss = 807.86169100\n",
      "Iteration 20560, loss = 807.79097684\n",
      "Iteration 20561, loss = 807.72028584\n",
      "Iteration 20562, loss = 807.64961796\n",
      "Iteration 20563, loss = 807.57897319\n",
      "Iteration 20564, loss = 807.50835150\n",
      "Iteration 20565, loss = 807.43775289\n",
      "Iteration 20566, loss = 807.36717733\n",
      "Iteration 20567, loss = 807.29662480\n",
      "Iteration 20568, loss = 807.22609529\n",
      "Iteration 20569, loss = 807.15558877\n",
      "Iteration 20570, loss = 807.08510523\n",
      "Iteration 20571, loss = 807.01464465\n",
      "Iteration 20572, loss = 806.94420700\n",
      "Iteration 20573, loss = 806.87379228\n",
      "Iteration 20574, loss = 806.80340047\n",
      "Iteration 20575, loss = 806.73303153\n",
      "Iteration 20576, loss = 806.66268546\n",
      "Iteration 20577, loss = 806.59236224\n",
      "Iteration 20578, loss = 806.52206185\n",
      "Iteration 20579, loss = 806.45178427\n",
      "Iteration 20580, loss = 806.38152948\n",
      "Iteration 20581, loss = 806.31129746\n",
      "Iteration 20582, loss = 806.24108820\n",
      "Iteration 20583, loss = 806.17090167\n",
      "Iteration 20584, loss = 806.10073786\n",
      "Iteration 20585, loss = 806.03059676\n",
      "Iteration 20586, loss = 805.96047834\n",
      "Iteration 20587, loss = 805.89038259\n",
      "Iteration 20588, loss = 805.82030951\n",
      "Iteration 20589, loss = 805.75025910\n",
      "Iteration 20590, loss = 805.68023139\n",
      "Iteration 20591, loss = 805.61022652\n",
      "Iteration 20592, loss = 805.54024477\n",
      "Iteration 20593, loss = 805.47028688\n",
      "Iteration 20594, loss = 805.40035454\n",
      "Iteration 20595, loss = 805.33045131\n",
      "Iteration 20596, loss = 805.26058311\n",
      "Iteration 20597, loss = 805.19075397\n",
      "Iteration 20598, loss = 805.12095049\n",
      "Iteration 20599, loss = 805.05114152\n",
      "Iteration 20600, loss = 804.98131711\n",
      "Iteration 20601, loss = 804.91148473\n",
      "Iteration 20602, loss = 804.84166799\n",
      "Iteration 20603, loss = 804.77192358\n",
      "Iteration 20604, loss = 804.70225288\n",
      "Iteration 20605, loss = 804.63258685\n",
      "Iteration 20606, loss = 804.56289925\n",
      "Iteration 20607, loss = 804.49322234\n",
      "Iteration 20608, loss = 804.42358032\n",
      "Iteration 20609, loss = 804.35398773\n",
      "Iteration 20610, loss = 804.28443240\n",
      "Iteration 20611, loss = 804.21487320\n",
      "Iteration 20612, loss = 804.14531364\n",
      "Iteration 20613, loss = 804.07579224\n",
      "Iteration 20614, loss = 804.00630937\n",
      "Iteration 20615, loss = 803.93684957\n",
      "Iteration 20616, loss = 803.86740432\n",
      "Iteration 20617, loss = 803.79796787\n",
      "Iteration 20618, loss = 803.72855719\n",
      "Iteration 20619, loss = 803.65918460\n",
      "Iteration 20620, loss = 803.58983295\n",
      "Iteration 20621, loss = 803.52049355\n",
      "Iteration 20622, loss = 803.45117408\n",
      "Iteration 20623, loss = 803.38187891\n",
      "Iteration 20624, loss = 803.31261167\n",
      "Iteration 20625, loss = 803.24336864\n",
      "Iteration 20626, loss = 803.17414059\n",
      "Iteration 20627, loss = 803.10493158\n",
      "Iteration 20628, loss = 803.03574929\n",
      "Iteration 20629, loss = 802.96659129\n",
      "Iteration 20630, loss = 802.89745449\n",
      "Iteration 20631, loss = 802.82833747\n",
      "Iteration 20632, loss = 802.75924015\n",
      "Iteration 20633, loss = 802.69016676\n",
      "Iteration 20634, loss = 802.62111804\n",
      "Iteration 20635, loss = 802.55208977\n",
      "Iteration 20636, loss = 802.48308144\n",
      "Iteration 20637, loss = 802.41409494\n",
      "Iteration 20638, loss = 802.34513088\n",
      "Iteration 20639, loss = 802.27618973\n",
      "Iteration 20640, loss = 802.20727039\n",
      "Iteration 20641, loss = 802.13837121\n",
      "Iteration 20642, loss = 802.06949341\n",
      "Iteration 20643, loss = 802.00063835\n",
      "Iteration 20644, loss = 801.93180533\n",
      "Iteration 20645, loss = 801.86299376\n",
      "Iteration 20646, loss = 801.79420338\n",
      "Iteration 20647, loss = 801.72543418\n",
      "Iteration 20648, loss = 801.65668694\n",
      "Iteration 20649, loss = 801.58796189\n",
      "Iteration 20650, loss = 801.51925819\n",
      "Iteration 20651, loss = 801.45057561\n",
      "Iteration 20652, loss = 801.38191452\n",
      "Iteration 20653, loss = 801.31327501\n",
      "Iteration 20654, loss = 801.24465723\n",
      "Iteration 20655, loss = 801.17606104\n",
      "Iteration 20656, loss = 801.10748604\n",
      "Iteration 20657, loss = 801.03893229\n",
      "Iteration 20658, loss = 800.97040009\n",
      "Iteration 20659, loss = 800.90188942\n",
      "Iteration 20660, loss = 800.83340016\n",
      "Iteration 20661, loss = 800.76493223\n",
      "Iteration 20662, loss = 800.69648552\n",
      "Iteration 20663, loss = 800.62806011\n",
      "Iteration 20664, loss = 800.55965613\n",
      "Iteration 20665, loss = 800.49127351\n",
      "Iteration 20666, loss = 800.42291212\n",
      "Iteration 20667, loss = 800.35457194\n",
      "Iteration 20668, loss = 800.28625300\n",
      "Iteration 20669, loss = 800.21795528\n",
      "Iteration 20670, loss = 800.14967884\n",
      "Iteration 20671, loss = 800.08142361\n",
      "Iteration 20672, loss = 800.01318953\n",
      "Iteration 20673, loss = 799.94497657\n",
      "Iteration 20674, loss = 799.87678476\n",
      "Iteration 20675, loss = 799.80861410\n",
      "Iteration 20676, loss = 799.74046457\n",
      "Iteration 20677, loss = 799.67233615\n",
      "Iteration 20678, loss = 799.60422878\n",
      "Iteration 20679, loss = 799.53614245\n",
      "Iteration 20680, loss = 799.46807718\n",
      "Iteration 20681, loss = 799.40003295\n",
      "Iteration 20682, loss = 799.33200973\n",
      "Iteration 20683, loss = 799.26400751\n",
      "Iteration 20684, loss = 799.19602627\n",
      "Iteration 20685, loss = 799.12806597\n",
      "Iteration 20686, loss = 799.06012662\n",
      "Iteration 20687, loss = 798.99220822\n",
      "Iteration 20688, loss = 798.92431072\n",
      "Iteration 20689, loss = 798.85643412\n",
      "Iteration 20690, loss = 798.78857840\n",
      "Iteration 20691, loss = 798.72074354\n",
      "Iteration 20692, loss = 798.65292952\n",
      "Iteration 20693, loss = 798.58513634\n",
      "Iteration 20694, loss = 798.51736398\n",
      "Iteration 20695, loss = 798.44961241\n",
      "Iteration 20696, loss = 798.38188162\n",
      "Iteration 20697, loss = 798.31417160\n",
      "Iteration 20698, loss = 798.24648232\n",
      "Iteration 20699, loss = 798.17881377\n",
      "Iteration 20700, loss = 798.11116595\n",
      "Iteration 20701, loss = 798.04353882\n",
      "Iteration 20702, loss = 797.97593237\n",
      "Iteration 20703, loss = 797.90834659\n",
      "Iteration 20704, loss = 797.84078146\n",
      "Iteration 20705, loss = 797.77323697\n",
      "Iteration 20706, loss = 797.70571309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20707, loss = 797.63820982\n",
      "Iteration 20708, loss = 797.57072713\n",
      "Iteration 20709, loss = 797.50326501\n",
      "Iteration 20710, loss = 797.43582344\n",
      "Iteration 20711, loss = 797.36840241\n",
      "Iteration 20712, loss = 797.30100190\n",
      "Iteration 20713, loss = 797.23362190\n",
      "Iteration 20714, loss = 797.16626238\n",
      "Iteration 20715, loss = 797.09892334\n",
      "Iteration 20716, loss = 797.03160475\n",
      "Iteration 20717, loss = 796.96430660\n",
      "Iteration 20718, loss = 796.89702888\n",
      "Iteration 20719, loss = 796.82977156\n",
      "Iteration 20720, loss = 796.76253464\n",
      "Iteration 20721, loss = 796.69531809\n",
      "Iteration 20722, loss = 796.62812190\n",
      "Iteration 20723, loss = 796.56094606\n",
      "Iteration 20724, loss = 796.49379054\n",
      "Iteration 20725, loss = 796.42665533\n",
      "Iteration 20726, loss = 796.35954042\n",
      "Iteration 20727, loss = 796.29244579\n",
      "Iteration 20728, loss = 796.22537142\n",
      "Iteration 20729, loss = 796.15831730\n",
      "Iteration 20730, loss = 796.09128342\n",
      "Iteration 20731, loss = 796.02426975\n",
      "Iteration 20732, loss = 795.95727627\n",
      "Iteration 20733, loss = 795.89030299\n",
      "Iteration 20734, loss = 795.82334987\n",
      "Iteration 20735, loss = 795.75641690\n",
      "Iteration 20736, loss = 795.68950407\n",
      "Iteration 20737, loss = 795.62261136\n",
      "Iteration 20738, loss = 795.55573875\n",
      "Iteration 20739, loss = 795.48888623\n",
      "Iteration 20740, loss = 795.42205379\n",
      "Iteration 20741, loss = 795.35524140\n",
      "Iteration 20742, loss = 795.28844906\n",
      "Iteration 20743, loss = 795.22167674\n",
      "Iteration 20744, loss = 795.15492443\n",
      "Iteration 20745, loss = 795.08819211\n",
      "Iteration 20746, loss = 795.02147977\n",
      "Iteration 20747, loss = 794.95478740\n",
      "Iteration 20748, loss = 794.88811497\n",
      "Iteration 20749, loss = 794.82146247\n",
      "Iteration 20750, loss = 794.75482989\n",
      "Iteration 20751, loss = 794.68821721\n",
      "Iteration 20752, loss = 794.62162441\n",
      "Iteration 20753, loss = 794.55505148\n",
      "Iteration 20754, loss = 794.48849840\n",
      "Iteration 20755, loss = 794.42196516\n",
      "Iteration 20756, loss = 794.35545174\n",
      "Iteration 20757, loss = 794.28895812\n",
      "Iteration 20758, loss = 794.22248430\n",
      "Iteration 20759, loss = 794.15603025\n",
      "Iteration 20760, loss = 794.08959596\n",
      "Iteration 20761, loss = 794.02318141\n",
      "Iteration 20762, loss = 793.95678660\n",
      "Iteration 20763, loss = 793.89041149\n",
      "Iteration 20764, loss = 793.82405608\n",
      "Iteration 20765, loss = 793.75772035\n",
      "Iteration 20766, loss = 793.69140428\n",
      "Iteration 20767, loss = 793.62510787\n",
      "Iteration 20768, loss = 793.55883109\n",
      "Iteration 20769, loss = 793.49257393\n",
      "Iteration 20770, loss = 793.42633637\n",
      "Iteration 20771, loss = 793.36011840\n",
      "Iteration 20772, loss = 793.29392000\n",
      "Iteration 20773, loss = 793.22774116\n",
      "Iteration 20774, loss = 793.16158187\n",
      "Iteration 20775, loss = 793.09544209\n",
      "Iteration 20776, loss = 793.02932183\n",
      "Iteration 20777, loss = 792.96322107\n",
      "Iteration 20778, loss = 792.89713978\n",
      "Iteration 20779, loss = 792.83107796\n",
      "Iteration 20780, loss = 792.76503558\n",
      "Iteration 20781, loss = 792.69901264\n",
      "Iteration 20782, loss = 792.63300912\n",
      "Iteration 20783, loss = 792.56702500\n",
      "Iteration 20784, loss = 792.50106027\n",
      "Iteration 20785, loss = 792.43511491\n",
      "Iteration 20786, loss = 792.36918891\n",
      "Iteration 20787, loss = 792.30328225\n",
      "Iteration 20788, loss = 792.23739492\n",
      "Iteration 20789, loss = 792.17152690\n",
      "Iteration 20790, loss = 792.10567818\n",
      "Iteration 20791, loss = 792.03984874\n",
      "Iteration 20792, loss = 791.97403858\n",
      "Iteration 20793, loss = 791.90824770\n",
      "Iteration 20794, loss = 791.84247609\n",
      "Iteration 20795, loss = 791.77672379\n",
      "Iteration 20796, loss = 791.71099087\n",
      "Iteration 20797, loss = 791.64527748\n",
      "Iteration 20798, loss = 791.57958398\n",
      "Iteration 20799, loss = 791.51391108\n",
      "Iteration 20800, loss = 791.44826019\n",
      "Iteration 20801, loss = 791.38263381\n",
      "Iteration 20802, loss = 791.31703565\n",
      "Iteration 20803, loss = 791.25146818\n",
      "Iteration 20804, loss = 791.18592579\n",
      "Iteration 20805, loss = 791.12038868\n",
      "Iteration 20806, loss = 791.05483564\n",
      "Iteration 20807, loss = 790.98926637\n",
      "Iteration 20808, loss = 790.92370636\n",
      "Iteration 20809, loss = 790.85819868\n",
      "Iteration 20810, loss = 790.79275663\n",
      "Iteration 20811, loss = 790.72734293\n",
      "Iteration 20812, loss = 790.66191955\n",
      "Iteration 20813, loss = 790.59648582\n",
      "Iteration 20814, loss = 790.53106675\n",
      "Iteration 20815, loss = 790.46568894\n",
      "Iteration 20816, loss = 790.40035507\n",
      "Iteration 20817, loss = 790.33503688\n",
      "Iteration 20818, loss = 790.26971424\n",
      "Iteration 20819, loss = 790.20440037\n",
      "Iteration 20820, loss = 790.13911531\n",
      "Iteration 20821, loss = 790.07386366\n",
      "Iteration 20822, loss = 790.00863538\n",
      "Iteration 20823, loss = 789.94341498\n",
      "Iteration 20824, loss = 789.87820225\n",
      "Iteration 20825, loss = 789.81301226\n",
      "Iteration 20826, loss = 789.74785117\n",
      "Iteration 20827, loss = 789.68271183\n",
      "Iteration 20828, loss = 789.61758668\n",
      "Iteration 20829, loss = 789.55247379\n",
      "Iteration 20830, loss = 789.48737883\n",
      "Iteration 20831, loss = 789.42230859\n",
      "Iteration 20832, loss = 789.35726081\n",
      "Iteration 20833, loss = 789.29222899\n",
      "Iteration 20834, loss = 789.22721193\n",
      "Iteration 20835, loss = 789.16221260\n",
      "Iteration 20836, loss = 789.09723422\n",
      "Iteration 20837, loss = 789.03227739\n",
      "Iteration 20838, loss = 788.96733886\n",
      "Iteration 20839, loss = 788.90241615\n",
      "Iteration 20840, loss = 788.83751084\n",
      "Iteration 20841, loss = 788.77262526\n",
      "Iteration 20842, loss = 788.70775974\n",
      "Iteration 20843, loss = 788.64291326\n",
      "Iteration 20844, loss = 788.57808426\n",
      "Iteration 20845, loss = 788.51327239\n",
      "Iteration 20846, loss = 788.44847910\n",
      "Iteration 20847, loss = 788.38370535\n",
      "Iteration 20848, loss = 788.31895060\n",
      "Iteration 20849, loss = 788.25421397\n",
      "Iteration 20850, loss = 788.18949506\n",
      "Iteration 20851, loss = 788.12479411\n",
      "Iteration 20852, loss = 788.06011187\n",
      "Iteration 20853, loss = 787.99544860\n",
      "Iteration 20854, loss = 787.93080378\n",
      "Iteration 20855, loss = 787.86617693\n",
      "Iteration 20856, loss = 787.80156808\n",
      "Iteration 20857, loss = 787.73697744\n",
      "Iteration 20858, loss = 787.67240529\n",
      "Iteration 20859, loss = 787.60785171\n",
      "Iteration 20860, loss = 787.54331639\n",
      "Iteration 20861, loss = 787.47879908\n",
      "Iteration 20862, loss = 787.41429982\n",
      "Iteration 20863, loss = 787.34981877\n",
      "Iteration 20864, loss = 787.28535603\n",
      "Iteration 20865, loss = 787.22091160\n",
      "Iteration 20866, loss = 787.15648534\n",
      "Iteration 20867, loss = 787.09207710\n",
      "Iteration 20868, loss = 787.02768690\n",
      "Iteration 20869, loss = 786.96331481\n",
      "Iteration 20870, loss = 786.89896088\n",
      "Iteration 20871, loss = 786.83462510\n",
      "Iteration 20872, loss = 786.77030741\n",
      "Iteration 20873, loss = 786.70600773\n",
      "Iteration 20874, loss = 786.64172604\n",
      "Iteration 20875, loss = 786.57746234\n",
      "Iteration 20876, loss = 786.51321668\n",
      "Iteration 20877, loss = 786.44898905\n",
      "Iteration 20878, loss = 786.38477942\n",
      "Iteration 20879, loss = 786.32058775\n",
      "Iteration 20880, loss = 786.25641401\n",
      "Iteration 20881, loss = 786.19225817\n",
      "Iteration 20882, loss = 786.12812026\n",
      "Iteration 20883, loss = 786.06400027\n",
      "Iteration 20884, loss = 785.99989818\n",
      "Iteration 20885, loss = 785.93581398\n",
      "Iteration 20886, loss = 785.87174763\n",
      "Iteration 20887, loss = 785.80769913\n",
      "Iteration 20888, loss = 785.74366844\n",
      "Iteration 20889, loss = 785.67965557\n",
      "Iteration 20890, loss = 785.61566051\n",
      "Iteration 20891, loss = 785.55168324\n",
      "Iteration 20892, loss = 785.48772375\n",
      "Iteration 20893, loss = 785.42378203\n",
      "Iteration 20894, loss = 785.35985804\n",
      "Iteration 20895, loss = 785.29595178\n",
      "Iteration 20896, loss = 785.23206323\n",
      "Iteration 20897, loss = 785.16819238\n",
      "Iteration 20898, loss = 785.10433922\n",
      "Iteration 20899, loss = 785.04050374\n",
      "Iteration 20900, loss = 784.97668591\n",
      "Iteration 20901, loss = 784.91288573\n",
      "Iteration 20902, loss = 784.84910317\n",
      "Iteration 20903, loss = 784.78533823\n",
      "Iteration 20904, loss = 784.72159088\n",
      "Iteration 20905, loss = 784.65786112\n",
      "Iteration 20906, loss = 784.59414892\n",
      "Iteration 20907, loss = 784.53045428\n",
      "Iteration 20908, loss = 784.46677719\n",
      "Iteration 20909, loss = 784.40311761\n",
      "Iteration 20910, loss = 784.33947556\n",
      "Iteration 20911, loss = 784.27585099\n",
      "Iteration 20912, loss = 784.21224391\n",
      "Iteration 20913, loss = 784.14865430\n",
      "Iteration 20914, loss = 784.08508214\n",
      "Iteration 20915, loss = 784.02152742\n",
      "Iteration 20916, loss = 783.95799012\n",
      "Iteration 20917, loss = 783.89447023\n",
      "Iteration 20918, loss = 783.83096774\n",
      "Iteration 20919, loss = 783.76748263\n",
      "Iteration 20920, loss = 783.70401488\n",
      "Iteration 20921, loss = 783.64056449\n",
      "Iteration 20922, loss = 783.57713143\n",
      "Iteration 20923, loss = 783.51371569\n",
      "Iteration 20924, loss = 783.45031727\n",
      "Iteration 20925, loss = 783.38693613\n",
      "Iteration 20926, loss = 783.32357228\n",
      "Iteration 20927, loss = 783.26022569\n",
      "Iteration 20928, loss = 783.19689635\n",
      "Iteration 20929, loss = 783.13358424\n",
      "Iteration 20930, loss = 783.07028936\n",
      "Iteration 20931, loss = 783.00701169\n",
      "Iteration 20932, loss = 782.94375120\n",
      "Iteration 20933, loss = 782.88050789\n",
      "Iteration 20934, loss = 782.81728175\n",
      "Iteration 20935, loss = 782.75407276\n",
      "Iteration 20936, loss = 782.69088090\n",
      "Iteration 20937, loss = 782.62770616\n",
      "Iteration 20938, loss = 782.56454852\n",
      "Iteration 20939, loss = 782.50140798\n",
      "Iteration 20940, loss = 782.43828452\n",
      "Iteration 20941, loss = 782.37517813\n",
      "Iteration 20942, loss = 782.31208879\n",
      "Iteration 20943, loss = 782.24901649\n",
      "Iteration 20944, loss = 782.18596124\n",
      "Iteration 20945, loss = 782.12292302\n",
      "Iteration 20946, loss = 782.05990186\n",
      "Iteration 20947, loss = 781.99689779\n",
      "Iteration 20948, loss = 781.93391087\n",
      "Iteration 20949, loss = 781.87094126\n",
      "Iteration 20950, loss = 781.80798924\n",
      "Iteration 20951, loss = 781.74505532\n",
      "Iteration 20952, loss = 781.68214041\n",
      "Iteration 20953, loss = 781.61924597\n",
      "Iteration 20954, loss = 781.55637397\n",
      "Iteration 20955, loss = 781.49352578\n",
      "Iteration 20956, loss = 781.43069922\n",
      "Iteration 20957, loss = 781.36788442\n",
      "Iteration 20958, loss = 781.30506641\n",
      "Iteration 20959, loss = 781.24223841\n",
      "Iteration 20960, loss = 781.17941251\n",
      "Iteration 20961, loss = 781.11661481\n",
      "Iteration 20962, loss = 781.05386344\n",
      "Iteration 20963, loss = 780.99115055\n",
      "Iteration 20964, loss = 780.92845159\n",
      "Iteration 20965, loss = 780.86574959\n",
      "Iteration 20966, loss = 780.80304653\n",
      "Iteration 20967, loss = 780.74035867\n",
      "Iteration 20968, loss = 780.67770291\n",
      "Iteration 20969, loss = 780.61507934\n",
      "Iteration 20970, loss = 780.55247292\n",
      "Iteration 20971, loss = 780.48987177\n",
      "Iteration 20972, loss = 780.42727693\n",
      "Iteration 20973, loss = 780.36469843\n",
      "Iteration 20974, loss = 780.30214533\n",
      "Iteration 20975, loss = 780.23961703\n",
      "Iteration 20976, loss = 780.17710462\n",
      "Iteration 20977, loss = 780.11460188\n",
      "Iteration 20978, loss = 780.05211068\n",
      "Iteration 20979, loss = 779.98963674\n",
      "Iteration 20980, loss = 779.92718427\n",
      "Iteration 20981, loss = 779.86475232\n",
      "Iteration 20982, loss = 779.80233604\n",
      "Iteration 20983, loss = 779.73993236\n",
      "Iteration 20984, loss = 779.67754261\n",
      "Iteration 20985, loss = 779.61516999\n",
      "Iteration 20986, loss = 779.55281645\n",
      "Iteration 20987, loss = 779.49048137\n",
      "Iteration 20988, loss = 779.42816225\n",
      "Iteration 20989, loss = 779.36585746\n",
      "Iteration 20990, loss = 779.30356768\n",
      "Iteration 20991, loss = 779.24129449\n",
      "Iteration 20992, loss = 779.17903893\n",
      "Iteration 20993, loss = 779.11680086\n",
      "Iteration 20994, loss = 779.05457913\n",
      "Iteration 20995, loss = 778.99237274\n",
      "Iteration 20996, loss = 778.93018174\n",
      "Iteration 20997, loss = 778.86800689\n",
      "Iteration 20998, loss = 778.80584881\n",
      "Iteration 20999, loss = 778.74370764\n",
      "Iteration 21000, loss = 778.68158298\n",
      "Iteration 21001, loss = 778.61947422\n",
      "Iteration 21002, loss = 778.55738115\n",
      "Iteration 21003, loss = 778.49530397\n",
      "Iteration 21004, loss = 778.43324302\n",
      "Iteration 21005, loss = 778.37119850\n",
      "Iteration 21006, loss = 778.30917042\n",
      "Iteration 21007, loss = 778.24715853\n",
      "Iteration 21008, loss = 778.18516257\n",
      "Iteration 21009, loss = 778.12318248\n",
      "Iteration 21010, loss = 778.06121832\n",
      "Iteration 21011, loss = 777.99927023\n",
      "Iteration 21012, loss = 777.93733831\n",
      "Iteration 21013, loss = 777.87542256\n",
      "Iteration 21014, loss = 777.81352288\n",
      "Iteration 21015, loss = 777.75163917\n",
      "Iteration 21016, loss = 777.68977135\n",
      "Iteration 21017, loss = 777.62791942\n",
      "Iteration 21018, loss = 777.56608340\n",
      "Iteration 21019, loss = 777.50426334\n",
      "Iteration 21020, loss = 777.44245926\n",
      "Iteration 21021, loss = 777.38067114\n",
      "Iteration 21022, loss = 777.31889894\n",
      "Iteration 21023, loss = 777.25714263\n",
      "Iteration 21024, loss = 777.19540215\n",
      "Iteration 21025, loss = 777.13367749\n",
      "Iteration 21026, loss = 777.07196864\n",
      "Iteration 21027, loss = 777.01027560\n",
      "Iteration 21028, loss = 776.94859839\n",
      "Iteration 21029, loss = 776.88693698\n",
      "Iteration 21030, loss = 776.82529137\n",
      "Iteration 21031, loss = 776.76366154\n",
      "Iteration 21032, loss = 776.70204747\n",
      "Iteration 21033, loss = 776.64044913\n",
      "Iteration 21034, loss = 776.57886650\n",
      "Iteration 21035, loss = 776.51729957\n",
      "Iteration 21036, loss = 776.45574832\n",
      "Iteration 21037, loss = 776.39421275\n",
      "Iteration 21038, loss = 776.33269284\n",
      "Iteration 21039, loss = 776.27118858\n",
      "Iteration 21040, loss = 776.20969996\n",
      "Iteration 21041, loss = 776.14822697\n",
      "Iteration 21042, loss = 776.08676958\n",
      "Iteration 21043, loss = 776.02532778\n",
      "Iteration 21044, loss = 775.96390157\n",
      "Iteration 21045, loss = 775.90249092\n",
      "Iteration 21046, loss = 775.84109581\n",
      "Iteration 21047, loss = 775.77971625\n",
      "Iteration 21048, loss = 775.71835220\n",
      "Iteration 21049, loss = 775.65700366\n",
      "Iteration 21050, loss = 775.59567060\n",
      "Iteration 21051, loss = 775.53435303\n",
      "Iteration 21052, loss = 775.47305092\n",
      "Iteration 21053, loss = 775.41176426\n",
      "Iteration 21054, loss = 775.35049303\n",
      "Iteration 21055, loss = 775.28923723\n",
      "Iteration 21056, loss = 775.22799684\n",
      "Iteration 21057, loss = 775.16677185\n",
      "Iteration 21058, loss = 775.10556226\n",
      "Iteration 21059, loss = 775.04436807\n",
      "Iteration 21060, loss = 774.98318927\n",
      "Iteration 21061, loss = 774.92202589\n",
      "Iteration 21062, loss = 774.86087798\n",
      "Iteration 21063, loss = 774.79974562\n",
      "Iteration 21064, loss = 774.73862895\n",
      "Iteration 21065, loss = 774.67752826\n",
      "Iteration 21066, loss = 774.61644399\n",
      "Iteration 21067, loss = 774.55537690\n",
      "Iteration 21068, loss = 774.49432807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21069, loss = 774.43329882\n",
      "Iteration 21070, loss = 774.37228988\n",
      "Iteration 21071, loss = 774.31129945\n",
      "Iteration 21072, loss = 774.25032085\n",
      "Iteration 21073, loss = 774.18934313\n",
      "Iteration 21074, loss = 774.12835904\n",
      "Iteration 21075, loss = 774.06737506\n",
      "Iteration 21076, loss = 774.00641006\n",
      "Iteration 21077, loss = 773.94548105\n",
      "Iteration 21078, loss = 773.88458828\n",
      "Iteration 21079, loss = 773.82371689\n",
      "Iteration 21080, loss = 773.76285081\n",
      "Iteration 21081, loss = 773.70198329\n",
      "Iteration 21082, loss = 773.64112073\n",
      "Iteration 21083, loss = 773.58027744\n",
      "Iteration 21084, loss = 773.51946231\n",
      "Iteration 21085, loss = 773.45867156\n",
      "Iteration 21086, loss = 773.39789500\n",
      "Iteration 21087, loss = 773.33712509\n",
      "Iteration 21088, loss = 773.27636207\n",
      "Iteration 21089, loss = 773.21561318\n",
      "Iteration 21090, loss = 773.15488517\n",
      "Iteration 21091, loss = 773.09417838\n",
      "Iteration 21092, loss = 773.03348812\n",
      "Iteration 21093, loss = 772.97280942\n",
      "Iteration 21094, loss = 772.91214078\n",
      "Iteration 21095, loss = 772.85148492\n",
      "Iteration 21096, loss = 772.79084588\n",
      "Iteration 21097, loss = 772.73022518\n",
      "Iteration 21098, loss = 772.66962135\n",
      "Iteration 21099, loss = 772.60903169\n",
      "Iteration 21100, loss = 772.54845442\n",
      "Iteration 21101, loss = 772.48788998\n",
      "Iteration 21102, loss = 772.42734022\n",
      "Iteration 21103, loss = 772.36680662\n",
      "Iteration 21104, loss = 772.30628931\n",
      "Iteration 21105, loss = 772.24578733\n",
      "Iteration 21106, loss = 772.18529944\n",
      "Iteration 21107, loss = 772.12482504\n",
      "Iteration 21108, loss = 772.06436451\n",
      "Iteration 21109, loss = 772.00391866\n",
      "Iteration 21110, loss = 771.94348809\n",
      "Iteration 21111, loss = 771.88307287\n",
      "Iteration 21112, loss = 771.82267259\n",
      "Iteration 21113, loss = 771.76228668\n",
      "Iteration 21114, loss = 771.70191484\n",
      "Iteration 21115, loss = 771.64155715\n",
      "Iteration 21116, loss = 771.58121383\n",
      "Iteration 21117, loss = 771.52088521\n",
      "Iteration 21118, loss = 771.46057142\n",
      "Iteration 21119, loss = 771.40027238\n",
      "Iteration 21120, loss = 771.33998790\n",
      "Iteration 21121, loss = 771.27971778\n",
      "Iteration 21122, loss = 771.21946192\n",
      "Iteration 21123, loss = 771.15922031\n",
      "Iteration 21124, loss = 771.09899304\n",
      "Iteration 21125, loss = 771.03878019\n",
      "Iteration 21126, loss = 770.97858183\n",
      "Iteration 21127, loss = 770.91839795\n",
      "Iteration 21128, loss = 770.85822850\n",
      "Iteration 21129, loss = 770.79807342\n",
      "Iteration 21130, loss = 770.73793264\n",
      "Iteration 21131, loss = 770.67780612\n",
      "Iteration 21132, loss = 770.61769383\n",
      "Iteration 21133, loss = 770.55759578\n",
      "Iteration 21134, loss = 770.49751197\n",
      "Iteration 21135, loss = 770.43744242\n",
      "Iteration 21136, loss = 770.37738713\n",
      "Iteration 21137, loss = 770.31734609\n",
      "Iteration 21138, loss = 770.25731928\n",
      "Iteration 21139, loss = 770.19730669\n",
      "Iteration 21140, loss = 770.13730828\n",
      "Iteration 21141, loss = 770.07732403\n",
      "Iteration 21142, loss = 770.01735393\n",
      "Iteration 21143, loss = 769.95739796\n",
      "Iteration 21144, loss = 769.89745610\n",
      "Iteration 21145, loss = 769.83752833\n",
      "Iteration 21146, loss = 769.77761465\n",
      "Iteration 21147, loss = 769.71771504\n",
      "Iteration 21148, loss = 769.65782948\n",
      "Iteration 21149, loss = 769.59795797\n",
      "Iteration 21150, loss = 769.53810050\n",
      "Iteration 21151, loss = 769.47825704\n",
      "Iteration 21152, loss = 769.41842759\n",
      "Iteration 21153, loss = 769.35861214\n",
      "Iteration 21154, loss = 769.29881067\n",
      "Iteration 21155, loss = 769.23902319\n",
      "Iteration 21156, loss = 769.17924968\n",
      "Iteration 21157, loss = 769.11949016\n",
      "Iteration 21158, loss = 769.05974464\n",
      "Iteration 21159, loss = 769.00001315\n",
      "Iteration 21160, loss = 768.94029578\n",
      "Iteration 21161, loss = 768.88059264\n",
      "Iteration 21162, loss = 768.82090394\n",
      "Iteration 21163, loss = 768.76123002\n",
      "Iteration 21164, loss = 768.70157143\n",
      "Iteration 21165, loss = 768.64192893\n",
      "Iteration 21166, loss = 768.58230349\n",
      "Iteration 21167, loss = 768.52269589\n",
      "Iteration 21168, loss = 768.46310562\n",
      "Iteration 21169, loss = 768.40352924\n",
      "Iteration 21170, loss = 768.34395926\n",
      "Iteration 21171, loss = 768.28438718\n",
      "Iteration 21172, loss = 768.22481120\n",
      "Iteration 21173, loss = 768.16524139\n",
      "Iteration 21174, loss = 768.10569454\n",
      "Iteration 21175, loss = 768.04618063\n",
      "Iteration 21176, loss = 767.98669575\n",
      "Iteration 21177, loss = 767.92722718\n",
      "Iteration 21178, loss = 767.86776286\n",
      "Iteration 21179, loss = 767.80829845\n",
      "Iteration 21180, loss = 767.74883973\n",
      "Iteration 21181, loss = 767.68939800\n",
      "Iteration 21182, loss = 767.62998011\n",
      "Iteration 21183, loss = 767.57058420\n",
      "Iteration 21184, loss = 767.51120294\n",
      "Iteration 21185, loss = 767.45182944\n",
      "Iteration 21186, loss = 767.39246230\n",
      "Iteration 21187, loss = 767.33310570\n",
      "Iteration 21188, loss = 767.27376524\n",
      "Iteration 21189, loss = 767.21444353\n",
      "Iteration 21190, loss = 767.15513898\n",
      "Iteration 21191, loss = 767.09584763\n",
      "Iteration 21192, loss = 767.03656648\n",
      "Iteration 21193, loss = 766.97729543\n",
      "Iteration 21194, loss = 766.91803663\n",
      "Iteration 21195, loss = 766.85879265\n",
      "Iteration 21196, loss = 766.79956458\n",
      "Iteration 21197, loss = 766.74035155\n",
      "Iteration 21198, loss = 766.68115179\n",
      "Iteration 21199, loss = 766.62196396\n",
      "Iteration 21200, loss = 766.56278783\n",
      "Iteration 21201, loss = 766.50362420\n",
      "Iteration 21202, loss = 766.44447421\n",
      "Iteration 21203, loss = 766.38533851\n",
      "Iteration 21204, loss = 766.32621701\n",
      "Iteration 21205, loss = 766.26710909\n",
      "Iteration 21206, loss = 766.20801405\n",
      "Iteration 21207, loss = 766.14893152\n",
      "Iteration 21208, loss = 766.08986156\n",
      "Iteration 21209, loss = 766.03080451\n",
      "Iteration 21210, loss = 765.97176075\n",
      "Iteration 21211, loss = 765.91273052\n",
      "Iteration 21212, loss = 765.85371379\n",
      "Iteration 21213, loss = 765.79471035\n",
      "Iteration 21214, loss = 765.73571997\n",
      "Iteration 21215, loss = 765.67674246\n",
      "Iteration 21216, loss = 765.61777774\n",
      "Iteration 21217, loss = 765.55882585\n",
      "Iteration 21218, loss = 765.49988690\n",
      "Iteration 21219, loss = 765.44096097\n",
      "Iteration 21220, loss = 765.38204812\n",
      "Iteration 21221, loss = 765.32314837\n",
      "Iteration 21222, loss = 765.26426167\n",
      "Iteration 21223, loss = 765.20538795\n",
      "Iteration 21224, loss = 765.14652716\n",
      "Iteration 21225, loss = 765.08767925\n",
      "Iteration 21226, loss = 765.02884416\n",
      "Iteration 21227, loss = 764.97002189\n",
      "Iteration 21228, loss = 764.91121242\n",
      "Iteration 21229, loss = 764.85241577\n",
      "Iteration 21230, loss = 764.79363192\n",
      "Iteration 21231, loss = 764.73486088\n",
      "Iteration 21232, loss = 764.67610264\n",
      "Iteration 21233, loss = 764.61735719\n",
      "Iteration 21234, loss = 764.55862452\n",
      "Iteration 21235, loss = 764.49990460\n",
      "Iteration 21236, loss = 764.44119743\n",
      "Iteration 21237, loss = 764.38250298\n",
      "Iteration 21238, loss = 764.32382124\n",
      "Iteration 21239, loss = 764.26515218\n",
      "Iteration 21240, loss = 764.20649580\n",
      "Iteration 21241, loss = 764.14785207\n",
      "Iteration 21242, loss = 764.08922098\n",
      "Iteration 21243, loss = 764.03060252\n",
      "Iteration 21244, loss = 763.97199667\n",
      "Iteration 21245, loss = 763.91340342\n",
      "Iteration 21246, loss = 763.85482277\n",
      "Iteration 21247, loss = 763.79625470\n",
      "Iteration 21248, loss = 763.73769922\n",
      "Iteration 21249, loss = 763.67915633\n",
      "Iteration 21250, loss = 763.62062609\n",
      "Iteration 21251, loss = 763.56210853\n",
      "Iteration 21252, loss = 763.50360382\n",
      "Iteration 21253, loss = 763.44511217\n",
      "Iteration 21254, loss = 763.38663402\n",
      "Iteration 21255, loss = 763.32817012\n",
      "Iteration 21256, loss = 763.26972174\n",
      "Iteration 21257, loss = 763.21129077\n",
      "Iteration 21258, loss = 763.15287949\n",
      "Iteration 21259, loss = 763.09448903\n",
      "Iteration 21260, loss = 763.03611527\n",
      "Iteration 21261, loss = 762.97774448\n",
      "Iteration 21262, loss = 762.91935671\n",
      "Iteration 21263, loss = 762.86094526\n",
      "Iteration 21264, loss = 762.80253356\n",
      "Iteration 21265, loss = 762.74415916\n",
      "Iteration 21266, loss = 762.68583757\n",
      "Iteration 21267, loss = 762.62754875\n",
      "Iteration 21268, loss = 762.56925968\n",
      "Iteration 21269, loss = 762.51095299\n",
      "Iteration 21270, loss = 762.45263971\n",
      "Iteration 21271, loss = 762.39434851\n",
      "Iteration 21272, loss = 762.33609429\n",
      "Iteration 21273, loss = 762.27786526\n",
      "Iteration 21274, loss = 762.21963996\n",
      "Iteration 21275, loss = 762.16140861\n",
      "Iteration 21276, loss = 762.10318123\n",
      "Iteration 21277, loss = 762.04497472\n",
      "Iteration 21278, loss = 761.98679403\n",
      "Iteration 21279, loss = 761.92862963\n",
      "Iteration 21280, loss = 761.87046989\n",
      "Iteration 21281, loss = 761.81231254\n",
      "Iteration 21282, loss = 761.75416544\n",
      "Iteration 21283, loss = 761.69603695\n",
      "Iteration 21284, loss = 761.63792719\n",
      "Iteration 21285, loss = 761.57982986\n",
      "Iteration 21286, loss = 761.52173948\n",
      "Iteration 21287, loss = 761.46365638\n",
      "Iteration 21288, loss = 761.40558548\n",
      "Iteration 21289, loss = 761.34753042\n",
      "Iteration 21290, loss = 761.28949043\n",
      "Iteration 21291, loss = 761.23146210\n",
      "Iteration 21292, loss = 761.17344280\n",
      "Iteration 21293, loss = 761.11543305\n",
      "Iteration 21294, loss = 761.05743536\n",
      "Iteration 21295, loss = 760.99945151\n",
      "Iteration 21296, loss = 760.94148119\n",
      "Iteration 21297, loss = 760.88352266\n",
      "Iteration 21298, loss = 760.82557454\n",
      "Iteration 21299, loss = 760.76763686\n",
      "Iteration 21300, loss = 760.70971075\n",
      "Iteration 21301, loss = 760.65179720\n",
      "Iteration 21302, loss = 760.59389637\n",
      "Iteration 21303, loss = 760.53600758\n",
      "Iteration 21304, loss = 760.47813002\n",
      "Iteration 21305, loss = 760.42026339\n",
      "Iteration 21306, loss = 760.36240797\n",
      "Iteration 21307, loss = 760.30456430\n",
      "Iteration 21308, loss = 760.24673271\n",
      "Iteration 21309, loss = 760.18891313\n",
      "Iteration 21310, loss = 760.13110522\n",
      "Iteration 21311, loss = 760.07330865\n",
      "Iteration 21312, loss = 760.01552330\n",
      "Iteration 21313, loss = 759.95774926\n",
      "Iteration 21314, loss = 759.89998676\n",
      "Iteration 21315, loss = 759.84223592\n",
      "Iteration 21316, loss = 759.78449676\n",
      "Iteration 21317, loss = 759.72676918\n",
      "Iteration 21318, loss = 759.66905301\n",
      "Iteration 21319, loss = 759.61134817\n",
      "Iteration 21320, loss = 759.55365460\n",
      "Iteration 21321, loss = 759.49597236\n",
      "Iteration 21322, loss = 759.43830151\n",
      "Iteration 21323, loss = 759.38064208\n",
      "Iteration 21324, loss = 759.32299407\n",
      "Iteration 21325, loss = 759.26535745\n",
      "Iteration 21326, loss = 759.20773217\n",
      "Iteration 21327, loss = 759.15011817\n",
      "Iteration 21328, loss = 759.09251542\n",
      "Iteration 21329, loss = 759.03492389\n",
      "Iteration 21330, loss = 758.97734359\n",
      "Iteration 21331, loss = 758.91977451\n",
      "Iteration 21332, loss = 758.86221665\n",
      "Iteration 21333, loss = 758.80467002\n",
      "Iteration 21334, loss = 758.74713458\n",
      "Iteration 21335, loss = 758.68961034\n",
      "Iteration 21336, loss = 758.63209726\n",
      "Iteration 21337, loss = 758.57459533\n",
      "Iteration 21338, loss = 758.51710452\n",
      "Iteration 21339, loss = 758.45962481\n",
      "Iteration 21340, loss = 758.40215619\n",
      "Iteration 21341, loss = 758.34469864\n",
      "Iteration 21342, loss = 758.28725213\n",
      "Iteration 21343, loss = 758.22981667\n",
      "Iteration 21344, loss = 758.17239223\n",
      "Iteration 21345, loss = 758.11497880\n",
      "Iteration 21346, loss = 758.05757636\n",
      "Iteration 21347, loss = 758.00018490\n",
      "Iteration 21348, loss = 757.94280440\n",
      "Iteration 21349, loss = 757.88543486\n",
      "Iteration 21350, loss = 757.82807625\n",
      "Iteration 21351, loss = 757.77072856\n",
      "Iteration 21352, loss = 757.71339179\n",
      "Iteration 21353, loss = 757.65606592\n",
      "Iteration 21354, loss = 757.59875095\n",
      "Iteration 21355, loss = 757.54144689\n",
      "Iteration 21356, loss = 757.48415375\n",
      "Iteration 21357, loss = 757.42687159\n",
      "Iteration 21358, loss = 757.36960048\n",
      "Iteration 21359, loss = 757.31234060\n",
      "Iteration 21360, loss = 757.25509220\n",
      "Iteration 21361, loss = 757.19785579\n",
      "Iteration 21362, loss = 757.14063213\n",
      "Iteration 21363, loss = 757.08342252\n",
      "Iteration 21364, loss = 757.02622868\n",
      "Iteration 21365, loss = 756.96905241\n",
      "Iteration 21366, loss = 756.91189383\n",
      "Iteration 21367, loss = 756.85474775\n",
      "Iteration 21368, loss = 756.79760076\n",
      "Iteration 21369, loss = 756.74043592\n",
      "Iteration 21370, loss = 756.68325039\n",
      "Iteration 21371, loss = 756.62606726\n",
      "Iteration 21372, loss = 756.56891908\n",
      "Iteration 21373, loss = 756.51181747\n",
      "Iteration 21374, loss = 756.45474478\n",
      "Iteration 21375, loss = 756.39767275\n",
      "Iteration 21376, loss = 756.34058496\n",
      "Iteration 21377, loss = 756.28348892\n",
      "Iteration 21378, loss = 756.22640873\n",
      "Iteration 21379, loss = 756.16936000\n",
      "Iteration 21380, loss = 756.11233680\n",
      "Iteration 21381, loss = 756.05532123\n",
      "Iteration 21382, loss = 755.99830088\n",
      "Iteration 21383, loss = 755.94127966\n",
      "Iteration 21384, loss = 755.88427135\n",
      "Iteration 21385, loss = 755.82728498\n",
      "Iteration 21386, loss = 755.77031740\n",
      "Iteration 21387, loss = 755.71335836\n",
      "Iteration 21388, loss = 755.65640129\n",
      "Iteration 21389, loss = 755.59944848\n",
      "Iteration 21390, loss = 755.54250734\n",
      "Iteration 21391, loss = 755.48558268\n",
      "Iteration 21392, loss = 755.42867287\n",
      "Iteration 21393, loss = 755.37177254\n",
      "Iteration 21394, loss = 755.31487813\n",
      "Iteration 21395, loss = 755.25799049\n",
      "Iteration 21396, loss = 755.20111325\n",
      "Iteration 21397, loss = 755.14424921\n",
      "Iteration 21398, loss = 755.08739805\n",
      "Iteration 21399, loss = 755.03055729\n",
      "Iteration 21400, loss = 754.97372479\n",
      "Iteration 21401, loss = 754.91690027\n",
      "Iteration 21402, loss = 754.86008525\n",
      "Iteration 21403, loss = 754.80328135\n",
      "Iteration 21404, loss = 754.74648908\n",
      "Iteration 21405, loss = 754.68970768\n",
      "Iteration 21406, loss = 754.63293592\n",
      "Iteration 21407, loss = 754.57617312\n",
      "Iteration 21408, loss = 754.51941946\n",
      "Iteration 21409, loss = 754.46267566\n",
      "Iteration 21410, loss = 754.40594238\n",
      "Iteration 21411, loss = 754.34921974\n",
      "Iteration 21412, loss = 754.29250739\n",
      "Iteration 21413, loss = 754.23580482\n",
      "Iteration 21414, loss = 754.17911171\n",
      "Iteration 21415, loss = 754.12242803\n",
      "Iteration 21416, loss = 754.06575404\n",
      "Iteration 21417, loss = 754.00909000\n",
      "Iteration 21418, loss = 753.95243607\n",
      "Iteration 21419, loss = 753.89579220\n",
      "Iteration 21420, loss = 753.83915821\n",
      "Iteration 21421, loss = 753.78253393\n",
      "Iteration 21422, loss = 753.72591924\n",
      "Iteration 21423, loss = 753.66931411\n",
      "Iteration 21424, loss = 753.61271859\n",
      "Iteration 21425, loss = 753.55613278\n",
      "Iteration 21426, loss = 753.49955672\n",
      "Iteration 21427, loss = 753.44299043\n",
      "Iteration 21428, loss = 753.38643387\n",
      "Iteration 21429, loss = 753.32988698\n",
      "Iteration 21430, loss = 753.27334970\n",
      "Iteration 21431, loss = 753.21682199\n",
      "Iteration 21432, loss = 753.16030380\n",
      "Iteration 21433, loss = 753.10379514\n",
      "Iteration 21434, loss = 753.04729599\n",
      "Iteration 21435, loss = 752.99080636\n",
      "Iteration 21436, loss = 752.93432626\n",
      "Iteration 21437, loss = 752.87785566\n",
      "Iteration 21438, loss = 752.82139456\n",
      "Iteration 21439, loss = 752.76494295\n",
      "Iteration 21440, loss = 752.70850080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21441, loss = 752.65206810\n",
      "Iteration 21442, loss = 752.59564481\n",
      "Iteration 21443, loss = 752.53923092\n",
      "Iteration 21444, loss = 752.48282642\n",
      "Iteration 21445, loss = 752.42643128\n",
      "Iteration 21446, loss = 752.37004549\n",
      "Iteration 21447, loss = 752.31366903\n",
      "Iteration 21448, loss = 752.25730189\n",
      "Iteration 21449, loss = 752.20094406\n",
      "Iteration 21450, loss = 752.14459552\n",
      "Iteration 21451, loss = 752.08825627\n",
      "Iteration 21452, loss = 752.03192629\n",
      "Iteration 21453, loss = 751.97560560\n",
      "Iteration 21454, loss = 751.91929419\n",
      "Iteration 21455, loss = 751.86299211\n",
      "Iteration 21456, loss = 751.80669939\n",
      "Iteration 21457, loss = 751.75041613\n",
      "Iteration 21458, loss = 751.69414249\n",
      "Iteration 21459, loss = 751.63787876\n",
      "Iteration 21460, loss = 751.58162537\n",
      "Iteration 21461, loss = 751.52538309\n",
      "Iteration 21462, loss = 751.46915296\n",
      "Iteration 21463, loss = 751.41293643\n",
      "Iteration 21464, loss = 751.35673481\n",
      "Iteration 21465, loss = 751.30054793\n",
      "Iteration 21466, loss = 751.24437162\n",
      "Iteration 21467, loss = 751.18819506\n",
      "Iteration 21468, loss = 751.13200444\n",
      "Iteration 21469, loss = 751.07579493\n",
      "Iteration 21470, loss = 751.01958212\n",
      "Iteration 21471, loss = 750.96339349\n",
      "Iteration 21472, loss = 750.90724445\n",
      "Iteration 21473, loss = 750.85112681\n",
      "Iteration 21474, loss = 750.79501863\n",
      "Iteration 21475, loss = 750.73890099\n",
      "Iteration 21476, loss = 750.68277096\n",
      "Iteration 21477, loss = 750.62664315\n",
      "Iteration 21478, loss = 750.57053591\n",
      "Iteration 21479, loss = 750.51445494\n",
      "Iteration 21480, loss = 750.45839091\n",
      "Iteration 21481, loss = 750.40232977\n",
      "Iteration 21482, loss = 750.34626480\n",
      "Iteration 21483, loss = 750.29020088\n",
      "Iteration 21484, loss = 750.23414853\n",
      "Iteration 21485, loss = 750.17811416\n",
      "Iteration 21486, loss = 750.12209529\n",
      "Iteration 21487, loss = 750.06608451\n",
      "Iteration 21488, loss = 750.01007640\n",
      "Iteration 21489, loss = 749.95407131\n",
      "Iteration 21490, loss = 749.89807418\n",
      "Iteration 21491, loss = 749.84208947\n",
      "Iteration 21492, loss = 749.78611784\n",
      "Iteration 21493, loss = 749.73015639\n",
      "Iteration 21494, loss = 749.67420157\n",
      "Iteration 21495, loss = 749.61825206\n",
      "Iteration 21496, loss = 749.56230915\n",
      "Iteration 21497, loss = 749.50637532\n",
      "Iteration 21498, loss = 749.45045214\n",
      "Iteration 21499, loss = 749.39453933\n",
      "Iteration 21500, loss = 749.33863539\n",
      "Iteration 21501, loss = 749.28273882\n",
      "Iteration 21502, loss = 749.22684918\n",
      "Iteration 21503, loss = 749.17096707\n",
      "Iteration 21504, loss = 749.11509354\n",
      "Iteration 21505, loss = 749.05922928\n",
      "Iteration 21506, loss = 749.00337430\n",
      "Iteration 21507, loss = 748.94752805\n",
      "Iteration 21508, loss = 748.89168988\n",
      "Iteration 21509, loss = 748.83585940\n",
      "Iteration 21510, loss = 748.78003665\n",
      "Iteration 21511, loss = 748.72422195\n",
      "Iteration 21512, loss = 748.66841565\n",
      "Iteration 21513, loss = 748.61261795\n",
      "Iteration 21514, loss = 748.55682883\n",
      "Iteration 21515, loss = 748.50104809\n",
      "Iteration 21516, loss = 748.44527551\n",
      "Iteration 21517, loss = 748.38951090\n",
      "Iteration 21518, loss = 748.33375422\n",
      "Iteration 21519, loss = 748.27800550\n",
      "Iteration 21520, loss = 748.22226485\n",
      "Iteration 21521, loss = 748.16653233\n",
      "Iteration 21522, loss = 748.11080801\n",
      "Iteration 21523, loss = 748.05509187\n",
      "Iteration 21524, loss = 747.99938386\n",
      "Iteration 21525, loss = 747.94368393\n",
      "Iteration 21526, loss = 747.88799200\n",
      "Iteration 21527, loss = 747.83230804\n",
      "Iteration 21528, loss = 747.77663200\n",
      "Iteration 21529, loss = 747.72096387\n",
      "Iteration 21530, loss = 747.66530364\n",
      "Iteration 21531, loss = 747.60965133\n",
      "Iteration 21532, loss = 747.55400692\n",
      "Iteration 21533, loss = 747.49837042\n",
      "Iteration 21534, loss = 747.44274180\n",
      "Iteration 21535, loss = 747.38712106\n",
      "Iteration 21536, loss = 747.33150818\n",
      "Iteration 21537, loss = 747.27590315\n",
      "Iteration 21538, loss = 747.22030593\n",
      "Iteration 21539, loss = 747.16471652\n",
      "Iteration 21540, loss = 747.10913489\n",
      "Iteration 21541, loss = 747.05356103\n",
      "Iteration 21542, loss = 746.99799492\n",
      "Iteration 21543, loss = 746.94243653\n",
      "Iteration 21544, loss = 746.88688587\n",
      "Iteration 21545, loss = 746.83134291\n",
      "Iteration 21546, loss = 746.77580764\n",
      "Iteration 21547, loss = 746.72028005\n",
      "Iteration 21548, loss = 746.66476014\n",
      "Iteration 21549, loss = 746.60924791\n",
      "Iteration 21550, loss = 746.55374337\n",
      "Iteration 21551, loss = 746.49824656\n",
      "Iteration 21552, loss = 746.44275754\n",
      "Iteration 21553, loss = 746.38727643\n",
      "Iteration 21554, loss = 746.33180347\n",
      "Iteration 21555, loss = 746.27633903\n",
      "Iteration 21556, loss = 746.22088377\n",
      "Iteration 21557, loss = 746.16543876\n",
      "Iteration 21558, loss = 746.11000566\n",
      "Iteration 21559, loss = 746.05458670\n",
      "Iteration 21560, loss = 745.99918389\n",
      "Iteration 21561, loss = 745.94379672\n",
      "Iteration 21562, loss = 745.88841708\n",
      "Iteration 21563, loss = 745.83302668\n",
      "Iteration 21564, loss = 745.77760511\n",
      "Iteration 21565, loss = 745.72215452\n",
      "Iteration 21566, loss = 745.66670987\n",
      "Iteration 21567, loss = 745.61131026\n",
      "Iteration 21568, loss = 745.55596121\n",
      "Iteration 21569, loss = 745.50063384\n",
      "Iteration 21570, loss = 745.44529275\n",
      "Iteration 21571, loss = 745.38992449\n",
      "Iteration 21572, loss = 745.33454848\n",
      "Iteration 21573, loss = 745.27919623\n",
      "Iteration 21574, loss = 745.22387876\n",
      "Iteration 21575, loss = 745.16857962\n",
      "Iteration 21576, loss = 745.11327509\n",
      "Iteration 21577, loss = 745.05795754\n",
      "Iteration 21578, loss = 745.00264033\n",
      "Iteration 21579, loss = 744.94734139\n",
      "Iteration 21580, loss = 744.89206466\n",
      "Iteration 21581, loss = 744.83679882\n",
      "Iteration 21582, loss = 744.78153120\n",
      "Iteration 21583, loss = 744.72626006\n",
      "Iteration 21584, loss = 744.67099430\n",
      "Iteration 21585, loss = 744.61574289\n",
      "Iteration 21586, loss = 744.56050609\n",
      "Iteration 21587, loss = 744.50527703\n",
      "Iteration 21588, loss = 744.45004955\n",
      "Iteration 21589, loss = 744.39482370\n",
      "Iteration 21590, loss = 744.33960457\n",
      "Iteration 21591, loss = 744.28439644\n",
      "Iteration 21592, loss = 744.22919913\n",
      "Iteration 21593, loss = 744.17400901\n",
      "Iteration 21594, loss = 744.11882294\n",
      "Iteration 21595, loss = 744.06364092\n",
      "Iteration 21596, loss = 744.00846536\n",
      "Iteration 21597, loss = 743.95329856\n",
      "Iteration 21598, loss = 743.89814073\n",
      "Iteration 21599, loss = 743.84299027\n",
      "Iteration 21600, loss = 743.78784547\n",
      "Iteration 21601, loss = 743.73270583\n",
      "Iteration 21602, loss = 743.67757226\n",
      "Iteration 21603, loss = 743.62244599\n",
      "Iteration 21604, loss = 743.56732757\n",
      "Iteration 21605, loss = 743.51221658\n",
      "Iteration 21606, loss = 743.45711216\n",
      "Iteration 21607, loss = 743.40201371\n",
      "Iteration 21608, loss = 743.34692122\n",
      "Iteration 21609, loss = 743.29183519\n",
      "Iteration 21610, loss = 743.23675608\n",
      "Iteration 21611, loss = 743.18168409\n",
      "Iteration 21612, loss = 743.12661901\n",
      "Iteration 21613, loss = 743.07156046\n",
      "Iteration 21614, loss = 743.01650817\n",
      "Iteration 21615, loss = 742.96146209\n",
      "Iteration 21616, loss = 742.90642235\n",
      "Iteration 21617, loss = 742.85138916\n",
      "Iteration 21618, loss = 742.79636264\n",
      "Iteration 21619, loss = 742.74134277\n",
      "Iteration 21620, loss = 742.68632943\n",
      "Iteration 21621, loss = 742.63132249\n",
      "Iteration 21622, loss = 742.57632184\n",
      "Iteration 21623, loss = 742.52132746\n",
      "Iteration 21624, loss = 742.46633936\n",
      "Iteration 21625, loss = 742.41135762\n",
      "Iteration 21626, loss = 742.35638226\n",
      "Iteration 21627, loss = 742.30141329\n",
      "Iteration 21628, loss = 742.24645069\n",
      "Iteration 21629, loss = 742.19149440\n",
      "Iteration 21630, loss = 742.13654437\n",
      "Iteration 21631, loss = 742.08160056\n",
      "Iteration 21632, loss = 742.02666295\n",
      "Iteration 21633, loss = 741.97173151\n",
      "Iteration 21634, loss = 741.91680626\n",
      "Iteration 21635, loss = 741.86188718\n",
      "Iteration 21636, loss = 741.80697428\n",
      "Iteration 21637, loss = 741.75206753\n",
      "Iteration 21638, loss = 741.69716693\n",
      "Iteration 21639, loss = 741.64227246\n",
      "Iteration 21640, loss = 741.58738410\n",
      "Iteration 21641, loss = 741.53250181\n",
      "Iteration 21642, loss = 741.47762558\n",
      "Iteration 21643, loss = 741.42275540\n",
      "Iteration 21644, loss = 741.36789123\n",
      "Iteration 21645, loss = 741.31303306\n",
      "Iteration 21646, loss = 741.25818089\n",
      "Iteration 21647, loss = 741.20333468\n",
      "Iteration 21648, loss = 741.14849442\n",
      "Iteration 21649, loss = 741.09366010\n",
      "Iteration 21650, loss = 741.03883170\n",
      "Iteration 21651, loss = 740.98400921\n",
      "Iteration 21652, loss = 740.92919260\n",
      "Iteration 21653, loss = 740.87438187\n",
      "Iteration 21654, loss = 740.81957699\n",
      "Iteration 21655, loss = 740.76477796\n",
      "Iteration 21656, loss = 740.70998475\n",
      "Iteration 21657, loss = 740.65519737\n",
      "Iteration 21658, loss = 740.60041579\n",
      "Iteration 21659, loss = 740.54564002\n",
      "Iteration 21660, loss = 740.49087008\n",
      "Iteration 21661, loss = 740.43610598\n",
      "Iteration 21662, loss = 740.38134779\n",
      "Iteration 21663, loss = 740.32659561\n",
      "Iteration 21664, loss = 740.27184960\n",
      "Iteration 21665, loss = 740.21711010\n",
      "Iteration 21666, loss = 740.16237760\n",
      "Iteration 21667, loss = 740.10765296\n",
      "Iteration 21668, loss = 740.05293748\n",
      "Iteration 21669, loss = 739.99823298\n",
      "Iteration 21670, loss = 739.94354148\n",
      "Iteration 21671, loss = 739.88886373\n",
      "Iteration 21672, loss = 739.83419630\n",
      "Iteration 21673, loss = 739.77952682\n",
      "Iteration 21674, loss = 739.72483611\n",
      "Iteration 21675, loss = 739.67011177\n",
      "Iteration 21676, loss = 739.61536927\n",
      "Iteration 21677, loss = 739.56064674\n",
      "Iteration 21678, loss = 739.50597116\n",
      "Iteration 21679, loss = 739.45133508\n",
      "Iteration 21680, loss = 739.39670751\n",
      "Iteration 21681, loss = 739.34205983\n",
      "Iteration 21682, loss = 739.28738747\n",
      "Iteration 21683, loss = 739.23271272\n",
      "Iteration 21684, loss = 739.17806209\n",
      "Iteration 21685, loss = 739.12344116\n",
      "Iteration 21686, loss = 739.06883300\n",
      "Iteration 21687, loss = 739.01421740\n",
      "Iteration 21688, loss = 738.95958903\n",
      "Iteration 21689, loss = 738.90496009\n",
      "Iteration 21690, loss = 738.85034626\n",
      "Iteration 21691, loss = 738.79575127\n",
      "Iteration 21692, loss = 738.74116581\n",
      "Iteration 21693, loss = 738.68657844\n",
      "Iteration 21694, loss = 738.63198635\n",
      "Iteration 21695, loss = 738.57739626\n",
      "Iteration 21696, loss = 738.52281654\n",
      "Iteration 21697, loss = 738.46824924\n",
      "Iteration 21698, loss = 738.41368948\n",
      "Iteration 21699, loss = 738.35913122\n",
      "Iteration 21700, loss = 738.30457268\n",
      "Iteration 21701, loss = 738.25001707\n",
      "Iteration 21702, loss = 738.19546879\n",
      "Iteration 21703, loss = 738.14092936\n",
      "Iteration 21704, loss = 738.08639672\n",
      "Iteration 21705, loss = 738.03186770\n",
      "Iteration 21706, loss = 737.97734084\n",
      "Iteration 21707, loss = 737.92281717\n",
      "Iteration 21708, loss = 737.86829889\n",
      "Iteration 21709, loss = 737.81378731\n",
      "Iteration 21710, loss = 737.75928203\n",
      "Iteration 21711, loss = 737.70478158\n",
      "Iteration 21712, loss = 737.65028475\n",
      "Iteration 21713, loss = 737.59579144\n",
      "Iteration 21714, loss = 737.54130244\n",
      "Iteration 21715, loss = 737.48681869\n",
      "Iteration 21716, loss = 737.43234052\n",
      "Iteration 21717, loss = 737.37786758\n",
      "Iteration 21718, loss = 737.32339919\n",
      "Iteration 21719, loss = 737.26893486\n",
      "Iteration 21720, loss = 737.21447456\n",
      "Iteration 21721, loss = 737.16001862\n",
      "Iteration 21722, loss = 737.10556742\n",
      "Iteration 21723, loss = 737.05112114\n",
      "Iteration 21724, loss = 736.99667967\n",
      "Iteration 21725, loss = 736.94224275\n",
      "Iteration 21726, loss = 736.88781010\n",
      "Iteration 21727, loss = 736.83338163\n",
      "Iteration 21728, loss = 736.77895738\n",
      "Iteration 21729, loss = 736.72453749\n",
      "Iteration 21730, loss = 736.67012206\n",
      "Iteration 21731, loss = 736.61571112\n",
      "Iteration 21732, loss = 736.56130462\n",
      "Iteration 21733, loss = 736.50690245\n",
      "Iteration 21734, loss = 736.45250451\n",
      "Iteration 21735, loss = 736.39811072\n",
      "Iteration 21736, loss = 736.34372106\n",
      "Iteration 21737, loss = 736.28933555\n",
      "Iteration 21738, loss = 736.23495422\n",
      "Iteration 21739, loss = 736.18057708\n",
      "Iteration 21740, loss = 736.12620411\n",
      "Iteration 21741, loss = 736.07183528\n",
      "Iteration 21742, loss = 736.01747056\n",
      "Iteration 21743, loss = 735.96310988\n",
      "Iteration 21744, loss = 735.90875321\n",
      "Iteration 21745, loss = 735.85440052\n",
      "Iteration 21746, loss = 735.80005178\n",
      "Iteration 21747, loss = 735.74570697\n",
      "Iteration 21748, loss = 735.69136607\n",
      "Iteration 21749, loss = 735.63702908\n",
      "Iteration 21750, loss = 735.58269597\n",
      "Iteration 21751, loss = 735.52836672\n",
      "Iteration 21752, loss = 735.47404131\n",
      "Iteration 21753, loss = 735.41971969\n",
      "Iteration 21754, loss = 735.36540185\n",
      "Iteration 21755, loss = 735.31108775\n",
      "Iteration 21756, loss = 735.25677736\n",
      "Iteration 21757, loss = 735.20247066\n",
      "Iteration 21758, loss = 735.14816762\n",
      "Iteration 21759, loss = 735.09386821\n",
      "Iteration 21760, loss = 735.03957239\n",
      "Iteration 21761, loss = 734.98528015\n",
      "Iteration 21762, loss = 734.93099146\n",
      "Iteration 21763, loss = 734.87670629\n",
      "Iteration 21764, loss = 734.82242460\n",
      "Iteration 21765, loss = 734.76814638\n",
      "Iteration 21766, loss = 734.71387160\n",
      "Iteration 21767, loss = 734.65960022\n",
      "Iteration 21768, loss = 734.60533222\n",
      "Iteration 21769, loss = 734.55106756\n",
      "Iteration 21770, loss = 734.49680623\n",
      "Iteration 21771, loss = 734.44254820\n",
      "Iteration 21772, loss = 734.38829344\n",
      "Iteration 21773, loss = 734.33404193\n",
      "Iteration 21774, loss = 734.27979367\n",
      "Iteration 21775, loss = 734.22554863\n",
      "Iteration 21776, loss = 734.17130683\n",
      "Iteration 21777, loss = 734.11706831\n",
      "Iteration 21778, loss = 734.06283314\n",
      "Iteration 21779, loss = 734.00860145\n",
      "Iteration 21780, loss = 733.95437348\n",
      "Iteration 21781, loss = 733.90014965\n",
      "Iteration 21782, loss = 733.84593061\n",
      "Iteration 21783, loss = 733.79171739\n",
      "Iteration 21784, loss = 733.73751144\n",
      "Iteration 21785, loss = 733.68331450\n",
      "Iteration 21786, loss = 733.62912776\n",
      "Iteration 21787, loss = 733.57495003\n",
      "Iteration 21788, loss = 733.52077384\n",
      "Iteration 21789, loss = 733.46658452\n",
      "Iteration 21790, loss = 733.41236545\n",
      "Iteration 21791, loss = 733.35811640\n",
      "Iteration 21792, loss = 733.30386235\n",
      "Iteration 21793, loss = 733.24963705\n",
      "Iteration 21794, loss = 733.19545328\n",
      "Iteration 21795, loss = 733.14129480\n",
      "Iteration 21796, loss = 733.08713247\n",
      "Iteration 21797, loss = 733.03294583\n",
      "Iteration 21798, loss = 732.97873772\n",
      "Iteration 21799, loss = 732.92453048\n",
      "Iteration 21800, loss = 732.87034485\n",
      "Iteration 21801, loss = 732.81618192\n",
      "Iteration 21802, loss = 732.76202566\n",
      "Iteration 21803, loss = 732.70785937\n",
      "Iteration 21804, loss = 732.65367957\n",
      "Iteration 21805, loss = 732.59949702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21806, loss = 732.54532497\n",
      "Iteration 21807, loss = 732.49116693\n",
      "Iteration 21808, loss = 732.43701544\n",
      "Iteration 21809, loss = 732.38286060\n",
      "Iteration 21810, loss = 732.32869889\n",
      "Iteration 21811, loss = 732.27453497\n",
      "Iteration 21812, loss = 732.22037615\n",
      "Iteration 21813, loss = 732.16622550\n",
      "Iteration 21814, loss = 732.11208007\n",
      "Iteration 21815, loss = 732.05793452\n",
      "Iteration 21816, loss = 732.00378603\n",
      "Iteration 21817, loss = 731.94963602\n",
      "Iteration 21818, loss = 731.89548818\n",
      "Iteration 21819, loss = 731.84134487\n",
      "Iteration 21820, loss = 731.78720550\n",
      "Iteration 21821, loss = 731.73306753\n",
      "Iteration 21822, loss = 731.67892886\n",
      "Iteration 21823, loss = 731.62478933\n",
      "Iteration 21824, loss = 731.57065037\n",
      "Iteration 21825, loss = 731.51651357\n",
      "Iteration 21826, loss = 731.46237939\n",
      "Iteration 21827, loss = 731.40824700\n",
      "Iteration 21828, loss = 731.35411515\n",
      "Iteration 21829, loss = 731.29998309\n",
      "Iteration 21830, loss = 731.24585098\n",
      "Iteration 21831, loss = 731.19171954\n",
      "Iteration 21832, loss = 731.13758936\n",
      "Iteration 21833, loss = 731.08346051\n",
      "Iteration 21834, loss = 731.02933257\n",
      "Iteration 21835, loss = 730.97520495\n",
      "Iteration 21836, loss = 730.92107728\n",
      "Iteration 21837, loss = 730.86694956\n",
      "Iteration 21838, loss = 730.81282204\n",
      "Iteration 21839, loss = 730.75869496\n",
      "Iteration 21840, loss = 730.70456837\n",
      "Iteration 21841, loss = 730.65044211\n",
      "Iteration 21842, loss = 730.59631589\n",
      "Iteration 21843, loss = 730.54218948\n",
      "Iteration 21844, loss = 730.48806275\n",
      "Iteration 21845, loss = 730.43393571\n",
      "Iteration 21846, loss = 730.37980840\n",
      "Iteration 21847, loss = 730.32568086\n",
      "Iteration 21848, loss = 730.27155304\n",
      "Iteration 21849, loss = 730.21742484\n",
      "Iteration 21850, loss = 730.16329609\n",
      "Iteration 21851, loss = 730.10916666\n",
      "Iteration 21852, loss = 730.05503643\n",
      "Iteration 21853, loss = 730.00090534\n",
      "Iteration 21854, loss = 729.94677334\n",
      "Iteration 21855, loss = 729.89264040\n",
      "Iteration 21856, loss = 729.83850647\n",
      "Iteration 21857, loss = 729.78437144\n",
      "Iteration 21858, loss = 729.73023523\n",
      "Iteration 21859, loss = 729.67609772\n",
      "Iteration 21860, loss = 729.62195881\n",
      "Iteration 21861, loss = 729.56781838\n",
      "Iteration 21862, loss = 729.51367635\n",
      "Iteration 21863, loss = 729.45953264\n",
      "Iteration 21864, loss = 729.40538716\n",
      "Iteration 21865, loss = 729.35123983\n",
      "Iteration 21866, loss = 729.29709055\n",
      "Iteration 21867, loss = 729.24293922\n",
      "Iteration 21868, loss = 729.18878575\n",
      "Iteration 21869, loss = 729.13463002\n",
      "Iteration 21870, loss = 729.08047193\n",
      "Iteration 21871, loss = 729.02631136\n",
      "Iteration 21872, loss = 728.97214821\n",
      "Iteration 21873, loss = 728.91798236\n",
      "Iteration 21874, loss = 728.86381371\n",
      "Iteration 21875, loss = 728.80964215\n",
      "Iteration 21876, loss = 728.75546756\n",
      "Iteration 21877, loss = 728.70128983\n",
      "Iteration 21878, loss = 728.64710884\n",
      "Iteration 21879, loss = 728.59292447\n",
      "Iteration 21880, loss = 728.53873661\n",
      "Iteration 21881, loss = 728.48454512\n",
      "Iteration 21882, loss = 728.43034988\n",
      "Iteration 21883, loss = 728.37615075\n",
      "Iteration 21884, loss = 728.32194762\n",
      "Iteration 21885, loss = 728.26774035\n",
      "Iteration 21886, loss = 728.21352879\n",
      "Iteration 21887, loss = 728.15931282\n",
      "Iteration 21888, loss = 728.10509230\n",
      "Iteration 21889, loss = 728.05086708\n",
      "Iteration 21890, loss = 727.99663702\n",
      "Iteration 21891, loss = 727.94240197\n",
      "Iteration 21892, loss = 727.88816179\n",
      "Iteration 21893, loss = 727.83391631\n",
      "Iteration 21894, loss = 727.77966540\n",
      "Iteration 21895, loss = 727.72540889\n",
      "Iteration 21896, loss = 727.67114662\n",
      "Iteration 21897, loss = 727.61687844\n",
      "Iteration 21898, loss = 727.56260417\n",
      "Iteration 21899, loss = 727.50832364\n",
      "Iteration 21900, loss = 727.45403670\n",
      "Iteration 21901, loss = 727.39974317\n",
      "Iteration 21902, loss = 727.34544287\n",
      "Iteration 21903, loss = 727.29113562\n",
      "Iteration 21904, loss = 727.23682126\n",
      "Iteration 21905, loss = 727.18249959\n",
      "Iteration 21906, loss = 727.12817045\n",
      "Iteration 21907, loss = 727.07383365\n",
      "Iteration 21908, loss = 727.01948902\n",
      "Iteration 21909, loss = 726.96513642\n",
      "Iteration 21910, loss = 726.91077569\n",
      "Iteration 21911, loss = 726.85640674\n",
      "Iteration 21912, loss = 726.80202950\n",
      "Iteration 21913, loss = 726.74764401\n",
      "Iteration 21914, loss = 726.69325042\n",
      "Iteration 21915, loss = 726.63884906\n",
      "Iteration 21916, loss = 726.58444049\n",
      "Iteration 21917, loss = 726.53002557\n",
      "Iteration 21918, loss = 726.47560517\n",
      "Iteration 21919, loss = 726.42117990\n",
      "Iteration 21920, loss = 726.36674847\n",
      "Iteration 21921, loss = 726.31230639\n",
      "Iteration 21922, loss = 726.25784369\n",
      "Iteration 21923, loss = 726.20334894\n",
      "Iteration 21924, loss = 726.14881664\n",
      "Iteration 21925, loss = 726.09425772\n",
      "Iteration 21926, loss = 726.03969467\n",
      "Iteration 21927, loss = 725.98514516\n",
      "Iteration 21928, loss = 725.93060875\n",
      "Iteration 21929, loss = 725.87606951\n",
      "Iteration 21930, loss = 725.82150805\n",
      "Iteration 21931, loss = 725.76691337\n",
      "Iteration 21932, loss = 725.71228948\n",
      "Iteration 21933, loss = 725.65765111\n",
      "Iteration 21934, loss = 725.60301132\n",
      "Iteration 21935, loss = 725.54837128\n",
      "Iteration 21936, loss = 725.49372128\n",
      "Iteration 21937, loss = 725.43904967\n",
      "Iteration 21938, loss = 725.38435135\n",
      "Iteration 21939, loss = 725.32963045\n",
      "Iteration 21940, loss = 725.27489534\n",
      "Iteration 21941, loss = 725.22015116\n",
      "Iteration 21942, loss = 725.16539605\n",
      "Iteration 21943, loss = 725.11062365\n",
      "Iteration 21944, loss = 725.05582856\n",
      "Iteration 21945, loss = 725.00100990\n",
      "Iteration 21946, loss = 724.94617093\n",
      "Iteration 21947, loss = 724.89131544\n",
      "Iteration 21948, loss = 724.83644439\n",
      "Iteration 21949, loss = 724.78155541\n",
      "Iteration 21950, loss = 724.72664496\n",
      "Iteration 21951, loss = 724.67171086\n",
      "Iteration 21952, loss = 724.61675335\n",
      "Iteration 21953, loss = 724.56177412\n",
      "Iteration 21954, loss = 724.50677438\n",
      "Iteration 21955, loss = 724.45175373\n",
      "Iteration 21956, loss = 724.39671042\n",
      "Iteration 21957, loss = 724.34164252\n",
      "Iteration 21958, loss = 724.28654905\n",
      "Iteration 21959, loss = 724.23143009\n",
      "Iteration 21960, loss = 724.17628615\n",
      "Iteration 21961, loss = 724.12111736\n",
      "Iteration 21962, loss = 724.06592304\n",
      "Iteration 21963, loss = 724.01070197\n",
      "Iteration 21964, loss = 723.95545298\n",
      "Iteration 21965, loss = 723.90017533\n",
      "Iteration 21966, loss = 723.84486874\n",
      "Iteration 21967, loss = 723.78953311\n",
      "Iteration 21968, loss = 723.73416809\n",
      "Iteration 21969, loss = 723.67877299\n",
      "Iteration 21970, loss = 723.62334687\n",
      "Iteration 21971, loss = 723.56788880\n",
      "Iteration 21972, loss = 723.51239802\n",
      "Iteration 21973, loss = 723.45687399\n",
      "Iteration 21974, loss = 723.40131625\n",
      "Iteration 21975, loss = 723.34572422\n",
      "Iteration 21976, loss = 723.29009718\n",
      "Iteration 21977, loss = 723.23443427\n",
      "Iteration 21978, loss = 723.17873460\n",
      "Iteration 21979, loss = 723.12299734\n",
      "Iteration 21980, loss = 723.06722175\n",
      "Iteration 21981, loss = 723.01140713\n",
      "Iteration 21982, loss = 722.95555274\n",
      "Iteration 21983, loss = 722.89965778\n",
      "Iteration 21984, loss = 722.84372134\n",
      "Iteration 21985, loss = 722.78774251\n",
      "Iteration 21986, loss = 722.73172035\n",
      "Iteration 21987, loss = 722.67565396\n",
      "Iteration 21988, loss = 722.61954244\n",
      "Iteration 21989, loss = 722.56338491\n",
      "Iteration 21990, loss = 722.50718042\n",
      "Iteration 21991, loss = 722.45092799\n",
      "Iteration 21992, loss = 722.39462658\n",
      "Iteration 21993, loss = 722.33827516\n",
      "Iteration 21994, loss = 722.28187266\n",
      "Iteration 21995, loss = 722.22541801\n",
      "Iteration 21996, loss = 722.16891016\n",
      "Iteration 21997, loss = 722.11234799\n",
      "Iteration 21998, loss = 722.05573038\n",
      "Iteration 21999, loss = 721.99905616\n",
      "Iteration 22000, loss = 721.94232413\n",
      "Iteration 22001, loss = 721.88553307\n",
      "Iteration 22002, loss = 721.82868173\n",
      "Iteration 22003, loss = 721.77176886\n",
      "Iteration 22004, loss = 721.71479315\n",
      "Iteration 22005, loss = 721.65775330\n",
      "Iteration 22006, loss = 721.60064796\n",
      "Iteration 22007, loss = 721.54347575\n",
      "Iteration 22008, loss = 721.48623523\n",
      "Iteration 22009, loss = 721.42892498\n",
      "Iteration 22010, loss = 721.37154350\n",
      "Iteration 22011, loss = 721.31408929\n",
      "Iteration 22012, loss = 721.25656081\n",
      "Iteration 22013, loss = 721.19895649\n",
      "Iteration 22014, loss = 721.14127471\n",
      "Iteration 22015, loss = 721.08351382\n",
      "Iteration 22016, loss = 721.02567213\n",
      "Iteration 22017, loss = 720.96774792\n",
      "Iteration 22018, loss = 720.90973940\n",
      "Iteration 22019, loss = 720.85164478\n",
      "Iteration 22020, loss = 720.79346221\n",
      "Iteration 22021, loss = 720.73518980\n",
      "Iteration 22022, loss = 720.67682560\n",
      "Iteration 22023, loss = 720.61836764\n",
      "Iteration 22024, loss = 720.55981388\n",
      "Iteration 22025, loss = 720.50116225\n",
      "Iteration 22026, loss = 720.44241061\n",
      "Iteration 22027, loss = 720.38355679\n",
      "Iteration 22028, loss = 720.32459856\n",
      "Iteration 22029, loss = 720.26553362\n",
      "Iteration 22030, loss = 720.20635963\n",
      "Iteration 22031, loss = 720.14707420\n",
      "Iteration 22032, loss = 720.08767486\n",
      "Iteration 22033, loss = 720.02815910\n",
      "Iteration 22034, loss = 719.96852431\n",
      "Iteration 22035, loss = 719.90876786\n",
      "Iteration 22036, loss = 719.84888703\n",
      "Iteration 22037, loss = 719.78887902\n",
      "Iteration 22038, loss = 719.72874098\n",
      "Iteration 22039, loss = 719.66846998\n",
      "Iteration 22040, loss = 719.60806299\n",
      "Iteration 22041, loss = 719.54751693\n",
      "Iteration 22042, loss = 719.48682863\n",
      "Iteration 22043, loss = 719.42599482\n",
      "Iteration 22044, loss = 719.36501216\n",
      "Iteration 22045, loss = 719.30387721\n",
      "Iteration 22046, loss = 719.24258643\n",
      "Iteration 22047, loss = 719.18113620\n",
      "Iteration 22048, loss = 719.11952278\n",
      "Iteration 22049, loss = 719.05774233\n",
      "Iteration 22050, loss = 718.99579090\n",
      "Iteration 22051, loss = 718.93366444\n",
      "Iteration 22052, loss = 718.87135875\n",
      "Iteration 22053, loss = 718.80886955\n",
      "Iteration 22054, loss = 718.74619239\n",
      "Iteration 22055, loss = 718.68332271\n",
      "Iteration 22056, loss = 718.62025583\n",
      "Iteration 22057, loss = 718.55698688\n",
      "Iteration 22058, loss = 718.49351088\n",
      "Iteration 22059, loss = 718.42982268\n",
      "Iteration 22060, loss = 718.36591698\n",
      "Iteration 22061, loss = 718.30178828\n",
      "Iteration 22062, loss = 718.23743094\n",
      "Iteration 22063, loss = 718.17283911\n",
      "Iteration 22064, loss = 718.10800677\n",
      "Iteration 22065, loss = 718.04292768\n",
      "Iteration 22066, loss = 717.97759541\n",
      "Iteration 22067, loss = 717.91200329\n",
      "Iteration 22068, loss = 717.84614443\n",
      "Iteration 22069, loss = 717.78001171\n",
      "Iteration 22070, loss = 717.71359775\n",
      "Iteration 22071, loss = 717.64689490\n",
      "Iteration 22072, loss = 717.57989525\n",
      "Iteration 22073, loss = 717.51259059\n",
      "Iteration 22074, loss = 717.44497241\n",
      "Iteration 22075, loss = 717.37703188\n",
      "Iteration 22076, loss = 717.30875984\n",
      "Iteration 22077, loss = 717.24014678\n",
      "Iteration 22078, loss = 717.17118281\n",
      "Iteration 22079, loss = 717.10185766\n",
      "Iteration 22080, loss = 717.03216064\n",
      "Iteration 22081, loss = 716.96208063\n",
      "Iteration 22082, loss = 716.89160608\n",
      "Iteration 22083, loss = 716.82072491\n",
      "Iteration 22084, loss = 716.74942458\n",
      "Iteration 22085, loss = 716.67769199\n",
      "Iteration 22086, loss = 716.60551347\n",
      "Iteration 22087, loss = 716.53287475\n",
      "Iteration 22088, loss = 716.45976094\n",
      "Iteration 22089, loss = 716.38615645\n",
      "Iteration 22090, loss = 716.31204501\n",
      "Iteration 22091, loss = 716.23740955\n",
      "Iteration 22092, loss = 716.16223222\n",
      "Iteration 22093, loss = 716.08649429\n",
      "Iteration 22094, loss = 716.01017615\n",
      "Iteration 22095, loss = 715.93325718\n",
      "Iteration 22096, loss = 715.85571574\n",
      "Iteration 22097, loss = 715.77752907\n",
      "Iteration 22098, loss = 715.69867324\n",
      "Iteration 22099, loss = 715.61912303\n",
      "Iteration 22100, loss = 715.53885188\n",
      "Iteration 22101, loss = 715.45783176\n",
      "Iteration 22102, loss = 715.37603307\n",
      "Iteration 22103, loss = 715.29342454\n",
      "Iteration 22104, loss = 715.20997309\n",
      "Iteration 22105, loss = 715.12564366\n",
      "Iteration 22106, loss = 715.04039910\n",
      "Iteration 22107, loss = 714.95419999\n",
      "Iteration 22108, loss = 714.86700442\n",
      "Iteration 22109, loss = 714.77876782\n",
      "Iteration 22110, loss = 714.68944269\n",
      "Iteration 22111, loss = 714.59897839\n",
      "Iteration 22112, loss = 714.50732081\n",
      "Iteration 22113, loss = 714.41441208\n",
      "Iteration 22114, loss = 714.32019021\n",
      "Iteration 22115, loss = 714.22458870\n",
      "Iteration 22116, loss = 714.12753605\n",
      "Iteration 22117, loss = 714.02895533\n",
      "Iteration 22118, loss = 713.92876356\n",
      "Iteration 22119, loss = 713.82687107\n",
      "Iteration 22120, loss = 713.72318081\n",
      "Iteration 22121, loss = 713.61758749\n",
      "Iteration 22122, loss = 713.50997666\n",
      "Iteration 22123, loss = 713.40022363\n",
      "Iteration 22124, loss = 713.28819223\n",
      "Iteration 22125, loss = 713.17373345\n",
      "Iteration 22126, loss = 713.05668377\n",
      "Iteration 22127, loss = 712.93686340\n",
      "Iteration 22128, loss = 712.81407415\n",
      "Iteration 22129, loss = 712.68809707\n",
      "Iteration 22130, loss = 712.55868987\n",
      "Iteration 22131, loss = 712.42558400\n",
      "Iteration 22132, loss = 712.28848165\n",
      "Iteration 22133, loss = 712.14705274\n",
      "Iteration 22134, loss = 712.00093233\n",
      "Iteration 22135, loss = 711.84971903\n",
      "Iteration 22136, loss = 711.69297542\n",
      "Iteration 22137, loss = 711.53023202\n",
      "Iteration 22138, loss = 711.36099677\n",
      "Iteration 22139, loss = 711.18477228\n",
      "Iteration 22140, loss = 711.00108256\n",
      "Iteration 22141, loss = 710.80950932\n",
      "Iteration 22142, loss = 710.60973496\n",
      "Iteration 22143, loss = 710.40158628\n",
      "Iteration 22144, loss = 710.18507093\n",
      "Iteration 22145, loss = 709.96039969\n",
      "Iteration 22146, loss = 709.72799112\n",
      "Iteration 22147, loss = 709.48845851\n",
      "Iteration 22148, loss = 709.24258188\n",
      "Iteration 22149, loss = 708.99126838\n",
      "Iteration 22150, loss = 708.73550408\n",
      "Iteration 22151, loss = 708.47629959\n",
      "Iteration 22152, loss = 708.21463191\n",
      "Iteration 22153, loss = 707.95138581\n",
      "Iteration 22154, loss = 707.68729962\n",
      "Iteration 22155, loss = 707.42292366\n",
      "Iteration 22156, loss = 707.15860150\n",
      "Iteration 22157, loss = 706.89448412\n",
      "Iteration 22158, loss = 706.63058031\n",
      "Iteration 22159, loss = 706.36683414\n",
      "Iteration 22160, loss = 706.10320820\n",
      "Iteration 22161, loss = 705.83974705\n",
      "Iteration 22162, loss = 705.57660441\n",
      "Iteration 22163, loss = 705.31403199\n",
      "Iteration 22164, loss = 705.05234044\n",
      "Iteration 22165, loss = 704.79184733\n",
      "Iteration 22166, loss = 704.53282587\n",
      "Iteration 22167, loss = 704.27546556\n",
      "Iteration 22168, loss = 704.01985250\n",
      "Iteration 22169, loss = 703.76597369\n",
      "Iteration 22170, loss = 703.51374411\n",
      "Iteration 22171, loss = 703.26304853\n",
      "Iteration 22172, loss = 703.01378478\n",
      "Iteration 22173, loss = 702.76589516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22174, loss = 702.51937797\n",
      "Iteration 22175, loss = 702.27427922\n",
      "Iteration 22176, loss = 702.03067082\n",
      "Iteration 22177, loss = 701.78862414\n",
      "Iteration 22178, loss = 701.54818735\n",
      "Iteration 22179, loss = 701.30937203\n",
      "Iteration 22180, loss = 701.07215152\n",
      "Iteration 22181, loss = 700.83646995\n",
      "Iteration 22182, loss = 700.60225809\n",
      "Iteration 22183, loss = 700.36945050\n",
      "Iteration 22184, loss = 700.13799890\n",
      "Iteration 22185, loss = 699.90787814\n",
      "Iteration 22186, loss = 699.67908413\n",
      "Iteration 22187, loss = 699.45162564\n",
      "Iteration 22188, loss = 699.22551317\n",
      "Iteration 22189, loss = 699.00074890\n",
      "Iteration 22190, loss = 698.77732055\n",
      "Iteration 22191, loss = 698.55520074\n",
      "Iteration 22192, loss = 698.33435131\n",
      "Iteration 22193, loss = 698.11473059\n",
      "Iteration 22194, loss = 697.89630081\n",
      "Iteration 22195, loss = 697.67903315\n",
      "Iteration 22196, loss = 697.46290896\n",
      "Iteration 22197, loss = 697.24791738\n",
      "Iteration 22198, loss = 697.03405083\n",
      "Iteration 22199, loss = 696.82130013\n",
      "Iteration 22200, loss = 696.60965113\n",
      "Iteration 22201, loss = 696.39908373\n",
      "Iteration 22202, loss = 696.18957325\n",
      "Iteration 22203, loss = 695.98109332\n",
      "Iteration 22204, loss = 695.77361903\n",
      "Iteration 22205, loss = 695.56712922\n",
      "Iteration 22206, loss = 695.36160720\n",
      "Iteration 22207, loss = 695.15703990\n",
      "Iteration 22208, loss = 694.95341604\n",
      "Iteration 22209, loss = 694.75072403\n",
      "Iteration 22210, loss = 694.54895049\n",
      "Iteration 22211, loss = 694.34807979\n",
      "Iteration 22212, loss = 694.14809468\n",
      "Iteration 22213, loss = 693.94897746\n",
      "Iteration 22214, loss = 693.75071140\n",
      "Iteration 22215, loss = 693.55328156\n",
      "Iteration 22216, loss = 693.35667503\n",
      "Iteration 22217, loss = 693.16088038\n",
      "Iteration 22218, loss = 692.96588680\n",
      "Iteration 22219, loss = 692.77168329\n",
      "Iteration 22220, loss = 692.57825811\n",
      "Iteration 22221, loss = 692.38559879\n",
      "Iteration 22222, loss = 692.19369251\n",
      "Iteration 22223, loss = 692.00252670\n",
      "Iteration 22224, loss = 691.81208952\n",
      "Iteration 22225, loss = 691.62237009\n",
      "Iteration 22226, loss = 691.43335840\n",
      "Iteration 22227, loss = 691.24504503\n",
      "Iteration 22228, loss = 691.05742069\n",
      "Iteration 22229, loss = 690.87047600\n",
      "Iteration 22230, loss = 690.68420134\n",
      "Iteration 22231, loss = 690.49858697\n",
      "Iteration 22232, loss = 690.31362330\n",
      "Iteration 22233, loss = 690.12930103\n",
      "Iteration 22234, loss = 689.94561139\n",
      "Iteration 22235, loss = 689.76254605\n",
      "Iteration 22236, loss = 689.58009708\n",
      "Iteration 22237, loss = 689.39825668\n",
      "Iteration 22238, loss = 689.21701713\n",
      "Iteration 22239, loss = 689.03637070\n",
      "Iteration 22240, loss = 688.85630968\n",
      "Iteration 22241, loss = 688.67682645\n",
      "Iteration 22242, loss = 688.49791363\n",
      "Iteration 22243, loss = 688.31956409\n",
      "Iteration 22244, loss = 688.14177099\n",
      "Iteration 22245, loss = 687.96452768\n",
      "Iteration 22246, loss = 687.78782770\n",
      "Iteration 22247, loss = 687.61166463\n",
      "Iteration 22248, loss = 687.43603214\n",
      "Iteration 22249, loss = 687.26092396\n",
      "Iteration 22250, loss = 687.08633392\n",
      "Iteration 22251, loss = 686.91225601\n",
      "Iteration 22252, loss = 686.73868438\n",
      "Iteration 22253, loss = 686.56561337\n",
      "Iteration 22254, loss = 686.39303743\n",
      "Iteration 22255, loss = 686.22095115\n",
      "Iteration 22256, loss = 686.04934917\n",
      "Iteration 22257, loss = 685.87822622\n",
      "Iteration 22258, loss = 685.70757713\n",
      "Iteration 22259, loss = 685.53739678\n",
      "Iteration 22260, loss = 685.36768020\n",
      "Iteration 22261, loss = 685.19842252\n",
      "Iteration 22262, loss = 685.02961899\n",
      "Iteration 22263, loss = 684.86126494\n",
      "Iteration 22264, loss = 684.69335580\n",
      "Iteration 22265, loss = 684.52588707\n",
      "Iteration 22266, loss = 684.35885431\n",
      "Iteration 22267, loss = 684.19225317\n",
      "Iteration 22268, loss = 684.02607938\n",
      "Iteration 22269, loss = 683.86032873\n",
      "Iteration 22270, loss = 683.69499712\n",
      "Iteration 22271, loss = 683.53008052\n",
      "Iteration 22272, loss = 683.36557498\n",
      "Iteration 22273, loss = 683.20147661\n",
      "Iteration 22274, loss = 683.03778157\n",
      "Iteration 22275, loss = 682.87448610\n",
      "Iteration 22276, loss = 682.71158651\n",
      "Iteration 22277, loss = 682.54907914\n",
      "Iteration 22278, loss = 682.38696044\n",
      "Iteration 22279, loss = 682.22522688\n",
      "Iteration 22280, loss = 682.06387502\n",
      "Iteration 22281, loss = 681.90290147\n",
      "Iteration 22282, loss = 681.74230289\n",
      "Iteration 22283, loss = 681.58207599\n",
      "Iteration 22284, loss = 681.42221754\n",
      "Iteration 22285, loss = 681.26272435\n",
      "Iteration 22286, loss = 681.10359331\n",
      "Iteration 22287, loss = 680.94482133\n",
      "Iteration 22288, loss = 680.78640538\n",
      "Iteration 22289, loss = 680.62834249\n",
      "Iteration 22290, loss = 680.47062972\n",
      "Iteration 22291, loss = 680.31326418\n",
      "Iteration 22292, loss = 680.15624302\n",
      "Iteration 22293, loss = 679.99956345\n",
      "Iteration 22294, loss = 679.84322270\n",
      "Iteration 22295, loss = 679.68721806\n",
      "Iteration 22296, loss = 679.53154685\n",
      "Iteration 22297, loss = 679.37620644\n",
      "Iteration 22298, loss = 679.22119422\n",
      "Iteration 22299, loss = 679.06650764\n",
      "Iteration 22300, loss = 678.91214418\n",
      "Iteration 22301, loss = 678.75810135\n",
      "Iteration 22302, loss = 678.60437671\n",
      "Iteration 22303, loss = 678.45096783\n",
      "Iteration 22304, loss = 678.29787234\n",
      "Iteration 22305, loss = 678.14508789\n",
      "Iteration 22306, loss = 677.99261217\n",
      "Iteration 22307, loss = 677.84044291\n",
      "Iteration 22308, loss = 677.68857784\n",
      "Iteration 22309, loss = 677.53701476\n",
      "Iteration 22310, loss = 677.38575148\n",
      "Iteration 22311, loss = 677.23478583\n",
      "Iteration 22312, loss = 677.08411569\n",
      "Iteration 22313, loss = 676.93373897\n",
      "Iteration 22314, loss = 676.78365358\n",
      "Iteration 22315, loss = 676.63385749\n",
      "Iteration 22316, loss = 676.48434868\n",
      "Iteration 22317, loss = 676.33512515\n",
      "Iteration 22318, loss = 676.18618495\n",
      "Iteration 22319, loss = 676.03752614\n",
      "Iteration 22320, loss = 675.88914680\n",
      "Iteration 22321, loss = 675.74104503\n",
      "Iteration 22322, loss = 675.59321899\n",
      "Iteration 22323, loss = 675.44566683\n",
      "Iteration 22324, loss = 675.29838672\n",
      "Iteration 22325, loss = 675.15137688\n",
      "Iteration 22326, loss = 675.00463553\n",
      "Iteration 22327, loss = 674.85816091\n",
      "Iteration 22328, loss = 674.71195131\n",
      "Iteration 22329, loss = 674.56600502\n",
      "Iteration 22330, loss = 674.42032033\n",
      "Iteration 22331, loss = 674.27489560\n",
      "Iteration 22332, loss = 674.12972917\n",
      "Iteration 22333, loss = 673.98481942\n",
      "Iteration 22334, loss = 673.84016473\n",
      "Iteration 22335, loss = 673.69576353\n",
      "Iteration 22336, loss = 673.55161423\n",
      "Iteration 22337, loss = 673.40771530\n",
      "Iteration 22338, loss = 673.26406519\n",
      "Iteration 22339, loss = 673.12066240\n",
      "Iteration 22340, loss = 672.97750542\n",
      "Iteration 22341, loss = 672.83459277\n",
      "Iteration 22342, loss = 672.69192299\n",
      "Iteration 22343, loss = 672.54949463\n",
      "Iteration 22344, loss = 672.40730627\n",
      "Iteration 22345, loss = 672.26535648\n",
      "Iteration 22346, loss = 672.12364387\n",
      "Iteration 22347, loss = 671.98216706\n",
      "Iteration 22348, loss = 671.84092468\n",
      "Iteration 22349, loss = 671.69991537\n",
      "Iteration 22350, loss = 671.55913780\n",
      "Iteration 22351, loss = 671.41859064\n",
      "Iteration 22352, loss = 671.27827258\n",
      "Iteration 22353, loss = 671.13818234\n",
      "Iteration 22354, loss = 670.99831862\n",
      "Iteration 22355, loss = 670.85868017\n",
      "Iteration 22356, loss = 670.71926572\n",
      "Iteration 22357, loss = 670.58007404\n",
      "Iteration 22358, loss = 670.44110390\n",
      "Iteration 22359, loss = 670.30235409\n",
      "Iteration 22360, loss = 670.16382339\n",
      "Iteration 22361, loss = 670.02551063\n",
      "Iteration 22362, loss = 669.88741463\n",
      "Iteration 22363, loss = 669.74953421\n",
      "Iteration 22364, loss = 669.61186823\n",
      "Iteration 22365, loss = 669.47441554\n",
      "Iteration 22366, loss = 669.33717502\n",
      "Iteration 22367, loss = 669.20014555\n",
      "Iteration 22368, loss = 669.06332601\n",
      "Iteration 22369, loss = 668.92671532\n",
      "Iteration 22370, loss = 668.79031238\n",
      "Iteration 22371, loss = 668.65411612\n",
      "Iteration 22372, loss = 668.51812548\n",
      "Iteration 22373, loss = 668.38233940\n",
      "Iteration 22374, loss = 668.24675685\n",
      "Iteration 22375, loss = 668.11137677\n",
      "Iteration 22376, loss = 667.97619816\n",
      "Iteration 22377, loss = 667.84121999\n",
      "Iteration 22378, loss = 667.70644127\n",
      "Iteration 22379, loss = 667.57186100\n",
      "Iteration 22380, loss = 667.43747819\n",
      "Iteration 22381, loss = 667.30329187\n",
      "Iteration 22382, loss = 667.16930107\n",
      "Iteration 22383, loss = 667.03550484\n",
      "Iteration 22384, loss = 666.90190221\n",
      "Iteration 22385, loss = 666.76849227\n",
      "Iteration 22386, loss = 666.63527406\n",
      "Iteration 22387, loss = 666.50224667\n",
      "Iteration 22388, loss = 666.36940919\n",
      "Iteration 22389, loss = 666.23676071\n",
      "Iteration 22390, loss = 666.10430033\n",
      "Iteration 22391, loss = 665.97202717\n",
      "Iteration 22392, loss = 665.83994033\n",
      "Iteration 22393, loss = 665.70803894\n",
      "Iteration 22394, loss = 665.57632215\n",
      "Iteration 22395, loss = 665.44478909\n",
      "Iteration 22396, loss = 665.31343890\n",
      "Iteration 22397, loss = 665.18227075\n",
      "Iteration 22398, loss = 665.05128381\n",
      "Iteration 22399, loss = 664.92047723\n",
      "Iteration 22400, loss = 664.78985020\n",
      "Iteration 22401, loss = 664.65940190\n",
      "Iteration 22402, loss = 664.52913154\n",
      "Iteration 22403, loss = 664.39903829\n",
      "Iteration 22404, loss = 664.26912138\n",
      "Iteration 22405, loss = 664.13938002\n",
      "Iteration 22406, loss = 664.00981341\n",
      "Iteration 22407, loss = 663.88042080\n",
      "Iteration 22408, loss = 663.75120141\n",
      "Iteration 22409, loss = 663.62215448\n",
      "Iteration 22410, loss = 663.49327926\n",
      "Iteration 22411, loss = 663.36457499\n",
      "Iteration 22412, loss = 663.23604094\n",
      "Iteration 22413, loss = 663.10767637\n",
      "Iteration 22414, loss = 662.97948055\n",
      "Iteration 22415, loss = 662.85145275\n",
      "Iteration 22416, loss = 662.72359226\n",
      "Iteration 22417, loss = 662.59589836\n",
      "Iteration 22418, loss = 662.46837035\n",
      "Iteration 22419, loss = 662.34100752\n",
      "Iteration 22420, loss = 662.21380917\n",
      "Iteration 22421, loss = 662.08677463\n",
      "Iteration 22422, loss = 661.95990320\n",
      "Iteration 22423, loss = 661.83319421\n",
      "Iteration 22424, loss = 661.70664697\n",
      "Iteration 22425, loss = 661.58026083\n",
      "Iteration 22426, loss = 661.45403512\n",
      "Iteration 22427, loss = 661.32796917\n",
      "Iteration 22428, loss = 661.20206234\n",
      "Iteration 22429, loss = 661.07631398\n",
      "Iteration 22430, loss = 660.95072344\n",
      "Iteration 22431, loss = 660.82529008\n",
      "Iteration 22432, loss = 660.70001328\n",
      "Iteration 22433, loss = 660.57489241\n",
      "Iteration 22434, loss = 660.44992683\n",
      "Iteration 22435, loss = 660.32511593\n",
      "Iteration 22436, loss = 660.20045910\n",
      "Iteration 22437, loss = 660.07595572\n",
      "Iteration 22438, loss = 659.95160519\n",
      "Iteration 22439, loss = 659.82740691\n",
      "Iteration 22440, loss = 659.70336028\n",
      "Iteration 22441, loss = 659.57946471\n",
      "Iteration 22442, loss = 659.45571961\n",
      "Iteration 22443, loss = 659.33212440\n",
      "Iteration 22444, loss = 659.20867849\n",
      "Iteration 22445, loss = 659.08538132\n",
      "Iteration 22446, loss = 658.96223231\n",
      "Iteration 22447, loss = 658.83923090\n",
      "Iteration 22448, loss = 658.71637651\n",
      "Iteration 22449, loss = 658.59366860\n",
      "Iteration 22450, loss = 658.47110661\n",
      "Iteration 22451, loss = 658.34868998\n",
      "Iteration 22452, loss = 658.22641817\n",
      "Iteration 22453, loss = 658.10429064\n",
      "Iteration 22454, loss = 657.98230685\n",
      "Iteration 22455, loss = 657.86046625\n",
      "Iteration 22456, loss = 657.73876833\n",
      "Iteration 22457, loss = 657.61721254\n",
      "Iteration 22458, loss = 657.49579837\n",
      "Iteration 22459, loss = 657.37452530\n",
      "Iteration 22460, loss = 657.25339280\n",
      "Iteration 22461, loss = 657.13240037\n",
      "Iteration 22462, loss = 657.01154749\n",
      "Iteration 22463, loss = 656.89083365\n",
      "Iteration 22464, loss = 656.77025836\n",
      "Iteration 22465, loss = 656.64982111\n",
      "Iteration 22466, loss = 656.52952140\n",
      "Iteration 22467, loss = 656.40935875\n",
      "Iteration 22468, loss = 656.28933266\n",
      "Iteration 22469, loss = 656.16944264\n",
      "Iteration 22470, loss = 656.04968821\n",
      "Iteration 22471, loss = 655.93006890\n",
      "Iteration 22472, loss = 655.81058421\n",
      "Iteration 22473, loss = 655.69123369\n",
      "Iteration 22474, loss = 655.57201685\n",
      "Iteration 22475, loss = 655.45293323\n",
      "Iteration 22476, loss = 655.33398237\n",
      "Iteration 22477, loss = 655.21516380\n",
      "Iteration 22478, loss = 655.09647706\n",
      "Iteration 22479, loss = 654.97792170\n",
      "Iteration 22480, loss = 654.85949726\n",
      "Iteration 22481, loss = 654.74120330\n",
      "Iteration 22482, loss = 654.62303937\n",
      "Iteration 22483, loss = 654.50500501\n",
      "Iteration 22484, loss = 654.38709980\n",
      "Iteration 22485, loss = 654.26932328\n",
      "Iteration 22486, loss = 654.15167503\n",
      "Iteration 22487, loss = 654.03415462\n",
      "Iteration 22488, loss = 653.91676160\n",
      "Iteration 22489, loss = 653.79949555\n",
      "Iteration 22490, loss = 653.68235605\n",
      "Iteration 22491, loss = 653.56534268\n",
      "Iteration 22492, loss = 653.44845501\n",
      "Iteration 22493, loss = 653.33169262\n",
      "Iteration 22494, loss = 653.21505511\n",
      "Iteration 22495, loss = 653.09854205\n",
      "Iteration 22496, loss = 652.98215304\n",
      "Iteration 22497, loss = 652.86588767\n",
      "Iteration 22498, loss = 652.74974554\n",
      "Iteration 22499, loss = 652.63372624\n",
      "Iteration 22500, loss = 652.51782937\n",
      "Iteration 22501, loss = 652.40205453\n",
      "Iteration 22502, loss = 652.28640134\n",
      "Iteration 22503, loss = 652.17086939\n",
      "Iteration 22504, loss = 652.05545829\n",
      "Iteration 22505, loss = 651.94016766\n",
      "Iteration 22506, loss = 651.82499711\n",
      "Iteration 22507, loss = 651.70994626\n",
      "Iteration 22508, loss = 651.59501472\n",
      "Iteration 22509, loss = 651.48020212\n",
      "Iteration 22510, loss = 651.36550807\n",
      "Iteration 22511, loss = 651.25093221\n",
      "Iteration 22512, loss = 651.13647415\n",
      "Iteration 22513, loss = 651.02213354\n",
      "Iteration 22514, loss = 650.90790999\n",
      "Iteration 22515, loss = 650.79380315\n",
      "Iteration 22516, loss = 650.67981264\n",
      "Iteration 22517, loss = 650.56593811\n",
      "Iteration 22518, loss = 650.45217920\n",
      "Iteration 22519, loss = 650.33853555\n",
      "Iteration 22520, loss = 650.22500680\n",
      "Iteration 22521, loss = 650.11159259\n",
      "Iteration 22522, loss = 649.99829259\n",
      "Iteration 22523, loss = 649.88510642\n",
      "Iteration 22524, loss = 649.77203375\n",
      "Iteration 22525, loss = 649.65907424\n",
      "Iteration 22526, loss = 649.54622752\n",
      "Iteration 22527, loss = 649.43349328\n",
      "Iteration 22528, loss = 649.32087115\n",
      "Iteration 22529, loss = 649.20836081\n",
      "Iteration 22530, loss = 649.09596191\n",
      "Iteration 22531, loss = 648.98367412\n",
      "Iteration 22532, loss = 648.87149712\n",
      "Iteration 22533, loss = 648.75943056\n",
      "Iteration 22534, loss = 648.64747411\n",
      "Iteration 22535, loss = 648.53562746\n",
      "Iteration 22536, loss = 648.42389027\n",
      "Iteration 22537, loss = 648.31226222\n",
      "Iteration 22538, loss = 648.20074298\n",
      "Iteration 22539, loss = 648.08933224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22540, loss = 647.97802967\n",
      "Iteration 22541, loss = 647.86683496\n",
      "Iteration 22542, loss = 647.75574780\n",
      "Iteration 22543, loss = 647.64476786\n",
      "Iteration 22544, loss = 647.53389484\n",
      "Iteration 22545, loss = 647.42312842\n",
      "Iteration 22546, loss = 647.31246830\n",
      "Iteration 22547, loss = 647.20191417\n",
      "Iteration 22548, loss = 647.09146572\n",
      "Iteration 22549, loss = 646.98112264\n",
      "Iteration 22550, loss = 646.87088464\n",
      "Iteration 22551, loss = 646.76075142\n",
      "Iteration 22552, loss = 646.65072266\n",
      "Iteration 22553, loss = 646.54079808\n",
      "Iteration 22554, loss = 646.43097739\n",
      "Iteration 22555, loss = 646.32126027\n",
      "Iteration 22556, loss = 646.21164645\n",
      "Iteration 22557, loss = 646.10213562\n",
      "Iteration 22558, loss = 645.99272750\n",
      "Iteration 22559, loss = 645.88342179\n",
      "Iteration 22560, loss = 645.77421822\n",
      "Iteration 22561, loss = 645.66511649\n",
      "Iteration 22562, loss = 645.55611632\n",
      "Iteration 22563, loss = 645.44721742\n",
      "Iteration 22564, loss = 645.33841952\n",
      "Iteration 22565, loss = 645.22972233\n",
      "Iteration 22566, loss = 645.12112558\n",
      "Iteration 22567, loss = 645.01262898\n",
      "Iteration 22568, loss = 644.90423226\n",
      "Iteration 22569, loss = 644.79593514\n",
      "Iteration 22570, loss = 644.68773735\n",
      "Iteration 22571, loss = 644.57963862\n",
      "Iteration 22572, loss = 644.47163868\n",
      "Iteration 22573, loss = 644.36373726\n",
      "Iteration 22574, loss = 644.25593408\n",
      "Iteration 22575, loss = 644.14822888\n",
      "Iteration 22576, loss = 644.04062140\n",
      "Iteration 22577, loss = 643.93311137\n",
      "Iteration 22578, loss = 643.82569853\n",
      "Iteration 22579, loss = 643.71838262\n",
      "Iteration 22580, loss = 643.61116336\n",
      "Iteration 22581, loss = 643.50404052\n",
      "Iteration 22582, loss = 643.39701382\n",
      "Iteration 22583, loss = 643.29008301\n",
      "Iteration 22584, loss = 643.18324783\n",
      "Iteration 22585, loss = 643.07650803\n",
      "Iteration 22586, loss = 642.96986336\n",
      "Iteration 22587, loss = 642.86331356\n",
      "Iteration 22588, loss = 642.75685839\n",
      "Iteration 22589, loss = 642.65049758\n",
      "Iteration 22590, loss = 642.54423090\n",
      "Iteration 22591, loss = 642.43805810\n",
      "Iteration 22592, loss = 642.33197893\n",
      "Iteration 22593, loss = 642.22599314\n",
      "Iteration 22594, loss = 642.12010049\n",
      "Iteration 22595, loss = 642.01430073\n",
      "Iteration 22596, loss = 641.90859364\n",
      "Iteration 22597, loss = 641.80297895\n",
      "Iteration 22598, loss = 641.69745645\n",
      "Iteration 22599, loss = 641.59202587\n",
      "Iteration 22600, loss = 641.48668700\n",
      "Iteration 22601, loss = 641.38143959\n",
      "Iteration 22602, loss = 641.27628340\n",
      "Iteration 22603, loss = 641.17121821\n",
      "Iteration 22604, loss = 641.06624378\n",
      "Iteration 22605, loss = 640.96135987\n",
      "Iteration 22606, loss = 640.85656626\n",
      "Iteration 22607, loss = 640.75186272\n",
      "Iteration 22608, loss = 640.64724901\n",
      "Iteration 22609, loss = 640.54272491\n",
      "Iteration 22610, loss = 640.43829019\n",
      "Iteration 22611, loss = 640.33394463\n",
      "Iteration 22612, loss = 640.22968800\n",
      "Iteration 22613, loss = 640.12552007\n",
      "Iteration 22614, loss = 640.02144063\n",
      "Iteration 22615, loss = 639.91744944\n",
      "Iteration 22616, loss = 639.81354630\n",
      "Iteration 22617, loss = 639.70973098\n",
      "Iteration 22618, loss = 639.60600326\n",
      "Iteration 22619, loss = 639.50236292\n",
      "Iteration 22620, loss = 639.39880975\n",
      "Iteration 22621, loss = 639.29534352\n",
      "Iteration 22622, loss = 639.19196403\n",
      "Iteration 22623, loss = 639.08867106\n",
      "Iteration 22624, loss = 638.98546439\n",
      "Iteration 22625, loss = 638.88234382\n",
      "Iteration 22626, loss = 638.77930913\n",
      "Iteration 22627, loss = 638.67636010\n",
      "Iteration 22628, loss = 638.57349654\n",
      "Iteration 22629, loss = 638.47071823\n",
      "Iteration 22630, loss = 638.36802496\n",
      "Iteration 22631, loss = 638.26541653\n",
      "Iteration 22632, loss = 638.16289273\n",
      "Iteration 22633, loss = 638.06045335\n",
      "Iteration 22634, loss = 637.95809819\n",
      "Iteration 22635, loss = 637.85582705\n",
      "Iteration 22636, loss = 637.75363971\n",
      "Iteration 22637, loss = 637.65153599\n",
      "Iteration 22638, loss = 637.54951568\n",
      "Iteration 22639, loss = 637.44757858\n",
      "Iteration 22640, loss = 637.34572449\n",
      "Iteration 22641, loss = 637.24395321\n",
      "Iteration 22642, loss = 637.14226454\n",
      "Iteration 22643, loss = 637.04065829\n",
      "Iteration 22644, loss = 636.93913425\n",
      "Iteration 22645, loss = 636.83769224\n",
      "Iteration 22646, loss = 636.73633206\n",
      "Iteration 22647, loss = 636.63505352\n",
      "Iteration 22648, loss = 636.53385642\n",
      "Iteration 22649, loss = 636.43274056\n",
      "Iteration 22650, loss = 636.33170577\n",
      "Iteration 22651, loss = 636.23075184\n",
      "Iteration 22652, loss = 636.12987859\n",
      "Iteration 22653, loss = 636.02908583\n",
      "Iteration 22654, loss = 635.92837337\n",
      "Iteration 22655, loss = 635.82774103\n",
      "Iteration 22656, loss = 635.72718861\n",
      "Iteration 22657, loss = 635.62671592\n",
      "Iteration 22658, loss = 635.52632280\n",
      "Iteration 22659, loss = 635.42600904\n",
      "Iteration 22660, loss = 635.32577446\n",
      "Iteration 22661, loss = 635.22561889\n",
      "Iteration 22662, loss = 635.12554214\n",
      "Iteration 22663, loss = 635.02554403\n",
      "Iteration 22664, loss = 634.92562437\n",
      "Iteration 22665, loss = 634.82578299\n",
      "Iteration 22666, loss = 634.72601971\n",
      "Iteration 22667, loss = 634.62633434\n",
      "Iteration 22668, loss = 634.52672671\n",
      "Iteration 22669, loss = 634.42719665\n",
      "Iteration 22670, loss = 634.32774397\n",
      "Iteration 22671, loss = 634.22836850\n",
      "Iteration 22672, loss = 634.12907007\n",
      "Iteration 22673, loss = 634.02984849\n",
      "Iteration 22674, loss = 633.93070360\n",
      "Iteration 22675, loss = 633.83163522\n",
      "Iteration 22676, loss = 633.73264318\n",
      "Iteration 22677, loss = 633.63372730\n",
      "Iteration 22678, loss = 633.53488742\n",
      "Iteration 22679, loss = 633.43612337\n",
      "Iteration 22680, loss = 633.33743497\n",
      "Iteration 22681, loss = 633.23882205\n",
      "Iteration 22682, loss = 633.14028445\n",
      "Iteration 22683, loss = 633.04182200\n",
      "Iteration 22684, loss = 632.94343452\n",
      "Iteration 22685, loss = 632.84512186\n",
      "Iteration 22686, loss = 632.74688385\n",
      "Iteration 22687, loss = 632.64872032\n",
      "Iteration 22688, loss = 632.55063110\n",
      "Iteration 22689, loss = 632.45261604\n",
      "Iteration 22690, loss = 632.35467496\n",
      "Iteration 22691, loss = 632.25680771\n",
      "Iteration 22692, loss = 632.15901413\n",
      "Iteration 22693, loss = 632.06129404\n",
      "Iteration 22694, loss = 631.96364729\n",
      "Iteration 22695, loss = 631.86607372\n",
      "Iteration 22696, loss = 631.76857317\n",
      "Iteration 22697, loss = 631.67114547\n",
      "Iteration 22698, loss = 631.57379048\n",
      "Iteration 22699, loss = 631.47650802\n",
      "Iteration 22700, loss = 631.37929795\n",
      "Iteration 22701, loss = 631.28216011\n",
      "Iteration 22702, loss = 631.18509433\n",
      "Iteration 22703, loss = 631.08810047\n",
      "Iteration 22704, loss = 630.99117836\n",
      "Iteration 22705, loss = 630.89432786\n",
      "Iteration 22706, loss = 630.79754881\n",
      "Iteration 22707, loss = 630.70084105\n",
      "Iteration 22708, loss = 630.60420443\n",
      "Iteration 22709, loss = 630.50763880\n",
      "Iteration 22710, loss = 630.41114401\n",
      "Iteration 22711, loss = 630.31471990\n",
      "Iteration 22712, loss = 630.21836633\n",
      "Iteration 22713, loss = 630.12208313\n",
      "Iteration 22714, loss = 630.02587018\n",
      "Iteration 22715, loss = 629.92972730\n",
      "Iteration 22716, loss = 629.83365436\n",
      "Iteration 22717, loss = 629.73765121\n",
      "Iteration 22718, loss = 629.64171769\n",
      "Iteration 22719, loss = 629.54585367\n",
      "Iteration 22720, loss = 629.45005899\n",
      "Iteration 22721, loss = 629.35433350\n",
      "Iteration 22722, loss = 629.25867707\n",
      "Iteration 22723, loss = 629.16308955\n",
      "Iteration 22724, loss = 629.06757079\n",
      "Iteration 22725, loss = 628.97212065\n",
      "Iteration 22726, loss = 628.87673898\n",
      "Iteration 22727, loss = 628.78142564\n",
      "Iteration 22728, loss = 628.68618049\n",
      "Iteration 22729, loss = 628.59100339\n",
      "Iteration 22730, loss = 628.49589419\n",
      "Iteration 22731, loss = 628.40085275\n",
      "Iteration 22732, loss = 628.30587894\n",
      "Iteration 22733, loss = 628.21097261\n",
      "Iteration 22734, loss = 628.11613362\n",
      "Iteration 22735, loss = 628.02136183\n",
      "Iteration 22736, loss = 627.92665711\n",
      "Iteration 22737, loss = 627.83201931\n",
      "Iteration 22738, loss = 627.73744830\n",
      "Iteration 22739, loss = 627.64294395\n",
      "Iteration 22740, loss = 627.54850610\n",
      "Iteration 22741, loss = 627.45413463\n",
      "Iteration 22742, loss = 627.35982941\n",
      "Iteration 22743, loss = 627.26559028\n",
      "Iteration 22744, loss = 627.17141713\n",
      "Iteration 22745, loss = 627.07730982\n",
      "Iteration 22746, loss = 626.98326820\n",
      "Iteration 22747, loss = 626.88929216\n",
      "Iteration 22748, loss = 626.79538155\n",
      "Iteration 22749, loss = 626.70153624\n",
      "Iteration 22750, loss = 626.60775610\n",
      "Iteration 22751, loss = 626.51404100\n",
      "Iteration 22752, loss = 626.42039080\n",
      "Iteration 22753, loss = 626.32680538\n",
      "Iteration 22754, loss = 626.23328461\n",
      "Iteration 22755, loss = 626.13982834\n",
      "Iteration 22756, loss = 626.04643647\n",
      "Iteration 22757, loss = 625.95310884\n",
      "Iteration 22758, loss = 625.85984535\n",
      "Iteration 22759, loss = 625.76664585\n",
      "Iteration 22760, loss = 625.67351023\n",
      "Iteration 22761, loss = 625.58043834\n",
      "Iteration 22762, loss = 625.48743007\n",
      "Iteration 22763, loss = 625.39448529\n",
      "Iteration 22764, loss = 625.30160387\n",
      "Iteration 22765, loss = 625.20878569\n",
      "Iteration 22766, loss = 625.11603062\n",
      "Iteration 22767, loss = 625.02333853\n",
      "Iteration 22768, loss = 624.93070931\n",
      "Iteration 22769, loss = 624.83814282\n",
      "Iteration 22770, loss = 624.74563894\n",
      "Iteration 22771, loss = 624.65319756\n",
      "Iteration 22772, loss = 624.56081854\n",
      "Iteration 22773, loss = 624.46850176\n",
      "Iteration 22774, loss = 624.37624711\n",
      "Iteration 22775, loss = 624.28405445\n",
      "Iteration 22776, loss = 624.19192368\n",
      "Iteration 22777, loss = 624.09985465\n",
      "Iteration 22778, loss = 624.00784727\n",
      "Iteration 22779, loss = 623.91590140\n",
      "Iteration 22780, loss = 623.82401693\n",
      "Iteration 22781, loss = 623.73219373\n",
      "Iteration 22782, loss = 623.64043169\n",
      "Iteration 22783, loss = 623.54873069\n",
      "Iteration 22784, loss = 623.45709061\n",
      "Iteration 22785, loss = 623.36551133\n",
      "Iteration 22786, loss = 623.27399274\n",
      "Iteration 22787, loss = 623.18253471\n",
      "Iteration 22788, loss = 623.09113713\n",
      "Iteration 22789, loss = 622.99979989\n",
      "Iteration 22790, loss = 622.90852286\n",
      "Iteration 22791, loss = 622.81730593\n",
      "Iteration 22792, loss = 622.72614899\n",
      "Iteration 22793, loss = 622.63505193\n",
      "Iteration 22794, loss = 622.54401461\n",
      "Iteration 22795, loss = 622.45303694\n",
      "Iteration 22796, loss = 622.36211880\n",
      "Iteration 22797, loss = 622.27126007\n",
      "Iteration 22798, loss = 622.18046064\n",
      "Iteration 22799, loss = 622.08972040\n",
      "Iteration 22800, loss = 621.99903924\n",
      "Iteration 22801, loss = 621.90841703\n",
      "Iteration 22802, loss = 621.81785368\n",
      "Iteration 22803, loss = 621.72734907\n",
      "Iteration 22804, loss = 621.63690309\n",
      "Iteration 22805, loss = 621.54651562\n",
      "Iteration 22806, loss = 621.45618656\n",
      "Iteration 22807, loss = 621.36591580\n",
      "Iteration 22808, loss = 621.27570323\n",
      "Iteration 22809, loss = 621.18554873\n",
      "Iteration 22810, loss = 621.09545220\n",
      "Iteration 22811, loss = 621.00541353\n",
      "Iteration 22812, loss = 620.91543261\n",
      "Iteration 22813, loss = 620.82550933\n",
      "Iteration 22814, loss = 620.73564359\n",
      "Iteration 22815, loss = 620.64583527\n",
      "Iteration 22816, loss = 620.55608428\n",
      "Iteration 22817, loss = 620.46639049\n",
      "Iteration 22818, loss = 620.37675382\n",
      "Iteration 22819, loss = 620.28717414\n",
      "Iteration 22820, loss = 620.19765136\n",
      "Iteration 22821, loss = 620.10818537\n",
      "Iteration 22822, loss = 620.01877606\n",
      "Iteration 22823, loss = 619.92942333\n",
      "Iteration 22824, loss = 619.84012707\n",
      "Iteration 22825, loss = 619.75088719\n",
      "Iteration 22826, loss = 619.66170357\n",
      "Iteration 22827, loss = 619.57257611\n",
      "Iteration 22828, loss = 619.48350470\n",
      "Iteration 22829, loss = 619.39448926\n",
      "Iteration 22830, loss = 619.30552966\n",
      "Iteration 22831, loss = 619.21662582\n",
      "Iteration 22832, loss = 619.12777763\n",
      "Iteration 22833, loss = 619.03898498\n",
      "Iteration 22834, loss = 618.95024777\n",
      "Iteration 22835, loss = 618.86156591\n",
      "Iteration 22836, loss = 618.77293929\n",
      "Iteration 22837, loss = 618.68436781\n",
      "Iteration 22838, loss = 618.59585137\n",
      "Iteration 22839, loss = 618.50738987\n",
      "Iteration 22840, loss = 618.41898322\n",
      "Iteration 22841, loss = 618.33063130\n",
      "Iteration 22842, loss = 618.24233403\n",
      "Iteration 22843, loss = 618.15409130\n",
      "Iteration 22844, loss = 618.06590302\n",
      "Iteration 22845, loss = 617.97776908\n",
      "Iteration 22846, loss = 617.88968939\n",
      "Iteration 22847, loss = 617.80166385\n",
      "Iteration 22848, loss = 617.71369237\n",
      "Iteration 22849, loss = 617.62577484\n",
      "Iteration 22850, loss = 617.53791117\n",
      "Iteration 22851, loss = 617.45010126\n",
      "Iteration 22852, loss = 617.36234502\n",
      "Iteration 22853, loss = 617.27464234\n",
      "Iteration 22854, loss = 617.18699314\n",
      "Iteration 22855, loss = 617.09939732\n",
      "Iteration 22856, loss = 617.01185479\n",
      "Iteration 22857, loss = 616.92436544\n",
      "Iteration 22858, loss = 616.83692918\n",
      "Iteration 22859, loss = 616.74954592\n",
      "Iteration 22860, loss = 616.66221557\n",
      "Iteration 22861, loss = 616.57493803\n",
      "Iteration 22862, loss = 616.48771320\n",
      "Iteration 22863, loss = 616.40054100\n",
      "Iteration 22864, loss = 616.31342133\n",
      "Iteration 22865, loss = 616.22635409\n",
      "Iteration 22866, loss = 616.13933921\n",
      "Iteration 22867, loss = 616.05237657\n",
      "Iteration 22868, loss = 615.96546609\n",
      "Iteration 22869, loss = 615.87860769\n",
      "Iteration 22870, loss = 615.79180126\n",
      "Iteration 22871, loss = 615.70504672\n",
      "Iteration 22872, loss = 615.61834397\n",
      "Iteration 22873, loss = 615.53169293\n",
      "Iteration 22874, loss = 615.44509351\n",
      "Iteration 22875, loss = 615.35854563\n",
      "Iteration 22876, loss = 615.27204922\n",
      "Iteration 22877, loss = 615.18560424\n",
      "Iteration 22878, loss = 615.09921067\n",
      "Iteration 22879, loss = 615.01286866\n",
      "Iteration 22880, loss = 614.92657859\n",
      "Iteration 22881, loss = 614.84034143\n",
      "Iteration 22882, loss = 614.75415940\n",
      "Iteration 22883, loss = 614.66803727\n",
      "Iteration 22884, loss = 614.58198389\n",
      "Iteration 22885, loss = 614.49601109\n",
      "Iteration 22886, loss = 614.41011607\n",
      "Iteration 22887, loss = 614.32424065\n",
      "Iteration 22888, loss = 614.23828351\n",
      "Iteration 22889, loss = 614.15228764\n",
      "Iteration 22890, loss = 614.06645521\n",
      "Iteration 22891, loss = 613.98081531\n",
      "Iteration 22892, loss = 613.89517480\n",
      "Iteration 22893, loss = 613.80944935\n",
      "Iteration 22894, loss = 613.72380742\n",
      "Iteration 22895, loss = 613.63833317\n",
      "Iteration 22896, loss = 613.55287520\n",
      "Iteration 22897, loss = 613.46737332\n",
      "Iteration 22898, loss = 613.38196544\n",
      "Iteration 22899, loss = 613.29667636\n",
      "Iteration 22900, loss = 613.21138439\n",
      "Iteration 22901, loss = 613.12609950\n",
      "Iteration 22902, loss = 613.04092009\n",
      "Iteration 22903, loss = 612.95580697\n",
      "Iteration 22904, loss = 612.87069168\n",
      "Iteration 22905, loss = 612.78562998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22906, loss = 612.70065767\n",
      "Iteration 22907, loss = 612.61571528\n",
      "Iteration 22908, loss = 612.53079632\n",
      "Iteration 22909, loss = 612.44595182\n",
      "Iteration 22910, loss = 612.36116607\n",
      "Iteration 22911, loss = 612.27640378\n",
      "Iteration 22912, loss = 612.19169228\n",
      "Iteration 22913, loss = 612.10704855\n",
      "Iteration 22914, loss = 612.02244285\n",
      "Iteration 22915, loss = 611.93787401\n",
      "Iteration 22916, loss = 611.85336649\n",
      "Iteration 22917, loss = 611.76891040\n",
      "Iteration 22918, loss = 611.68449001\n",
      "Iteration 22919, loss = 611.60012001\n",
      "Iteration 22920, loss = 611.51580656\n",
      "Iteration 22921, loss = 611.43153485\n",
      "Iteration 22922, loss = 611.34730618\n",
      "Iteration 22923, loss = 611.26313178\n",
      "Iteration 22924, loss = 611.17900555\n",
      "Iteration 22925, loss = 611.09492083\n",
      "Iteration 22926, loss = 611.01088527\n",
      "Iteration 22927, loss = 610.92690079\n",
      "Iteration 22928, loss = 610.84296018\n",
      "Iteration 22929, loss = 610.75906480\n",
      "Iteration 22930, loss = 610.67521970\n",
      "Iteration 22931, loss = 610.59142150\n",
      "Iteration 22932, loss = 610.50766735\n",
      "Iteration 22933, loss = 610.42396097\n",
      "Iteration 22934, loss = 610.34030300\n",
      "Iteration 22935, loss = 610.25668995\n",
      "Iteration 22936, loss = 610.17312258\n",
      "Iteration 22937, loss = 610.08960322\n",
      "Iteration 22938, loss = 610.00613015\n",
      "Iteration 22939, loss = 609.92270202\n",
      "Iteration 22940, loss = 609.83932055\n",
      "Iteration 22941, loss = 609.75598602\n",
      "Iteration 22942, loss = 609.67269675\n",
      "Iteration 22943, loss = 609.58945300\n",
      "Iteration 22944, loss = 609.50625585\n",
      "Iteration 22945, loss = 609.42310454\n",
      "Iteration 22946, loss = 609.33999829\n",
      "Iteration 22947, loss = 609.25693786\n",
      "Iteration 22948, loss = 609.17392343\n",
      "Iteration 22949, loss = 609.09095417\n",
      "Iteration 22950, loss = 609.00803005\n",
      "Iteration 22951, loss = 608.92515162\n",
      "Iteration 22952, loss = 608.84231852\n",
      "Iteration 22953, loss = 608.75953030\n",
      "Iteration 22954, loss = 608.67678722\n",
      "Iteration 22955, loss = 608.59408942\n",
      "Iteration 22956, loss = 608.51143647\n",
      "Iteration 22957, loss = 608.42882826\n",
      "Iteration 22958, loss = 608.34626500\n",
      "Iteration 22959, loss = 608.26374658\n",
      "Iteration 22960, loss = 608.18127269\n",
      "Iteration 22961, loss = 608.09884338\n",
      "Iteration 22962, loss = 608.01645871\n",
      "Iteration 22963, loss = 607.93411849\n",
      "Iteration 22964, loss = 607.85182257\n",
      "Iteration 22965, loss = 607.76957100\n",
      "Iteration 22966, loss = 607.68736374\n",
      "Iteration 22967, loss = 607.60520060\n",
      "Iteration 22968, loss = 607.52308153\n",
      "Iteration 22969, loss = 607.44100654\n",
      "Iteration 22970, loss = 607.35897553\n",
      "Iteration 22971, loss = 607.27698837\n",
      "Iteration 22972, loss = 607.19504503\n",
      "Iteration 22973, loss = 607.11314548\n",
      "Iteration 22974, loss = 607.03128960\n",
      "Iteration 22975, loss = 606.94947731\n",
      "Iteration 22976, loss = 606.86770858\n",
      "Iteration 22977, loss = 606.78598334\n",
      "Iteration 22978, loss = 606.70430149\n",
      "Iteration 22979, loss = 606.62266297\n",
      "Iteration 22980, loss = 606.54106773\n",
      "Iteration 22981, loss = 606.45951570\n",
      "Iteration 22982, loss = 606.37800679\n",
      "Iteration 22983, loss = 606.29654094\n",
      "Iteration 22984, loss = 606.21511809\n",
      "Iteration 22985, loss = 606.13373818\n",
      "Iteration 22986, loss = 606.05240111\n",
      "Iteration 22987, loss = 605.97110684\n",
      "Iteration 22988, loss = 605.88985531\n",
      "Iteration 22989, loss = 605.80864643\n",
      "Iteration 22990, loss = 605.72748014\n",
      "Iteration 22991, loss = 605.64635637\n",
      "Iteration 22992, loss = 605.56527507\n",
      "Iteration 22993, loss = 605.48423616\n",
      "Iteration 22994, loss = 605.40323957\n",
      "Iteration 22995, loss = 605.32228524\n",
      "Iteration 22996, loss = 605.24137311\n",
      "Iteration 22997, loss = 605.16050310\n",
      "Iteration 22998, loss = 605.07967516\n",
      "Iteration 22999, loss = 604.99888921\n",
      "Iteration 23000, loss = 604.91814520\n",
      "Iteration 23001, loss = 604.83744305\n",
      "Iteration 23002, loss = 604.75678270\n",
      "Iteration 23003, loss = 604.67616409\n",
      "Iteration 23004, loss = 604.59558715\n",
      "Iteration 23005, loss = 604.51505182\n",
      "Iteration 23006, loss = 604.43455803\n",
      "Iteration 23007, loss = 604.35410572\n",
      "Iteration 23008, loss = 604.27369483\n",
      "Iteration 23009, loss = 604.19332528\n",
      "Iteration 23010, loss = 604.11299702\n",
      "Iteration 23011, loss = 604.03270999\n",
      "Iteration 23012, loss = 603.95246411\n",
      "Iteration 23013, loss = 603.87225933\n",
      "Iteration 23014, loss = 603.79209558\n",
      "Iteration 23015, loss = 603.71197281\n",
      "Iteration 23016, loss = 603.63189094\n",
      "Iteration 23017, loss = 603.55184991\n",
      "Iteration 23018, loss = 603.47184967\n",
      "Iteration 23019, loss = 603.39189015\n",
      "Iteration 23020, loss = 603.31197128\n",
      "Iteration 23021, loss = 603.23209301\n",
      "Iteration 23022, loss = 603.15225527\n",
      "Iteration 23023, loss = 603.07245801\n",
      "Iteration 23024, loss = 602.99270115\n",
      "Iteration 23025, loss = 602.91298464\n",
      "Iteration 23026, loss = 602.83330842\n",
      "Iteration 23027, loss = 602.75367242\n",
      "Iteration 23028, loss = 602.67407658\n",
      "Iteration 23029, loss = 602.59452085\n",
      "Iteration 23030, loss = 602.51500516\n",
      "Iteration 23031, loss = 602.43552946\n",
      "Iteration 23032, loss = 602.35609367\n",
      "Iteration 23033, loss = 602.27669774\n",
      "Iteration 23034, loss = 602.19734162\n",
      "Iteration 23035, loss = 602.11802523\n",
      "Iteration 23036, loss = 602.03874853\n",
      "Iteration 23037, loss = 601.95951144\n",
      "Iteration 23038, loss = 601.88031392\n",
      "Iteration 23039, loss = 601.80115589\n",
      "Iteration 23040, loss = 601.72203731\n",
      "Iteration 23041, loss = 601.64295811\n",
      "Iteration 23042, loss = 601.56391823\n",
      "Iteration 23043, loss = 601.48491761\n",
      "Iteration 23044, loss = 601.40595620\n",
      "Iteration 23045, loss = 601.32703394\n",
      "Iteration 23046, loss = 601.24815076\n",
      "Iteration 23047, loss = 601.16930662\n",
      "Iteration 23048, loss = 601.09050144\n",
      "Iteration 23049, loss = 601.01173518\n",
      "Iteration 23050, loss = 600.93300777\n",
      "Iteration 23051, loss = 600.85431915\n",
      "Iteration 23052, loss = 600.77566928\n",
      "Iteration 23053, loss = 600.69705808\n",
      "Iteration 23054, loss = 600.61848551\n",
      "Iteration 23055, loss = 600.53995151\n",
      "Iteration 23056, loss = 600.46145601\n",
      "Iteration 23057, loss = 600.38299896\n",
      "Iteration 23058, loss = 600.30458031\n",
      "Iteration 23059, loss = 600.22620000\n",
      "Iteration 23060, loss = 600.14785796\n",
      "Iteration 23061, loss = 600.06955415\n",
      "Iteration 23062, loss = 599.99128851\n",
      "Iteration 23063, loss = 599.91306098\n",
      "Iteration 23064, loss = 599.83487150\n",
      "Iteration 23065, loss = 599.75672002\n",
      "Iteration 23066, loss = 599.67860648\n",
      "Iteration 23067, loss = 599.60053083\n",
      "Iteration 23068, loss = 599.52249301\n",
      "Iteration 23069, loss = 599.44449296\n",
      "Iteration 23070, loss = 599.36653063\n",
      "Iteration 23071, loss = 599.28860597\n",
      "Iteration 23072, loss = 599.21071891\n",
      "Iteration 23073, loss = 599.13286941\n",
      "Iteration 23074, loss = 599.05505741\n",
      "Iteration 23075, loss = 598.97728285\n",
      "Iteration 23076, loss = 598.89954568\n",
      "Iteration 23077, loss = 598.82184584\n",
      "Iteration 23078, loss = 598.74418329\n",
      "Iteration 23079, loss = 598.66655795\n",
      "Iteration 23080, loss = 598.58896979\n",
      "Iteration 23081, loss = 598.51141875\n",
      "Iteration 23082, loss = 598.43390476\n",
      "Iteration 23083, loss = 598.35642779\n",
      "Iteration 23084, loss = 598.27898777\n",
      "Iteration 23085, loss = 598.20158465\n",
      "Iteration 23086, loss = 598.12421837\n",
      "Iteration 23087, loss = 598.04688890\n",
      "Iteration 23088, loss = 597.96959616\n",
      "Iteration 23089, loss = 597.89234011\n",
      "Iteration 23090, loss = 597.81512069\n",
      "Iteration 23091, loss = 597.73793785\n",
      "Iteration 23092, loss = 597.66079154\n",
      "Iteration 23093, loss = 597.58368171\n",
      "Iteration 23094, loss = 597.50660830\n",
      "Iteration 23095, loss = 597.42957126\n",
      "Iteration 23096, loss = 597.35257054\n",
      "Iteration 23097, loss = 597.27560608\n",
      "Iteration 23098, loss = 597.19867783\n",
      "Iteration 23099, loss = 597.12178575\n",
      "Iteration 23100, loss = 597.04492977\n",
      "Iteration 23101, loss = 596.96810986\n",
      "Iteration 23102, loss = 596.89132594\n",
      "Iteration 23103, loss = 596.81457798\n",
      "Iteration 23104, loss = 596.73786593\n",
      "Iteration 23105, loss = 596.66118972\n",
      "Iteration 23106, loss = 596.58454931\n",
      "Iteration 23107, loss = 596.50794465\n",
      "Iteration 23108, loss = 596.43137569\n",
      "Iteration 23109, loss = 596.35484237\n",
      "Iteration 23110, loss = 596.27834465\n",
      "Iteration 23111, loss = 596.20188248\n",
      "Iteration 23112, loss = 596.12545579\n",
      "Iteration 23113, loss = 596.04906455\n",
      "Iteration 23114, loss = 595.97270871\n",
      "Iteration 23115, loss = 595.89638820\n",
      "Iteration 23116, loss = 595.82010299\n",
      "Iteration 23117, loss = 595.74385302\n",
      "Iteration 23118, loss = 595.66763824\n",
      "Iteration 23119, loss = 595.59145860\n",
      "Iteration 23120, loss = 595.51531405\n",
      "Iteration 23121, loss = 595.43920455\n",
      "Iteration 23122, loss = 595.36313004\n",
      "Iteration 23123, loss = 595.28709047\n",
      "Iteration 23124, loss = 595.21108580\n",
      "Iteration 23125, loss = 595.13511597\n",
      "Iteration 23126, loss = 595.05918094\n",
      "Iteration 23127, loss = 594.98328066\n",
      "Iteration 23128, loss = 594.90741507\n",
      "Iteration 23129, loss = 594.83158413\n",
      "Iteration 23130, loss = 594.75578779\n",
      "Iteration 23131, loss = 594.68002600\n",
      "Iteration 23132, loss = 594.60429872\n",
      "Iteration 23133, loss = 594.52860589\n",
      "Iteration 23134, loss = 594.45294746\n",
      "Iteration 23135, loss = 594.37732339\n",
      "Iteration 23136, loss = 594.30173363\n",
      "Iteration 23137, loss = 594.22617814\n",
      "Iteration 23138, loss = 594.15065685\n",
      "Iteration 23139, loss = 594.07516973\n",
      "Iteration 23140, loss = 593.99971673\n",
      "Iteration 23141, loss = 593.92429780\n",
      "Iteration 23142, loss = 593.84891290\n",
      "Iteration 23143, loss = 593.77356196\n",
      "Iteration 23144, loss = 593.69824496\n",
      "Iteration 23145, loss = 593.62296184\n",
      "Iteration 23146, loss = 593.54771254\n",
      "Iteration 23147, loss = 593.47249704\n",
      "Iteration 23148, loss = 593.39731527\n",
      "Iteration 23149, loss = 593.32216720\n",
      "Iteration 23150, loss = 593.24705277\n",
      "Iteration 23151, loss = 593.17197195\n",
      "Iteration 23152, loss = 593.09692467\n",
      "Iteration 23153, loss = 593.02191090\n",
      "Iteration 23154, loss = 592.94693059\n",
      "Iteration 23155, loss = 592.87198369\n",
      "Iteration 23156, loss = 592.79707016\n",
      "Iteration 23157, loss = 592.72218995\n",
      "Iteration 23158, loss = 592.64734302\n",
      "Iteration 23159, loss = 592.57252932\n",
      "Iteration 23160, loss = 592.49774879\n",
      "Iteration 23161, loss = 592.42300141\n",
      "Iteration 23162, loss = 592.34828712\n",
      "Iteration 23163, loss = 592.27360587\n",
      "Iteration 23164, loss = 592.19895762\n",
      "Iteration 23165, loss = 592.12434233\n",
      "Iteration 23166, loss = 592.04975995\n",
      "Iteration 23167, loss = 591.97521044\n",
      "Iteration 23168, loss = 591.90069374\n",
      "Iteration 23169, loss = 591.82620982\n",
      "Iteration 23170, loss = 591.75175863\n",
      "Iteration 23171, loss = 591.67734013\n",
      "Iteration 23172, loss = 591.60295426\n",
      "Iteration 23173, loss = 591.52860099\n",
      "Iteration 23174, loss = 591.45428027\n",
      "Iteration 23175, loss = 591.37999206\n",
      "Iteration 23176, loss = 591.30573631\n",
      "Iteration 23177, loss = 591.23151298\n",
      "Iteration 23178, loss = 591.15732203\n",
      "Iteration 23179, loss = 591.08316340\n",
      "Iteration 23180, loss = 591.00903706\n",
      "Iteration 23181, loss = 590.93494296\n",
      "Iteration 23182, loss = 590.86088106\n",
      "Iteration 23183, loss = 590.78685132\n",
      "Iteration 23184, loss = 590.71285368\n",
      "Iteration 23185, loss = 590.63888811\n",
      "Iteration 23186, loss = 590.56495457\n",
      "Iteration 23187, loss = 590.49105300\n",
      "Iteration 23188, loss = 590.41718338\n",
      "Iteration 23189, loss = 590.34334564\n",
      "Iteration 23190, loss = 590.26953976\n",
      "Iteration 23191, loss = 590.19576568\n",
      "Iteration 23192, loss = 590.12202337\n",
      "Iteration 23193, loss = 590.04831278\n",
      "Iteration 23194, loss = 589.97463387\n",
      "Iteration 23195, loss = 589.90098660\n",
      "Iteration 23196, loss = 589.82737092\n",
      "Iteration 23197, loss = 589.75378679\n",
      "Iteration 23198, loss = 589.68023417\n",
      "Iteration 23199, loss = 589.60671301\n",
      "Iteration 23200, loss = 589.53322328\n",
      "Iteration 23201, loss = 589.45976493\n",
      "Iteration 23202, loss = 589.38633792\n",
      "Iteration 23203, loss = 589.31294221\n",
      "Iteration 23204, loss = 589.23957775\n",
      "Iteration 23205, loss = 589.16624451\n",
      "Iteration 23206, loss = 589.09294243\n",
      "Iteration 23207, loss = 589.01967149\n",
      "Iteration 23208, loss = 588.94643164\n",
      "Iteration 23209, loss = 588.87322283\n",
      "Iteration 23210, loss = 588.80004503\n",
      "Iteration 23211, loss = 588.72689819\n",
      "Iteration 23212, loss = 588.65378227\n",
      "Iteration 23213, loss = 588.58069724\n",
      "Iteration 23214, loss = 588.50764305\n",
      "Iteration 23215, loss = 588.43461965\n",
      "Iteration 23216, loss = 588.36162701\n",
      "Iteration 23217, loss = 588.28866509\n",
      "Iteration 23218, loss = 588.21573385\n",
      "Iteration 23219, loss = 588.14283324\n",
      "Iteration 23220, loss = 588.06996323\n",
      "Iteration 23221, loss = 587.99712377\n",
      "Iteration 23222, loss = 587.92431483\n",
      "Iteration 23223, loss = 587.85153636\n",
      "Iteration 23224, loss = 587.77878832\n",
      "Iteration 23225, loss = 587.70607067\n",
      "Iteration 23226, loss = 587.63338338\n",
      "Iteration 23227, loss = 587.56072639\n",
      "Iteration 23228, loss = 587.48809968\n",
      "Iteration 23229, loss = 587.41550321\n",
      "Iteration 23230, loss = 587.34293692\n",
      "Iteration 23231, loss = 587.27040079\n",
      "Iteration 23232, loss = 587.19789477\n",
      "Iteration 23233, loss = 587.12541882\n",
      "Iteration 23234, loss = 587.05297291\n",
      "Iteration 23235, loss = 586.98055699\n",
      "Iteration 23236, loss = 586.90817102\n",
      "Iteration 23237, loss = 586.83581497\n",
      "Iteration 23238, loss = 586.76348879\n",
      "Iteration 23239, loss = 586.69119245\n",
      "Iteration 23240, loss = 586.61892591\n",
      "Iteration 23241, loss = 586.54668912\n",
      "Iteration 23242, loss = 586.47448206\n",
      "Iteration 23243, loss = 586.40230467\n",
      "Iteration 23244, loss = 586.33015693\n",
      "Iteration 23245, loss = 586.25803879\n",
      "Iteration 23246, loss = 586.18595021\n",
      "Iteration 23247, loss = 586.11389115\n",
      "Iteration 23248, loss = 586.04186159\n",
      "Iteration 23249, loss = 585.96986147\n",
      "Iteration 23250, loss = 585.89789076\n",
      "Iteration 23251, loss = 585.82594942\n",
      "Iteration 23252, loss = 585.75403741\n",
      "Iteration 23253, loss = 585.68215470\n",
      "Iteration 23254, loss = 585.61030125\n",
      "Iteration 23255, loss = 585.53847701\n",
      "Iteration 23256, loss = 585.46668195\n",
      "Iteration 23257, loss = 585.39491604\n",
      "Iteration 23258, loss = 585.32317923\n",
      "Iteration 23259, loss = 585.25147148\n",
      "Iteration 23260, loss = 585.17979277\n",
      "Iteration 23261, loss = 585.10814304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23262, loss = 585.03652227\n",
      "Iteration 23263, loss = 584.96493042\n",
      "Iteration 23264, loss = 584.89336744\n",
      "Iteration 23265, loss = 584.82183331\n",
      "Iteration 23266, loss = 584.75032798\n",
      "Iteration 23267, loss = 584.67885141\n",
      "Iteration 23268, loss = 584.60740358\n",
      "Iteration 23269, loss = 584.53598444\n",
      "Iteration 23270, loss = 584.46459395\n",
      "Iteration 23271, loss = 584.39323208\n",
      "Iteration 23272, loss = 584.32189879\n",
      "Iteration 23273, loss = 584.25059405\n",
      "Iteration 23274, loss = 584.17931781\n",
      "Iteration 23275, loss = 584.10807005\n",
      "Iteration 23276, loss = 584.03685072\n",
      "Iteration 23277, loss = 583.96565978\n",
      "Iteration 23278, loss = 583.89449721\n",
      "Iteration 23279, loss = 583.82336296\n",
      "Iteration 23280, loss = 583.75225700\n",
      "Iteration 23281, loss = 583.68117930\n",
      "Iteration 23282, loss = 583.61012980\n",
      "Iteration 23283, loss = 583.53910849\n",
      "Iteration 23284, loss = 583.46811532\n",
      "Iteration 23285, loss = 583.39715026\n",
      "Iteration 23286, loss = 583.32621327\n",
      "Iteration 23287, loss = 583.25530432\n",
      "Iteration 23288, loss = 583.18442336\n",
      "Iteration 23289, loss = 583.11357037\n",
      "Iteration 23290, loss = 583.04274531\n",
      "Iteration 23291, loss = 582.97194813\n",
      "Iteration 23292, loss = 582.90117882\n",
      "Iteration 23293, loss = 582.83043732\n",
      "Iteration 23294, loss = 582.75972362\n",
      "Iteration 23295, loss = 582.68903766\n",
      "Iteration 23296, loss = 582.61837941\n",
      "Iteration 23297, loss = 582.54774885\n",
      "Iteration 23298, loss = 582.47714593\n",
      "Iteration 23299, loss = 582.40657062\n",
      "Iteration 23300, loss = 582.33602288\n",
      "Iteration 23301, loss = 582.26550268\n",
      "Iteration 23302, loss = 582.19500999\n",
      "Iteration 23303, loss = 582.12454476\n",
      "Iteration 23304, loss = 582.05410697\n",
      "Iteration 23305, loss = 581.98369658\n",
      "Iteration 23306, loss = 581.91331355\n",
      "Iteration 23307, loss = 581.84295785\n",
      "Iteration 23308, loss = 581.77262945\n",
      "Iteration 23309, loss = 581.70232831\n",
      "Iteration 23310, loss = 581.63205439\n",
      "Iteration 23311, loss = 581.56180766\n",
      "Iteration 23312, loss = 581.49158810\n",
      "Iteration 23313, loss = 581.42139565\n",
      "Iteration 23314, loss = 581.35123029\n",
      "Iteration 23315, loss = 581.28109199\n",
      "Iteration 23316, loss = 581.21098071\n",
      "Iteration 23317, loss = 581.14089641\n",
      "Iteration 23318, loss = 581.07083907\n",
      "Iteration 23319, loss = 581.00080865\n",
      "Iteration 23320, loss = 580.93080510\n",
      "Iteration 23321, loss = 580.86082841\n",
      "Iteration 23322, loss = 580.79087854\n",
      "Iteration 23323, loss = 580.72095545\n",
      "Iteration 23324, loss = 580.65105911\n",
      "Iteration 23325, loss = 580.58118948\n",
      "Iteration 23326, loss = 580.51134653\n",
      "Iteration 23327, loss = 580.44153024\n",
      "Iteration 23328, loss = 580.37174055\n",
      "Iteration 23329, loss = 580.30197745\n",
      "Iteration 23330, loss = 580.23224090\n",
      "Iteration 23331, loss = 580.16253086\n",
      "Iteration 23332, loss = 580.09284731\n",
      "Iteration 23333, loss = 580.02319020\n",
      "Iteration 23334, loss = 579.95355951\n",
      "Iteration 23335, loss = 579.88395520\n",
      "Iteration 23336, loss = 579.81437724\n",
      "Iteration 23337, loss = 579.74482559\n",
      "Iteration 23338, loss = 579.67530023\n",
      "Iteration 23339, loss = 579.60580112\n",
      "Iteration 23340, loss = 579.53632823\n",
      "Iteration 23341, loss = 579.46688152\n",
      "Iteration 23342, loss = 579.39746097\n",
      "Iteration 23343, loss = 579.32806653\n",
      "Iteration 23344, loss = 579.25869818\n",
      "Iteration 23345, loss = 579.18935589\n",
      "Iteration 23346, loss = 579.12003962\n",
      "Iteration 23347, loss = 579.05074934\n",
      "Iteration 23348, loss = 578.98148501\n",
      "Iteration 23349, loss = 578.91224661\n",
      "Iteration 23350, loss = 578.84303411\n",
      "Iteration 23351, loss = 578.77384746\n",
      "Iteration 23352, loss = 578.70468664\n",
      "Iteration 23353, loss = 578.63555162\n",
      "Iteration 23354, loss = 578.56644237\n",
      "Iteration 23355, loss = 578.49735884\n",
      "Iteration 23356, loss = 578.42830102\n",
      "Iteration 23357, loss = 578.35926886\n",
      "Iteration 23358, loss = 578.29026234\n",
      "Iteration 23359, loss = 578.22128143\n",
      "Iteration 23360, loss = 578.15232609\n",
      "Iteration 23361, loss = 578.08339629\n",
      "Iteration 23362, loss = 578.01449201\n",
      "Iteration 23363, loss = 577.94561320\n",
      "Iteration 23364, loss = 577.87675983\n",
      "Iteration 23365, loss = 577.80793188\n",
      "Iteration 23366, loss = 577.73912932\n",
      "Iteration 23367, loss = 577.67035211\n",
      "Iteration 23368, loss = 577.60160022\n",
      "Iteration 23369, loss = 577.53287362\n",
      "Iteration 23370, loss = 577.46417228\n",
      "Iteration 23371, loss = 577.39549617\n",
      "Iteration 23372, loss = 577.32684525\n",
      "Iteration 23373, loss = 577.25821950\n",
      "Iteration 23374, loss = 577.18961888\n",
      "Iteration 23375, loss = 577.12104337\n",
      "Iteration 23376, loss = 577.05249293\n",
      "Iteration 23377, loss = 576.98396753\n",
      "Iteration 23378, loss = 576.91546715\n",
      "Iteration 23379, loss = 576.84699174\n",
      "Iteration 23380, loss = 576.77854128\n",
      "Iteration 23381, loss = 576.71011574\n",
      "Iteration 23382, loss = 576.64171509\n",
      "Iteration 23383, loss = 576.57333930\n",
      "Iteration 23384, loss = 576.50498833\n",
      "Iteration 23385, loss = 576.43666217\n",
      "Iteration 23386, loss = 576.36836077\n",
      "Iteration 23387, loss = 576.30008410\n",
      "Iteration 23388, loss = 576.23183215\n",
      "Iteration 23389, loss = 576.16360488\n",
      "Iteration 23390, loss = 576.09540228\n",
      "Iteration 23391, loss = 576.02722435\n",
      "Iteration 23392, loss = 575.95907110\n",
      "Iteration 23393, loss = 575.89094264\n",
      "Iteration 23394, loss = 575.82283919\n",
      "Iteration 23395, loss = 575.75476131\n",
      "Iteration 23396, loss = 575.68671021\n",
      "Iteration 23397, loss = 575.61868853\n",
      "Iteration 23398, loss = 575.55070153\n",
      "Iteration 23399, loss = 575.48275868\n",
      "Iteration 23400, loss = 575.41487047\n",
      "Iteration 23401, loss = 575.34703129\n",
      "Iteration 23402, loss = 575.27917644\n",
      "Iteration 23403, loss = 575.21121411\n",
      "Iteration 23404, loss = 575.14319202\n",
      "Iteration 23405, loss = 575.07530432\n",
      "Iteration 23406, loss = 575.00758426\n",
      "Iteration 23407, loss = 574.93985248\n",
      "Iteration 23408, loss = 574.87200901\n",
      "Iteration 23409, loss = 574.80419567\n",
      "Iteration 23410, loss = 574.73652639\n",
      "Iteration 23411, loss = 574.66888358\n",
      "Iteration 23412, loss = 574.60116552\n",
      "Iteration 23413, loss = 574.53347552\n",
      "Iteration 23414, loss = 574.46589260\n",
      "Iteration 23415, loss = 574.39832094\n",
      "Iteration 23416, loss = 574.33070752\n",
      "Iteration 23417, loss = 574.26314056\n",
      "Iteration 23418, loss = 574.19564758\n",
      "Iteration 23419, loss = 574.12814964\n",
      "Iteration 23420, loss = 574.06064161\n",
      "Iteration 23421, loss = 573.99318959\n",
      "Iteration 23422, loss = 573.92578103\n",
      "Iteration 23423, loss = 573.85836502\n",
      "Iteration 23424, loss = 573.79096538\n",
      "Iteration 23425, loss = 573.72361708\n",
      "Iteration 23426, loss = 573.65629059\n",
      "Iteration 23427, loss = 573.58896595\n",
      "Iteration 23428, loss = 573.52167284\n",
      "Iteration 23429, loss = 573.45441872\n",
      "Iteration 23430, loss = 573.38717714\n",
      "Iteration 23431, loss = 573.31994985\n",
      "Iteration 23432, loss = 573.25275777\n",
      "Iteration 23433, loss = 573.18559307\n",
      "Iteration 23434, loss = 573.11844110\n",
      "Iteration 23435, loss = 573.05131250\n",
      "Iteration 23436, loss = 572.98421591\n",
      "Iteration 23437, loss = 572.91714007\n",
      "Iteration 23438, loss = 572.85008124\n",
      "Iteration 23439, loss = 572.78304956\n",
      "Iteration 23440, loss = 572.71604505\n",
      "Iteration 23441, loss = 572.64905944\n",
      "Iteration 23442, loss = 572.58209499\n",
      "Iteration 23443, loss = 572.51515771\n",
      "Iteration 23444, loss = 572.44824401\n",
      "Iteration 23445, loss = 572.38134997\n",
      "Iteration 23446, loss = 572.31447950\n",
      "Iteration 23447, loss = 572.24763466\n",
      "Iteration 23448, loss = 572.18081168\n",
      "Iteration 23449, loss = 572.11400981\n",
      "Iteration 23450, loss = 572.04723224\n",
      "Iteration 23451, loss = 571.98047870\n",
      "Iteration 23452, loss = 571.91374664\n",
      "Iteration 23453, loss = 571.84703682\n",
      "Iteration 23454, loss = 571.78035108\n",
      "Iteration 23455, loss = 571.71368830\n",
      "Iteration 23456, loss = 571.64704721\n",
      "Iteration 23457, loss = 571.58042893\n",
      "Iteration 23458, loss = 571.51383419\n",
      "Iteration 23459, loss = 571.44726187\n",
      "Iteration 23460, loss = 571.38071155\n",
      "Iteration 23461, loss = 571.31418419\n",
      "Iteration 23462, loss = 571.24767986\n",
      "Iteration 23463, loss = 571.18119772\n",
      "Iteration 23464, loss = 571.11473783\n",
      "Iteration 23465, loss = 571.04830079\n",
      "Iteration 23466, loss = 570.98188639\n",
      "Iteration 23467, loss = 570.91549413\n",
      "Iteration 23468, loss = 570.84912421\n",
      "Iteration 23469, loss = 570.78277696\n",
      "Iteration 23470, loss = 570.71645209\n",
      "Iteration 23471, loss = 570.65014935\n",
      "Iteration 23472, loss = 570.58386894\n",
      "Iteration 23473, loss = 570.51761098\n",
      "Iteration 23474, loss = 570.45137526\n",
      "Iteration 23475, loss = 570.38516163\n",
      "Iteration 23476, loss = 570.31897026\n",
      "Iteration 23477, loss = 570.25280117\n",
      "Iteration 23478, loss = 570.18665418\n",
      "Iteration 23479, loss = 570.12052925\n",
      "Iteration 23480, loss = 570.05442646\n",
      "Iteration 23481, loss = 569.98834580\n",
      "Iteration 23482, loss = 569.92228715\n",
      "Iteration 23483, loss = 569.85625048\n",
      "Iteration 23484, loss = 569.79023584\n",
      "Iteration 23485, loss = 569.72424320\n",
      "Iteration 23486, loss = 569.65827247\n",
      "Iteration 23487, loss = 569.59232363\n",
      "Iteration 23488, loss = 569.52639671\n",
      "Iteration 23489, loss = 569.46049167\n",
      "Iteration 23490, loss = 569.39460845\n",
      "Iteration 23491, loss = 569.32874702\n",
      "Iteration 23492, loss = 569.26290739\n",
      "Iteration 23493, loss = 569.19708954\n",
      "Iteration 23494, loss = 569.13129340\n",
      "Iteration 23495, loss = 569.06551896\n",
      "Iteration 23496, loss = 568.99976622\n",
      "Iteration 23497, loss = 568.93403513\n",
      "Iteration 23498, loss = 568.86832567\n",
      "Iteration 23499, loss = 568.80263780\n",
      "Iteration 23500, loss = 568.73697151\n",
      "Iteration 23501, loss = 568.67132679\n",
      "Iteration 23502, loss = 568.60570358\n",
      "Iteration 23503, loss = 568.54010187\n",
      "Iteration 23504, loss = 568.47452163\n",
      "Iteration 23505, loss = 568.40896285\n",
      "Iteration 23506, loss = 568.34342549\n",
      "Iteration 23507, loss = 568.27790952\n",
      "Iteration 23508, loss = 568.21241492\n",
      "Iteration 23509, loss = 568.14694168\n",
      "Iteration 23510, loss = 568.08148975\n",
      "Iteration 23511, loss = 568.01605912\n",
      "Iteration 23512, loss = 567.95064975\n",
      "Iteration 23513, loss = 567.88526163\n",
      "Iteration 23514, loss = 567.81989473\n",
      "Iteration 23515, loss = 567.75454903\n",
      "Iteration 23516, loss = 567.68922449\n",
      "Iteration 23517, loss = 567.62392109\n",
      "Iteration 23518, loss = 567.55863881\n",
      "Iteration 23519, loss = 567.49337762\n",
      "Iteration 23520, loss = 567.42813750\n",
      "Iteration 23521, loss = 567.36291842\n",
      "Iteration 23522, loss = 567.29772036\n",
      "Iteration 23523, loss = 567.23254329\n",
      "Iteration 23524, loss = 567.16738719\n",
      "Iteration 23525, loss = 567.10225202\n",
      "Iteration 23526, loss = 567.03713778\n",
      "Iteration 23527, loss = 566.97204442\n",
      "Iteration 23528, loss = 566.90697193\n",
      "Iteration 23529, loss = 566.84192028\n",
      "Iteration 23530, loss = 566.77688945\n",
      "Iteration 23531, loss = 566.71187941\n",
      "Iteration 23532, loss = 566.64689014\n",
      "Iteration 23533, loss = 566.58192161\n",
      "Iteration 23534, loss = 566.51697380\n",
      "Iteration 23535, loss = 566.45204668\n",
      "Iteration 23536, loss = 566.38714022\n",
      "Iteration 23537, loss = 566.32225441\n",
      "Iteration 23538, loss = 566.25738922\n",
      "Iteration 23539, loss = 566.19254462\n",
      "Iteration 23540, loss = 566.12772060\n",
      "Iteration 23541, loss = 566.06291711\n",
      "Iteration 23542, loss = 565.99813415\n",
      "Iteration 23543, loss = 565.93337168\n",
      "Iteration 23544, loss = 565.86862968\n",
      "Iteration 23545, loss = 565.80390813\n",
      "Iteration 23546, loss = 565.73920700\n",
      "Iteration 23547, loss = 565.67452626\n",
      "Iteration 23548, loss = 565.60986590\n",
      "Iteration 23549, loss = 565.54522589\n",
      "Iteration 23550, loss = 565.48060621\n",
      "Iteration 23551, loss = 565.41600682\n",
      "Iteration 23552, loss = 565.35142771\n",
      "Iteration 23553, loss = 565.28686885\n",
      "Iteration 23554, loss = 565.22233022\n",
      "Iteration 23555, loss = 565.15781179\n",
      "Iteration 23556, loss = 565.09331355\n",
      "Iteration 23557, loss = 565.02883545\n",
      "Iteration 23558, loss = 564.96437749\n",
      "Iteration 23559, loss = 564.89993963\n",
      "Iteration 23560, loss = 564.83552186\n",
      "Iteration 23561, loss = 564.77112414\n",
      "Iteration 23562, loss = 564.70674646\n",
      "Iteration 23563, loss = 564.64238879\n",
      "Iteration 23564, loss = 564.57805110\n",
      "Iteration 23565, loss = 564.51373338\n",
      "Iteration 23566, loss = 564.44943560\n",
      "Iteration 23567, loss = 564.38515773\n",
      "Iteration 23568, loss = 564.32089975\n",
      "Iteration 23569, loss = 564.25666164\n",
      "Iteration 23570, loss = 564.19244337\n",
      "Iteration 23571, loss = 564.12824493\n",
      "Iteration 23572, loss = 564.06406627\n",
      "Iteration 23573, loss = 563.99990739\n",
      "Iteration 23574, loss = 563.93576826\n",
      "Iteration 23575, loss = 563.87164885\n",
      "Iteration 23576, loss = 563.80754915\n",
      "Iteration 23577, loss = 563.74346912\n",
      "Iteration 23578, loss = 563.67940874\n",
      "Iteration 23579, loss = 563.61536800\n",
      "Iteration 23580, loss = 563.55134686\n",
      "Iteration 23581, loss = 563.48734530\n",
      "Iteration 23582, loss = 563.42336330\n",
      "Iteration 23583, loss = 563.35940084\n",
      "Iteration 23584, loss = 563.29545789\n",
      "Iteration 23585, loss = 563.23153443\n",
      "Iteration 23586, loss = 563.16763044\n",
      "Iteration 23587, loss = 563.10374588\n",
      "Iteration 23588, loss = 563.03988075\n",
      "Iteration 23589, loss = 562.97603501\n",
      "Iteration 23590, loss = 562.91220864\n",
      "Iteration 23591, loss = 562.84840162\n",
      "Iteration 23592, loss = 562.78461393\n",
      "Iteration 23593, loss = 562.72084554\n",
      "Iteration 23594, loss = 562.65709643\n",
      "Iteration 23595, loss = 562.59336657\n",
      "Iteration 23596, loss = 562.52965595\n",
      "Iteration 23597, loss = 562.46596453\n",
      "Iteration 23598, loss = 562.40229230\n",
      "Iteration 23599, loss = 562.33863924\n",
      "Iteration 23600, loss = 562.27500531\n",
      "Iteration 23601, loss = 562.21139050\n",
      "Iteration 23602, loss = 562.14779478\n",
      "Iteration 23603, loss = 562.08421814\n",
      "Iteration 23604, loss = 562.02066054\n",
      "Iteration 23605, loss = 561.95712196\n",
      "Iteration 23606, loss = 561.89360239\n",
      "Iteration 23607, loss = 561.83010180\n",
      "Iteration 23608, loss = 561.76662016\n",
      "Iteration 23609, loss = 561.70315745\n",
      "Iteration 23610, loss = 561.63971366\n",
      "Iteration 23611, loss = 561.57628875\n",
      "Iteration 23612, loss = 561.51288270\n",
      "Iteration 23613, loss = 561.44949550\n",
      "Iteration 23614, loss = 561.38612711\n",
      "Iteration 23615, loss = 561.32277752\n",
      "Iteration 23616, loss = 561.25944670\n",
      "Iteration 23617, loss = 561.19613463\n",
      "Iteration 23618, loss = 561.13284129\n",
      "Iteration 23619, loss = 561.06956665\n",
      "Iteration 23620, loss = 561.00631069\n",
      "Iteration 23621, loss = 560.94307340\n",
      "Iteration 23622, loss = 560.87985474\n",
      "Iteration 23623, loss = 560.81665469\n",
      "Iteration 23624, loss = 560.75347323\n",
      "Iteration 23625, loss = 560.69031034\n",
      "Iteration 23626, loss = 560.62716600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23627, loss = 560.56404018\n",
      "Iteration 23628, loss = 560.50093286\n",
      "Iteration 23629, loss = 560.43784402\n",
      "Iteration 23630, loss = 560.37477363\n",
      "Iteration 23631, loss = 560.31172168\n",
      "Iteration 23632, loss = 560.24868814\n",
      "Iteration 23633, loss = 560.18567298\n",
      "Iteration 23634, loss = 560.12267619\n",
      "Iteration 23635, loss = 560.05969775\n",
      "Iteration 23636, loss = 559.99673762\n",
      "Iteration 23637, loss = 559.93379579\n",
      "Iteration 23638, loss = 559.87087224\n",
      "Iteration 23639, loss = 559.80796694\n",
      "Iteration 23640, loss = 559.74507988\n",
      "Iteration 23641, loss = 559.68221102\n",
      "Iteration 23642, loss = 559.61936034\n",
      "Iteration 23643, loss = 559.55652783\n",
      "Iteration 23644, loss = 559.49371347\n",
      "Iteration 23645, loss = 559.43091722\n",
      "Iteration 23646, loss = 559.36813907\n",
      "Iteration 23647, loss = 559.30537899\n",
      "Iteration 23648, loss = 559.24263697\n",
      "Iteration 23649, loss = 559.17991298\n",
      "Iteration 23650, loss = 559.11720699\n",
      "Iteration 23651, loss = 559.05451899\n",
      "Iteration 23652, loss = 558.99184896\n",
      "Iteration 23653, loss = 558.92919686\n",
      "Iteration 23654, loss = 558.86656269\n",
      "Iteration 23655, loss = 558.80394641\n",
      "Iteration 23656, loss = 558.74134801\n",
      "Iteration 23657, loss = 558.67876746\n",
      "Iteration 23658, loss = 558.61620474\n",
      "Iteration 23659, loss = 558.55365983\n",
      "Iteration 23660, loss = 558.49113271\n",
      "Iteration 23661, loss = 558.42862335\n",
      "Iteration 23662, loss = 558.36613174\n",
      "Iteration 23663, loss = 558.30365785\n",
      "Iteration 23664, loss = 558.24120165\n",
      "Iteration 23665, loss = 558.17876313\n",
      "Iteration 23666, loss = 558.11634227\n",
      "Iteration 23667, loss = 558.05393904\n",
      "Iteration 23668, loss = 557.99155342\n",
      "Iteration 23669, loss = 557.92918538\n",
      "Iteration 23670, loss = 557.86683492\n",
      "Iteration 23671, loss = 557.80450200\n",
      "Iteration 23672, loss = 557.74218660\n",
      "Iteration 23673, loss = 557.67988871\n",
      "Iteration 23674, loss = 557.61760829\n",
      "Iteration 23675, loss = 557.55534533\n",
      "Iteration 23676, loss = 557.49309981\n",
      "Iteration 23677, loss = 557.43087170\n",
      "Iteration 23678, loss = 557.36866098\n",
      "Iteration 23679, loss = 557.30646763\n",
      "Iteration 23680, loss = 557.24429163\n",
      "Iteration 23681, loss = 557.18213295\n",
      "Iteration 23682, loss = 557.11999158\n",
      "Iteration 23683, loss = 557.05786750\n",
      "Iteration 23684, loss = 556.99576067\n",
      "Iteration 23685, loss = 556.93367108\n",
      "Iteration 23686, loss = 556.87159871\n",
      "Iteration 23687, loss = 556.80954354\n",
      "Iteration 23688, loss = 556.74750554\n",
      "Iteration 23689, loss = 556.68548469\n",
      "Iteration 23690, loss = 556.62348097\n",
      "Iteration 23691, loss = 556.56149436\n",
      "Iteration 23692, loss = 556.49952484\n",
      "Iteration 23693, loss = 556.43757238\n",
      "Iteration 23694, loss = 556.37563696\n",
      "Iteration 23695, loss = 556.31371857\n",
      "Iteration 23696, loss = 556.25181718\n",
      "Iteration 23697, loss = 556.18993276\n",
      "Iteration 23698, loss = 556.12806531\n",
      "Iteration 23699, loss = 556.06621478\n",
      "Iteration 23700, loss = 556.00438117\n",
      "Iteration 23701, loss = 555.94256446\n",
      "Iteration 23702, loss = 555.88076461\n",
      "Iteration 23703, loss = 555.81898161\n",
      "Iteration 23704, loss = 555.75721544\n",
      "Iteration 23705, loss = 555.69546607\n",
      "Iteration 23706, loss = 555.63373349\n",
      "Iteration 23707, loss = 555.57201767\n",
      "Iteration 23708, loss = 555.51031859\n",
      "Iteration 23709, loss = 555.44863623\n",
      "Iteration 23710, loss = 555.38697056\n",
      "Iteration 23711, loss = 555.32532158\n",
      "Iteration 23712, loss = 555.26368924\n",
      "Iteration 23713, loss = 555.20207354\n",
      "Iteration 23714, loss = 555.14047445\n",
      "Iteration 23715, loss = 555.07889195\n",
      "Iteration 23716, loss = 555.01732601\n",
      "Iteration 23717, loss = 554.95577662\n",
      "Iteration 23718, loss = 554.89424376\n",
      "Iteration 23719, loss = 554.83272740\n",
      "Iteration 23720, loss = 554.77122752\n",
      "Iteration 23721, loss = 554.70974410\n",
      "Iteration 23722, loss = 554.64827712\n",
      "Iteration 23723, loss = 554.58682656\n",
      "Iteration 23724, loss = 554.52539239\n",
      "Iteration 23725, loss = 554.46397460\n",
      "Iteration 23726, loss = 554.40257316\n",
      "Iteration 23727, loss = 554.34118804\n",
      "Iteration 23728, loss = 554.27981924\n",
      "Iteration 23729, loss = 554.21846673\n",
      "Iteration 23730, loss = 554.15713048\n",
      "Iteration 23731, loss = 554.09581048\n",
      "Iteration 23732, loss = 554.03450669\n",
      "Iteration 23733, loss = 553.97321912\n",
      "Iteration 23734, loss = 553.91194772\n",
      "Iteration 23735, loss = 553.85069247\n",
      "Iteration 23736, loss = 553.78945337\n",
      "Iteration 23737, loss = 553.72823038\n",
      "Iteration 23738, loss = 553.66702349\n",
      "Iteration 23739, loss = 553.60583266\n",
      "Iteration 23740, loss = 553.54465789\n",
      "Iteration 23741, loss = 553.48349915\n",
      "Iteration 23742, loss = 553.42235642\n",
      "Iteration 23743, loss = 553.36122967\n",
      "Iteration 23744, loss = 553.30011888\n",
      "Iteration 23745, loss = 553.23902404\n",
      "Iteration 23746, loss = 553.17794512\n",
      "Iteration 23747, loss = 553.11688210\n",
      "Iteration 23748, loss = 553.05583496\n",
      "Iteration 23749, loss = 552.99480367\n",
      "Iteration 23750, loss = 552.93378822\n",
      "Iteration 23751, loss = 552.87278859\n",
      "Iteration 23752, loss = 552.81180474\n",
      "Iteration 23753, loss = 552.75083667\n",
      "Iteration 23754, loss = 552.68988434\n",
      "Iteration 23755, loss = 552.62894774\n",
      "Iteration 23756, loss = 552.56802685\n",
      "Iteration 23757, loss = 552.50712164\n",
      "Iteration 23758, loss = 552.44623210\n",
      "Iteration 23759, loss = 552.38535819\n",
      "Iteration 23760, loss = 552.32449990\n",
      "Iteration 23761, loss = 552.26365721\n",
      "Iteration 23762, loss = 552.20283010\n",
      "Iteration 23763, loss = 552.14201854\n",
      "Iteration 23764, loss = 552.08122252\n",
      "Iteration 23765, loss = 552.02044200\n",
      "Iteration 23766, loss = 551.95967698\n",
      "Iteration 23767, loss = 551.89892743\n",
      "Iteration 23768, loss = 551.83819333\n",
      "Iteration 23769, loss = 551.77747468\n",
      "Iteration 23770, loss = 551.71677147\n",
      "Iteration 23771, loss = 551.65608372\n",
      "Iteration 23772, loss = 551.59541153\n",
      "Iteration 23773, loss = 551.53475509\n",
      "Iteration 23774, loss = 551.47411490\n",
      "Iteration 23775, loss = 551.41349205\n",
      "Iteration 23776, loss = 551.35288895\n",
      "Iteration 23777, loss = 551.29231065\n",
      "Iteration 23778, loss = 551.23176663\n",
      "Iteration 23779, loss = 551.17126949\n",
      "Iteration 23780, loss = 551.11081978\n",
      "Iteration 23781, loss = 551.05036418\n",
      "Iteration 23782, loss = 550.98979867\n",
      "Iteration 23783, loss = 550.92912194\n",
      "Iteration 23784, loss = 550.86853101\n",
      "Iteration 23785, loss = 550.80813167\n",
      "Iteration 23786, loss = 550.74776336\n",
      "Iteration 23787, loss = 550.68726491\n",
      "Iteration 23788, loss = 550.62673244\n",
      "Iteration 23789, loss = 550.56633637\n",
      "Iteration 23790, loss = 550.50600911\n",
      "Iteration 23791, loss = 550.44559711\n",
      "Iteration 23792, loss = 550.38515905\n",
      "Iteration 23793, loss = 550.32482235\n",
      "Iteration 23794, loss = 550.26452697\n",
      "Iteration 23795, loss = 550.20417355\n",
      "Iteration 23796, loss = 550.14382398\n",
      "Iteration 23797, loss = 550.08355281\n",
      "Iteration 23798, loss = 550.02329316\n",
      "Iteration 23799, loss = 549.96299813\n",
      "Iteration 23800, loss = 549.90273172\n",
      "Iteration 23801, loss = 549.84251823\n",
      "Iteration 23802, loss = 549.78229975\n",
      "Iteration 23803, loss = 549.72206964\n",
      "Iteration 23804, loss = 549.66187765\n",
      "Iteration 23805, loss = 549.60171556\n",
      "Iteration 23806, loss = 549.54154566\n",
      "Iteration 23807, loss = 549.48138386\n",
      "Iteration 23808, loss = 549.42125687\n",
      "Iteration 23809, loss = 549.36114458\n",
      "Iteration 23810, loss = 549.30103035\n",
      "Iteration 23811, loss = 549.24093525\n",
      "Iteration 23812, loss = 549.18086668\n",
      "Iteration 23813, loss = 549.12080596\n",
      "Iteration 23814, loss = 549.06075162\n",
      "Iteration 23815, loss = 549.00071928\n",
      "Iteration 23816, loss = 548.94070602\n",
      "Iteration 23817, loss = 548.88069982\n",
      "Iteration 23818, loss = 548.82070613\n",
      "Iteration 23819, loss = 548.76073310\n",
      "Iteration 23820, loss = 548.70077448\n",
      "Iteration 23821, loss = 548.64082495\n",
      "Iteration 23822, loss = 548.58089088\n",
      "Iteration 23823, loss = 548.52097499\n",
      "Iteration 23824, loss = 548.46107146\n",
      "Iteration 23825, loss = 548.40117941\n",
      "Iteration 23826, loss = 548.34130355\n",
      "Iteration 23827, loss = 548.28144368\n",
      "Iteration 23828, loss = 548.22159590\n",
      "Iteration 23829, loss = 548.16176114\n",
      "Iteration 23830, loss = 548.10194231\n",
      "Iteration 23831, loss = 548.04213806\n",
      "Iteration 23832, loss = 547.98234625\n",
      "Iteration 23833, loss = 547.92256829\n",
      "Iteration 23834, loss = 547.86280563\n",
      "Iteration 23835, loss = 547.80305683\n",
      "Iteration 23836, loss = 547.74332092\n",
      "Iteration 23837, loss = 547.68359914\n",
      "Iteration 23838, loss = 547.62389206\n",
      "Iteration 23839, loss = 547.56419856\n",
      "Iteration 23840, loss = 547.50451827\n",
      "Iteration 23841, loss = 547.44485211\n",
      "Iteration 23842, loss = 547.38520021\n",
      "Iteration 23843, loss = 547.32556177\n",
      "Iteration 23844, loss = 547.26593672\n",
      "Iteration 23845, loss = 547.20632567\n",
      "Iteration 23846, loss = 547.14672858\n",
      "Iteration 23847, loss = 547.08714492\n",
      "Iteration 23848, loss = 547.02757471\n",
      "Iteration 23849, loss = 546.96801834\n",
      "Iteration 23850, loss = 546.90847570\n",
      "Iteration 23851, loss = 546.84894647\n",
      "Iteration 23852, loss = 546.78943069\n",
      "Iteration 23853, loss = 546.72992858\n",
      "Iteration 23854, loss = 546.67044006\n",
      "Iteration 23855, loss = 546.61096490\n",
      "Iteration 23856, loss = 546.55150314\n",
      "Iteration 23857, loss = 546.49205490\n",
      "Iteration 23858, loss = 546.43262013\n",
      "Iteration 23859, loss = 546.37319867\n",
      "Iteration 23860, loss = 546.31379052\n",
      "Iteration 23861, loss = 546.25439577\n",
      "Iteration 23862, loss = 546.19501438\n",
      "Iteration 23863, loss = 546.13564623\n",
      "Iteration 23864, loss = 546.07629131\n",
      "Iteration 23865, loss = 546.01694967\n",
      "Iteration 23866, loss = 545.95762127\n",
      "Iteration 23867, loss = 545.89830604\n",
      "Iteration 23868, loss = 545.83900396\n",
      "Iteration 23869, loss = 545.77971505\n",
      "Iteration 23870, loss = 545.72043927\n",
      "Iteration 23871, loss = 545.66117658\n",
      "Iteration 23872, loss = 545.60192695\n",
      "Iteration 23873, loss = 545.54269037\n",
      "Iteration 23874, loss = 545.48346684\n",
      "Iteration 23875, loss = 545.42425630\n",
      "Iteration 23876, loss = 545.36505873\n",
      "Iteration 23877, loss = 545.30587411\n",
      "Iteration 23878, loss = 545.24670244\n",
      "Iteration 23879, loss = 545.18754367\n",
      "Iteration 23880, loss = 545.12839777\n",
      "Iteration 23881, loss = 545.06926473\n",
      "Iteration 23882, loss = 545.01014453\n",
      "Iteration 23883, loss = 544.95103714\n",
      "Iteration 23884, loss = 544.89194254\n",
      "Iteration 23885, loss = 544.83286070\n",
      "Iteration 23886, loss = 544.77379159\n",
      "Iteration 23887, loss = 544.71473521\n",
      "Iteration 23888, loss = 544.65569152\n",
      "Iteration 23889, loss = 544.59666050\n",
      "Iteration 23890, loss = 544.53764212\n",
      "Iteration 23891, loss = 544.47863636\n",
      "Iteration 23892, loss = 544.41964321\n",
      "Iteration 23893, loss = 544.36066263\n",
      "Iteration 23894, loss = 544.30169460\n",
      "Iteration 23895, loss = 544.24273910\n",
      "Iteration 23896, loss = 544.18379611\n",
      "Iteration 23897, loss = 544.12486561\n",
      "Iteration 23898, loss = 544.06594756\n",
      "Iteration 23899, loss = 544.00704196\n",
      "Iteration 23900, loss = 543.94814878\n",
      "Iteration 23901, loss = 543.88926798\n",
      "Iteration 23902, loss = 543.83039957\n",
      "Iteration 23903, loss = 543.77154350\n",
      "Iteration 23904, loss = 543.71269976\n",
      "Iteration 23905, loss = 543.65386833\n",
      "Iteration 23906, loss = 543.59504919\n",
      "Iteration 23907, loss = 543.53624231\n",
      "Iteration 23908, loss = 543.47744768\n",
      "Iteration 23909, loss = 543.41866527\n",
      "Iteration 23910, loss = 543.35989506\n",
      "Iteration 23911, loss = 543.30113704\n",
      "Iteration 23912, loss = 543.24239117\n",
      "Iteration 23913, loss = 543.18365745\n",
      "Iteration 23914, loss = 543.12493585\n",
      "Iteration 23915, loss = 543.06622636\n",
      "Iteration 23916, loss = 543.00752894\n",
      "Iteration 23917, loss = 542.94884359\n",
      "Iteration 23918, loss = 542.89017029\n",
      "Iteration 23919, loss = 542.83150901\n",
      "Iteration 23920, loss = 542.77285974\n",
      "Iteration 23921, loss = 542.71422246\n",
      "Iteration 23922, loss = 542.65559715\n",
      "Iteration 23923, loss = 542.59698379\n",
      "Iteration 23924, loss = 542.53838237\n",
      "Iteration 23925, loss = 542.47979287\n",
      "Iteration 23926, loss = 542.42121527\n",
      "Iteration 23927, loss = 542.36264956\n",
      "Iteration 23928, loss = 542.30409572\n",
      "Iteration 23929, loss = 542.24555373\n",
      "Iteration 23930, loss = 542.18702357\n",
      "Iteration 23931, loss = 542.12850524\n",
      "Iteration 23932, loss = 542.06999871\n",
      "Iteration 23933, loss = 542.01150398\n",
      "Iteration 23934, loss = 541.95302102\n",
      "Iteration 23935, loss = 541.89454982\n",
      "Iteration 23936, loss = 541.83609037\n",
      "Iteration 23937, loss = 541.77764265\n",
      "Iteration 23938, loss = 541.71920666\n",
      "Iteration 23939, loss = 541.66078236\n",
      "Iteration 23940, loss = 541.60236976\n",
      "Iteration 23941, loss = 541.54396884\n",
      "Iteration 23942, loss = 541.48557959\n",
      "Iteration 23943, loss = 541.42720198\n",
      "Iteration 23944, loss = 541.36883602\n",
      "Iteration 23945, loss = 541.31048169\n",
      "Iteration 23946, loss = 541.25213897\n",
      "Iteration 23947, loss = 541.19380786\n",
      "Iteration 23948, loss = 541.13548834\n",
      "Iteration 23949, loss = 541.07718041\n",
      "Iteration 23950, loss = 541.01888404\n",
      "Iteration 23951, loss = 540.96059924\n",
      "Iteration 23952, loss = 540.90232598\n",
      "Iteration 23953, loss = 540.84406426\n",
      "Iteration 23954, loss = 540.78581407\n",
      "Iteration 23955, loss = 540.72757539\n",
      "Iteration 23956, loss = 540.66934823\n",
      "Iteration 23957, loss = 540.61113256\n",
      "Iteration 23958, loss = 540.55292837\n",
      "Iteration 23959, loss = 540.49473566\n",
      "Iteration 23960, loss = 540.43655443\n",
      "Iteration 23961, loss = 540.37838464\n",
      "Iteration 23962, loss = 540.32022631\n",
      "Iteration 23963, loss = 540.26207942\n",
      "Iteration 23964, loss = 540.20394396\n",
      "Iteration 23965, loss = 540.14581991\n",
      "Iteration 23966, loss = 540.08770728\n",
      "Iteration 23967, loss = 540.02960606\n",
      "Iteration 23968, loss = 539.97151622\n",
      "Iteration 23969, loss = 539.91343777\n",
      "Iteration 23970, loss = 539.85537070\n",
      "Iteration 23971, loss = 539.79731500\n",
      "Iteration 23972, loss = 539.73927066\n",
      "Iteration 23973, loss = 539.68123766\n",
      "Iteration 23974, loss = 539.62321601\n",
      "Iteration 23975, loss = 539.56520569\n",
      "Iteration 23976, loss = 539.50720670\n",
      "Iteration 23977, loss = 539.44921903\n",
      "Iteration 23978, loss = 539.39124266\n",
      "Iteration 23979, loss = 539.33327760\n",
      "Iteration 23980, loss = 539.27532383\n",
      "Iteration 23981, loss = 539.21738134\n",
      "Iteration 23982, loss = 539.15945012\n",
      "Iteration 23983, loss = 539.10153018\n",
      "Iteration 23984, loss = 539.04362149\n",
      "Iteration 23985, loss = 538.98572405\n",
      "Iteration 23986, loss = 538.92783786\n",
      "Iteration 23987, loss = 538.86996290\n",
      "Iteration 23988, loss = 538.81209917\n",
      "Iteration 23989, loss = 538.75424665\n",
      "Iteration 23990, loss = 538.69640535\n",
      "Iteration 23991, loss = 538.63857524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23992, loss = 538.58075633\n",
      "Iteration 23993, loss = 538.52294860\n",
      "Iteration 23994, loss = 538.46515205\n",
      "Iteration 23995, loss = 538.40736666\n",
      "Iteration 23996, loss = 538.34959244\n",
      "Iteration 23997, loss = 538.29182936\n",
      "Iteration 23998, loss = 538.23407743\n",
      "Iteration 23999, loss = 538.17633663\n",
      "Iteration 24000, loss = 538.11860696\n",
      "Iteration 24001, loss = 538.06088840\n",
      "Iteration 24002, loss = 538.00318095\n",
      "Iteration 24003, loss = 537.94548460\n",
      "Iteration 24004, loss = 537.88779933\n",
      "Iteration 24005, loss = 537.83012515\n",
      "Iteration 24006, loss = 537.77246205\n",
      "Iteration 24007, loss = 537.71481000\n",
      "Iteration 24008, loss = 537.65716901\n",
      "Iteration 24009, loss = 537.59953907\n",
      "Iteration 24010, loss = 537.54192017\n",
      "Iteration 24011, loss = 537.48431229\n",
      "Iteration 24012, loss = 537.42671543\n",
      "Iteration 24013, loss = 537.36912958\n",
      "Iteration 24014, loss = 537.31155473\n",
      "Iteration 24015, loss = 537.25399087\n",
      "Iteration 24016, loss = 537.19643799\n",
      "Iteration 24017, loss = 537.13889609\n",
      "Iteration 24018, loss = 537.08136515\n",
      "Iteration 24019, loss = 537.02384516\n",
      "Iteration 24020, loss = 536.96633612\n",
      "Iteration 24021, loss = 536.90883801\n",
      "Iteration 24022, loss = 536.85135082\n",
      "Iteration 24023, loss = 536.79387455\n",
      "Iteration 24024, loss = 536.73640919\n",
      "Iteration 24025, loss = 536.67895472\n",
      "Iteration 24026, loss = 536.62151114\n",
      "Iteration 24027, loss = 536.56407843\n",
      "Iteration 24028, loss = 536.50665659\n",
      "Iteration 24029, loss = 536.44924560\n",
      "Iteration 24030, loss = 536.39184546\n",
      "Iteration 24031, loss = 536.33445616\n",
      "Iteration 24032, loss = 536.27707768\n",
      "Iteration 24033, loss = 536.21971001\n",
      "Iteration 24034, loss = 536.16235315\n",
      "Iteration 24035, loss = 536.10500709\n",
      "Iteration 24036, loss = 536.04767181\n",
      "Iteration 24037, loss = 535.99034730\n",
      "Iteration 24038, loss = 535.93303356\n",
      "Iteration 24039, loss = 535.87573057\n",
      "Iteration 24040, loss = 535.81843832\n",
      "Iteration 24041, loss = 535.76115680\n",
      "Iteration 24042, loss = 535.70388600\n",
      "Iteration 24043, loss = 535.64662592\n",
      "Iteration 24044, loss = 535.58937653\n",
      "Iteration 24045, loss = 535.53213783\n",
      "Iteration 24046, loss = 535.47490980\n",
      "Iteration 24047, loss = 535.41769245\n",
      "Iteration 24048, loss = 535.36048575\n",
      "Iteration 24049, loss = 535.30328969\n",
      "Iteration 24050, loss = 535.24610426\n",
      "Iteration 24051, loss = 535.18892946\n",
      "Iteration 24052, loss = 535.13176527\n",
      "Iteration 24053, loss = 535.07461168\n",
      "Iteration 24054, loss = 535.01746867\n",
      "Iteration 24055, loss = 534.96033624\n",
      "Iteration 24056, loss = 534.90321438\n",
      "Iteration 24057, loss = 534.84610307\n",
      "Iteration 24058, loss = 534.78900230\n",
      "Iteration 24059, loss = 534.73191206\n",
      "Iteration 24060, loss = 534.67483234\n",
      "Iteration 24061, loss = 534.61776313\n",
      "Iteration 24062, loss = 534.56070441\n",
      "Iteration 24063, loss = 534.50365618\n",
      "Iteration 24064, loss = 534.44661842\n",
      "Iteration 24065, loss = 534.38959112\n",
      "Iteration 24066, loss = 534.33257429\n",
      "Iteration 24067, loss = 534.27556791\n",
      "Iteration 24068, loss = 534.21857200\n",
      "Iteration 24069, loss = 534.16158662\n",
      "Iteration 24070, loss = 534.10461191\n",
      "Iteration 24071, loss = 534.04764823\n",
      "Iteration 24072, loss = 533.99069641\n",
      "Iteration 24073, loss = 533.93375847\n",
      "Iteration 24074, loss = 533.87683899\n",
      "Iteration 24075, loss = 533.81994761\n",
      "Iteration 24076, loss = 533.76310033\n",
      "Iteration 24077, loss = 533.70630651\n",
      "Iteration 24078, loss = 533.64952172\n",
      "Iteration 24079, loss = 533.59262463\n",
      "Iteration 24080, loss = 533.53557374\n",
      "Iteration 24081, loss = 533.47857090\n",
      "Iteration 24082, loss = 533.42178447\n",
      "Iteration 24083, loss = 533.36505822\n",
      "Iteration 24084, loss = 533.30818297\n",
      "Iteration 24085, loss = 533.25124115\n",
      "Iteration 24086, loss = 533.19444096\n",
      "Iteration 24087, loss = 533.13772613\n",
      "Iteration 24088, loss = 533.08090983\n",
      "Iteration 24089, loss = 533.02405160\n",
      "Iteration 24090, loss = 532.96730073\n",
      "Iteration 24091, loss = 532.91059277\n",
      "Iteration 24092, loss = 532.85380999\n",
      "Iteration 24093, loss = 532.79702712\n",
      "Iteration 24094, loss = 532.74032787\n",
      "Iteration 24095, loss = 532.68363004\n",
      "Iteration 24096, loss = 532.62688629\n",
      "Iteration 24097, loss = 532.57017310\n",
      "Iteration 24098, loss = 532.51351213\n",
      "Iteration 24099, loss = 532.45683223\n",
      "Iteration 24100, loss = 532.40013752\n",
      "Iteration 24101, loss = 532.34348326\n",
      "Iteration 24102, loss = 532.28685101\n",
      "Iteration 24103, loss = 532.23020071\n",
      "Iteration 24104, loss = 532.17355902\n",
      "Iteration 24105, loss = 532.11695105\n",
      "Iteration 24106, loss = 532.06034681\n",
      "Iteration 24107, loss = 532.00373575\n",
      "Iteration 24108, loss = 531.94714427\n",
      "Iteration 24109, loss = 531.89057405\n",
      "Iteration 24110, loss = 531.83400227\n",
      "Iteration 24111, loss = 531.77743491\n",
      "Iteration 24112, loss = 531.72088815\n",
      "Iteration 24113, loss = 531.66435279\n",
      "Iteration 24114, loss = 531.60781819\n",
      "Iteration 24115, loss = 531.55129466\n",
      "Iteration 24116, loss = 531.49478813\n",
      "Iteration 24117, loss = 531.43828834\n",
      "Iteration 24118, loss = 531.38179351\n",
      "Iteration 24119, loss = 531.32531202\n",
      "Iteration 24120, loss = 531.26884345\n",
      "Iteration 24121, loss = 531.21238084\n",
      "Iteration 24122, loss = 531.15592640\n",
      "Iteration 24123, loss = 531.09948504\n",
      "Iteration 24124, loss = 531.04305389\n",
      "Iteration 24125, loss = 530.98662958\n",
      "Iteration 24126, loss = 530.93021510\n",
      "Iteration 24127, loss = 530.87381257\n",
      "Iteration 24128, loss = 530.81741902\n",
      "Iteration 24129, loss = 530.76103340\n",
      "Iteration 24130, loss = 530.70465818\n",
      "Iteration 24131, loss = 530.64829381\n",
      "Iteration 24132, loss = 530.59193810\n",
      "Iteration 24133, loss = 530.53559110\n",
      "Iteration 24134, loss = 530.47925450\n",
      "Iteration 24135, loss = 530.42292797\n",
      "Iteration 24136, loss = 530.36661018\n",
      "Iteration 24137, loss = 530.31030153\n",
      "Iteration 24138, loss = 530.25400306\n",
      "Iteration 24139, loss = 530.19771421\n",
      "Iteration 24140, loss = 530.14143426\n",
      "Iteration 24141, loss = 530.08516364\n",
      "Iteration 24142, loss = 530.02890291\n",
      "Iteration 24143, loss = 529.97265161\n",
      "Iteration 24144, loss = 529.91640931\n",
      "Iteration 24145, loss = 529.86017640\n",
      "Iteration 24146, loss = 529.80395314\n",
      "Iteration 24147, loss = 529.74773920\n",
      "Iteration 24148, loss = 529.69153434\n",
      "Iteration 24149, loss = 529.63533882\n",
      "Iteration 24150, loss = 529.57915279\n",
      "Iteration 24151, loss = 529.52297600\n",
      "Iteration 24152, loss = 529.46680832\n",
      "Iteration 24153, loss = 529.41064992\n",
      "Iteration 24154, loss = 529.35450087\n",
      "Iteration 24155, loss = 529.29836102\n",
      "Iteration 24156, loss = 529.24223026\n",
      "Iteration 24157, loss = 529.18610871\n",
      "Iteration 24158, loss = 529.12999641\n",
      "Iteration 24159, loss = 529.07389325\n",
      "Iteration 24160, loss = 529.01779916\n",
      "Iteration 24161, loss = 528.96171420\n",
      "Iteration 24162, loss = 528.90563840\n",
      "Iteration 24163, loss = 528.84957170\n",
      "Iteration 24164, loss = 528.79351401\n",
      "Iteration 24165, loss = 528.73746539\n",
      "Iteration 24166, loss = 528.68142585\n",
      "Iteration 24167, loss = 528.62539533\n",
      "Iteration 24168, loss = 528.56937380\n",
      "Iteration 24169, loss = 528.51336126\n",
      "Iteration 24170, loss = 528.45735771\n",
      "Iteration 24171, loss = 528.40136314\n",
      "Iteration 24172, loss = 528.34537750\n",
      "Iteration 24173, loss = 528.28940078\n",
      "Iteration 24174, loss = 528.23343299\n",
      "Iteration 24175, loss = 528.17747410\n",
      "Iteration 24176, loss = 528.12152409\n",
      "Iteration 24177, loss = 528.06558293\n",
      "Iteration 24178, loss = 528.00965063\n",
      "Iteration 24179, loss = 527.95372717\n",
      "Iteration 24180, loss = 527.89781252\n",
      "Iteration 24181, loss = 527.84190666\n",
      "Iteration 24182, loss = 527.78600959\n",
      "Iteration 24183, loss = 527.73012129\n",
      "Iteration 24184, loss = 527.67424175\n",
      "Iteration 24185, loss = 527.61837093\n",
      "Iteration 24186, loss = 527.56250883\n",
      "Iteration 24187, loss = 527.50665543\n",
      "Iteration 24188, loss = 527.45081072\n",
      "Iteration 24189, loss = 527.39497467\n",
      "Iteration 24190, loss = 527.33914727\n",
      "Iteration 24191, loss = 527.28332851\n",
      "Iteration 24192, loss = 527.22751836\n",
      "Iteration 24193, loss = 527.17171682\n",
      "Iteration 24194, loss = 527.11592385\n",
      "Iteration 24195, loss = 527.06013946\n",
      "Iteration 24196, loss = 527.00436361\n",
      "Iteration 24197, loss = 526.94859629\n",
      "Iteration 24198, loss = 526.89283749\n",
      "Iteration 24199, loss = 526.83708719\n",
      "Iteration 24200, loss = 526.78134537\n",
      "Iteration 24201, loss = 526.72561201\n",
      "Iteration 24202, loss = 526.66988710\n",
      "Iteration 24203, loss = 526.61417062\n",
      "Iteration 24204, loss = 526.55846255\n",
      "Iteration 24205, loss = 526.50276288\n",
      "Iteration 24206, loss = 526.44707158\n",
      "Iteration 24207, loss = 526.39138865\n",
      "Iteration 24208, loss = 526.33571406\n",
      "Iteration 24209, loss = 526.28004779\n",
      "Iteration 24210, loss = 526.22438983\n",
      "Iteration 24211, loss = 526.16874016\n",
      "Iteration 24212, loss = 526.11309877\n",
      "Iteration 24213, loss = 526.05746563\n",
      "Iteration 24214, loss = 526.00184072\n",
      "Iteration 24215, loss = 525.94622404\n",
      "Iteration 24216, loss = 525.89061556\n",
      "Iteration 24217, loss = 525.83501526\n",
      "Iteration 24218, loss = 525.77942314\n",
      "Iteration 24219, loss = 525.72383916\n",
      "Iteration 24220, loss = 525.66826331\n",
      "Iteration 24221, loss = 525.61269557\n",
      "Iteration 24222, loss = 525.55713594\n",
      "Iteration 24223, loss = 525.50158437\n",
      "Iteration 24224, loss = 525.44604087\n",
      "Iteration 24225, loss = 525.39050541\n",
      "Iteration 24226, loss = 525.33497798\n",
      "Iteration 24227, loss = 525.27945854\n",
      "Iteration 24228, loss = 525.22394710\n",
      "Iteration 24229, loss = 525.16844362\n",
      "Iteration 24230, loss = 525.11294810\n",
      "Iteration 24231, loss = 525.05746051\n",
      "Iteration 24232, loss = 525.00198083\n",
      "Iteration 24233, loss = 524.94650905\n",
      "Iteration 24234, loss = 524.89104515\n",
      "Iteration 24235, loss = 524.83558910\n",
      "Iteration 24236, loss = 524.78014090\n",
      "Iteration 24237, loss = 524.72470052\n",
      "Iteration 24238, loss = 524.66926794\n",
      "Iteration 24239, loss = 524.61384315\n",
      "Iteration 24240, loss = 524.55842612\n",
      "Iteration 24241, loss = 524.50301684\n",
      "Iteration 24242, loss = 524.44761529\n",
      "Iteration 24243, loss = 524.39222145\n",
      "Iteration 24244, loss = 524.33683531\n",
      "Iteration 24245, loss = 524.28145683\n",
      "Iteration 24246, loss = 524.22608601\n",
      "Iteration 24247, loss = 524.17072283\n",
      "Iteration 24248, loss = 524.11536726\n",
      "Iteration 24249, loss = 524.06001929\n",
      "Iteration 24250, loss = 524.00467890\n",
      "Iteration 24251, loss = 523.94934607\n",
      "Iteration 24252, loss = 523.89402077\n",
      "Iteration 24253, loss = 523.83870300\n",
      "Iteration 24254, loss = 523.78339273\n",
      "Iteration 24255, loss = 523.72808994\n",
      "Iteration 24256, loss = 523.67279462\n",
      "Iteration 24257, loss = 523.61750674\n",
      "Iteration 24258, loss = 523.56222629\n",
      "Iteration 24259, loss = 523.50695324\n",
      "Iteration 24260, loss = 523.45168757\n",
      "Iteration 24261, loss = 523.39642928\n",
      "Iteration 24262, loss = 523.34117833\n",
      "Iteration 24263, loss = 523.28593471\n",
      "Iteration 24264, loss = 523.23069839\n",
      "Iteration 24265, loss = 523.17546937\n",
      "Iteration 24266, loss = 523.12024761\n",
      "Iteration 24267, loss = 523.06503310\n",
      "Iteration 24268, loss = 523.00982582\n",
      "Iteration 24269, loss = 522.95462576\n",
      "Iteration 24270, loss = 522.89943288\n",
      "Iteration 24271, loss = 522.84424717\n",
      "Iteration 24272, loss = 522.78906861\n",
      "Iteration 24273, loss = 522.73389718\n",
      "Iteration 24274, loss = 522.67873285\n",
      "Iteration 24275, loss = 522.62357562\n",
      "Iteration 24276, loss = 522.56842546\n",
      "Iteration 24277, loss = 522.51328235\n",
      "Iteration 24278, loss = 522.45814627\n",
      "Iteration 24279, loss = 522.40301720\n",
      "Iteration 24280, loss = 522.34789511\n",
      "Iteration 24281, loss = 522.29277999\n",
      "Iteration 24282, loss = 522.23767183\n",
      "Iteration 24283, loss = 522.18257059\n",
      "Iteration 24284, loss = 522.12747625\n",
      "Iteration 24285, loss = 522.07238881\n",
      "Iteration 24286, loss = 522.01730822\n",
      "Iteration 24287, loss = 521.96223449\n",
      "Iteration 24288, loss = 521.90716758\n",
      "Iteration 24289, loss = 521.85210747\n",
      "Iteration 24290, loss = 521.79705415\n",
      "Iteration 24291, loss = 521.74200759\n",
      "Iteration 24292, loss = 521.68696777\n",
      "Iteration 24293, loss = 521.63193467\n",
      "Iteration 24294, loss = 521.57690828\n",
      "Iteration 24295, loss = 521.52188856\n",
      "Iteration 24296, loss = 521.46687550\n",
      "Iteration 24297, loss = 521.41186908\n",
      "Iteration 24298, loss = 521.35686927\n",
      "Iteration 24299, loss = 521.30187605\n",
      "Iteration 24300, loss = 521.24688941\n",
      "Iteration 24301, loss = 521.19190933\n",
      "Iteration 24302, loss = 521.13693577\n",
      "Iteration 24303, loss = 521.08196872\n",
      "Iteration 24304, loss = 521.02700816\n",
      "Iteration 24305, loss = 520.97205407\n",
      "Iteration 24306, loss = 520.91710642\n",
      "Iteration 24307, loss = 520.86216520\n",
      "Iteration 24308, loss = 520.80723037\n",
      "Iteration 24309, loss = 520.75230193\n",
      "Iteration 24310, loss = 520.69737985\n",
      "Iteration 24311, loss = 520.64246410\n",
      "Iteration 24312, loss = 520.58755467\n",
      "Iteration 24313, loss = 520.53265153\n",
      "Iteration 24314, loss = 520.47775466\n",
      "Iteration 24315, loss = 520.42286404\n",
      "Iteration 24316, loss = 520.36797965\n",
      "Iteration 24317, loss = 520.31310146\n",
      "Iteration 24318, loss = 520.25822945\n",
      "Iteration 24319, loss = 520.20336361\n",
      "Iteration 24320, loss = 520.14850390\n",
      "Iteration 24321, loss = 520.09365031\n",
      "Iteration 24322, loss = 520.03880282\n",
      "Iteration 24323, loss = 519.98396139\n",
      "Iteration 24324, loss = 519.92912602\n",
      "Iteration 24325, loss = 519.87429667\n",
      "Iteration 24326, loss = 519.81947332\n",
      "Iteration 24327, loss = 519.76465596\n",
      "Iteration 24328, loss = 519.70984455\n",
      "Iteration 24329, loss = 519.65503908\n",
      "Iteration 24330, loss = 519.60023952\n",
      "Iteration 24331, loss = 519.54544585\n",
      "Iteration 24332, loss = 519.49065805\n",
      "Iteration 24333, loss = 519.43587609\n",
      "Iteration 24334, loss = 519.38109996\n",
      "Iteration 24335, loss = 519.32632962\n",
      "Iteration 24336, loss = 519.27156506\n",
      "Iteration 24337, loss = 519.21680625\n",
      "Iteration 24338, loss = 519.16205316\n",
      "Iteration 24339, loss = 519.10730579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24340, loss = 519.05256409\n",
      "Iteration 24341, loss = 518.99782805\n",
      "Iteration 24342, loss = 518.94309765\n",
      "Iteration 24343, loss = 518.88837286\n",
      "Iteration 24344, loss = 518.83365366\n",
      "Iteration 24345, loss = 518.77894002\n",
      "Iteration 24346, loss = 518.72423192\n",
      "Iteration 24347, loss = 518.66952935\n",
      "Iteration 24348, loss = 518.61483227\n",
      "Iteration 24349, loss = 518.56014067\n",
      "Iteration 24350, loss = 518.50545453\n",
      "Iteration 24351, loss = 518.45077387\n",
      "Iteration 24352, loss = 518.39609870\n",
      "Iteration 24353, loss = 518.34142912\n",
      "Iteration 24354, loss = 518.28676533\n",
      "Iteration 24355, loss = 518.23210783\n",
      "Iteration 24356, loss = 518.17745768\n",
      "Iteration 24357, loss = 518.12281720\n",
      "Iteration 24358, loss = 518.06819105\n",
      "Iteration 24359, loss = 518.01358769\n",
      "Iteration 24360, loss = 517.95901828\n",
      "Iteration 24361, loss = 517.90448263\n",
      "Iteration 24362, loss = 517.84993629\n",
      "Iteration 24363, loss = 517.79528808\n",
      "Iteration 24364, loss = 517.74052514\n",
      "Iteration 24365, loss = 517.68580341\n",
      "Iteration 24366, loss = 517.63124199\n",
      "Iteration 24367, loss = 517.57674258\n",
      "Iteration 24368, loss = 517.52214450\n",
      "Iteration 24369, loss = 517.46745810\n",
      "Iteration 24370, loss = 517.41284161\n",
      "Iteration 24371, loss = 517.35832645\n",
      "Iteration 24372, loss = 517.30378278\n",
      "Iteration 24373, loss = 517.24915916\n",
      "Iteration 24374, loss = 517.19455841\n",
      "Iteration 24375, loss = 517.14003617\n",
      "Iteration 24376, loss = 517.08550899\n",
      "Iteration 24377, loss = 517.03092660\n",
      "Iteration 24378, loss = 516.97635565\n",
      "Iteration 24379, loss = 516.92183972\n",
      "Iteration 24380, loss = 516.86732298\n",
      "Iteration 24381, loss = 516.81277069\n",
      "Iteration 24382, loss = 516.75822856\n",
      "Iteration 24383, loss = 516.70372432\n",
      "Iteration 24384, loss = 516.64921918\n",
      "Iteration 24385, loss = 516.59469208\n",
      "Iteration 24386, loss = 516.54017540\n",
      "Iteration 24387, loss = 516.48568475\n",
      "Iteration 24388, loss = 516.43119306\n",
      "Iteration 24389, loss = 516.37668877\n",
      "Iteration 24390, loss = 516.32219438\n",
      "Iteration 24391, loss = 516.26771810\n",
      "Iteration 24392, loss = 516.21324140\n",
      "Iteration 24393, loss = 516.15875814\n",
      "Iteration 24394, loss = 516.10428373\n",
      "Iteration 24395, loss = 516.04982229\n",
      "Iteration 24396, loss = 515.99536138\n",
      "Iteration 24397, loss = 515.94089779\n",
      "Iteration 24398, loss = 515.88644171\n",
      "Iteration 24399, loss = 515.83199538\n",
      "Iteration 24400, loss = 515.77755059\n",
      "Iteration 24401, loss = 515.72310544\n",
      "Iteration 24402, loss = 515.66866661\n",
      "Iteration 24403, loss = 515.61423550\n",
      "Iteration 24404, loss = 515.55980675\n",
      "Iteration 24405, loss = 515.50537906\n",
      "Iteration 24406, loss = 515.45095668\n",
      "Iteration 24407, loss = 515.39654073\n",
      "Iteration 24408, loss = 515.34212776\n",
      "Iteration 24409, loss = 515.28771669\n",
      "Iteration 24410, loss = 515.23331017\n",
      "Iteration 24411, loss = 515.17890919\n",
      "Iteration 24412, loss = 515.12451159\n",
      "Iteration 24413, loss = 515.07011642\n",
      "Iteration 24414, loss = 515.01572525\n",
      "Iteration 24415, loss = 514.96133895\n",
      "Iteration 24416, loss = 514.90695629\n",
      "Iteration 24417, loss = 514.85257637\n",
      "Iteration 24418, loss = 514.79820007\n",
      "Iteration 24419, loss = 514.74382813\n",
      "Iteration 24420, loss = 514.68945990\n",
      "Iteration 24421, loss = 514.63509465\n",
      "Iteration 24422, loss = 514.58073275\n",
      "Iteration 24423, loss = 514.52637479\n",
      "Iteration 24424, loss = 514.47202052\n",
      "Iteration 24425, loss = 514.41766937\n",
      "Iteration 24426, loss = 514.36332139\n",
      "Iteration 24427, loss = 514.30897701\n",
      "Iteration 24428, loss = 514.25463621\n",
      "Iteration 24429, loss = 514.20029860\n",
      "Iteration 24430, loss = 514.14596406\n",
      "Iteration 24431, loss = 514.09163284\n",
      "Iteration 24432, loss = 514.03730503\n",
      "Iteration 24433, loss = 513.98298040\n",
      "Iteration 24434, loss = 513.92865880\n",
      "Iteration 24435, loss = 513.87434029\n",
      "Iteration 24436, loss = 513.82002500\n",
      "Iteration 24437, loss = 513.76571284\n",
      "Iteration 24438, loss = 513.71140363\n",
      "Iteration 24439, loss = 513.65709737\n",
      "Iteration 24440, loss = 513.60279413\n",
      "Iteration 24441, loss = 513.54849390\n",
      "Iteration 24442, loss = 513.49419657\n",
      "Iteration 24443, loss = 513.43990206\n",
      "Iteration 24444, loss = 513.38561040\n",
      "Iteration 24445, loss = 513.33132159\n",
      "Iteration 24446, loss = 513.27703559\n",
      "Iteration 24447, loss = 513.22275232\n",
      "Iteration 24448, loss = 513.16847173\n",
      "Iteration 24449, loss = 513.11419385\n",
      "Iteration 24450, loss = 513.05991865\n",
      "Iteration 24451, loss = 513.00564607\n",
      "Iteration 24452, loss = 512.95137606\n",
      "Iteration 24453, loss = 512.89710859\n",
      "Iteration 24454, loss = 512.84284366\n",
      "Iteration 24455, loss = 512.78858123\n",
      "Iteration 24456, loss = 512.73432126\n",
      "Iteration 24457, loss = 512.68006369\n",
      "Iteration 24458, loss = 512.62580851\n",
      "Iteration 24459, loss = 512.57155569\n",
      "Iteration 24460, loss = 512.51730520\n",
      "Iteration 24461, loss = 512.46305699\n",
      "Iteration 24462, loss = 512.40881103\n",
      "Iteration 24463, loss = 512.35456728\n",
      "Iteration 24464, loss = 512.30032573\n",
      "Iteration 24465, loss = 512.24608632\n",
      "Iteration 24466, loss = 512.19184903\n",
      "Iteration 24467, loss = 512.13761381\n",
      "Iteration 24468, loss = 512.08338064\n",
      "Iteration 24469, loss = 512.02914948\n",
      "Iteration 24470, loss = 511.97492030\n",
      "Iteration 24471, loss = 511.92069305\n",
      "Iteration 24472, loss = 511.86646770\n",
      "Iteration 24473, loss = 511.81224422\n",
      "Iteration 24474, loss = 511.75802257\n",
      "Iteration 24475, loss = 511.70380272\n",
      "Iteration 24476, loss = 511.64958463\n",
      "Iteration 24477, loss = 511.59536825\n",
      "Iteration 24478, loss = 511.54115357\n",
      "Iteration 24479, loss = 511.48694053\n",
      "Iteration 24480, loss = 511.43272911\n",
      "Iteration 24481, loss = 511.37851926\n",
      "Iteration 24482, loss = 511.32431095\n",
      "Iteration 24483, loss = 511.27010414\n",
      "Iteration 24484, loss = 511.21589880\n",
      "Iteration 24485, loss = 511.16169488\n",
      "Iteration 24486, loss = 511.10749235\n",
      "Iteration 24487, loss = 511.05329117\n",
      "Iteration 24488, loss = 510.99909131\n",
      "Iteration 24489, loss = 510.94489271\n",
      "Iteration 24490, loss = 510.89069536\n",
      "Iteration 24491, loss = 510.83649920\n",
      "Iteration 24492, loss = 510.78230420\n",
      "Iteration 24493, loss = 510.72811032\n",
      "Iteration 24494, loss = 510.67391752\n",
      "Iteration 24495, loss = 510.61972577\n",
      "Iteration 24496, loss = 510.56553501\n",
      "Iteration 24497, loss = 510.51134522\n",
      "Iteration 24498, loss = 510.45715635\n",
      "Iteration 24499, loss = 510.40296836\n",
      "Iteration 24500, loss = 510.34878121\n",
      "Iteration 24501, loss = 510.29459487\n",
      "Iteration 24502, loss = 510.24040929\n",
      "Iteration 24503, loss = 510.18622443\n",
      "Iteration 24504, loss = 510.13204025\n",
      "Iteration 24505, loss = 510.07785671\n",
      "Iteration 24506, loss = 510.02367376\n",
      "Iteration 24507, loss = 509.96949138\n",
      "Iteration 24508, loss = 509.91530950\n",
      "Iteration 24509, loss = 509.86112810\n",
      "Iteration 24510, loss = 509.80694713\n",
      "Iteration 24511, loss = 509.75276655\n",
      "Iteration 24512, loss = 509.69858631\n",
      "Iteration 24513, loss = 509.64440638\n",
      "Iteration 24514, loss = 509.59022671\n",
      "Iteration 24515, loss = 509.53604725\n",
      "Iteration 24516, loss = 509.48186797\n",
      "Iteration 24517, loss = 509.42768882\n",
      "Iteration 24518, loss = 509.37350975\n",
      "Iteration 24519, loss = 509.31933073\n",
      "Iteration 24520, loss = 509.26515171\n",
      "Iteration 24521, loss = 509.21097264\n",
      "Iteration 24522, loss = 509.15679348\n",
      "Iteration 24523, loss = 509.10261418\n",
      "Iteration 24524, loss = 509.04843471\n",
      "Iteration 24525, loss = 508.99425500\n",
      "Iteration 24526, loss = 508.94007503\n",
      "Iteration 24527, loss = 508.88589474\n",
      "Iteration 24528, loss = 508.83171408\n",
      "Iteration 24529, loss = 508.77753302\n",
      "Iteration 24530, loss = 508.72335150\n",
      "Iteration 24531, loss = 508.66916948\n",
      "Iteration 24532, loss = 508.61498691\n",
      "Iteration 24533, loss = 508.56080374\n",
      "Iteration 24534, loss = 508.50661993\n",
      "Iteration 24535, loss = 508.45243542\n",
      "Iteration 24536, loss = 508.39825018\n",
      "Iteration 24537, loss = 508.34406414\n",
      "Iteration 24538, loss = 508.28987727\n",
      "Iteration 24539, loss = 508.23568952\n",
      "Iteration 24540, loss = 508.18150083\n",
      "Iteration 24541, loss = 508.12731115\n",
      "Iteration 24542, loss = 508.07312044\n",
      "Iteration 24543, loss = 508.01892865\n",
      "Iteration 24544, loss = 507.96473573\n",
      "Iteration 24545, loss = 507.91054162\n",
      "Iteration 24546, loss = 507.85634627\n",
      "Iteration 24547, loss = 507.80214964\n",
      "Iteration 24548, loss = 507.74795168\n",
      "Iteration 24549, loss = 507.69375232\n",
      "Iteration 24550, loss = 507.63955153\n",
      "Iteration 24551, loss = 507.58534924\n",
      "Iteration 24552, loss = 507.53114541\n",
      "Iteration 24553, loss = 507.47693998\n",
      "Iteration 24554, loss = 507.42273290\n",
      "Iteration 24555, loss = 507.36852411\n",
      "Iteration 24556, loss = 507.31431357\n",
      "Iteration 24557, loss = 507.26010121\n",
      "Iteration 24558, loss = 507.20588699\n",
      "Iteration 24559, loss = 507.15167085\n",
      "Iteration 24560, loss = 507.09745273\n",
      "Iteration 24561, loss = 507.04323258\n",
      "Iteration 24562, loss = 506.98901034\n",
      "Iteration 24563, loss = 506.93478596\n",
      "Iteration 24564, loss = 506.88055938\n",
      "Iteration 24565, loss = 506.82633055\n",
      "Iteration 24566, loss = 506.77209940\n",
      "Iteration 24567, loss = 506.71786588\n",
      "Iteration 24568, loss = 506.66362994\n",
      "Iteration 24569, loss = 506.60939150\n",
      "Iteration 24570, loss = 506.55515053\n",
      "Iteration 24571, loss = 506.50090695\n",
      "Iteration 24572, loss = 506.44666070\n",
      "Iteration 24573, loss = 506.39241174\n",
      "Iteration 24574, loss = 506.33815999\n",
      "Iteration 24575, loss = 506.28390540\n",
      "Iteration 24576, loss = 506.22964790\n",
      "Iteration 24577, loss = 506.17538744\n",
      "Iteration 24578, loss = 506.12112396\n",
      "Iteration 24579, loss = 506.06685739\n",
      "Iteration 24580, loss = 506.01258766\n",
      "Iteration 24581, loss = 505.95831473\n",
      "Iteration 24582, loss = 505.90403851\n",
      "Iteration 24583, loss = 505.84975896\n",
      "Iteration 24584, loss = 505.79547601\n",
      "Iteration 24585, loss = 505.74118958\n",
      "Iteration 24586, loss = 505.68689962\n",
      "Iteration 24587, loss = 505.63260607\n",
      "Iteration 24588, loss = 505.57830884\n",
      "Iteration 24589, loss = 505.52400789\n",
      "Iteration 24590, loss = 505.46970314\n",
      "Iteration 24591, loss = 505.41539453\n",
      "Iteration 24592, loss = 505.36108198\n",
      "Iteration 24593, loss = 505.30676544\n",
      "Iteration 24594, loss = 505.25244482\n",
      "Iteration 24595, loss = 505.19812007\n",
      "Iteration 24596, loss = 505.14379111\n",
      "Iteration 24597, loss = 505.08945787\n",
      "Iteration 24598, loss = 505.03512028\n",
      "Iteration 24599, loss = 504.98077828\n",
      "Iteration 24600, loss = 504.92643178\n",
      "Iteration 24601, loss = 504.87208073\n",
      "Iteration 24602, loss = 504.81772503\n",
      "Iteration 24603, loss = 504.76336463\n",
      "Iteration 24604, loss = 504.70899944\n",
      "Iteration 24605, loss = 504.65462940\n",
      "Iteration 24606, loss = 504.60025443\n",
      "Iteration 24607, loss = 504.54587445\n",
      "Iteration 24608, loss = 504.49148939\n",
      "Iteration 24609, loss = 504.43709917\n",
      "Iteration 24610, loss = 504.38270372\n",
      "Iteration 24611, loss = 504.32830295\n",
      "Iteration 24612, loss = 504.27389678\n",
      "Iteration 24613, loss = 504.21948515\n",
      "Iteration 24614, loss = 504.16506797\n",
      "Iteration 24615, loss = 504.11064515\n",
      "Iteration 24616, loss = 504.05621663\n",
      "Iteration 24617, loss = 504.00178231\n",
      "Iteration 24618, loss = 503.94734212\n",
      "Iteration 24619, loss = 503.89289597\n",
      "Iteration 24620, loss = 503.83844378\n",
      "Iteration 24621, loss = 503.78398547\n",
      "Iteration 24622, loss = 503.72952095\n",
      "Iteration 24623, loss = 503.67505013\n",
      "Iteration 24624, loss = 503.62057293\n",
      "Iteration 24625, loss = 503.56608927\n",
      "Iteration 24626, loss = 503.51159905\n",
      "Iteration 24627, loss = 503.45710219\n",
      "Iteration 24628, loss = 503.40259860\n",
      "Iteration 24629, loss = 503.34808819\n",
      "Iteration 24630, loss = 503.29357087\n",
      "Iteration 24631, loss = 503.23904656\n",
      "Iteration 24632, loss = 503.18451515\n",
      "Iteration 24633, loss = 503.12997658\n",
      "Iteration 24634, loss = 503.07543075\n",
      "Iteration 24635, loss = 503.02087760\n",
      "Iteration 24636, loss = 502.96631706\n",
      "Iteration 24637, loss = 502.91174913\n",
      "Iteration 24638, loss = 502.85717386\n",
      "Iteration 24639, loss = 502.80259142\n",
      "Iteration 24640, loss = 502.74800224\n",
      "Iteration 24641, loss = 502.69340720\n",
      "Iteration 24642, loss = 502.63880796\n",
      "Iteration 24643, loss = 502.58420754\n",
      "Iteration 24644, loss = 502.52961045\n",
      "Iteration 24645, loss = 502.47502192\n",
      "Iteration 24646, loss = 502.42044143\n",
      "Iteration 24647, loss = 502.36585025\n",
      "Iteration 24648, loss = 502.31120256\n",
      "Iteration 24649, loss = 502.25646364\n",
      "Iteration 24650, loss = 502.20167775\n",
      "Iteration 24651, loss = 502.14694292\n",
      "Iteration 24652, loss = 502.09229018\n",
      "Iteration 24653, loss = 502.03764974\n",
      "Iteration 24654, loss = 501.98293795\n",
      "Iteration 24655, loss = 501.92815526\n",
      "Iteration 24656, loss = 501.87338198\n",
      "Iteration 24657, loss = 501.81866298\n",
      "Iteration 24658, loss = 501.76395129\n",
      "Iteration 24659, loss = 501.70918529\n",
      "Iteration 24660, loss = 501.65437526\n",
      "Iteration 24661, loss = 501.59957875\n",
      "Iteration 24662, loss = 501.54480985\n",
      "Iteration 24663, loss = 501.49002590\n",
      "Iteration 24664, loss = 501.43519890\n",
      "Iteration 24665, loss = 501.38035410\n",
      "Iteration 24666, loss = 501.32552320\n",
      "Iteration 24667, loss = 501.27069555\n",
      "Iteration 24668, loss = 501.21584156\n",
      "Iteration 24669, loss = 501.16096027\n",
      "Iteration 24670, loss = 501.10607550\n",
      "Iteration 24671, loss = 501.05119501\n",
      "Iteration 24672, loss = 500.99630149\n",
      "Iteration 24673, loss = 500.94138325\n",
      "Iteration 24674, loss = 500.88645068\n",
      "Iteration 24675, loss = 500.83151618\n",
      "Iteration 24676, loss = 500.77657464\n",
      "Iteration 24677, loss = 500.72161436\n",
      "Iteration 24678, loss = 500.66663576\n",
      "Iteration 24679, loss = 500.61164828\n",
      "Iteration 24680, loss = 500.55665409\n",
      "Iteration 24681, loss = 500.50164601\n",
      "Iteration 24682, loss = 500.44661988\n",
      "Iteration 24683, loss = 500.39158005\n",
      "Iteration 24684, loss = 500.33653094\n",
      "Iteration 24685, loss = 500.28147020\n",
      "Iteration 24686, loss = 500.22639326\n",
      "Iteration 24687, loss = 500.17130038\n",
      "Iteration 24688, loss = 500.11619508\n",
      "Iteration 24689, loss = 500.06107805\n",
      "Iteration 24690, loss = 500.00594641\n",
      "Iteration 24691, loss = 499.95079845\n",
      "Iteration 24692, loss = 499.89563566\n",
      "Iteration 24693, loss = 499.84045968\n",
      "Iteration 24694, loss = 499.78526962\n",
      "Iteration 24695, loss = 499.73006360\n",
      "Iteration 24696, loss = 499.67484144\n",
      "Iteration 24697, loss = 499.61960432\n",
      "Iteration 24698, loss = 499.56435258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24699, loss = 499.50908510\n",
      "Iteration 24700, loss = 499.45380096\n",
      "Iteration 24701, loss = 499.39850046\n",
      "Iteration 24702, loss = 499.34318418\n",
      "Iteration 24703, loss = 499.28785184\n",
      "Iteration 24704, loss = 499.23250259\n",
      "Iteration 24705, loss = 499.17713607\n",
      "Iteration 24706, loss = 499.12175252\n",
      "Iteration 24707, loss = 499.06635209\n",
      "Iteration 24708, loss = 499.01093434\n",
      "Iteration 24709, loss = 498.95549870\n",
      "Iteration 24710, loss = 498.90004501\n",
      "Iteration 24711, loss = 498.84457337\n",
      "Iteration 24712, loss = 498.78908367\n",
      "Iteration 24713, loss = 498.73357549\n",
      "Iteration 24714, loss = 498.67804844\n",
      "Iteration 24715, loss = 498.62250241\n",
      "Iteration 24716, loss = 498.56693734\n",
      "Iteration 24717, loss = 498.51135302\n",
      "Iteration 24718, loss = 498.45574908\n",
      "Iteration 24719, loss = 498.40012521\n",
      "Iteration 24720, loss = 498.34448129\n",
      "Iteration 24721, loss = 498.28881715\n",
      "Iteration 24722, loss = 498.23313254\n",
      "Iteration 24723, loss = 498.17742713\n",
      "Iteration 24724, loss = 498.12170065\n",
      "Iteration 24725, loss = 498.06595292\n",
      "Iteration 24726, loss = 498.01018373\n",
      "Iteration 24727, loss = 497.95439278\n",
      "Iteration 24728, loss = 497.89857979\n",
      "Iteration 24729, loss = 497.84274448\n",
      "Iteration 24730, loss = 497.78688663\n",
      "Iteration 24731, loss = 497.73100598\n",
      "Iteration 24732, loss = 497.67510224\n",
      "Iteration 24733, loss = 497.61917511\n",
      "Iteration 24734, loss = 497.56322431\n",
      "Iteration 24735, loss = 497.50724958\n",
      "Iteration 24736, loss = 497.45125063\n",
      "Iteration 24737, loss = 497.39522717\n",
      "Iteration 24738, loss = 497.33917887\n",
      "Iteration 24739, loss = 497.28310544\n",
      "Iteration 24740, loss = 497.22700658\n",
      "Iteration 24741, loss = 497.17088199\n",
      "Iteration 24742, loss = 497.11473135\n",
      "Iteration 24743, loss = 497.05855432\n",
      "Iteration 24744, loss = 497.00235059\n",
      "Iteration 24745, loss = 496.94611982\n",
      "Iteration 24746, loss = 496.88986169\n",
      "Iteration 24747, loss = 496.83357586\n",
      "Iteration 24748, loss = 496.77726196\n",
      "Iteration 24749, loss = 496.72091966\n",
      "Iteration 24750, loss = 496.66454859\n",
      "Iteration 24751, loss = 496.60814841\n",
      "Iteration 24752, loss = 496.55171873\n",
      "Iteration 24753, loss = 496.49525918\n",
      "Iteration 24754, loss = 496.43876939\n",
      "Iteration 24755, loss = 496.38224897\n",
      "Iteration 24756, loss = 496.32569753\n",
      "Iteration 24757, loss = 496.26911467\n",
      "Iteration 24758, loss = 496.21249998\n",
      "Iteration 24759, loss = 496.15585305\n",
      "Iteration 24760, loss = 496.09917347\n",
      "Iteration 24761, loss = 496.04246081\n",
      "Iteration 24762, loss = 495.98571464\n",
      "Iteration 24763, loss = 495.92893452\n",
      "Iteration 24764, loss = 495.87212000\n",
      "Iteration 24765, loss = 495.81527063\n",
      "Iteration 24766, loss = 495.75838594\n",
      "Iteration 24767, loss = 495.70146548\n",
      "Iteration 24768, loss = 495.64450874\n",
      "Iteration 24769, loss = 495.58751526\n",
      "Iteration 24770, loss = 495.53048454\n",
      "Iteration 24771, loss = 495.47341607\n",
      "Iteration 24772, loss = 495.41630934\n",
      "Iteration 24773, loss = 495.35916382\n",
      "Iteration 24774, loss = 495.30197900\n",
      "Iteration 24775, loss = 495.24475431\n",
      "Iteration 24776, loss = 495.18748923\n",
      "Iteration 24777, loss = 495.13018318\n",
      "Iteration 24778, loss = 495.07283559\n",
      "Iteration 24779, loss = 495.01544589\n",
      "Iteration 24780, loss = 494.95801347\n",
      "Iteration 24781, loss = 494.90053775\n",
      "Iteration 24782, loss = 494.84301809\n",
      "Iteration 24783, loss = 494.78545388\n",
      "Iteration 24784, loss = 494.72784448\n",
      "Iteration 24785, loss = 494.67018923\n",
      "Iteration 24786, loss = 494.61248747\n",
      "Iteration 24787, loss = 494.55473853\n",
      "Iteration 24788, loss = 494.49694172\n",
      "Iteration 24789, loss = 494.43909633\n",
      "Iteration 24790, loss = 494.38120165\n",
      "Iteration 24791, loss = 494.32325694\n",
      "Iteration 24792, loss = 494.26526146\n",
      "Iteration 24793, loss = 494.20721445\n",
      "Iteration 24794, loss = 494.14911513\n",
      "Iteration 24795, loss = 494.09096271\n",
      "Iteration 24796, loss = 494.03275638\n",
      "Iteration 24797, loss = 493.97449531\n",
      "Iteration 24798, loss = 493.91617865\n",
      "Iteration 24799, loss = 493.85780556\n",
      "Iteration 24800, loss = 493.79937515\n",
      "Iteration 24801, loss = 493.74088652\n",
      "Iteration 24802, loss = 493.68233876\n",
      "Iteration 24803, loss = 493.62373092\n",
      "Iteration 24804, loss = 493.56506205\n",
      "Iteration 24805, loss = 493.50633118\n",
      "Iteration 24806, loss = 493.44753729\n",
      "Iteration 24807, loss = 493.38867938\n",
      "Iteration 24808, loss = 493.32975639\n",
      "Iteration 24809, loss = 493.27076725\n",
      "Iteration 24810, loss = 493.21171087\n",
      "Iteration 24811, loss = 493.15258614\n",
      "Iteration 24812, loss = 493.09339190\n",
      "Iteration 24813, loss = 493.03412700\n",
      "Iteration 24814, loss = 492.97479022\n",
      "Iteration 24815, loss = 492.91538036\n",
      "Iteration 24816, loss = 492.85589614\n",
      "Iteration 24817, loss = 492.79633628\n",
      "Iteration 24818, loss = 492.73669948\n",
      "Iteration 24819, loss = 492.67698438\n",
      "Iteration 24820, loss = 492.61718960\n",
      "Iteration 24821, loss = 492.55731373\n",
      "Iteration 24822, loss = 492.49735532\n",
      "Iteration 24823, loss = 492.43731287\n",
      "Iteration 24824, loss = 492.37718488\n",
      "Iteration 24825, loss = 492.31696978\n",
      "Iteration 24826, loss = 492.25666597\n",
      "Iteration 24827, loss = 492.19627180\n",
      "Iteration 24828, loss = 492.13578559\n",
      "Iteration 24829, loss = 492.07520562\n",
      "Iteration 24830, loss = 492.01453010\n",
      "Iteration 24831, loss = 491.95375723\n",
      "Iteration 24832, loss = 491.89288512\n",
      "Iteration 24833, loss = 491.83191187\n",
      "Iteration 24834, loss = 491.77083550\n",
      "Iteration 24835, loss = 491.70965399\n",
      "Iteration 24836, loss = 491.64836525\n",
      "Iteration 24837, loss = 491.58696714\n",
      "Iteration 24838, loss = 491.52545748\n",
      "Iteration 24839, loss = 491.46383401\n",
      "Iteration 24840, loss = 491.40209439\n",
      "Iteration 24841, loss = 491.34023624\n",
      "Iteration 24842, loss = 491.27825710\n",
      "Iteration 24843, loss = 491.21615444\n",
      "Iteration 24844, loss = 491.15392567\n",
      "Iteration 24845, loss = 491.09156809\n",
      "Iteration 24846, loss = 491.02907896\n",
      "Iteration 24847, loss = 490.96645542\n",
      "Iteration 24848, loss = 490.90369455\n",
      "Iteration 24849, loss = 490.84079334\n",
      "Iteration 24850, loss = 490.77774867\n",
      "Iteration 24851, loss = 490.71455735\n",
      "Iteration 24852, loss = 490.65121605\n",
      "Iteration 24853, loss = 490.58772139\n",
      "Iteration 24854, loss = 490.52406983\n",
      "Iteration 24855, loss = 490.46025775\n",
      "Iteration 24856, loss = 490.39628141\n",
      "Iteration 24857, loss = 490.33213693\n",
      "Iteration 24858, loss = 490.26782032\n",
      "Iteration 24859, loss = 490.20332746\n",
      "Iteration 24860, loss = 490.13865407\n",
      "Iteration 24861, loss = 490.07379576\n",
      "Iteration 24862, loss = 490.00874796\n",
      "Iteration 24863, loss = 489.94350596\n",
      "Iteration 24864, loss = 489.87806489\n",
      "Iteration 24865, loss = 489.81241970\n",
      "Iteration 24866, loss = 489.74656517\n",
      "Iteration 24867, loss = 489.68049589\n",
      "Iteration 24868, loss = 489.61420626\n",
      "Iteration 24869, loss = 489.54769048\n",
      "Iteration 24870, loss = 489.48094253\n",
      "Iteration 24871, loss = 489.41395619\n",
      "Iteration 24872, loss = 489.34672498\n",
      "Iteration 24873, loss = 489.27924219\n",
      "Iteration 24874, loss = 489.21150088\n",
      "Iteration 24875, loss = 489.14349380\n",
      "Iteration 24876, loss = 489.07521347\n",
      "Iteration 24877, loss = 489.00665208\n",
      "Iteration 24878, loss = 488.93780153\n",
      "Iteration 24879, loss = 488.86865341\n",
      "Iteration 24880, loss = 488.79919895\n",
      "Iteration 24881, loss = 488.72942906\n",
      "Iteration 24882, loss = 488.65933424\n",
      "Iteration 24883, loss = 488.58890463\n",
      "Iteration 24884, loss = 488.51812995\n",
      "Iteration 24885, loss = 488.44699948\n",
      "Iteration 24886, loss = 488.37550207\n",
      "Iteration 24887, loss = 488.30362607\n",
      "Iteration 24888, loss = 488.23135934\n",
      "Iteration 24889, loss = 488.15868919\n",
      "Iteration 24890, loss = 488.08560240\n",
      "Iteration 24891, loss = 488.01208515\n",
      "Iteration 24892, loss = 487.93812298\n",
      "Iteration 24893, loss = 487.86370078\n",
      "Iteration 24894, loss = 487.78880277\n",
      "Iteration 24895, loss = 487.71341241\n",
      "Iteration 24896, loss = 487.63751239\n",
      "Iteration 24897, loss = 487.56108456\n",
      "Iteration 24898, loss = 487.48410994\n",
      "Iteration 24899, loss = 487.40656859\n",
      "Iteration 24900, loss = 487.32843961\n",
      "Iteration 24901, loss = 487.24970104\n",
      "Iteration 24902, loss = 487.17032986\n",
      "Iteration 24903, loss = 487.09030183\n",
      "Iteration 24904, loss = 487.00959150\n",
      "Iteration 24905, loss = 486.92817208\n",
      "Iteration 24906, loss = 486.84601538\n",
      "Iteration 24907, loss = 486.76309170\n",
      "Iteration 24908, loss = 486.67936975\n",
      "Iteration 24909, loss = 486.59481653\n",
      "Iteration 24910, loss = 486.50939722\n",
      "Iteration 24911, loss = 486.42307507\n",
      "Iteration 24912, loss = 486.33581123\n",
      "Iteration 24913, loss = 486.24756467\n",
      "Iteration 24914, loss = 486.15829195\n",
      "Iteration 24915, loss = 486.06794712\n",
      "Iteration 24916, loss = 485.97648148\n",
      "Iteration 24917, loss = 485.88384346\n",
      "Iteration 24918, loss = 485.78997835\n",
      "Iteration 24919, loss = 485.69482808\n",
      "Iteration 24920, loss = 485.59833104\n",
      "Iteration 24921, loss = 485.50042175\n",
      "Iteration 24922, loss = 485.40103062\n",
      "Iteration 24923, loss = 485.30008367\n",
      "Iteration 24924, loss = 485.19750219\n",
      "Iteration 24925, loss = 485.09320245\n",
      "Iteration 24926, loss = 484.98709532\n",
      "Iteration 24927, loss = 484.87908598\n",
      "Iteration 24928, loss = 484.76907352\n",
      "Iteration 24929, loss = 484.65695063\n",
      "Iteration 24930, loss = 484.54260325\n",
      "Iteration 24931, loss = 484.42591033\n",
      "Iteration 24932, loss = 484.30674357\n",
      "Iteration 24933, loss = 484.18496732\n",
      "Iteration 24934, loss = 484.06043858\n",
      "Iteration 24935, loss = 483.93300727\n",
      "Iteration 24936, loss = 483.80251672\n",
      "Iteration 24937, loss = 483.66880454\n",
      "Iteration 24938, loss = 483.53170404\n",
      "Iteration 24939, loss = 483.39104622\n",
      "Iteration 24940, loss = 483.24666254\n",
      "Iteration 24941, loss = 483.09838863\n",
      "Iteration 24942, loss = 482.94606891\n",
      "Iteration 24943, loss = 482.78956235\n",
      "Iteration 24944, loss = 482.62874910\n",
      "Iteration 24945, loss = 482.46353778\n",
      "Iteration 24946, loss = 482.29387315\n",
      "Iteration 24947, loss = 482.11974321\n",
      "Iteration 24948, loss = 481.94118514\n",
      "Iteration 24949, loss = 481.75828917\n",
      "Iteration 24950, loss = 481.57119942\n",
      "Iteration 24951, loss = 481.38011132\n",
      "Iteration 24952, loss = 481.18526533\n",
      "Iteration 24953, loss = 480.98693730\n",
      "Iteration 24954, loss = 480.78542653\n",
      "Iteration 24955, loss = 480.58104298\n",
      "Iteration 24956, loss = 480.37409549\n",
      "Iteration 24957, loss = 480.16488301\n",
      "Iteration 24958, loss = 479.95368971\n",
      "Iteration 24959, loss = 479.74078431\n",
      "Iteration 24960, loss = 479.52642179\n",
      "Iteration 24961, loss = 479.31084571\n",
      "Iteration 24962, loss = 479.09428866\n",
      "Iteration 24963, loss = 478.87697049\n",
      "Iteration 24964, loss = 478.65909466\n",
      "Iteration 24965, loss = 478.44084489\n",
      "Iteration 24966, loss = 478.22238364\n",
      "Iteration 24967, loss = 478.00385333\n",
      "Iteration 24968, loss = 477.78537965\n",
      "Iteration 24969, loss = 477.56707544\n",
      "Iteration 24970, loss = 477.34904346\n",
      "Iteration 24971, loss = 477.13137739\n",
      "Iteration 24972, loss = 476.91416130\n",
      "Iteration 24973, loss = 476.69746866\n",
      "Iteration 24974, loss = 476.48136226\n",
      "Iteration 24975, loss = 476.26589525\n",
      "Iteration 24976, loss = 476.05111333\n",
      "Iteration 24977, loss = 475.83705689\n",
      "Iteration 24978, loss = 475.62376237\n",
      "Iteration 24979, loss = 475.41126242\n",
      "Iteration 24980, loss = 475.19958523\n",
      "Iteration 24981, loss = 474.98875387\n",
      "Iteration 24982, loss = 474.77878627\n",
      "Iteration 24983, loss = 474.56969604\n",
      "Iteration 24984, loss = 474.36149369\n",
      "Iteration 24985, loss = 474.15418765\n",
      "Iteration 24986, loss = 473.94778475\n",
      "Iteration 24987, loss = 473.74228995\n",
      "Iteration 24988, loss = 473.53770602\n",
      "Iteration 24989, loss = 473.33403337\n",
      "Iteration 24990, loss = 473.13127042\n",
      "Iteration 24991, loss = 472.92941419\n",
      "Iteration 24992, loss = 472.72846094\n",
      "Iteration 24993, loss = 472.52840643\n",
      "Iteration 24994, loss = 472.32924584\n",
      "Iteration 24995, loss = 472.13097345\n",
      "Iteration 24996, loss = 471.93358255\n",
      "Iteration 24997, loss = 471.73706550\n",
      "Iteration 24998, loss = 471.54141411\n",
      "Iteration 24999, loss = 471.34661990\n",
      "Iteration 25000, loss = 471.15267428\n",
      "Iteration 25001, loss = 470.95956853\n",
      "Iteration 25002, loss = 470.76729359\n",
      "Iteration 25003, loss = 470.57584004\n",
      "Iteration 25004, loss = 470.38519816\n",
      "Iteration 25005, loss = 470.19535811\n",
      "Iteration 25006, loss = 470.00631012\n",
      "Iteration 25007, loss = 469.81804450\n",
      "Iteration 25008, loss = 469.63055162\n",
      "Iteration 25009, loss = 469.44382180\n",
      "Iteration 25010, loss = 469.25784529\n",
      "Iteration 25011, loss = 469.07261229\n",
      "Iteration 25012, loss = 468.88811310\n",
      "Iteration 25013, loss = 468.70433813\n",
      "Iteration 25014, loss = 468.52127795\n",
      "Iteration 25015, loss = 468.33892324\n",
      "Iteration 25016, loss = 468.15726472\n",
      "Iteration 25017, loss = 467.97629318\n",
      "Iteration 25018, loss = 467.79599952\n",
      "Iteration 25019, loss = 467.61637476\n",
      "Iteration 25020, loss = 467.43741012\n",
      "Iteration 25021, loss = 467.25909697\n",
      "Iteration 25022, loss = 467.08142681\n",
      "Iteration 25023, loss = 466.90439123\n",
      "Iteration 25024, loss = 466.72798195\n",
      "Iteration 25025, loss = 466.55219081\n",
      "Iteration 25026, loss = 466.37700983\n",
      "Iteration 25027, loss = 466.20243118\n",
      "Iteration 25028, loss = 466.02844716\n",
      "Iteration 25029, loss = 465.85505020\n",
      "Iteration 25030, loss = 465.68223284\n",
      "Iteration 25031, loss = 465.50998779\n",
      "Iteration 25032, loss = 465.33830785\n",
      "Iteration 25033, loss = 465.16718600\n",
      "Iteration 25034, loss = 464.99661535\n",
      "Iteration 25035, loss = 464.82658913\n",
      "Iteration 25036, loss = 464.65710070\n",
      "Iteration 25037, loss = 464.48814353\n",
      "Iteration 25038, loss = 464.31971120\n",
      "Iteration 25039, loss = 464.15179746\n",
      "Iteration 25040, loss = 463.98439614\n",
      "Iteration 25041, loss = 463.81750121\n",
      "Iteration 25042, loss = 463.65110675\n",
      "Iteration 25043, loss = 463.48520693\n",
      "Iteration 25044, loss = 463.31979604\n",
      "Iteration 25045, loss = 463.15486850\n",
      "Iteration 25046, loss = 462.99041882\n",
      "Iteration 25047, loss = 462.82644161\n",
      "Iteration 25048, loss = 462.66293159\n",
      "Iteration 25049, loss = 462.49988357\n",
      "Iteration 25050, loss = 462.33729246\n",
      "Iteration 25051, loss = 462.17515328\n",
      "Iteration 25052, loss = 462.01346111\n",
      "Iteration 25053, loss = 461.85221117\n",
      "Iteration 25054, loss = 461.69139871\n",
      "Iteration 25055, loss = 461.53101911\n",
      "Iteration 25056, loss = 461.37106782\n",
      "Iteration 25057, loss = 461.21154038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25058, loss = 461.05243239\n",
      "Iteration 25059, loss = 460.89373956\n",
      "Iteration 25060, loss = 460.73545765\n",
      "Iteration 25061, loss = 460.57758252\n",
      "Iteration 25062, loss = 460.42011008\n",
      "Iteration 25063, loss = 460.26303633\n",
      "Iteration 25064, loss = 460.10635734\n",
      "Iteration 25065, loss = 459.95006923\n",
      "Iteration 25066, loss = 459.79416821\n",
      "Iteration 25067, loss = 459.63865055\n",
      "Iteration 25068, loss = 459.48351257\n",
      "Iteration 25069, loss = 459.32875067\n",
      "Iteration 25070, loss = 459.17436131\n",
      "Iteration 25071, loss = 459.02034100\n",
      "Iteration 25072, loss = 458.86668633\n",
      "Iteration 25073, loss = 458.71339391\n",
      "Iteration 25074, loss = 458.56046043\n",
      "Iteration 25075, loss = 458.40788265\n",
      "Iteration 25076, loss = 458.25565736\n",
      "Iteration 25077, loss = 458.10378141\n",
      "Iteration 25078, loss = 457.95225169\n",
      "Iteration 25079, loss = 457.80106517\n",
      "Iteration 25080, loss = 457.65021883\n",
      "Iteration 25081, loss = 457.49970974\n",
      "Iteration 25082, loss = 457.34953497\n",
      "Iteration 25083, loss = 457.19969168\n",
      "Iteration 25084, loss = 457.05017705\n",
      "Iteration 25085, loss = 456.90098831\n",
      "Iteration 25086, loss = 456.75212273\n",
      "Iteration 25087, loss = 456.60357763\n",
      "Iteration 25088, loss = 456.45535037\n",
      "Iteration 25089, loss = 456.30743833\n",
      "Iteration 25090, loss = 456.15983896\n",
      "Iteration 25091, loss = 456.01254974\n",
      "Iteration 25092, loss = 455.86556817\n",
      "Iteration 25093, loss = 455.71889180\n",
      "Iteration 25094, loss = 455.57251822\n",
      "Iteration 25095, loss = 455.42644505\n",
      "Iteration 25096, loss = 455.28066995\n",
      "Iteration 25097, loss = 455.13519061\n",
      "Iteration 25098, loss = 454.99000475\n",
      "Iteration 25099, loss = 454.84511013\n",
      "Iteration 25100, loss = 454.70050453\n",
      "Iteration 25101, loss = 454.55618578\n",
      "Iteration 25102, loss = 454.41215172\n",
      "Iteration 25103, loss = 454.26840025\n",
      "Iteration 25104, loss = 454.12492926\n",
      "Iteration 25105, loss = 453.98173669\n",
      "Iteration 25106, loss = 453.83882052\n",
      "Iteration 25107, loss = 453.69617875\n",
      "Iteration 25108, loss = 453.55380938\n",
      "Iteration 25109, loss = 453.41171048\n",
      "Iteration 25110, loss = 453.26988012\n",
      "Iteration 25111, loss = 453.12831639\n",
      "Iteration 25112, loss = 452.98701744\n",
      "Iteration 25113, loss = 452.84598140\n",
      "Iteration 25114, loss = 452.70520645\n",
      "Iteration 25115, loss = 452.56469081\n",
      "Iteration 25116, loss = 452.42443268\n",
      "Iteration 25117, loss = 452.28443031\n",
      "Iteration 25118, loss = 452.14468198\n",
      "Iteration 25119, loss = 452.00518597\n",
      "Iteration 25120, loss = 451.86594060\n",
      "Iteration 25121, loss = 451.72694420\n",
      "Iteration 25122, loss = 451.58819513\n",
      "Iteration 25123, loss = 451.44969176\n",
      "Iteration 25124, loss = 451.31143248\n",
      "Iteration 25125, loss = 451.17341572\n",
      "Iteration 25126, loss = 451.03563991\n",
      "Iteration 25127, loss = 450.89810350\n",
      "Iteration 25128, loss = 450.76080497\n",
      "Iteration 25129, loss = 450.62374280\n",
      "Iteration 25130, loss = 450.48691551\n",
      "Iteration 25131, loss = 450.35032163\n",
      "Iteration 25132, loss = 450.21395969\n",
      "Iteration 25133, loss = 450.07782827\n",
      "Iteration 25134, loss = 449.94192593\n",
      "Iteration 25135, loss = 449.80625129\n",
      "Iteration 25136, loss = 449.67080294\n",
      "Iteration 25137, loss = 449.53557952\n",
      "Iteration 25138, loss = 449.40057967\n",
      "Iteration 25139, loss = 449.26580206\n",
      "Iteration 25140, loss = 449.13124535\n",
      "Iteration 25141, loss = 448.99690823\n",
      "Iteration 25142, loss = 448.86278942\n",
      "Iteration 25143, loss = 448.72888762\n",
      "Iteration 25144, loss = 448.59520158\n",
      "Iteration 25145, loss = 448.46173004\n",
      "Iteration 25146, loss = 448.32847177\n",
      "Iteration 25147, loss = 448.19542553\n",
      "Iteration 25148, loss = 448.06259011\n",
      "Iteration 25149, loss = 447.92996433\n",
      "Iteration 25150, loss = 447.79754699\n",
      "Iteration 25151, loss = 447.66533692\n",
      "Iteration 25152, loss = 447.53333296\n",
      "Iteration 25153, loss = 447.40153396\n",
      "Iteration 25154, loss = 447.26993879\n",
      "Iteration 25155, loss = 447.13854633\n",
      "Iteration 25156, loss = 447.00735546\n",
      "Iteration 25157, loss = 446.87636508\n",
      "Iteration 25158, loss = 446.74557410\n",
      "Iteration 25159, loss = 446.61498145\n",
      "Iteration 25160, loss = 446.48458606\n",
      "Iteration 25161, loss = 446.35438688\n",
      "Iteration 25162, loss = 446.22438286\n",
      "Iteration 25163, loss = 446.09457296\n",
      "Iteration 25164, loss = 445.96495617\n",
      "Iteration 25165, loss = 445.83553148\n",
      "Iteration 25166, loss = 445.70629786\n",
      "Iteration 25167, loss = 445.57725435\n",
      "Iteration 25168, loss = 445.44839995\n",
      "Iteration 25169, loss = 445.31973368\n",
      "Iteration 25170, loss = 445.19125459\n",
      "Iteration 25171, loss = 445.06296172\n",
      "Iteration 25172, loss = 444.93485413\n",
      "Iteration 25173, loss = 444.80693087\n",
      "Iteration 25174, loss = 444.67919103\n",
      "Iteration 25175, loss = 444.55163369\n",
      "Iteration 25176, loss = 444.42425793\n",
      "Iteration 25177, loss = 444.29706285\n",
      "Iteration 25178, loss = 444.17004757\n",
      "Iteration 25179, loss = 444.04321119\n",
      "Iteration 25180, loss = 443.91655285\n",
      "Iteration 25181, loss = 443.79007168\n",
      "Iteration 25182, loss = 443.66376681\n",
      "Iteration 25183, loss = 443.53763741\n",
      "Iteration 25184, loss = 443.41168261\n",
      "Iteration 25185, loss = 443.28590159\n",
      "Iteration 25186, loss = 443.16029352\n",
      "Iteration 25187, loss = 443.03485758\n",
      "Iteration 25188, loss = 442.90959296\n",
      "Iteration 25189, loss = 442.78449885\n",
      "Iteration 25190, loss = 442.65957445\n",
      "Iteration 25191, loss = 442.53481897\n",
      "Iteration 25192, loss = 442.41023163\n",
      "Iteration 25193, loss = 442.28581165\n",
      "Iteration 25194, loss = 442.16155825\n",
      "Iteration 25195, loss = 442.03747069\n",
      "Iteration 25196, loss = 441.91354819\n",
      "Iteration 25197, loss = 441.78979001\n",
      "Iteration 25198, loss = 441.66619540\n",
      "Iteration 25199, loss = 441.54276363\n",
      "Iteration 25200, loss = 441.41949396\n",
      "Iteration 25201, loss = 441.29638568\n",
      "Iteration 25202, loss = 441.17343806\n",
      "Iteration 25203, loss = 441.05065038\n",
      "Iteration 25204, loss = 440.92802195\n",
      "Iteration 25205, loss = 440.80555207\n",
      "Iteration 25206, loss = 440.68324003\n",
      "Iteration 25207, loss = 440.56108515\n",
      "Iteration 25208, loss = 440.43908674\n",
      "Iteration 25209, loss = 440.31724414\n",
      "Iteration 25210, loss = 440.19555666\n",
      "Iteration 25211, loss = 440.07402364\n",
      "Iteration 25212, loss = 439.95264441\n",
      "Iteration 25213, loss = 439.83141834\n",
      "Iteration 25214, loss = 439.71034475\n",
      "Iteration 25215, loss = 439.58942301\n",
      "Iteration 25216, loss = 439.46865248\n",
      "Iteration 25217, loss = 439.34803253\n",
      "Iteration 25218, loss = 439.22756252\n",
      "Iteration 25219, loss = 439.10724183\n",
      "Iteration 25220, loss = 438.98706983\n",
      "Iteration 25221, loss = 438.86704593\n",
      "Iteration 25222, loss = 438.74716950\n",
      "Iteration 25223, loss = 438.62743994\n",
      "Iteration 25224, loss = 438.50785665\n",
      "Iteration 25225, loss = 438.38841903\n",
      "Iteration 25226, loss = 438.26912650\n",
      "Iteration 25227, loss = 438.14997846\n",
      "Iteration 25228, loss = 438.03097434\n",
      "Iteration 25229, loss = 437.91211355\n",
      "Iteration 25230, loss = 437.79339553\n",
      "Iteration 25231, loss = 437.67481970\n",
      "Iteration 25232, loss = 437.55638551\n",
      "Iteration 25233, loss = 437.43809238\n",
      "Iteration 25234, loss = 437.31993977\n",
      "Iteration 25235, loss = 437.20192712\n",
      "Iteration 25236, loss = 437.08405389\n",
      "Iteration 25237, loss = 436.96631953\n",
      "Iteration 25238, loss = 436.84872350\n",
      "Iteration 25239, loss = 436.73126526\n",
      "Iteration 25240, loss = 436.61394429\n",
      "Iteration 25241, loss = 436.49676006\n",
      "Iteration 25242, loss = 436.37971203\n",
      "Iteration 25243, loss = 436.26279970\n",
      "Iteration 25244, loss = 436.14602255\n",
      "Iteration 25245, loss = 436.02938006\n",
      "Iteration 25246, loss = 435.91287172\n",
      "Iteration 25247, loss = 435.79649703\n",
      "Iteration 25248, loss = 435.68025549\n",
      "Iteration 25249, loss = 435.56414660\n",
      "Iteration 25250, loss = 435.44816986\n",
      "Iteration 25251, loss = 435.33232478\n",
      "Iteration 25252, loss = 435.21661088\n",
      "Iteration 25253, loss = 435.10102768\n",
      "Iteration 25254, loss = 434.98557468\n",
      "Iteration 25255, loss = 434.87025141\n",
      "Iteration 25256, loss = 434.75505741\n",
      "Iteration 25257, loss = 434.63999219\n",
      "Iteration 25258, loss = 434.52505529\n",
      "Iteration 25259, loss = 434.41024625\n",
      "Iteration 25260, loss = 434.29556460\n",
      "Iteration 25261, loss = 434.18100989\n",
      "Iteration 25262, loss = 434.06658166\n",
      "Iteration 25263, loss = 433.95227945\n",
      "Iteration 25264, loss = 433.83810283\n",
      "Iteration 25265, loss = 433.72405135\n",
      "Iteration 25266, loss = 433.61012455\n",
      "Iteration 25267, loss = 433.49632201\n",
      "Iteration 25268, loss = 433.38264328\n",
      "Iteration 25269, loss = 433.26908794\n",
      "Iteration 25270, loss = 433.15565554\n",
      "Iteration 25271, loss = 433.04234567\n",
      "Iteration 25272, loss = 432.92915789\n",
      "Iteration 25273, loss = 432.81609178\n",
      "Iteration 25274, loss = 432.70314693\n",
      "Iteration 25275, loss = 432.59032291\n",
      "Iteration 25276, loss = 432.47761932\n",
      "Iteration 25277, loss = 432.36503573\n",
      "Iteration 25278, loss = 432.25257175\n",
      "Iteration 25279, loss = 432.14022696\n",
      "Iteration 25280, loss = 432.02800096\n",
      "Iteration 25281, loss = 431.91589334\n",
      "Iteration 25282, loss = 431.80390372\n",
      "Iteration 25283, loss = 431.69203169\n",
      "Iteration 25284, loss = 431.58027686\n",
      "Iteration 25285, loss = 431.46863884\n",
      "Iteration 25286, loss = 431.35711724\n",
      "Iteration 25287, loss = 431.24571167\n",
      "Iteration 25288, loss = 431.13442175\n",
      "Iteration 25289, loss = 431.02324710\n",
      "Iteration 25290, loss = 430.91218734\n",
      "Iteration 25291, loss = 430.80124209\n",
      "Iteration 25292, loss = 430.69041097\n",
      "Iteration 25293, loss = 430.57969362\n",
      "Iteration 25294, loss = 430.46908967\n",
      "Iteration 25295, loss = 430.35859874\n",
      "Iteration 25296, loss = 430.24822048\n",
      "Iteration 25297, loss = 430.13795451\n",
      "Iteration 25298, loss = 430.02780048\n",
      "Iteration 25299, loss = 429.91775803\n",
      "Iteration 25300, loss = 429.80782680\n",
      "Iteration 25301, loss = 429.69800644\n",
      "Iteration 25302, loss = 429.58829659\n",
      "Iteration 25303, loss = 429.47869691\n",
      "Iteration 25304, loss = 429.36920704\n",
      "Iteration 25305, loss = 429.25982664\n",
      "Iteration 25306, loss = 429.15055537\n",
      "Iteration 25307, loss = 429.04139289\n",
      "Iteration 25308, loss = 428.93233885\n",
      "Iteration 25309, loss = 428.82339291\n",
      "Iteration 25310, loss = 428.71455474\n",
      "Iteration 25311, loss = 428.60582401\n",
      "Iteration 25312, loss = 428.49720038\n",
      "Iteration 25313, loss = 428.38868352\n",
      "Iteration 25314, loss = 428.28027311\n",
      "Iteration 25315, loss = 428.17196882\n",
      "Iteration 25316, loss = 428.06377032\n",
      "Iteration 25317, loss = 427.95567729\n",
      "Iteration 25318, loss = 427.84768941\n",
      "Iteration 25319, loss = 427.73980636\n",
      "Iteration 25320, loss = 427.63202782\n",
      "Iteration 25321, loss = 427.52435349\n",
      "Iteration 25322, loss = 427.41678303\n",
      "Iteration 25323, loss = 427.30931615\n",
      "Iteration 25324, loss = 427.20195253\n",
      "Iteration 25325, loss = 427.09469186\n",
      "Iteration 25326, loss = 426.98753384\n",
      "Iteration 25327, loss = 426.88047816\n",
      "Iteration 25328, loss = 426.77352452\n",
      "Iteration 25329, loss = 426.66667262\n",
      "Iteration 25330, loss = 426.55992215\n",
      "Iteration 25331, loss = 426.45327283\n",
      "Iteration 25332, loss = 426.34672434\n",
      "Iteration 25333, loss = 426.24027640\n",
      "Iteration 25334, loss = 426.13392871\n",
      "Iteration 25335, loss = 426.02768099\n",
      "Iteration 25336, loss = 425.92153293\n",
      "Iteration 25337, loss = 425.81548426\n",
      "Iteration 25338, loss = 425.70953468\n",
      "Iteration 25339, loss = 425.60368392\n",
      "Iteration 25340, loss = 425.49793167\n",
      "Iteration 25341, loss = 425.39227767\n",
      "Iteration 25342, loss = 425.28672164\n",
      "Iteration 25343, loss = 425.18126328\n",
      "Iteration 25344, loss = 425.07590233\n",
      "Iteration 25345, loss = 424.97063850\n",
      "Iteration 25346, loss = 424.86547153\n",
      "Iteration 25347, loss = 424.76040114\n",
      "Iteration 25348, loss = 424.65542705\n",
      "Iteration 25349, loss = 424.55054900\n",
      "Iteration 25350, loss = 424.44576672\n",
      "Iteration 25351, loss = 424.34107993\n",
      "Iteration 25352, loss = 424.23648838\n",
      "Iteration 25353, loss = 424.13199179\n",
      "Iteration 25354, loss = 424.02758991\n",
      "Iteration 25355, loss = 423.92328246\n",
      "Iteration 25356, loss = 423.81906920\n",
      "Iteration 25357, loss = 423.71494985\n",
      "Iteration 25358, loss = 423.61092417\n",
      "Iteration 25359, loss = 423.50699189\n",
      "Iteration 25360, loss = 423.40315275\n",
      "Iteration 25361, loss = 423.29940651\n",
      "Iteration 25362, loss = 423.19575291\n",
      "Iteration 25363, loss = 423.09219170\n",
      "Iteration 25364, loss = 422.98872263\n",
      "Iteration 25365, loss = 422.88534544\n",
      "Iteration 25366, loss = 422.78205989\n",
      "Iteration 25367, loss = 422.67886574\n",
      "Iteration 25368, loss = 422.57576273\n",
      "Iteration 25369, loss = 422.47275063\n",
      "Iteration 25370, loss = 422.36982918\n",
      "Iteration 25371, loss = 422.26699816\n",
      "Iteration 25372, loss = 422.16425731\n",
      "Iteration 25373, loss = 422.06160640\n",
      "Iteration 25374, loss = 421.95904518\n",
      "Iteration 25375, loss = 421.85657343\n",
      "Iteration 25376, loss = 421.75419090\n",
      "Iteration 25377, loss = 421.65189736\n",
      "Iteration 25378, loss = 421.54969258\n",
      "Iteration 25379, loss = 421.44757632\n",
      "Iteration 25380, loss = 421.34554835\n",
      "Iteration 25381, loss = 421.24360845\n",
      "Iteration 25382, loss = 421.14175638\n",
      "Iteration 25383, loss = 421.03999191\n",
      "Iteration 25384, loss = 420.93831481\n",
      "Iteration 25385, loss = 420.83672487\n",
      "Iteration 25386, loss = 420.73522185\n",
      "Iteration 25387, loss = 420.63380554\n",
      "Iteration 25388, loss = 420.53247570\n",
      "Iteration 25389, loss = 420.43123212\n",
      "Iteration 25390, loss = 420.33007458\n",
      "Iteration 25391, loss = 420.22900285\n",
      "Iteration 25392, loss = 420.12801672\n",
      "Iteration 25393, loss = 420.02711598\n",
      "Iteration 25394, loss = 419.92630039\n",
      "Iteration 25395, loss = 419.82556976\n",
      "Iteration 25396, loss = 419.72492385\n",
      "Iteration 25397, loss = 419.62436247\n",
      "Iteration 25398, loss = 419.52388539\n",
      "Iteration 25399, loss = 419.42349241\n",
      "Iteration 25400, loss = 419.32318332\n",
      "Iteration 25401, loss = 419.22295790\n",
      "Iteration 25402, loss = 419.12281594\n",
      "Iteration 25403, loss = 419.02275725\n",
      "Iteration 25404, loss = 418.92278161\n",
      "Iteration 25405, loss = 418.82288881\n",
      "Iteration 25406, loss = 418.72307866\n",
      "Iteration 25407, loss = 418.62335094\n",
      "Iteration 25408, loss = 418.52370546\n",
      "Iteration 25409, loss = 418.42414201\n",
      "Iteration 25410, loss = 418.32466039\n",
      "Iteration 25411, loss = 418.22526040\n",
      "Iteration 25412, loss = 418.12594184\n",
      "Iteration 25413, loss = 418.02670452\n",
      "Iteration 25414, loss = 417.92754823\n",
      "Iteration 25415, loss = 417.82847278\n",
      "Iteration 25416, loss = 417.72947797\n",
      "Iteration 25417, loss = 417.63056361\n",
      "Iteration 25418, loss = 417.53172950\n",
      "Iteration 25419, loss = 417.43297545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25420, loss = 417.33430128\n",
      "Iteration 25421, loss = 417.23570677\n",
      "Iteration 25422, loss = 417.13719176\n",
      "Iteration 25423, loss = 417.03875603\n",
      "Iteration 25424, loss = 416.94039942\n",
      "Iteration 25425, loss = 416.84212172\n",
      "Iteration 25426, loss = 416.74392276\n",
      "Iteration 25427, loss = 416.64580234\n",
      "Iteration 25428, loss = 416.54776028\n",
      "Iteration 25429, loss = 416.44979639\n",
      "Iteration 25430, loss = 416.35191049\n",
      "Iteration 25431, loss = 416.25410240\n",
      "Iteration 25432, loss = 416.15637194\n",
      "Iteration 25433, loss = 416.05871891\n",
      "Iteration 25434, loss = 415.96114315\n",
      "Iteration 25435, loss = 415.86364446\n",
      "Iteration 25436, loss = 415.76622268\n",
      "Iteration 25437, loss = 415.66887762\n",
      "Iteration 25438, loss = 415.57160911\n",
      "Iteration 25439, loss = 415.47441696\n",
      "Iteration 25440, loss = 415.37730100\n",
      "Iteration 25441, loss = 415.28026106\n",
      "Iteration 25442, loss = 415.18329696\n",
      "Iteration 25443, loss = 415.08640853\n",
      "Iteration 25444, loss = 414.98959559\n",
      "Iteration 25445, loss = 414.89285797\n",
      "Iteration 25446, loss = 414.79619550\n",
      "Iteration 25447, loss = 414.69960800\n",
      "Iteration 25448, loss = 414.60309531\n",
      "Iteration 25449, loss = 414.50665726\n",
      "Iteration 25450, loss = 414.41029367\n",
      "Iteration 25451, loss = 414.31400439\n",
      "Iteration 25452, loss = 414.21778923\n",
      "Iteration 25453, loss = 414.12164804\n",
      "Iteration 25454, loss = 414.02558065\n",
      "Iteration 25455, loss = 413.92958689\n",
      "Iteration 25456, loss = 413.83366659\n",
      "Iteration 25457, loss = 413.73781960\n",
      "Iteration 25458, loss = 413.64204575\n",
      "Iteration 25459, loss = 413.54634487\n",
      "Iteration 25460, loss = 413.45071680\n",
      "Iteration 25461, loss = 413.35516139\n",
      "Iteration 25462, loss = 413.25967847\n",
      "Iteration 25463, loss = 413.16426788\n",
      "Iteration 25464, loss = 413.06892946\n",
      "Iteration 25465, loss = 412.97366305\n",
      "Iteration 25466, loss = 412.87846850\n",
      "Iteration 25467, loss = 412.78334564\n",
      "Iteration 25468, loss = 412.68829431\n",
      "Iteration 25469, loss = 412.59331437\n",
      "Iteration 25470, loss = 412.49840566\n",
      "Iteration 25471, loss = 412.40356802\n",
      "Iteration 25472, loss = 412.30880129\n",
      "Iteration 25473, loss = 412.21410532\n",
      "Iteration 25474, loss = 412.11947997\n",
      "Iteration 25475, loss = 412.02492506\n",
      "Iteration 25476, loss = 411.93044047\n",
      "Iteration 25477, loss = 411.83602602\n",
      "Iteration 25478, loss = 411.74168157\n",
      "Iteration 25479, loss = 411.64740698\n",
      "Iteration 25480, loss = 411.55320208\n",
      "Iteration 25481, loss = 411.45906673\n",
      "Iteration 25482, loss = 411.36500079\n",
      "Iteration 25483, loss = 411.27100410\n",
      "Iteration 25484, loss = 411.17707652\n",
      "Iteration 25485, loss = 411.08321790\n",
      "Iteration 25486, loss = 410.98942809\n",
      "Iteration 25487, loss = 410.89570695\n",
      "Iteration 25488, loss = 410.80205433\n",
      "Iteration 25489, loss = 410.70847008\n",
      "Iteration 25490, loss = 410.61495408\n",
      "Iteration 25491, loss = 410.52150616\n",
      "Iteration 25492, loss = 410.42812618\n",
      "Iteration 25493, loss = 410.33481402\n",
      "Iteration 25494, loss = 410.24156951\n",
      "Iteration 25495, loss = 410.14839252\n",
      "Iteration 25496, loss = 410.05528292\n",
      "Iteration 25497, loss = 409.96224055\n",
      "Iteration 25498, loss = 409.86926529\n",
      "Iteration 25499, loss = 409.77635698\n",
      "Iteration 25500, loss = 409.68351550\n",
      "Iteration 25501, loss = 409.59074070\n",
      "Iteration 25502, loss = 409.49803244\n",
      "Iteration 25503, loss = 409.40539059\n",
      "Iteration 25504, loss = 409.31281502\n",
      "Iteration 25505, loss = 409.22030558\n",
      "Iteration 25506, loss = 409.12786214\n",
      "Iteration 25507, loss = 409.03548457\n",
      "Iteration 25508, loss = 408.94317273\n",
      "Iteration 25509, loss = 408.85092648\n",
      "Iteration 25510, loss = 408.75874569\n",
      "Iteration 25511, loss = 408.66663024\n",
      "Iteration 25512, loss = 408.57457998\n",
      "Iteration 25513, loss = 408.48259478\n",
      "Iteration 25514, loss = 408.39067452\n",
      "Iteration 25515, loss = 408.29881906\n",
      "Iteration 25516, loss = 408.20702827\n",
      "Iteration 25517, loss = 408.11530202\n",
      "Iteration 25518, loss = 408.02364018\n",
      "Iteration 25519, loss = 407.93204262\n",
      "Iteration 25520, loss = 407.84050922\n",
      "Iteration 25521, loss = 407.74903984\n",
      "Iteration 25522, loss = 407.65763436\n",
      "Iteration 25523, loss = 407.56629264\n",
      "Iteration 25524, loss = 407.47501457\n",
      "Iteration 25525, loss = 407.38380001\n",
      "Iteration 25526, loss = 407.29264884\n",
      "Iteration 25527, loss = 407.20156094\n",
      "Iteration 25528, loss = 407.11053618\n",
      "Iteration 25529, loss = 407.01957442\n",
      "Iteration 25530, loss = 406.92867556\n",
      "Iteration 25531, loss = 406.83783947\n",
      "Iteration 25532, loss = 406.74706601\n",
      "Iteration 25533, loss = 406.65635508\n",
      "Iteration 25534, loss = 406.56570655\n",
      "Iteration 25535, loss = 406.47512028\n",
      "Iteration 25536, loss = 406.38459618\n",
      "Iteration 25537, loss = 406.29413410\n",
      "Iteration 25538, loss = 406.20373394\n",
      "Iteration 25539, loss = 406.11339557\n",
      "Iteration 25540, loss = 406.02311887\n",
      "Iteration 25541, loss = 405.93290372\n",
      "Iteration 25542, loss = 405.84275000\n",
      "Iteration 25543, loss = 405.75265760\n",
      "Iteration 25544, loss = 405.66262639\n",
      "Iteration 25545, loss = 405.57265627\n",
      "Iteration 25546, loss = 405.48274710\n",
      "Iteration 25547, loss = 405.39289878\n",
      "Iteration 25548, loss = 405.30311118\n",
      "Iteration 25549, loss = 405.21338419\n",
      "Iteration 25550, loss = 405.12371770\n",
      "Iteration 25551, loss = 405.03411159\n",
      "Iteration 25552, loss = 404.94456575\n",
      "Iteration 25553, loss = 404.85508005\n",
      "Iteration 25554, loss = 404.76565439\n",
      "Iteration 25555, loss = 404.67628866\n",
      "Iteration 25556, loss = 404.58698273\n",
      "Iteration 25557, loss = 404.49773650\n",
      "Iteration 25558, loss = 404.40854985\n",
      "Iteration 25559, loss = 404.31942267\n",
      "Iteration 25560, loss = 404.23035485\n",
      "Iteration 25561, loss = 404.14134628\n",
      "Iteration 25562, loss = 404.05239684\n",
      "Iteration 25563, loss = 403.96350643\n",
      "Iteration 25564, loss = 403.87467494\n",
      "Iteration 25565, loss = 403.78590225\n",
      "Iteration 25566, loss = 403.69718826\n",
      "Iteration 25567, loss = 403.60853285\n",
      "Iteration 25568, loss = 403.51993592\n",
      "Iteration 25569, loss = 403.43139736\n",
      "Iteration 25570, loss = 403.34291707\n",
      "Iteration 25571, loss = 403.25449492\n",
      "Iteration 25572, loss = 403.16613082\n",
      "Iteration 25573, loss = 403.07782466\n",
      "Iteration 25574, loss = 402.98957633\n",
      "Iteration 25575, loss = 402.90138573\n",
      "Iteration 25576, loss = 402.81325275\n",
      "Iteration 25577, loss = 402.72517728\n",
      "Iteration 25578, loss = 402.63715922\n",
      "Iteration 25579, loss = 402.54919847\n",
      "Iteration 25580, loss = 402.46129491\n",
      "Iteration 25581, loss = 402.37344845\n",
      "Iteration 25582, loss = 402.28565898\n",
      "Iteration 25583, loss = 402.19792640\n",
      "Iteration 25584, loss = 402.11025060\n",
      "Iteration 25585, loss = 402.02263149\n",
      "Iteration 25586, loss = 401.93506895\n",
      "Iteration 25587, loss = 401.84756289\n",
      "Iteration 25588, loss = 401.76011320\n",
      "Iteration 25589, loss = 401.67271979\n",
      "Iteration 25590, loss = 401.58538255\n",
      "Iteration 25591, loss = 401.49810139\n",
      "Iteration 25592, loss = 401.41087619\n",
      "Iteration 25593, loss = 401.32370686\n",
      "Iteration 25594, loss = 401.23659331\n",
      "Iteration 25595, loss = 401.14953542\n",
      "Iteration 25596, loss = 401.06253311\n",
      "Iteration 25597, loss = 400.97558627\n",
      "Iteration 25598, loss = 400.88869481\n",
      "Iteration 25599, loss = 400.80185862\n",
      "Iteration 25600, loss = 400.71507761\n",
      "Iteration 25601, loss = 400.62835167\n",
      "Iteration 25602, loss = 400.54168073\n",
      "Iteration 25603, loss = 400.45506467\n",
      "Iteration 25604, loss = 400.36850339\n",
      "Iteration 25605, loss = 400.28199681\n",
      "Iteration 25606, loss = 400.19554483\n",
      "Iteration 25607, loss = 400.10914735\n",
      "Iteration 25608, loss = 400.02280427\n",
      "Iteration 25609, loss = 399.93651551\n",
      "Iteration 25610, loss = 399.85028095\n",
      "Iteration 25611, loss = 399.76410052\n",
      "Iteration 25612, loss = 399.67797412\n",
      "Iteration 25613, loss = 399.59190165\n",
      "Iteration 25614, loss = 399.50588302\n",
      "Iteration 25615, loss = 399.41991813\n",
      "Iteration 25616, loss = 399.33400689\n",
      "Iteration 25617, loss = 399.24814922\n",
      "Iteration 25618, loss = 399.16234501\n",
      "Iteration 25619, loss = 399.07659417\n",
      "Iteration 25620, loss = 398.99089662\n",
      "Iteration 25621, loss = 398.90525226\n",
      "Iteration 25622, loss = 398.81966100\n",
      "Iteration 25623, loss = 398.73412275\n",
      "Iteration 25624, loss = 398.64863741\n",
      "Iteration 25625, loss = 398.56320490\n",
      "Iteration 25626, loss = 398.47782513\n",
      "Iteration 25627, loss = 398.39249801\n",
      "Iteration 25628, loss = 398.30722344\n",
      "Iteration 25629, loss = 398.22200134\n",
      "Iteration 25630, loss = 398.13683161\n",
      "Iteration 25631, loss = 398.05171418\n",
      "Iteration 25632, loss = 397.96664895\n",
      "Iteration 25633, loss = 397.88163583\n",
      "Iteration 25634, loss = 397.79667474\n",
      "Iteration 25635, loss = 397.71176558\n",
      "Iteration 25636, loss = 397.62690827\n",
      "Iteration 25637, loss = 397.54210273\n",
      "Iteration 25638, loss = 397.45734886\n",
      "Iteration 25639, loss = 397.37264657\n",
      "Iteration 25640, loss = 397.28799579\n",
      "Iteration 25641, loss = 397.20339643\n",
      "Iteration 25642, loss = 397.11884839\n",
      "Iteration 25643, loss = 397.03435160\n",
      "Iteration 25644, loss = 396.94990597\n",
      "Iteration 25645, loss = 396.86551141\n",
      "Iteration 25646, loss = 396.78116784\n",
      "Iteration 25647, loss = 396.69687517\n",
      "Iteration 25648, loss = 396.61263333\n",
      "Iteration 25649, loss = 396.52844221\n",
      "Iteration 25650, loss = 396.44430175\n",
      "Iteration 25651, loss = 396.36021186\n",
      "Iteration 25652, loss = 396.27617245\n",
      "Iteration 25653, loss = 396.19218344\n",
      "Iteration 25654, loss = 396.10824475\n",
      "Iteration 25655, loss = 396.02435630\n",
      "Iteration 25656, loss = 395.94051800\n",
      "Iteration 25657, loss = 395.85672977\n",
      "Iteration 25658, loss = 395.77299153\n",
      "Iteration 25659, loss = 395.68930320\n",
      "Iteration 25660, loss = 395.60566469\n",
      "Iteration 25661, loss = 395.52207593\n",
      "Iteration 25662, loss = 395.43853683\n",
      "Iteration 25663, loss = 395.35504732\n",
      "Iteration 25664, loss = 395.27160731\n",
      "Iteration 25665, loss = 395.18821672\n",
      "Iteration 25666, loss = 395.10487548\n",
      "Iteration 25667, loss = 395.02158351\n",
      "Iteration 25668, loss = 394.93834074\n",
      "Iteration 25669, loss = 394.85514712\n",
      "Iteration 25670, loss = 394.77200262\n",
      "Iteration 25671, loss = 394.68890729\n",
      "Iteration 25672, loss = 394.60586137\n",
      "Iteration 25673, loss = 394.52286550\n",
      "Iteration 25674, loss = 394.43992134\n",
      "Iteration 25675, loss = 394.35703272\n",
      "Iteration 25676, loss = 394.27420771\n",
      "Iteration 25677, loss = 394.19145997\n",
      "Iteration 25678, loss = 394.10879567\n",
      "Iteration 25679, loss = 394.02616889\n",
      "Iteration 25680, loss = 393.94345914\n",
      "Iteration 25681, loss = 393.86068249\n",
      "Iteration 25682, loss = 393.77806895\n",
      "Iteration 25683, loss = 393.69565871\n",
      "Iteration 25684, loss = 393.61322285\n",
      "Iteration 25685, loss = 393.53069825\n",
      "Iteration 25686, loss = 393.44830203\n",
      "Iteration 25687, loss = 393.36605608\n",
      "Iteration 25688, loss = 393.28376553\n",
      "Iteration 25689, loss = 393.20146839\n",
      "Iteration 25690, loss = 393.11931734\n",
      "Iteration 25691, loss = 393.03721783\n",
      "Iteration 25692, loss = 392.95508398\n",
      "Iteration 25693, loss = 392.87303505\n",
      "Iteration 25694, loss = 392.79108147\n",
      "Iteration 25695, loss = 392.70911899\n",
      "Iteration 25696, loss = 392.62719640\n",
      "Iteration 25697, loss = 392.54537121\n",
      "Iteration 25698, loss = 392.46356935\n",
      "Iteration 25699, loss = 392.38178808\n",
      "Iteration 25700, loss = 392.30008936\n",
      "Iteration 25701, loss = 392.21843663\n",
      "Iteration 25702, loss = 392.13680221\n",
      "Iteration 25703, loss = 392.05523334\n",
      "Iteration 25704, loss = 391.97372192\n",
      "Iteration 25705, loss = 391.89223457\n",
      "Iteration 25706, loss = 391.81079946\n",
      "Iteration 25707, loss = 391.72942504\n",
      "Iteration 25708, loss = 391.64808268\n",
      "Iteration 25709, loss = 391.56678419\n",
      "Iteration 25710, loss = 391.48554484\n",
      "Iteration 25711, loss = 391.40434474\n",
      "Iteration 25712, loss = 391.32318448\n",
      "Iteration 25713, loss = 391.24207961\n",
      "Iteration 25714, loss = 391.16101921\n",
      "Iteration 25715, loss = 391.07999769\n",
      "Iteration 25716, loss = 390.99902738\n",
      "Iteration 25717, loss = 390.91810456\n",
      "Iteration 25718, loss = 390.83722149\n",
      "Iteration 25719, loss = 390.75638605\n",
      "Iteration 25720, loss = 390.67559922\n",
      "Iteration 25721, loss = 390.59485381\n",
      "Iteration 25722, loss = 390.51415349\n",
      "Iteration 25723, loss = 390.43350155\n",
      "Iteration 25724, loss = 390.35289275\n",
      "Iteration 25725, loss = 390.27232759\n",
      "Iteration 25726, loss = 390.19180982\n",
      "Iteration 25727, loss = 390.11133652\n",
      "Iteration 25728, loss = 390.03090630\n",
      "Iteration 25729, loss = 389.95052224\n",
      "Iteration 25730, loss = 389.87018338\n",
      "Iteration 25731, loss = 389.78988767\n",
      "Iteration 25732, loss = 389.70963696\n",
      "Iteration 25733, loss = 389.62943164\n",
      "Iteration 25734, loss = 389.54926980\n",
      "Iteration 25735, loss = 389.46915212\n",
      "Iteration 25736, loss = 389.38907957\n",
      "Iteration 25737, loss = 389.30905089\n",
      "Iteration 25738, loss = 389.22906586\n",
      "Iteration 25739, loss = 389.14912548\n",
      "Iteration 25740, loss = 389.06922918\n",
      "Iteration 25741, loss = 388.98937633\n",
      "Iteration 25742, loss = 388.90956759\n",
      "Iteration 25743, loss = 388.82980295\n",
      "Iteration 25744, loss = 388.75008173\n",
      "Iteration 25745, loss = 388.67040416\n",
      "Iteration 25746, loss = 388.59077052\n",
      "Iteration 25747, loss = 388.51118030\n",
      "Iteration 25748, loss = 388.43163342\n",
      "Iteration 25749, loss = 388.35213017\n",
      "Iteration 25750, loss = 388.27267032\n",
      "Iteration 25751, loss = 388.19325361\n",
      "Iteration 25752, loss = 388.11388021\n",
      "Iteration 25753, loss = 388.03455010\n",
      "Iteration 25754, loss = 387.95526301\n",
      "Iteration 25755, loss = 387.87601894\n",
      "Iteration 25756, loss = 387.79681797\n",
      "Iteration 25757, loss = 387.71765991\n",
      "Iteration 25758, loss = 387.63854465\n",
      "Iteration 25759, loss = 387.55947225\n",
      "Iteration 25760, loss = 387.48044263\n",
      "Iteration 25761, loss = 387.40145564\n",
      "Iteration 25762, loss = 387.32251128\n",
      "Iteration 25763, loss = 387.24360954\n",
      "Iteration 25764, loss = 387.16475027\n",
      "Iteration 25765, loss = 387.08593341\n",
      "Iteration 25766, loss = 387.00715897\n",
      "Iteration 25767, loss = 386.92842686\n",
      "Iteration 25768, loss = 386.84973698\n",
      "Iteration 25769, loss = 386.77108930\n",
      "Iteration 25770, loss = 386.69248379\n",
      "Iteration 25771, loss = 386.61392035\n",
      "Iteration 25772, loss = 386.53539891\n",
      "Iteration 25773, loss = 386.45691945\n",
      "Iteration 25774, loss = 386.37848190\n",
      "Iteration 25775, loss = 386.30008618\n",
      "Iteration 25776, loss = 386.22173224\n",
      "Iteration 25777, loss = 386.14342003\n",
      "Iteration 25778, loss = 386.06514949\n",
      "Iteration 25779, loss = 385.98692055\n",
      "Iteration 25780, loss = 385.90873316\n",
      "Iteration 25781, loss = 385.83058727\n",
      "Iteration 25782, loss = 385.75248280\n",
      "Iteration 25783, loss = 385.67441970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25784, loss = 385.59639793\n",
      "Iteration 25785, loss = 385.51841741\n",
      "Iteration 25786, loss = 385.44047809\n",
      "Iteration 25787, loss = 385.36257991\n",
      "Iteration 25788, loss = 385.28472283\n",
      "Iteration 25789, loss = 385.20690676\n",
      "Iteration 25790, loss = 385.12913167\n",
      "Iteration 25791, loss = 385.05139750\n",
      "Iteration 25792, loss = 384.97370419\n",
      "Iteration 25793, loss = 384.89605167\n",
      "Iteration 25794, loss = 384.81843990\n",
      "Iteration 25795, loss = 384.74086882\n",
      "Iteration 25796, loss = 384.66333837\n",
      "Iteration 25797, loss = 384.58584849\n",
      "Iteration 25798, loss = 384.50839914\n",
      "Iteration 25799, loss = 384.43099025\n",
      "Iteration 25800, loss = 384.35362177\n",
      "Iteration 25801, loss = 384.27629365\n",
      "Iteration 25802, loss = 384.19900582\n",
      "Iteration 25803, loss = 384.12175823\n",
      "Iteration 25804, loss = 384.04455084\n",
      "Iteration 25805, loss = 383.96738357\n",
      "Iteration 25806, loss = 383.89025639\n",
      "Iteration 25807, loss = 383.81316922\n",
      "Iteration 25808, loss = 383.73612203\n",
      "Iteration 25809, loss = 383.65911475\n",
      "Iteration 25810, loss = 383.58214734\n",
      "Iteration 25811, loss = 383.50521972\n",
      "Iteration 25812, loss = 383.42833187\n",
      "Iteration 25813, loss = 383.35148371\n",
      "Iteration 25814, loss = 383.27467519\n",
      "Iteration 25815, loss = 383.19790627\n",
      "Iteration 25816, loss = 383.12117688\n",
      "Iteration 25817, loss = 383.04448698\n",
      "Iteration 25818, loss = 382.96783651\n",
      "Iteration 25819, loss = 382.89122542\n",
      "Iteration 25820, loss = 382.81465365\n",
      "Iteration 25821, loss = 382.73812116\n",
      "Iteration 25822, loss = 382.66162788\n",
      "Iteration 25823, loss = 382.58517378\n",
      "Iteration 25824, loss = 382.50875879\n",
      "Iteration 25825, loss = 382.43238286\n",
      "Iteration 25826, loss = 382.35604594\n",
      "Iteration 25827, loss = 382.27974798\n",
      "Iteration 25828, loss = 382.20348893\n",
      "Iteration 25829, loss = 382.12726873\n",
      "Iteration 25830, loss = 382.05108734\n",
      "Iteration 25831, loss = 381.97494470\n",
      "Iteration 25832, loss = 381.89884076\n",
      "Iteration 25833, loss = 381.82277546\n",
      "Iteration 25834, loss = 381.74674877\n",
      "Iteration 25835, loss = 381.67076062\n",
      "Iteration 25836, loss = 381.59481097\n",
      "Iteration 25837, loss = 381.51889977\n",
      "Iteration 25838, loss = 381.44302696\n",
      "Iteration 25839, loss = 381.36719250\n",
      "Iteration 25840, loss = 381.29139632\n",
      "Iteration 25841, loss = 381.21563840\n",
      "Iteration 25842, loss = 381.13991866\n",
      "Iteration 25843, loss = 381.06423707\n",
      "Iteration 25844, loss = 380.98859358\n",
      "Iteration 25845, loss = 380.91298812\n",
      "Iteration 25846, loss = 380.83742067\n",
      "Iteration 25847, loss = 380.76189115\n",
      "Iteration 25848, loss = 380.68639953\n",
      "Iteration 25849, loss = 380.61094576\n",
      "Iteration 25850, loss = 380.53552979\n",
      "Iteration 25851, loss = 380.46015156\n",
      "Iteration 25852, loss = 380.38481103\n",
      "Iteration 25853, loss = 380.30950815\n",
      "Iteration 25854, loss = 380.23424287\n",
      "Iteration 25855, loss = 380.15901515\n",
      "Iteration 25856, loss = 380.08382493\n",
      "Iteration 25857, loss = 380.00867216\n",
      "Iteration 25858, loss = 379.93355680\n",
      "Iteration 25859, loss = 379.85847880\n",
      "Iteration 25860, loss = 379.78343812\n",
      "Iteration 25861, loss = 379.70843469\n",
      "Iteration 25862, loss = 379.63346849\n",
      "Iteration 25863, loss = 379.55853944\n",
      "Iteration 25864, loss = 379.48364752\n",
      "Iteration 25865, loss = 379.40879268\n",
      "Iteration 25866, loss = 379.33397485\n",
      "Iteration 25867, loss = 379.25919401\n",
      "Iteration 25868, loss = 379.18445010\n",
      "Iteration 25869, loss = 379.10974307\n",
      "Iteration 25870, loss = 379.03507288\n",
      "Iteration 25871, loss = 378.96043948\n",
      "Iteration 25872, loss = 378.88584282\n",
      "Iteration 25873, loss = 378.81128286\n",
      "Iteration 25874, loss = 378.73675955\n",
      "Iteration 25875, loss = 378.66227285\n",
      "Iteration 25876, loss = 378.58782270\n",
      "Iteration 25877, loss = 378.51340906\n",
      "Iteration 25878, loss = 378.43903189\n",
      "Iteration 25879, loss = 378.36469114\n",
      "Iteration 25880, loss = 378.29038677\n",
      "Iteration 25881, loss = 378.21611872\n",
      "Iteration 25882, loss = 378.14188696\n",
      "Iteration 25883, loss = 378.06769143\n",
      "Iteration 25884, loss = 377.99353209\n",
      "Iteration 25885, loss = 377.91940891\n",
      "Iteration 25886, loss = 377.84532182\n",
      "Iteration 25887, loss = 377.77127079\n",
      "Iteration 25888, loss = 377.69725577\n",
      "Iteration 25889, loss = 377.62327671\n",
      "Iteration 25890, loss = 377.54933358\n",
      "Iteration 25891, loss = 377.47542633\n",
      "Iteration 25892, loss = 377.40155490\n",
      "Iteration 25893, loss = 377.32771927\n",
      "Iteration 25894, loss = 377.25391938\n",
      "Iteration 25895, loss = 377.18015519\n",
      "Iteration 25896, loss = 377.10642665\n",
      "Iteration 25897, loss = 377.03273372\n",
      "Iteration 25898, loss = 376.95907636\n",
      "Iteration 25899, loss = 376.88545453\n",
      "Iteration 25900, loss = 376.81186817\n",
      "Iteration 25901, loss = 376.73831725\n",
      "Iteration 25902, loss = 376.66480173\n",
      "Iteration 25903, loss = 376.59132155\n",
      "Iteration 25904, loss = 376.51787667\n",
      "Iteration 25905, loss = 376.44446706\n",
      "Iteration 25906, loss = 376.37109267\n",
      "Iteration 25907, loss = 376.29775345\n",
      "Iteration 25908, loss = 376.22444937\n",
      "Iteration 25909, loss = 376.15118038\n",
      "Iteration 25910, loss = 376.07794643\n",
      "Iteration 25911, loss = 376.00474749\n",
      "Iteration 25912, loss = 375.93158351\n",
      "Iteration 25913, loss = 375.85845445\n",
      "Iteration 25914, loss = 375.78536027\n",
      "Iteration 25915, loss = 375.71230092\n",
      "Iteration 25916, loss = 375.63927636\n",
      "Iteration 25917, loss = 375.56628656\n",
      "Iteration 25918, loss = 375.49333146\n",
      "Iteration 25919, loss = 375.42041103\n",
      "Iteration 25920, loss = 375.34752523\n",
      "Iteration 25921, loss = 375.27467401\n",
      "Iteration 25922, loss = 375.20185733\n",
      "Iteration 25923, loss = 375.12907515\n",
      "Iteration 25924, loss = 375.05632743\n",
      "Iteration 25925, loss = 374.98361412\n",
      "Iteration 25926, loss = 374.91093520\n",
      "Iteration 25927, loss = 374.83829060\n",
      "Iteration 25928, loss = 374.76568030\n",
      "Iteration 25929, loss = 374.69310426\n",
      "Iteration 25930, loss = 374.62056242\n",
      "Iteration 25931, loss = 374.54805476\n",
      "Iteration 25932, loss = 374.47558122\n",
      "Iteration 25933, loss = 374.40314178\n",
      "Iteration 25934, loss = 374.33073638\n",
      "Iteration 25935, loss = 374.25836499\n",
      "Iteration 25936, loss = 374.18602758\n",
      "Iteration 25937, loss = 374.11372409\n",
      "Iteration 25938, loss = 374.04145448\n",
      "Iteration 25939, loss = 373.96921873\n",
      "Iteration 25940, loss = 373.89701678\n",
      "Iteration 25941, loss = 373.82484860\n",
      "Iteration 25942, loss = 373.75271415\n",
      "Iteration 25943, loss = 373.68061339\n",
      "Iteration 25944, loss = 373.60854627\n",
      "Iteration 25945, loss = 373.53651277\n",
      "Iteration 25946, loss = 373.46451283\n",
      "Iteration 25947, loss = 373.39254643\n",
      "Iteration 25948, loss = 373.32061351\n",
      "Iteration 25949, loss = 373.24871405\n",
      "Iteration 25950, loss = 373.17684800\n",
      "Iteration 25951, loss = 373.10501532\n",
      "Iteration 25952, loss = 373.03321598\n",
      "Iteration 25953, loss = 372.96144993\n",
      "Iteration 25954, loss = 372.88971714\n",
      "Iteration 25955, loss = 372.81801757\n",
      "Iteration 25956, loss = 372.74635118\n",
      "Iteration 25957, loss = 372.67471793\n",
      "Iteration 25958, loss = 372.60311778\n",
      "Iteration 25959, loss = 372.53155070\n",
      "Iteration 25960, loss = 372.46001664\n",
      "Iteration 25961, loss = 372.38851557\n",
      "Iteration 25962, loss = 372.31704745\n",
      "Iteration 25963, loss = 372.24561224\n",
      "Iteration 25964, loss = 372.17420990\n",
      "Iteration 25965, loss = 372.10284040\n",
      "Iteration 25966, loss = 372.03150370\n",
      "Iteration 25967, loss = 371.96019976\n",
      "Iteration 25968, loss = 371.88892854\n",
      "Iteration 25969, loss = 371.81769000\n",
      "Iteration 25970, loss = 371.74648412\n",
      "Iteration 25971, loss = 371.67531084\n",
      "Iteration 25972, loss = 371.60417014\n",
      "Iteration 25973, loss = 371.53306197\n",
      "Iteration 25974, loss = 371.46198630\n",
      "Iteration 25975, loss = 371.39094309\n",
      "Iteration 25976, loss = 371.31993231\n",
      "Iteration 25977, loss = 371.24895392\n",
      "Iteration 25978, loss = 371.17800787\n",
      "Iteration 25979, loss = 371.10709414\n",
      "Iteration 25980, loss = 371.03621269\n",
      "Iteration 25981, loss = 370.96536347\n",
      "Iteration 25982, loss = 370.89454646\n",
      "Iteration 25983, loss = 370.82376162\n",
      "Iteration 25984, loss = 370.75300891\n",
      "Iteration 25985, loss = 370.68228830\n",
      "Iteration 25986, loss = 370.61159974\n",
      "Iteration 25987, loss = 370.54094321\n",
      "Iteration 25988, loss = 370.47031866\n",
      "Iteration 25989, loss = 370.39972607\n",
      "Iteration 25990, loss = 370.32916539\n",
      "Iteration 25991, loss = 370.25863659\n",
      "Iteration 25992, loss = 370.18813963\n",
      "Iteration 25993, loss = 370.11767448\n",
      "Iteration 25994, loss = 370.04724110\n",
      "Iteration 25995, loss = 369.97683946\n",
      "Iteration 25996, loss = 369.90646952\n",
      "Iteration 25997, loss = 369.83613124\n",
      "Iteration 25998, loss = 369.76582459\n",
      "Iteration 25999, loss = 369.69554954\n",
      "Iteration 26000, loss = 369.62530605\n",
      "Iteration 26001, loss = 369.55509409\n",
      "Iteration 26002, loss = 369.48491361\n",
      "Iteration 26003, loss = 369.41476459\n",
      "Iteration 26004, loss = 369.34464699\n",
      "Iteration 26005, loss = 369.27456078\n",
      "Iteration 26006, loss = 369.20450591\n",
      "Iteration 26007, loss = 369.13448236\n",
      "Iteration 26008, loss = 369.06449010\n",
      "Iteration 26009, loss = 368.99452908\n",
      "Iteration 26010, loss = 368.92459927\n",
      "Iteration 26011, loss = 368.85470064\n",
      "Iteration 26012, loss = 368.78483315\n",
      "Iteration 26013, loss = 368.71499677\n",
      "Iteration 26014, loss = 368.64519147\n",
      "Iteration 26015, loss = 368.57541721\n",
      "Iteration 26016, loss = 368.50567396\n",
      "Iteration 26017, loss = 368.43596168\n",
      "Iteration 26018, loss = 368.36628034\n",
      "Iteration 26019, loss = 368.29662991\n",
      "Iteration 26020, loss = 368.22701035\n",
      "Iteration 26021, loss = 368.15742163\n",
      "Iteration 26022, loss = 368.08786371\n",
      "Iteration 26023, loss = 368.01833656\n",
      "Iteration 26024, loss = 367.94884015\n",
      "Iteration 26025, loss = 367.87937445\n",
      "Iteration 26026, loss = 367.80993942\n",
      "Iteration 26027, loss = 367.74053502\n",
      "Iteration 26028, loss = 367.67116123\n",
      "Iteration 26029, loss = 367.60181801\n",
      "Iteration 26030, loss = 367.53250533\n",
      "Iteration 26031, loss = 367.46322316\n",
      "Iteration 26032, loss = 367.39397146\n",
      "Iteration 26033, loss = 367.32475020\n",
      "Iteration 26034, loss = 367.25555935\n",
      "Iteration 26035, loss = 367.18639887\n",
      "Iteration 26036, loss = 367.11726873\n",
      "Iteration 26037, loss = 367.04816890\n",
      "Iteration 26038, loss = 366.97909935\n",
      "Iteration 26039, loss = 366.91006005\n",
      "Iteration 26040, loss = 366.84105095\n",
      "Iteration 26041, loss = 366.77207204\n",
      "Iteration 26042, loss = 366.70312327\n",
      "Iteration 26043, loss = 366.63420462\n",
      "Iteration 26044, loss = 366.56531605\n",
      "Iteration 26045, loss = 366.49645753\n",
      "Iteration 26046, loss = 366.42762904\n",
      "Iteration 26047, loss = 366.35883053\n",
      "Iteration 26048, loss = 366.29006197\n",
      "Iteration 26049, loss = 366.22132334\n",
      "Iteration 26050, loss = 366.15261460\n",
      "Iteration 26051, loss = 366.08393572\n",
      "Iteration 26052, loss = 366.01528668\n",
      "Iteration 26053, loss = 365.94666742\n",
      "Iteration 26054, loss = 365.87807794\n",
      "Iteration 26055, loss = 365.80951819\n",
      "Iteration 26056, loss = 365.74098814\n",
      "Iteration 26057, loss = 365.67248776\n",
      "Iteration 26058, loss = 365.60401702\n",
      "Iteration 26059, loss = 365.53557590\n",
      "Iteration 26060, loss = 365.46716435\n",
      "Iteration 26061, loss = 365.39878235\n",
      "Iteration 26062, loss = 365.33042986\n",
      "Iteration 26063, loss = 365.26210687\n",
      "Iteration 26064, loss = 365.19381332\n",
      "Iteration 26065, loss = 365.12554920\n",
      "Iteration 26066, loss = 365.05731447\n",
      "Iteration 26067, loss = 364.98910911\n",
      "Iteration 26068, loss = 364.92093308\n",
      "Iteration 26069, loss = 364.85278635\n",
      "Iteration 26070, loss = 364.78466889\n",
      "Iteration 26071, loss = 364.71658067\n",
      "Iteration 26072, loss = 364.64852166\n",
      "Iteration 26073, loss = 364.58049183\n",
      "Iteration 26074, loss = 364.51249115\n",
      "Iteration 26075, loss = 364.44451959\n",
      "Iteration 26076, loss = 364.37657712\n",
      "Iteration 26077, loss = 364.30866371\n",
      "Iteration 26078, loss = 364.24077933\n",
      "Iteration 26079, loss = 364.17292395\n",
      "Iteration 26080, loss = 364.10509754\n",
      "Iteration 26081, loss = 364.03730006\n",
      "Iteration 26082, loss = 363.96953150\n",
      "Iteration 26083, loss = 363.90179182\n",
      "Iteration 26084, loss = 363.83408099\n",
      "Iteration 26085, loss = 363.76639898\n",
      "Iteration 26086, loss = 363.69874576\n",
      "Iteration 26087, loss = 363.63112131\n",
      "Iteration 26088, loss = 363.56352558\n",
      "Iteration 26089, loss = 363.49595856\n",
      "Iteration 26090, loss = 363.42842022\n",
      "Iteration 26091, loss = 363.36091052\n",
      "Iteration 26092, loss = 363.29342943\n",
      "Iteration 26093, loss = 363.22597693\n",
      "Iteration 26094, loss = 363.15855299\n",
      "Iteration 26095, loss = 363.09115758\n",
      "Iteration 26096, loss = 363.02379067\n",
      "Iteration 26097, loss = 362.95645223\n",
      "Iteration 26098, loss = 362.88914223\n",
      "Iteration 26099, loss = 362.82186064\n",
      "Iteration 26100, loss = 362.75460744\n",
      "Iteration 26101, loss = 362.68738259\n",
      "Iteration 26102, loss = 362.62018608\n",
      "Iteration 26103, loss = 362.55301786\n",
      "Iteration 26104, loss = 362.48587790\n",
      "Iteration 26105, loss = 362.41876620\n",
      "Iteration 26106, loss = 362.35168270\n",
      "Iteration 26107, loss = 362.28462739\n",
      "Iteration 26108, loss = 362.21760024\n",
      "Iteration 26109, loss = 362.15060121\n",
      "Iteration 26110, loss = 362.08363029\n",
      "Iteration 26111, loss = 362.01668743\n",
      "Iteration 26112, loss = 361.94977263\n",
      "Iteration 26113, loss = 361.88288583\n",
      "Iteration 26114, loss = 361.81602703\n",
      "Iteration 26115, loss = 361.74919618\n",
      "Iteration 26116, loss = 361.68239327\n",
      "Iteration 26117, loss = 361.61561827\n",
      "Iteration 26118, loss = 361.54887114\n",
      "Iteration 26119, loss = 361.48215185\n",
      "Iteration 26120, loss = 361.41546040\n",
      "Iteration 26121, loss = 361.34879673\n",
      "Iteration 26122, loss = 361.28216083\n",
      "Iteration 26123, loss = 361.21555267\n",
      "Iteration 26124, loss = 361.14897222\n",
      "Iteration 26125, loss = 361.08241946\n",
      "Iteration 26126, loss = 361.01589435\n",
      "Iteration 26127, loss = 360.94939687\n",
      "Iteration 26128, loss = 360.88292700\n",
      "Iteration 26129, loss = 360.81648470\n",
      "Iteration 26130, loss = 360.75006995\n",
      "Iteration 26131, loss = 360.68368272\n",
      "Iteration 26132, loss = 360.61732298\n",
      "Iteration 26133, loss = 360.55099071\n",
      "Iteration 26134, loss = 360.48468588\n",
      "Iteration 26135, loss = 360.41840846\n",
      "Iteration 26136, loss = 360.35215843\n",
      "Iteration 26137, loss = 360.28593576\n",
      "Iteration 26138, loss = 360.21974043\n",
      "Iteration 26139, loss = 360.15357240\n",
      "Iteration 26140, loss = 360.08743165\n",
      "Iteration 26141, loss = 360.02131815\n",
      "Iteration 26142, loss = 359.95523188\n",
      "Iteration 26143, loss = 359.88917281\n",
      "Iteration 26144, loss = 359.82314092\n",
      "Iteration 26145, loss = 359.75713617\n",
      "Iteration 26146, loss = 359.69115854\n",
      "Iteration 26147, loss = 359.62520801\n",
      "Iteration 26148, loss = 359.55928455\n",
      "Iteration 26149, loss = 359.49338813\n",
      "Iteration 26150, loss = 359.42751872\n",
      "Iteration 26151, loss = 359.36167631\n",
      "Iteration 26152, loss = 359.29586086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26153, loss = 359.23007235\n",
      "Iteration 26154, loss = 359.16431076\n",
      "Iteration 26155, loss = 359.09857605\n",
      "Iteration 26156, loss = 359.03286820\n",
      "Iteration 26157, loss = 358.96718718\n",
      "Iteration 26158, loss = 358.90153298\n",
      "Iteration 26159, loss = 358.83590556\n",
      "Iteration 26160, loss = 358.77030490\n",
      "Iteration 26161, loss = 358.70473097\n",
      "Iteration 26162, loss = 358.63918375\n",
      "Iteration 26163, loss = 358.57366321\n",
      "Iteration 26164, loss = 358.50816933\n",
      "Iteration 26165, loss = 358.44270209\n",
      "Iteration 26166, loss = 358.37726146\n",
      "Iteration 26167, loss = 358.31184743\n",
      "Iteration 26168, loss = 358.24646000\n",
      "Iteration 26169, loss = 358.18109921\n",
      "Iteration 26170, loss = 358.11576515\n",
      "Iteration 26171, loss = 358.05045809\n",
      "Iteration 26172, loss = 357.98517863\n",
      "Iteration 26173, loss = 357.91992815\n",
      "Iteration 26174, loss = 357.85470967\n",
      "Iteration 26175, loss = 357.78952918\n",
      "Iteration 26176, loss = 357.72439705\n",
      "Iteration 26177, loss = 357.65932075\n",
      "Iteration 26178, loss = 357.59428004\n",
      "Iteration 26179, loss = 357.52918735\n",
      "Iteration 26180, loss = 357.46399269\n",
      "Iteration 26181, loss = 357.39883287\n",
      "Iteration 26182, loss = 357.33385215\n",
      "Iteration 26183, loss = 357.26894845\n",
      "Iteration 26184, loss = 357.20395165\n",
      "Iteration 26185, loss = 357.13892144\n",
      "Iteration 26186, loss = 357.07402144\n",
      "Iteration 26187, loss = 357.00919447\n",
      "Iteration 26188, loss = 356.94430347\n",
      "Iteration 26189, loss = 356.87941425\n",
      "Iteration 26190, loss = 356.81463240\n",
      "Iteration 26191, loss = 356.74987763\n",
      "Iteration 26192, loss = 356.68508233\n",
      "Iteration 26193, loss = 356.62033317\n",
      "Iteration 26194, loss = 356.55565840\n",
      "Iteration 26195, loss = 356.49097670\n",
      "Iteration 26196, loss = 356.42629384\n",
      "Iteration 26197, loss = 356.36167444\n",
      "Iteration 26198, loss = 356.29708843\n",
      "Iteration 26199, loss = 356.23249494\n",
      "Iteration 26200, loss = 356.16793519\n",
      "Iteration 26201, loss = 356.10342523\n",
      "Iteration 26202, loss = 356.03892444\n",
      "Iteration 26203, loss = 355.97443727\n",
      "Iteration 26204, loss = 355.90999477\n",
      "Iteration 26205, loss = 355.84557952\n",
      "Iteration 26206, loss = 355.78117392\n",
      "Iteration 26207, loss = 355.71679998\n",
      "Iteration 26208, loss = 355.65246201\n",
      "Iteration 26209, loss = 355.58814013\n",
      "Iteration 26210, loss = 355.52383976\n",
      "Iteration 26211, loss = 355.45957449\n",
      "Iteration 26212, loss = 355.39533376\n",
      "Iteration 26213, loss = 355.33111123\n",
      "Iteration 26214, loss = 355.26691824\n",
      "Iteration 26215, loss = 355.20275480\n",
      "Iteration 26216, loss = 355.13861167\n",
      "Iteration 26217, loss = 355.07449286\n",
      "Iteration 26218, loss = 355.01040404\n",
      "Iteration 26219, loss = 354.94633942\n",
      "Iteration 26220, loss = 354.88229688\n",
      "Iteration 26221, loss = 354.81828195\n",
      "Iteration 26222, loss = 354.75429394\n",
      "Iteration 26223, loss = 354.69032859\n",
      "Iteration 26224, loss = 354.62638823\n",
      "Iteration 26225, loss = 354.56247525\n",
      "Iteration 26226, loss = 354.49858675\n",
      "Iteration 26227, loss = 354.43472191\n",
      "Iteration 26228, loss = 354.37088337\n",
      "Iteration 26229, loss = 354.30707068\n",
      "Iteration 26230, loss = 354.24328182\n",
      "Iteration 26231, loss = 354.17951792\n",
      "Iteration 26232, loss = 354.11578010\n",
      "Iteration 26233, loss = 354.05206698\n",
      "Iteration 26234, loss = 353.98837812\n",
      "Iteration 26235, loss = 353.92471476\n",
      "Iteration 26236, loss = 353.86107674\n",
      "Iteration 26237, loss = 353.79746307\n",
      "Iteration 26238, loss = 353.73387419\n",
      "Iteration 26239, loss = 353.67031069\n",
      "Iteration 26240, loss = 353.60677195\n",
      "Iteration 26241, loss = 353.54325768\n",
      "Iteration 26242, loss = 353.47976842\n",
      "Iteration 26243, loss = 353.41630418\n",
      "Iteration 26244, loss = 353.35286446\n",
      "Iteration 26245, loss = 353.28944938\n",
      "Iteration 26246, loss = 353.22605926\n",
      "Iteration 26247, loss = 353.16269385\n",
      "Iteration 26248, loss = 353.09935292\n",
      "Iteration 26249, loss = 353.03603670\n",
      "Iteration 26250, loss = 352.97274526\n",
      "Iteration 26251, loss = 352.90947835\n",
      "Iteration 26252, loss = 352.84623594\n",
      "Iteration 26253, loss = 352.78301819\n",
      "Iteration 26254, loss = 352.71982504\n",
      "Iteration 26255, loss = 352.65665633\n",
      "Iteration 26256, loss = 352.59351210\n",
      "Iteration 26257, loss = 352.53039244\n",
      "Iteration 26258, loss = 352.46729722\n",
      "Iteration 26259, loss = 352.40422639\n",
      "Iteration 26260, loss = 352.34118001\n",
      "Iteration 26261, loss = 352.27815806\n",
      "Iteration 26262, loss = 352.21516045\n",
      "Iteration 26263, loss = 352.15218718\n",
      "Iteration 26264, loss = 352.08923827\n",
      "Iteration 26265, loss = 352.02631368\n",
      "Iteration 26266, loss = 351.96341336\n",
      "Iteration 26267, loss = 351.90053731\n",
      "Iteration 26268, loss = 351.83768552\n",
      "Iteration 26269, loss = 351.77485797\n",
      "Iteration 26270, loss = 351.71205460\n",
      "Iteration 26271, loss = 351.64927542\n",
      "Iteration 26272, loss = 351.58652043\n",
      "Iteration 26273, loss = 351.52378956\n",
      "Iteration 26274, loss = 351.46108282\n",
      "Iteration 26275, loss = 351.39840018\n",
      "Iteration 26276, loss = 351.33574163\n",
      "Iteration 26277, loss = 351.27310713\n",
      "Iteration 26278, loss = 351.21049667\n",
      "Iteration 26279, loss = 351.14791024\n",
      "Iteration 26280, loss = 351.08534780\n",
      "Iteration 26281, loss = 351.02280934\n",
      "Iteration 26282, loss = 350.96029484\n",
      "Iteration 26283, loss = 350.89780427\n",
      "Iteration 26284, loss = 350.83533762\n",
      "Iteration 26285, loss = 350.77289487\n",
      "Iteration 26286, loss = 350.71047599\n",
      "Iteration 26287, loss = 350.64808097\n",
      "Iteration 26288, loss = 350.58570978\n",
      "Iteration 26289, loss = 350.52336240\n",
      "Iteration 26290, loss = 350.46103882\n",
      "Iteration 26291, loss = 350.39873902\n",
      "Iteration 26292, loss = 350.33646296\n",
      "Iteration 26293, loss = 350.27421064\n",
      "Iteration 26294, loss = 350.21198203\n",
      "Iteration 26295, loss = 350.14977712\n",
      "Iteration 26296, loss = 350.08759588\n",
      "Iteration 26297, loss = 350.02543829\n",
      "Iteration 26298, loss = 349.96330433\n",
      "Iteration 26299, loss = 349.90119399\n",
      "Iteration 26300, loss = 349.83910724\n",
      "Iteration 26301, loss = 349.77704406\n",
      "Iteration 26302, loss = 349.71500443\n",
      "Iteration 26303, loss = 349.65298834\n",
      "Iteration 26304, loss = 349.59099576\n",
      "Iteration 26305, loss = 349.52902668\n",
      "Iteration 26306, loss = 349.46708106\n",
      "Iteration 26307, loss = 349.40515891\n",
      "Iteration 26308, loss = 349.34326018\n",
      "Iteration 26309, loss = 349.28138487\n",
      "Iteration 26310, loss = 349.21953296\n",
      "Iteration 26311, loss = 349.15770442\n",
      "Iteration 26312, loss = 349.09589924\n",
      "Iteration 26313, loss = 349.03411739\n",
      "Iteration 26314, loss = 348.97235886\n",
      "Iteration 26315, loss = 348.91062362\n",
      "Iteration 26316, loss = 348.84891167\n",
      "Iteration 26317, loss = 348.78722297\n",
      "Iteration 26318, loss = 348.72555751\n",
      "Iteration 26319, loss = 348.66391527\n",
      "Iteration 26320, loss = 348.60229624\n",
      "Iteration 26321, loss = 348.54070038\n",
      "Iteration 26322, loss = 348.47912768\n",
      "Iteration 26323, loss = 348.41757813\n",
      "Iteration 26324, loss = 348.35605170\n",
      "Iteration 26325, loss = 348.29454838\n",
      "Iteration 26326, loss = 348.23306814\n",
      "Iteration 26327, loss = 348.17161097\n",
      "Iteration 26328, loss = 348.11017684\n",
      "Iteration 26329, loss = 348.04876574\n",
      "Iteration 26330, loss = 347.98737765\n",
      "Iteration 26331, loss = 347.92601256\n",
      "Iteration 26332, loss = 347.86467043\n",
      "Iteration 26333, loss = 347.80335125\n",
      "Iteration 26334, loss = 347.74205501\n",
      "Iteration 26335, loss = 347.68078169\n",
      "Iteration 26336, loss = 347.61953126\n",
      "Iteration 26337, loss = 347.55830370\n",
      "Iteration 26338, loss = 347.49709901\n",
      "Iteration 26339, loss = 347.43591715\n",
      "Iteration 26340, loss = 347.37475812\n",
      "Iteration 26341, loss = 347.31362189\n",
      "Iteration 26342, loss = 347.25250844\n",
      "Iteration 26343, loss = 347.19141776\n",
      "Iteration 26344, loss = 347.13034982\n",
      "Iteration 26345, loss = 347.06930461\n",
      "Iteration 26346, loss = 347.00828211\n",
      "Iteration 26347, loss = 346.94728231\n",
      "Iteration 26348, loss = 346.88630517\n",
      "Iteration 26349, loss = 346.82535069\n",
      "Iteration 26350, loss = 346.76441885\n",
      "Iteration 26351, loss = 346.70350963\n",
      "Iteration 26352, loss = 346.64262300\n",
      "Iteration 26353, loss = 346.58175895\n",
      "Iteration 26354, loss = 346.52091747\n",
      "Iteration 26355, loss = 346.46009853\n",
      "Iteration 26356, loss = 346.39930212\n",
      "Iteration 26357, loss = 346.33852822\n",
      "Iteration 26358, loss = 346.27777681\n",
      "Iteration 26359, loss = 346.21704787\n",
      "Iteration 26360, loss = 346.15634138\n",
      "Iteration 26361, loss = 346.09565733\n",
      "Iteration 26362, loss = 346.03499570\n",
      "Iteration 26363, loss = 345.97435647\n",
      "Iteration 26364, loss = 345.91373962\n",
      "Iteration 26365, loss = 345.85314513\n",
      "Iteration 26366, loss = 345.79257300\n",
      "Iteration 26367, loss = 345.73202318\n",
      "Iteration 26368, loss = 345.67149568\n",
      "Iteration 26369, loss = 345.61099048\n",
      "Iteration 26370, loss = 345.55050755\n",
      "Iteration 26371, loss = 345.49004687\n",
      "Iteration 26372, loss = 345.42960844\n",
      "Iteration 26373, loss = 345.36919222\n",
      "Iteration 26374, loss = 345.30879821\n",
      "Iteration 26375, loss = 345.24842639\n",
      "Iteration 26376, loss = 345.18807674\n",
      "Iteration 26377, loss = 345.12774924\n",
      "Iteration 26378, loss = 345.06744387\n",
      "Iteration 26379, loss = 345.00716062\n",
      "Iteration 26380, loss = 344.94689947\n",
      "Iteration 26381, loss = 344.88666040\n",
      "Iteration 26382, loss = 344.82644339\n",
      "Iteration 26383, loss = 344.76624843\n",
      "Iteration 26384, loss = 344.70607550\n",
      "Iteration 26385, loss = 344.64592458\n",
      "Iteration 26386, loss = 344.58579566\n",
      "Iteration 26387, loss = 344.52568871\n",
      "Iteration 26388, loss = 344.46560372\n",
      "Iteration 26389, loss = 344.40554068\n",
      "Iteration 26390, loss = 344.34549956\n",
      "Iteration 26391, loss = 344.28548035\n",
      "Iteration 26392, loss = 344.22548304\n",
      "Iteration 26393, loss = 344.16550759\n",
      "Iteration 26394, loss = 344.10555400\n",
      "Iteration 26395, loss = 344.04562226\n",
      "Iteration 26396, loss = 343.98571233\n",
      "Iteration 26397, loss = 343.92582422\n",
      "Iteration 26398, loss = 343.86595789\n",
      "Iteration 26399, loss = 343.80611333\n",
      "Iteration 26400, loss = 343.74629053\n",
      "Iteration 26401, loss = 343.68648947\n",
      "Iteration 26402, loss = 343.62671012\n",
      "Iteration 26403, loss = 343.56695249\n",
      "Iteration 26404, loss = 343.50721654\n",
      "Iteration 26405, loss = 343.44750226\n",
      "Iteration 26406, loss = 343.38780963\n",
      "Iteration 26407, loss = 343.32813865\n",
      "Iteration 26408, loss = 343.26848928\n",
      "Iteration 26409, loss = 343.20886152\n",
      "Iteration 26410, loss = 343.14925534\n",
      "Iteration 26411, loss = 343.08967074\n",
      "Iteration 26412, loss = 343.03010769\n",
      "Iteration 26413, loss = 342.97056617\n",
      "Iteration 26414, loss = 342.91104618\n",
      "Iteration 26415, loss = 342.85154769\n",
      "Iteration 26416, loss = 342.79207069\n",
      "Iteration 26417, loss = 342.73261516\n",
      "Iteration 26418, loss = 342.67318109\n",
      "Iteration 26419, loss = 342.61376846\n",
      "Iteration 26420, loss = 342.55437724\n",
      "Iteration 26421, loss = 342.49500744\n",
      "Iteration 26422, loss = 342.43565902\n",
      "Iteration 26423, loss = 342.37633197\n",
      "Iteration 26424, loss = 342.31702628\n",
      "Iteration 26425, loss = 342.25774194\n",
      "Iteration 26426, loss = 342.19847891\n",
      "Iteration 26427, loss = 342.13923720\n",
      "Iteration 26428, loss = 342.08001677\n",
      "Iteration 26429, loss = 342.02081763\n",
      "Iteration 26430, loss = 341.96163974\n",
      "Iteration 26431, loss = 341.90248309\n",
      "Iteration 26432, loss = 341.84334768\n",
      "Iteration 26433, loss = 341.78423347\n",
      "Iteration 26434, loss = 341.72514046\n",
      "Iteration 26435, loss = 341.66606863\n",
      "Iteration 26436, loss = 341.60701796\n",
      "Iteration 26437, loss = 341.54798844\n",
      "Iteration 26438, loss = 341.48898005\n",
      "Iteration 26439, loss = 341.42999277\n",
      "Iteration 26440, loss = 341.37102660\n",
      "Iteration 26441, loss = 341.31208150\n",
      "Iteration 26442, loss = 341.25315748\n",
      "Iteration 26443, loss = 341.19425451\n",
      "Iteration 26444, loss = 341.13537257\n",
      "Iteration 26445, loss = 341.07651165\n",
      "Iteration 26446, loss = 341.01767174\n",
      "Iteration 26447, loss = 340.95885282\n",
      "Iteration 26448, loss = 340.90005487\n",
      "Iteration 26449, loss = 340.84127788\n",
      "Iteration 26450, loss = 340.78252183\n",
      "Iteration 26451, loss = 340.72378671\n",
      "Iteration 26452, loss = 340.66507249\n",
      "Iteration 26453, loss = 340.60637918\n",
      "Iteration 26454, loss = 340.54770674\n",
      "Iteration 26455, loss = 340.48905516\n",
      "Iteration 26456, loss = 340.43042444\n",
      "Iteration 26457, loss = 340.37181454\n",
      "Iteration 26458, loss = 340.31322547\n",
      "Iteration 26459, loss = 340.25465720\n",
      "Iteration 26460, loss = 340.19610971\n",
      "Iteration 26461, loss = 340.13758299\n",
      "Iteration 26462, loss = 340.07907704\n",
      "Iteration 26463, loss = 340.02059182\n",
      "Iteration 26464, loss = 339.96212732\n",
      "Iteration 26465, loss = 339.90368354\n",
      "Iteration 26466, loss = 339.84526045\n",
      "Iteration 26467, loss = 339.78685804\n",
      "Iteration 26468, loss = 339.72847630\n",
      "Iteration 26469, loss = 339.67011520\n",
      "Iteration 26470, loss = 339.61177474\n",
      "Iteration 26471, loss = 339.55345490\n",
      "Iteration 26472, loss = 339.49515566\n",
      "Iteration 26473, loss = 339.43687701\n",
      "Iteration 26474, loss = 339.37861893\n",
      "Iteration 26475, loss = 339.32038141\n",
      "Iteration 26476, loss = 339.26216443\n",
      "Iteration 26477, loss = 339.20396799\n",
      "Iteration 26478, loss = 339.14579205\n",
      "Iteration 26479, loss = 339.08763662\n",
      "Iteration 26480, loss = 339.02950167\n",
      "Iteration 26481, loss = 338.97138718\n",
      "Iteration 26482, loss = 338.91329315\n",
      "Iteration 26483, loss = 338.85521956\n",
      "Iteration 26484, loss = 338.79716639\n",
      "Iteration 26485, loss = 338.73913364\n",
      "Iteration 26486, loss = 338.68112127\n",
      "Iteration 26487, loss = 338.62312929\n",
      "Iteration 26488, loss = 338.56515767\n",
      "Iteration 26489, loss = 338.50720640\n",
      "Iteration 26490, loss = 338.44927546\n",
      "Iteration 26491, loss = 338.39136485\n",
      "Iteration 26492, loss = 338.33347454\n",
      "Iteration 26493, loss = 338.27560452\n",
      "Iteration 26494, loss = 338.21775478\n",
      "Iteration 26495, loss = 338.15992530\n",
      "Iteration 26496, loss = 338.10211607\n",
      "Iteration 26497, loss = 338.04432708\n",
      "Iteration 26498, loss = 337.98655830\n",
      "Iteration 26499, loss = 337.92880972\n",
      "Iteration 26500, loss = 337.87108133\n",
      "Iteration 26501, loss = 337.81337312\n",
      "Iteration 26502, loss = 337.75568507\n",
      "Iteration 26503, loss = 337.69801716\n",
      "Iteration 26504, loss = 337.64036939\n",
      "Iteration 26505, loss = 337.58274173\n",
      "Iteration 26506, loss = 337.52513418\n",
      "Iteration 26507, loss = 337.46754671\n",
      "Iteration 26508, loss = 337.40997932\n",
      "Iteration 26509, loss = 337.35243199\n",
      "Iteration 26510, loss = 337.29490470\n",
      "Iteration 26511, loss = 337.23739745\n",
      "Iteration 26512, loss = 337.17991021\n",
      "Iteration 26513, loss = 337.12244297\n",
      "Iteration 26514, loss = 337.06499573\n",
      "Iteration 26515, loss = 337.00756845\n",
      "Iteration 26516, loss = 336.95016114\n",
      "Iteration 26517, loss = 336.89277378\n",
      "Iteration 26518, loss = 336.83540634\n",
      "Iteration 26519, loss = 336.77805882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26520, loss = 336.72073121\n",
      "Iteration 26521, loss = 336.66342349\n",
      "Iteration 26522, loss = 336.60613564\n",
      "Iteration 26523, loss = 336.54886766\n",
      "Iteration 26524, loss = 336.49161952\n",
      "Iteration 26525, loss = 336.43439122\n",
      "Iteration 26526, loss = 336.37718273\n",
      "Iteration 26527, loss = 336.31999406\n",
      "Iteration 26528, loss = 336.26282517\n",
      "Iteration 26529, loss = 336.20567606\n",
      "Iteration 26530, loss = 336.14854672\n",
      "Iteration 26531, loss = 336.09143713\n",
      "Iteration 26532, loss = 336.03434727\n",
      "Iteration 26533, loss = 335.97727714\n",
      "Iteration 26534, loss = 335.92022671\n",
      "Iteration 26535, loss = 335.86319598\n",
      "Iteration 26536, loss = 335.80618494\n",
      "Iteration 26537, loss = 335.74919356\n",
      "Iteration 26538, loss = 335.69222183\n",
      "Iteration 26539, loss = 335.63526975\n",
      "Iteration 26540, loss = 335.57833729\n",
      "Iteration 26541, loss = 335.52142444\n",
      "Iteration 26542, loss = 335.46453120\n",
      "Iteration 26543, loss = 335.40765754\n",
      "Iteration 26544, loss = 335.35080345\n",
      "Iteration 26545, loss = 335.29396892\n",
      "Iteration 26546, loss = 335.23715394\n",
      "Iteration 26547, loss = 335.18035849\n",
      "Iteration 26548, loss = 335.12358255\n",
      "Iteration 26549, loss = 335.06682612\n",
      "Iteration 26550, loss = 335.01008919\n",
      "Iteration 26551, loss = 334.95337173\n",
      "Iteration 26552, loss = 334.89667373\n",
      "Iteration 26553, loss = 334.83999519\n",
      "Iteration 26554, loss = 334.78333608\n",
      "Iteration 26555, loss = 334.72669640\n",
      "Iteration 26556, loss = 334.67007613\n",
      "Iteration 26557, loss = 334.61347525\n",
      "Iteration 26558, loss = 334.55689376\n",
      "Iteration 26559, loss = 334.50033164\n",
      "Iteration 26560, loss = 334.44378888\n",
      "Iteration 26561, loss = 334.38726547\n",
      "Iteration 26562, loss = 334.33076138\n",
      "Iteration 26563, loss = 334.27427661\n",
      "Iteration 26564, loss = 334.21781115\n",
      "Iteration 26565, loss = 334.16136498\n",
      "Iteration 26566, loss = 334.10493809\n",
      "Iteration 26567, loss = 334.04853046\n",
      "Iteration 26568, loss = 333.99214209\n",
      "Iteration 26569, loss = 333.93577295\n",
      "Iteration 26570, loss = 333.87942304\n",
      "Iteration 26571, loss = 333.82309235\n",
      "Iteration 26572, loss = 333.76678085\n",
      "Iteration 26573, loss = 333.71048854\n",
      "Iteration 26574, loss = 333.65421540\n",
      "Iteration 26575, loss = 333.59796143\n",
      "Iteration 26576, loss = 333.54172660\n",
      "Iteration 26577, loss = 333.48551091\n",
      "Iteration 26578, loss = 333.42931434\n",
      "Iteration 26579, loss = 333.37313689\n",
      "Iteration 26580, loss = 333.31697852\n",
      "Iteration 26581, loss = 333.26083924\n",
      "Iteration 26582, loss = 333.20471903\n",
      "Iteration 26583, loss = 333.14861788\n",
      "Iteration 26584, loss = 333.09253578\n",
      "Iteration 26585, loss = 333.03647270\n",
      "Iteration 26586, loss = 332.98042865\n",
      "Iteration 26587, loss = 332.92440360\n",
      "Iteration 26588, loss = 332.86839755\n",
      "Iteration 26589, loss = 332.81241047\n",
      "Iteration 26590, loss = 332.75644237\n",
      "Iteration 26591, loss = 332.70049322\n",
      "Iteration 26592, loss = 332.64456301\n",
      "Iteration 26593, loss = 332.58865174\n",
      "Iteration 26594, loss = 332.53275938\n",
      "Iteration 26595, loss = 332.47688593\n",
      "Iteration 26596, loss = 332.42103137\n",
      "Iteration 26597, loss = 332.36519569\n",
      "Iteration 26598, loss = 332.30937888\n",
      "Iteration 26599, loss = 332.25358092\n",
      "Iteration 26600, loss = 332.19780181\n",
      "Iteration 26601, loss = 332.14204153\n",
      "Iteration 26602, loss = 332.08630006\n",
      "Iteration 26603, loss = 332.03057740\n",
      "Iteration 26604, loss = 331.97487353\n",
      "Iteration 26605, loss = 331.91918844\n",
      "Iteration 26606, loss = 331.86352212\n",
      "Iteration 26607, loss = 331.80787455\n",
      "Iteration 26608, loss = 331.75224573\n",
      "Iteration 26609, loss = 331.69663563\n",
      "Iteration 26610, loss = 331.64104426\n",
      "Iteration 26611, loss = 331.58547159\n",
      "Iteration 26612, loss = 331.52991761\n",
      "Iteration 26613, loss = 331.47438232\n",
      "Iteration 26614, loss = 331.41886569\n",
      "Iteration 26615, loss = 331.36336772\n",
      "Iteration 26616, loss = 331.30788840\n",
      "Iteration 26617, loss = 331.25242771\n",
      "Iteration 26618, loss = 331.19698563\n",
      "Iteration 26619, loss = 331.14156217\n",
      "Iteration 26620, loss = 331.08615730\n",
      "Iteration 26621, loss = 331.03077101\n",
      "Iteration 26622, loss = 330.97540330\n",
      "Iteration 26623, loss = 330.92005414\n",
      "Iteration 26624, loss = 330.86472353\n",
      "Iteration 26625, loss = 330.80941146\n",
      "Iteration 26626, loss = 330.75411791\n",
      "Iteration 26627, loss = 330.69884287\n",
      "Iteration 26628, loss = 330.64358633\n",
      "Iteration 26629, loss = 330.58834828\n",
      "Iteration 26630, loss = 330.53312870\n",
      "Iteration 26631, loss = 330.47792758\n",
      "Iteration 26632, loss = 330.42274492\n",
      "Iteration 26633, loss = 330.36758069\n",
      "Iteration 26634, loss = 330.31243490\n",
      "Iteration 26635, loss = 330.25730753\n",
      "Iteration 26636, loss = 330.20219859\n",
      "Iteration 26637, loss = 330.14710808\n",
      "Iteration 26638, loss = 330.09203604\n",
      "Iteration 26639, loss = 330.03698258\n",
      "Iteration 26640, loss = 329.98194792\n",
      "Iteration 26641, loss = 329.92693261\n",
      "Iteration 26642, loss = 329.87193781\n",
      "Iteration 26643, loss = 329.81696608\n",
      "Iteration 26644, loss = 329.76202247\n",
      "Iteration 26645, loss = 329.70711632\n",
      "Iteration 26646, loss = 329.65225702\n",
      "Iteration 26647, loss = 329.59743774\n",
      "Iteration 26648, loss = 329.54258936\n",
      "Iteration 26649, loss = 329.48763158\n",
      "Iteration 26650, loss = 329.43263253\n",
      "Iteration 26651, loss = 329.37777689\n",
      "Iteration 26652, loss = 329.32305577\n",
      "Iteration 26653, loss = 329.26828443\n",
      "Iteration 26654, loss = 329.21341503\n",
      "Iteration 26655, loss = 329.15861187\n",
      "Iteration 26656, loss = 329.10392998\n",
      "Iteration 26657, loss = 329.04922443\n",
      "Iteration 26658, loss = 328.99445493\n",
      "Iteration 26659, loss = 328.93975134\n",
      "Iteration 26660, loss = 328.88512609\n",
      "Iteration 26661, loss = 328.83046792\n",
      "Iteration 26662, loss = 328.77579134\n",
      "Iteration 26663, loss = 328.72118517\n",
      "Iteration 26664, loss = 328.66661257\n",
      "Iteration 26665, loss = 328.61201116\n",
      "Iteration 26666, loss = 328.55743069\n",
      "Iteration 26667, loss = 328.50290604\n",
      "Iteration 26668, loss = 328.44838437\n",
      "Iteration 26669, loss = 328.39385562\n",
      "Iteration 26670, loss = 328.33936673\n",
      "Iteration 26671, loss = 328.28490834\n",
      "Iteration 26672, loss = 328.23044567\n",
      "Iteration 26673, loss = 328.17599964\n",
      "Iteration 26674, loss = 328.12159037\n",
      "Iteration 26675, loss = 328.06719297\n",
      "Iteration 26676, loss = 328.01280081\n",
      "Iteration 26677, loss = 327.95843670\n",
      "Iteration 26678, loss = 327.90409693\n",
      "Iteration 26679, loss = 327.84976444\n",
      "Iteration 26680, loss = 327.79544896\n",
      "Iteration 26681, loss = 327.74116043\n",
      "Iteration 26682, loss = 327.68688700\n",
      "Iteration 26683, loss = 327.63262524\n",
      "Iteration 26684, loss = 327.57838610\n",
      "Iteration 26685, loss = 327.52416801\n",
      "Iteration 26686, loss = 327.46996269\n",
      "Iteration 26687, loss = 327.41577459\n",
      "Iteration 26688, loss = 327.36160867\n",
      "Iteration 26689, loss = 327.30745941\n",
      "Iteration 26690, loss = 327.25332485\n",
      "Iteration 26691, loss = 327.19921018\n",
      "Iteration 26692, loss = 327.14511501\n",
      "Iteration 26693, loss = 327.09103526\n",
      "Iteration 26694, loss = 327.03697272\n",
      "Iteration 26695, loss = 326.98293001\n",
      "Iteration 26696, loss = 326.92890471\n",
      "Iteration 26697, loss = 326.87489554\n",
      "Iteration 26698, loss = 326.82090489\n",
      "Iteration 26699, loss = 326.76693292\n",
      "Iteration 26700, loss = 326.71297764\n",
      "Iteration 26701, loss = 326.65903955\n",
      "Iteration 26702, loss = 326.60512009\n",
      "Iteration 26703, loss = 326.55121833\n",
      "Iteration 26704, loss = 326.49733341\n",
      "Iteration 26705, loss = 326.44346631\n",
      "Iteration 26706, loss = 326.38961741\n",
      "Iteration 26707, loss = 326.33578576\n",
      "Iteration 26708, loss = 326.28197133\n",
      "Iteration 26709, loss = 326.22817488\n",
      "Iteration 26710, loss = 326.17439617\n",
      "Iteration 26711, loss = 326.12063465\n",
      "Iteration 26712, loss = 326.06689063\n",
      "Iteration 26713, loss = 326.01316447\n",
      "Iteration 26714, loss = 325.95945576\n",
      "Iteration 26715, loss = 325.90576433\n",
      "Iteration 26716, loss = 325.85209052\n",
      "Iteration 26717, loss = 325.79843436\n",
      "Iteration 26718, loss = 325.74479555\n",
      "Iteration 26719, loss = 325.69117411\n",
      "Iteration 26720, loss = 325.63757026\n",
      "Iteration 26721, loss = 325.58398390\n",
      "Iteration 26722, loss = 325.53041487\n",
      "Iteration 26723, loss = 325.47686325\n",
      "Iteration 26724, loss = 325.42332915\n",
      "Iteration 26725, loss = 325.36981243\n",
      "Iteration 26726, loss = 325.31631304\n",
      "Iteration 26727, loss = 325.26283106\n",
      "Iteration 26728, loss = 325.20936651\n",
      "Iteration 26729, loss = 325.15591929\n",
      "Iteration 26730, loss = 325.10248939\n",
      "Iteration 26731, loss = 325.04907686\n",
      "Iteration 26732, loss = 324.99568169\n",
      "Iteration 26733, loss = 324.94230380\n",
      "Iteration 26734, loss = 324.88894322\n",
      "Iteration 26735, loss = 324.83559996\n",
      "Iteration 26736, loss = 324.78227400\n",
      "Iteration 26737, loss = 324.72896530\n",
      "Iteration 26738, loss = 324.67567386\n",
      "Iteration 26739, loss = 324.62239970\n",
      "Iteration 26740, loss = 324.56914279\n",
      "Iteration 26741, loss = 324.51590311\n",
      "Iteration 26742, loss = 324.46268065\n",
      "Iteration 26743, loss = 324.40947543\n",
      "Iteration 26744, loss = 324.35628740\n",
      "Iteration 26745, loss = 324.30311657\n",
      "Iteration 26746, loss = 324.24996292\n",
      "Iteration 26747, loss = 324.19682646\n",
      "Iteration 26748, loss = 324.14370716\n",
      "Iteration 26749, loss = 324.09060502\n",
      "Iteration 26750, loss = 324.03752002\n",
      "Iteration 26751, loss = 323.98445216\n",
      "Iteration 26752, loss = 323.93140143\n",
      "Iteration 26753, loss = 323.87836780\n",
      "Iteration 26754, loss = 323.82535129\n",
      "Iteration 26755, loss = 323.77235187\n",
      "Iteration 26756, loss = 323.71936953\n",
      "Iteration 26757, loss = 323.66640427\n",
      "Iteration 26758, loss = 323.61345608\n",
      "Iteration 26759, loss = 323.56052494\n",
      "Iteration 26760, loss = 323.50761084\n",
      "Iteration 26761, loss = 323.45471377\n",
      "Iteration 26762, loss = 323.40183373\n",
      "Iteration 26763, loss = 323.34897071\n",
      "Iteration 26764, loss = 323.29612469\n",
      "Iteration 26765, loss = 323.24329566\n",
      "Iteration 26766, loss = 323.19048362\n",
      "Iteration 26767, loss = 323.13768855\n",
      "Iteration 26768, loss = 323.08491045\n",
      "Iteration 26769, loss = 323.03214930\n",
      "Iteration 26770, loss = 322.97940509\n",
      "Iteration 26771, loss = 322.92667782\n",
      "Iteration 26772, loss = 322.87396747\n",
      "Iteration 26773, loss = 322.82127404\n",
      "Iteration 26774, loss = 322.76859751\n",
      "Iteration 26775, loss = 322.71593788\n",
      "Iteration 26776, loss = 322.66329513\n",
      "Iteration 26777, loss = 322.61066925\n",
      "Iteration 26778, loss = 322.55806024\n",
      "Iteration 26779, loss = 322.50546809\n",
      "Iteration 26780, loss = 322.45289278\n",
      "Iteration 26781, loss = 322.40033431\n",
      "Iteration 26782, loss = 322.34779266\n",
      "Iteration 26783, loss = 322.29526783\n",
      "Iteration 26784, loss = 322.24275980\n",
      "Iteration 26785, loss = 322.19026857\n",
      "Iteration 26786, loss = 322.13779413\n",
      "Iteration 26787, loss = 322.08533646\n",
      "Iteration 26788, loss = 322.03289556\n",
      "Iteration 26789, loss = 321.98047142\n",
      "Iteration 26790, loss = 321.92806402\n",
      "Iteration 26791, loss = 321.87567337\n",
      "Iteration 26792, loss = 321.82329944\n",
      "Iteration 26793, loss = 321.77094223\n",
      "Iteration 26794, loss = 321.71860173\n",
      "Iteration 26795, loss = 321.66627793\n",
      "Iteration 26796, loss = 321.61397081\n",
      "Iteration 26797, loss = 321.56168038\n",
      "Iteration 26798, loss = 321.50940662\n",
      "Iteration 26799, loss = 321.45714952\n",
      "Iteration 26800, loss = 321.40490907\n",
      "Iteration 26801, loss = 321.35268526\n",
      "Iteration 26802, loss = 321.30047808\n",
      "Iteration 26803, loss = 321.24828753\n",
      "Iteration 26804, loss = 321.19611359\n",
      "Iteration 26805, loss = 321.14395625\n",
      "Iteration 26806, loss = 321.09181551\n",
      "Iteration 26807, loss = 321.03969135\n",
      "Iteration 26808, loss = 320.98758376\n",
      "Iteration 26809, loss = 320.93549275\n",
      "Iteration 26810, loss = 320.88341828\n",
      "Iteration 26811, loss = 320.83136037\n",
      "Iteration 26812, loss = 320.77931899\n",
      "Iteration 26813, loss = 320.72729414\n",
      "Iteration 26814, loss = 320.67528580\n",
      "Iteration 26815, loss = 320.62329398\n",
      "Iteration 26816, loss = 320.57131865\n",
      "Iteration 26817, loss = 320.51935982\n",
      "Iteration 26818, loss = 320.46741746\n",
      "Iteration 26819, loss = 320.41549158\n",
      "Iteration 26820, loss = 320.36358216\n",
      "Iteration 26821, loss = 320.31168919\n",
      "Iteration 26822, loss = 320.25981266\n",
      "Iteration 26823, loss = 320.20795257\n",
      "Iteration 26824, loss = 320.15610890\n",
      "Iteration 26825, loss = 320.10428165\n",
      "Iteration 26826, loss = 320.05247080\n",
      "Iteration 26827, loss = 320.00067635\n",
      "Iteration 26828, loss = 319.94889829\n",
      "Iteration 26829, loss = 319.89713661\n",
      "Iteration 26830, loss = 319.84539129\n",
      "Iteration 26831, loss = 319.79366234\n",
      "Iteration 26832, loss = 319.74194973\n",
      "Iteration 26833, loss = 319.69025347\n",
      "Iteration 26834, loss = 319.63857354\n",
      "Iteration 26835, loss = 319.58690993\n",
      "Iteration 26836, loss = 319.53526264\n",
      "Iteration 26837, loss = 319.48363165\n",
      "Iteration 26838, loss = 319.43201695\n",
      "Iteration 26839, loss = 319.38041855\n",
      "Iteration 26840, loss = 319.32883642\n",
      "Iteration 26841, loss = 319.27727055\n",
      "Iteration 26842, loss = 319.22572095\n",
      "Iteration 26843, loss = 319.17418760\n",
      "Iteration 26844, loss = 319.12267048\n",
      "Iteration 26845, loss = 319.07116960\n",
      "Iteration 26846, loss = 319.01968495\n",
      "Iteration 26847, loss = 318.96821650\n",
      "Iteration 26848, loss = 318.91676426\n",
      "Iteration 26849, loss = 318.86532822\n",
      "Iteration 26850, loss = 318.81390836\n",
      "Iteration 26851, loss = 318.76250468\n",
      "Iteration 26852, loss = 318.71111717\n",
      "Iteration 26853, loss = 318.65974582\n",
      "Iteration 26854, loss = 318.60839062\n",
      "Iteration 26855, loss = 318.55705156\n",
      "Iteration 26856, loss = 318.50572863\n",
      "Iteration 26857, loss = 318.45442183\n",
      "Iteration 26858, loss = 318.40313114\n",
      "Iteration 26859, loss = 318.35185656\n",
      "Iteration 26860, loss = 318.30059808\n",
      "Iteration 26861, loss = 318.24935568\n",
      "Iteration 26862, loss = 318.19812936\n",
      "Iteration 26863, loss = 318.14691912\n",
      "Iteration 26864, loss = 318.09572493\n",
      "Iteration 26865, loss = 318.04454680\n",
      "Iteration 26866, loss = 317.99338471\n",
      "Iteration 26867, loss = 317.94223866\n",
      "Iteration 26868, loss = 317.89110863\n",
      "Iteration 26869, loss = 317.83999462\n",
      "Iteration 26870, loss = 317.78889662\n",
      "Iteration 26871, loss = 317.73781461\n",
      "Iteration 26872, loss = 317.68674860\n",
      "Iteration 26873, loss = 317.63569858\n",
      "Iteration 26874, loss = 317.58466452\n",
      "Iteration 26875, loss = 317.53364643\n",
      "Iteration 26876, loss = 317.48264430\n",
      "Iteration 26877, loss = 317.43165811\n",
      "Iteration 26878, loss = 317.38068786\n",
      "Iteration 26879, loss = 317.32973354\n",
      "Iteration 26880, loss = 317.27879515\n",
      "Iteration 26881, loss = 317.22787266\n",
      "Iteration 26882, loss = 317.17696608\n",
      "Iteration 26883, loss = 317.12607540\n",
      "Iteration 26884, loss = 317.07520060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26885, loss = 317.02434168\n",
      "Iteration 26886, loss = 316.97349862\n",
      "Iteration 26887, loss = 316.92267143\n",
      "Iteration 26888, loss = 316.87186009\n",
      "Iteration 26889, loss = 316.82106460\n",
      "Iteration 26890, loss = 316.77028494\n",
      "Iteration 26891, loss = 316.71952110\n",
      "Iteration 26892, loss = 316.66877308\n",
      "Iteration 26893, loss = 316.61804088\n",
      "Iteration 26894, loss = 316.56732447\n",
      "Iteration 26895, loss = 316.51662385\n",
      "Iteration 26896, loss = 316.46593902\n",
      "Iteration 26897, loss = 316.41526996\n",
      "Iteration 26898, loss = 316.36461667\n",
      "Iteration 26899, loss = 316.31397914\n",
      "Iteration 26900, loss = 316.26335736\n",
      "Iteration 26901, loss = 316.21275131\n",
      "Iteration 26902, loss = 316.16216100\n",
      "Iteration 26903, loss = 316.11158642\n",
      "Iteration 26904, loss = 316.06102755\n",
      "Iteration 26905, loss = 316.01048439\n",
      "Iteration 26906, loss = 315.95995692\n",
      "Iteration 26907, loss = 315.90944515\n",
      "Iteration 26908, loss = 315.85894906\n",
      "Iteration 26909, loss = 315.80846864\n",
      "Iteration 26910, loss = 315.75800388\n",
      "Iteration 26911, loss = 315.70755479\n",
      "Iteration 26912, loss = 315.65712134\n",
      "Iteration 26913, loss = 315.60670353\n",
      "Iteration 26914, loss = 315.55630135\n",
      "Iteration 26915, loss = 315.50591480\n",
      "Iteration 26916, loss = 315.45554386\n",
      "Iteration 26917, loss = 315.40518853\n",
      "Iteration 26918, loss = 315.35484880\n",
      "Iteration 26919, loss = 315.30452465\n",
      "Iteration 26920, loss = 315.25421609\n",
      "Iteration 26921, loss = 315.20392310\n",
      "Iteration 26922, loss = 315.15364568\n",
      "Iteration 26923, loss = 315.10338381\n",
      "Iteration 26924, loss = 315.05313749\n",
      "Iteration 26925, loss = 315.00290672\n",
      "Iteration 26926, loss = 314.95269147\n",
      "Iteration 26927, loss = 314.90249175\n",
      "Iteration 26928, loss = 314.85230755\n",
      "Iteration 26929, loss = 314.80213885\n",
      "Iteration 26930, loss = 314.75198565\n",
      "Iteration 26931, loss = 314.70184794\n",
      "Iteration 26932, loss = 314.65172572\n",
      "Iteration 26933, loss = 314.60161897\n",
      "Iteration 26934, loss = 314.55152768\n",
      "Iteration 26935, loss = 314.50145186\n",
      "Iteration 26936, loss = 314.45139148\n",
      "Iteration 26937, loss = 314.40134655\n",
      "Iteration 26938, loss = 314.35131705\n",
      "Iteration 26939, loss = 314.30130298\n",
      "Iteration 26940, loss = 314.25130433\n",
      "Iteration 26941, loss = 314.20132108\n",
      "Iteration 26942, loss = 314.15135324\n",
      "Iteration 26943, loss = 314.10140079\n",
      "Iteration 26944, loss = 314.05146373\n",
      "Iteration 26945, loss = 314.00154204\n",
      "Iteration 26946, loss = 313.95163572\n",
      "Iteration 26947, loss = 313.90174477\n",
      "Iteration 26948, loss = 313.85186916\n",
      "Iteration 26949, loss = 313.80200891\n",
      "Iteration 26950, loss = 313.75216399\n",
      "Iteration 26951, loss = 313.70233440\n",
      "Iteration 26952, loss = 313.65252013\n",
      "Iteration 26953, loss = 313.60272117\n",
      "Iteration 26954, loss = 313.55293752\n",
      "Iteration 26955, loss = 313.50316917\n",
      "Iteration 26956, loss = 313.45341610\n",
      "Iteration 26957, loss = 313.40367832\n",
      "Iteration 26958, loss = 313.35395581\n",
      "Iteration 26959, loss = 313.30424857\n",
      "Iteration 26960, loss = 313.25455658\n",
      "Iteration 26961, loss = 313.20487985\n",
      "Iteration 26962, loss = 313.15521835\n",
      "Iteration 26963, loss = 313.10557210\n",
      "Iteration 26964, loss = 313.05594106\n",
      "Iteration 26965, loss = 313.00632525\n",
      "Iteration 26966, loss = 312.95672464\n",
      "Iteration 26967, loss = 312.90713924\n",
      "Iteration 26968, loss = 312.85756903\n",
      "Iteration 26969, loss = 312.80801401\n",
      "Iteration 26970, loss = 312.75847417\n",
      "Iteration 26971, loss = 312.70894949\n",
      "Iteration 26972, loss = 312.65943999\n",
      "Iteration 26973, loss = 312.60994563\n",
      "Iteration 26974, loss = 312.56046643\n",
      "Iteration 26975, loss = 312.51100236\n",
      "Iteration 26976, loss = 312.46155343\n",
      "Iteration 26977, loss = 312.41211962\n",
      "Iteration 26978, loss = 312.36270093\n",
      "Iteration 26979, loss = 312.31329735\n",
      "Iteration 26980, loss = 312.26390887\n",
      "Iteration 26981, loss = 312.21453548\n",
      "Iteration 26982, loss = 312.16517717\n",
      "Iteration 26983, loss = 312.11583395\n",
      "Iteration 26984, loss = 312.06650579\n",
      "Iteration 26985, loss = 312.01719270\n",
      "Iteration 26986, loss = 311.96789466\n",
      "Iteration 26987, loss = 311.91861167\n",
      "Iteration 26988, loss = 311.86934372\n",
      "Iteration 26989, loss = 311.82009080\n",
      "Iteration 26990, loss = 311.77085291\n",
      "Iteration 26991, loss = 311.72163003\n",
      "Iteration 26992, loss = 311.67242216\n",
      "Iteration 26993, loss = 311.62322929\n",
      "Iteration 26994, loss = 311.57405142\n",
      "Iteration 26995, loss = 311.52488853\n",
      "Iteration 26996, loss = 311.47574062\n",
      "Iteration 26997, loss = 311.42660768\n",
      "Iteration 26998, loss = 311.37748970\n",
      "Iteration 26999, loss = 311.32838668\n",
      "Iteration 27000, loss = 311.27929860\n",
      "Iteration 27001, loss = 311.23022547\n",
      "Iteration 27002, loss = 311.18116727\n",
      "Iteration 27003, loss = 311.13212399\n",
      "Iteration 27004, loss = 311.08309564\n",
      "Iteration 27005, loss = 311.03408219\n",
      "Iteration 27006, loss = 310.98508365\n",
      "Iteration 27007, loss = 310.93610000\n",
      "Iteration 27008, loss = 310.88713123\n",
      "Iteration 27009, loss = 310.83817735\n",
      "Iteration 27010, loss = 310.78923834\n",
      "Iteration 27011, loss = 310.74031420\n",
      "Iteration 27012, loss = 310.69140491\n",
      "Iteration 27013, loss = 310.64251048\n",
      "Iteration 27014, loss = 310.59363089\n",
      "Iteration 27015, loss = 310.54476613\n",
      "Iteration 27016, loss = 310.49591620\n",
      "Iteration 27017, loss = 310.44708109\n",
      "Iteration 27018, loss = 310.39826079\n",
      "Iteration 27019, loss = 310.34945530\n",
      "Iteration 27020, loss = 310.30066461\n",
      "Iteration 27021, loss = 310.25188871\n",
      "Iteration 27022, loss = 310.20312759\n",
      "Iteration 27023, loss = 310.15438124\n",
      "Iteration 27024, loss = 310.10564967\n",
      "Iteration 27025, loss = 310.05693286\n",
      "Iteration 27026, loss = 310.00823080\n",
      "Iteration 27027, loss = 309.95954349\n",
      "Iteration 27028, loss = 309.91087091\n",
      "Iteration 27029, loss = 309.86221307\n",
      "Iteration 27030, loss = 309.81356995\n",
      "Iteration 27031, loss = 309.76494155\n",
      "Iteration 27032, loss = 309.71632786\n",
      "Iteration 27033, loss = 309.66772888\n",
      "Iteration 27034, loss = 309.61914458\n",
      "Iteration 27035, loss = 309.57057498\n",
      "Iteration 27036, loss = 309.52202006\n",
      "Iteration 27037, loss = 309.47347981\n",
      "Iteration 27038, loss = 309.42495422\n",
      "Iteration 27039, loss = 309.37644330\n",
      "Iteration 27040, loss = 309.32794702\n",
      "Iteration 27041, loss = 309.27946539\n",
      "Iteration 27042, loss = 309.23099840\n",
      "Iteration 27043, loss = 309.18254604\n",
      "Iteration 27044, loss = 309.13410830\n",
      "Iteration 27045, loss = 309.08568517\n",
      "Iteration 27046, loss = 309.03727666\n",
      "Iteration 27047, loss = 308.98888274\n",
      "Iteration 27048, loss = 308.94050342\n",
      "Iteration 27049, loss = 308.89213868\n",
      "Iteration 27050, loss = 308.84378853\n",
      "Iteration 27051, loss = 308.79545295\n",
      "Iteration 27052, loss = 308.74713193\n",
      "Iteration 27053, loss = 308.69882547\n",
      "Iteration 27054, loss = 308.65053356\n",
      "Iteration 27055, loss = 308.60225619\n",
      "Iteration 27056, loss = 308.55399336\n",
      "Iteration 27057, loss = 308.50574506\n",
      "Iteration 27058, loss = 308.45751129\n",
      "Iteration 27059, loss = 308.40929203\n",
      "Iteration 27060, loss = 308.36108727\n",
      "Iteration 27061, loss = 308.31289702\n",
      "Iteration 27062, loss = 308.26472126\n",
      "Iteration 27063, loss = 308.21655999\n",
      "Iteration 27064, loss = 308.16841319\n",
      "Iteration 27065, loss = 308.12028087\n",
      "Iteration 27066, loss = 308.07216302\n",
      "Iteration 27067, loss = 308.02405962\n",
      "Iteration 27068, loss = 307.97597068\n",
      "Iteration 27069, loss = 307.92789618\n",
      "Iteration 27070, loss = 307.87983612\n",
      "Iteration 27071, loss = 307.83179049\n",
      "Iteration 27072, loss = 307.78375928\n",
      "Iteration 27073, loss = 307.73574249\n",
      "Iteration 27074, loss = 307.68774010\n",
      "Iteration 27075, loss = 307.63975212\n",
      "Iteration 27076, loss = 307.59177854\n",
      "Iteration 27077, loss = 307.54381934\n",
      "Iteration 27078, loss = 307.49587453\n",
      "Iteration 27079, loss = 307.44794409\n",
      "Iteration 27080, loss = 307.40002802\n",
      "Iteration 27081, loss = 307.35212631\n",
      "Iteration 27082, loss = 307.30423895\n",
      "Iteration 27083, loss = 307.25636594\n",
      "Iteration 27084, loss = 307.20850727\n",
      "Iteration 27085, loss = 307.16066293\n",
      "Iteration 27086, loss = 307.11283292\n",
      "Iteration 27087, loss = 307.06501722\n",
      "Iteration 27088, loss = 307.01721584\n",
      "Iteration 27089, loss = 306.96942877\n",
      "Iteration 27090, loss = 306.92165599\n",
      "Iteration 27091, loss = 306.87389750\n",
      "Iteration 27092, loss = 306.82615330\n",
      "Iteration 27093, loss = 306.77842338\n",
      "Iteration 27094, loss = 306.73070773\n",
      "Iteration 27095, loss = 306.68300634\n",
      "Iteration 27096, loss = 306.63531921\n",
      "Iteration 27097, loss = 306.58764633\n",
      "Iteration 27098, loss = 306.53998769\n",
      "Iteration 27099, loss = 306.49234329\n",
      "Iteration 27100, loss = 306.44471312\n",
      "Iteration 27101, loss = 306.39709717\n",
      "Iteration 27102, loss = 306.34949545\n",
      "Iteration 27103, loss = 306.30190793\n",
      "Iteration 27104, loss = 306.25433461\n",
      "Iteration 27105, loss = 306.20677550\n",
      "Iteration 27106, loss = 306.15923059\n",
      "Iteration 27107, loss = 306.11169988\n",
      "Iteration 27108, loss = 306.06418339\n",
      "Iteration 27109, loss = 306.01668115\n",
      "Iteration 27110, loss = 305.96919326\n",
      "Iteration 27111, loss = 305.92171991\n",
      "Iteration 27112, loss = 305.87426152\n",
      "Iteration 27113, loss = 305.82681898\n",
      "Iteration 27114, loss = 305.77939415\n",
      "Iteration 27115, loss = 305.73199062\n",
      "Iteration 27116, loss = 305.68461511\n",
      "Iteration 27117, loss = 305.63727574\n",
      "Iteration 27118, loss = 305.58997508\n",
      "Iteration 27119, loss = 305.54267719\n",
      "Iteration 27120, loss = 305.49531011\n",
      "Iteration 27121, loss = 305.44785207\n",
      "Iteration 27122, loss = 305.40043904\n",
      "Iteration 27123, loss = 305.35317259\n",
      "Iteration 27124, loss = 305.30596128\n",
      "Iteration 27125, loss = 305.25866737\n",
      "Iteration 27126, loss = 305.21132111\n",
      "Iteration 27127, loss = 305.16406346\n",
      "Iteration 27128, loss = 305.11688651\n",
      "Iteration 27129, loss = 305.06966766\n",
      "Iteration 27130, loss = 305.02240632\n",
      "Iteration 27131, loss = 304.97520754\n",
      "Iteration 27132, loss = 304.92806787\n",
      "Iteration 27133, loss = 304.88089947\n",
      "Iteration 27134, loss = 304.83371289\n",
      "Iteration 27135, loss = 304.78658054\n",
      "Iteration 27136, loss = 304.73948286\n",
      "Iteration 27137, loss = 304.69236318\n",
      "Iteration 27138, loss = 304.64524763\n",
      "Iteration 27139, loss = 304.59817772\n",
      "Iteration 27140, loss = 304.55112355\n",
      "Iteration 27141, loss = 304.50405756\n",
      "Iteration 27142, loss = 304.45700998\n",
      "Iteration 27143, loss = 304.40999661\n",
      "Iteration 27144, loss = 304.36298902\n",
      "Iteration 27145, loss = 304.31598097\n",
      "Iteration 27146, loss = 304.26899718\n",
      "Iteration 27147, loss = 304.22203659\n",
      "Iteration 27148, loss = 304.17507938\n",
      "Iteration 27149, loss = 304.12813129\n",
      "Iteration 27150, loss = 304.08120691\n",
      "Iteration 27151, loss = 304.03429799\n",
      "Iteration 27152, loss = 303.98739470\n",
      "Iteration 27153, loss = 303.94050613\n",
      "Iteration 27154, loss = 303.89363800\n",
      "Iteration 27155, loss = 303.84678152\n",
      "Iteration 27156, loss = 303.79993416\n",
      "Iteration 27157, loss = 303.75310364\n",
      "Iteration 27158, loss = 303.70629015\n",
      "Iteration 27159, loss = 303.65948736\n",
      "Iteration 27160, loss = 303.61269661\n",
      "Iteration 27161, loss = 303.56592267\n",
      "Iteration 27162, loss = 303.51916336\n",
      "Iteration 27163, loss = 303.47241530\n",
      "Iteration 27164, loss = 303.42568097\n",
      "Iteration 27165, loss = 303.37896257\n",
      "Iteration 27166, loss = 303.33225759\n",
      "Iteration 27167, loss = 303.28556477\n",
      "Iteration 27168, loss = 303.23888639\n",
      "Iteration 27169, loss = 303.19222298\n",
      "Iteration 27170, loss = 303.14557259\n",
      "Iteration 27171, loss = 303.09893515\n",
      "Iteration 27172, loss = 303.05231224\n",
      "Iteration 27173, loss = 303.00570361\n",
      "Iteration 27174, loss = 302.95910801\n",
      "Iteration 27175, loss = 302.91252585\n",
      "Iteration 27176, loss = 302.86595806\n",
      "Iteration 27177, loss = 302.81940413\n",
      "Iteration 27178, loss = 302.77286339\n",
      "Iteration 27179, loss = 302.72633634\n",
      "Iteration 27180, loss = 302.67982344\n",
      "Iteration 27181, loss = 302.63332418\n",
      "Iteration 27182, loss = 302.58683829\n",
      "Iteration 27183, loss = 302.54036616\n",
      "Iteration 27184, loss = 302.49390799\n",
      "Iteration 27185, loss = 302.44746338\n",
      "Iteration 27186, loss = 302.40103225\n",
      "Iteration 27187, loss = 302.35461488\n",
      "Iteration 27188, loss = 302.30821133\n",
      "Iteration 27189, loss = 302.26182132\n",
      "Iteration 27190, loss = 302.21544484\n",
      "Iteration 27191, loss = 302.16908210\n",
      "Iteration 27192, loss = 302.12273307\n",
      "Iteration 27193, loss = 302.07639758\n",
      "Iteration 27194, loss = 302.03007565\n",
      "Iteration 27195, loss = 301.98376741\n",
      "Iteration 27196, loss = 301.93747282\n",
      "Iteration 27197, loss = 301.89119176\n",
      "Iteration 27198, loss = 301.84492427\n",
      "Iteration 27199, loss = 301.79867042\n",
      "Iteration 27200, loss = 301.75243018\n",
      "Iteration 27201, loss = 301.70620346\n",
      "Iteration 27202, loss = 301.65999030\n",
      "Iteration 27203, loss = 301.61379074\n",
      "Iteration 27204, loss = 301.56760475\n",
      "Iteration 27205, loss = 301.52143227\n",
      "Iteration 27206, loss = 301.47527334\n",
      "Iteration 27207, loss = 301.42912797\n",
      "Iteration 27208, loss = 301.38299614\n",
      "Iteration 27209, loss = 301.33687781\n",
      "Iteration 27210, loss = 301.29077300\n",
      "Iteration 27211, loss = 301.24468172\n",
      "Iteration 27212, loss = 301.19860395\n",
      "Iteration 27213, loss = 301.15253967\n",
      "Iteration 27214, loss = 301.10648888\n",
      "Iteration 27215, loss = 301.06045160\n",
      "Iteration 27216, loss = 301.01442779\n",
      "Iteration 27217, loss = 300.96841746\n",
      "Iteration 27218, loss = 300.92242060\n",
      "Iteration 27219, loss = 300.87643721\n",
      "Iteration 27220, loss = 300.83046728\n",
      "Iteration 27221, loss = 300.78451080\n",
      "Iteration 27222, loss = 300.73856777\n",
      "Iteration 27223, loss = 300.69263818\n",
      "Iteration 27224, loss = 300.64672202\n",
      "Iteration 27225, loss = 300.60081930\n",
      "Iteration 27226, loss = 300.55492999\n",
      "Iteration 27227, loss = 300.50905410\n",
      "Iteration 27228, loss = 300.46319163\n",
      "Iteration 27229, loss = 300.41734256\n",
      "Iteration 27230, loss = 300.37150689\n",
      "Iteration 27231, loss = 300.32568461\n",
      "Iteration 27232, loss = 300.27987572\n",
      "Iteration 27233, loss = 300.23408021\n",
      "Iteration 27234, loss = 300.18829808\n",
      "Iteration 27235, loss = 300.14252931\n",
      "Iteration 27236, loss = 300.09677391\n",
      "Iteration 27237, loss = 300.05103186\n",
      "Iteration 27238, loss = 300.00530317\n",
      "Iteration 27239, loss = 299.95958782\n",
      "Iteration 27240, loss = 299.91388581\n",
      "Iteration 27241, loss = 299.86819713\n",
      "Iteration 27242, loss = 299.82252179\n",
      "Iteration 27243, loss = 299.77685976\n",
      "Iteration 27244, loss = 299.73121105\n",
      "Iteration 27245, loss = 299.68557564\n",
      "Iteration 27246, loss = 299.63995355\n",
      "Iteration 27247, loss = 299.59434475\n",
      "Iteration 27248, loss = 299.54874924\n",
      "Iteration 27249, loss = 299.50316702\n",
      "Iteration 27250, loss = 299.45759807\n",
      "Iteration 27251, loss = 299.41204240\n",
      "Iteration 27252, loss = 299.36650000\n",
      "Iteration 27253, loss = 299.32097087\n",
      "Iteration 27254, loss = 299.27545499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27255, loss = 299.22995236\n",
      "Iteration 27256, loss = 299.18446297\n",
      "Iteration 27257, loss = 299.13898683\n",
      "Iteration 27258, loss = 299.09352391\n",
      "Iteration 27259, loss = 299.04807423\n",
      "Iteration 27260, loss = 299.00263776\n",
      "Iteration 27261, loss = 298.95721451\n",
      "Iteration 27262, loss = 298.91180447\n",
      "Iteration 27263, loss = 298.86640764\n",
      "Iteration 27264, loss = 298.82102400\n",
      "Iteration 27265, loss = 298.77565356\n",
      "Iteration 27266, loss = 298.73029630\n",
      "Iteration 27267, loss = 298.68495222\n",
      "Iteration 27268, loss = 298.63962132\n",
      "Iteration 27269, loss = 298.59430359\n",
      "Iteration 27270, loss = 298.54899902\n",
      "Iteration 27271, loss = 298.50370760\n",
      "Iteration 27272, loss = 298.45842934\n",
      "Iteration 27273, loss = 298.41316423\n",
      "Iteration 27274, loss = 298.36791225\n",
      "Iteration 27275, loss = 298.32267341\n",
      "Iteration 27276, loss = 298.27744770\n",
      "Iteration 27277, loss = 298.23223511\n",
      "Iteration 27278, loss = 298.18703564\n",
      "Iteration 27279, loss = 298.14184928\n",
      "Iteration 27280, loss = 298.09667603\n",
      "Iteration 27281, loss = 298.05151587\n",
      "Iteration 27282, loss = 298.00636881\n",
      "Iteration 27283, loss = 297.96123484\n",
      "Iteration 27284, loss = 297.91611395\n",
      "Iteration 27285, loss = 297.87100614\n",
      "Iteration 27286, loss = 297.82591140\n",
      "Iteration 27287, loss = 297.78082973\n",
      "Iteration 27288, loss = 297.73576111\n",
      "Iteration 27289, loss = 297.69070555\n",
      "Iteration 27290, loss = 297.64566304\n",
      "Iteration 27291, loss = 297.60063357\n",
      "Iteration 27292, loss = 297.55561714\n",
      "Iteration 27293, loss = 297.51061374\n",
      "Iteration 27294, loss = 297.46562337\n",
      "Iteration 27295, loss = 297.42064601\n",
      "Iteration 27296, loss = 297.37568167\n",
      "Iteration 27297, loss = 297.33073034\n",
      "Iteration 27298, loss = 297.28579201\n",
      "Iteration 27299, loss = 297.24086668\n",
      "Iteration 27300, loss = 297.19595435\n",
      "Iteration 27301, loss = 297.15105499\n",
      "Iteration 27302, loss = 297.10616862\n",
      "Iteration 27303, loss = 297.06129523\n",
      "Iteration 27304, loss = 297.01643480\n",
      "Iteration 27305, loss = 296.97158734\n",
      "Iteration 27306, loss = 296.92675283\n",
      "Iteration 27307, loss = 296.88193128\n",
      "Iteration 27308, loss = 296.83712268\n",
      "Iteration 27309, loss = 296.79232701\n",
      "Iteration 27310, loss = 296.74754429\n",
      "Iteration 27311, loss = 296.70277449\n",
      "Iteration 27312, loss = 296.65801762\n",
      "Iteration 27313, loss = 296.61327366\n",
      "Iteration 27314, loss = 296.56854262\n",
      "Iteration 27315, loss = 296.52382449\n",
      "Iteration 27316, loss = 296.47911926\n",
      "Iteration 27317, loss = 296.43442693\n",
      "Iteration 27318, loss = 296.38974749\n",
      "Iteration 27319, loss = 296.34508093\n",
      "Iteration 27320, loss = 296.30042725\n",
      "Iteration 27321, loss = 296.25578645\n",
      "Iteration 27322, loss = 296.21115852\n",
      "Iteration 27323, loss = 296.16654345\n",
      "Iteration 27324, loss = 296.12194124\n",
      "Iteration 27325, loss = 296.07735188\n",
      "Iteration 27326, loss = 296.03277537\n",
      "Iteration 27327, loss = 295.98821170\n",
      "Iteration 27328, loss = 295.94366087\n",
      "Iteration 27329, loss = 295.89912287\n",
      "Iteration 27330, loss = 295.85459769\n",
      "Iteration 27331, loss = 295.81008533\n",
      "Iteration 27332, loss = 295.76558579\n",
      "Iteration 27333, loss = 295.72109905\n",
      "Iteration 27334, loss = 295.67662512\n",
      "Iteration 27335, loss = 295.63216398\n",
      "Iteration 27336, loss = 295.58771564\n",
      "Iteration 27337, loss = 295.54328008\n",
      "Iteration 27338, loss = 295.49885731\n",
      "Iteration 27339, loss = 295.45444731\n",
      "Iteration 27340, loss = 295.41005008\n",
      "Iteration 27341, loss = 295.36566561\n",
      "Iteration 27342, loss = 295.32129391\n",
      "Iteration 27343, loss = 295.27693496\n",
      "Iteration 27344, loss = 295.23258875\n",
      "Iteration 27345, loss = 295.18825529\n",
      "Iteration 27346, loss = 295.14393457\n",
      "Iteration 27347, loss = 295.09962658\n",
      "Iteration 27348, loss = 295.05533132\n",
      "Iteration 27349, loss = 295.01104878\n",
      "Iteration 27350, loss = 294.96677895\n",
      "Iteration 27351, loss = 294.92252184\n",
      "Iteration 27352, loss = 294.87827743\n",
      "Iteration 27353, loss = 294.83404572\n",
      "Iteration 27354, loss = 294.78982670\n",
      "Iteration 27355, loss = 294.74562038\n",
      "Iteration 27356, loss = 294.70142673\n",
      "Iteration 27357, loss = 294.65724577\n",
      "Iteration 27358, loss = 294.61307748\n",
      "Iteration 27359, loss = 294.56892185\n",
      "Iteration 27360, loss = 294.52477889\n",
      "Iteration 27361, loss = 294.48064859\n",
      "Iteration 27362, loss = 294.43653094\n",
      "Iteration 27363, loss = 294.39242593\n",
      "Iteration 27364, loss = 294.34833356\n",
      "Iteration 27365, loss = 294.30425383\n",
      "Iteration 27366, loss = 294.26018673\n",
      "Iteration 27367, loss = 294.21613225\n",
      "Iteration 27368, loss = 294.17209040\n",
      "Iteration 27369, loss = 294.12806116\n",
      "Iteration 27370, loss = 294.08404452\n",
      "Iteration 27371, loss = 294.04004049\n",
      "Iteration 27372, loss = 293.99604906\n",
      "Iteration 27373, loss = 293.95207022\n",
      "Iteration 27374, loss = 293.90810397\n",
      "Iteration 27375, loss = 293.86415030\n",
      "Iteration 27376, loss = 293.82020921\n",
      "Iteration 27377, loss = 293.77628069\n",
      "Iteration 27378, loss = 293.73236474\n",
      "Iteration 27379, loss = 293.68846134\n",
      "Iteration 27380, loss = 293.64457051\n",
      "Iteration 27381, loss = 293.60069222\n",
      "Iteration 27382, loss = 293.55682648\n",
      "Iteration 27383, loss = 293.51297328\n",
      "Iteration 27384, loss = 293.46913261\n",
      "Iteration 27385, loss = 293.42530448\n",
      "Iteration 27386, loss = 293.38148887\n",
      "Iteration 27387, loss = 293.33768577\n",
      "Iteration 27388, loss = 293.29389519\n",
      "Iteration 27389, loss = 293.25011712\n",
      "Iteration 27390, loss = 293.20635156\n",
      "Iteration 27391, loss = 293.16259849\n",
      "Iteration 27392, loss = 293.11885791\n",
      "Iteration 27393, loss = 293.07512982\n",
      "Iteration 27394, loss = 293.03141422\n",
      "Iteration 27395, loss = 292.98771109\n",
      "Iteration 27396, loss = 292.94402043\n",
      "Iteration 27397, loss = 292.90034224\n",
      "Iteration 27398, loss = 292.85667652\n",
      "Iteration 27399, loss = 292.81302324\n",
      "Iteration 27400, loss = 292.76938242\n",
      "Iteration 27401, loss = 292.72575405\n",
      "Iteration 27402, loss = 292.68213812\n",
      "Iteration 27403, loss = 292.63853462\n",
      "Iteration 27404, loss = 292.59494355\n",
      "Iteration 27405, loss = 292.55136491\n",
      "Iteration 27406, loss = 292.50779869\n",
      "Iteration 27407, loss = 292.46424488\n",
      "Iteration 27408, loss = 292.42070349\n",
      "Iteration 27409, loss = 292.37717450\n",
      "Iteration 27410, loss = 292.33365790\n",
      "Iteration 27411, loss = 292.29015371\n",
      "Iteration 27412, loss = 292.24666190\n",
      "Iteration 27413, loss = 292.20318247\n",
      "Iteration 27414, loss = 292.15971543\n",
      "Iteration 27415, loss = 292.11626076\n",
      "Iteration 27416, loss = 292.07281845\n",
      "Iteration 27417, loss = 292.02938852\n",
      "Iteration 27418, loss = 291.98597094\n",
      "Iteration 27419, loss = 291.94256571\n",
      "Iteration 27420, loss = 291.89917283\n",
      "Iteration 27421, loss = 291.85579229\n",
      "Iteration 27422, loss = 291.81242410\n",
      "Iteration 27423, loss = 291.76906823\n",
      "Iteration 27424, loss = 291.72572470\n",
      "Iteration 27425, loss = 291.68239348\n",
      "Iteration 27426, loss = 291.63907459\n",
      "Iteration 27427, loss = 291.59576800\n",
      "Iteration 27428, loss = 291.55247373\n",
      "Iteration 27429, loss = 291.50919175\n",
      "Iteration 27430, loss = 291.46592208\n",
      "Iteration 27431, loss = 291.42266469\n",
      "Iteration 27432, loss = 291.37941960\n",
      "Iteration 27433, loss = 291.33618678\n",
      "Iteration 27434, loss = 291.29296625\n",
      "Iteration 27435, loss = 291.24975798\n",
      "Iteration 27436, loss = 291.20656198\n",
      "Iteration 27437, loss = 291.16337825\n",
      "Iteration 27438, loss = 291.12020677\n",
      "Iteration 27439, loss = 291.07704754\n",
      "Iteration 27440, loss = 291.03390056\n",
      "Iteration 27441, loss = 290.99076582\n",
      "Iteration 27442, loss = 290.94764332\n",
      "Iteration 27443, loss = 290.90453305\n",
      "Iteration 27444, loss = 290.86143501\n",
      "Iteration 27445, loss = 290.81834919\n",
      "Iteration 27446, loss = 290.77527559\n",
      "Iteration 27447, loss = 290.73221419\n",
      "Iteration 27448, loss = 290.68916501\n",
      "Iteration 27449, loss = 290.64612802\n",
      "Iteration 27450, loss = 290.60310324\n",
      "Iteration 27451, loss = 290.56009064\n",
      "Iteration 27452, loss = 290.51709023\n",
      "Iteration 27453, loss = 290.47410201\n",
      "Iteration 27454, loss = 290.43112596\n",
      "Iteration 27455, loss = 290.38816208\n",
      "Iteration 27456, loss = 290.34521037\n",
      "Iteration 27457, loss = 290.30227082\n",
      "Iteration 27458, loss = 290.25934342\n",
      "Iteration 27459, loss = 290.21642818\n",
      "Iteration 27460, loss = 290.17352509\n",
      "Iteration 27461, loss = 290.13063414\n",
      "Iteration 27462, loss = 290.08775533\n",
      "Iteration 27463, loss = 290.04488864\n",
      "Iteration 27464, loss = 290.00203409\n",
      "Iteration 27465, loss = 289.95919166\n",
      "Iteration 27466, loss = 289.91636134\n",
      "Iteration 27467, loss = 289.87354314\n",
      "Iteration 27468, loss = 289.83073704\n",
      "Iteration 27469, loss = 289.78794305\n",
      "Iteration 27470, loss = 289.74516116\n",
      "Iteration 27471, loss = 289.70239135\n",
      "Iteration 27472, loss = 289.65963364\n",
      "Iteration 27473, loss = 289.61688801\n",
      "Iteration 27474, loss = 289.57415445\n",
      "Iteration 27475, loss = 289.53143297\n",
      "Iteration 27476, loss = 289.48872356\n",
      "Iteration 27477, loss = 289.44602621\n",
      "Iteration 27478, loss = 289.40334092\n",
      "Iteration 27479, loss = 289.36066768\n",
      "Iteration 27480, loss = 289.31800650\n",
      "Iteration 27481, loss = 289.27535735\n",
      "Iteration 27482, loss = 289.23272024\n",
      "Iteration 27483, loss = 289.19009517\n",
      "Iteration 27484, loss = 289.14748213\n",
      "Iteration 27485, loss = 289.10488111\n",
      "Iteration 27486, loss = 289.06229211\n",
      "Iteration 27487, loss = 289.01971513\n",
      "Iteration 27488, loss = 288.97715015\n",
      "Iteration 27489, loss = 288.93459718\n",
      "Iteration 27490, loss = 288.89205621\n",
      "Iteration 27491, loss = 288.84952724\n",
      "Iteration 27492, loss = 288.80701025\n",
      "Iteration 27493, loss = 288.76450525\n",
      "Iteration 27494, loss = 288.72201223\n",
      "Iteration 27495, loss = 288.67953119\n",
      "Iteration 27496, loss = 288.63706212\n",
      "Iteration 27497, loss = 288.59460501\n",
      "Iteration 27498, loss = 288.55215987\n",
      "Iteration 27499, loss = 288.50972668\n",
      "Iteration 27500, loss = 288.46730544\n",
      "Iteration 27501, loss = 288.42489615\n",
      "Iteration 27502, loss = 288.38249880\n",
      "Iteration 27503, loss = 288.34011339\n",
      "Iteration 27504, loss = 288.29773992\n",
      "Iteration 27505, loss = 288.25537836\n",
      "Iteration 27506, loss = 288.21302874\n",
      "Iteration 27507, loss = 288.17069103\n",
      "Iteration 27508, loss = 288.12836523\n",
      "Iteration 27509, loss = 288.08605134\n",
      "Iteration 27510, loss = 288.04374936\n",
      "Iteration 27511, loss = 288.00145927\n",
      "Iteration 27512, loss = 287.95918108\n",
      "Iteration 27513, loss = 287.91691478\n",
      "Iteration 27514, loss = 287.87466036\n",
      "Iteration 27515, loss = 287.83241782\n",
      "Iteration 27516, loss = 287.79018716\n",
      "Iteration 27517, loss = 287.74796837\n",
      "Iteration 27518, loss = 287.70576144\n",
      "Iteration 27519, loss = 287.66356638\n",
      "Iteration 27520, loss = 287.62138317\n",
      "Iteration 27521, loss = 287.57921181\n",
      "Iteration 27522, loss = 287.53705229\n",
      "Iteration 27523, loss = 287.49490462\n",
      "Iteration 27524, loss = 287.45276879\n",
      "Iteration 27525, loss = 287.41064479\n",
      "Iteration 27526, loss = 287.36853262\n",
      "Iteration 27527, loss = 287.32643227\n",
      "Iteration 27528, loss = 287.28434373\n",
      "Iteration 27529, loss = 287.24226701\n",
      "Iteration 27530, loss = 287.20020210\n",
      "Iteration 27531, loss = 287.15814900\n",
      "Iteration 27532, loss = 287.11610769\n",
      "Iteration 27533, loss = 287.07407818\n",
      "Iteration 27534, loss = 287.03206046\n",
      "Iteration 27535, loss = 286.99005452\n",
      "Iteration 27536, loss = 286.94806036\n",
      "Iteration 27537, loss = 286.90607798\n",
      "Iteration 27538, loss = 286.86410737\n",
      "Iteration 27539, loss = 286.82214853\n",
      "Iteration 27540, loss = 286.78020145\n",
      "Iteration 27541, loss = 286.73826612\n",
      "Iteration 27542, loss = 286.69634255\n",
      "Iteration 27543, loss = 286.65443073\n",
      "Iteration 27544, loss = 286.61253064\n",
      "Iteration 27545, loss = 286.57064230\n",
      "Iteration 27546, loss = 286.52876569\n",
      "Iteration 27547, loss = 286.48690081\n",
      "Iteration 27548, loss = 286.44504766\n",
      "Iteration 27549, loss = 286.40320622\n",
      "Iteration 27550, loss = 286.36137650\n",
      "Iteration 27551, loss = 286.31955849\n",
      "Iteration 27552, loss = 286.27775218\n",
      "Iteration 27553, loss = 286.23595758\n",
      "Iteration 27554, loss = 286.19417468\n",
      "Iteration 27555, loss = 286.15240346\n",
      "Iteration 27556, loss = 286.11064394\n",
      "Iteration 27557, loss = 286.06889611\n",
      "Iteration 27558, loss = 286.02715997\n",
      "Iteration 27559, loss = 285.98543553\n",
      "Iteration 27560, loss = 285.94372281\n",
      "Iteration 27561, loss = 285.90202187\n",
      "Iteration 27562, loss = 285.86033282\n",
      "Iteration 27563, loss = 285.81865588\n",
      "Iteration 27564, loss = 285.77699155\n",
      "Iteration 27565, loss = 285.73534081\n",
      "Iteration 27566, loss = 285.69370566\n",
      "Iteration 27567, loss = 285.65208977\n",
      "Iteration 27568, loss = 285.61049963\n",
      "Iteration 27569, loss = 285.56894180\n",
      "Iteration 27570, loss = 285.52741561\n",
      "Iteration 27571, loss = 285.48588273\n",
      "Iteration 27572, loss = 285.44428043\n",
      "Iteration 27573, loss = 285.40260066\n",
      "Iteration 27574, loss = 285.36096811\n",
      "Iteration 27575, loss = 285.31946559\n",
      "Iteration 27576, loss = 285.27801168\n",
      "Iteration 27577, loss = 285.23648597\n",
      "Iteration 27578, loss = 285.19490611\n",
      "Iteration 27579, loss = 285.15339559\n",
      "Iteration 27580, loss = 285.11196532\n",
      "Iteration 27581, loss = 285.07051068\n",
      "Iteration 27582, loss = 285.02900678\n",
      "Iteration 27583, loss = 284.98754045\n",
      "Iteration 27584, loss = 284.94613821\n",
      "Iteration 27585, loss = 284.90472737\n",
      "Iteration 27586, loss = 284.86328537\n",
      "Iteration 27587, loss = 284.82187383\n",
      "Iteration 27588, loss = 284.78050812\n",
      "Iteration 27589, loss = 284.73913644\n",
      "Iteration 27590, loss = 284.69775017\n",
      "Iteration 27591, loss = 284.65639256\n",
      "Iteration 27592, loss = 284.61506627\n",
      "Iteration 27593, loss = 284.57373554\n",
      "Iteration 27594, loss = 284.53240233\n",
      "Iteration 27595, loss = 284.49109572\n",
      "Iteration 27596, loss = 284.44981012\n",
      "Iteration 27597, loss = 284.40852259\n",
      "Iteration 27598, loss = 284.36724092\n",
      "Iteration 27599, loss = 284.32598257\n",
      "Iteration 27600, loss = 284.28473870\n",
      "Iteration 27601, loss = 284.24349639\n",
      "Iteration 27602, loss = 284.20226468\n",
      "Iteration 27603, loss = 284.16105272\n",
      "Iteration 27604, loss = 284.11985181\n",
      "Iteration 27605, loss = 284.07865577\n",
      "Iteration 27606, loss = 284.03747256\n",
      "Iteration 27607, loss = 283.99630600\n",
      "Iteration 27608, loss = 283.95514911\n",
      "Iteration 27609, loss = 283.91399975\n",
      "Iteration 27610, loss = 283.87286385\n",
      "Iteration 27611, loss = 283.83174233\n",
      "Iteration 27612, loss = 283.79063025\n",
      "Iteration 27613, loss = 283.74952751\n",
      "Iteration 27614, loss = 283.70843808\n",
      "Iteration 27615, loss = 283.66736158\n",
      "Iteration 27616, loss = 283.62629479\n",
      "Iteration 27617, loss = 283.58523841\n",
      "Iteration 27618, loss = 283.54419495\n",
      "Iteration 27619, loss = 283.50316354\n",
      "Iteration 27620, loss = 283.46214226\n",
      "Iteration 27621, loss = 283.42113198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27622, loss = 283.38013416\n",
      "Iteration 27623, loss = 283.33914796\n",
      "Iteration 27624, loss = 283.29817226\n",
      "Iteration 27625, loss = 283.25720783\n",
      "Iteration 27626, loss = 283.21625549\n",
      "Iteration 27627, loss = 283.17531456\n",
      "Iteration 27628, loss = 283.13438440\n",
      "Iteration 27629, loss = 283.09346561\n",
      "Iteration 27630, loss = 283.05255866\n",
      "Iteration 27631, loss = 283.01166302\n",
      "Iteration 27632, loss = 282.97077834\n",
      "Iteration 27633, loss = 282.92990505\n",
      "Iteration 27634, loss = 282.88904340\n",
      "Iteration 27635, loss = 282.84819304\n",
      "Iteration 27636, loss = 282.80735375\n",
      "Iteration 27637, loss = 282.76652584\n",
      "Iteration 27638, loss = 282.72570944\n",
      "Iteration 27639, loss = 282.68490431\n",
      "Iteration 27640, loss = 282.64411034\n",
      "Iteration 27641, loss = 282.60332770\n",
      "Iteration 27642, loss = 282.56255649\n",
      "Iteration 27643, loss = 282.52179655\n",
      "Iteration 27644, loss = 282.48104780\n",
      "Iteration 27645, loss = 282.44031035\n",
      "Iteration 27646, loss = 282.39958428\n",
      "Iteration 27647, loss = 282.35886946\n",
      "Iteration 27648, loss = 282.31816585\n",
      "Iteration 27649, loss = 282.27747352\n",
      "Iteration 27650, loss = 282.23679251\n",
      "Iteration 27651, loss = 282.19612276\n",
      "Iteration 27652, loss = 282.15546421\n",
      "Iteration 27653, loss = 282.11481692\n",
      "Iteration 27654, loss = 282.07418092\n",
      "Iteration 27655, loss = 282.03355615\n",
      "Iteration 27656, loss = 281.99294260\n",
      "Iteration 27657, loss = 281.95234028\n",
      "Iteration 27658, loss = 281.91174921\n",
      "Iteration 27659, loss = 281.87116937\n",
      "Iteration 27660, loss = 281.83060073\n",
      "Iteration 27661, loss = 281.79004331\n",
      "Iteration 27662, loss = 281.74949711\n",
      "Iteration 27663, loss = 281.70896213\n",
      "Iteration 27664, loss = 281.66843833\n",
      "Iteration 27665, loss = 281.62792574\n",
      "Iteration 27666, loss = 281.58742434\n",
      "Iteration 27667, loss = 281.54693414\n",
      "Iteration 27668, loss = 281.50645513\n",
      "Iteration 27669, loss = 281.46598728\n",
      "Iteration 27670, loss = 281.42553063\n",
      "Iteration 27671, loss = 281.38508515\n",
      "Iteration 27672, loss = 281.34465083\n",
      "Iteration 27673, loss = 281.30422768\n",
      "Iteration 27674, loss = 281.26381569\n",
      "Iteration 27675, loss = 281.22341486\n",
      "Iteration 27676, loss = 281.18302518\n",
      "Iteration 27677, loss = 281.14264664\n",
      "Iteration 27678, loss = 281.10227925\n",
      "Iteration 27679, loss = 281.06192300\n",
      "Iteration 27680, loss = 281.02157788\n",
      "Iteration 27681, loss = 280.98124390\n",
      "Iteration 27682, loss = 280.94092104\n",
      "Iteration 27683, loss = 280.90060930\n",
      "Iteration 27684, loss = 280.86030868\n",
      "Iteration 27685, loss = 280.82001917\n",
      "Iteration 27686, loss = 280.77974077\n",
      "Iteration 27687, loss = 280.73947348\n",
      "Iteration 27688, loss = 280.69921729\n",
      "Iteration 27689, loss = 280.65897219\n",
      "Iteration 27690, loss = 280.61873819\n",
      "Iteration 27691, loss = 280.57851527\n",
      "Iteration 27692, loss = 280.53830344\n",
      "Iteration 27693, loss = 280.49810269\n",
      "Iteration 27694, loss = 280.45791301\n",
      "Iteration 27695, loss = 280.41773440\n",
      "Iteration 27696, loss = 280.37756686\n",
      "Iteration 27697, loss = 280.33741038\n",
      "Iteration 27698, loss = 280.29726496\n",
      "Iteration 27699, loss = 280.25713060\n",
      "Iteration 27700, loss = 280.21700728\n",
      "Iteration 27701, loss = 280.17689501\n",
      "Iteration 27702, loss = 280.13679378\n",
      "Iteration 27703, loss = 280.09670358\n",
      "Iteration 27704, loss = 280.05662442\n",
      "Iteration 27705, loss = 280.01655629\n",
      "Iteration 27706, loss = 279.97649918\n",
      "Iteration 27707, loss = 279.93645309\n",
      "Iteration 27708, loss = 279.89641801\n",
      "Iteration 27709, loss = 279.85639395\n",
      "Iteration 27710, loss = 279.81638090\n",
      "Iteration 27711, loss = 279.77637885\n",
      "Iteration 27712, loss = 279.73638779\n",
      "Iteration 27713, loss = 279.69640774\n",
      "Iteration 27714, loss = 279.65643867\n",
      "Iteration 27715, loss = 279.61648059\n",
      "Iteration 27716, loss = 279.57653349\n",
      "Iteration 27717, loss = 279.53659736\n",
      "Iteration 27718, loss = 279.49667222\n",
      "Iteration 27719, loss = 279.45675804\n",
      "Iteration 27720, loss = 279.41685482\n",
      "Iteration 27721, loss = 279.37696257\n",
      "Iteration 27722, loss = 279.33708128\n",
      "Iteration 27723, loss = 279.29721093\n",
      "Iteration 27724, loss = 279.25735154\n",
      "Iteration 27725, loss = 279.21750309\n",
      "Iteration 27726, loss = 279.17766558\n",
      "Iteration 27727, loss = 279.13783900\n",
      "Iteration 27728, loss = 279.09802336\n",
      "Iteration 27729, loss = 279.05821865\n",
      "Iteration 27730, loss = 279.01842486\n",
      "Iteration 27731, loss = 278.97864198\n",
      "Iteration 27732, loss = 278.93887003\n",
      "Iteration 27733, loss = 278.89910898\n",
      "Iteration 27734, loss = 278.85935884\n",
      "Iteration 27735, loss = 278.81961960\n",
      "Iteration 27736, loss = 278.77989127\n",
      "Iteration 27737, loss = 278.74017382\n",
      "Iteration 27738, loss = 278.70046727\n",
      "Iteration 27739, loss = 278.66077160\n",
      "Iteration 27740, loss = 278.62108681\n",
      "Iteration 27741, loss = 278.58141290\n",
      "Iteration 27742, loss = 278.54174987\n",
      "Iteration 27743, loss = 278.50209770\n",
      "Iteration 27744, loss = 278.46245640\n",
      "Iteration 27745, loss = 278.42282597\n",
      "Iteration 27746, loss = 278.38320638\n",
      "Iteration 27747, loss = 278.34359765\n",
      "Iteration 27748, loss = 278.30399977\n",
      "Iteration 27749, loss = 278.26441274\n",
      "Iteration 27750, loss = 278.22483654\n",
      "Iteration 27751, loss = 278.18527118\n",
      "Iteration 27752, loss = 278.14571666\n",
      "Iteration 27753, loss = 278.10617296\n",
      "Iteration 27754, loss = 278.06664008\n",
      "Iteration 27755, loss = 278.02711803\n",
      "Iteration 27756, loss = 277.98760679\n",
      "Iteration 27757, loss = 277.94810636\n",
      "Iteration 27758, loss = 277.90861674\n",
      "Iteration 27759, loss = 277.86913793\n",
      "Iteration 27760, loss = 277.82966991\n",
      "Iteration 27761, loss = 277.79021269\n",
      "Iteration 27762, loss = 277.75076626\n",
      "Iteration 27763, loss = 277.71133061\n",
      "Iteration 27764, loss = 277.67190575\n",
      "Iteration 27765, loss = 277.63249167\n",
      "Iteration 27766, loss = 277.59308836\n",
      "Iteration 27767, loss = 277.55369583\n",
      "Iteration 27768, loss = 277.51431406\n",
      "Iteration 27769, loss = 277.47494305\n",
      "Iteration 27770, loss = 277.43558280\n",
      "Iteration 27771, loss = 277.39623331\n",
      "Iteration 27772, loss = 277.35689456\n",
      "Iteration 27773, loss = 277.31756656\n",
      "Iteration 27774, loss = 277.27824931\n",
      "Iteration 27775, loss = 277.23894279\n",
      "Iteration 27776, loss = 277.19964701\n",
      "Iteration 27777, loss = 277.16036195\n",
      "Iteration 27778, loss = 277.12108762\n",
      "Iteration 27779, loss = 277.08182402\n",
      "Iteration 27780, loss = 277.04257113\n",
      "Iteration 27781, loss = 277.00332895\n",
      "Iteration 27782, loss = 276.96409749\n",
      "Iteration 27783, loss = 276.92487673\n",
      "Iteration 27784, loss = 276.88566667\n",
      "Iteration 27785, loss = 276.84646731\n",
      "Iteration 27786, loss = 276.80727864\n",
      "Iteration 27787, loss = 276.76810066\n",
      "Iteration 27788, loss = 276.72893337\n",
      "Iteration 27789, loss = 276.68977675\n",
      "Iteration 27790, loss = 276.65063082\n",
      "Iteration 27791, loss = 276.61149556\n",
      "Iteration 27792, loss = 276.57237096\n",
      "Iteration 27793, loss = 276.53325704\n",
      "Iteration 27794, loss = 276.49415377\n",
      "Iteration 27795, loss = 276.45506116\n",
      "Iteration 27796, loss = 276.41597920\n",
      "Iteration 27797, loss = 276.37690790\n",
      "Iteration 27798, loss = 276.33784723\n",
      "Iteration 27799, loss = 276.29879721\n",
      "Iteration 27800, loss = 276.25975783\n",
      "Iteration 27801, loss = 276.22072907\n",
      "Iteration 27802, loss = 276.18171095\n",
      "Iteration 27803, loss = 276.14270345\n",
      "Iteration 27804, loss = 276.10370658\n",
      "Iteration 27805, loss = 276.06472031\n",
      "Iteration 27806, loss = 276.02574467\n",
      "Iteration 27807, loss = 275.98677963\n",
      "Iteration 27808, loss = 275.94782519\n",
      "Iteration 27809, loss = 275.90888136\n",
      "Iteration 27810, loss = 275.86994812\n",
      "Iteration 27811, loss = 275.83102548\n",
      "Iteration 27812, loss = 275.79211342\n",
      "Iteration 27813, loss = 275.75321195\n",
      "Iteration 27814, loss = 275.71432106\n",
      "Iteration 27815, loss = 275.67544075\n",
      "Iteration 27816, loss = 275.63657101\n",
      "Iteration 27817, loss = 275.59771184\n",
      "Iteration 27818, loss = 275.55886323\n",
      "Iteration 27819, loss = 275.52002518\n",
      "Iteration 27820, loss = 275.48119769\n",
      "Iteration 27821, loss = 275.44238076\n",
      "Iteration 27822, loss = 275.40357437\n",
      "Iteration 27823, loss = 275.36477853\n",
      "Iteration 27824, loss = 275.32599323\n",
      "Iteration 27825, loss = 275.28721846\n",
      "Iteration 27826, loss = 275.24845423\n",
      "Iteration 27827, loss = 275.20970053\n",
      "Iteration 27828, loss = 275.17095735\n",
      "Iteration 27829, loss = 275.13222469\n",
      "Iteration 27830, loss = 275.09350255\n",
      "Iteration 27831, loss = 275.05479093\n",
      "Iteration 27832, loss = 275.01608981\n",
      "Iteration 27833, loss = 274.97739920\n",
      "Iteration 27834, loss = 274.93871909\n",
      "Iteration 27835, loss = 274.90004947\n",
      "Iteration 27836, loss = 274.86139035\n",
      "Iteration 27837, loss = 274.82274172\n",
      "Iteration 27838, loss = 274.78410358\n",
      "Iteration 27839, loss = 274.74547591\n",
      "Iteration 27840, loss = 274.70685873\n",
      "Iteration 27841, loss = 274.66825202\n",
      "Iteration 27842, loss = 274.62965577\n",
      "Iteration 27843, loss = 274.59107000\n",
      "Iteration 27844, loss = 274.55249468\n",
      "Iteration 27845, loss = 274.51392983\n",
      "Iteration 27846, loss = 274.47537542\n",
      "Iteration 27847, loss = 274.43683147\n",
      "Iteration 27848, loss = 274.39829796\n",
      "Iteration 27849, loss = 274.35977490\n",
      "Iteration 27850, loss = 274.32126227\n",
      "Iteration 27851, loss = 274.28276008\n",
      "Iteration 27852, loss = 274.24426832\n",
      "Iteration 27853, loss = 274.20578698\n",
      "Iteration 27854, loss = 274.16731607\n",
      "Iteration 27855, loss = 274.12885557\n",
      "Iteration 27856, loss = 274.09040549\n",
      "Iteration 27857, loss = 274.05196582\n",
      "Iteration 27858, loss = 274.01353656\n",
      "Iteration 27859, loss = 273.97511770\n",
      "Iteration 27860, loss = 273.93670924\n",
      "Iteration 27861, loss = 273.89831118\n",
      "Iteration 27862, loss = 273.85992350\n",
      "Iteration 27863, loss = 273.82154622\n",
      "Iteration 27864, loss = 273.78317932\n",
      "Iteration 27865, loss = 273.74482279\n",
      "Iteration 27866, loss = 273.70647664\n",
      "Iteration 27867, loss = 273.66814087\n",
      "Iteration 27868, loss = 273.62981546\n",
      "Iteration 27869, loss = 273.59150042\n",
      "Iteration 27870, loss = 273.55319573\n",
      "Iteration 27871, loss = 273.51490140\n",
      "Iteration 27872, loss = 273.47661743\n",
      "Iteration 27873, loss = 273.43834380\n",
      "Iteration 27874, loss = 273.40008052\n",
      "Iteration 27875, loss = 273.36182758\n",
      "Iteration 27876, loss = 273.32358497\n",
      "Iteration 27877, loss = 273.28535270\n",
      "Iteration 27878, loss = 273.24713075\n",
      "Iteration 27879, loss = 273.20891914\n",
      "Iteration 27880, loss = 273.17071784\n",
      "Iteration 27881, loss = 273.13252686\n",
      "Iteration 27882, loss = 273.09434619\n",
      "Iteration 27883, loss = 273.05617583\n",
      "Iteration 27884, loss = 273.01801578\n",
      "Iteration 27885, loss = 272.97986603\n",
      "Iteration 27886, loss = 272.94172658\n",
      "Iteration 27887, loss = 272.90359743\n",
      "Iteration 27888, loss = 272.86547856\n",
      "Iteration 27889, loss = 272.82736998\n",
      "Iteration 27890, loss = 272.78927168\n",
      "Iteration 27891, loss = 272.75118366\n",
      "Iteration 27892, loss = 272.71310592\n",
      "Iteration 27893, loss = 272.67503845\n",
      "Iteration 27894, loss = 272.63698124\n",
      "Iteration 27895, loss = 272.59893430\n",
      "Iteration 27896, loss = 272.56089761\n",
      "Iteration 27897, loss = 272.52287119\n",
      "Iteration 27898, loss = 272.48485501\n",
      "Iteration 27899, loss = 272.44684908\n",
      "Iteration 27900, loss = 272.40885340\n",
      "Iteration 27901, loss = 272.37086796\n",
      "Iteration 27902, loss = 272.33289275\n",
      "Iteration 27903, loss = 272.29492777\n",
      "Iteration 27904, loss = 272.25697303\n",
      "Iteration 27905, loss = 272.21902851\n",
      "Iteration 27906, loss = 272.18109421\n",
      "Iteration 27907, loss = 272.14317013\n",
      "Iteration 27908, loss = 272.10525626\n",
      "Iteration 27909, loss = 272.06735260\n",
      "Iteration 27910, loss = 272.02945914\n",
      "Iteration 27911, loss = 271.99157589\n",
      "Iteration 27912, loss = 271.95370284\n",
      "Iteration 27913, loss = 271.91583998\n",
      "Iteration 27914, loss = 271.87798731\n",
      "Iteration 27915, loss = 271.84014483\n",
      "Iteration 27916, loss = 271.80231253\n",
      "Iteration 27917, loss = 271.76449041\n",
      "Iteration 27918, loss = 271.72667847\n",
      "Iteration 27919, loss = 271.68887669\n",
      "Iteration 27920, loss = 271.65108509\n",
      "Iteration 27921, loss = 271.61330364\n",
      "Iteration 27922, loss = 271.57553236\n",
      "Iteration 27923, loss = 271.53777124\n",
      "Iteration 27924, loss = 271.50002026\n",
      "Iteration 27925, loss = 271.46227944\n",
      "Iteration 27926, loss = 271.42454876\n",
      "Iteration 27927, loss = 271.38682822\n",
      "Iteration 27928, loss = 271.34911782\n",
      "Iteration 27929, loss = 271.31141755\n",
      "Iteration 27930, loss = 271.27372741\n",
      "Iteration 27931, loss = 271.23604740\n",
      "Iteration 27932, loss = 271.19837751\n",
      "Iteration 27933, loss = 271.16071774\n",
      "Iteration 27934, loss = 271.12306808\n",
      "Iteration 27935, loss = 271.08542853\n",
      "Iteration 27936, loss = 271.04779909\n",
      "Iteration 27937, loss = 271.01017975\n",
      "Iteration 27938, loss = 270.97257051\n",
      "Iteration 27939, loss = 270.93497137\n",
      "Iteration 27940, loss = 270.89738232\n",
      "Iteration 27941, loss = 270.85980336\n",
      "Iteration 27942, loss = 270.82223448\n",
      "Iteration 27943, loss = 270.78467568\n",
      "Iteration 27944, loss = 270.74712696\n",
      "Iteration 27945, loss = 270.70958831\n",
      "Iteration 27946, loss = 270.67205973\n",
      "Iteration 27947, loss = 270.63454122\n",
      "Iteration 27948, loss = 270.59703277\n",
      "Iteration 27949, loss = 270.55953437\n",
      "Iteration 27950, loss = 270.52204603\n",
      "Iteration 27951, loss = 270.48456774\n",
      "Iteration 27952, loss = 270.44709950\n",
      "Iteration 27953, loss = 270.40964130\n",
      "Iteration 27954, loss = 270.37219314\n",
      "Iteration 27955, loss = 270.33475501\n",
      "Iteration 27956, loss = 270.29732692\n",
      "Iteration 27957, loss = 270.25990885\n",
      "Iteration 27958, loss = 270.22250081\n",
      "Iteration 27959, loss = 270.18510279\n",
      "Iteration 27960, loss = 270.14771478\n",
      "Iteration 27961, loss = 270.11033679\n",
      "Iteration 27962, loss = 270.07296880\n",
      "Iteration 27963, loss = 270.03561083\n",
      "Iteration 27964, loss = 269.99826285\n",
      "Iteration 27965, loss = 269.96092487\n",
      "Iteration 27966, loss = 269.92359688\n",
      "Iteration 27967, loss = 269.88627889\n",
      "Iteration 27968, loss = 269.84897088\n",
      "Iteration 27969, loss = 269.81167286\n",
      "Iteration 27970, loss = 269.77438481\n",
      "Iteration 27971, loss = 269.73710674\n",
      "Iteration 27972, loss = 269.69983864\n",
      "Iteration 27973, loss = 269.66258051\n",
      "Iteration 27974, loss = 269.62533234\n",
      "Iteration 27975, loss = 269.58809414\n",
      "Iteration 27976, loss = 269.55086589\n",
      "Iteration 27977, loss = 269.51364759\n",
      "Iteration 27978, loss = 269.47643925\n",
      "Iteration 27979, loss = 269.43924084\n",
      "Iteration 27980, loss = 269.40205239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27981, loss = 269.36487386\n",
      "Iteration 27982, loss = 269.32770528\n",
      "Iteration 27983, loss = 269.29054662\n",
      "Iteration 27984, loss = 269.25339789\n",
      "Iteration 27985, loss = 269.21625909\n",
      "Iteration 27986, loss = 269.17913020\n",
      "Iteration 27987, loss = 269.14201123\n",
      "Iteration 27988, loss = 269.10490217\n",
      "Iteration 27989, loss = 269.06780303\n",
      "Iteration 27990, loss = 269.03071378\n",
      "Iteration 27991, loss = 268.99363444\n",
      "Iteration 27992, loss = 268.95656499\n",
      "Iteration 27993, loss = 268.91950544\n",
      "Iteration 27994, loss = 268.88245578\n",
      "Iteration 27995, loss = 268.84541600\n",
      "Iteration 27996, loss = 268.80838611\n",
      "Iteration 27997, loss = 268.77136610\n",
      "Iteration 27998, loss = 268.73435596\n",
      "Iteration 27999, loss = 268.69735570\n",
      "Iteration 28000, loss = 268.66036531\n",
      "Iteration 28001, loss = 268.62338479\n",
      "Iteration 28002, loss = 268.58641414\n",
      "Iteration 28003, loss = 268.54945339\n",
      "Iteration 28004, loss = 268.51250254\n",
      "Iteration 28005, loss = 268.47556167\n",
      "Iteration 28006, loss = 268.43863089\n",
      "Iteration 28007, loss = 268.40171044\n",
      "Iteration 28008, loss = 268.36480084\n",
      "Iteration 28009, loss = 268.32790307\n",
      "Iteration 28010, loss = 268.29101918\n",
      "Iteration 28011, loss = 268.25415274\n",
      "Iteration 28012, loss = 268.21731001\n",
      "Iteration 28013, loss = 268.18049687\n",
      "Iteration 28014, loss = 268.14371190\n",
      "Iteration 28015, loss = 268.10691778\n",
      "Iteration 28016, loss = 268.07005620\n",
      "Iteration 28017, loss = 268.03311967\n",
      "Iteration 28018, loss = 267.99622449\n",
      "Iteration 28019, loss = 267.95945117\n",
      "Iteration 28020, loss = 267.92272856\n",
      "Iteration 28021, loss = 267.88594150\n",
      "Iteration 28022, loss = 267.84909508\n",
      "Iteration 28023, loss = 267.81230417\n",
      "Iteration 28024, loss = 267.77559419\n",
      "Iteration 28025, loss = 267.73887159\n",
      "Iteration 28026, loss = 267.70209655\n",
      "Iteration 28027, loss = 267.66534266\n",
      "Iteration 28028, loss = 267.62865236\n",
      "Iteration 28029, loss = 267.59196619\n",
      "Iteration 28030, loss = 267.55524552\n",
      "Iteration 28031, loss = 267.51853941\n",
      "Iteration 28032, loss = 267.48187967\n",
      "Iteration 28033, loss = 267.44522528\n",
      "Iteration 28034, loss = 267.40855133\n",
      "Iteration 28035, loss = 267.37189230\n",
      "Iteration 28036, loss = 267.33526701\n",
      "Iteration 28037, loss = 267.29864588\n",
      "Iteration 28038, loss = 267.26201548\n",
      "Iteration 28039, loss = 267.22540115\n",
      "Iteration 28040, loss = 267.18881159\n",
      "Iteration 28041, loss = 267.15222541\n",
      "Iteration 28042, loss = 267.11563748\n",
      "Iteration 28043, loss = 267.07906560\n",
      "Iteration 28044, loss = 267.04251225\n",
      "Iteration 28045, loss = 267.00596273\n",
      "Iteration 28046, loss = 266.96941638\n",
      "Iteration 28047, loss = 266.93288524\n",
      "Iteration 28048, loss = 266.89636862\n",
      "Iteration 28049, loss = 266.85985682\n",
      "Iteration 28050, loss = 266.82335133\n",
      "Iteration 28051, loss = 266.78685983\n",
      "Iteration 28052, loss = 266.75038039\n",
      "Iteration 28053, loss = 266.71390698\n",
      "Iteration 28054, loss = 266.67744165\n",
      "Iteration 28055, loss = 266.64098913\n",
      "Iteration 28056, loss = 266.60454733\n",
      "Iteration 28057, loss = 266.56811258\n",
      "Iteration 28058, loss = 266.53168687\n",
      "Iteration 28059, loss = 266.49527298\n",
      "Iteration 28060, loss = 266.45886912\n",
      "Iteration 28061, loss = 266.42247314\n",
      "Iteration 28062, loss = 266.38608662\n",
      "Iteration 28063, loss = 266.34971119\n",
      "Iteration 28064, loss = 266.31334548\n",
      "Iteration 28065, loss = 266.27698823\n",
      "Iteration 28066, loss = 266.24064060\n",
      "Iteration 28067, loss = 266.20430356\n",
      "Iteration 28068, loss = 266.16797611\n",
      "Iteration 28069, loss = 266.13165751\n",
      "Iteration 28070, loss = 266.09534857\n",
      "Iteration 28071, loss = 266.05904987\n",
      "Iteration 28072, loss = 266.02276073\n",
      "Iteration 28073, loss = 265.98648068\n",
      "Iteration 28074, loss = 265.95021029\n",
      "Iteration 28075, loss = 265.91394990\n",
      "Iteration 28076, loss = 265.87769906\n",
      "Iteration 28077, loss = 265.84145748\n",
      "Iteration 28078, loss = 265.80522552\n",
      "Iteration 28079, loss = 265.76900340\n",
      "Iteration 28080, loss = 265.73279084\n",
      "Iteration 28081, loss = 265.69658764\n",
      "Iteration 28082, loss = 265.66039403\n",
      "Iteration 28083, loss = 265.62421015\n",
      "Iteration 28084, loss = 265.58803584\n",
      "Iteration 28085, loss = 265.55187094\n",
      "Iteration 28086, loss = 265.51571559\n",
      "Iteration 28087, loss = 265.47956992\n",
      "Iteration 28088, loss = 265.44343379\n",
      "Iteration 28089, loss = 265.40730712\n",
      "Iteration 28090, loss = 265.37118998\n",
      "Iteration 28091, loss = 265.33508246\n",
      "Iteration 28092, loss = 265.29898448\n",
      "Iteration 28093, loss = 265.26289597\n",
      "Iteration 28094, loss = 265.22681697\n",
      "Iteration 28095, loss = 265.19074754\n",
      "Iteration 28096, loss = 265.15468765\n",
      "Iteration 28097, loss = 265.11863724\n",
      "Iteration 28098, loss = 265.08259632\n",
      "Iteration 28099, loss = 265.04656495\n",
      "Iteration 28100, loss = 265.01054309\n",
      "Iteration 28101, loss = 264.97453071\n",
      "Iteration 28102, loss = 264.93852782\n",
      "Iteration 28103, loss = 264.90253443\n",
      "Iteration 28104, loss = 264.86655055\n",
      "Iteration 28105, loss = 264.83057615\n",
      "Iteration 28106, loss = 264.79461122\n",
      "Iteration 28107, loss = 264.75865578\n",
      "Iteration 28108, loss = 264.72270982\n",
      "Iteration 28109, loss = 264.68677333\n",
      "Iteration 28110, loss = 264.65084631\n",
      "Iteration 28111, loss = 264.61492875\n",
      "Iteration 28112, loss = 264.57902066\n",
      "Iteration 28113, loss = 264.54312203\n",
      "Iteration 28114, loss = 264.50723285\n",
      "Iteration 28115, loss = 264.47135312\n",
      "Iteration 28116, loss = 264.43548284\n",
      "Iteration 28117, loss = 264.39962201\n",
      "Iteration 28118, loss = 264.36377062\n",
      "Iteration 28119, loss = 264.32792866\n",
      "Iteration 28120, loss = 264.29209614\n",
      "Iteration 28121, loss = 264.25627305\n",
      "Iteration 28122, loss = 264.22045939\n",
      "Iteration 28123, loss = 264.18465515\n",
      "Iteration 28124, loss = 264.14886033\n",
      "Iteration 28125, loss = 264.11307492\n",
      "Iteration 28126, loss = 264.07729893\n",
      "Iteration 28127, loss = 264.04153235\n",
      "Iteration 28128, loss = 264.00577518\n",
      "Iteration 28129, loss = 263.97002740\n",
      "Iteration 28130, loss = 263.93428903\n",
      "Iteration 28131, loss = 263.89856005\n",
      "Iteration 28132, loss = 263.86284046\n",
      "Iteration 28133, loss = 263.82713026\n",
      "Iteration 28134, loss = 263.79142945\n",
      "Iteration 28135, loss = 263.75573801\n",
      "Iteration 28136, loss = 263.72005596\n",
      "Iteration 28137, loss = 263.68438328\n",
      "Iteration 28138, loss = 263.64871996\n",
      "Iteration 28139, loss = 263.61306602\n",
      "Iteration 28140, loss = 263.57742144\n",
      "Iteration 28141, loss = 263.54178622\n",
      "Iteration 28142, loss = 263.50616035\n",
      "Iteration 28143, loss = 263.47054384\n",
      "Iteration 28144, loss = 263.43493668\n",
      "Iteration 28145, loss = 263.39933886\n",
      "Iteration 28146, loss = 263.36375039\n",
      "Iteration 28147, loss = 263.32817125\n",
      "Iteration 28148, loss = 263.29260145\n",
      "Iteration 28149, loss = 263.25704099\n",
      "Iteration 28150, loss = 263.22148985\n",
      "Iteration 28151, loss = 263.18594803\n",
      "Iteration 28152, loss = 263.15041554\n",
      "Iteration 28153, loss = 263.11489236\n",
      "Iteration 28154, loss = 263.07937850\n",
      "Iteration 28155, loss = 263.04387395\n",
      "Iteration 28156, loss = 263.00837871\n",
      "Iteration 28157, loss = 262.97289277\n",
      "Iteration 28158, loss = 262.93741613\n",
      "Iteration 28159, loss = 262.90194879\n",
      "Iteration 28160, loss = 262.86649074\n",
      "Iteration 28161, loss = 262.83104198\n",
      "Iteration 28162, loss = 262.79560251\n",
      "Iteration 28163, loss = 262.76017232\n",
      "Iteration 28164, loss = 262.72475141\n",
      "Iteration 28165, loss = 262.68933977\n",
      "Iteration 28166, loss = 262.65393741\n",
      "Iteration 28167, loss = 262.61854432\n",
      "Iteration 28168, loss = 262.58316049\n",
      "Iteration 28169, loss = 262.54778593\n",
      "Iteration 28170, loss = 262.51242062\n",
      "Iteration 28171, loss = 262.47706456\n",
      "Iteration 28172, loss = 262.44171776\n",
      "Iteration 28173, loss = 262.40638021\n",
      "Iteration 28174, loss = 262.37105190\n",
      "Iteration 28175, loss = 262.33573283\n",
      "Iteration 28176, loss = 262.30042300\n",
      "Iteration 28177, loss = 262.26512241\n",
      "Iteration 28178, loss = 262.22983104\n",
      "Iteration 28179, loss = 262.19454890\n",
      "Iteration 28180, loss = 262.15927599\n",
      "Iteration 28181, loss = 262.12401229\n",
      "Iteration 28182, loss = 262.08875781\n",
      "Iteration 28183, loss = 262.05351255\n",
      "Iteration 28184, loss = 262.01827649\n",
      "Iteration 28185, loss = 261.98304964\n",
      "Iteration 28186, loss = 261.94783200\n",
      "Iteration 28187, loss = 261.91262355\n",
      "Iteration 28188, loss = 261.87742430\n",
      "Iteration 28189, loss = 261.84223424\n",
      "Iteration 28190, loss = 261.80705337\n",
      "Iteration 28191, loss = 261.77188168\n",
      "Iteration 28192, loss = 261.73671918\n",
      "Iteration 28193, loss = 261.70156585\n",
      "Iteration 28194, loss = 261.66642170\n",
      "Iteration 28195, loss = 261.63128673\n",
      "Iteration 28196, loss = 261.59616092\n",
      "Iteration 28197, loss = 261.56104427\n",
      "Iteration 28198, loss = 261.52593679\n",
      "Iteration 28199, loss = 261.49083846\n",
      "Iteration 28200, loss = 261.45574929\n",
      "Iteration 28201, loss = 261.42066927\n",
      "Iteration 28202, loss = 261.38559839\n",
      "Iteration 28203, loss = 261.35053666\n",
      "Iteration 28204, loss = 261.31548407\n",
      "Iteration 28205, loss = 261.28044062\n",
      "Iteration 28206, loss = 261.24540630\n",
      "Iteration 28207, loss = 261.21038111\n",
      "Iteration 28208, loss = 261.17536505\n",
      "Iteration 28209, loss = 261.14035811\n",
      "Iteration 28210, loss = 261.10536029\n",
      "Iteration 28211, loss = 261.07037158\n",
      "Iteration 28212, loss = 261.03539199\n",
      "Iteration 28213, loss = 261.00042151\n",
      "Iteration 28214, loss = 260.96546014\n",
      "Iteration 28215, loss = 260.93050786\n",
      "Iteration 28216, loss = 260.89556469\n",
      "Iteration 28217, loss = 260.86063061\n",
      "Iteration 28218, loss = 260.82570563\n",
      "Iteration 28219, loss = 260.79078973\n",
      "Iteration 28220, loss = 260.75588292\n",
      "Iteration 28221, loss = 260.72098519\n",
      "Iteration 28222, loss = 260.68609654\n",
      "Iteration 28223, loss = 260.65121696\n",
      "Iteration 28224, loss = 260.61634645\n",
      "Iteration 28225, loss = 260.58148502\n",
      "Iteration 28226, loss = 260.54663265\n",
      "Iteration 28227, loss = 260.51178933\n",
      "Iteration 28228, loss = 260.47695508\n",
      "Iteration 28229, loss = 260.44212988\n",
      "Iteration 28230, loss = 260.40731373\n",
      "Iteration 28231, loss = 260.37250663\n",
      "Iteration 28232, loss = 260.33770858\n",
      "Iteration 28233, loss = 260.30291956\n",
      "Iteration 28234, loss = 260.26813959\n",
      "Iteration 28235, loss = 260.23336864\n",
      "Iteration 28236, loss = 260.19860673\n",
      "Iteration 28237, loss = 260.16385384\n",
      "Iteration 28238, loss = 260.12910998\n",
      "Iteration 28239, loss = 260.09437513\n",
      "Iteration 28240, loss = 260.05964931\n",
      "Iteration 28241, loss = 260.02493250\n",
      "Iteration 28242, loss = 259.99022469\n",
      "Iteration 28243, loss = 259.95552590\n",
      "Iteration 28244, loss = 259.92083610\n",
      "Iteration 28245, loss = 259.88615531\n",
      "Iteration 28246, loss = 259.85148351\n",
      "Iteration 28247, loss = 259.81682071\n",
      "Iteration 28248, loss = 259.78216689\n",
      "Iteration 28249, loss = 259.74752206\n",
      "Iteration 28250, loss = 259.71288622\n",
      "Iteration 28251, loss = 259.67825935\n",
      "Iteration 28252, loss = 259.64364146\n",
      "Iteration 28253, loss = 259.60903254\n",
      "Iteration 28254, loss = 259.57443259\n",
      "Iteration 28255, loss = 259.53984160\n",
      "Iteration 28256, loss = 259.50525958\n",
      "Iteration 28257, loss = 259.47068652\n",
      "Iteration 28258, loss = 259.43612241\n",
      "Iteration 28259, loss = 259.40156725\n",
      "Iteration 28260, loss = 259.36702105\n",
      "Iteration 28261, loss = 259.33248378\n",
      "Iteration 28262, loss = 259.29795546\n",
      "Iteration 28263, loss = 259.26343608\n",
      "Iteration 28264, loss = 259.22892563\n",
      "Iteration 28265, loss = 259.19442412\n",
      "Iteration 28266, loss = 259.15993153\n",
      "Iteration 28267, loss = 259.12544787\n",
      "Iteration 28268, loss = 259.09097313\n",
      "Iteration 28269, loss = 259.05650730\n",
      "Iteration 28270, loss = 259.02205039\n",
      "Iteration 28271, loss = 258.98760240\n",
      "Iteration 28272, loss = 258.95316331\n",
      "Iteration 28273, loss = 258.91873312\n",
      "Iteration 28274, loss = 258.88431184\n",
      "Iteration 28275, loss = 258.84989945\n",
      "Iteration 28276, loss = 258.81549596\n",
      "Iteration 28277, loss = 258.78110136\n",
      "Iteration 28278, loss = 258.74671565\n",
      "Iteration 28279, loss = 258.71233882\n",
      "Iteration 28280, loss = 258.67797087\n",
      "Iteration 28281, loss = 258.64361180\n",
      "Iteration 28282, loss = 258.60926160\n",
      "Iteration 28283, loss = 258.57492027\n",
      "Iteration 28284, loss = 258.54058781\n",
      "Iteration 28285, loss = 258.50626422\n",
      "Iteration 28286, loss = 258.47194948\n",
      "Iteration 28287, loss = 258.43764360\n",
      "Iteration 28288, loss = 258.40334658\n",
      "Iteration 28289, loss = 258.36905840\n",
      "Iteration 28290, loss = 258.33477908\n",
      "Iteration 28291, loss = 258.30050859\n",
      "Iteration 28292, loss = 258.26624695\n",
      "Iteration 28293, loss = 258.23199414\n",
      "Iteration 28294, loss = 258.19775017\n",
      "Iteration 28295, loss = 258.16351503\n",
      "Iteration 28296, loss = 258.12928871\n",
      "Iteration 28297, loss = 258.09507122\n",
      "Iteration 28298, loss = 258.06086255\n",
      "Iteration 28299, loss = 258.02666269\n",
      "Iteration 28300, loss = 257.99247165\n",
      "Iteration 28301, loss = 257.95828942\n",
      "Iteration 28302, loss = 257.92411599\n",
      "Iteration 28303, loss = 257.88995137\n",
      "Iteration 28304, loss = 257.85579554\n",
      "Iteration 28305, loss = 257.82164852\n",
      "Iteration 28306, loss = 257.78751028\n",
      "Iteration 28307, loss = 257.75338084\n",
      "Iteration 28308, loss = 257.71926018\n",
      "Iteration 28309, loss = 257.68514831\n",
      "Iteration 28310, loss = 257.65104522\n",
      "Iteration 28311, loss = 257.61695090\n",
      "Iteration 28312, loss = 257.58286535\n",
      "Iteration 28313, loss = 257.54878858\n",
      "Iteration 28314, loss = 257.51472057\n",
      "Iteration 28315, loss = 257.48066132\n",
      "Iteration 28316, loss = 257.44661083\n",
      "Iteration 28317, loss = 257.41256910\n",
      "Iteration 28318, loss = 257.37853613\n",
      "Iteration 28319, loss = 257.34451190\n",
      "Iteration 28320, loss = 257.31049642\n",
      "Iteration 28321, loss = 257.27648968\n",
      "Iteration 28322, loss = 257.24249168\n",
      "Iteration 28323, loss = 257.20850241\n",
      "Iteration 28324, loss = 257.17452188\n",
      "Iteration 28325, loss = 257.14055008\n",
      "Iteration 28326, loss = 257.10658701\n",
      "Iteration 28327, loss = 257.07263266\n",
      "Iteration 28328, loss = 257.03868702\n",
      "Iteration 28329, loss = 257.00475011\n",
      "Iteration 28330, loss = 256.97082190\n",
      "Iteration 28331, loss = 256.93690241\n",
      "Iteration 28332, loss = 256.90299162\n",
      "Iteration 28333, loss = 256.86908954\n",
      "Iteration 28334, loss = 256.83519615\n",
      "Iteration 28335, loss = 256.80131146\n",
      "Iteration 28336, loss = 256.76743546\n",
      "Iteration 28337, loss = 256.73356816\n",
      "Iteration 28338, loss = 256.69970953\n",
      "Iteration 28339, loss = 256.66585960\n",
      "Iteration 28340, loss = 256.63201834\n",
      "Iteration 28341, loss = 256.59818576\n",
      "Iteration 28342, loss = 256.56436186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28343, loss = 256.53054663\n",
      "Iteration 28344, loss = 256.49674008\n",
      "Iteration 28345, loss = 256.46294221\n",
      "Iteration 28346, loss = 256.42915303\n",
      "Iteration 28347, loss = 256.39537255\n",
      "Iteration 28348, loss = 256.36160082\n",
      "Iteration 28349, loss = 256.32783789\n",
      "Iteration 28350, loss = 256.29408384\n",
      "Iteration 28351, loss = 256.26033883\n",
      "Iteration 28352, loss = 256.22660294\n",
      "Iteration 28353, loss = 256.19287625\n",
      "Iteration 28354, loss = 256.15915823\n",
      "Iteration 28355, loss = 256.12544800\n",
      "Iteration 28356, loss = 256.09174405\n",
      "Iteration 28357, loss = 256.05804653\n",
      "Iteration 28358, loss = 256.02435737\n",
      "Iteration 28359, loss = 255.99067912\n",
      "Iteration 28360, loss = 255.95701213\n",
      "Iteration 28361, loss = 255.92335445\n",
      "Iteration 28362, loss = 255.88970389\n",
      "Iteration 28363, loss = 255.85605982\n",
      "Iteration 28364, loss = 255.82242393\n",
      "Iteration 28365, loss = 255.78879809\n",
      "Iteration 28366, loss = 255.75518238\n",
      "Iteration 28367, loss = 255.72157526\n",
      "Iteration 28368, loss = 255.68797544\n",
      "Iteration 28369, loss = 255.65438330\n",
      "Iteration 28370, loss = 255.62080017\n",
      "Iteration 28371, loss = 255.58722668\n",
      "Iteration 28372, loss = 255.55366214\n",
      "Iteration 28373, loss = 255.52010556\n",
      "Iteration 28374, loss = 255.48655685\n",
      "Iteration 28375, loss = 255.45301675\n",
      "Iteration 28376, loss = 255.41948581\n",
      "Iteration 28377, loss = 255.38596380\n",
      "Iteration 28378, loss = 255.35245008\n",
      "Iteration 28379, loss = 255.31894445\n",
      "Iteration 28380, loss = 255.28544730\n",
      "Iteration 28381, loss = 255.25195903\n",
      "Iteration 28382, loss = 255.21847956\n",
      "Iteration 28383, loss = 255.18500853\n",
      "Iteration 28384, loss = 255.15154576\n",
      "Iteration 28385, loss = 255.11809143\n",
      "Iteration 28386, loss = 255.08464580\n",
      "Iteration 28387, loss = 255.05120888\n",
      "Iteration 28388, loss = 255.01778045\n",
      "Iteration 28389, loss = 254.98436038\n",
      "Iteration 28390, loss = 254.95094874\n",
      "Iteration 28391, loss = 254.91754570\n",
      "Iteration 28392, loss = 254.88415128\n",
      "Iteration 28393, loss = 254.85076537\n",
      "Iteration 28394, loss = 254.81738787\n",
      "Iteration 28395, loss = 254.78401882\n",
      "Iteration 28396, loss = 254.75065828\n",
      "Iteration 28397, loss = 254.71730632\n",
      "Iteration 28398, loss = 254.68396286\n",
      "Iteration 28399, loss = 254.65062784\n",
      "Iteration 28400, loss = 254.61730126\n",
      "Iteration 28401, loss = 254.58398316\n",
      "Iteration 28402, loss = 254.55067359\n",
      "Iteration 28403, loss = 254.51737251\n",
      "Iteration 28404, loss = 254.48407989\n",
      "Iteration 28405, loss = 254.45079571\n",
      "Iteration 28406, loss = 254.41752000\n",
      "Iteration 28407, loss = 254.38425280\n",
      "Iteration 28408, loss = 254.35099409\n",
      "Iteration 28409, loss = 254.31774389\n",
      "Iteration 28410, loss = 254.28450219\n",
      "Iteration 28411, loss = 254.25126904\n",
      "Iteration 28412, loss = 254.21804452\n",
      "Iteration 28413, loss = 254.18482873\n",
      "Iteration 28414, loss = 254.15162182\n",
      "Iteration 28415, loss = 254.11842400\n",
      "Iteration 28416, loss = 254.08523560\n",
      "Iteration 28417, loss = 254.05205715\n",
      "Iteration 28418, loss = 254.01888920\n",
      "Iteration 28419, loss = 253.98573247\n",
      "Iteration 28420, loss = 253.95258690\n",
      "Iteration 28421, loss = 253.91945177\n",
      "Iteration 28422, loss = 253.88632310\n",
      "Iteration 28423, loss = 253.85319572\n",
      "Iteration 28424, loss = 253.82006303\n",
      "Iteration 28425, loss = 253.78692625\n",
      "Iteration 28426, loss = 253.75379430\n",
      "Iteration 28427, loss = 253.72068036\n",
      "Iteration 28428, loss = 253.68759043\n",
      "Iteration 28429, loss = 253.65451990\n",
      "Iteration 28430, loss = 253.62145814\n",
      "Iteration 28431, loss = 253.58839577\n",
      "Iteration 28432, loss = 253.55533110\n",
      "Iteration 28433, loss = 253.52227037\n",
      "Iteration 28434, loss = 253.48922275\n",
      "Iteration 28435, loss = 253.45619227\n",
      "Iteration 28436, loss = 253.42317555\n",
      "Iteration 28437, loss = 253.39016576\n",
      "Iteration 28438, loss = 253.35715836\n",
      "Iteration 28439, loss = 253.32415447\n",
      "Iteration 28440, loss = 253.29115895\n",
      "Iteration 28441, loss = 253.25817588\n",
      "Iteration 28442, loss = 253.22520527\n",
      "Iteration 28443, loss = 253.19224383\n",
      "Iteration 28444, loss = 253.15928825\n",
      "Iteration 28445, loss = 253.12633786\n",
      "Iteration 28446, loss = 253.09339475\n",
      "Iteration 28447, loss = 253.06046150\n",
      "Iteration 28448, loss = 253.02753897\n",
      "Iteration 28449, loss = 252.99462593\n",
      "Iteration 28450, loss = 252.96172045\n",
      "Iteration 28451, loss = 252.92882160\n",
      "Iteration 28452, loss = 252.89593001\n",
      "Iteration 28453, loss = 252.86304705\n",
      "Iteration 28454, loss = 252.83017358\n",
      "Iteration 28455, loss = 252.79730935\n",
      "Iteration 28456, loss = 252.76445344\n",
      "Iteration 28457, loss = 252.73160509\n",
      "Iteration 28458, loss = 252.69876427\n",
      "Iteration 28459, loss = 252.66593156\n",
      "Iteration 28460, loss = 252.63310759\n",
      "Iteration 28461, loss = 252.60029249\n",
      "Iteration 28462, loss = 252.56748595\n",
      "Iteration 28463, loss = 252.53468749\n",
      "Iteration 28464, loss = 252.50189688\n",
      "Iteration 28465, loss = 252.46911427\n",
      "Iteration 28466, loss = 252.43633996\n",
      "Iteration 28467, loss = 252.40357419\n",
      "Iteration 28468, loss = 252.37081695\n",
      "Iteration 28469, loss = 252.33806801\n",
      "Iteration 28470, loss = 252.30532720\n",
      "Iteration 28471, loss = 252.27259443\n",
      "Iteration 28472, loss = 252.23986981\n",
      "Iteration 28473, loss = 252.20715348\n",
      "Iteration 28474, loss = 252.17444553\n",
      "Iteration 28475, loss = 252.14174593\n",
      "Iteration 28476, loss = 252.10905458\n",
      "Iteration 28477, loss = 252.07637139\n",
      "Iteration 28478, loss = 252.04369634\n",
      "Iteration 28479, loss = 252.01102946\n",
      "Iteration 28480, loss = 251.97837083\n",
      "Iteration 28481, loss = 251.94572048\n",
      "Iteration 28482, loss = 251.91307839\n",
      "Iteration 28483, loss = 251.88044454\n",
      "Iteration 28484, loss = 251.84781886\n",
      "Iteration 28485, loss = 251.81520135\n",
      "Iteration 28486, loss = 251.78259201\n",
      "Iteration 28487, loss = 251.74999087\n",
      "Iteration 28488, loss = 251.71739795\n",
      "Iteration 28489, loss = 251.68481325\n",
      "Iteration 28490, loss = 251.65223676\n",
      "Iteration 28491, loss = 251.61966844\n",
      "Iteration 28492, loss = 251.58710829\n",
      "Iteration 28493, loss = 251.55455631\n",
      "Iteration 28494, loss = 251.52201249\n",
      "Iteration 28495, loss = 251.48947685\n",
      "Iteration 28496, loss = 251.45694939\n",
      "Iteration 28497, loss = 251.42443011\n",
      "Iteration 28498, loss = 251.39191900\n",
      "Iteration 28499, loss = 251.35941604\n",
      "Iteration 28500, loss = 251.32692124\n",
      "Iteration 28501, loss = 251.29443458\n",
      "Iteration 28502, loss = 251.26195607\n",
      "Iteration 28503, loss = 251.22948570\n",
      "Iteration 28504, loss = 251.19702349\n",
      "Iteration 28505, loss = 251.16456942\n",
      "Iteration 28506, loss = 251.13212350\n",
      "Iteration 28507, loss = 251.09968570\n",
      "Iteration 28508, loss = 251.06725604\n",
      "Iteration 28509, loss = 251.03483450\n",
      "Iteration 28510, loss = 251.00242108\n",
      "Iteration 28511, loss = 250.97001579\n",
      "Iteration 28512, loss = 250.93761861\n",
      "Iteration 28513, loss = 250.90522955\n",
      "Iteration 28514, loss = 250.87284861\n",
      "Iteration 28515, loss = 250.84047578\n",
      "Iteration 28516, loss = 250.80811105\n",
      "Iteration 28517, loss = 250.77575442\n",
      "Iteration 28518, loss = 250.74340589\n",
      "Iteration 28519, loss = 250.71106546\n",
      "Iteration 28520, loss = 250.67873312\n",
      "Iteration 28521, loss = 250.64640887\n",
      "Iteration 28522, loss = 250.61409271\n",
      "Iteration 28523, loss = 250.58178463\n",
      "Iteration 28524, loss = 250.54948463\n",
      "Iteration 28525, loss = 250.51719271\n",
      "Iteration 28526, loss = 250.48490886\n",
      "Iteration 28527, loss = 250.45263309\n",
      "Iteration 28528, loss = 250.42036538\n",
      "Iteration 28529, loss = 250.38810574\n",
      "Iteration 28530, loss = 250.35585415\n",
      "Iteration 28531, loss = 250.32361063\n",
      "Iteration 28532, loss = 250.29137516\n",
      "Iteration 28533, loss = 250.25914774\n",
      "Iteration 28534, loss = 250.22692837\n",
      "Iteration 28535, loss = 250.19471705\n",
      "Iteration 28536, loss = 250.16251376\n",
      "Iteration 28537, loss = 250.13031852\n",
      "Iteration 28538, loss = 250.09813132\n",
      "Iteration 28539, loss = 250.06595214\n",
      "Iteration 28540, loss = 250.03378100\n",
      "Iteration 28541, loss = 250.00161788\n",
      "Iteration 28542, loss = 249.96946278\n",
      "Iteration 28543, loss = 249.93731571\n",
      "Iteration 28544, loss = 249.90517665\n",
      "Iteration 28545, loss = 249.87304561\n",
      "Iteration 28546, loss = 249.84092257\n",
      "Iteration 28547, loss = 249.80880755\n",
      "Iteration 28548, loss = 249.77670052\n",
      "Iteration 28549, loss = 249.74460150\n",
      "Iteration 28550, loss = 249.71251048\n",
      "Iteration 28551, loss = 249.68042745\n",
      "Iteration 28552, loss = 249.64835241\n",
      "Iteration 28553, loss = 249.61628537\n",
      "Iteration 28554, loss = 249.58422630\n",
      "Iteration 28555, loss = 249.55217522\n",
      "Iteration 28556, loss = 249.52013212\n",
      "Iteration 28557, loss = 249.48809699\n",
      "Iteration 28558, loss = 249.45606984\n",
      "Iteration 28559, loss = 249.42405065\n",
      "Iteration 28560, loss = 249.39203944\n",
      "Iteration 28561, loss = 249.36003618\n",
      "Iteration 28562, loss = 249.32804089\n",
      "Iteration 28563, loss = 249.29605355\n",
      "Iteration 28564, loss = 249.26407417\n",
      "Iteration 28565, loss = 249.23210273\n",
      "Iteration 28566, loss = 249.20013925\n",
      "Iteration 28567, loss = 249.16818370\n",
      "Iteration 28568, loss = 249.13623610\n",
      "Iteration 28569, loss = 249.10429644\n",
      "Iteration 28570, loss = 249.07236471\n",
      "Iteration 28571, loss = 249.04044092\n",
      "Iteration 28572, loss = 249.00852505\n",
      "Iteration 28573, loss = 248.97661711\n",
      "Iteration 28574, loss = 248.94471709\n",
      "Iteration 28575, loss = 248.91282499\n",
      "Iteration 28576, loss = 248.88094080\n",
      "Iteration 28577, loss = 248.84906453\n",
      "Iteration 28578, loss = 248.81719617\n",
      "Iteration 28579, loss = 248.78533571\n",
      "Iteration 28580, loss = 248.75348316\n",
      "Iteration 28581, loss = 248.72163851\n",
      "Iteration 28582, loss = 248.68980175\n",
      "Iteration 28583, loss = 248.65797289\n",
      "Iteration 28584, loss = 248.62615192\n",
      "Iteration 28585, loss = 248.59433884\n",
      "Iteration 28586, loss = 248.56253364\n",
      "Iteration 28587, loss = 248.53073633\n",
      "Iteration 28588, loss = 248.49894689\n",
      "Iteration 28589, loss = 248.46716533\n",
      "Iteration 28590, loss = 248.43539164\n",
      "Iteration 28591, loss = 248.40362582\n",
      "Iteration 28592, loss = 248.37186786\n",
      "Iteration 28593, loss = 248.34011777\n",
      "Iteration 28594, loss = 248.30837553\n",
      "Iteration 28595, loss = 248.27664116\n",
      "Iteration 28596, loss = 248.24491464\n",
      "Iteration 28597, loss = 248.21319596\n",
      "Iteration 28598, loss = 248.18148514\n",
      "Iteration 28599, loss = 248.14978216\n",
      "Iteration 28600, loss = 248.11808701\n",
      "Iteration 28601, loss = 248.08639971\n",
      "Iteration 28602, loss = 248.05472024\n",
      "Iteration 28603, loss = 248.02304861\n",
      "Iteration 28604, loss = 247.99138480\n",
      "Iteration 28605, loss = 247.95972882\n",
      "Iteration 28606, loss = 247.92808066\n",
      "Iteration 28607, loss = 247.89644032\n",
      "Iteration 28608, loss = 247.86480780\n",
      "Iteration 28609, loss = 247.83318310\n",
      "Iteration 28610, loss = 247.80156622\n",
      "Iteration 28611, loss = 247.76995715\n",
      "Iteration 28612, loss = 247.73835590\n",
      "Iteration 28613, loss = 247.70676247\n",
      "Iteration 28614, loss = 247.67517689\n",
      "Iteration 28615, loss = 247.64359916\n",
      "Iteration 28616, loss = 247.61202933\n",
      "Iteration 28617, loss = 247.58046747\n",
      "Iteration 28618, loss = 247.54891369\n",
      "Iteration 28619, loss = 247.51736816\n",
      "Iteration 28620, loss = 247.48583119\n",
      "Iteration 28621, loss = 247.45430325\n",
      "Iteration 28622, loss = 247.42278507\n",
      "Iteration 28623, loss = 247.39127760\n",
      "Iteration 28624, loss = 247.35978210\n",
      "Iteration 28625, loss = 247.32829893\n",
      "Iteration 28626, loss = 247.29682715\n",
      "Iteration 28627, loss = 247.26536016\n",
      "Iteration 28628, loss = 247.23388851\n",
      "Iteration 28629, loss = 247.20240171\n",
      "Iteration 28630, loss = 247.17090553\n",
      "Iteration 28631, loss = 247.13941984\n",
      "Iteration 28632, loss = 247.10796442\n",
      "Iteration 28633, loss = 247.07653978\n",
      "Iteration 28634, loss = 247.04512904\n",
      "Iteration 28635, loss = 247.01371342\n",
      "Iteration 28636, loss = 246.98228654\n",
      "Iteration 28637, loss = 246.95086031\n",
      "Iteration 28638, loss = 246.91945167\n",
      "Iteration 28639, loss = 246.88806590\n",
      "Iteration 28640, loss = 246.85669323\n",
      "Iteration 28641, loss = 246.82532055\n",
      "Iteration 28642, loss = 246.79394463\n",
      "Iteration 28643, loss = 246.76257358\n",
      "Iteration 28644, loss = 246.73121724\n",
      "Iteration 28645, loss = 246.69987664\n",
      "Iteration 28646, loss = 246.66854462\n",
      "Iteration 28647, loss = 246.63721455\n",
      "Iteration 28648, loss = 246.60588682\n",
      "Iteration 28649, loss = 246.57456741\n",
      "Iteration 28650, loss = 246.54326054\n",
      "Iteration 28651, loss = 246.51196473\n",
      "Iteration 28652, loss = 246.48067535\n",
      "Iteration 28653, loss = 246.44938995\n",
      "Iteration 28654, loss = 246.41811039\n",
      "Iteration 28655, loss = 246.38684009\n",
      "Iteration 28656, loss = 246.35558022\n",
      "Iteration 28657, loss = 246.32432893\n",
      "Iteration 28658, loss = 246.29308380\n",
      "Iteration 28659, loss = 246.26184443\n",
      "Iteration 28660, loss = 246.23061245\n",
      "Iteration 28661, loss = 246.19938945\n",
      "Iteration 28662, loss = 246.16817540\n",
      "Iteration 28663, loss = 246.13696897\n",
      "Iteration 28664, loss = 246.10576913\n",
      "Iteration 28665, loss = 246.07457611\n",
      "Iteration 28666, loss = 246.04339091\n",
      "Iteration 28667, loss = 246.01221418\n",
      "Iteration 28668, loss = 245.98104562\n",
      "Iteration 28669, loss = 245.94988446\n",
      "Iteration 28670, loss = 245.91873032\n",
      "Iteration 28671, loss = 245.88758347\n",
      "Iteration 28672, loss = 245.85644447\n",
      "Iteration 28673, loss = 245.82531354\n",
      "Iteration 28674, loss = 245.79419042\n",
      "Iteration 28675, loss = 245.76307474\n",
      "Iteration 28676, loss = 245.73196634\n",
      "Iteration 28677, loss = 245.70086541\n",
      "Iteration 28678, loss = 245.66977223\n",
      "Iteration 28679, loss = 245.63868689\n",
      "Iteration 28680, loss = 245.60760923\n",
      "Iteration 28681, loss = 245.57653905\n",
      "Iteration 28682, loss = 245.54547629\n",
      "Iteration 28683, loss = 245.51442106\n",
      "Iteration 28684, loss = 245.48337348\n",
      "Iteration 28685, loss = 245.45233362\n",
      "Iteration 28686, loss = 245.42130137\n",
      "Iteration 28687, loss = 245.39027665\n",
      "Iteration 28688, loss = 245.35925940\n",
      "Iteration 28689, loss = 245.32824969\n",
      "Iteration 28690, loss = 245.29724757\n",
      "Iteration 28691, loss = 245.26625308\n",
      "Iteration 28692, loss = 245.23526618\n",
      "Iteration 28693, loss = 245.20428681\n",
      "Iteration 28694, loss = 245.17331495\n",
      "Iteration 28695, loss = 245.14235061\n",
      "Iteration 28696, loss = 245.11139382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28697, loss = 245.08044461\n",
      "Iteration 28698, loss = 245.04950296\n",
      "Iteration 28699, loss = 245.01856885\n",
      "Iteration 28700, loss = 244.98764225\n",
      "Iteration 28701, loss = 244.95672316\n",
      "Iteration 28702, loss = 244.92581159\n",
      "Iteration 28703, loss = 244.89490756\n",
      "Iteration 28704, loss = 244.86401107\n",
      "Iteration 28705, loss = 244.83312210\n",
      "Iteration 28706, loss = 244.80224063\n",
      "Iteration 28707, loss = 244.77136667\n",
      "Iteration 28708, loss = 244.74050021\n",
      "Iteration 28709, loss = 244.70964126\n",
      "Iteration 28710, loss = 244.67878982\n",
      "Iteration 28711, loss = 244.64794589\n",
      "Iteration 28712, loss = 244.61710946\n",
      "Iteration 28713, loss = 244.58628051\n",
      "Iteration 28714, loss = 244.55545905\n",
      "Iteration 28715, loss = 244.52464509\n",
      "Iteration 28716, loss = 244.49383861\n",
      "Iteration 28717, loss = 244.46303962\n",
      "Iteration 28718, loss = 244.43224812\n",
      "Iteration 28719, loss = 244.40146411\n",
      "Iteration 28720, loss = 244.37068758\n",
      "Iteration 28721, loss = 244.33991854\n",
      "Iteration 28722, loss = 244.30915700\n",
      "Iteration 28723, loss = 244.27840297\n",
      "Iteration 28724, loss = 244.24765645\n",
      "Iteration 28725, loss = 244.21691746\n",
      "Iteration 28726, loss = 244.18618601\n",
      "Iteration 28727, loss = 244.15546210\n",
      "Iteration 28728, loss = 244.12474571\n",
      "Iteration 28729, loss = 244.09403677\n",
      "Iteration 28730, loss = 244.06333519\n",
      "Iteration 28731, loss = 244.03264078\n",
      "Iteration 28732, loss = 244.00195344\n",
      "Iteration 28733, loss = 243.97127308\n",
      "Iteration 28734, loss = 243.94059989\n",
      "Iteration 28735, loss = 243.90993412\n",
      "Iteration 28736, loss = 243.87927608\n",
      "Iteration 28737, loss = 243.84862590\n",
      "Iteration 28738, loss = 243.81798353\n",
      "Iteration 28739, loss = 243.78734877\n",
      "Iteration 28740, loss = 243.75672137\n",
      "Iteration 28741, loss = 243.72610116\n",
      "Iteration 28742, loss = 243.69548808\n",
      "Iteration 28743, loss = 243.66488220\n",
      "Iteration 28744, loss = 243.63428369\n",
      "Iteration 28745, loss = 243.60369270\n",
      "Iteration 28746, loss = 243.57310931\n",
      "Iteration 28747, loss = 243.54253347\n",
      "Iteration 28748, loss = 243.51196508\n",
      "Iteration 28749, loss = 243.48140402\n",
      "Iteration 28750, loss = 243.45085024\n",
      "Iteration 28751, loss = 243.42030372\n",
      "Iteration 28752, loss = 243.38976452\n",
      "Iteration 28753, loss = 243.35923271\n",
      "Iteration 28754, loss = 243.32870834\n",
      "Iteration 28755, loss = 243.29819142\n",
      "Iteration 28756, loss = 243.26768192\n",
      "Iteration 28757, loss = 243.23717978\n",
      "Iteration 28758, loss = 243.20668496\n",
      "Iteration 28759, loss = 243.17619744\n",
      "Iteration 28760, loss = 243.14571725\n",
      "Iteration 28761, loss = 243.11524439\n",
      "Iteration 28762, loss = 243.08477889\n",
      "Iteration 28763, loss = 243.05432078\n",
      "Iteration 28764, loss = 243.02387003\n",
      "Iteration 28765, loss = 242.99342663\n",
      "Iteration 28766, loss = 242.96299056\n",
      "Iteration 28767, loss = 242.93256181\n",
      "Iteration 28768, loss = 242.90214037\n",
      "Iteration 28769, loss = 242.87172624\n",
      "Iteration 28770, loss = 242.84131943\n",
      "Iteration 28771, loss = 242.81091995\n",
      "Iteration 28772, loss = 242.78052780\n",
      "Iteration 28773, loss = 242.75014297\n",
      "Iteration 28774, loss = 242.71976546\n",
      "Iteration 28775, loss = 242.68939525\n",
      "Iteration 28776, loss = 242.65903234\n",
      "Iteration 28777, loss = 242.62867673\n",
      "Iteration 28778, loss = 242.59832841\n",
      "Iteration 28779, loss = 242.56798739\n",
      "Iteration 28780, loss = 242.53765366\n",
      "Iteration 28781, loss = 242.50732723\n",
      "Iteration 28782, loss = 242.47700808\n",
      "Iteration 28783, loss = 242.44669623\n",
      "Iteration 28784, loss = 242.41639165\n",
      "Iteration 28785, loss = 242.38609436\n",
      "Iteration 28786, loss = 242.35580433\n",
      "Iteration 28787, loss = 242.32552157\n",
      "Iteration 28788, loss = 242.29524609\n",
      "Iteration 28789, loss = 242.26497787\n",
      "Iteration 28790, loss = 242.23471691\n",
      "Iteration 28791, loss = 242.20446322\n",
      "Iteration 28792, loss = 242.17421678\n",
      "Iteration 28793, loss = 242.14397760\n",
      "Iteration 28794, loss = 242.11374567\n",
      "Iteration 28795, loss = 242.08352099\n",
      "Iteration 28796, loss = 242.05330355\n",
      "Iteration 28797, loss = 242.02309336\n",
      "Iteration 28798, loss = 241.99289041\n",
      "Iteration 28799, loss = 241.96269469\n",
      "Iteration 28800, loss = 241.93250621\n",
      "Iteration 28801, loss = 241.90232495\n",
      "Iteration 28802, loss = 241.87215093\n",
      "Iteration 28803, loss = 241.84198413\n",
      "Iteration 28804, loss = 241.81182456\n",
      "Iteration 28805, loss = 241.78167220\n",
      "Iteration 28806, loss = 241.75152706\n",
      "Iteration 28807, loss = 241.72138913\n",
      "Iteration 28808, loss = 241.69125842\n",
      "Iteration 28809, loss = 241.66113491\n",
      "Iteration 28810, loss = 241.63101860\n",
      "Iteration 28811, loss = 241.60090950\n",
      "Iteration 28812, loss = 241.57080759\n",
      "Iteration 28813, loss = 241.54071288\n",
      "Iteration 28814, loss = 241.51062537\n",
      "Iteration 28815, loss = 241.48054504\n",
      "Iteration 28816, loss = 241.45047190\n",
      "Iteration 28817, loss = 241.42040595\n",
      "Iteration 28818, loss = 241.39034717\n",
      "Iteration 28819, loss = 241.36029558\n",
      "Iteration 28820, loss = 241.33025116\n",
      "Iteration 28821, loss = 241.30021391\n",
      "Iteration 28822, loss = 241.27018383\n",
      "Iteration 28823, loss = 241.24016092\n",
      "Iteration 28824, loss = 241.21014517\n",
      "Iteration 28825, loss = 241.18013658\n",
      "Iteration 28826, loss = 241.15013515\n",
      "Iteration 28827, loss = 241.12014088\n",
      "Iteration 28828, loss = 241.09015376\n",
      "Iteration 28829, loss = 241.06017378\n",
      "Iteration 28830, loss = 241.03020095\n",
      "Iteration 28831, loss = 241.00023527\n",
      "Iteration 28832, loss = 240.97027672\n",
      "Iteration 28833, loss = 240.94032532\n",
      "Iteration 28834, loss = 240.91038104\n",
      "Iteration 28835, loss = 240.88044390\n",
      "Iteration 28836, loss = 240.85051389\n",
      "Iteration 28837, loss = 240.82059100\n",
      "Iteration 28838, loss = 240.79067524\n",
      "Iteration 28839, loss = 240.76076660\n",
      "Iteration 28840, loss = 240.73086507\n",
      "Iteration 28841, loss = 240.70097066\n",
      "Iteration 28842, loss = 240.67108335\n",
      "Iteration 28843, loss = 240.64120316\n",
      "Iteration 28844, loss = 240.61133007\n",
      "Iteration 28845, loss = 240.58146409\n",
      "Iteration 28846, loss = 240.55160520\n",
      "Iteration 28847, loss = 240.52175341\n",
      "Iteration 28848, loss = 240.49190872\n",
      "Iteration 28849, loss = 240.46207111\n",
      "Iteration 28850, loss = 240.43224060\n",
      "Iteration 28851, loss = 240.40241717\n",
      "Iteration 28852, loss = 240.37260082\n",
      "Iteration 28853, loss = 240.34279155\n",
      "Iteration 28854, loss = 240.31298936\n",
      "Iteration 28855, loss = 240.28319424\n",
      "Iteration 28856, loss = 240.25340619\n",
      "Iteration 28857, loss = 240.22362521\n",
      "Iteration 28858, loss = 240.19385130\n",
      "Iteration 28859, loss = 240.16408445\n",
      "Iteration 28860, loss = 240.13432467\n",
      "Iteration 28861, loss = 240.10457194\n",
      "Iteration 28862, loss = 240.07482627\n",
      "Iteration 28863, loss = 240.04508767\n",
      "Iteration 28864, loss = 240.01535614\n",
      "Iteration 28865, loss = 239.98563168\n",
      "Iteration 28866, loss = 239.95591433\n",
      "Iteration 28867, loss = 239.92620410\n",
      "Iteration 28868, loss = 239.89650109\n",
      "Iteration 28869, loss = 239.86680538\n",
      "Iteration 28870, loss = 239.83711719\n",
      "Iteration 28871, loss = 239.80743684\n",
      "Iteration 28872, loss = 239.77776490\n",
      "Iteration 28873, loss = 239.74810224\n",
      "Iteration 28874, loss = 239.71845027\n",
      "Iteration 28875, loss = 239.68881050\n",
      "Iteration 28876, loss = 239.65918449\n",
      "Iteration 28877, loss = 239.62957025\n",
      "Iteration 28878, loss = 239.59996100\n",
      "Iteration 28879, loss = 239.57033981\n",
      "Iteration 28880, loss = 239.54069566\n",
      "Iteration 28881, loss = 239.51103644\n",
      "Iteration 28882, loss = 239.48139512\n",
      "Iteration 28883, loss = 239.45179513\n",
      "Iteration 28884, loss = 239.42222825\n",
      "Iteration 28885, loss = 239.39266546\n",
      "Iteration 28886, loss = 239.36308395\n",
      "Iteration 28887, loss = 239.33348920\n",
      "Iteration 28888, loss = 239.30390698\n",
      "Iteration 28889, loss = 239.27435403\n",
      "Iteration 28890, loss = 239.24482065\n",
      "Iteration 28891, loss = 239.21528541\n",
      "Iteration 28892, loss = 239.18574044\n",
      "Iteration 28893, loss = 239.15619794\n",
      "Iteration 28894, loss = 239.12667359\n",
      "Iteration 28895, loss = 239.09716750\n",
      "Iteration 28896, loss = 239.06766685\n",
      "Iteration 28897, loss = 239.03816310\n",
      "Iteration 28898, loss = 239.00866102\n",
      "Iteration 28899, loss = 238.97917098\n",
      "Iteration 28900, loss = 238.94969543\n",
      "Iteration 28901, loss = 238.92022747\n",
      "Iteration 28902, loss = 238.89076077\n",
      "Iteration 28903, loss = 238.86129686\n",
      "Iteration 28904, loss = 238.83184194\n",
      "Iteration 28905, loss = 238.80239854\n",
      "Iteration 28906, loss = 238.77296320\n",
      "Iteration 28907, loss = 238.74353179\n",
      "Iteration 28908, loss = 238.71410453\n",
      "Iteration 28909, loss = 238.68468498\n",
      "Iteration 28910, loss = 238.65527519\n",
      "Iteration 28911, loss = 238.62587355\n",
      "Iteration 28912, loss = 238.59647740\n",
      "Iteration 28913, loss = 238.56708635\n",
      "Iteration 28914, loss = 238.53770226\n",
      "Iteration 28915, loss = 238.50832660\n",
      "Iteration 28916, loss = 238.47895876\n",
      "Iteration 28917, loss = 238.44959717\n",
      "Iteration 28918, loss = 238.42024128\n",
      "Iteration 28919, loss = 238.39089201\n",
      "Iteration 28920, loss = 238.36155040\n",
      "Iteration 28921, loss = 238.33221640\n",
      "Iteration 28922, loss = 238.30288914\n",
      "Iteration 28923, loss = 238.27356812\n",
      "Iteration 28924, loss = 238.24425366\n",
      "Iteration 28925, loss = 238.21494642\n",
      "Iteration 28926, loss = 238.18564656\n",
      "Iteration 28927, loss = 238.15635365\n",
      "Iteration 28928, loss = 238.12706727\n",
      "Iteration 28929, loss = 238.09778746\n",
      "Iteration 28930, loss = 238.06851456\n",
      "Iteration 28931, loss = 238.03924880\n",
      "Iteration 28932, loss = 238.00999005\n",
      "Iteration 28933, loss = 237.98073801\n",
      "Iteration 28934, loss = 237.95149262\n",
      "Iteration 28935, loss = 237.92225401\n",
      "Iteration 28936, loss = 237.89302239\n",
      "Iteration 28937, loss = 237.86379775\n",
      "Iteration 28938, loss = 237.83457995\n",
      "Iteration 28939, loss = 237.80536887\n",
      "Iteration 28940, loss = 237.77616455\n",
      "Iteration 28941, loss = 237.74696709\n",
      "Iteration 28942, loss = 237.71777655\n",
      "Iteration 28943, loss = 237.68859287\n",
      "Iteration 28944, loss = 237.65941599\n",
      "Iteration 28945, loss = 237.63024585\n",
      "Iteration 28946, loss = 237.60108251\n",
      "Iteration 28947, loss = 237.57192601\n",
      "Iteration 28948, loss = 237.54277637\n",
      "Iteration 28949, loss = 237.51363354\n",
      "Iteration 28950, loss = 237.48449749\n",
      "Iteration 28951, loss = 237.45536821\n",
      "Iteration 28952, loss = 237.42624572\n",
      "Iteration 28953, loss = 237.39713006\n",
      "Iteration 28954, loss = 237.36802121\n",
      "Iteration 28955, loss = 237.33891914\n",
      "Iteration 28956, loss = 237.30982385\n",
      "Iteration 28957, loss = 237.28073533\n",
      "Iteration 28958, loss = 237.25165359\n",
      "Iteration 28959, loss = 237.22257865\n",
      "Iteration 28960, loss = 237.19351049\n",
      "Iteration 28961, loss = 237.16444911\n",
      "Iteration 28962, loss = 237.13539448\n",
      "Iteration 28963, loss = 237.10634662\n",
      "Iteration 28964, loss = 237.07730552\n",
      "Iteration 28965, loss = 237.04827120\n",
      "Iteration 28966, loss = 237.01924364\n",
      "Iteration 28967, loss = 236.99022283\n",
      "Iteration 28968, loss = 236.96120877\n",
      "Iteration 28969, loss = 236.93220146\n",
      "Iteration 28970, loss = 236.90320091\n",
      "Iteration 28971, loss = 236.87420710\n",
      "Iteration 28972, loss = 236.84522003\n",
      "Iteration 28973, loss = 236.81623971\n",
      "Iteration 28974, loss = 236.78726612\n",
      "Iteration 28975, loss = 236.75829926\n",
      "Iteration 28976, loss = 236.72933914\n",
      "Iteration 28977, loss = 236.70038575\n",
      "Iteration 28978, loss = 236.67143908\n",
      "Iteration 28979, loss = 236.64249914\n",
      "Iteration 28980, loss = 236.61356592\n",
      "Iteration 28981, loss = 236.58463942\n",
      "Iteration 28982, loss = 236.55571963\n",
      "Iteration 28983, loss = 236.52680656\n",
      "Iteration 28984, loss = 236.49790020\n",
      "Iteration 28985, loss = 236.46900054\n",
      "Iteration 28986, loss = 236.44010760\n",
      "Iteration 28987, loss = 236.41122135\n",
      "Iteration 28988, loss = 236.38234180\n",
      "Iteration 28989, loss = 236.35346895\n",
      "Iteration 28990, loss = 236.32460280\n",
      "Iteration 28991, loss = 236.29574334\n",
      "Iteration 28992, loss = 236.26689057\n",
      "Iteration 28993, loss = 236.23804448\n",
      "Iteration 28994, loss = 236.20920509\n",
      "Iteration 28995, loss = 236.18037238\n",
      "Iteration 28996, loss = 236.15154635\n",
      "Iteration 28997, loss = 236.12272701\n",
      "Iteration 28998, loss = 236.09391435\n",
      "Iteration 28999, loss = 236.06510837\n",
      "Iteration 29000, loss = 236.03630908\n",
      "Iteration 29001, loss = 236.00751648\n",
      "Iteration 29002, loss = 235.97873057\n",
      "Iteration 29003, loss = 235.94995136\n",
      "Iteration 29004, loss = 235.92117883\n",
      "Iteration 29005, loss = 235.89241301\n",
      "Iteration 29006, loss = 235.86365386\n",
      "Iteration 29007, loss = 235.83490138\n",
      "Iteration 29008, loss = 235.80615552\n",
      "Iteration 29009, loss = 235.77741623\n",
      "Iteration 29010, loss = 235.74868344\n",
      "Iteration 29011, loss = 235.71995712\n",
      "Iteration 29012, loss = 235.69123721\n",
      "Iteration 29013, loss = 235.66252379\n",
      "Iteration 29014, loss = 235.63381693\n",
      "Iteration 29015, loss = 235.60511674\n",
      "Iteration 29016, loss = 235.57642332\n",
      "Iteration 29017, loss = 235.54773672\n",
      "Iteration 29018, loss = 235.51905692\n",
      "Iteration 29019, loss = 235.49038386\n",
      "Iteration 29020, loss = 235.46171745\n",
      "Iteration 29021, loss = 235.43305761\n",
      "Iteration 29022, loss = 235.40440430\n",
      "Iteration 29023, loss = 235.37575748\n",
      "Iteration 29024, loss = 235.34711718\n",
      "Iteration 29025, loss = 235.31848342\n",
      "Iteration 29026, loss = 235.28985627\n",
      "Iteration 29027, loss = 235.26123574\n",
      "Iteration 29028, loss = 235.23262187\n",
      "Iteration 29029, loss = 235.20401466\n",
      "Iteration 29030, loss = 235.17541407\n",
      "Iteration 29031, loss = 235.14682008\n",
      "Iteration 29032, loss = 235.11823266\n",
      "Iteration 29033, loss = 235.08965179\n",
      "Iteration 29034, loss = 235.06107746\n",
      "Iteration 29035, loss = 235.03250968\n",
      "Iteration 29036, loss = 235.00394844\n",
      "Iteration 29037, loss = 234.97539377\n",
      "Iteration 29038, loss = 234.94684568\n",
      "Iteration 29039, loss = 234.91830417\n",
      "Iteration 29040, loss = 234.88976923\n",
      "Iteration 29041, loss = 234.86124087\n",
      "Iteration 29042, loss = 234.83271906\n",
      "Iteration 29043, loss = 234.80420381\n",
      "Iteration 29044, loss = 234.77569509\n",
      "Iteration 29045, loss = 234.74719292\n",
      "Iteration 29046, loss = 234.71869727\n",
      "Iteration 29047, loss = 234.69020816\n",
      "Iteration 29048, loss = 234.66172558\n",
      "Iteration 29049, loss = 234.63324954\n",
      "Iteration 29050, loss = 234.60478003\n",
      "Iteration 29051, loss = 234.57631706\n",
      "Iteration 29052, loss = 234.54786062\n",
      "Iteration 29053, loss = 234.51941070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29054, loss = 234.49096731\n",
      "Iteration 29055, loss = 234.46253044\n",
      "Iteration 29056, loss = 234.43410008\n",
      "Iteration 29057, loss = 234.40567624\n",
      "Iteration 29058, loss = 234.37725890\n",
      "Iteration 29059, loss = 234.34884807\n",
      "Iteration 29060, loss = 234.32044374\n",
      "Iteration 29061, loss = 234.29204591\n",
      "Iteration 29062, loss = 234.26365459\n",
      "Iteration 29063, loss = 234.23526976\n",
      "Iteration 29064, loss = 234.20689142\n",
      "Iteration 29065, loss = 234.17851958\n",
      "Iteration 29066, loss = 234.15015423\n",
      "Iteration 29067, loss = 234.12179537\n",
      "Iteration 29068, loss = 234.09344299\n",
      "Iteration 29069, loss = 234.06509710\n",
      "Iteration 29070, loss = 234.03675768\n",
      "Iteration 29071, loss = 234.00842473\n",
      "Iteration 29072, loss = 233.98009826\n",
      "Iteration 29073, loss = 233.95177827\n",
      "Iteration 29074, loss = 233.92346473\n",
      "Iteration 29075, loss = 233.89515767\n",
      "Iteration 29076, loss = 233.86685706\n",
      "Iteration 29077, loss = 233.83856292\n",
      "Iteration 29078, loss = 233.81027524\n",
      "Iteration 29079, loss = 233.78199401\n",
      "Iteration 29080, loss = 233.75371923\n",
      "Iteration 29081, loss = 233.72545090\n",
      "Iteration 29082, loss = 233.69718902\n",
      "Iteration 29083, loss = 233.66893358\n",
      "Iteration 29084, loss = 233.64068459\n",
      "Iteration 29085, loss = 233.61244203\n",
      "Iteration 29086, loss = 233.58420592\n",
      "Iteration 29087, loss = 233.55597623\n",
      "Iteration 29088, loss = 233.52775298\n",
      "Iteration 29089, loss = 233.49953615\n",
      "Iteration 29090, loss = 233.47132576\n",
      "Iteration 29091, loss = 233.44312178\n",
      "Iteration 29092, loss = 233.41492423\n",
      "Iteration 29093, loss = 233.38673309\n",
      "Iteration 29094, loss = 233.35854838\n",
      "Iteration 29095, loss = 233.33037007\n",
      "Iteration 29096, loss = 233.30219817\n",
      "Iteration 29097, loss = 233.27403269\n",
      "Iteration 29098, loss = 233.24587360\n",
      "Iteration 29099, loss = 233.21772092\n",
      "Iteration 29100, loss = 233.18957464\n",
      "Iteration 29101, loss = 233.16143476\n",
      "Iteration 29102, loss = 233.13330127\n",
      "Iteration 29103, loss = 233.10517418\n",
      "Iteration 29104, loss = 233.07705347\n",
      "Iteration 29105, loss = 233.04893916\n",
      "Iteration 29106, loss = 233.02083122\n",
      "Iteration 29107, loss = 232.99272967\n",
      "Iteration 29108, loss = 232.96463450\n",
      "Iteration 29109, loss = 232.93654570\n",
      "Iteration 29110, loss = 232.90846328\n",
      "Iteration 29111, loss = 232.88038723\n",
      "Iteration 29112, loss = 232.85231755\n",
      "Iteration 29113, loss = 232.82425424\n",
      "Iteration 29114, loss = 232.79619729\n",
      "Iteration 29115, loss = 232.76814670\n",
      "Iteration 29116, loss = 232.74010247\n",
      "Iteration 29117, loss = 232.71206459\n",
      "Iteration 29118, loss = 232.68403307\n",
      "Iteration 29119, loss = 232.65600790\n",
      "Iteration 29120, loss = 232.62798908\n",
      "Iteration 29121, loss = 232.59997661\n",
      "Iteration 29122, loss = 232.57197048\n",
      "Iteration 29123, loss = 232.54397069\n",
      "Iteration 29124, loss = 232.51597723\n",
      "Iteration 29125, loss = 232.48799012\n",
      "Iteration 29126, loss = 232.46000933\n",
      "Iteration 29127, loss = 232.43203488\n",
      "Iteration 29128, loss = 232.40406676\n",
      "Iteration 29129, loss = 232.37610496\n",
      "Iteration 29130, loss = 232.34814949\n",
      "Iteration 29131, loss = 232.32020034\n",
      "Iteration 29132, loss = 232.29225752\n",
      "Iteration 29133, loss = 232.26432101\n",
      "Iteration 29134, loss = 232.23639082\n",
      "Iteration 29135, loss = 232.20846695\n",
      "Iteration 29136, loss = 232.18054940\n",
      "Iteration 29137, loss = 232.15263818\n",
      "Iteration 29138, loss = 232.12473328\n",
      "Iteration 29139, loss = 232.09683472\n",
      "Iteration 29140, loss = 232.06894249\n",
      "Iteration 29141, loss = 232.04105663\n",
      "Iteration 29142, loss = 232.01317714\n",
      "Iteration 29143, loss = 231.98530403\n",
      "Iteration 29144, loss = 231.95743732\n",
      "Iteration 29145, loss = 231.92957701\n",
      "Iteration 29146, loss = 231.90172304\n",
      "Iteration 29147, loss = 231.87387541\n",
      "Iteration 29148, loss = 231.84603397\n",
      "Iteration 29149, loss = 231.81819876\n",
      "Iteration 29150, loss = 231.79036980\n",
      "Iteration 29151, loss = 231.76254748\n",
      "Iteration 29152, loss = 231.73473245\n",
      "Iteration 29153, loss = 231.70692566\n",
      "Iteration 29154, loss = 231.67912838\n",
      "Iteration 29155, loss = 231.65134173\n",
      "Iteration 29156, loss = 231.62356674\n",
      "Iteration 29157, loss = 231.59580195\n",
      "Iteration 29158, loss = 231.56804295\n",
      "Iteration 29159, loss = 231.54027816\n",
      "Iteration 29160, loss = 231.51249799\n",
      "Iteration 29161, loss = 231.48470255\n",
      "Iteration 29162, loss = 231.45691227\n",
      "Iteration 29163, loss = 231.42914942\n",
      "Iteration 29164, loss = 231.40141849\n",
      "Iteration 29165, loss = 231.37370378\n",
      "Iteration 29166, loss = 231.34598413\n",
      "Iteration 29167, loss = 231.31825083\n",
      "Iteration 29168, loss = 231.29051377\n",
      "Iteration 29169, loss = 231.26279163\n",
      "Iteration 29170, loss = 231.23509186\n",
      "Iteration 29171, loss = 231.20740529\n",
      "Iteration 29172, loss = 231.17971781\n",
      "Iteration 29173, loss = 231.15202466\n",
      "Iteration 29174, loss = 231.12433413\n",
      "Iteration 29175, loss = 231.09665687\n",
      "Iteration 29176, loss = 231.06899453\n",
      "Iteration 29177, loss = 231.04133959\n",
      "Iteration 29178, loss = 231.01368470\n",
      "Iteration 29179, loss = 230.98603033\n",
      "Iteration 29180, loss = 230.95838280\n",
      "Iteration 29181, loss = 230.93074671\n",
      "Iteration 29182, loss = 230.90312031\n",
      "Iteration 29183, loss = 230.87549857\n",
      "Iteration 29184, loss = 230.84787908\n",
      "Iteration 29185, loss = 230.82026404\n",
      "Iteration 29186, loss = 230.79265714\n",
      "Iteration 29187, loss = 230.76505932\n",
      "Iteration 29188, loss = 230.73746831\n",
      "Iteration 29189, loss = 230.70988166\n",
      "Iteration 29190, loss = 230.68229926\n",
      "Iteration 29191, loss = 230.65472306\n",
      "Iteration 29192, loss = 230.62715463\n",
      "Iteration 29193, loss = 230.59959359\n",
      "Iteration 29194, loss = 230.57203838\n",
      "Iteration 29195, loss = 230.54448811\n",
      "Iteration 29196, loss = 230.51694332\n",
      "Iteration 29197, loss = 230.48940514\n",
      "Iteration 29198, loss = 230.46187404\n",
      "Iteration 29199, loss = 230.43434944\n",
      "Iteration 29200, loss = 230.40683055\n",
      "Iteration 29201, loss = 230.37931716\n",
      "Iteration 29202, loss = 230.35180975\n",
      "Iteration 29203, loss = 230.32430889\n",
      "Iteration 29204, loss = 230.29681462\n",
      "Iteration 29205, loss = 230.26932654\n",
      "Iteration 29206, loss = 230.24184428\n",
      "Iteration 29207, loss = 230.21436784\n",
      "Iteration 29208, loss = 230.18689753\n",
      "Iteration 29209, loss = 230.15943359\n",
      "Iteration 29210, loss = 230.13197599\n",
      "Iteration 29211, loss = 230.10452449\n",
      "Iteration 29212, loss = 230.07707892\n",
      "Iteration 29213, loss = 230.04963933\n",
      "Iteration 29214, loss = 230.02220587\n",
      "Iteration 29215, loss = 229.99477866\n",
      "Iteration 29216, loss = 229.96735766\n",
      "Iteration 29217, loss = 229.93994275\n",
      "Iteration 29218, loss = 229.91253384\n",
      "Iteration 29219, loss = 229.88513096\n",
      "Iteration 29220, loss = 229.85773419\n",
      "Iteration 29221, loss = 229.83034359\n",
      "Iteration 29222, loss = 229.80295913\n",
      "Iteration 29223, loss = 229.77558076\n",
      "Iteration 29224, loss = 229.74820842\n",
      "Iteration 29225, loss = 229.72084213\n",
      "Iteration 29226, loss = 229.69348193\n",
      "Iteration 29227, loss = 229.66612784\n",
      "Iteration 29228, loss = 229.63877987\n",
      "Iteration 29229, loss = 229.61143797\n",
      "Iteration 29230, loss = 229.58410211\n",
      "Iteration 29231, loss = 229.55677231\n",
      "Iteration 29232, loss = 229.52944857\n",
      "Iteration 29233, loss = 229.50213091\n",
      "Iteration 29234, loss = 229.47481933\n",
      "Iteration 29235, loss = 229.44751382\n",
      "Iteration 29236, loss = 229.42021436\n",
      "Iteration 29237, loss = 229.39292094\n",
      "Iteration 29238, loss = 229.36563357\n",
      "Iteration 29239, loss = 229.33835226\n",
      "Iteration 29240, loss = 229.31107700\n",
      "Iteration 29241, loss = 229.28380780\n",
      "Iteration 29242, loss = 229.25654464\n",
      "Iteration 29243, loss = 229.22928751\n",
      "Iteration 29244, loss = 229.20203642\n",
      "Iteration 29245, loss = 229.17479136\n",
      "Iteration 29246, loss = 229.14755235\n",
      "Iteration 29247, loss = 229.12031937\n",
      "Iteration 29248, loss = 229.09309242\n",
      "Iteration 29249, loss = 229.06587149\n",
      "Iteration 29250, loss = 229.03865659\n",
      "Iteration 29251, loss = 229.01144771\n",
      "Iteration 29252, loss = 228.98424485\n",
      "Iteration 29253, loss = 228.95704800\n",
      "Iteration 29254, loss = 228.92985718\n",
      "Iteration 29255, loss = 228.90267237\n",
      "Iteration 29256, loss = 228.87549356\n",
      "Iteration 29257, loss = 228.84832077\n",
      "Iteration 29258, loss = 228.82115397\n",
      "Iteration 29259, loss = 228.79399319\n",
      "Iteration 29260, loss = 228.76683840\n",
      "Iteration 29261, loss = 228.73968961\n",
      "Iteration 29262, loss = 228.71254682\n",
      "Iteration 29263, loss = 228.68541002\n",
      "Iteration 29264, loss = 228.65827922\n",
      "Iteration 29265, loss = 228.63115440\n",
      "Iteration 29266, loss = 228.60403557\n",
      "Iteration 29267, loss = 228.57692272\n",
      "Iteration 29268, loss = 228.54981585\n",
      "Iteration 29269, loss = 228.52271497\n",
      "Iteration 29270, loss = 228.49562006\n",
      "Iteration 29271, loss = 228.46853112\n",
      "Iteration 29272, loss = 228.44144816\n",
      "Iteration 29273, loss = 228.41437117\n",
      "Iteration 29274, loss = 228.38730014\n",
      "Iteration 29275, loss = 228.36023508\n",
      "Iteration 29276, loss = 228.33317598\n",
      "Iteration 29277, loss = 228.30612284\n",
      "Iteration 29278, loss = 228.27907567\n",
      "Iteration 29279, loss = 228.25203444\n",
      "Iteration 29280, loss = 228.22499917\n",
      "Iteration 29281, loss = 228.19796985\n",
      "Iteration 29282, loss = 228.17094648\n",
      "Iteration 29283, loss = 228.14392906\n",
      "Iteration 29284, loss = 228.11691758\n",
      "Iteration 29285, loss = 228.08991204\n",
      "Iteration 29286, loss = 228.06291244\n",
      "Iteration 29287, loss = 228.03591877\n",
      "Iteration 29288, loss = 228.00893104\n",
      "Iteration 29289, loss = 227.98194925\n",
      "Iteration 29290, loss = 227.95497338\n",
      "Iteration 29291, loss = 227.92800344\n",
      "Iteration 29292, loss = 227.90103943\n",
      "Iteration 29293, loss = 227.87408133\n",
      "Iteration 29294, loss = 227.84712916\n",
      "Iteration 29295, loss = 227.82018291\n",
      "Iteration 29296, loss = 227.79324257\n",
      "Iteration 29297, loss = 227.76630815\n",
      "Iteration 29298, loss = 227.73937963\n",
      "Iteration 29299, loss = 227.71245703\n",
      "Iteration 29300, loss = 227.68554033\n",
      "Iteration 29301, loss = 227.65862954\n",
      "Iteration 29302, loss = 227.63172464\n",
      "Iteration 29303, loss = 227.60482565\n",
      "Iteration 29304, loss = 227.57793255\n",
      "Iteration 29305, loss = 227.55104535\n",
      "Iteration 29306, loss = 227.52416404\n",
      "Iteration 29307, loss = 227.49728862\n",
      "Iteration 29308, loss = 227.47041909\n",
      "Iteration 29309, loss = 227.44355545\n",
      "Iteration 29310, loss = 227.41669769\n",
      "Iteration 29311, loss = 227.38984580\n",
      "Iteration 29312, loss = 227.36299980\n",
      "Iteration 29313, loss = 227.33615968\n",
      "Iteration 29314, loss = 227.30932543\n",
      "Iteration 29315, loss = 227.28249706\n",
      "Iteration 29316, loss = 227.25567457\n",
      "Iteration 29317, loss = 227.22885795\n",
      "Iteration 29318, loss = 227.20204720\n",
      "Iteration 29319, loss = 227.17524234\n",
      "Iteration 29320, loss = 227.14844337\n",
      "Iteration 29321, loss = 227.12165031\n",
      "Iteration 29322, loss = 227.09486316\n",
      "Iteration 29323, loss = 227.06808197\n",
      "Iteration 29324, loss = 227.04130676\n",
      "Iteration 29325, loss = 227.01453760\n",
      "Iteration 29326, loss = 226.98777451\n",
      "Iteration 29327, loss = 226.96101754\n",
      "Iteration 29328, loss = 226.93426655\n",
      "Iteration 29329, loss = 226.90752139\n",
      "Iteration 29330, loss = 226.88078151\n",
      "Iteration 29331, loss = 226.85404654\n",
      "Iteration 29332, loss = 226.82731612\n",
      "Iteration 29333, loss = 226.80059078\n",
      "Iteration 29334, loss = 226.77387141\n",
      "Iteration 29335, loss = 226.74715893\n",
      "Iteration 29336, loss = 226.72045357\n",
      "Iteration 29337, loss = 226.69375484\n",
      "Iteration 29338, loss = 226.66706191\n",
      "Iteration 29339, loss = 226.64037406\n",
      "Iteration 29340, loss = 226.61369117\n",
      "Iteration 29341, loss = 226.58701359\n",
      "Iteration 29342, loss = 226.56034203\n",
      "Iteration 29343, loss = 226.53367692\n",
      "Iteration 29344, loss = 226.50701820\n",
      "Iteration 29345, loss = 226.48036547\n",
      "Iteration 29346, loss = 226.45371825\n",
      "Iteration 29347, loss = 226.42707637\n",
      "Iteration 29348, loss = 226.40043998\n",
      "Iteration 29349, loss = 226.37380943\n",
      "Iteration 29350, loss = 226.34718499\n",
      "Iteration 29351, loss = 226.32056663\n",
      "Iteration 29352, loss = 226.29395417\n",
      "Iteration 29353, loss = 226.26734735\n",
      "Iteration 29354, loss = 226.24074609\n",
      "Iteration 29355, loss = 226.21415046\n",
      "Iteration 29356, loss = 226.18756063\n",
      "Iteration 29357, loss = 226.16097673\n",
      "Iteration 29358, loss = 226.13439874\n",
      "Iteration 29359, loss = 226.10782658\n",
      "Iteration 29360, loss = 226.08126012\n",
      "Iteration 29361, loss = 226.05469932\n",
      "Iteration 29362, loss = 226.02814421\n",
      "Iteration 29363, loss = 226.00159487\n",
      "Iteration 29364, loss = 225.97505136\n",
      "Iteration 29365, loss = 225.94851368\n",
      "Iteration 29366, loss = 225.92198178\n",
      "Iteration 29367, loss = 225.89545560\n",
      "Iteration 29368, loss = 225.86893513\n",
      "Iteration 29369, loss = 225.84242036\n",
      "Iteration 29370, loss = 225.81591134\n",
      "Iteration 29371, loss = 225.78940810\n",
      "Iteration 29372, loss = 225.76291063\n",
      "Iteration 29373, loss = 225.73641892\n",
      "Iteration 29374, loss = 225.70993294\n",
      "Iteration 29375, loss = 225.68345267\n",
      "Iteration 29376, loss = 225.65697811\n",
      "Iteration 29377, loss = 225.63050928\n",
      "Iteration 29378, loss = 225.60404619\n",
      "Iteration 29379, loss = 225.57758884\n",
      "Iteration 29380, loss = 225.55113722\n",
      "Iteration 29381, loss = 225.52469133\n",
      "Iteration 29382, loss = 225.49825115\n",
      "Iteration 29383, loss = 225.47181667\n",
      "Iteration 29384, loss = 225.44538790\n",
      "Iteration 29385, loss = 225.41896485\n",
      "Iteration 29386, loss = 225.39254752\n",
      "Iteration 29387, loss = 225.36613590\n",
      "Iteration 29388, loss = 225.33972999\n",
      "Iteration 29389, loss = 225.31332978\n",
      "Iteration 29390, loss = 225.28693527\n",
      "Iteration 29391, loss = 225.26054645\n",
      "Iteration 29392, loss = 225.23416334\n",
      "Iteration 29393, loss = 225.20778592\n",
      "Iteration 29394, loss = 225.18141420\n",
      "Iteration 29395, loss = 225.15504818\n",
      "Iteration 29396, loss = 225.12868786\n",
      "Iteration 29397, loss = 225.10233324\n",
      "Iteration 29398, loss = 225.07598432\n",
      "Iteration 29399, loss = 225.04964112\n",
      "Iteration 29400, loss = 225.02330366\n",
      "Iteration 29401, loss = 224.99697198\n",
      "Iteration 29402, loss = 224.97064612\n",
      "Iteration 29403, loss = 224.94432620\n",
      "Iteration 29404, loss = 224.91801235\n",
      "Iteration 29405, loss = 224.89170485\n",
      "Iteration 29406, loss = 224.86540407\n",
      "Iteration 29407, loss = 224.83911065\n",
      "Iteration 29408, loss = 224.81282541\n",
      "Iteration 29409, loss = 224.78654946\n",
      "Iteration 29410, loss = 224.76028338\n",
      "Iteration 29411, loss = 224.73402687\n",
      "Iteration 29412, loss = 224.70777528\n",
      "Iteration 29413, loss = 224.68152083\n",
      "Iteration 29414, loss = 224.65525268\n",
      "Iteration 29415, loss = 224.62897114\n",
      "Iteration 29416, loss = 224.60269044\n",
      "Iteration 29417, loss = 224.57643137\n",
      "Iteration 29418, loss = 224.55020130\n",
      "Iteration 29419, loss = 224.52398957\n",
      "Iteration 29420, loss = 224.49777801\n",
      "Iteration 29421, loss = 224.47155498\n",
      "Iteration 29422, loss = 224.44532497\n",
      "Iteration 29423, loss = 224.41910315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29424, loss = 224.39290049\n",
      "Iteration 29425, loss = 224.36671382\n",
      "Iteration 29426, loss = 224.34053117\n",
      "Iteration 29427, loss = 224.31434428\n",
      "Iteration 29428, loss = 224.28815556\n",
      "Iteration 29429, loss = 224.26197447\n",
      "Iteration 29430, loss = 224.23580689\n",
      "Iteration 29431, loss = 224.20965000\n",
      "Iteration 29432, loss = 224.18349664\n",
      "Iteration 29433, loss = 224.15734301\n",
      "Iteration 29434, loss = 224.13119191\n",
      "Iteration 29435, loss = 224.10504871\n",
      "Iteration 29436, loss = 224.07891558\n",
      "Iteration 29437, loss = 224.05278985\n",
      "Iteration 29438, loss = 224.02666763\n",
      "Iteration 29439, loss = 224.00054785\n",
      "Iteration 29440, loss = 223.97443281\n",
      "Iteration 29441, loss = 223.94832525\n",
      "Iteration 29442, loss = 223.92222555\n",
      "Iteration 29443, loss = 223.89613178\n",
      "Iteration 29444, loss = 223.87004207\n",
      "Iteration 29445, loss = 223.84395641\n",
      "Iteration 29446, loss = 223.81787633\n",
      "Iteration 29447, loss = 223.79180306\n",
      "Iteration 29448, loss = 223.76573642\n",
      "Iteration 29449, loss = 223.73967525\n",
      "Iteration 29450, loss = 223.71361871\n",
      "Iteration 29451, loss = 223.68756706\n",
      "Iteration 29452, loss = 223.66152115\n",
      "Iteration 29453, loss = 223.63548151\n",
      "Iteration 29454, loss = 223.60944791\n",
      "Iteration 29455, loss = 223.58341972\n",
      "Iteration 29456, loss = 223.55739657\n",
      "Iteration 29457, loss = 223.53137865\n",
      "Iteration 29458, loss = 223.50536644\n",
      "Iteration 29459, loss = 223.47936016\n",
      "Iteration 29460, loss = 223.45335965\n",
      "Iteration 29461, loss = 223.42736459\n",
      "Iteration 29462, loss = 223.40137481\n",
      "Iteration 29463, loss = 223.37539041\n",
      "Iteration 29464, loss = 223.34941162\n",
      "Iteration 29465, loss = 223.32343857\n",
      "Iteration 29466, loss = 223.29747119\n",
      "Iteration 29467, loss = 223.27150929\n",
      "Iteration 29468, loss = 223.24555279\n",
      "Iteration 29469, loss = 223.21960172\n",
      "Iteration 29470, loss = 223.19365621\n",
      "Iteration 29471, loss = 223.16771633\n",
      "Iteration 29472, loss = 223.14178204\n",
      "Iteration 29473, loss = 223.11585327\n",
      "Iteration 29474, loss = 223.08992995\n",
      "Iteration 29475, loss = 223.06401209\n",
      "Iteration 29476, loss = 223.03809974\n",
      "Iteration 29477, loss = 223.01219295\n",
      "Iteration 29478, loss = 222.98629172\n",
      "Iteration 29479, loss = 222.96039601\n",
      "Iteration 29480, loss = 222.93450578\n",
      "Iteration 29481, loss = 222.90862102\n",
      "Iteration 29482, loss = 222.88274175\n",
      "Iteration 29483, loss = 222.85686800\n",
      "Iteration 29484, loss = 222.83099977\n",
      "Iteration 29485, loss = 222.80513705\n",
      "Iteration 29486, loss = 222.77927982\n",
      "Iteration 29487, loss = 222.75342807\n",
      "Iteration 29488, loss = 222.72758179\n",
      "Iteration 29489, loss = 222.70174100\n",
      "Iteration 29490, loss = 222.67590571\n",
      "Iteration 29491, loss = 222.65007591\n",
      "Iteration 29492, loss = 222.62425160\n",
      "Iteration 29493, loss = 222.59843276\n",
      "Iteration 29494, loss = 222.57261940\n",
      "Iteration 29495, loss = 222.54681150\n",
      "Iteration 29496, loss = 222.52100908\n",
      "Iteration 29497, loss = 222.49521213\n",
      "Iteration 29498, loss = 222.46942066\n",
      "Iteration 29499, loss = 222.44363466\n",
      "Iteration 29500, loss = 222.41785412\n",
      "Iteration 29501, loss = 222.39207904\n",
      "Iteration 29502, loss = 222.36630942\n",
      "Iteration 29503, loss = 222.34054526\n",
      "Iteration 29504, loss = 222.31478656\n",
      "Iteration 29505, loss = 222.28903332\n",
      "Iteration 29506, loss = 222.26328552\n",
      "Iteration 29507, loss = 222.23754318\n",
      "Iteration 29508, loss = 222.21180629\n",
      "Iteration 29509, loss = 222.18607484\n",
      "Iteration 29510, loss = 222.16034883\n",
      "Iteration 29511, loss = 222.13462827\n",
      "Iteration 29512, loss = 222.10891315\n",
      "Iteration 29513, loss = 222.08320347\n",
      "Iteration 29514, loss = 222.05749923\n",
      "Iteration 29515, loss = 222.03180042\n",
      "Iteration 29516, loss = 222.00610704\n",
      "Iteration 29517, loss = 221.98041909\n",
      "Iteration 29518, loss = 221.95473656\n",
      "Iteration 29519, loss = 221.92905947\n",
      "Iteration 29520, loss = 221.90338780\n",
      "Iteration 29521, loss = 221.87772155\n",
      "Iteration 29522, loss = 221.85206072\n",
      "Iteration 29523, loss = 221.82640531\n",
      "Iteration 29524, loss = 221.80075531\n",
      "Iteration 29525, loss = 221.77511073\n",
      "Iteration 29526, loss = 221.74947155\n",
      "Iteration 29527, loss = 221.72383779\n",
      "Iteration 29528, loss = 221.69820944\n",
      "Iteration 29529, loss = 221.67258649\n",
      "Iteration 29530, loss = 221.64696894\n",
      "Iteration 29531, loss = 221.62135680\n",
      "Iteration 29532, loss = 221.59575005\n",
      "Iteration 29533, loss = 221.57014870\n",
      "Iteration 29534, loss = 221.54455275\n",
      "Iteration 29535, loss = 221.51896219\n",
      "Iteration 29536, loss = 221.49337702\n",
      "Iteration 29537, loss = 221.46779724\n",
      "Iteration 29538, loss = 221.44222285\n",
      "Iteration 29539, loss = 221.41665384\n",
      "Iteration 29540, loss = 221.39109022\n",
      "Iteration 29541, loss = 221.36553197\n",
      "Iteration 29542, loss = 221.33997911\n",
      "Iteration 29543, loss = 221.31443162\n",
      "Iteration 29544, loss = 221.28888951\n",
      "Iteration 29545, loss = 221.26335277\n",
      "Iteration 29546, loss = 221.23782140\n",
      "Iteration 29547, loss = 221.21229540\n",
      "Iteration 29548, loss = 221.18677476\n",
      "Iteration 29549, loss = 221.16125949\n",
      "Iteration 29550, loss = 221.13574959\n",
      "Iteration 29551, loss = 221.11024504\n",
      "Iteration 29552, loss = 221.08474585\n",
      "Iteration 29553, loss = 221.05925202\n",
      "Iteration 29554, loss = 221.03376354\n",
      "Iteration 29555, loss = 221.00828042\n",
      "Iteration 29556, loss = 220.98280265\n",
      "Iteration 29557, loss = 220.95733022\n",
      "Iteration 29558, loss = 220.93186314\n",
      "Iteration 29559, loss = 220.90640141\n",
      "Iteration 29560, loss = 220.88094502\n",
      "Iteration 29561, loss = 220.85549397\n",
      "Iteration 29562, loss = 220.83004826\n",
      "Iteration 29563, loss = 220.80460788\n",
      "Iteration 29564, loss = 220.77917284\n",
      "Iteration 29565, loss = 220.75374313\n",
      "Iteration 29566, loss = 220.72831875\n",
      "Iteration 29567, loss = 220.70289970\n",
      "Iteration 29568, loss = 220.67748598\n",
      "Iteration 29569, loss = 220.65207758\n",
      "Iteration 29570, loss = 220.62667450\n",
      "Iteration 29571, loss = 220.60127675\n",
      "Iteration 29572, loss = 220.57588431\n",
      "Iteration 29573, loss = 220.55049719\n",
      "Iteration 29574, loss = 220.52511538\n",
      "Iteration 29575, loss = 220.49973889\n",
      "Iteration 29576, loss = 220.47436772\n",
      "Iteration 29577, loss = 220.44900185\n",
      "Iteration 29578, loss = 220.42364130\n",
      "Iteration 29579, loss = 220.39828606\n",
      "Iteration 29580, loss = 220.37293614\n",
      "Iteration 29581, loss = 220.34759154\n",
      "Iteration 29582, loss = 220.32225227\n",
      "Iteration 29583, loss = 220.29691836\n",
      "Iteration 29584, loss = 220.27158982\n",
      "Iteration 29585, loss = 220.24626669\n",
      "Iteration 29586, loss = 220.22094904\n",
      "Iteration 29587, loss = 220.19563694\n",
      "Iteration 29588, loss = 220.17033044\n",
      "Iteration 29589, loss = 220.14502961\n",
      "Iteration 29590, loss = 220.11973426\n",
      "Iteration 29591, loss = 220.09444414\n",
      "Iteration 29592, loss = 220.06915840\n",
      "Iteration 29593, loss = 220.04387651\n",
      "Iteration 29594, loss = 220.01859815\n",
      "Iteration 29595, loss = 219.99332440\n",
      "Iteration 29596, loss = 219.96805672\n",
      "Iteration 29597, loss = 219.94279614\n",
      "Iteration 29598, loss = 219.91754243\n",
      "Iteration 29599, loss = 219.89229441\n",
      "Iteration 29600, loss = 219.86705088\n",
      "Iteration 29601, loss = 219.84181124\n",
      "Iteration 29602, loss = 219.81657602\n",
      "Iteration 29603, loss = 219.79134625\n",
      "Iteration 29604, loss = 219.76612270\n",
      "Iteration 29605, loss = 219.74090529\n",
      "Iteration 29606, loss = 219.71569329\n",
      "Iteration 29607, loss = 219.69048601\n",
      "Iteration 29608, loss = 219.66528326\n",
      "Iteration 29609, loss = 219.64008547\n",
      "Iteration 29610, loss = 219.61489323\n",
      "Iteration 29611, loss = 219.58970678\n",
      "Iteration 29612, loss = 219.56452588\n",
      "Iteration 29613, loss = 219.53935010\n",
      "Iteration 29614, loss = 219.51417919\n",
      "Iteration 29615, loss = 219.48901322\n",
      "Iteration 29616, loss = 219.46385252\n",
      "Iteration 29617, loss = 219.43869730\n",
      "Iteration 29618, loss = 219.41354756\n",
      "Iteration 29619, loss = 219.38840307\n",
      "Iteration 29620, loss = 219.36326364\n",
      "Iteration 29621, loss = 219.33812926\n",
      "Iteration 29622, loss = 219.31300004\n",
      "Iteration 29623, loss = 219.28787613\n",
      "Iteration 29624, loss = 219.26275758\n",
      "Iteration 29625, loss = 219.23764432\n",
      "Iteration 29626, loss = 219.21253622\n",
      "Iteration 29627, loss = 219.18743323\n",
      "Iteration 29628, loss = 219.16233538\n",
      "Iteration 29629, loss = 219.13724277\n",
      "Iteration 29630, loss = 219.11215543\n",
      "Iteration 29631, loss = 219.08707335\n",
      "Iteration 29632, loss = 219.06199648\n",
      "Iteration 29633, loss = 219.03692478\n",
      "Iteration 29634, loss = 219.01185823\n",
      "Iteration 29635, loss = 218.98679689\n",
      "Iteration 29636, loss = 218.96174079\n",
      "Iteration 29637, loss = 218.93668996\n",
      "Iteration 29638, loss = 218.91164440\n",
      "Iteration 29639, loss = 218.88660412\n",
      "Iteration 29640, loss = 218.86156915\n",
      "Iteration 29641, loss = 218.83653957\n",
      "Iteration 29642, loss = 218.81151555\n",
      "Iteration 29643, loss = 218.78649727\n",
      "Iteration 29644, loss = 218.76148504\n",
      "Iteration 29645, loss = 218.73647923\n",
      "Iteration 29646, loss = 218.71148041\n",
      "Iteration 29647, loss = 218.68648910\n",
      "Iteration 29648, loss = 218.66150581\n",
      "Iteration 29649, loss = 218.63652985\n",
      "Iteration 29650, loss = 218.61155930\n",
      "Iteration 29651, loss = 218.58658885\n",
      "Iteration 29652, loss = 218.56161315\n",
      "Iteration 29653, loss = 218.53662886\n",
      "Iteration 29654, loss = 218.51164200\n",
      "Iteration 29655, loss = 218.48666421\n",
      "Iteration 29656, loss = 218.46170512\n",
      "Iteration 29657, loss = 218.43676473\n",
      "Iteration 29658, loss = 218.41183477\n",
      "Iteration 29659, loss = 218.38690517\n",
      "Iteration 29660, loss = 218.36197023\n",
      "Iteration 29661, loss = 218.33703262\n",
      "Iteration 29662, loss = 218.31210042\n",
      "Iteration 29663, loss = 218.28718055\n",
      "Iteration 29664, loss = 218.26227333\n",
      "Iteration 29665, loss = 218.23737338\n",
      "Iteration 29666, loss = 218.21247477\n",
      "Iteration 29667, loss = 218.18757550\n",
      "Iteration 29668, loss = 218.16267860\n",
      "Iteration 29669, loss = 218.13778880\n",
      "Iteration 29670, loss = 218.11290847\n",
      "Iteration 29671, loss = 218.08803610\n",
      "Iteration 29672, loss = 218.06316823\n",
      "Iteration 29673, loss = 218.03830260\n",
      "Iteration 29674, loss = 218.01343966\n",
      "Iteration 29675, loss = 217.98858181\n",
      "Iteration 29676, loss = 217.96373103\n",
      "Iteration 29677, loss = 217.93888737\n",
      "Iteration 29678, loss = 217.91404930\n",
      "Iteration 29679, loss = 217.88921520\n",
      "Iteration 29680, loss = 217.86438471\n",
      "Iteration 29681, loss = 217.83955871\n",
      "Iteration 29682, loss = 217.81473844\n",
      "Iteration 29683, loss = 217.78992440\n",
      "Iteration 29684, loss = 217.76511613\n",
      "Iteration 29685, loss = 217.74031274\n",
      "Iteration 29686, loss = 217.71551370\n",
      "Iteration 29687, loss = 217.69071915\n",
      "Iteration 29688, loss = 217.66592969\n",
      "Iteration 29689, loss = 217.64114580\n",
      "Iteration 29690, loss = 217.61636752\n",
      "Iteration 29691, loss = 217.59159448\n",
      "Iteration 29692, loss = 217.56682628\n",
      "Iteration 29693, loss = 217.54206279\n",
      "Iteration 29694, loss = 217.51730417\n",
      "Iteration 29695, loss = 217.49255073\n",
      "Iteration 29696, loss = 217.46780262\n",
      "Iteration 29697, loss = 217.44305980\n",
      "Iteration 29698, loss = 217.41832209\n",
      "Iteration 29699, loss = 217.39358930\n",
      "Iteration 29700, loss = 217.36886141\n",
      "Iteration 29701, loss = 217.34413851\n",
      "Iteration 29702, loss = 217.31942073\n",
      "Iteration 29703, loss = 217.29470815\n",
      "Iteration 29704, loss = 217.27000072\n",
      "Iteration 29705, loss = 217.24529837\n",
      "Iteration 29706, loss = 217.22060100\n",
      "Iteration 29707, loss = 217.19590861\n",
      "Iteration 29708, loss = 217.17122124\n",
      "Iteration 29709, loss = 217.14653895\n",
      "Iteration 29710, loss = 217.12186176\n",
      "Iteration 29711, loss = 217.09718967\n",
      "Iteration 29712, loss = 217.07252264\n",
      "Iteration 29713, loss = 217.04786063\n",
      "Iteration 29714, loss = 217.02320363\n",
      "Iteration 29715, loss = 216.99855165\n",
      "Iteration 29716, loss = 216.97390471\n",
      "Iteration 29717, loss = 216.94926283\n",
      "Iteration 29718, loss = 216.92462601\n",
      "Iteration 29719, loss = 216.89999424\n",
      "Iteration 29720, loss = 216.87536750\n",
      "Iteration 29721, loss = 216.85074577\n",
      "Iteration 29722, loss = 216.82612906\n",
      "Iteration 29723, loss = 216.80151737\n",
      "Iteration 29724, loss = 216.77691071\n",
      "Iteration 29725, loss = 216.75230908\n",
      "Iteration 29726, loss = 216.72771249\n",
      "Iteration 29727, loss = 216.70312092\n",
      "Iteration 29728, loss = 216.67853437\n",
      "Iteration 29729, loss = 216.65395282\n",
      "Iteration 29730, loss = 216.62937629\n",
      "Iteration 29731, loss = 216.60480476\n",
      "Iteration 29732, loss = 216.58023825\n",
      "Iteration 29733, loss = 216.55567675\n",
      "Iteration 29734, loss = 216.53112026\n",
      "Iteration 29735, loss = 216.50656878\n",
      "Iteration 29736, loss = 216.48202230\n",
      "Iteration 29737, loss = 216.45748082\n",
      "Iteration 29738, loss = 216.43294434\n",
      "Iteration 29739, loss = 216.40841286\n",
      "Iteration 29740, loss = 216.38388637\n",
      "Iteration 29741, loss = 216.35936488\n",
      "Iteration 29742, loss = 216.33484838\n",
      "Iteration 29743, loss = 216.31033687\n",
      "Iteration 29744, loss = 216.28583035\n",
      "Iteration 29745, loss = 216.26132882\n",
      "Iteration 29746, loss = 216.23683228\n",
      "Iteration 29747, loss = 216.21234071\n",
      "Iteration 29748, loss = 216.18785413\n",
      "Iteration 29749, loss = 216.16337252\n",
      "Iteration 29750, loss = 216.13889590\n",
      "Iteration 29751, loss = 216.11442425\n",
      "Iteration 29752, loss = 216.08995757\n",
      "Iteration 29753, loss = 216.06549587\n",
      "Iteration 29754, loss = 216.04103914\n",
      "Iteration 29755, loss = 216.01658737\n",
      "Iteration 29756, loss = 215.99214057\n",
      "Iteration 29757, loss = 215.96769874\n",
      "Iteration 29758, loss = 215.94326187\n",
      "Iteration 29759, loss = 215.91882996\n",
      "Iteration 29760, loss = 215.89440301\n",
      "Iteration 29761, loss = 215.86998102\n",
      "Iteration 29762, loss = 215.84556398\n",
      "Iteration 29763, loss = 215.82115190\n",
      "Iteration 29764, loss = 215.79674477\n",
      "Iteration 29765, loss = 215.77234259\n",
      "Iteration 29766, loss = 215.74794536\n",
      "Iteration 29767, loss = 215.72355308\n",
      "Iteration 29768, loss = 215.69916574\n",
      "Iteration 29769, loss = 215.67478334\n",
      "Iteration 29770, loss = 215.65040589\n",
      "Iteration 29771, loss = 215.62603337\n",
      "Iteration 29772, loss = 215.60166579\n",
      "Iteration 29773, loss = 215.57730315\n",
      "Iteration 29774, loss = 215.55294544\n",
      "Iteration 29775, loss = 215.52859266\n",
      "Iteration 29776, loss = 215.50424481\n",
      "Iteration 29777, loss = 215.47990190\n",
      "Iteration 29778, loss = 215.45556390\n",
      "Iteration 29779, loss = 215.43123084\n",
      "Iteration 29780, loss = 215.40690269\n",
      "Iteration 29781, loss = 215.38257947\n",
      "Iteration 29782, loss = 215.35826117\n",
      "Iteration 29783, loss = 215.33394778\n",
      "Iteration 29784, loss = 215.30963931\n",
      "Iteration 29785, loss = 215.28533575\n",
      "Iteration 29786, loss = 215.26103711\n",
      "Iteration 29787, loss = 215.23674337\n",
      "Iteration 29788, loss = 215.21245455\n",
      "Iteration 29789, loss = 215.18817063\n",
      "Iteration 29790, loss = 215.16389161\n",
      "Iteration 29791, loss = 215.13961750\n",
      "Iteration 29792, loss = 215.11534829\n",
      "Iteration 29793, loss = 215.09108398\n",
      "Iteration 29794, loss = 215.06682457\n",
      "Iteration 29795, loss = 215.04257005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29796, loss = 215.01832043\n",
      "Iteration 29797, loss = 214.99407570\n",
      "Iteration 29798, loss = 214.96983585\n",
      "Iteration 29799, loss = 214.94560090\n",
      "Iteration 29800, loss = 214.92137084\n",
      "Iteration 29801, loss = 214.89714566\n",
      "Iteration 29802, loss = 214.87292536\n",
      "Iteration 29803, loss = 214.84870994\n",
      "Iteration 29804, loss = 214.82449941\n",
      "Iteration 29805, loss = 214.80029375\n",
      "Iteration 29806, loss = 214.77609297\n",
      "Iteration 29807, loss = 214.75189706\n",
      "Iteration 29808, loss = 214.72770602\n",
      "Iteration 29809, loss = 214.70351986\n",
      "Iteration 29810, loss = 214.67933856\n",
      "Iteration 29811, loss = 214.65516213\n",
      "Iteration 29812, loss = 214.63099057\n",
      "Iteration 29813, loss = 214.60682387\n",
      "Iteration 29814, loss = 214.58266203\n",
      "Iteration 29815, loss = 214.55850505\n",
      "Iteration 29816, loss = 214.53435293\n",
      "Iteration 29817, loss = 214.51020566\n",
      "Iteration 29818, loss = 214.48606325\n",
      "Iteration 29819, loss = 214.46192569\n",
      "Iteration 29820, loss = 214.43779299\n",
      "Iteration 29821, loss = 214.41366513\n",
      "Iteration 29822, loss = 214.38954212\n",
      "Iteration 29823, loss = 214.36542395\n",
      "Iteration 29824, loss = 214.34131063\n",
      "Iteration 29825, loss = 214.31720215\n",
      "Iteration 29826, loss = 214.29309851\n",
      "Iteration 29827, loss = 214.26899971\n",
      "Iteration 29828, loss = 214.24490575\n",
      "Iteration 29829, loss = 214.22081662\n",
      "Iteration 29830, loss = 214.19673232\n",
      "Iteration 29831, loss = 214.17265286\n",
      "Iteration 29832, loss = 214.14857822\n",
      "Iteration 29833, loss = 214.12450842\n",
      "Iteration 29834, loss = 214.10044343\n",
      "Iteration 29835, loss = 214.07638328\n",
      "Iteration 29836, loss = 214.05232794\n",
      "Iteration 29837, loss = 214.02827743\n",
      "Iteration 29838, loss = 214.00423173\n",
      "Iteration 29839, loss = 213.98019085\n",
      "Iteration 29840, loss = 213.95615479\n",
      "Iteration 29841, loss = 213.93212355\n",
      "Iteration 29842, loss = 213.90809711\n",
      "Iteration 29843, loss = 213.88407549\n",
      "Iteration 29844, loss = 213.86005868\n",
      "Iteration 29845, loss = 213.83604668\n",
      "Iteration 29846, loss = 213.81203949\n",
      "Iteration 29847, loss = 213.78803712\n",
      "Iteration 29848, loss = 213.76403957\n",
      "Iteration 29849, loss = 213.74004685\n",
      "Iteration 29850, loss = 213.71605898\n",
      "Iteration 29851, loss = 213.69207600\n",
      "Iteration 29852, loss = 213.66809795\n",
      "Iteration 29853, loss = 213.64412493\n",
      "Iteration 29854, loss = 213.62015708\n",
      "Iteration 29855, loss = 213.59619465\n",
      "Iteration 29856, loss = 213.57223803\n",
      "Iteration 29857, loss = 213.54828781\n",
      "Iteration 29858, loss = 213.52434491\n",
      "Iteration 29859, loss = 213.50041037\n",
      "Iteration 29860, loss = 213.47648530\n",
      "Iteration 29861, loss = 213.45256914\n",
      "Iteration 29862, loss = 213.42865869\n",
      "Iteration 29863, loss = 213.40474446\n",
      "Iteration 29864, loss = 213.38081629\n",
      "Iteration 29865, loss = 213.35687069\n",
      "Iteration 29866, loss = 213.33292312\n",
      "Iteration 29867, loss = 213.30899600\n",
      "Iteration 29868, loss = 213.28509905\n",
      "Iteration 29869, loss = 213.26122147\n",
      "Iteration 29870, loss = 213.23734307\n",
      "Iteration 29871, loss = 213.21345114\n",
      "Iteration 29872, loss = 213.18955015\n",
      "Iteration 29873, loss = 213.16565732\n",
      "Iteration 29874, loss = 213.14178433\n",
      "Iteration 29875, loss = 213.11792691\n",
      "Iteration 29876, loss = 213.09407165\n",
      "Iteration 29877, loss = 213.07021013\n",
      "Iteration 29878, loss = 213.04634652\n",
      "Iteration 29879, loss = 213.02249148\n",
      "Iteration 29880, loss = 212.99865004\n",
      "Iteration 29881, loss = 212.97481732\n",
      "Iteration 29882, loss = 212.95098455\n",
      "Iteration 29883, loss = 212.92714888\n",
      "Iteration 29884, loss = 212.90331487\n",
      "Iteration 29885, loss = 212.87948939\n",
      "Iteration 29886, loss = 212.85567428\n",
      "Iteration 29887, loss = 212.83186591\n",
      "Iteration 29888, loss = 212.80806002\n",
      "Iteration 29889, loss = 212.78425594\n",
      "Iteration 29890, loss = 212.76045626\n",
      "Iteration 29891, loss = 212.73666305\n",
      "Iteration 29892, loss = 212.71287585\n",
      "Iteration 29893, loss = 212.68909279\n",
      "Iteration 29894, loss = 212.66531308\n",
      "Iteration 29895, loss = 212.64153776\n",
      "Iteration 29896, loss = 212.61776826\n",
      "Iteration 29897, loss = 212.59400471\n",
      "Iteration 29898, loss = 212.57024586\n",
      "Iteration 29899, loss = 212.54649058\n",
      "Iteration 29900, loss = 212.52273901\n",
      "Iteration 29901, loss = 212.49899231\n",
      "Iteration 29902, loss = 212.47525138\n",
      "Iteration 29903, loss = 212.45151598\n",
      "Iteration 29904, loss = 212.42778514\n",
      "Iteration 29905, loss = 212.40405818\n",
      "Iteration 29906, loss = 212.38033530\n",
      "Iteration 29907, loss = 212.35661723\n",
      "Iteration 29908, loss = 212.33290447\n",
      "Iteration 29909, loss = 212.30919689\n",
      "Iteration 29910, loss = 212.28549395\n",
      "Iteration 29911, loss = 212.26179527\n",
      "Iteration 29912, loss = 212.23810096\n",
      "Iteration 29913, loss = 212.21441136\n",
      "Iteration 29914, loss = 212.19072672\n",
      "Iteration 29915, loss = 212.16704700\n",
      "Iteration 29916, loss = 212.14337196\n",
      "Iteration 29917, loss = 212.11970143\n",
      "Iteration 29918, loss = 212.09603544\n",
      "Iteration 29919, loss = 212.07237413\n",
      "Iteration 29920, loss = 212.04871759\n",
      "Iteration 29921, loss = 212.02506581\n",
      "Iteration 29922, loss = 212.00141871\n",
      "Iteration 29923, loss = 211.97777622\n",
      "Iteration 29924, loss = 211.95413835\n",
      "Iteration 29925, loss = 211.93050515\n",
      "Iteration 29926, loss = 211.90687665\n",
      "Iteration 29927, loss = 211.88325284\n",
      "Iteration 29928, loss = 211.85963369\n",
      "Iteration 29929, loss = 211.83601917\n",
      "Iteration 29930, loss = 211.81240929\n",
      "Iteration 29931, loss = 211.78880408\n",
      "Iteration 29932, loss = 211.76520354\n",
      "Iteration 29933, loss = 211.74160768\n",
      "Iteration 29934, loss = 211.71801645\n",
      "Iteration 29935, loss = 211.69442985\n",
      "Iteration 29936, loss = 211.67084789\n",
      "Iteration 29937, loss = 211.64727057\n",
      "Iteration 29938, loss = 211.62369792\n",
      "Iteration 29939, loss = 211.60012993\n",
      "Iteration 29940, loss = 211.57656657\n",
      "Iteration 29941, loss = 211.55300784\n",
      "Iteration 29942, loss = 211.52945373\n",
      "Iteration 29943, loss = 211.50590426\n",
      "Iteration 29944, loss = 211.48235942\n",
      "Iteration 29945, loss = 211.45881923\n",
      "Iteration 29946, loss = 211.43528367\n",
      "Iteration 29947, loss = 211.41175274\n",
      "Iteration 29948, loss = 211.38822643\n",
      "Iteration 29949, loss = 211.36470474\n",
      "Iteration 29950, loss = 211.34118767\n",
      "Iteration 29951, loss = 211.31767522\n",
      "Iteration 29952, loss = 211.29416740\n",
      "Iteration 29953, loss = 211.27066420\n",
      "Iteration 29954, loss = 211.24716561\n",
      "Iteration 29955, loss = 211.22367164\n",
      "Iteration 29956, loss = 211.20018227\n",
      "Iteration 29957, loss = 211.17669751\n",
      "Iteration 29958, loss = 211.15321737\n",
      "Iteration 29959, loss = 211.12974183\n",
      "Iteration 29960, loss = 211.10627090\n",
      "Iteration 29961, loss = 211.08280458\n",
      "Iteration 29962, loss = 211.05934285\n",
      "Iteration 29963, loss = 211.03588573\n",
      "Iteration 29964, loss = 211.01243320\n",
      "Iteration 29965, loss = 210.98898527\n",
      "Iteration 29966, loss = 210.96554194\n",
      "Iteration 29967, loss = 210.94210320\n",
      "Iteration 29968, loss = 210.91866906\n",
      "Iteration 29969, loss = 210.89523950\n",
      "Iteration 29970, loss = 210.87181453\n",
      "Iteration 29971, loss = 210.84839415\n",
      "Iteration 29972, loss = 210.82497835\n",
      "Iteration 29973, loss = 210.80156714\n",
      "Iteration 29974, loss = 210.77816050\n",
      "Iteration 29975, loss = 210.75475845\n",
      "Iteration 29976, loss = 210.73136098\n",
      "Iteration 29977, loss = 210.70796808\n",
      "Iteration 29978, loss = 210.68457976\n",
      "Iteration 29979, loss = 210.66119601\n",
      "Iteration 29980, loss = 210.63781683\n",
      "Iteration 29981, loss = 210.61444222\n",
      "Iteration 29982, loss = 210.59107218\n",
      "Iteration 29983, loss = 210.56770670\n",
      "Iteration 29984, loss = 210.54434579\n",
      "Iteration 29985, loss = 210.52098945\n",
      "Iteration 29986, loss = 210.49763766\n",
      "Iteration 29987, loss = 210.47429043\n",
      "Iteration 29988, loss = 210.45094776\n",
      "Iteration 29989, loss = 210.42760965\n",
      "Iteration 29990, loss = 210.40427609\n",
      "Iteration 29991, loss = 210.38094708\n",
      "Iteration 29992, loss = 210.35762263\n",
      "Iteration 29993, loss = 210.33430272\n",
      "Iteration 29994, loss = 210.31098736\n",
      "Iteration 29995, loss = 210.28767654\n",
      "Iteration 29996, loss = 210.26437027\n",
      "Iteration 29997, loss = 210.24106855\n",
      "Iteration 29998, loss = 210.21777136\n",
      "Iteration 29999, loss = 210.19447871\n",
      "Iteration 30000, loss = 210.17119060\n",
      "Iteration 30001, loss = 210.14790702\n",
      "Iteration 30002, loss = 210.12462798\n",
      "Iteration 30003, loss = 210.10135347\n",
      "Iteration 30004, loss = 210.07808349\n",
      "Iteration 30005, loss = 210.05481804\n",
      "Iteration 30006, loss = 210.03155711\n",
      "Iteration 30007, loss = 210.00830071\n",
      "Iteration 30008, loss = 209.98504884\n",
      "Iteration 30009, loss = 209.96180148\n",
      "Iteration 30010, loss = 209.93855865\n",
      "Iteration 30011, loss = 209.91532034\n",
      "Iteration 30012, loss = 209.89208654\n",
      "Iteration 30013, loss = 209.86885725\n",
      "Iteration 30014, loss = 209.84563248\n",
      "Iteration 30015, loss = 209.82241222\n",
      "Iteration 30016, loss = 209.79919647\n",
      "Iteration 30017, loss = 209.77598523\n",
      "Iteration 30018, loss = 209.75277850\n",
      "Iteration 30019, loss = 209.72957627\n",
      "Iteration 30020, loss = 209.70637854\n",
      "Iteration 30021, loss = 209.68318532\n",
      "Iteration 30022, loss = 209.65999659\n",
      "Iteration 30023, loss = 209.63681237\n",
      "Iteration 30024, loss = 209.61363264\n",
      "Iteration 30025, loss = 209.59045740\n",
      "Iteration 30026, loss = 209.56728666\n",
      "Iteration 30027, loss = 209.54412040\n",
      "Iteration 30028, loss = 209.52095864\n",
      "Iteration 30029, loss = 209.49780137\n",
      "Iteration 30030, loss = 209.47464858\n",
      "Iteration 30031, loss = 209.45150027\n",
      "Iteration 30032, loss = 209.42835645\n",
      "Iteration 30033, loss = 209.40521711\n",
      "Iteration 30034, loss = 209.38208225\n",
      "Iteration 30035, loss = 209.35895187\n",
      "Iteration 30036, loss = 209.33582596\n",
      "Iteration 30037, loss = 209.31270453\n",
      "Iteration 30038, loss = 209.28958757\n",
      "Iteration 30039, loss = 209.26647508\n",
      "Iteration 30040, loss = 209.24336706\n",
      "Iteration 30041, loss = 209.22026350\n",
      "Iteration 30042, loss = 209.19716442\n",
      "Iteration 30043, loss = 209.17406979\n",
      "Iteration 30044, loss = 209.15097963\n",
      "Iteration 30045, loss = 209.12789393\n",
      "Iteration 30046, loss = 209.10481269\n",
      "Iteration 30047, loss = 209.08173591\n",
      "Iteration 30048, loss = 209.05866358\n",
      "Iteration 30049, loss = 209.03559571\n",
      "Iteration 30050, loss = 209.01253228\n",
      "Iteration 30051, loss = 208.98947331\n",
      "Iteration 30052, loss = 208.96641879\n",
      "Iteration 30053, loss = 208.94336872\n",
      "Iteration 30054, loss = 208.92032309\n",
      "Iteration 30055, loss = 208.89728190\n",
      "Iteration 30056, loss = 208.87424516\n",
      "Iteration 30057, loss = 208.85121285\n",
      "Iteration 30058, loss = 208.82818499\n",
      "Iteration 30059, loss = 208.80516156\n",
      "Iteration 30060, loss = 208.78214257\n",
      "Iteration 30061, loss = 208.75912801\n",
      "Iteration 30062, loss = 208.73611788\n",
      "Iteration 30063, loss = 208.71311219\n",
      "Iteration 30064, loss = 208.69011092\n",
      "Iteration 30065, loss = 208.66711408\n",
      "Iteration 30066, loss = 208.64412167\n",
      "Iteration 30067, loss = 208.62113367\n",
      "Iteration 30068, loss = 208.59815010\n",
      "Iteration 30069, loss = 208.57517095\n",
      "Iteration 30070, loss = 208.55219622\n",
      "Iteration 30071, loss = 208.52922591\n",
      "Iteration 30072, loss = 208.50626001\n",
      "Iteration 30073, loss = 208.48329852\n",
      "Iteration 30074, loss = 208.46034145\n",
      "Iteration 30075, loss = 208.43738879\n",
      "Iteration 30076, loss = 208.41444053\n",
      "Iteration 30077, loss = 208.39149668\n",
      "Iteration 30078, loss = 208.36855724\n",
      "Iteration 30079, loss = 208.34562220\n",
      "Iteration 30080, loss = 208.32269156\n",
      "Iteration 30081, loss = 208.29976532\n",
      "Iteration 30082, loss = 208.27684348\n",
      "Iteration 30083, loss = 208.25392603\n",
      "Iteration 30084, loss = 208.23101299\n",
      "Iteration 30085, loss = 208.20810433\n",
      "Iteration 30086, loss = 208.18520007\n",
      "Iteration 30087, loss = 208.16230019\n",
      "Iteration 30088, loss = 208.13940470\n",
      "Iteration 30089, loss = 208.11651360\n",
      "Iteration 30090, loss = 208.09362689\n",
      "Iteration 30091, loss = 208.07074456\n",
      "Iteration 30092, loss = 208.04786661\n",
      "Iteration 30093, loss = 208.02499304\n",
      "Iteration 30094, loss = 208.00212384\n",
      "Iteration 30095, loss = 207.97925903\n",
      "Iteration 30096, loss = 207.95639859\n",
      "Iteration 30097, loss = 207.93354252\n",
      "Iteration 30098, loss = 207.91069082\n",
      "Iteration 30099, loss = 207.88784350\n",
      "Iteration 30100, loss = 207.86500054\n",
      "Iteration 30101, loss = 207.84216194\n",
      "Iteration 30102, loss = 207.81932772\n",
      "Iteration 30103, loss = 207.79649785\n",
      "Iteration 30104, loss = 207.77367235\n",
      "Iteration 30105, loss = 207.75085120\n",
      "Iteration 30106, loss = 207.72803442\n",
      "Iteration 30107, loss = 207.70522199\n",
      "Iteration 30108, loss = 207.68241392\n",
      "Iteration 30109, loss = 207.65961021\n",
      "Iteration 30110, loss = 207.63681085\n",
      "Iteration 30111, loss = 207.61401585\n",
      "Iteration 30112, loss = 207.59122521\n",
      "Iteration 30113, loss = 207.56843894\n",
      "Iteration 30114, loss = 207.54565705\n",
      "Iteration 30115, loss = 207.52287958\n",
      "Iteration 30116, loss = 207.50010657\n",
      "Iteration 30117, loss = 207.47733810\n",
      "Iteration 30118, loss = 207.45457433\n",
      "Iteration 30119, loss = 207.43181553\n",
      "Iteration 30120, loss = 207.40906214\n",
      "Iteration 30121, loss = 207.38631492\n",
      "Iteration 30122, loss = 207.36357510\n",
      "Iteration 30123, loss = 207.34084436\n",
      "Iteration 30124, loss = 207.31812474\n",
      "Iteration 30125, loss = 207.29541654\n",
      "Iteration 30126, loss = 207.27271575\n",
      "Iteration 30127, loss = 207.25000795\n",
      "Iteration 30128, loss = 207.22727543\n",
      "Iteration 30129, loss = 207.20451391\n",
      "Iteration 30130, loss = 207.18175228\n",
      "Iteration 30131, loss = 207.15902651\n",
      "Iteration 30132, loss = 207.13634213\n",
      "Iteration 30133, loss = 207.11367093\n",
      "Iteration 30134, loss = 207.09098046\n",
      "Iteration 30135, loss = 207.06826598\n",
      "Iteration 30136, loss = 207.04555375\n",
      "Iteration 30137, loss = 207.02286946\n",
      "Iteration 30138, loss = 207.00020832\n",
      "Iteration 30139, loss = 206.97754539\n",
      "Iteration 30140, loss = 206.95486722\n",
      "Iteration 30141, loss = 206.93218571\n",
      "Iteration 30142, loss = 206.90952047\n",
      "Iteration 30143, loss = 206.88687344\n",
      "Iteration 30144, loss = 206.86422970\n",
      "Iteration 30145, loss = 206.84157873\n",
      "Iteration 30146, loss = 206.81892645\n",
      "Iteration 30147, loss = 206.79628521\n",
      "Iteration 30148, loss = 206.77365647\n",
      "Iteration 30149, loss = 206.75103076\n",
      "Iteration 30150, loss = 206.72840068\n",
      "Iteration 30151, loss = 206.70577008\n",
      "Iteration 30152, loss = 206.68314732\n",
      "Iteration 30153, loss = 206.66053491\n",
      "Iteration 30154, loss = 206.63792804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30155, loss = 206.61532244\n",
      "Iteration 30156, loss = 206.59271934\n",
      "Iteration 30157, loss = 206.57012214\n",
      "Iteration 30158, loss = 206.54753108\n",
      "Iteration 30159, loss = 206.52494329\n",
      "Iteration 30160, loss = 206.50235742\n",
      "Iteration 30161, loss = 206.47977547\n",
      "Iteration 30162, loss = 206.45720000\n",
      "Iteration 30163, loss = 206.43463073\n",
      "Iteration 30164, loss = 206.41206514\n",
      "Iteration 30165, loss = 206.38950171\n",
      "Iteration 30166, loss = 206.36694152\n",
      "Iteration 30167, loss = 206.34438658\n",
      "Iteration 30168, loss = 206.32183741\n",
      "Iteration 30169, loss = 206.29929278\n",
      "Iteration 30170, loss = 206.27675153\n",
      "Iteration 30171, loss = 206.25421378\n",
      "Iteration 30172, loss = 206.23168042\n",
      "Iteration 30173, loss = 206.20915188\n",
      "Iteration 30174, loss = 206.18662780\n",
      "Iteration 30175, loss = 206.16410770\n",
      "Iteration 30176, loss = 206.14159162\n",
      "Iteration 30177, loss = 206.11907991\n",
      "Iteration 30178, loss = 206.09657266\n",
      "Iteration 30179, loss = 206.07406963\n",
      "Iteration 30180, loss = 206.05157059\n",
      "Iteration 30181, loss = 206.02907567\n",
      "Iteration 30182, loss = 206.00658514\n",
      "Iteration 30183, loss = 205.98409908\n",
      "Iteration 30184, loss = 205.96161729\n",
      "Iteration 30185, loss = 205.93913953\n",
      "Iteration 30186, loss = 205.91666580\n",
      "Iteration 30187, loss = 205.89419632\n",
      "Iteration 30188, loss = 205.87173124\n",
      "Iteration 30189, loss = 205.84927051\n",
      "Iteration 30190, loss = 205.82681395\n",
      "Iteration 30191, loss = 205.80436148\n",
      "Iteration 30192, loss = 205.78191315\n",
      "Iteration 30193, loss = 205.75946908\n",
      "Iteration 30194, loss = 205.73702930\n",
      "Iteration 30195, loss = 205.71459377\n",
      "Iteration 30196, loss = 205.69216240\n",
      "Iteration 30197, loss = 205.66973520\n",
      "Iteration 30198, loss = 205.64731220\n",
      "Iteration 30199, loss = 205.62489343\n",
      "Iteration 30200, loss = 205.60247887\n",
      "Iteration 30201, loss = 205.58006851\n",
      "Iteration 30202, loss = 205.55766232\n",
      "Iteration 30203, loss = 205.53526033\n",
      "Iteration 30204, loss = 205.51286255\n",
      "Iteration 30205, loss = 205.49046898\n",
      "Iteration 30206, loss = 205.46807958\n",
      "Iteration 30207, loss = 205.44569436\n",
      "Iteration 30208, loss = 205.42331332\n",
      "Iteration 30209, loss = 205.40093648\n",
      "Iteration 30210, loss = 205.37856383\n",
      "Iteration 30211, loss = 205.35619537\n",
      "Iteration 30212, loss = 205.33383109\n",
      "Iteration 30213, loss = 205.31147097\n",
      "Iteration 30214, loss = 205.28911502\n",
      "Iteration 30215, loss = 205.26676326\n",
      "Iteration 30216, loss = 205.24441568\n",
      "Iteration 30217, loss = 205.22207227\n",
      "Iteration 30218, loss = 205.19973303\n",
      "Iteration 30219, loss = 205.17739796\n",
      "Iteration 30220, loss = 205.15506704\n",
      "Iteration 30221, loss = 205.13274030\n",
      "Iteration 30222, loss = 205.11041772\n",
      "Iteration 30223, loss = 205.08809931\n",
      "Iteration 30224, loss = 205.06578506\n",
      "Iteration 30225, loss = 205.04347496\n",
      "Iteration 30226, loss = 205.02116902\n",
      "Iteration 30227, loss = 204.99886724\n",
      "Iteration 30228, loss = 204.97656961\n",
      "Iteration 30229, loss = 204.95427613\n",
      "Iteration 30230, loss = 204.93198681\n",
      "Iteration 30231, loss = 204.90970163\n",
      "Iteration 30232, loss = 204.88742060\n",
      "Iteration 30233, loss = 204.86514371\n",
      "Iteration 30234, loss = 204.84287097\n",
      "Iteration 30235, loss = 204.82060237\n",
      "Iteration 30236, loss = 204.79833791\n",
      "Iteration 30237, loss = 204.77607759\n",
      "Iteration 30238, loss = 204.75382141\n",
      "Iteration 30239, loss = 204.73156936\n",
      "Iteration 30240, loss = 204.70932145\n",
      "Iteration 30241, loss = 204.68707767\n",
      "Iteration 30242, loss = 204.66483802\n",
      "Iteration 30243, loss = 204.64260249\n",
      "Iteration 30244, loss = 204.62037110\n",
      "Iteration 30245, loss = 204.59814383\n",
      "Iteration 30246, loss = 204.57592068\n",
      "Iteration 30247, loss = 204.55370166\n",
      "Iteration 30248, loss = 204.53148675\n",
      "Iteration 30249, loss = 204.50927597\n",
      "Iteration 30250, loss = 204.48706930\n",
      "Iteration 30251, loss = 204.46486675\n",
      "Iteration 30252, loss = 204.44266831\n",
      "Iteration 30253, loss = 204.42047398\n",
      "Iteration 30254, loss = 204.39828377\n",
      "Iteration 30255, loss = 204.37609766\n",
      "Iteration 30256, loss = 204.35391566\n",
      "Iteration 30257, loss = 204.33173777\n",
      "Iteration 30258, loss = 204.30956398\n",
      "Iteration 30259, loss = 204.28739429\n",
      "Iteration 30260, loss = 204.26522870\n",
      "Iteration 30261, loss = 204.24306721\n",
      "Iteration 30262, loss = 204.22090982\n",
      "Iteration 30263, loss = 204.19875652\n",
      "Iteration 30264, loss = 204.17660731\n",
      "Iteration 30265, loss = 204.15446220\n",
      "Iteration 30266, loss = 204.13232118\n",
      "Iteration 30267, loss = 204.11018425\n",
      "Iteration 30268, loss = 204.08805140\n",
      "Iteration 30269, loss = 204.06592264\n",
      "Iteration 30270, loss = 204.04379797\n",
      "Iteration 30271, loss = 204.02167737\n",
      "Iteration 30272, loss = 203.99956086\n",
      "Iteration 30273, loss = 203.97744842\n",
      "Iteration 30274, loss = 203.95534006\n",
      "Iteration 30275, loss = 203.93323578\n",
      "Iteration 30276, loss = 203.91113557\n",
      "Iteration 30277, loss = 203.88903943\n",
      "Iteration 30278, loss = 203.86694737\n",
      "Iteration 30279, loss = 203.84485937\n",
      "Iteration 30280, loss = 203.82277544\n",
      "Iteration 30281, loss = 203.80069557\n",
      "Iteration 30282, loss = 203.77861977\n",
      "Iteration 30283, loss = 203.75654803\n",
      "Iteration 30284, loss = 203.73448035\n",
      "Iteration 30285, loss = 203.71241673\n",
      "Iteration 30286, loss = 203.69035716\n",
      "Iteration 30287, loss = 203.66830165\n",
      "Iteration 30288, loss = 203.64625020\n",
      "Iteration 30289, loss = 203.62420279\n",
      "Iteration 30290, loss = 203.60215944\n",
      "Iteration 30291, loss = 203.58012013\n",
      "Iteration 30292, loss = 203.55808488\n",
      "Iteration 30293, loss = 203.53605366\n",
      "Iteration 30294, loss = 203.51402649\n",
      "Iteration 30295, loss = 203.49200337\n",
      "Iteration 30296, loss = 203.46998428\n",
      "Iteration 30297, loss = 203.44796923\n",
      "Iteration 30298, loss = 203.42595822\n",
      "Iteration 30299, loss = 203.40395124\n",
      "Iteration 30300, loss = 203.38194830\n",
      "Iteration 30301, loss = 203.35994939\n",
      "Iteration 30302, loss = 203.33795451\n",
      "Iteration 30303, loss = 203.31596366\n",
      "Iteration 30304, loss = 203.29397683\n",
      "Iteration 30305, loss = 203.27199403\n",
      "Iteration 30306, loss = 203.25001525\n",
      "Iteration 30307, loss = 203.22804050\n",
      "Iteration 30308, loss = 203.20606976\n",
      "Iteration 30309, loss = 203.18410305\n",
      "Iteration 30310, loss = 203.16214035\n",
      "Iteration 30311, loss = 203.14018166\n",
      "Iteration 30312, loss = 203.11822699\n",
      "Iteration 30313, loss = 203.09627633\n",
      "Iteration 30314, loss = 203.07432968\n",
      "Iteration 30315, loss = 203.05238704\n",
      "Iteration 30316, loss = 203.03044841\n",
      "Iteration 30317, loss = 203.00851378\n",
      "Iteration 30318, loss = 202.98658315\n",
      "Iteration 30319, loss = 202.96465653\n",
      "Iteration 30320, loss = 202.94273391\n",
      "Iteration 30321, loss = 202.92081528\n",
      "Iteration 30322, loss = 202.89890065\n",
      "Iteration 30323, loss = 202.87699002\n",
      "Iteration 30324, loss = 202.85508338\n",
      "Iteration 30325, loss = 202.83318073\n",
      "Iteration 30326, loss = 202.81128207\n",
      "Iteration 30327, loss = 202.78938740\n",
      "Iteration 30328, loss = 202.76749671\n",
      "Iteration 30329, loss = 202.74561001\n",
      "Iteration 30330, loss = 202.72372730\n",
      "Iteration 30331, loss = 202.70184856\n",
      "Iteration 30332, loss = 202.67997381\n",
      "Iteration 30333, loss = 202.65810303\n",
      "Iteration 30334, loss = 202.63623623\n",
      "Iteration 30335, loss = 202.61437341\n",
      "Iteration 30336, loss = 202.59251455\n",
      "Iteration 30337, loss = 202.57065967\n",
      "Iteration 30338, loss = 202.54880876\n",
      "Iteration 30339, loss = 202.52696182\n",
      "Iteration 30340, loss = 202.50511884\n",
      "Iteration 30341, loss = 202.48327983\n",
      "Iteration 30342, loss = 202.46144478\n",
      "Iteration 30343, loss = 202.43961370\n",
      "Iteration 30344, loss = 202.41778657\n",
      "Iteration 30345, loss = 202.39596340\n",
      "Iteration 30346, loss = 202.37414419\n",
      "Iteration 30347, loss = 202.35232893\n",
      "Iteration 30348, loss = 202.33051762\n",
      "Iteration 30349, loss = 202.30871027\n",
      "Iteration 30350, loss = 202.28690686\n",
      "Iteration 30351, loss = 202.26510740\n",
      "Iteration 30352, loss = 202.24331189\n",
      "Iteration 30353, loss = 202.22152033\n",
      "Iteration 30354, loss = 202.19973270\n",
      "Iteration 30355, loss = 202.17794902\n",
      "Iteration 30356, loss = 202.15616928\n",
      "Iteration 30357, loss = 202.13439348\n",
      "Iteration 30358, loss = 202.11262161\n",
      "Iteration 30359, loss = 202.09085367\n",
      "Iteration 30360, loss = 202.06908967\n",
      "Iteration 30361, loss = 202.04732960\n",
      "Iteration 30362, loss = 202.02557346\n",
      "Iteration 30363, loss = 202.00382124\n",
      "Iteration 30364, loss = 201.98207296\n",
      "Iteration 30365, loss = 201.96032859\n",
      "Iteration 30366, loss = 201.93858815\n",
      "Iteration 30367, loss = 201.91685163\n",
      "Iteration 30368, loss = 201.89511903\n",
      "Iteration 30369, loss = 201.87339035\n",
      "Iteration 30370, loss = 201.85166558\n",
      "Iteration 30371, loss = 201.82994473\n",
      "Iteration 30372, loss = 201.80822779\n",
      "Iteration 30373, loss = 201.78651476\n",
      "Iteration 30374, loss = 201.76480563\n",
      "Iteration 30375, loss = 201.74310042\n",
      "Iteration 30376, loss = 201.72139911\n",
      "Iteration 30377, loss = 201.69970171\n",
      "Iteration 30378, loss = 201.67800821\n",
      "Iteration 30379, loss = 201.65631860\n",
      "Iteration 30380, loss = 201.63463290\n",
      "Iteration 30381, loss = 201.61295110\n",
      "Iteration 30382, loss = 201.59127319\n",
      "Iteration 30383, loss = 201.56959917\n",
      "Iteration 30384, loss = 201.54792905\n",
      "Iteration 30385, loss = 201.52626281\n",
      "Iteration 30386, loss = 201.50460047\n",
      "Iteration 30387, loss = 201.48294201\n",
      "Iteration 30388, loss = 201.46128744\n",
      "Iteration 30389, loss = 201.43963675\n",
      "Iteration 30390, loss = 201.41798994\n",
      "Iteration 30391, loss = 201.39634701\n",
      "Iteration 30392, loss = 201.37470796\n",
      "Iteration 30393, loss = 201.35307279\n",
      "Iteration 30394, loss = 201.33144150\n",
      "Iteration 30395, loss = 201.30981407\n",
      "Iteration 30396, loss = 201.28819052\n",
      "Iteration 30397, loss = 201.26657084\n",
      "Iteration 30398, loss = 201.24495502\n",
      "Iteration 30399, loss = 201.22334308\n",
      "Iteration 30400, loss = 201.20173500\n",
      "Iteration 30401, loss = 201.18013078\n",
      "Iteration 30402, loss = 201.15853042\n",
      "Iteration 30403, loss = 201.13693392\n",
      "Iteration 30404, loss = 201.11534128\n",
      "Iteration 30405, loss = 201.09375250\n",
      "Iteration 30406, loss = 201.07216757\n",
      "Iteration 30407, loss = 201.05058649\n",
      "Iteration 30408, loss = 201.02900927\n",
      "Iteration 30409, loss = 201.00743589\n",
      "Iteration 30410, loss = 200.98586636\n",
      "Iteration 30411, loss = 200.96430068\n",
      "Iteration 30412, loss = 200.94273885\n",
      "Iteration 30413, loss = 200.92118085\n",
      "Iteration 30414, loss = 200.89962670\n",
      "Iteration 30415, loss = 200.87807638\n",
      "Iteration 30416, loss = 200.85652991\n",
      "Iteration 30417, loss = 200.83498727\n",
      "Iteration 30418, loss = 200.81344846\n",
      "Iteration 30419, loss = 200.79191349\n",
      "Iteration 30420, loss = 200.77038235\n",
      "Iteration 30421, loss = 200.74885503\n",
      "Iteration 30422, loss = 200.72733155\n",
      "Iteration 30423, loss = 200.70581190\n",
      "Iteration 30424, loss = 200.68429608\n",
      "Iteration 30425, loss = 200.66278410\n",
      "Iteration 30426, loss = 200.64127596\n",
      "Iteration 30427, loss = 200.61977167\n",
      "Iteration 30428, loss = 200.59827127\n",
      "Iteration 30429, loss = 200.57677480\n",
      "Iteration 30430, loss = 200.55528233\n",
      "Iteration 30431, loss = 200.53379402\n",
      "Iteration 30432, loss = 200.51231010\n",
      "Iteration 30433, loss = 200.49083102\n",
      "Iteration 30434, loss = 200.46935751\n",
      "Iteration 30435, loss = 200.44789077\n",
      "Iteration 30436, loss = 200.42643263\n",
      "Iteration 30437, loss = 200.40498540\n",
      "Iteration 30438, loss = 200.38355080\n",
      "Iteration 30439, loss = 200.36212650\n",
      "Iteration 30440, loss = 200.34070034\n",
      "Iteration 30441, loss = 200.31925007\n",
      "Iteration 30442, loss = 200.29776075\n",
      "Iteration 30443, loss = 200.27625505\n",
      "Iteration 30444, loss = 200.25478071\n",
      "Iteration 30445, loss = 200.23335909\n",
      "Iteration 30446, loss = 200.21196325\n",
      "Iteration 30447, loss = 200.19054916\n",
      "Iteration 30448, loss = 200.16910096\n",
      "Iteration 30449, loss = 200.14764689\n",
      "Iteration 30450, loss = 200.12622329\n",
      "Iteration 30451, loss = 200.10482938\n",
      "Iteration 30452, loss = 200.08343428\n",
      "Iteration 30453, loss = 200.06201901\n",
      "Iteration 30454, loss = 200.04059781\n",
      "Iteration 30455, loss = 200.01919492\n",
      "Iteration 30456, loss = 199.99781147\n",
      "Iteration 30457, loss = 199.97642834\n",
      "Iteration 30458, loss = 199.95503480\n",
      "Iteration 30459, loss = 199.93364112\n",
      "Iteration 30460, loss = 199.91226112\n",
      "Iteration 30461, loss = 199.89089270\n",
      "Iteration 30462, loss = 199.86952359\n",
      "Iteration 30463, loss = 199.84814991\n",
      "Iteration 30464, loss = 199.82678004\n",
      "Iteration 30465, loss = 199.80542093\n",
      "Iteration 30466, loss = 199.78406878\n",
      "Iteration 30467, loss = 199.76271609\n",
      "Iteration 30468, loss = 199.74136256\n",
      "Iteration 30469, loss = 199.72001426\n",
      "Iteration 30470, loss = 199.69867424\n",
      "Iteration 30471, loss = 199.67733896\n",
      "Iteration 30472, loss = 199.65600418\n",
      "Iteration 30473, loss = 199.63467083\n",
      "Iteration 30474, loss = 199.61334277\n",
      "Iteration 30475, loss = 199.59202108\n",
      "Iteration 30476, loss = 199.57070317\n",
      "Iteration 30477, loss = 199.54938693\n",
      "Iteration 30478, loss = 199.52807342\n",
      "Iteration 30479, loss = 199.50676482\n",
      "Iteration 30480, loss = 199.48546130\n",
      "Iteration 30481, loss = 199.46416124\n",
      "Iteration 30482, loss = 199.44286371\n",
      "Iteration 30483, loss = 199.42156958\n",
      "Iteration 30484, loss = 199.40027995\n",
      "Iteration 30485, loss = 199.37899470\n",
      "Iteration 30486, loss = 199.35771284\n",
      "Iteration 30487, loss = 199.33643403\n",
      "Iteration 30488, loss = 199.31515886\n",
      "Iteration 30489, loss = 199.29388794\n",
      "Iteration 30490, loss = 199.27262104\n",
      "Iteration 30491, loss = 199.25135758\n",
      "Iteration 30492, loss = 199.23009743\n",
      "Iteration 30493, loss = 199.20884100\n",
      "Iteration 30494, loss = 199.18758860\n",
      "Iteration 30495, loss = 199.16634008\n",
      "Iteration 30496, loss = 199.14509509\n",
      "Iteration 30497, loss = 199.12385355\n",
      "Iteration 30498, loss = 199.10261571\n",
      "Iteration 30499, loss = 199.08138176\n",
      "Iteration 30500, loss = 199.06015162\n",
      "Iteration 30501, loss = 199.03892507\n",
      "Iteration 30502, loss = 199.01770207\n",
      "Iteration 30503, loss = 198.99648274\n",
      "Iteration 30504, loss = 198.97526720\n",
      "Iteration 30505, loss = 198.95405542\n",
      "Iteration 30506, loss = 198.93284728\n",
      "Iteration 30507, loss = 198.91164273\n",
      "Iteration 30508, loss = 198.89044184\n",
      "Iteration 30509, loss = 198.86924469\n",
      "Iteration 30510, loss = 198.84805125\n",
      "Iteration 30511, loss = 198.82686146\n",
      "Iteration 30512, loss = 198.80567530\n",
      "Iteration 30513, loss = 198.78449279\n",
      "Iteration 30514, loss = 198.76331398\n",
      "Iteration 30515, loss = 198.74213885\n",
      "Iteration 30516, loss = 198.72096739\n",
      "Iteration 30517, loss = 198.69979955\n",
      "Iteration 30518, loss = 198.67863536\n",
      "Iteration 30519, loss = 198.65747484\n",
      "Iteration 30520, loss = 198.63631800\n",
      "Iteration 30521, loss = 198.61516481\n",
      "Iteration 30522, loss = 198.59401525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30523, loss = 198.57286933\n",
      "Iteration 30524, loss = 198.55172706\n",
      "Iteration 30525, loss = 198.53058845\n",
      "Iteration 30526, loss = 198.50945349\n",
      "Iteration 30527, loss = 198.48832216\n",
      "Iteration 30528, loss = 198.46719447\n",
      "Iteration 30529, loss = 198.44607040\n",
      "Iteration 30530, loss = 198.42494998\n",
      "Iteration 30531, loss = 198.40383320\n",
      "Iteration 30532, loss = 198.38272005\n",
      "Iteration 30533, loss = 198.36161053\n",
      "Iteration 30534, loss = 198.34050463\n",
      "Iteration 30535, loss = 198.31940236\n",
      "Iteration 30536, loss = 198.29830371\n",
      "Iteration 30537, loss = 198.27720869\n",
      "Iteration 30538, loss = 198.25611729\n",
      "Iteration 30539, loss = 198.23502951\n",
      "Iteration 30540, loss = 198.21394534\n",
      "Iteration 30541, loss = 198.19286479\n",
      "Iteration 30542, loss = 198.17178785\n",
      "Iteration 30543, loss = 198.15071452\n",
      "Iteration 30544, loss = 198.12964481\n",
      "Iteration 30545, loss = 198.10857869\n",
      "Iteration 30546, loss = 198.08751619\n",
      "Iteration 30547, loss = 198.06645728\n",
      "Iteration 30548, loss = 198.04540199\n",
      "Iteration 30549, loss = 198.02435028\n",
      "Iteration 30550, loss = 198.00330218\n",
      "Iteration 30551, loss = 197.98225767\n",
      "Iteration 30552, loss = 197.96121676\n",
      "Iteration 30553, loss = 197.94017944\n",
      "Iteration 30554, loss = 197.91914571\n",
      "Iteration 30555, loss = 197.89811557\n",
      "Iteration 30556, loss = 197.87708901\n",
      "Iteration 30557, loss = 197.85606604\n",
      "Iteration 30558, loss = 197.83504665\n",
      "Iteration 30559, loss = 197.81403084\n",
      "Iteration 30560, loss = 197.79301861\n",
      "Iteration 30561, loss = 197.77200996\n",
      "Iteration 30562, loss = 197.75100488\n",
      "Iteration 30563, loss = 197.73000338\n",
      "Iteration 30564, loss = 197.70900544\n",
      "Iteration 30565, loss = 197.68801108\n",
      "Iteration 30566, loss = 197.66702028\n",
      "Iteration 30567, loss = 197.64603304\n",
      "Iteration 30568, loss = 197.62504937\n",
      "Iteration 30569, loss = 197.60406926\n",
      "Iteration 30570, loss = 197.58309271\n",
      "Iteration 30571, loss = 197.56211972\n",
      "Iteration 30572, loss = 197.54115028\n",
      "Iteration 30573, loss = 197.52018439\n",
      "Iteration 30574, loss = 197.49922206\n",
      "Iteration 30575, loss = 197.47826327\n",
      "Iteration 30576, loss = 197.45730804\n",
      "Iteration 30577, loss = 197.43635634\n",
      "Iteration 30578, loss = 197.41540819\n",
      "Iteration 30579, loss = 197.39446358\n",
      "Iteration 30580, loss = 197.37352251\n",
      "Iteration 30581, loss = 197.35258498\n",
      "Iteration 30582, loss = 197.33165098\n",
      "Iteration 30583, loss = 197.31072052\n",
      "Iteration 30584, loss = 197.28979359\n",
      "Iteration 30585, loss = 197.26887018\n",
      "Iteration 30586, loss = 197.24795031\n",
      "Iteration 30587, loss = 197.22703395\n",
      "Iteration 30588, loss = 197.20612113\n",
      "Iteration 30589, loss = 197.18521182\n",
      "Iteration 30590, loss = 197.16430603\n",
      "Iteration 30591, loss = 197.14340375\n",
      "Iteration 30592, loss = 197.12250500\n",
      "Iteration 30593, loss = 197.10160975\n",
      "Iteration 30594, loss = 197.08071801\n",
      "Iteration 30595, loss = 197.05982979\n",
      "Iteration 30596, loss = 197.03894507\n",
      "Iteration 30597, loss = 197.01806385\n",
      "Iteration 30598, loss = 196.99718614\n",
      "Iteration 30599, loss = 196.97631192\n",
      "Iteration 30600, loss = 196.95544121\n",
      "Iteration 30601, loss = 196.93457399\n",
      "Iteration 30602, loss = 196.91371026\n",
      "Iteration 30603, loss = 196.89285003\n",
      "Iteration 30604, loss = 196.87199328\n",
      "Iteration 30605, loss = 196.85114002\n",
      "Iteration 30606, loss = 196.83029025\n",
      "Iteration 30607, loss = 196.80944396\n",
      "Iteration 30608, loss = 196.78860115\n",
      "Iteration 30609, loss = 196.76776182\n",
      "Iteration 30610, loss = 196.74692596\n",
      "Iteration 30611, loss = 196.72609358\n",
      "Iteration 30612, loss = 196.70526467\n",
      "Iteration 30613, loss = 196.68443924\n",
      "Iteration 30614, loss = 196.66361727\n",
      "Iteration 30615, loss = 196.64279876\n",
      "Iteration 30616, loss = 196.62198372\n",
      "Iteration 30617, loss = 196.60117214\n",
      "Iteration 30618, loss = 196.58036402\n",
      "Iteration 30619, loss = 196.55955935\n",
      "Iteration 30620, loss = 196.53875814\n",
      "Iteration 30621, loss = 196.51796038\n",
      "Iteration 30622, loss = 196.49716607\n",
      "Iteration 30623, loss = 196.47637521\n",
      "Iteration 30624, loss = 196.45558780\n",
      "Iteration 30625, loss = 196.43480382\n",
      "Iteration 30626, loss = 196.41402329\n",
      "Iteration 30627, loss = 196.39324620\n",
      "Iteration 30628, loss = 196.37247254\n",
      "Iteration 30629, loss = 196.35170232\n",
      "Iteration 30630, loss = 196.33093552\n",
      "Iteration 30631, loss = 196.31017216\n",
      "Iteration 30632, loss = 196.28941222\n",
      "Iteration 30633, loss = 196.26865571\n",
      "Iteration 30634, loss = 196.24790262\n",
      "Iteration 30635, loss = 196.22715295\n",
      "Iteration 30636, loss = 196.20640669\n",
      "Iteration 30637, loss = 196.18566385\n",
      "Iteration 30638, loss = 196.16492443\n",
      "Iteration 30639, loss = 196.14418841\n",
      "Iteration 30640, loss = 196.12345580\n",
      "Iteration 30641, loss = 196.10272660\n",
      "Iteration 30642, loss = 196.08200080\n",
      "Iteration 30643, loss = 196.06127840\n",
      "Iteration 30644, loss = 196.04055939\n",
      "Iteration 30645, loss = 196.01984378\n",
      "Iteration 30646, loss = 195.99913157\n",
      "Iteration 30647, loss = 195.97842274\n",
      "Iteration 30648, loss = 195.95771730\n",
      "Iteration 30649, loss = 195.93701525\n",
      "Iteration 30650, loss = 195.91631658\n",
      "Iteration 30651, loss = 195.89562129\n",
      "Iteration 30652, loss = 195.87492938\n",
      "Iteration 30653, loss = 195.85424084\n",
      "Iteration 30654, loss = 195.83355567\n",
      "Iteration 30655, loss = 195.81287388\n",
      "Iteration 30656, loss = 195.79219545\n",
      "Iteration 30657, loss = 195.77152038\n",
      "Iteration 30658, loss = 195.75084868\n",
      "Iteration 30659, loss = 195.73018033\n",
      "Iteration 30660, loss = 195.70951534\n",
      "Iteration 30661, loss = 195.68885370\n",
      "Iteration 30662, loss = 195.66819542\n",
      "Iteration 30663, loss = 195.64754048\n",
      "Iteration 30664, loss = 195.62688889\n",
      "Iteration 30665, loss = 195.60624064\n",
      "Iteration 30666, loss = 195.58559573\n",
      "Iteration 30667, loss = 195.56495416\n",
      "Iteration 30668, loss = 195.54431592\n",
      "Iteration 30669, loss = 195.52368101\n",
      "Iteration 30670, loss = 195.50304943\n",
      "Iteration 30671, loss = 195.48242117\n",
      "Iteration 30672, loss = 195.46179624\n",
      "Iteration 30673, loss = 195.44117462\n",
      "Iteration 30674, loss = 195.42055632\n",
      "Iteration 30675, loss = 195.39994134\n",
      "Iteration 30676, loss = 195.37932966\n",
      "Iteration 30677, loss = 195.35872129\n",
      "Iteration 30678, loss = 195.33811623\n",
      "Iteration 30679, loss = 195.31751447\n",
      "Iteration 30680, loss = 195.29691600\n",
      "Iteration 30681, loss = 195.27632083\n",
      "Iteration 30682, loss = 195.25572896\n",
      "Iteration 30683, loss = 195.23514037\n",
      "Iteration 30684, loss = 195.21455506\n",
      "Iteration 30685, loss = 195.19397304\n",
      "Iteration 30686, loss = 195.17339430\n",
      "Iteration 30687, loss = 195.15281883\n",
      "Iteration 30688, loss = 195.13224663\n",
      "Iteration 30689, loss = 195.11167770\n",
      "Iteration 30690, loss = 195.09111204\n",
      "Iteration 30691, loss = 195.07054964\n",
      "Iteration 30692, loss = 195.04999049\n",
      "Iteration 30693, loss = 195.02943461\n",
      "Iteration 30694, loss = 195.00888197\n",
      "Iteration 30695, loss = 194.98833258\n",
      "Iteration 30696, loss = 194.96778644\n",
      "Iteration 30697, loss = 194.94724353\n",
      "Iteration 30698, loss = 194.92670386\n",
      "Iteration 30699, loss = 194.90616743\n",
      "Iteration 30700, loss = 194.88563422\n",
      "Iteration 30701, loss = 194.86510425\n",
      "Iteration 30702, loss = 194.84457749\n",
      "Iteration 30703, loss = 194.82405395\n",
      "Iteration 30704, loss = 194.80353362\n",
      "Iteration 30705, loss = 194.78301650\n",
      "Iteration 30706, loss = 194.76250259\n",
      "Iteration 30707, loss = 194.74199188\n",
      "Iteration 30708, loss = 194.72148437\n",
      "Iteration 30709, loss = 194.70098005\n",
      "Iteration 30710, loss = 194.68047893\n",
      "Iteration 30711, loss = 194.65998098\n",
      "Iteration 30712, loss = 194.63948622\n",
      "Iteration 30713, loss = 194.61899463\n",
      "Iteration 30714, loss = 194.59850622\n",
      "Iteration 30715, loss = 194.57802097\n",
      "Iteration 30716, loss = 194.55753888\n",
      "Iteration 30717, loss = 194.53705996\n",
      "Iteration 30718, loss = 194.51658418\n",
      "Iteration 30719, loss = 194.49611156\n",
      "Iteration 30720, loss = 194.47564208\n",
      "Iteration 30721, loss = 194.45517574\n",
      "Iteration 30722, loss = 194.43471253\n",
      "Iteration 30723, loss = 194.41425245\n",
      "Iteration 30724, loss = 194.39379549\n",
      "Iteration 30725, loss = 194.37334166\n",
      "Iteration 30726, loss = 194.35289093\n",
      "Iteration 30727, loss = 194.33244331\n",
      "Iteration 30728, loss = 194.31199880\n",
      "Iteration 30729, loss = 194.29155738\n",
      "Iteration 30730, loss = 194.27111906\n",
      "Iteration 30731, loss = 194.25068382\n",
      "Iteration 30732, loss = 194.23025166\n",
      "Iteration 30733, loss = 194.20982257\n",
      "Iteration 30734, loss = 194.18939655\n",
      "Iteration 30735, loss = 194.16897359\n",
      "Iteration 30736, loss = 194.14855369\n",
      "Iteration 30737, loss = 194.12813683\n",
      "Iteration 30738, loss = 194.10772302\n",
      "Iteration 30739, loss = 194.08731224\n",
      "Iteration 30740, loss = 194.06690449\n",
      "Iteration 30741, loss = 194.04649977\n",
      "Iteration 30742, loss = 194.02609806\n",
      "Iteration 30743, loss = 194.00569935\n",
      "Iteration 30744, loss = 193.98530365\n",
      "Iteration 30745, loss = 193.96491094\n",
      "Iteration 30746, loss = 193.94452121\n",
      "Iteration 30747, loss = 193.92413446\n",
      "Iteration 30748, loss = 193.90375068\n",
      "Iteration 30749, loss = 193.88336986\n",
      "Iteration 30750, loss = 193.86299200\n",
      "Iteration 30751, loss = 193.84261707\n",
      "Iteration 30752, loss = 193.82224509\n",
      "Iteration 30753, loss = 193.80187603\n",
      "Iteration 30754, loss = 193.78150988\n",
      "Iteration 30755, loss = 193.76114665\n",
      "Iteration 30756, loss = 193.74078631\n",
      "Iteration 30757, loss = 193.72042886\n",
      "Iteration 30758, loss = 193.70007429\n",
      "Iteration 30759, loss = 193.67972259\n",
      "Iteration 30760, loss = 193.65937374\n",
      "Iteration 30761, loss = 193.63902774\n",
      "Iteration 30762, loss = 193.61868457\n",
      "Iteration 30763, loss = 193.59834423\n",
      "Iteration 30764, loss = 193.57800670\n",
      "Iteration 30765, loss = 193.55767196\n",
      "Iteration 30766, loss = 193.53734002\n",
      "Iteration 30767, loss = 193.51701084\n",
      "Iteration 30768, loss = 193.49668443\n",
      "Iteration 30769, loss = 193.47636076\n",
      "Iteration 30770, loss = 193.45603982\n",
      "Iteration 30771, loss = 193.43572160\n",
      "Iteration 30772, loss = 193.41540609\n",
      "Iteration 30773, loss = 193.39509326\n",
      "Iteration 30774, loss = 193.37478311\n",
      "Iteration 30775, loss = 193.35447563\n",
      "Iteration 30776, loss = 193.33417080\n",
      "Iteration 30777, loss = 193.31386863\n",
      "Iteration 30778, loss = 193.29356914\n",
      "Iteration 30779, loss = 193.27327236\n",
      "Iteration 30780, loss = 193.25297839\n",
      "Iteration 30781, loss = 193.23268742\n",
      "Iteration 30782, loss = 193.21239981\n",
      "Iteration 30783, loss = 193.19211624\n",
      "Iteration 30784, loss = 193.17183793\n",
      "Iteration 30785, loss = 193.15156691\n",
      "Iteration 30786, loss = 193.13130617\n",
      "Iteration 30787, loss = 193.11105889\n",
      "Iteration 30788, loss = 193.09082453\n",
      "Iteration 30789, loss = 193.07059128\n",
      "Iteration 30790, loss = 193.05033075\n",
      "Iteration 30791, loss = 193.03002066\n",
      "Iteration 30792, loss = 193.00968429\n",
      "Iteration 30793, loss = 192.98938140\n",
      "Iteration 30794, loss = 192.96913696\n",
      "Iteration 30795, loss = 192.94891564\n",
      "Iteration 30796, loss = 192.92866555\n",
      "Iteration 30797, loss = 192.90837823\n",
      "Iteration 30798, loss = 192.88809710\n",
      "Iteration 30799, loss = 192.86785424\n",
      "Iteration 30800, loss = 192.84762834\n",
      "Iteration 30801, loss = 192.82738176\n",
      "Iteration 30802, loss = 192.80711481\n",
      "Iteration 30803, loss = 192.78686014\n",
      "Iteration 30804, loss = 192.76663046\n",
      "Iteration 30805, loss = 192.74640277\n",
      "Iteration 30806, loss = 192.72615744\n",
      "Iteration 30807, loss = 192.70590677\n",
      "Iteration 30808, loss = 192.68567191\n",
      "Iteration 30809, loss = 192.66544940\n",
      "Iteration 30810, loss = 192.64522003\n",
      "Iteration 30811, loss = 192.62498010\n",
      "Iteration 30812, loss = 192.60474470\n",
      "Iteration 30813, loss = 192.58452142\n",
      "Iteration 30814, loss = 192.56429994\n",
      "Iteration 30815, loss = 192.54407067\n",
      "Iteration 30816, loss = 192.52383890\n",
      "Iteration 30817, loss = 192.50361396\n",
      "Iteration 30818, loss = 192.48339413\n",
      "Iteration 30819, loss = 192.46317112\n",
      "Iteration 30820, loss = 192.44294374\n",
      "Iteration 30821, loss = 192.42271794\n",
      "Iteration 30822, loss = 192.40249621\n",
      "Iteration 30823, loss = 192.38227418\n",
      "Iteration 30824, loss = 192.36204835\n",
      "Iteration 30825, loss = 192.34182106\n",
      "Iteration 30826, loss = 192.32159519\n",
      "Iteration 30827, loss = 192.30136929\n",
      "Iteration 30828, loss = 192.28114035\n",
      "Iteration 30829, loss = 192.26090827\n",
      "Iteration 30830, loss = 192.24067502\n",
      "Iteration 30831, loss = 192.22044048\n",
      "Iteration 30832, loss = 192.20020244\n",
      "Iteration 30833, loss = 192.17995995\n",
      "Iteration 30834, loss = 192.15971371\n",
      "Iteration 30835, loss = 192.13946395\n",
      "Iteration 30836, loss = 192.11920918\n",
      "Iteration 30837, loss = 192.09894778\n",
      "Iteration 30838, loss = 192.07867966\n",
      "Iteration 30839, loss = 192.05840474\n",
      "Iteration 30840, loss = 192.03812171\n",
      "Iteration 30841, loss = 192.01782876\n",
      "Iteration 30842, loss = 191.99752464\n",
      "Iteration 30843, loss = 191.97720867\n",
      "Iteration 30844, loss = 191.95687930\n",
      "Iteration 30845, loss = 191.93653406\n",
      "Iteration 30846, loss = 191.91617074\n",
      "Iteration 30847, loss = 191.89578718\n",
      "Iteration 30848, loss = 191.87538073\n",
      "Iteration 30849, loss = 191.85494783\n",
      "Iteration 30850, loss = 191.83448419\n",
      "Iteration 30851, loss = 191.81398544\n",
      "Iteration 30852, loss = 191.79344622\n",
      "Iteration 30853, loss = 191.77285979\n",
      "Iteration 30854, loss = 191.75221818\n",
      "Iteration 30855, loss = 191.73151190\n",
      "Iteration 30856, loss = 191.71072962\n",
      "Iteration 30857, loss = 191.68985731\n",
      "Iteration 30858, loss = 191.66887775\n",
      "Iteration 30859, loss = 191.64777023\n",
      "Iteration 30860, loss = 191.62650936\n",
      "Iteration 30861, loss = 191.60506387\n",
      "Iteration 30862, loss = 191.58339583\n",
      "Iteration 30863, loss = 191.56145970\n",
      "Iteration 30864, loss = 191.53920101\n",
      "Iteration 30865, loss = 191.51655598\n",
      "Iteration 30866, loss = 191.49345241\n",
      "Iteration 30867, loss = 191.46981023\n",
      "Iteration 30868, loss = 191.44554532\n",
      "Iteration 30869, loss = 191.42057426\n",
      "Iteration 30870, loss = 191.39481874\n",
      "Iteration 30871, loss = 191.36821352\n",
      "Iteration 30872, loss = 191.34071228\n",
      "Iteration 30873, loss = 191.31229193\n",
      "Iteration 30874, loss = 191.28295930\n",
      "Iteration 30875, loss = 191.25275397\n",
      "Iteration 30876, loss = 191.22175039\n",
      "Iteration 30877, loss = 191.19006098\n",
      "Iteration 30878, loss = 191.15783602\n",
      "Iteration 30879, loss = 191.12526257\n",
      "Iteration 30880, loss = 191.09256182\n",
      "Iteration 30881, loss = 191.05998382\n",
      "Iteration 30882, loss = 191.02779924\n",
      "Iteration 30883, loss = 190.99628732\n",
      "Iteration 30884, loss = 190.96572056\n",
      "Iteration 30885, loss = 190.93634506\n",
      "Iteration 30886, loss = 190.90835750\n",
      "Iteration 30887, loss = 190.88188179\n",
      "Iteration 30888, loss = 190.85694776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30889, loss = 190.83347939\n",
      "Iteration 30890, loss = 190.81129809\n",
      "Iteration 30891, loss = 190.79014252\n",
      "Iteration 30892, loss = 190.76970193\n",
      "Iteration 30893, loss = 190.74965186\n",
      "Iteration 30894, loss = 190.72968399\n",
      "Iteration 30895, loss = 190.70953098\n",
      "Iteration 30896, loss = 190.68899072\n",
      "Iteration 30897, loss = 190.66794585\n",
      "Iteration 30898, loss = 190.64636678\n",
      "Iteration 30899, loss = 190.62429569\n",
      "Iteration 30900, loss = 190.60182102\n",
      "Iteration 30901, loss = 190.57905325\n",
      "Iteration 30902, loss = 190.55610702\n",
      "Iteration 30903, loss = 190.53308971\n",
      "Iteration 30904, loss = 190.51009489\n",
      "Iteration 30905, loss = 190.48719850\n",
      "Iteration 30906, loss = 190.46445654\n",
      "Iteration 30907, loss = 190.44190376\n",
      "Iteration 30908, loss = 190.41955382\n",
      "Iteration 30909, loss = 190.39740129\n",
      "Iteration 30910, loss = 190.37542553\n",
      "Iteration 30911, loss = 190.35359579\n",
      "Iteration 30912, loss = 190.33187651\n",
      "Iteration 30913, loss = 190.31023172\n",
      "Iteration 30914, loss = 190.28862830\n",
      "Iteration 30915, loss = 190.26703787\n",
      "Iteration 30916, loss = 190.24543775\n",
      "Iteration 30917, loss = 190.22381140\n",
      "Iteration 30918, loss = 190.20214842\n",
      "Iteration 30919, loss = 190.18044429\n",
      "Iteration 30920, loss = 190.15869978\n",
      "Iteration 30921, loss = 190.13691987\n",
      "Iteration 30922, loss = 190.11511256\n",
      "Iteration 30923, loss = 190.09328747\n",
      "Iteration 30924, loss = 190.07145467\n",
      "Iteration 30925, loss = 190.04962369\n",
      "Iteration 30926, loss = 190.02780290\n",
      "Iteration 30927, loss = 190.00599910\n",
      "Iteration 30928, loss = 189.98421731\n",
      "Iteration 30929, loss = 189.96246066\n",
      "Iteration 30930, loss = 189.94073040\n",
      "Iteration 30931, loss = 189.91902605\n",
      "Iteration 30932, loss = 189.89734564\n",
      "Iteration 30933, loss = 189.87568617\n",
      "Iteration 30934, loss = 189.85404402\n",
      "Iteration 30935, loss = 189.83241545\n",
      "Iteration 30936, loss = 189.81079693\n",
      "Iteration 30937, loss = 189.78918545\n",
      "Iteration 30938, loss = 189.76757857\n",
      "Iteration 30939, loss = 189.74597455\n",
      "Iteration 30940, loss = 189.72437236\n",
      "Iteration 30941, loss = 189.70277160\n",
      "Iteration 30942, loss = 189.68117248\n",
      "Iteration 30943, loss = 189.65957569\n",
      "Iteration 30944, loss = 189.63798225\n",
      "Iteration 30945, loss = 189.61639335\n",
      "Iteration 30946, loss = 189.59481018\n",
      "Iteration 30947, loss = 189.57323381\n",
      "Iteration 30948, loss = 189.55166512\n",
      "Iteration 30949, loss = 189.53010476\n",
      "Iteration 30950, loss = 189.50855312\n",
      "Iteration 30951, loss = 189.48701039\n",
      "Iteration 30952, loss = 189.46547656\n",
      "Iteration 30953, loss = 189.44395141\n",
      "Iteration 30954, loss = 189.42243463\n",
      "Iteration 30955, loss = 189.40092579\n",
      "Iteration 30956, loss = 189.37942445\n",
      "Iteration 30957, loss = 189.35793019\n",
      "Iteration 30958, loss = 189.33644263\n",
      "Iteration 30959, loss = 189.31496147\n",
      "Iteration 30960, loss = 189.29348652\n",
      "Iteration 30961, loss = 189.27201765\n",
      "Iteration 30962, loss = 189.25055479\n",
      "Iteration 30963, loss = 189.22909798\n",
      "Iteration 30964, loss = 189.20764727\n",
      "Iteration 30965, loss = 189.18620276\n",
      "Iteration 30966, loss = 189.16476458\n",
      "Iteration 30967, loss = 189.14333286\n",
      "Iteration 30968, loss = 189.12190771\n",
      "Iteration 30969, loss = 189.10048922\n",
      "Iteration 30970, loss = 189.07907747\n",
      "Iteration 30971, loss = 189.05767248\n",
      "Iteration 30972, loss = 189.03627427\n",
      "Iteration 30973, loss = 189.01488281\n",
      "Iteration 30974, loss = 188.99349809\n",
      "Iteration 30975, loss = 188.97212003\n",
      "Iteration 30976, loss = 188.95074860\n",
      "Iteration 30977, loss = 188.92938372\n",
      "Iteration 30978, loss = 188.90802534\n",
      "Iteration 30979, loss = 188.88667340\n",
      "Iteration 30980, loss = 188.86532787\n",
      "Iteration 30981, loss = 188.84398870\n",
      "Iteration 30982, loss = 188.82265589\n",
      "Iteration 30983, loss = 188.80132940\n",
      "Iteration 30984, loss = 188.78000925\n",
      "Iteration 30985, loss = 188.75869542\n",
      "Iteration 30986, loss = 188.73738793\n",
      "Iteration 30987, loss = 188.71608678\n",
      "Iteration 30988, loss = 188.69479198\n",
      "Iteration 30989, loss = 188.67350353\n",
      "Iteration 30990, loss = 188.65222143\n",
      "Iteration 30991, loss = 188.63094568\n",
      "Iteration 30992, loss = 188.60967628\n",
      "Iteration 30993, loss = 188.58841321\n",
      "Iteration 30994, loss = 188.56715647\n",
      "Iteration 30995, loss = 188.54590603\n",
      "Iteration 30996, loss = 188.52466190\n",
      "Iteration 30997, loss = 188.50342404\n",
      "Iteration 30998, loss = 188.48219244\n",
      "Iteration 30999, loss = 188.46096710\n",
      "Iteration 31000, loss = 188.43974799\n",
      "Iteration 31001, loss = 188.41853510\n",
      "Iteration 31002, loss = 188.39732843\n",
      "Iteration 31003, loss = 188.37612795\n",
      "Iteration 31004, loss = 188.35493367\n",
      "Iteration 31005, loss = 188.33374557\n",
      "Iteration 31006, loss = 188.31256364\n",
      "Iteration 31007, loss = 188.29138789\n",
      "Iteration 31008, loss = 188.27021829\n",
      "Iteration 31009, loss = 188.24905485\n",
      "Iteration 31010, loss = 188.22789755\n",
      "Iteration 31011, loss = 188.20674639\n",
      "Iteration 31012, loss = 188.18560136\n",
      "Iteration 31013, loss = 188.16446246\n",
      "Iteration 31014, loss = 188.14332966\n",
      "Iteration 31015, loss = 188.12220296\n",
      "Iteration 31016, loss = 188.10108236\n",
      "Iteration 31017, loss = 188.07996783\n",
      "Iteration 31018, loss = 188.05885938\n",
      "Iteration 31019, loss = 188.03775700\n",
      "Iteration 31020, loss = 188.01666066\n",
      "Iteration 31021, loss = 187.99557037\n",
      "Iteration 31022, loss = 187.97448612\n",
      "Iteration 31023, loss = 187.95340789\n",
      "Iteration 31024, loss = 187.93233567\n",
      "Iteration 31025, loss = 187.91126947\n",
      "Iteration 31026, loss = 187.89020926\n",
      "Iteration 31027, loss = 187.86915505\n",
      "Iteration 31028, loss = 187.84810682\n",
      "Iteration 31029, loss = 187.82706456\n",
      "Iteration 31030, loss = 187.80602828\n",
      "Iteration 31031, loss = 187.78499795\n",
      "Iteration 31032, loss = 187.76397356\n",
      "Iteration 31033, loss = 187.74295513\n",
      "Iteration 31034, loss = 187.72194262\n",
      "Iteration 31035, loss = 187.70093604\n",
      "Iteration 31036, loss = 187.67993537\n",
      "Iteration 31037, loss = 187.65894061\n",
      "Iteration 31038, loss = 187.63795175\n",
      "Iteration 31039, loss = 187.61696879\n",
      "Iteration 31040, loss = 187.59599170\n",
      "Iteration 31041, loss = 187.57502049\n",
      "Iteration 31042, loss = 187.55405514\n",
      "Iteration 31043, loss = 187.53309566\n",
      "Iteration 31044, loss = 187.51214202\n",
      "Iteration 31045, loss = 187.49119422\n",
      "Iteration 31046, loss = 187.47025226\n",
      "Iteration 31047, loss = 187.44931613\n",
      "Iteration 31048, loss = 187.42838581\n",
      "Iteration 31049, loss = 187.40746130\n",
      "Iteration 31050, loss = 187.38654259\n",
      "Iteration 31051, loss = 187.36562968\n",
      "Iteration 31052, loss = 187.34472256\n",
      "Iteration 31053, loss = 187.32382121\n",
      "Iteration 31054, loss = 187.30292563\n",
      "Iteration 31055, loss = 187.28203582\n",
      "Iteration 31056, loss = 187.26115176\n",
      "Iteration 31057, loss = 187.24027345\n",
      "Iteration 31058, loss = 187.21940088\n",
      "Iteration 31059, loss = 187.19853404\n",
      "Iteration 31060, loss = 187.17767292\n",
      "Iteration 31061, loss = 187.15681752\n",
      "Iteration 31062, loss = 187.13596783\n",
      "Iteration 31063, loss = 187.11512384\n",
      "Iteration 31064, loss = 187.09428555\n",
      "Iteration 31065, loss = 187.07345294\n",
      "Iteration 31066, loss = 187.05262601\n",
      "Iteration 31067, loss = 187.03180475\n",
      "Iteration 31068, loss = 187.01098915\n",
      "Iteration 31069, loss = 186.99017922\n",
      "Iteration 31070, loss = 186.96937493\n",
      "Iteration 31071, loss = 186.94857628\n",
      "Iteration 31072, loss = 186.92778327\n",
      "Iteration 31073, loss = 186.90699588\n",
      "Iteration 31074, loss = 186.88621412\n",
      "Iteration 31075, loss = 186.86543796\n",
      "Iteration 31076, loss = 186.84466742\n",
      "Iteration 31077, loss = 186.82390247\n",
      "Iteration 31078, loss = 186.80314311\n",
      "Iteration 31079, loss = 186.78238933\n",
      "Iteration 31080, loss = 186.76164114\n",
      "Iteration 31081, loss = 186.74089851\n",
      "Iteration 31082, loss = 186.72016144\n",
      "Iteration 31083, loss = 186.69942993\n",
      "Iteration 31084, loss = 186.67870397\n",
      "Iteration 31085, loss = 186.65798355\n",
      "Iteration 31086, loss = 186.63726866\n",
      "Iteration 31087, loss = 186.61655930\n",
      "Iteration 31088, loss = 186.59585546\n",
      "Iteration 31089, loss = 186.57515714\n",
      "Iteration 31090, loss = 186.55446432\n",
      "Iteration 31091, loss = 186.53377700\n",
      "Iteration 31092, loss = 186.51309517\n",
      "Iteration 31093, loss = 186.49241883\n",
      "Iteration 31094, loss = 186.47174797\n",
      "Iteration 31095, loss = 186.45108258\n",
      "Iteration 31096, loss = 186.43042266\n",
      "Iteration 31097, loss = 186.40976820\n",
      "Iteration 31098, loss = 186.38911918\n",
      "Iteration 31099, loss = 186.36847562\n",
      "Iteration 31100, loss = 186.34783749\n",
      "Iteration 31101, loss = 186.32720479\n",
      "Iteration 31102, loss = 186.30657752\n",
      "Iteration 31103, loss = 186.28595567\n",
      "Iteration 31104, loss = 186.26533923\n",
      "Iteration 31105, loss = 186.24472820\n",
      "Iteration 31106, loss = 186.22412257\n",
      "Iteration 31107, loss = 186.20352232\n",
      "Iteration 31108, loss = 186.18292747\n",
      "Iteration 31109, loss = 186.16233799\n",
      "Iteration 31110, loss = 186.14175389\n",
      "Iteration 31111, loss = 186.12117515\n",
      "Iteration 31112, loss = 186.10060178\n",
      "Iteration 31113, loss = 186.08003376\n",
      "Iteration 31114, loss = 186.05947108\n",
      "Iteration 31115, loss = 186.03891375\n",
      "Iteration 31116, loss = 186.01836175\n",
      "Iteration 31117, loss = 185.99781508\n",
      "Iteration 31118, loss = 185.97727373\n",
      "Iteration 31119, loss = 185.95673770\n",
      "Iteration 31120, loss = 185.93620697\n",
      "Iteration 31121, loss = 185.91568155\n",
      "Iteration 31122, loss = 185.89516143\n",
      "Iteration 31123, loss = 185.87464660\n",
      "Iteration 31124, loss = 185.85413705\n",
      "Iteration 31125, loss = 185.83363278\n",
      "Iteration 31126, loss = 185.81313378\n",
      "Iteration 31127, loss = 185.79264005\n",
      "Iteration 31128, loss = 185.77215158\n",
      "Iteration 31129, loss = 185.75166836\n",
      "Iteration 31130, loss = 185.73119039\n",
      "Iteration 31131, loss = 185.71071766\n",
      "Iteration 31132, loss = 185.69025017\n",
      "Iteration 31133, loss = 185.66978791\n",
      "Iteration 31134, loss = 185.64933087\n",
      "Iteration 31135, loss = 185.62887904\n",
      "Iteration 31136, loss = 185.60843243\n",
      "Iteration 31137, loss = 185.58799103\n",
      "Iteration 31138, loss = 185.56755482\n",
      "Iteration 31139, loss = 185.54712381\n",
      "Iteration 31140, loss = 185.52669799\n",
      "Iteration 31141, loss = 185.50627735\n",
      "Iteration 31142, loss = 185.48586188\n",
      "Iteration 31143, loss = 185.46545159\n",
      "Iteration 31144, loss = 185.44504646\n",
      "Iteration 31145, loss = 185.42464648\n",
      "Iteration 31146, loss = 185.40425166\n",
      "Iteration 31147, loss = 185.38386199\n",
      "Iteration 31148, loss = 185.36347746\n",
      "Iteration 31149, loss = 185.34309806\n",
      "Iteration 31150, loss = 185.32272380\n",
      "Iteration 31151, loss = 185.30235465\n",
      "Iteration 31152, loss = 185.28199063\n",
      "Iteration 31153, loss = 185.26163172\n",
      "Iteration 31154, loss = 185.24127791\n",
      "Iteration 31155, loss = 185.22092921\n",
      "Iteration 31156, loss = 185.20058560\n",
      "Iteration 31157, loss = 185.18024708\n",
      "Iteration 31158, loss = 185.15991364\n",
      "Iteration 31159, loss = 185.13958529\n",
      "Iteration 31160, loss = 185.11926201\n",
      "Iteration 31161, loss = 185.09894379\n",
      "Iteration 31162, loss = 185.07863064\n",
      "Iteration 31163, loss = 185.05832254\n",
      "Iteration 31164, loss = 185.03801949\n",
      "Iteration 31165, loss = 185.01772149\n",
      "Iteration 31166, loss = 184.99742853\n",
      "Iteration 31167, loss = 184.97714060\n",
      "Iteration 31168, loss = 184.95685771\n",
      "Iteration 31169, loss = 184.93657983\n",
      "Iteration 31170, loss = 184.91630698\n",
      "Iteration 31171, loss = 184.89603913\n",
      "Iteration 31172, loss = 184.87577630\n",
      "Iteration 31173, loss = 184.85551846\n",
      "Iteration 31174, loss = 184.83526562\n",
      "Iteration 31175, loss = 184.81501778\n",
      "Iteration 31176, loss = 184.79477491\n",
      "Iteration 31177, loss = 184.77453703\n",
      "Iteration 31178, loss = 184.75430413\n",
      "Iteration 31179, loss = 184.73407619\n",
      "Iteration 31180, loss = 184.71385322\n",
      "Iteration 31181, loss = 184.69363521\n",
      "Iteration 31182, loss = 184.67342215\n",
      "Iteration 31183, loss = 184.65321404\n",
      "Iteration 31184, loss = 184.63301087\n",
      "Iteration 31185, loss = 184.61281264\n",
      "Iteration 31186, loss = 184.59261935\n",
      "Iteration 31187, loss = 184.57243098\n",
      "Iteration 31188, loss = 184.55224754\n",
      "Iteration 31189, loss = 184.53206901\n",
      "Iteration 31190, loss = 184.51189539\n",
      "Iteration 31191, loss = 184.49172668\n",
      "Iteration 31192, loss = 184.47156288\n",
      "Iteration 31193, loss = 184.45140397\n",
      "Iteration 31194, loss = 184.43124995\n",
      "Iteration 31195, loss = 184.41110082\n",
      "Iteration 31196, loss = 184.39095657\n",
      "Iteration 31197, loss = 184.37081720\n",
      "Iteration 31198, loss = 184.35068270\n",
      "Iteration 31199, loss = 184.33055307\n",
      "Iteration 31200, loss = 184.31042829\n",
      "Iteration 31201, loss = 184.29030838\n",
      "Iteration 31202, loss = 184.27019331\n",
      "Iteration 31203, loss = 184.25008310\n",
      "Iteration 31204, loss = 184.22997772\n",
      "Iteration 31205, loss = 184.20987718\n",
      "Iteration 31206, loss = 184.18978147\n",
      "Iteration 31207, loss = 184.16969060\n",
      "Iteration 31208, loss = 184.14960454\n",
      "Iteration 31209, loss = 184.12952331\n",
      "Iteration 31210, loss = 184.10944690\n",
      "Iteration 31211, loss = 184.08937530\n",
      "Iteration 31212, loss = 184.06930854\n",
      "Iteration 31213, loss = 184.04924662\n",
      "Iteration 31214, loss = 184.02918957\n",
      "Iteration 31215, loss = 184.00913744\n",
      "Iteration 31216, loss = 183.98909033\n",
      "Iteration 31217, loss = 183.96904841\n",
      "Iteration 31218, loss = 183.94901188\n",
      "Iteration 31219, loss = 183.92898107\n",
      "Iteration 31220, loss = 183.90895592\n",
      "Iteration 31221, loss = 183.88893607\n",
      "Iteration 31222, loss = 183.86891921\n",
      "Iteration 31223, loss = 183.84890333\n",
      "Iteration 31224, loss = 183.82888762\n",
      "Iteration 31225, loss = 183.80887648\n",
      "Iteration 31226, loss = 183.78887459\n",
      "Iteration 31227, loss = 183.76888221\n",
      "Iteration 31228, loss = 183.74889522\n",
      "Iteration 31229, loss = 183.72890933\n",
      "Iteration 31230, loss = 183.70892468\n",
      "Iteration 31231, loss = 183.68894521\n",
      "Iteration 31232, loss = 183.66897389\n",
      "Iteration 31233, loss = 183.64900924\n",
      "Iteration 31234, loss = 183.62904772\n",
      "Iteration 31235, loss = 183.60908834\n",
      "Iteration 31236, loss = 183.58913337\n",
      "Iteration 31237, loss = 183.56918513\n",
      "Iteration 31238, loss = 183.54924296\n",
      "Iteration 31239, loss = 183.52930456\n",
      "Iteration 31240, loss = 183.50936924\n",
      "Iteration 31241, loss = 183.48943848\n",
      "Iteration 31242, loss = 183.46951367\n",
      "Iteration 31243, loss = 183.44959426\n",
      "Iteration 31244, loss = 183.42967884\n",
      "Iteration 31245, loss = 183.40976715\n",
      "Iteration 31246, loss = 183.38986019\n",
      "Iteration 31247, loss = 183.36995868\n",
      "Iteration 31248, loss = 183.35006212\n",
      "Iteration 31249, loss = 183.33016970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31250, loss = 183.31028142\n",
      "Iteration 31251, loss = 183.29039792\n",
      "Iteration 31252, loss = 183.27051953\n",
      "Iteration 31253, loss = 183.25064585\n",
      "Iteration 31254, loss = 183.23077643\n",
      "Iteration 31255, loss = 183.21091138\n",
      "Iteration 31256, loss = 183.19105109\n",
      "Iteration 31257, loss = 183.17119567\n",
      "Iteration 31258, loss = 183.15134485\n",
      "Iteration 31259, loss = 183.13149838\n",
      "Iteration 31260, loss = 183.11165639\n",
      "Iteration 31261, loss = 183.09181911\n",
      "Iteration 31262, loss = 183.07198656\n",
      "Iteration 31263, loss = 183.05215854\n",
      "Iteration 31264, loss = 183.03233494\n",
      "Iteration 31265, loss = 183.01251587\n",
      "Iteration 31266, loss = 182.99270144\n",
      "Iteration 31267, loss = 182.97289165\n",
      "Iteration 31268, loss = 182.95308636\n",
      "Iteration 31269, loss = 182.93328554\n",
      "Iteration 31270, loss = 182.91348924\n",
      "Iteration 31271, loss = 182.89369754\n",
      "Iteration 31272, loss = 182.87391040\n",
      "Iteration 31273, loss = 182.85412777\n",
      "Iteration 31274, loss = 182.83434961\n",
      "Iteration 31275, loss = 182.81457596\n",
      "Iteration 31276, loss = 182.79480687\n",
      "Iteration 31277, loss = 182.77504230\n",
      "Iteration 31278, loss = 182.75528222\n",
      "Iteration 31279, loss = 182.73552661\n",
      "Iteration 31280, loss = 182.71577550\n",
      "Iteration 31281, loss = 182.69602890\n",
      "Iteration 31282, loss = 182.67628680\n",
      "Iteration 31283, loss = 182.65654917\n",
      "Iteration 31284, loss = 182.63681601\n",
      "Iteration 31285, loss = 182.61708732\n",
      "Iteration 31286, loss = 182.59736311\n",
      "Iteration 31287, loss = 182.57764338\n",
      "Iteration 31288, loss = 182.55792811\n",
      "Iteration 31289, loss = 182.53821728\n",
      "Iteration 31290, loss = 182.51851091\n",
      "Iteration 31291, loss = 182.49880900\n",
      "Iteration 31292, loss = 182.47911153\n",
      "Iteration 31293, loss = 182.45941851\n",
      "Iteration 31294, loss = 182.43972992\n",
      "Iteration 31295, loss = 182.42004576\n",
      "Iteration 31296, loss = 182.40036603\n",
      "Iteration 31297, loss = 182.38069074\n",
      "Iteration 31298, loss = 182.36101986\n",
      "Iteration 31299, loss = 182.34135340\n",
      "Iteration 31300, loss = 182.32169135\n",
      "Iteration 31301, loss = 182.30203372\n",
      "Iteration 31302, loss = 182.28238049\n",
      "Iteration 31303, loss = 182.26273166\n",
      "Iteration 31304, loss = 182.24308723\n",
      "Iteration 31305, loss = 182.22344719\n",
      "Iteration 31306, loss = 182.20381154\n",
      "Iteration 31307, loss = 182.18418029\n",
      "Iteration 31308, loss = 182.16455341\n",
      "Iteration 31309, loss = 182.14493091\n",
      "Iteration 31310, loss = 182.12531278\n",
      "Iteration 31311, loss = 182.10569902\n",
      "Iteration 31312, loss = 182.08608963\n",
      "Iteration 31313, loss = 182.06648461\n",
      "Iteration 31314, loss = 182.04688394\n",
      "Iteration 31315, loss = 182.02728762\n",
      "Iteration 31316, loss = 182.00769566\n",
      "Iteration 31317, loss = 181.98810804\n",
      "Iteration 31318, loss = 181.96852477\n",
      "Iteration 31319, loss = 181.94894583\n",
      "Iteration 31320, loss = 181.92937123\n",
      "Iteration 31321, loss = 181.90980096\n",
      "Iteration 31322, loss = 181.89023502\n",
      "Iteration 31323, loss = 181.87067340\n",
      "Iteration 31324, loss = 181.85111610\n",
      "Iteration 31325, loss = 181.83156312\n",
      "Iteration 31326, loss = 181.81201445\n",
      "Iteration 31327, loss = 181.79247009\n",
      "Iteration 31328, loss = 181.77293003\n",
      "Iteration 31329, loss = 181.75339428\n",
      "Iteration 31330, loss = 181.73386282\n",
      "Iteration 31331, loss = 181.71433565\n",
      "Iteration 31332, loss = 181.69481278\n",
      "Iteration 31333, loss = 181.67529419\n",
      "Iteration 31334, loss = 181.65577988\n",
      "Iteration 31335, loss = 181.63626985\n",
      "Iteration 31336, loss = 181.61676409\n",
      "Iteration 31337, loss = 181.59726261\n",
      "Iteration 31338, loss = 181.57776539\n",
      "Iteration 31339, loss = 181.55827243\n",
      "Iteration 31340, loss = 181.53878374\n",
      "Iteration 31341, loss = 181.51929930\n",
      "Iteration 31342, loss = 181.49981911\n",
      "Iteration 31343, loss = 181.48034317\n",
      "Iteration 31344, loss = 181.46087148\n",
      "Iteration 31345, loss = 181.44140402\n",
      "Iteration 31346, loss = 181.42194081\n",
      "Iteration 31347, loss = 181.40248182\n",
      "Iteration 31348, loss = 181.38302707\n",
      "Iteration 31349, loss = 181.36357654\n",
      "Iteration 31350, loss = 181.34413024\n",
      "Iteration 31351, loss = 181.32468816\n",
      "Iteration 31352, loss = 181.30525029\n",
      "Iteration 31353, loss = 181.28581663\n",
      "Iteration 31354, loss = 181.26638718\n",
      "Iteration 31355, loss = 181.24696194\n",
      "Iteration 31356, loss = 181.22754090\n",
      "Iteration 31357, loss = 181.20812405\n",
      "Iteration 31358, loss = 181.18871140\n",
      "Iteration 31359, loss = 181.16930294\n",
      "Iteration 31360, loss = 181.14989866\n",
      "Iteration 31361, loss = 181.13049857\n",
      "Iteration 31362, loss = 181.11110266\n",
      "Iteration 31363, loss = 181.09171092\n",
      "Iteration 31364, loss = 181.07232335\n",
      "Iteration 31365, loss = 181.05293996\n",
      "Iteration 31366, loss = 181.03356073\n",
      "Iteration 31367, loss = 181.01418566\n",
      "Iteration 31368, loss = 180.99481475\n",
      "Iteration 31369, loss = 180.97544799\n",
      "Iteration 31370, loss = 180.95608539\n",
      "Iteration 31371, loss = 180.93672693\n",
      "Iteration 31372, loss = 180.91737262\n",
      "Iteration 31373, loss = 180.89802244\n",
      "Iteration 31374, loss = 180.87867641\n",
      "Iteration 31375, loss = 180.85933451\n",
      "Iteration 31376, loss = 180.83999674\n",
      "Iteration 31377, loss = 180.82066309\n",
      "Iteration 31378, loss = 180.80133357\n",
      "Iteration 31379, loss = 180.78200817\n",
      "Iteration 31380, loss = 180.76268688\n",
      "Iteration 31381, loss = 180.74336971\n",
      "Iteration 31382, loss = 180.72405664\n",
      "Iteration 31383, loss = 180.70474768\n",
      "Iteration 31384, loss = 180.68544283\n",
      "Iteration 31385, loss = 180.66614207\n",
      "Iteration 31386, loss = 180.64684541\n",
      "Iteration 31387, loss = 180.62755284\n",
      "Iteration 31388, loss = 180.60826436\n",
      "Iteration 31389, loss = 180.58897996\n",
      "Iteration 31390, loss = 180.56969965\n",
      "Iteration 31391, loss = 180.55042342\n",
      "Iteration 31392, loss = 180.53115126\n",
      "Iteration 31393, loss = 180.51188317\n",
      "Iteration 31394, loss = 180.49261915\n",
      "Iteration 31395, loss = 180.47335920\n",
      "Iteration 31396, loss = 180.45410330\n",
      "Iteration 31397, loss = 180.43485147\n",
      "Iteration 31398, loss = 180.41560369\n",
      "Iteration 31399, loss = 180.39635996\n",
      "Iteration 31400, loss = 180.37712028\n",
      "Iteration 31401, loss = 180.35788464\n",
      "Iteration 31402, loss = 180.33865305\n",
      "Iteration 31403, loss = 180.31942550\n",
      "Iteration 31404, loss = 180.30020197\n",
      "Iteration 31405, loss = 180.28098249\n",
      "Iteration 31406, loss = 180.26176702\n",
      "Iteration 31407, loss = 180.24255559\n",
      "Iteration 31408, loss = 180.22334817\n",
      "Iteration 31409, loss = 180.20414478\n",
      "Iteration 31410, loss = 180.18494540\n",
      "Iteration 31411, loss = 180.16575003\n",
      "Iteration 31412, loss = 180.14655867\n",
      "Iteration 31413, loss = 180.12737131\n",
      "Iteration 31414, loss = 180.10818795\n",
      "Iteration 31415, loss = 180.08900860\n",
      "Iteration 31416, loss = 180.06983324\n",
      "Iteration 31417, loss = 180.05066187\n",
      "Iteration 31418, loss = 180.03149449\n",
      "Iteration 31419, loss = 180.01233110\n",
      "Iteration 31420, loss = 179.99317169\n",
      "Iteration 31421, loss = 179.97401625\n",
      "Iteration 31422, loss = 179.95486480\n",
      "Iteration 31423, loss = 179.93571731\n",
      "Iteration 31424, loss = 179.91657380\n",
      "Iteration 31425, loss = 179.89743425\n",
      "Iteration 31426, loss = 179.87829866\n",
      "Iteration 31427, loss = 179.85916704\n",
      "Iteration 31428, loss = 179.84003937\n",
      "Iteration 31429, loss = 179.82091565\n",
      "Iteration 31430, loss = 179.80179589\n",
      "Iteration 31431, loss = 179.78268007\n",
      "Iteration 31432, loss = 179.76356819\n",
      "Iteration 31433, loss = 179.74446026\n",
      "Iteration 31434, loss = 179.72535626\n",
      "Iteration 31435, loss = 179.70625620\n",
      "Iteration 31436, loss = 179.68716007\n",
      "Iteration 31437, loss = 179.66806786\n",
      "Iteration 31438, loss = 179.64897958\n",
      "Iteration 31439, loss = 179.62989523\n",
      "Iteration 31440, loss = 179.61081479\n",
      "Iteration 31441, loss = 179.59173826\n",
      "Iteration 31442, loss = 179.57266565\n",
      "Iteration 31443, loss = 179.55359695\n",
      "Iteration 31444, loss = 179.53453215\n",
      "Iteration 31445, loss = 179.51547126\n",
      "Iteration 31446, loss = 179.49641427\n",
      "Iteration 31447, loss = 179.47736117\n",
      "Iteration 31448, loss = 179.45831196\n",
      "Iteration 31449, loss = 179.43926665\n",
      "Iteration 31450, loss = 179.42022523\n",
      "Iteration 31451, loss = 179.40118768\n",
      "Iteration 31452, loss = 179.38215402\n",
      "Iteration 31453, loss = 179.36312424\n",
      "Iteration 31454, loss = 179.34409833\n",
      "Iteration 31455, loss = 179.32507630\n",
      "Iteration 31456, loss = 179.30605813\n",
      "Iteration 31457, loss = 179.28704383\n",
      "Iteration 31458, loss = 179.26803339\n",
      "Iteration 31459, loss = 179.24902681\n",
      "Iteration 31460, loss = 179.23002409\n",
      "Iteration 31461, loss = 179.21102522\n",
      "Iteration 31462, loss = 179.19203020\n",
      "Iteration 31463, loss = 179.17303903\n",
      "Iteration 31464, loss = 179.15405170\n",
      "Iteration 31465, loss = 179.13506821\n",
      "Iteration 31466, loss = 179.11608857\n",
      "Iteration 31467, loss = 179.09711275\n",
      "Iteration 31468, loss = 179.07814077\n",
      "Iteration 31469, loss = 179.05917262\n",
      "Iteration 31470, loss = 179.04020830\n",
      "Iteration 31471, loss = 179.02124780\n",
      "Iteration 31472, loss = 179.00229112\n",
      "Iteration 31473, loss = 178.98333825\n",
      "Iteration 31474, loss = 178.96438920\n",
      "Iteration 31475, loss = 178.94544396\n",
      "Iteration 31476, loss = 178.92650253\n",
      "Iteration 31477, loss = 178.90756491\n",
      "Iteration 31478, loss = 178.88863109\n",
      "Iteration 31479, loss = 178.86970106\n",
      "Iteration 31480, loss = 178.85077484\n",
      "Iteration 31481, loss = 178.83185240\n",
      "Iteration 31482, loss = 178.81293376\n",
      "Iteration 31483, loss = 178.79401891\n",
      "Iteration 31484, loss = 178.77510783\n",
      "Iteration 31485, loss = 178.75620055\n",
      "Iteration 31486, loss = 178.73729703\n",
      "Iteration 31487, loss = 178.71839730\n",
      "Iteration 31488, loss = 178.69950134\n",
      "Iteration 31489, loss = 178.68060914\n",
      "Iteration 31490, loss = 178.66172072\n",
      "Iteration 31491, loss = 178.64283606\n",
      "Iteration 31492, loss = 178.62395516\n",
      "Iteration 31493, loss = 178.60507801\n",
      "Iteration 31494, loss = 178.58620463\n",
      "Iteration 31495, loss = 178.56733499\n",
      "Iteration 31496, loss = 178.54846911\n",
      "Iteration 31497, loss = 178.52960697\n",
      "Iteration 31498, loss = 178.51074857\n",
      "Iteration 31499, loss = 178.49189392\n",
      "Iteration 31500, loss = 178.47304300\n",
      "Iteration 31501, loss = 178.45419582\n",
      "Iteration 31502, loss = 178.43535237\n",
      "Iteration 31503, loss = 178.41651265\n",
      "Iteration 31504, loss = 178.39767666\n",
      "Iteration 31505, loss = 178.37884439\n",
      "Iteration 31506, loss = 178.36001584\n",
      "Iteration 31507, loss = 178.34119100\n",
      "Iteration 31508, loss = 178.32236989\n",
      "Iteration 31509, loss = 178.30355248\n",
      "Iteration 31510, loss = 178.28473878\n",
      "Iteration 31511, loss = 178.26592879\n",
      "Iteration 31512, loss = 178.24712251\n",
      "Iteration 31513, loss = 178.22831992\n",
      "Iteration 31514, loss = 178.20952103\n",
      "Iteration 31515, loss = 178.19072584\n",
      "Iteration 31516, loss = 178.17193434\n",
      "Iteration 31517, loss = 178.15314653\n",
      "Iteration 31518, loss = 178.13436240\n",
      "Iteration 31519, loss = 178.11558196\n",
      "Iteration 31520, loss = 178.09680520\n",
      "Iteration 31521, loss = 178.07803212\n",
      "Iteration 31522, loss = 178.05926271\n",
      "Iteration 31523, loss = 178.04049698\n",
      "Iteration 31524, loss = 178.02173491\n",
      "Iteration 31525, loss = 178.00297651\n",
      "Iteration 31526, loss = 177.98422178\n",
      "Iteration 31527, loss = 177.96547071\n",
      "Iteration 31528, loss = 177.94672329\n",
      "Iteration 31529, loss = 177.92797953\n",
      "Iteration 31530, loss = 177.90923943\n",
      "Iteration 31531, loss = 177.89050297\n",
      "Iteration 31532, loss = 177.87177016\n",
      "Iteration 31533, loss = 177.85304100\n",
      "Iteration 31534, loss = 177.83431548\n",
      "Iteration 31535, loss = 177.81559360\n",
      "Iteration 31536, loss = 177.79687535\n",
      "Iteration 31537, loss = 177.77816074\n",
      "Iteration 31538, loss = 177.75944976\n",
      "Iteration 31539, loss = 177.74074240\n",
      "Iteration 31540, loss = 177.72203868\n",
      "Iteration 31541, loss = 177.70333857\n",
      "Iteration 31542, loss = 177.68464209\n",
      "Iteration 31543, loss = 177.66594923\n",
      "Iteration 31544, loss = 177.64725999\n",
      "Iteration 31545, loss = 177.62857438\n",
      "Iteration 31546, loss = 177.60989239\n",
      "Iteration 31547, loss = 177.59121407\n",
      "Iteration 31548, loss = 177.57253944\n",
      "Iteration 31549, loss = 177.55386859\n",
      "Iteration 31550, loss = 177.53520168\n",
      "Iteration 31551, loss = 177.51653905\n",
      "Iteration 31552, loss = 177.49788129\n",
      "Iteration 31553, loss = 177.47922956\n",
      "Iteration 31554, loss = 177.46058573\n",
      "Iteration 31555, loss = 177.44195274\n",
      "Iteration 31556, loss = 177.42333233\n",
      "Iteration 31557, loss = 177.40472186\n",
      "Iteration 31558, loss = 177.38610191\n",
      "Iteration 31559, loss = 177.36744883\n",
      "Iteration 31560, loss = 177.34876314\n",
      "Iteration 31561, loss = 177.33009542\n",
      "Iteration 31562, loss = 177.31148076\n",
      "Iteration 31563, loss = 177.29289339\n",
      "Iteration 31564, loss = 177.27428324\n",
      "Iteration 31565, loss = 177.25563964\n",
      "Iteration 31566, loss = 177.23700618\n",
      "Iteration 31567, loss = 177.21841106\n",
      "Iteration 31568, loss = 177.19982727\n",
      "Iteration 31569, loss = 177.18122120\n",
      "Iteration 31570, loss = 177.16260434\n",
      "Iteration 31571, loss = 177.14400956\n",
      "Iteration 31572, loss = 177.12543458\n",
      "Iteration 31573, loss = 177.10685154\n",
      "Iteration 31574, loss = 177.08825670\n",
      "Iteration 31575, loss = 177.06967242\n",
      "Iteration 31576, loss = 177.05110558\n",
      "Iteration 31577, loss = 177.03253867\n",
      "Iteration 31578, loss = 177.01396351\n",
      "Iteration 31579, loss = 176.99539357\n",
      "Iteration 31580, loss = 176.97683702\n",
      "Iteration 31581, loss = 176.95828375\n",
      "Iteration 31582, loss = 176.93972604\n",
      "Iteration 31583, loss = 176.92117134\n",
      "Iteration 31584, loss = 176.90262666\n",
      "Iteration 31585, loss = 176.88408653\n",
      "Iteration 31586, loss = 176.86554473\n",
      "Iteration 31587, loss = 176.84700524\n",
      "Iteration 31588, loss = 176.82847338\n",
      "Iteration 31589, loss = 176.80994635\n",
      "Iteration 31590, loss = 176.79141962\n",
      "Iteration 31591, loss = 176.77289506\n",
      "Iteration 31592, loss = 176.75437652\n",
      "Iteration 31593, loss = 176.73586276\n",
      "Iteration 31594, loss = 176.71735055\n",
      "Iteration 31595, loss = 176.69884064\n",
      "Iteration 31596, loss = 176.68033569\n",
      "Iteration 31597, loss = 176.66183531\n",
      "Iteration 31598, loss = 176.64333732\n",
      "Iteration 31599, loss = 176.62484182\n",
      "Iteration 31600, loss = 176.60635060\n",
      "Iteration 31601, loss = 176.58786372\n",
      "Iteration 31602, loss = 176.56937973\n",
      "Iteration 31603, loss = 176.55089845\n",
      "Iteration 31604, loss = 176.53242102\n",
      "Iteration 31605, loss = 176.51394769\n",
      "Iteration 31606, loss = 176.49547758\n",
      "Iteration 31607, loss = 176.47701037\n",
      "Iteration 31608, loss = 176.45854674\n",
      "Iteration 31609, loss = 176.44008702\n",
      "Iteration 31610, loss = 176.42163068\n",
      "Iteration 31611, loss = 176.40317741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31612, loss = 176.38472757\n",
      "Iteration 31613, loss = 176.36628148\n",
      "Iteration 31614, loss = 176.34783886\n",
      "Iteration 31615, loss = 176.32939943\n",
      "Iteration 31616, loss = 176.31096335\n",
      "Iteration 31617, loss = 176.29253089\n",
      "Iteration 31618, loss = 176.27410193\n",
      "Iteration 31619, loss = 176.25567626\n",
      "Iteration 31620, loss = 176.23725391\n",
      "Iteration 31621, loss = 176.21883507\n",
      "Iteration 31622, loss = 176.20041974\n",
      "Iteration 31623, loss = 176.18200774\n",
      "Iteration 31624, loss = 176.16359907\n",
      "Iteration 31625, loss = 176.14519385\n",
      "Iteration 31626, loss = 176.12679210\n",
      "Iteration 31627, loss = 176.10839374\n",
      "Iteration 31628, loss = 176.08999871\n",
      "Iteration 31629, loss = 176.07160708\n",
      "Iteration 31630, loss = 176.05321890\n",
      "Iteration 31631, loss = 176.03483412\n",
      "Iteration 31632, loss = 176.01645271\n",
      "Iteration 31633, loss = 175.99807468\n",
      "Iteration 31634, loss = 175.97970010\n",
      "Iteration 31635, loss = 175.96132895\n",
      "Iteration 31636, loss = 175.94296123\n",
      "Iteration 31637, loss = 175.92459695\n",
      "Iteration 31638, loss = 175.90623618\n",
      "Iteration 31639, loss = 175.88787897\n",
      "Iteration 31640, loss = 175.86952534\n",
      "Iteration 31641, loss = 175.85117524\n",
      "Iteration 31642, loss = 175.83282867\n",
      "Iteration 31643, loss = 175.81448532\n",
      "Iteration 31644, loss = 175.79614490\n",
      "Iteration 31645, loss = 175.77780685\n",
      "Iteration 31646, loss = 175.75947117\n",
      "Iteration 31647, loss = 175.74113821\n",
      "Iteration 31648, loss = 175.72280886\n",
      "Iteration 31649, loss = 175.70448382\n",
      "Iteration 31650, loss = 175.68616321\n",
      "Iteration 31651, loss = 175.66784659\n",
      "Iteration 31652, loss = 175.64953322\n",
      "Iteration 31653, loss = 175.63122256\n",
      "Iteration 31654, loss = 175.61291446\n",
      "Iteration 31655, loss = 175.59460932\n",
      "Iteration 31656, loss = 175.57630771\n",
      "Iteration 31657, loss = 175.55800998\n",
      "Iteration 31658, loss = 175.53971608\n",
      "Iteration 31659, loss = 175.52142563\n",
      "Iteration 31660, loss = 175.50313826\n",
      "Iteration 31661, loss = 175.48485380\n",
      "Iteration 31662, loss = 175.46657240\n",
      "Iteration 31663, loss = 175.44829435\n",
      "Iteration 31664, loss = 175.43001987\n",
      "Iteration 31665, loss = 175.41174897\n",
      "Iteration 31666, loss = 175.39348145\n",
      "Iteration 31667, loss = 175.37521713\n",
      "Iteration 31668, loss = 175.35695591\n",
      "Iteration 31669, loss = 175.33869786\n",
      "Iteration 31670, loss = 175.32044312\n",
      "Iteration 31671, loss = 175.30219179\n",
      "Iteration 31672, loss = 175.28394388\n",
      "Iteration 31673, loss = 175.26569930\n",
      "Iteration 31674, loss = 175.24745797\n",
      "Iteration 31675, loss = 175.22921982\n",
      "Iteration 31676, loss = 175.21098488\n",
      "Iteration 31677, loss = 175.19275323\n",
      "Iteration 31678, loss = 175.17452490\n",
      "Iteration 31679, loss = 175.15629991\n",
      "Iteration 31680, loss = 175.13807822\n",
      "Iteration 31681, loss = 175.11985978\n",
      "Iteration 31682, loss = 175.10164457\n",
      "Iteration 31683, loss = 175.08343258\n",
      "Iteration 31684, loss = 175.06522385\n",
      "Iteration 31685, loss = 175.04701840\n",
      "Iteration 31686, loss = 175.02881624\n",
      "Iteration 31687, loss = 175.01061735\n",
      "Iteration 31688, loss = 174.99242171\n",
      "Iteration 31689, loss = 174.97422930\n",
      "Iteration 31690, loss = 174.95604012\n",
      "Iteration 31691, loss = 174.93785418\n",
      "Iteration 31692, loss = 174.91967149\n",
      "Iteration 31693, loss = 174.90149205\n",
      "Iteration 31694, loss = 174.88331586\n",
      "Iteration 31695, loss = 174.86514291\n",
      "Iteration 31696, loss = 174.84697319\n",
      "Iteration 31697, loss = 174.82880669\n",
      "Iteration 31698, loss = 174.81064341\n",
      "Iteration 31699, loss = 174.79248336\n",
      "Iteration 31700, loss = 174.77432654\n",
      "Iteration 31701, loss = 174.75617295\n",
      "Iteration 31702, loss = 174.73802258\n",
      "Iteration 31703, loss = 174.71987542\n",
      "Iteration 31704, loss = 174.70173148\n",
      "Iteration 31705, loss = 174.68359075\n",
      "Iteration 31706, loss = 174.66545323\n",
      "Iteration 31707, loss = 174.64731891\n",
      "Iteration 31708, loss = 174.62918781\n",
      "Iteration 31709, loss = 174.61105991\n",
      "Iteration 31710, loss = 174.59293521\n",
      "Iteration 31711, loss = 174.57481372\n",
      "Iteration 31712, loss = 174.55669541\n",
      "Iteration 31713, loss = 174.53858030\n",
      "Iteration 31714, loss = 174.52046839\n",
      "Iteration 31715, loss = 174.50235966\n",
      "Iteration 31716, loss = 174.48425412\n",
      "Iteration 31717, loss = 174.46615177\n",
      "Iteration 31718, loss = 174.44805261\n",
      "Iteration 31719, loss = 174.42995662\n",
      "Iteration 31720, loss = 174.41186381\n",
      "Iteration 31721, loss = 174.39377418\n",
      "Iteration 31722, loss = 174.37568772\n",
      "Iteration 31723, loss = 174.35760444\n",
      "Iteration 31724, loss = 174.33952432\n",
      "Iteration 31725, loss = 174.32144737\n",
      "Iteration 31726, loss = 174.30337359\n",
      "Iteration 31727, loss = 174.28530298\n",
      "Iteration 31728, loss = 174.26723552\n",
      "Iteration 31729, loss = 174.24917122\n",
      "Iteration 31730, loss = 174.23111008\n",
      "Iteration 31731, loss = 174.21305209\n",
      "Iteration 31732, loss = 174.19499725\n",
      "Iteration 31733, loss = 174.17694556\n",
      "Iteration 31734, loss = 174.15889703\n",
      "Iteration 31735, loss = 174.14085163\n",
      "Iteration 31736, loss = 174.12280938\n",
      "Iteration 31737, loss = 174.10477027\n",
      "Iteration 31738, loss = 174.08673430\n",
      "Iteration 31739, loss = 174.06870147\n",
      "Iteration 31740, loss = 174.05067177\n",
      "Iteration 31741, loss = 174.03264520\n",
      "Iteration 31742, loss = 174.01462176\n",
      "Iteration 31743, loss = 173.99660145\n",
      "Iteration 31744, loss = 173.97858426\n",
      "Iteration 31745, loss = 173.96057020\n",
      "Iteration 31746, loss = 173.94255926\n",
      "Iteration 31747, loss = 173.92455144\n",
      "Iteration 31748, loss = 173.90654673\n",
      "Iteration 31749, loss = 173.88854514\n",
      "Iteration 31750, loss = 173.87054666\n",
      "Iteration 31751, loss = 173.85255129\n",
      "Iteration 31752, loss = 173.83455903\n",
      "Iteration 31753, loss = 173.81656987\n",
      "Iteration 31754, loss = 173.79858382\n",
      "Iteration 31755, loss = 173.78060087\n",
      "Iteration 31756, loss = 173.76262101\n",
      "Iteration 31757, loss = 173.74464426\n",
      "Iteration 31758, loss = 173.72667060\n",
      "Iteration 31759, loss = 173.70870003\n",
      "Iteration 31760, loss = 173.69073255\n",
      "Iteration 31761, loss = 173.67276816\n",
      "Iteration 31762, loss = 173.65480686\n",
      "Iteration 31763, loss = 173.63684864\n",
      "Iteration 31764, loss = 173.61889350\n",
      "Iteration 31765, loss = 173.60094144\n",
      "Iteration 31766, loss = 173.58299246\n",
      "Iteration 31767, loss = 173.56504655\n",
      "Iteration 31768, loss = 173.54710372\n",
      "Iteration 31769, loss = 173.52916396\n",
      "Iteration 31770, loss = 173.51122726\n",
      "Iteration 31771, loss = 173.49329364\n",
      "Iteration 31772, loss = 173.47536307\n",
      "Iteration 31773, loss = 173.45743557\n",
      "Iteration 31774, loss = 173.43951113\n",
      "Iteration 31775, loss = 173.42158975\n",
      "Iteration 31776, loss = 173.40367142\n",
      "Iteration 31777, loss = 173.38575615\n",
      "Iteration 31778, loss = 173.36784393\n",
      "Iteration 31779, loss = 173.34993476\n",
      "Iteration 31780, loss = 173.33202863\n",
      "Iteration 31781, loss = 173.31412555\n",
      "Iteration 31782, loss = 173.29622552\n",
      "Iteration 31783, loss = 173.27832852\n",
      "Iteration 31784, loss = 173.26043456\n",
      "Iteration 31785, loss = 173.24254364\n",
      "Iteration 31786, loss = 173.22465576\n",
      "Iteration 31787, loss = 173.20677090\n",
      "Iteration 31788, loss = 173.18888908\n",
      "Iteration 31789, loss = 173.17101028\n",
      "Iteration 31790, loss = 173.15313452\n",
      "Iteration 31791, loss = 173.13526177\n",
      "Iteration 31792, loss = 173.11739205\n",
      "Iteration 31793, loss = 173.09952534\n",
      "Iteration 31794, loss = 173.08166165\n",
      "Iteration 31795, loss = 173.06380098\n",
      "Iteration 31796, loss = 173.04594332\n",
      "Iteration 31797, loss = 173.02808868\n",
      "Iteration 31798, loss = 173.01023704\n",
      "Iteration 31799, loss = 172.99238841\n",
      "Iteration 31800, loss = 172.97454278\n",
      "Iteration 31801, loss = 172.95670016\n",
      "Iteration 31802, loss = 172.93886054\n",
      "Iteration 31803, loss = 172.92102391\n",
      "Iteration 31804, loss = 172.90319028\n",
      "Iteration 31805, loss = 172.88535965\n",
      "Iteration 31806, loss = 172.86753201\n",
      "Iteration 31807, loss = 172.84970736\n",
      "Iteration 31808, loss = 172.83188570\n",
      "Iteration 31809, loss = 172.81406702\n",
      "Iteration 31810, loss = 172.79625133\n",
      "Iteration 31811, loss = 172.77843862\n",
      "Iteration 31812, loss = 172.76062888\n",
      "Iteration 31813, loss = 172.74282213\n",
      "Iteration 31814, loss = 172.72501835\n",
      "Iteration 31815, loss = 172.70721755\n",
      "Iteration 31816, loss = 172.68941972\n",
      "Iteration 31817, loss = 172.67162485\n",
      "Iteration 31818, loss = 172.65383296\n",
      "Iteration 31819, loss = 172.63604403\n",
      "Iteration 31820, loss = 172.61825806\n",
      "Iteration 31821, loss = 172.60047505\n",
      "Iteration 31822, loss = 172.58269500\n",
      "Iteration 31823, loss = 172.56491791\n",
      "Iteration 31824, loss = 172.54714378\n",
      "Iteration 31825, loss = 172.52937259\n",
      "Iteration 31826, loss = 172.51160436\n",
      "Iteration 31827, loss = 172.49383908\n",
      "Iteration 31828, loss = 172.47607674\n",
      "Iteration 31829, loss = 172.45831735\n",
      "Iteration 31830, loss = 172.44056090\n",
      "Iteration 31831, loss = 172.42280739\n",
      "Iteration 31832, loss = 172.40505682\n",
      "Iteration 31833, loss = 172.38730919\n",
      "Iteration 31834, loss = 172.36956449\n",
      "Iteration 31835, loss = 172.35182272\n",
      "Iteration 31836, loss = 172.33408388\n",
      "Iteration 31837, loss = 172.31634797\n",
      "Iteration 31838, loss = 172.29861499\n",
      "Iteration 31839, loss = 172.28088493\n",
      "Iteration 31840, loss = 172.26315780\n",
      "Iteration 31841, loss = 172.24543358\n",
      "Iteration 31842, loss = 172.22771228\n",
      "Iteration 31843, loss = 172.20999390\n",
      "Iteration 31844, loss = 172.19227843\n",
      "Iteration 31845, loss = 172.17456587\n",
      "Iteration 31846, loss = 172.15685623\n",
      "Iteration 31847, loss = 172.13914949\n",
      "Iteration 31848, loss = 172.12144566\n",
      "Iteration 31849, loss = 172.10374473\n",
      "Iteration 31850, loss = 172.08604670\n",
      "Iteration 31851, loss = 172.06835157\n",
      "Iteration 31852, loss = 172.05065935\n",
      "Iteration 31853, loss = 172.03297001\n",
      "Iteration 31854, loss = 172.01528357\n",
      "Iteration 31855, loss = 171.99760003\n",
      "Iteration 31856, loss = 171.97991937\n",
      "Iteration 31857, loss = 171.96224160\n",
      "Iteration 31858, loss = 171.94456671\n",
      "Iteration 31859, loss = 171.92689471\n",
      "Iteration 31860, loss = 171.90922559\n",
      "Iteration 31861, loss = 171.89155935\n",
      "Iteration 31862, loss = 171.87389599\n",
      "Iteration 31863, loss = 171.85623551\n",
      "Iteration 31864, loss = 171.83857789\n",
      "Iteration 31865, loss = 171.82092315\n",
      "Iteration 31866, loss = 171.80327128\n",
      "Iteration 31867, loss = 171.78562228\n",
      "Iteration 31868, loss = 171.76797614\n",
      "Iteration 31869, loss = 171.75033287\n",
      "Iteration 31870, loss = 171.73269246\n",
      "Iteration 31871, loss = 171.71505491\n",
      "Iteration 31872, loss = 171.69742021\n",
      "Iteration 31873, loss = 171.67978837\n",
      "Iteration 31874, loss = 171.66215939\n",
      "Iteration 31875, loss = 171.64453326\n",
      "Iteration 31876, loss = 171.62690998\n",
      "Iteration 31877, loss = 171.60928955\n",
      "Iteration 31878, loss = 171.59167196\n",
      "Iteration 31879, loss = 171.57405722\n",
      "Iteration 31880, loss = 171.55644533\n",
      "Iteration 31881, loss = 171.53883629\n",
      "Iteration 31882, loss = 171.52123010\n",
      "Iteration 31883, loss = 171.50362676\n",
      "Iteration 31884, loss = 171.48602629\n",
      "Iteration 31885, loss = 171.46842869\n",
      "Iteration 31886, loss = 171.45083401\n",
      "Iteration 31887, loss = 171.43324228\n",
      "Iteration 31888, loss = 171.41565357\n",
      "Iteration 31889, loss = 171.39806794\n",
      "Iteration 31890, loss = 171.38048553\n",
      "Iteration 31891, loss = 171.36290632\n",
      "Iteration 31892, loss = 171.34533029\n",
      "Iteration 31893, loss = 171.32775682\n",
      "Iteration 31894, loss = 171.31018527\n",
      "Iteration 31895, loss = 171.29261453\n",
      "Iteration 31896, loss = 171.27504492\n",
      "Iteration 31897, loss = 171.25747772\n",
      "Iteration 31898, loss = 171.23991489\n",
      "Iteration 31899, loss = 171.22235707\n",
      "Iteration 31900, loss = 171.20480334\n",
      "Iteration 31901, loss = 171.18725206\n",
      "Iteration 31902, loss = 171.16970201\n",
      "Iteration 31903, loss = 171.15215345\n",
      "Iteration 31904, loss = 171.13460763\n",
      "Iteration 31905, loss = 171.11706573\n",
      "Iteration 31906, loss = 171.09952778\n",
      "Iteration 31907, loss = 171.08199280\n",
      "Iteration 31908, loss = 171.06445986\n",
      "Iteration 31909, loss = 171.04692883\n",
      "Iteration 31910, loss = 171.02940042\n",
      "Iteration 31911, loss = 171.01187537\n",
      "Iteration 31912, loss = 170.99435376\n",
      "Iteration 31913, loss = 170.97683506\n",
      "Iteration 31914, loss = 170.95931872\n",
      "Iteration 31915, loss = 170.94180467\n",
      "Iteration 31916, loss = 170.92429333\n",
      "Iteration 31917, loss = 170.90678508\n",
      "Iteration 31918, loss = 170.88927996\n",
      "Iteration 31919, loss = 170.87177764\n",
      "Iteration 31920, loss = 170.85427784\n",
      "Iteration 31921, loss = 170.83678056\n",
      "Iteration 31922, loss = 170.81928603\n",
      "Iteration 31923, loss = 170.80179444\n",
      "Iteration 31924, loss = 170.78430579\n",
      "Iteration 31925, loss = 170.76681990\n",
      "Iteration 31926, loss = 170.74933661\n",
      "Iteration 31927, loss = 170.73185596\n",
      "Iteration 31928, loss = 170.71437806\n",
      "Iteration 31929, loss = 170.69690301\n",
      "Iteration 31930, loss = 170.67943080\n",
      "Iteration 31931, loss = 170.66196133\n",
      "Iteration 31932, loss = 170.64449452\n",
      "Iteration 31933, loss = 170.62703038\n",
      "Iteration 31934, loss = 170.60956899\n",
      "Iteration 31935, loss = 170.59211039\n",
      "Iteration 31936, loss = 170.57465458\n",
      "Iteration 31937, loss = 170.55720148\n",
      "Iteration 31938, loss = 170.53975108\n",
      "Iteration 31939, loss = 170.52230337\n",
      "Iteration 31940, loss = 170.50485839\n",
      "Iteration 31941, loss = 170.48741617\n",
      "Iteration 31942, loss = 170.46997669\n",
      "Iteration 31943, loss = 170.45253993\n",
      "Iteration 31944, loss = 170.43510586\n",
      "Iteration 31945, loss = 170.41767450\n",
      "Iteration 31946, loss = 170.40024585\n",
      "Iteration 31947, loss = 170.38281992\n",
      "Iteration 31948, loss = 170.36539672\n",
      "Iteration 31949, loss = 170.34797623\n",
      "Iteration 31950, loss = 170.33055844\n",
      "Iteration 31951, loss = 170.31314334\n",
      "Iteration 31952, loss = 170.29573094\n",
      "Iteration 31953, loss = 170.27832125\n",
      "Iteration 31954, loss = 170.26091426\n",
      "Iteration 31955, loss = 170.24350998\n",
      "Iteration 31956, loss = 170.22610839\n",
      "Iteration 31957, loss = 170.20870948\n",
      "Iteration 31958, loss = 170.19131326\n",
      "Iteration 31959, loss = 170.17391974\n",
      "Iteration 31960, loss = 170.15652890\n",
      "Iteration 31961, loss = 170.13914076\n",
      "Iteration 31962, loss = 170.12175530\n",
      "Iteration 31963, loss = 170.10437251\n",
      "Iteration 31964, loss = 170.08699241\n",
      "Iteration 31965, loss = 170.06961498\n",
      "Iteration 31966, loss = 170.05224023\n",
      "Iteration 31967, loss = 170.03486816\n",
      "Iteration 31968, loss = 170.01749876\n",
      "Iteration 31969, loss = 170.00013203\n",
      "Iteration 31970, loss = 169.98276796\n",
      "Iteration 31971, loss = 169.96540657\n",
      "Iteration 31972, loss = 169.94804783\n",
      "Iteration 31973, loss = 169.93069177\n",
      "Iteration 31974, loss = 169.91333836\n",
      "Iteration 31975, loss = 169.89598762\n",
      "Iteration 31976, loss = 169.87863953\n",
      "Iteration 31977, loss = 169.86129409\n",
      "Iteration 31978, loss = 169.84395131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31979, loss = 169.82661118\n",
      "Iteration 31980, loss = 169.80927371\n",
      "Iteration 31981, loss = 169.79193888\n",
      "Iteration 31982, loss = 169.77460669\n",
      "Iteration 31983, loss = 169.75727716\n",
      "Iteration 31984, loss = 169.73995026\n",
      "Iteration 31985, loss = 169.72262600\n",
      "Iteration 31986, loss = 169.70530439\n",
      "Iteration 31987, loss = 169.68798540\n",
      "Iteration 31988, loss = 169.67066906\n",
      "Iteration 31989, loss = 169.65335535\n",
      "Iteration 31990, loss = 169.63604427\n",
      "Iteration 31991, loss = 169.61873582\n",
      "Iteration 31992, loss = 169.60142999\n",
      "Iteration 31993, loss = 169.58412679\n",
      "Iteration 31994, loss = 169.56682622\n",
      "Iteration 31995, loss = 169.54952827\n",
      "Iteration 31996, loss = 169.53223294\n",
      "Iteration 31997, loss = 169.51494022\n",
      "Iteration 31998, loss = 169.49765012\n",
      "Iteration 31999, loss = 169.48036264\n",
      "Iteration 32000, loss = 169.46307777\n",
      "Iteration 32001, loss = 169.44579551\n",
      "Iteration 32002, loss = 169.42851586\n",
      "Iteration 32003, loss = 169.41123882\n",
      "Iteration 32004, loss = 169.39396438\n",
      "Iteration 32005, loss = 169.37669255\n",
      "Iteration 32006, loss = 169.35942331\n",
      "Iteration 32007, loss = 169.34215668\n",
      "Iteration 32008, loss = 169.32489264\n",
      "Iteration 32009, loss = 169.30763120\n",
      "Iteration 32010, loss = 169.29037236\n",
      "Iteration 32011, loss = 169.27311611\n",
      "Iteration 32012, loss = 169.25586245\n",
      "Iteration 32013, loss = 169.23861138\n",
      "Iteration 32014, loss = 169.22136290\n",
      "Iteration 32015, loss = 169.20411701\n",
      "Iteration 32016, loss = 169.18687371\n",
      "Iteration 32017, loss = 169.16963301\n",
      "Iteration 32018, loss = 169.15239491\n",
      "Iteration 32019, loss = 169.13515944\n",
      "Iteration 32020, loss = 169.11792661\n",
      "Iteration 32021, loss = 169.10069649\n",
      "Iteration 32022, loss = 169.08346917\n",
      "Iteration 32023, loss = 169.06624480\n",
      "Iteration 32024, loss = 169.04902364\n",
      "Iteration 32025, loss = 169.03180614\n",
      "Iteration 32026, loss = 169.01459297\n",
      "Iteration 32027, loss = 168.99738506\n",
      "Iteration 32028, loss = 168.98018330\n",
      "Iteration 32029, loss = 168.96298777\n",
      "Iteration 32030, loss = 168.94579542\n",
      "Iteration 32031, loss = 168.92859897\n",
      "Iteration 32032, loss = 168.91138877\n",
      "Iteration 32033, loss = 168.89416484\n",
      "Iteration 32034, loss = 168.87694221\n",
      "Iteration 32035, loss = 168.85973899\n",
      "Iteration 32036, loss = 168.84255731\n",
      "Iteration 32037, loss = 168.82538275\n",
      "Iteration 32038, loss = 168.80819905\n",
      "Iteration 32039, loss = 168.79100298\n",
      "Iteration 32040, loss = 168.77380727\n",
      "Iteration 32041, loss = 168.75662546\n",
      "Iteration 32042, loss = 168.73945682\n",
      "Iteration 32043, loss = 168.72228938\n",
      "Iteration 32044, loss = 168.70511474\n",
      "Iteration 32045, loss = 168.68793692\n",
      "Iteration 32046, loss = 168.67076598\n",
      "Iteration 32047, loss = 168.65360527\n",
      "Iteration 32048, loss = 168.63644861\n",
      "Iteration 32049, loss = 168.61928924\n",
      "Iteration 32050, loss = 168.60212784\n",
      "Iteration 32051, loss = 168.58497046\n",
      "Iteration 32052, loss = 168.56782030\n",
      "Iteration 32053, loss = 168.55067438\n",
      "Iteration 32054, loss = 168.53352822\n",
      "Iteration 32055, loss = 168.51638154\n",
      "Iteration 32056, loss = 168.49923780\n",
      "Iteration 32057, loss = 168.48209933\n",
      "Iteration 32058, loss = 168.46496469\n",
      "Iteration 32059, loss = 168.44783115\n",
      "Iteration 32060, loss = 168.43069820\n",
      "Iteration 32061, loss = 168.41356776\n",
      "Iteration 32062, loss = 168.39644140\n",
      "Iteration 32063, loss = 168.37931848\n",
      "Iteration 32064, loss = 168.36219738\n",
      "Iteration 32065, loss = 168.34507759\n",
      "Iteration 32066, loss = 168.32796013\n",
      "Iteration 32067, loss = 168.31084604\n",
      "Iteration 32068, loss = 168.29373510\n",
      "Iteration 32069, loss = 168.27662635\n",
      "Iteration 32070, loss = 168.25951938\n",
      "Iteration 32071, loss = 168.24241469\n",
      "Iteration 32072, loss = 168.22531292\n",
      "Iteration 32073, loss = 168.20821409\n",
      "Iteration 32074, loss = 168.19111765\n",
      "Iteration 32075, loss = 168.17402329\n",
      "Iteration 32076, loss = 168.15693119\n",
      "Iteration 32077, loss = 168.13984176\n",
      "Iteration 32078, loss = 168.12275510\n",
      "Iteration 32079, loss = 168.10567093\n",
      "Iteration 32080, loss = 168.08858902\n",
      "Iteration 32081, loss = 168.07150939\n",
      "Iteration 32082, loss = 168.05443229\n",
      "Iteration 32083, loss = 168.03735783\n",
      "Iteration 32084, loss = 168.02028589\n",
      "Iteration 32085, loss = 168.00321631\n",
      "Iteration 32086, loss = 167.98614906\n",
      "Iteration 32087, loss = 167.96908425\n",
      "Iteration 32088, loss = 167.95202198\n",
      "Iteration 32089, loss = 167.93496223\n",
      "Iteration 32090, loss = 167.91790490\n",
      "Iteration 32091, loss = 167.90084994\n",
      "Iteration 32092, loss = 167.88379738\n",
      "Iteration 32093, loss = 167.86674730\n",
      "Iteration 32094, loss = 167.84969971\n",
      "Iteration 32095, loss = 167.83265456\n",
      "Iteration 32096, loss = 167.81561180\n",
      "Iteration 32097, loss = 167.79857144\n",
      "Iteration 32098, loss = 167.78153351\n",
      "Iteration 32099, loss = 167.76449804\n",
      "Iteration 32100, loss = 167.74746502\n",
      "Iteration 32101, loss = 167.73043440\n",
      "Iteration 32102, loss = 167.71340618\n",
      "Iteration 32103, loss = 167.69638037\n",
      "Iteration 32104, loss = 167.67935698\n",
      "Iteration 32105, loss = 167.66233603\n",
      "Iteration 32106, loss = 167.64531749\n",
      "Iteration 32107, loss = 167.62830135\n",
      "Iteration 32108, loss = 167.61128760\n",
      "Iteration 32109, loss = 167.59427626\n",
      "Iteration 32110, loss = 167.57726734\n",
      "Iteration 32111, loss = 167.56026082\n",
      "Iteration 32112, loss = 167.54325670\n",
      "Iteration 32113, loss = 167.52625497\n",
      "Iteration 32114, loss = 167.50925563\n",
      "Iteration 32115, loss = 167.49225868\n",
      "Iteration 32116, loss = 167.47526413\n",
      "Iteration 32117, loss = 167.45827198\n",
      "Iteration 32118, loss = 167.44128220\n",
      "Iteration 32119, loss = 167.42429481\n",
      "Iteration 32120, loss = 167.40730980\n",
      "Iteration 32121, loss = 167.39032717\n",
      "Iteration 32122, loss = 167.37334693\n",
      "Iteration 32123, loss = 167.35636906\n",
      "Iteration 32124, loss = 167.33939356\n",
      "Iteration 32125, loss = 167.32242043\n",
      "Iteration 32126, loss = 167.30544967\n",
      "Iteration 32127, loss = 167.28848128\n",
      "Iteration 32128, loss = 167.27151526\n",
      "Iteration 32129, loss = 167.25455160\n",
      "Iteration 32130, loss = 167.23759030\n",
      "Iteration 32131, loss = 167.22063136\n",
      "Iteration 32132, loss = 167.20367477\n",
      "Iteration 32133, loss = 167.18672054\n",
      "Iteration 32134, loss = 167.16976867\n",
      "Iteration 32135, loss = 167.15281914\n",
      "Iteration 32136, loss = 167.13587196\n",
      "Iteration 32137, loss = 167.11892713\n",
      "Iteration 32138, loss = 167.10198463\n",
      "Iteration 32139, loss = 167.08504448\n",
      "Iteration 32140, loss = 167.06810667\n",
      "Iteration 32141, loss = 167.05117120\n",
      "Iteration 32142, loss = 167.03423806\n",
      "Iteration 32143, loss = 167.01730725\n",
      "Iteration 32144, loss = 167.00037877\n",
      "Iteration 32145, loss = 166.98345261\n",
      "Iteration 32146, loss = 166.96652878\n",
      "Iteration 32147, loss = 166.94960728\n",
      "Iteration 32148, loss = 166.93268809\n",
      "Iteration 32149, loss = 166.91577122\n",
      "Iteration 32150, loss = 166.89885667\n",
      "Iteration 32151, loss = 166.88194443\n",
      "Iteration 32152, loss = 166.86503450\n",
      "Iteration 32153, loss = 166.84812687\n",
      "Iteration 32154, loss = 166.83122155\n",
      "Iteration 32155, loss = 166.81431854\n",
      "Iteration 32156, loss = 166.79741782\n",
      "Iteration 32157, loss = 166.78051941\n",
      "Iteration 32158, loss = 166.76362328\n",
      "Iteration 32159, loss = 166.74672945\n",
      "Iteration 32160, loss = 166.72983791\n",
      "Iteration 32161, loss = 166.71294866\n",
      "Iteration 32162, loss = 166.69606169\n",
      "Iteration 32163, loss = 166.67917700\n",
      "Iteration 32164, loss = 166.66229460\n",
      "Iteration 32165, loss = 166.64541447\n",
      "Iteration 32166, loss = 166.62853661\n",
      "Iteration 32167, loss = 166.61166103\n",
      "Iteration 32168, loss = 166.59478771\n",
      "Iteration 32169, loss = 166.57791666\n",
      "Iteration 32170, loss = 166.56104787\n",
      "Iteration 32171, loss = 166.54418134\n",
      "Iteration 32172, loss = 166.52731707\n",
      "Iteration 32173, loss = 166.51045506\n",
      "Iteration 32174, loss = 166.49359529\n",
      "Iteration 32175, loss = 166.47673778\n",
      "Iteration 32176, loss = 166.45988251\n",
      "Iteration 32177, loss = 166.44302948\n",
      "Iteration 32178, loss = 166.42617869\n",
      "Iteration 32179, loss = 166.40933014\n",
      "Iteration 32180, loss = 166.39248382\n",
      "Iteration 32181, loss = 166.37563973\n",
      "Iteration 32182, loss = 166.35879787\n",
      "Iteration 32183, loss = 166.34195823\n",
      "Iteration 32184, loss = 166.32512081\n",
      "Iteration 32185, loss = 166.30828561\n",
      "Iteration 32186, loss = 166.29145263\n",
      "Iteration 32187, loss = 166.27462185\n",
      "Iteration 32188, loss = 166.25779328\n",
      "Iteration 32189, loss = 166.24096692\n",
      "Iteration 32190, loss = 166.22414276\n",
      "Iteration 32191, loss = 166.20732079\n",
      "Iteration 32192, loss = 166.19050102\n",
      "Iteration 32193, loss = 166.17368345\n",
      "Iteration 32194, loss = 166.15686806\n",
      "Iteration 32195, loss = 166.14005486\n",
      "Iteration 32196, loss = 166.12324384\n",
      "Iteration 32197, loss = 166.10643501\n",
      "Iteration 32198, loss = 166.08962838\n",
      "Iteration 32199, loss = 166.07282395\n",
      "Iteration 32200, loss = 166.05602175\n",
      "Iteration 32201, loss = 166.03922180\n",
      "Iteration 32202, loss = 166.02242415\n",
      "Iteration 32203, loss = 166.00562891\n",
      "Iteration 32204, loss = 165.98883616\n",
      "Iteration 32205, loss = 165.97204605\n",
      "Iteration 32206, loss = 165.95525852\n",
      "Iteration 32207, loss = 165.93847344\n",
      "Iteration 32208, loss = 165.92168983\n",
      "Iteration 32209, loss = 165.90490677\n",
      "Iteration 32210, loss = 165.88812325\n",
      "Iteration 32211, loss = 165.87134052\n",
      "Iteration 32212, loss = 165.85456083\n",
      "Iteration 32213, loss = 165.83778589\n",
      "Iteration 32214, loss = 165.82101519\n",
      "Iteration 32215, loss = 165.80424668\n",
      "Iteration 32216, loss = 165.78747860\n",
      "Iteration 32217, loss = 165.77071072\n",
      "Iteration 32218, loss = 165.75394463\n",
      "Iteration 32219, loss = 165.73718197\n",
      "Iteration 32220, loss = 165.72042286\n",
      "Iteration 32221, loss = 165.70366602\n",
      "Iteration 32222, loss = 165.68691020\n",
      "Iteration 32223, loss = 165.67015540\n",
      "Iteration 32224, loss = 165.65340263\n",
      "Iteration 32225, loss = 165.63665278\n",
      "Iteration 32226, loss = 165.61990569\n",
      "Iteration 32227, loss = 165.60316049\n",
      "Iteration 32228, loss = 165.58641663\n",
      "Iteration 32229, loss = 165.56967435\n",
      "Iteration 32230, loss = 165.55293432\n",
      "Iteration 32231, loss = 165.53619682\n",
      "Iteration 32232, loss = 165.51946156\n",
      "Iteration 32233, loss = 165.50272802\n",
      "Iteration 32234, loss = 165.48599608\n",
      "Iteration 32235, loss = 165.46926604\n",
      "Iteration 32236, loss = 165.45253821\n",
      "Iteration 32237, loss = 165.43581260\n",
      "Iteration 32238, loss = 165.41908894\n",
      "Iteration 32239, loss = 165.40236702\n",
      "Iteration 32240, loss = 165.38564686\n",
      "Iteration 32241, loss = 165.36892869\n",
      "Iteration 32242, loss = 165.35221260\n",
      "Iteration 32243, loss = 165.33549852\n",
      "Iteration 32244, loss = 165.31878627\n",
      "Iteration 32245, loss = 165.30207579\n",
      "Iteration 32246, loss = 165.28536715\n",
      "Iteration 32247, loss = 165.26866046\n",
      "Iteration 32248, loss = 165.25195572\n",
      "Iteration 32249, loss = 165.23525285\n",
      "Iteration 32250, loss = 165.21855177\n",
      "Iteration 32251, loss = 165.20185247\n",
      "Iteration 32252, loss = 165.18515501\n",
      "Iteration 32253, loss = 165.16845941\n",
      "Iteration 32254, loss = 165.15176567\n",
      "Iteration 32255, loss = 165.13507371\n",
      "Iteration 32256, loss = 165.11838351\n",
      "Iteration 32257, loss = 165.10169508\n",
      "Iteration 32258, loss = 165.08500842\n",
      "Iteration 32259, loss = 165.06832356\n",
      "Iteration 32260, loss = 165.05164047\n",
      "Iteration 32261, loss = 165.03495912\n",
      "Iteration 32262, loss = 165.01827947\n",
      "Iteration 32263, loss = 165.00160155\n",
      "Iteration 32264, loss = 164.98492536\n",
      "Iteration 32265, loss = 164.96825089\n",
      "Iteration 32266, loss = 164.95157812\n",
      "Iteration 32267, loss = 164.93490704\n",
      "Iteration 32268, loss = 164.91823763\n",
      "Iteration 32269, loss = 164.90156990\n",
      "Iteration 32270, loss = 164.88490383\n",
      "Iteration 32271, loss = 164.86823944\n",
      "Iteration 32272, loss = 164.85157669\n",
      "Iteration 32273, loss = 164.83491558\n",
      "Iteration 32274, loss = 164.81825611\n",
      "Iteration 32275, loss = 164.80159826\n",
      "Iteration 32276, loss = 164.78494203\n",
      "Iteration 32277, loss = 164.76828743\n",
      "Iteration 32278, loss = 164.75163443\n",
      "Iteration 32279, loss = 164.73498304\n",
      "Iteration 32280, loss = 164.71833323\n",
      "Iteration 32281, loss = 164.70168502\n",
      "Iteration 32282, loss = 164.68503839\n",
      "Iteration 32283, loss = 164.66839335\n",
      "Iteration 32284, loss = 164.65174987\n",
      "Iteration 32285, loss = 164.63510797\n",
      "Iteration 32286, loss = 164.61846762\n",
      "Iteration 32287, loss = 164.60182884\n",
      "Iteration 32288, loss = 164.58519161\n",
      "Iteration 32289, loss = 164.56855593\n",
      "Iteration 32290, loss = 164.55192179\n",
      "Iteration 32291, loss = 164.53528919\n",
      "Iteration 32292, loss = 164.51865814\n",
      "Iteration 32293, loss = 164.50202861\n",
      "Iteration 32294, loss = 164.48540061\n",
      "Iteration 32295, loss = 164.46877414\n",
      "Iteration 32296, loss = 164.45214919\n",
      "Iteration 32297, loss = 164.43552575\n",
      "Iteration 32298, loss = 164.41890384\n",
      "Iteration 32299, loss = 164.40228343\n",
      "Iteration 32300, loss = 164.38566453\n",
      "Iteration 32301, loss = 164.36904714\n",
      "Iteration 32302, loss = 164.35243125\n",
      "Iteration 32303, loss = 164.33581687\n",
      "Iteration 32304, loss = 164.31920397\n",
      "Iteration 32305, loss = 164.30259258\n",
      "Iteration 32306, loss = 164.28598268\n",
      "Iteration 32307, loss = 164.26937427\n",
      "Iteration 32308, loss = 164.25276734\n",
      "Iteration 32309, loss = 164.23616191\n",
      "Iteration 32310, loss = 164.21955796\n",
      "Iteration 32311, loss = 164.20295549\n",
      "Iteration 32312, loss = 164.18635450\n",
      "Iteration 32313, loss = 164.16975499\n",
      "Iteration 32314, loss = 164.15315696\n",
      "Iteration 32315, loss = 164.13656040\n",
      "Iteration 32316, loss = 164.11996532\n",
      "Iteration 32317, loss = 164.10337171\n",
      "Iteration 32318, loss = 164.08677957\n",
      "Iteration 32319, loss = 164.07018891\n",
      "Iteration 32320, loss = 164.05359971\n",
      "Iteration 32321, loss = 164.03701198\n",
      "Iteration 32322, loss = 164.02042572\n",
      "Iteration 32323, loss = 164.00384093\n",
      "Iteration 32324, loss = 163.98725760\n",
      "Iteration 32325, loss = 163.97067576\n",
      "Iteration 32326, loss = 163.95409540\n",
      "Iteration 32327, loss = 163.93751655\n",
      "Iteration 32328, loss = 163.92093925\n",
      "Iteration 32329, loss = 163.90436357\n",
      "Iteration 32330, loss = 163.88778965\n",
      "Iteration 32331, loss = 163.87121775\n",
      "Iteration 32332, loss = 163.85464834\n",
      "Iteration 32333, loss = 163.83808227\n",
      "Iteration 32334, loss = 163.82152093\n",
      "Iteration 32335, loss = 163.80496633\n",
      "Iteration 32336, loss = 163.78842028\n",
      "Iteration 32337, loss = 163.77188130\n",
      "Iteration 32338, loss = 163.75533905\n",
      "Iteration 32339, loss = 163.73877397\n",
      "Iteration 32340, loss = 163.72217760\n",
      "Iteration 32341, loss = 163.70557640\n",
      "Iteration 32342, loss = 163.68900810\n",
      "Iteration 32343, loss = 163.67247469\n",
      "Iteration 32344, loss = 163.65594242\n",
      "Iteration 32345, loss = 163.63938241\n",
      "Iteration 32346, loss = 163.62280475\n",
      "Iteration 32347, loss = 163.60624357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32348, loss = 163.58970838\n",
      "Iteration 32349, loss = 163.57317463\n",
      "Iteration 32350, loss = 163.55662207\n",
      "Iteration 32351, loss = 163.54006217\n",
      "Iteration 32352, loss = 163.52351735\n",
      "Iteration 32353, loss = 163.50698663\n",
      "Iteration 32354, loss = 163.49045104\n",
      "Iteration 32355, loss = 163.47390434\n",
      "Iteration 32356, loss = 163.45736012\n",
      "Iteration 32357, loss = 163.44082813\n",
      "Iteration 32358, loss = 163.42430026\n",
      "Iteration 32359, loss = 163.40776597\n",
      "Iteration 32360, loss = 163.39122860\n",
      "Iteration 32361, loss = 163.37469781\n",
      "Iteration 32362, loss = 163.35817372\n",
      "Iteration 32363, loss = 163.34164849\n",
      "Iteration 32364, loss = 163.32511972\n",
      "Iteration 32365, loss = 163.30859310\n",
      "Iteration 32366, loss = 163.29207221\n",
      "Iteration 32367, loss = 163.27555344\n",
      "Iteration 32368, loss = 163.25903286\n",
      "Iteration 32369, loss = 163.24251225\n",
      "Iteration 32370, loss = 163.22599531\n",
      "Iteration 32371, loss = 163.20948166\n",
      "Iteration 32372, loss = 163.19296821\n",
      "Iteration 32373, loss = 163.17645433\n",
      "Iteration 32374, loss = 163.15994235\n",
      "Iteration 32375, loss = 163.14343347\n",
      "Iteration 32376, loss = 163.12692615\n",
      "Iteration 32377, loss = 163.11041898\n",
      "Iteration 32378, loss = 163.09391273\n",
      "Iteration 32379, loss = 163.07740881\n",
      "Iteration 32380, loss = 163.06090702\n",
      "Iteration 32381, loss = 163.04440617\n",
      "Iteration 32382, loss = 163.02790603\n",
      "Iteration 32383, loss = 163.01140748\n",
      "Iteration 32384, loss = 162.99491100\n",
      "Iteration 32385, loss = 162.97841604\n",
      "Iteration 32386, loss = 162.96192202\n",
      "Iteration 32387, loss = 162.94542920\n",
      "Iteration 32388, loss = 162.92893811\n",
      "Iteration 32389, loss = 162.91244875\n",
      "Iteration 32390, loss = 162.89596068\n",
      "Iteration 32391, loss = 162.87947374\n",
      "Iteration 32392, loss = 162.86298823\n",
      "Iteration 32393, loss = 162.84650439\n",
      "Iteration 32394, loss = 162.83002206\n",
      "Iteration 32395, loss = 162.81354100\n",
      "Iteration 32396, loss = 162.79706123\n",
      "Iteration 32397, loss = 162.78058296\n",
      "Iteration 32398, loss = 162.76410625\n",
      "Iteration 32399, loss = 162.74763097\n",
      "Iteration 32400, loss = 162.73115699\n",
      "Iteration 32401, loss = 162.71468439\n",
      "Iteration 32402, loss = 162.69821329\n",
      "Iteration 32403, loss = 162.68174367\n",
      "Iteration 32404, loss = 162.66527545\n",
      "Iteration 32405, loss = 162.64880859\n",
      "Iteration 32406, loss = 162.63234314\n",
      "Iteration 32407, loss = 162.61587916\n",
      "Iteration 32408, loss = 162.59941663\n",
      "Iteration 32409, loss = 162.58295550\n",
      "Iteration 32410, loss = 162.56649575\n",
      "Iteration 32411, loss = 162.55003742\n",
      "Iteration 32412, loss = 162.53358055\n",
      "Iteration 32413, loss = 162.51712511\n",
      "Iteration 32414, loss = 162.50067107\n",
      "Iteration 32415, loss = 162.48421842\n",
      "Iteration 32416, loss = 162.46776721\n",
      "Iteration 32417, loss = 162.45131743\n",
      "Iteration 32418, loss = 162.43486907\n",
      "Iteration 32419, loss = 162.41842212\n",
      "Iteration 32420, loss = 162.40197658\n",
      "Iteration 32421, loss = 162.38553246\n",
      "Iteration 32422, loss = 162.36908976\n",
      "Iteration 32423, loss = 162.35264849\n",
      "Iteration 32424, loss = 162.33620863\n",
      "Iteration 32425, loss = 162.31977018\n",
      "Iteration 32426, loss = 162.30333314\n",
      "Iteration 32427, loss = 162.28689753\n",
      "Iteration 32428, loss = 162.27046334\n",
      "Iteration 32429, loss = 162.25403056\n",
      "Iteration 32430, loss = 162.23759919\n",
      "Iteration 32431, loss = 162.22116924\n",
      "Iteration 32432, loss = 162.20474071\n",
      "Iteration 32433, loss = 162.18831359\n",
      "Iteration 32434, loss = 162.17188789\n",
      "Iteration 32435, loss = 162.15546360\n",
      "Iteration 32436, loss = 162.13904072\n",
      "Iteration 32437, loss = 162.12261926\n",
      "Iteration 32438, loss = 162.10619922\n",
      "Iteration 32439, loss = 162.08978059\n",
      "Iteration 32440, loss = 162.07336337\n",
      "Iteration 32441, loss = 162.05694756\n",
      "Iteration 32442, loss = 162.04053317\n",
      "Iteration 32443, loss = 162.02412019\n",
      "Iteration 32444, loss = 162.00770863\n",
      "Iteration 32445, loss = 161.99129847\n",
      "Iteration 32446, loss = 161.97488973\n",
      "Iteration 32447, loss = 161.95848240\n",
      "Iteration 32448, loss = 161.94207649\n",
      "Iteration 32449, loss = 161.92567198\n",
      "Iteration 32450, loss = 161.90926889\n",
      "Iteration 32451, loss = 161.89286721\n",
      "Iteration 32452, loss = 161.87646694\n",
      "Iteration 32453, loss = 161.86006808\n",
      "Iteration 32454, loss = 161.84367063\n",
      "Iteration 32455, loss = 161.82727459\n",
      "Iteration 32456, loss = 161.81087997\n",
      "Iteration 32457, loss = 161.79448675\n",
      "Iteration 32458, loss = 161.77809494\n",
      "Iteration 32459, loss = 161.76170455\n",
      "Iteration 32460, loss = 161.74531556\n",
      "Iteration 32461, loss = 161.72892798\n",
      "Iteration 32462, loss = 161.71254181\n",
      "Iteration 32463, loss = 161.69615706\n",
      "Iteration 32464, loss = 161.67977371\n",
      "Iteration 32465, loss = 161.66339176\n",
      "Iteration 32466, loss = 161.64701123\n",
      "Iteration 32467, loss = 161.63063211\n",
      "Iteration 32468, loss = 161.61425439\n",
      "Iteration 32469, loss = 161.59787808\n",
      "Iteration 32470, loss = 161.58150318\n",
      "Iteration 32471, loss = 161.56512969\n",
      "Iteration 32472, loss = 161.54875761\n",
      "Iteration 32473, loss = 161.53238693\n",
      "Iteration 32474, loss = 161.51601766\n",
      "Iteration 32475, loss = 161.49964979\n",
      "Iteration 32476, loss = 161.48328334\n",
      "Iteration 32477, loss = 161.46691829\n",
      "Iteration 32478, loss = 161.45055464\n",
      "Iteration 32479, loss = 161.43419241\n",
      "Iteration 32480, loss = 161.41783157\n",
      "Iteration 32481, loss = 161.40147215\n",
      "Iteration 32482, loss = 161.38511413\n",
      "Iteration 32483, loss = 161.36875751\n",
      "Iteration 32484, loss = 161.35240231\n",
      "Iteration 32485, loss = 161.33604850\n",
      "Iteration 32486, loss = 161.31969610\n",
      "Iteration 32487, loss = 161.30334511\n",
      "Iteration 32488, loss = 161.28699552\n",
      "Iteration 32489, loss = 161.27064733\n",
      "Iteration 32490, loss = 161.25430055\n",
      "Iteration 32491, loss = 161.23795517\n",
      "Iteration 32492, loss = 161.22161120\n",
      "Iteration 32493, loss = 161.20526863\n",
      "Iteration 32494, loss = 161.18892747\n",
      "Iteration 32495, loss = 161.17258770\n",
      "Iteration 32496, loss = 161.15624934\n",
      "Iteration 32497, loss = 161.13991239\n",
      "Iteration 32498, loss = 161.12357683\n",
      "Iteration 32499, loss = 161.10724268\n",
      "Iteration 32500, loss = 161.09090994\n",
      "Iteration 32501, loss = 161.07457859\n",
      "Iteration 32502, loss = 161.05824865\n",
      "Iteration 32503, loss = 161.04192011\n",
      "Iteration 32504, loss = 161.02559297\n",
      "Iteration 32505, loss = 161.00926723\n",
      "Iteration 32506, loss = 160.99294289\n",
      "Iteration 32507, loss = 160.97661996\n",
      "Iteration 32508, loss = 160.96029842\n",
      "Iteration 32509, loss = 160.94397829\n",
      "Iteration 32510, loss = 160.92765956\n",
      "Iteration 32511, loss = 160.91134223\n",
      "Iteration 32512, loss = 160.89502630\n",
      "Iteration 32513, loss = 160.87871176\n",
      "Iteration 32514, loss = 160.86239863\n",
      "Iteration 32515, loss = 160.84608690\n",
      "Iteration 32516, loss = 160.82977657\n",
      "Iteration 32517, loss = 160.81346764\n",
      "Iteration 32518, loss = 160.79716011\n",
      "Iteration 32519, loss = 160.78085398\n",
      "Iteration 32520, loss = 160.76454925\n",
      "Iteration 32521, loss = 160.74824591\n",
      "Iteration 32522, loss = 160.73194398\n",
      "Iteration 32523, loss = 160.71564344\n",
      "Iteration 32524, loss = 160.69934430\n",
      "Iteration 32525, loss = 160.68304656\n",
      "Iteration 32526, loss = 160.66675022\n",
      "Iteration 32527, loss = 160.65045528\n",
      "Iteration 32528, loss = 160.63416174\n",
      "Iteration 32529, loss = 160.61786959\n",
      "Iteration 32530, loss = 160.60157884\n",
      "Iteration 32531, loss = 160.58528949\n",
      "Iteration 32532, loss = 160.56900154\n",
      "Iteration 32533, loss = 160.55271499\n",
      "Iteration 32534, loss = 160.53642984\n",
      "Iteration 32535, loss = 160.52014610\n",
      "Iteration 32536, loss = 160.50386377\n",
      "Iteration 32537, loss = 160.48758286\n",
      "Iteration 32538, loss = 160.47130339\n",
      "Iteration 32539, loss = 160.45502539\n",
      "Iteration 32540, loss = 160.43874891\n",
      "Iteration 32541, loss = 160.42247402\n",
      "Iteration 32542, loss = 160.40620084\n",
      "Iteration 32543, loss = 160.38992951\n",
      "Iteration 32544, loss = 160.37366020\n",
      "Iteration 32545, loss = 160.35739277\n",
      "Iteration 32546, loss = 160.34112688\n",
      "Iteration 32547, loss = 160.32486100\n",
      "Iteration 32548, loss = 160.30859406\n",
      "Iteration 32549, loss = 160.29232576\n",
      "Iteration 32550, loss = 160.27605873\n",
      "Iteration 32551, loss = 160.25979571\n",
      "Iteration 32552, loss = 160.24353720\n",
      "Iteration 32553, loss = 160.22728107\n",
      "Iteration 32554, loss = 160.21102464\n",
      "Iteration 32555, loss = 160.19476720\n",
      "Iteration 32556, loss = 160.17851036\n",
      "Iteration 32557, loss = 160.16225645\n",
      "Iteration 32558, loss = 160.14600584\n",
      "Iteration 32559, loss = 160.12975690\n",
      "Iteration 32560, loss = 160.11350802\n",
      "Iteration 32561, loss = 160.09725927\n",
      "Iteration 32562, loss = 160.08101212\n",
      "Iteration 32563, loss = 160.06476757\n",
      "Iteration 32564, loss = 160.04852512\n",
      "Iteration 32565, loss = 160.03228357\n",
      "Iteration 32566, loss = 160.01604250\n",
      "Iteration 32567, loss = 159.99980262\n",
      "Iteration 32568, loss = 159.98356474\n",
      "Iteration 32569, loss = 159.96732884\n",
      "Iteration 32570, loss = 159.95109423\n",
      "Iteration 32571, loss = 159.93486048\n",
      "Iteration 32572, loss = 159.91862785\n",
      "Iteration 32573, loss = 159.90239687\n",
      "Iteration 32574, loss = 159.88616768\n",
      "Iteration 32575, loss = 159.86993993\n",
      "Iteration 32576, loss = 159.85371329\n",
      "Iteration 32577, loss = 159.83748781\n",
      "Iteration 32578, loss = 159.82126381\n",
      "Iteration 32579, loss = 159.80504144\n",
      "Iteration 32580, loss = 159.78882055\n",
      "Iteration 32581, loss = 159.77260092\n",
      "Iteration 32582, loss = 159.75638252\n",
      "Iteration 32583, loss = 159.74016551\n",
      "Iteration 32584, loss = 159.72395002\n",
      "Iteration 32585, loss = 159.70773601\n",
      "Iteration 32586, loss = 159.69152334\n",
      "Iteration 32587, loss = 159.67531196\n",
      "Iteration 32588, loss = 159.65910194\n",
      "Iteration 32589, loss = 159.64289337\n",
      "Iteration 32590, loss = 159.62668626\n",
      "Iteration 32591, loss = 159.61048053\n",
      "Iteration 32592, loss = 159.59427613\n",
      "Iteration 32593, loss = 159.57807308\n",
      "Iteration 32594, loss = 159.56187145\n",
      "Iteration 32595, loss = 159.54567125\n",
      "Iteration 32596, loss = 159.52947244\n",
      "Iteration 32597, loss = 159.51327500\n",
      "Iteration 32598, loss = 159.49707892\n",
      "Iteration 32599, loss = 159.48088423\n",
      "Iteration 32600, loss = 159.46469094\n",
      "Iteration 32601, loss = 159.44849906\n",
      "Iteration 32602, loss = 159.43230856\n",
      "Iteration 32603, loss = 159.41611943\n",
      "Iteration 32604, loss = 159.39993168\n",
      "Iteration 32605, loss = 159.38374532\n",
      "Iteration 32606, loss = 159.36756037\n",
      "Iteration 32607, loss = 159.35137680\n",
      "Iteration 32608, loss = 159.33519461\n",
      "Iteration 32609, loss = 159.31901379\n",
      "Iteration 32610, loss = 159.30283437\n",
      "Iteration 32611, loss = 159.28665633\n",
      "Iteration 32612, loss = 159.27047969\n",
      "Iteration 32613, loss = 159.25430443\n",
      "Iteration 32614, loss = 159.23813054\n",
      "Iteration 32615, loss = 159.22195805\n",
      "Iteration 32616, loss = 159.20578693\n",
      "Iteration 32617, loss = 159.18961721\n",
      "Iteration 32618, loss = 159.17344887\n",
      "Iteration 32619, loss = 159.15728192\n",
      "Iteration 32620, loss = 159.14111635\n",
      "Iteration 32621, loss = 159.12495216\n",
      "Iteration 32622, loss = 159.10878935\n",
      "Iteration 32623, loss = 159.09262794\n",
      "Iteration 32624, loss = 159.07646790\n",
      "Iteration 32625, loss = 159.06030925\n",
      "Iteration 32626, loss = 159.04415198\n",
      "Iteration 32627, loss = 159.02799609\n",
      "Iteration 32628, loss = 159.01184159\n",
      "Iteration 32629, loss = 158.99568848\n",
      "Iteration 32630, loss = 158.97953674\n",
      "Iteration 32631, loss = 158.96338639\n",
      "Iteration 32632, loss = 158.94723742\n",
      "Iteration 32633, loss = 158.93108983\n",
      "Iteration 32634, loss = 158.91494362\n",
      "Iteration 32635, loss = 158.89879880\n",
      "Iteration 32636, loss = 158.88265536\n",
      "Iteration 32637, loss = 158.86651330\n",
      "Iteration 32638, loss = 158.85037263\n",
      "Iteration 32639, loss = 158.83423333\n",
      "Iteration 32640, loss = 158.81809542\n",
      "Iteration 32641, loss = 158.80195889\n",
      "Iteration 32642, loss = 158.78582374\n",
      "Iteration 32643, loss = 158.76968997\n",
      "Iteration 32644, loss = 158.75355758\n",
      "Iteration 32645, loss = 158.73742658\n",
      "Iteration 32646, loss = 158.72129695\n",
      "Iteration 32647, loss = 158.70516872\n",
      "Iteration 32648, loss = 158.68904186\n",
      "Iteration 32649, loss = 158.67291640\n",
      "Iteration 32650, loss = 158.65679233\n",
      "Iteration 32651, loss = 158.64066966\n",
      "Iteration 32652, loss = 158.62454842\n",
      "Iteration 32653, loss = 158.60842864\n",
      "Iteration 32654, loss = 158.59231037\n",
      "Iteration 32655, loss = 158.57619373\n",
      "Iteration 32656, loss = 158.56007889\n",
      "Iteration 32657, loss = 158.54396620\n",
      "Iteration 32658, loss = 158.52785620\n",
      "Iteration 32659, loss = 158.51174981\n",
      "Iteration 32660, loss = 158.49564837\n",
      "Iteration 32661, loss = 158.47955332\n",
      "Iteration 32662, loss = 158.46346492\n",
      "Iteration 32663, loss = 158.44737904\n",
      "Iteration 32664, loss = 158.43128436\n",
      "Iteration 32665, loss = 158.41516744\n",
      "Iteration 32666, loss = 158.39903069\n",
      "Iteration 32667, loss = 158.38289940\n",
      "Iteration 32668, loss = 158.36679671\n",
      "Iteration 32669, loss = 158.35071795\n",
      "Iteration 32670, loss = 158.33463795\n",
      "Iteration 32671, loss = 158.31853750\n",
      "Iteration 32672, loss = 158.30242326\n",
      "Iteration 32673, loss = 158.28631890\n",
      "Iteration 32674, loss = 158.27023486\n",
      "Iteration 32675, loss = 158.25415768\n",
      "Iteration 32676, loss = 158.23806986\n",
      "Iteration 32677, loss = 158.22197150\n",
      "Iteration 32678, loss = 158.20587783\n",
      "Iteration 32679, loss = 158.18979743\n",
      "Iteration 32680, loss = 158.17372229\n",
      "Iteration 32681, loss = 158.15764099\n",
      "Iteration 32682, loss = 158.14155397\n",
      "Iteration 32683, loss = 158.12547097\n",
      "Iteration 32684, loss = 158.10939655\n",
      "Iteration 32685, loss = 158.09332506\n",
      "Iteration 32686, loss = 158.07724989\n",
      "Iteration 32687, loss = 158.06117240\n",
      "Iteration 32688, loss = 158.04509864\n",
      "Iteration 32689, loss = 158.02903048\n",
      "Iteration 32690, loss = 158.01296384\n",
      "Iteration 32691, loss = 157.99689529\n",
      "Iteration 32692, loss = 157.98082641\n",
      "Iteration 32693, loss = 157.96476079\n",
      "Iteration 32694, loss = 157.94869886\n",
      "Iteration 32695, loss = 157.93263795\n",
      "Iteration 32696, loss = 157.91657636\n",
      "Iteration 32697, loss = 157.90051547\n",
      "Iteration 32698, loss = 157.88445728\n",
      "Iteration 32699, loss = 157.86840169\n",
      "Iteration 32700, loss = 157.85234704\n",
      "Iteration 32701, loss = 157.83629255\n",
      "Iteration 32702, loss = 157.82023920\n",
      "Iteration 32703, loss = 157.80418808\n",
      "Iteration 32704, loss = 157.78813898\n",
      "Iteration 32705, loss = 157.77209091\n",
      "Iteration 32706, loss = 157.75604351\n",
      "Iteration 32707, loss = 157.73999740\n",
      "Iteration 32708, loss = 157.72395319\n",
      "Iteration 32709, loss = 157.70791071\n",
      "Iteration 32710, loss = 157.69186938\n",
      "Iteration 32711, loss = 157.67582901\n",
      "Iteration 32712, loss = 157.65978998\n",
      "Iteration 32713, loss = 157.64375263\n",
      "Iteration 32714, loss = 157.62771686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32715, loss = 157.61168234\n",
      "Iteration 32716, loss = 157.59564895\n",
      "Iteration 32717, loss = 157.57961689\n",
      "Iteration 32718, loss = 157.56358639\n",
      "Iteration 32719, loss = 157.54755739\n",
      "Iteration 32720, loss = 157.53152970\n",
      "Iteration 32721, loss = 157.51550324\n",
      "Iteration 32722, loss = 157.49947811\n",
      "Iteration 32723, loss = 157.48345445\n",
      "Iteration 32724, loss = 157.46743225\n",
      "Iteration 32725, loss = 157.45141140\n",
      "Iteration 32726, loss = 157.43539184\n",
      "Iteration 32727, loss = 157.41937362\n",
      "Iteration 32728, loss = 157.40335681\n",
      "Iteration 32729, loss = 157.38734143\n",
      "Iteration 32730, loss = 157.37132742\n",
      "Iteration 32731, loss = 157.35531474\n",
      "Iteration 32732, loss = 157.33930339\n",
      "Iteration 32733, loss = 157.32329344\n",
      "Iteration 32734, loss = 157.30728489\n",
      "Iteration 32735, loss = 157.29127772\n",
      "Iteration 32736, loss = 157.27527190\n",
      "Iteration 32737, loss = 157.25926743\n",
      "Iteration 32738, loss = 157.24326432\n",
      "Iteration 32739, loss = 157.22726261\n",
      "Iteration 32740, loss = 157.21126228\n",
      "Iteration 32741, loss = 157.19526331\n",
      "Iteration 32742, loss = 157.17926570\n",
      "Iteration 32743, loss = 157.16326945\n",
      "Iteration 32744, loss = 157.14727457\n",
      "Iteration 32745, loss = 157.13128108\n",
      "Iteration 32746, loss = 157.11528896\n",
      "Iteration 32747, loss = 157.09929820\n",
      "Iteration 32748, loss = 157.08330880\n",
      "Iteration 32749, loss = 157.06732077\n",
      "Iteration 32750, loss = 157.05133411\n",
      "Iteration 32751, loss = 157.03534883\n",
      "Iteration 32752, loss = 157.01936491\n",
      "Iteration 32753, loss = 157.00338236\n",
      "Iteration 32754, loss = 156.98740117\n",
      "Iteration 32755, loss = 156.97142135\n",
      "Iteration 32756, loss = 156.95544290\n",
      "Iteration 32757, loss = 156.93946582\n",
      "Iteration 32758, loss = 156.92349011\n",
      "Iteration 32759, loss = 156.90751576\n",
      "Iteration 32760, loss = 156.89154278\n",
      "Iteration 32761, loss = 156.87557117\n",
      "Iteration 32762, loss = 156.85960093\n",
      "Iteration 32763, loss = 156.84363205\n",
      "Iteration 32764, loss = 156.82766454\n",
      "Iteration 32765, loss = 156.81169840\n",
      "Iteration 32766, loss = 156.79573362\n",
      "Iteration 32767, loss = 156.77977021\n",
      "Iteration 32768, loss = 156.76380816\n",
      "Iteration 32769, loss = 156.74784748\n",
      "Iteration 32770, loss = 156.73188817\n",
      "Iteration 32771, loss = 156.71593023\n",
      "Iteration 32772, loss = 156.69997365\n",
      "Iteration 32773, loss = 156.68401843\n",
      "Iteration 32774, loss = 156.66806458\n",
      "Iteration 32775, loss = 156.65211210\n",
      "Iteration 32776, loss = 156.63616098\n",
      "Iteration 32777, loss = 156.62021123\n",
      "Iteration 32778, loss = 156.60426285\n",
      "Iteration 32779, loss = 156.58831582\n",
      "Iteration 32780, loss = 156.57237017\n",
      "Iteration 32781, loss = 156.55642588\n",
      "Iteration 32782, loss = 156.54048295\n",
      "Iteration 32783, loss = 156.52454139\n",
      "Iteration 32784, loss = 156.50860119\n",
      "Iteration 32785, loss = 156.49266236\n",
      "Iteration 32786, loss = 156.47672489\n",
      "Iteration 32787, loss = 156.46078879\n",
      "Iteration 32788, loss = 156.44485405\n",
      "Iteration 32789, loss = 156.42892068\n",
      "Iteration 32790, loss = 156.41298867\n",
      "Iteration 32791, loss = 156.39705802\n",
      "Iteration 32792, loss = 156.38112874\n",
      "Iteration 32793, loss = 156.36520082\n",
      "Iteration 32794, loss = 156.34927426\n",
      "Iteration 32795, loss = 156.33334907\n",
      "Iteration 32796, loss = 156.31742524\n",
      "Iteration 32797, loss = 156.30150278\n",
      "Iteration 32798, loss = 156.28558168\n",
      "Iteration 32799, loss = 156.26966194\n",
      "Iteration 32800, loss = 156.25374356\n",
      "Iteration 32801, loss = 156.23782655\n",
      "Iteration 32802, loss = 156.22191090\n",
      "Iteration 32803, loss = 156.20599661\n",
      "Iteration 32804, loss = 156.19008369\n",
      "Iteration 32805, loss = 156.17417213\n",
      "Iteration 32806, loss = 156.15826193\n",
      "Iteration 32807, loss = 156.14235309\n",
      "Iteration 32808, loss = 156.12644561\n",
      "Iteration 32809, loss = 156.11053950\n",
      "Iteration 32810, loss = 156.09463475\n",
      "Iteration 32811, loss = 156.07873136\n",
      "Iteration 32812, loss = 156.06282933\n",
      "Iteration 32813, loss = 156.04692867\n",
      "Iteration 32814, loss = 156.03102937\n",
      "Iteration 32815, loss = 156.01513142\n",
      "Iteration 32816, loss = 155.99923484\n",
      "Iteration 32817, loss = 155.98333962\n",
      "Iteration 32818, loss = 155.96744576\n",
      "Iteration 32819, loss = 155.95155327\n",
      "Iteration 32820, loss = 155.93566213\n",
      "Iteration 32821, loss = 155.91977236\n",
      "Iteration 32822, loss = 155.90388394\n",
      "Iteration 32823, loss = 155.88799689\n",
      "Iteration 32824, loss = 155.87211119\n",
      "Iteration 32825, loss = 155.85622686\n",
      "Iteration 32826, loss = 155.84034389\n",
      "Iteration 32827, loss = 155.82446228\n",
      "Iteration 32828, loss = 155.80858203\n",
      "Iteration 32829, loss = 155.79270313\n",
      "Iteration 32830, loss = 155.77682560\n",
      "Iteration 32831, loss = 155.76094943\n",
      "Iteration 32832, loss = 155.74507462\n",
      "Iteration 32833, loss = 155.72920117\n",
      "Iteration 32834, loss = 155.71332908\n",
      "Iteration 32835, loss = 155.69745834\n",
      "Iteration 32836, loss = 155.68158897\n",
      "Iteration 32837, loss = 155.66572095\n",
      "Iteration 32838, loss = 155.64985430\n",
      "Iteration 32839, loss = 155.63398900\n",
      "Iteration 32840, loss = 155.61812507\n",
      "Iteration 32841, loss = 155.60226249\n",
      "Iteration 32842, loss = 155.58640127\n",
      "Iteration 32843, loss = 155.57054141\n",
      "Iteration 32844, loss = 155.55468291\n",
      "Iteration 32845, loss = 155.53882577\n",
      "Iteration 32846, loss = 155.52296998\n",
      "Iteration 32847, loss = 155.50711555\n",
      "Iteration 32848, loss = 155.49126249\n",
      "Iteration 32849, loss = 155.47541078\n",
      "Iteration 32850, loss = 155.45956043\n",
      "Iteration 32851, loss = 155.44371143\n",
      "Iteration 32852, loss = 155.42786380\n",
      "Iteration 32853, loss = 155.41201752\n",
      "Iteration 32854, loss = 155.39617260\n",
      "Iteration 32855, loss = 155.38032904\n",
      "Iteration 32856, loss = 155.36448683\n",
      "Iteration 32857, loss = 155.34864598\n",
      "Iteration 32858, loss = 155.33280649\n",
      "Iteration 32859, loss = 155.31696836\n",
      "Iteration 32860, loss = 155.30113158\n",
      "Iteration 32861, loss = 155.28529616\n",
      "Iteration 32862, loss = 155.26946210\n",
      "Iteration 32863, loss = 155.25362940\n",
      "Iteration 32864, loss = 155.23779805\n",
      "Iteration 32865, loss = 155.22196806\n",
      "Iteration 32866, loss = 155.20613942\n",
      "Iteration 32867, loss = 155.19031214\n",
      "Iteration 32868, loss = 155.17448622\n",
      "Iteration 32869, loss = 155.15866165\n",
      "Iteration 32870, loss = 155.14283844\n",
      "Iteration 32871, loss = 155.12701659\n",
      "Iteration 32872, loss = 155.11119609\n",
      "Iteration 32873, loss = 155.09537695\n",
      "Iteration 32874, loss = 155.07955916\n",
      "Iteration 32875, loss = 155.06374273\n",
      "Iteration 32876, loss = 155.04792766\n",
      "Iteration 32877, loss = 155.03211394\n",
      "Iteration 32878, loss = 155.01630157\n",
      "Iteration 32879, loss = 155.00049056\n",
      "Iteration 32880, loss = 154.98468091\n",
      "Iteration 32881, loss = 154.96887261\n",
      "Iteration 32882, loss = 154.95306567\n",
      "Iteration 32883, loss = 154.93726008\n",
      "Iteration 32884, loss = 154.92145585\n",
      "Iteration 32885, loss = 154.90565297\n",
      "Iteration 32886, loss = 154.88985145\n",
      "Iteration 32887, loss = 154.87405128\n",
      "Iteration 32888, loss = 154.85825246\n",
      "Iteration 32889, loss = 154.84245500\n",
      "Iteration 32890, loss = 154.82665890\n",
      "Iteration 32891, loss = 154.81086414\n",
      "Iteration 32892, loss = 154.79507075\n",
      "Iteration 32893, loss = 154.77927870\n",
      "Iteration 32894, loss = 154.76348801\n",
      "Iteration 32895, loss = 154.74769868\n",
      "Iteration 32896, loss = 154.73191070\n",
      "Iteration 32897, loss = 154.71612407\n",
      "Iteration 32898, loss = 154.70033880\n",
      "Iteration 32899, loss = 154.68455488\n",
      "Iteration 32900, loss = 154.66877231\n",
      "Iteration 32901, loss = 154.65299110\n",
      "Iteration 32902, loss = 154.63721124\n",
      "Iteration 32903, loss = 154.62143275\n",
      "Iteration 32904, loss = 154.60565561\n",
      "Iteration 32905, loss = 154.58987983\n",
      "Iteration 32906, loss = 154.57410544\n",
      "Iteration 32907, loss = 154.55833243\n",
      "Iteration 32908, loss = 154.54256085\n",
      "Iteration 32909, loss = 154.52679074\n",
      "Iteration 32910, loss = 154.51102220\n",
      "Iteration 32911, loss = 154.49525537\n",
      "Iteration 32912, loss = 154.47949049\n",
      "Iteration 32913, loss = 154.46372773\n",
      "Iteration 32914, loss = 154.44796726\n",
      "Iteration 32915, loss = 154.43220818\n",
      "Iteration 32916, loss = 154.41644904\n",
      "Iteration 32917, loss = 154.40068719\n",
      "Iteration 32918, loss = 154.38492341\n",
      "Iteration 32919, loss = 154.36916155\n",
      "Iteration 32920, loss = 154.35340548\n",
      "Iteration 32921, loss = 154.33765444\n",
      "Iteration 32922, loss = 154.32190426\n",
      "Iteration 32923, loss = 154.30615193\n",
      "Iteration 32924, loss = 154.29039848\n",
      "Iteration 32925, loss = 154.27464787\n",
      "Iteration 32926, loss = 154.25890169\n",
      "Iteration 32927, loss = 154.24315762\n",
      "Iteration 32928, loss = 154.22741288\n",
      "Iteration 32929, loss = 154.21166762\n",
      "Iteration 32930, loss = 154.19592443\n",
      "Iteration 32931, loss = 154.18018454\n",
      "Iteration 32932, loss = 154.16444644\n",
      "Iteration 32933, loss = 154.14870838\n",
      "Iteration 32934, loss = 154.13297064\n",
      "Iteration 32935, loss = 154.11723491\n",
      "Iteration 32936, loss = 154.10150173\n",
      "Iteration 32937, loss = 154.08577003\n",
      "Iteration 32938, loss = 154.07003891\n",
      "Iteration 32939, loss = 154.05430895\n",
      "Iteration 32940, loss = 154.03858132\n",
      "Iteration 32941, loss = 154.02285639\n",
      "Iteration 32942, loss = 154.00713388\n",
      "Iteration 32943, loss = 153.99141418\n",
      "Iteration 32944, loss = 153.97569886\n",
      "Iteration 32945, loss = 153.95998958\n",
      "Iteration 32946, loss = 153.94428633\n",
      "Iteration 32947, loss = 153.92858525\n",
      "Iteration 32948, loss = 153.91287733\n",
      "Iteration 32949, loss = 153.89715158\n",
      "Iteration 32950, loss = 153.88140790\n",
      "Iteration 32951, loss = 153.86566458\n",
      "Iteration 32952, loss = 153.84994289\n",
      "Iteration 32953, loss = 153.83424478\n",
      "Iteration 32954, loss = 153.81855262\n",
      "Iteration 32955, loss = 153.80284720\n",
      "Iteration 32956, loss = 153.78712576\n",
      "Iteration 32957, loss = 153.77140435\n",
      "Iteration 32958, loss = 153.75569856\n",
      "Iteration 32959, loss = 153.74000601\n",
      "Iteration 32960, loss = 153.72431184\n",
      "Iteration 32961, loss = 153.70860706\n",
      "Iteration 32962, loss = 153.69289796\n",
      "Iteration 32963, loss = 153.67719660\n",
      "Iteration 32964, loss = 153.66150549\n",
      "Iteration 32965, loss = 153.64581626\n",
      "Iteration 32966, loss = 153.63012151\n",
      "Iteration 32967, loss = 153.61442344\n",
      "Iteration 32968, loss = 153.59872959\n",
      "Iteration 32969, loss = 153.58304270\n",
      "Iteration 32970, loss = 153.56735825\n",
      "Iteration 32971, loss = 153.55167128\n",
      "Iteration 32972, loss = 153.53598250\n",
      "Iteration 32973, loss = 153.52029638\n",
      "Iteration 32974, loss = 153.50461499\n",
      "Iteration 32975, loss = 153.48893592\n",
      "Iteration 32976, loss = 153.47325606\n",
      "Iteration 32977, loss = 153.45757552\n",
      "Iteration 32978, loss = 153.44189686\n",
      "Iteration 32979, loss = 153.42622154\n",
      "Iteration 32980, loss = 153.41054835\n",
      "Iteration 32981, loss = 153.39487537\n",
      "Iteration 32982, loss = 153.37920245\n",
      "Iteration 32983, loss = 153.36353101\n",
      "Iteration 32984, loss = 153.34786206\n",
      "Iteration 32985, loss = 153.33219505\n",
      "Iteration 32986, loss = 153.31652886\n",
      "Iteration 32987, loss = 153.30086320\n",
      "Iteration 32988, loss = 153.28519881\n",
      "Iteration 32989, loss = 153.26953639\n",
      "Iteration 32990, loss = 153.25387578\n",
      "Iteration 32991, loss = 153.23821631\n",
      "Iteration 32992, loss = 153.22255769\n",
      "Iteration 32993, loss = 153.20690026\n",
      "Iteration 32994, loss = 153.19124448\n",
      "Iteration 32995, loss = 153.17559037\n",
      "Iteration 32996, loss = 153.15993758\n",
      "Iteration 32997, loss = 153.14428587\n",
      "Iteration 32998, loss = 153.12863533\n",
      "Iteration 32999, loss = 153.11298625\n",
      "Iteration 33000, loss = 153.09733873\n",
      "Iteration 33001, loss = 153.08169261\n",
      "Iteration 33002, loss = 153.06604771\n",
      "Iteration 33003, loss = 153.05040402\n",
      "Iteration 33004, loss = 153.03476168\n",
      "Iteration 33005, loss = 153.01912080\n",
      "Iteration 33006, loss = 153.00348134\n",
      "Iteration 33007, loss = 152.98784319\n",
      "Iteration 33008, loss = 152.97220631\n",
      "Iteration 33009, loss = 152.95657072\n",
      "Iteration 33010, loss = 152.94093653\n",
      "Iteration 33011, loss = 152.92530374\n",
      "Iteration 33012, loss = 152.90967231\n",
      "Iteration 33013, loss = 152.89404218\n",
      "Iteration 33014, loss = 152.87841336\n",
      "Iteration 33015, loss = 152.86278588\n",
      "Iteration 33016, loss = 152.84715978\n",
      "Iteration 33017, loss = 152.83153505\n",
      "Iteration 33018, loss = 152.81591166\n",
      "Iteration 33019, loss = 152.80028958\n",
      "Iteration 33020, loss = 152.78466883\n",
      "Iteration 33021, loss = 152.76904944\n",
      "Iteration 33022, loss = 152.75343140\n",
      "Iteration 33023, loss = 152.73781472\n",
      "Iteration 33024, loss = 152.72219938\n",
      "Iteration 33025, loss = 152.70658536\n",
      "Iteration 33026, loss = 152.69097268\n",
      "Iteration 33027, loss = 152.67536135\n",
      "Iteration 33028, loss = 152.65975137\n",
      "Iteration 33029, loss = 152.64414274\n",
      "Iteration 33030, loss = 152.62853545\n",
      "Iteration 33031, loss = 152.61292949\n",
      "Iteration 33032, loss = 152.59732488\n",
      "Iteration 33033, loss = 152.58172160\n",
      "Iteration 33034, loss = 152.56611968\n",
      "Iteration 33035, loss = 152.55051910\n",
      "Iteration 33036, loss = 152.53491986\n",
      "Iteration 33037, loss = 152.51932196\n",
      "Iteration 33038, loss = 152.50372540\n",
      "Iteration 33039, loss = 152.48813018\n",
      "Iteration 33040, loss = 152.47253631\n",
      "Iteration 33041, loss = 152.45694378\n",
      "Iteration 33042, loss = 152.44135259\n",
      "Iteration 33043, loss = 152.42576274\n",
      "Iteration 33044, loss = 152.41017423\n",
      "Iteration 33045, loss = 152.39458707\n",
      "Iteration 33046, loss = 152.37900124\n",
      "Iteration 33047, loss = 152.36341676\n",
      "Iteration 33048, loss = 152.34783362\n",
      "Iteration 33049, loss = 152.33225182\n",
      "Iteration 33050, loss = 152.31667136\n",
      "Iteration 33051, loss = 152.30109224\n",
      "Iteration 33052, loss = 152.28551446\n",
      "Iteration 33053, loss = 152.26993803\n",
      "Iteration 33054, loss = 152.25436293\n",
      "Iteration 33055, loss = 152.23878918\n",
      "Iteration 33056, loss = 152.22321676\n",
      "Iteration 33057, loss = 152.20764569\n",
      "Iteration 33058, loss = 152.19207595\n",
      "Iteration 33059, loss = 152.17650756\n",
      "Iteration 33060, loss = 152.16094051\n",
      "Iteration 33061, loss = 152.14537480\n",
      "Iteration 33062, loss = 152.12981042\n",
      "Iteration 33063, loss = 152.11424739\n",
      "Iteration 33064, loss = 152.09868570\n",
      "Iteration 33065, loss = 152.08312535\n",
      "Iteration 33066, loss = 152.06756634\n",
      "Iteration 33067, loss = 152.05200866\n",
      "Iteration 33068, loss = 152.03645233\n",
      "Iteration 33069, loss = 152.02089734\n",
      "Iteration 33070, loss = 152.00534368\n",
      "Iteration 33071, loss = 151.98979137\n",
      "Iteration 33072, loss = 151.97424040\n",
      "Iteration 33073, loss = 151.95869076\n",
      "Iteration 33074, loss = 151.94314247\n",
      "Iteration 33075, loss = 151.92759551\n",
      "Iteration 33076, loss = 151.91204989\n",
      "Iteration 33077, loss = 151.89650561\n",
      "Iteration 33078, loss = 151.88096267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33079, loss = 151.86542107\n",
      "Iteration 33080, loss = 151.84988081\n",
      "Iteration 33081, loss = 151.83434189\n",
      "Iteration 33082, loss = 151.81880431\n",
      "Iteration 33083, loss = 151.80326806\n",
      "Iteration 33084, loss = 151.78773315\n",
      "Iteration 33085, loss = 151.77219958\n",
      "Iteration 33086, loss = 151.75666735\n",
      "Iteration 33087, loss = 151.74113646\n",
      "Iteration 33088, loss = 151.72560691\n",
      "Iteration 33089, loss = 151.71007870\n",
      "Iteration 33090, loss = 151.69455182\n",
      "Iteration 33091, loss = 151.67902628\n",
      "Iteration 33092, loss = 151.66350208\n",
      "Iteration 33093, loss = 151.64797922\n",
      "Iteration 33094, loss = 151.63245769\n",
      "Iteration 33095, loss = 151.61693750\n",
      "Iteration 33096, loss = 151.60141865\n",
      "Iteration 33097, loss = 151.58590114\n",
      "Iteration 33098, loss = 151.57038497\n",
      "Iteration 33099, loss = 151.55487013\n",
      "Iteration 33100, loss = 151.53935663\n",
      "Iteration 33101, loss = 151.52384447\n",
      "Iteration 33102, loss = 151.50833364\n",
      "Iteration 33103, loss = 151.49282416\n",
      "Iteration 33104, loss = 151.47731601\n",
      "Iteration 33105, loss = 151.46180919\n",
      "Iteration 33106, loss = 151.44630372\n",
      "Iteration 33107, loss = 151.43079958\n",
      "Iteration 33108, loss = 151.41529677\n",
      "Iteration 33109, loss = 151.39979531\n",
      "Iteration 33110, loss = 151.38429518\n",
      "Iteration 33111, loss = 151.36879638\n",
      "Iteration 33112, loss = 151.35329893\n",
      "Iteration 33113, loss = 151.33780281\n",
      "Iteration 33114, loss = 151.32230803\n",
      "Iteration 33115, loss = 151.30681458\n",
      "Iteration 33116, loss = 151.29132247\n",
      "Iteration 33117, loss = 151.27583169\n",
      "Iteration 33118, loss = 151.26034226\n",
      "Iteration 33119, loss = 151.24485415\n",
      "Iteration 33120, loss = 151.22936739\n",
      "Iteration 33121, loss = 151.21388196\n",
      "Iteration 33122, loss = 151.19839786\n",
      "Iteration 33123, loss = 151.18291510\n",
      "Iteration 33124, loss = 151.16743368\n",
      "Iteration 33125, loss = 151.15195359\n",
      "Iteration 33126, loss = 151.13647484\n",
      "Iteration 33127, loss = 151.12099743\n",
      "Iteration 33128, loss = 151.10552135\n",
      "Iteration 33129, loss = 151.09004660\n",
      "Iteration 33130, loss = 151.07457319\n",
      "Iteration 33131, loss = 151.05910112\n",
      "Iteration 33132, loss = 151.04363038\n",
      "Iteration 33133, loss = 151.02816097\n",
      "Iteration 33134, loss = 151.01269290\n",
      "Iteration 33135, loss = 150.99722617\n",
      "Iteration 33136, loss = 150.98176077\n",
      "Iteration 33137, loss = 150.96629670\n",
      "Iteration 33138, loss = 150.95083397\n",
      "Iteration 33139, loss = 150.93537258\n",
      "Iteration 33140, loss = 150.91991252\n",
      "Iteration 33141, loss = 150.90445379\n",
      "Iteration 33142, loss = 150.88899640\n",
      "Iteration 33143, loss = 150.87354034\n",
      "Iteration 33144, loss = 150.85808562\n",
      "Iteration 33145, loss = 150.84263223\n",
      "Iteration 33146, loss = 150.82718017\n",
      "Iteration 33147, loss = 150.81172945\n",
      "Iteration 33148, loss = 150.79628007\n",
      "Iteration 33149, loss = 150.78083201\n",
      "Iteration 33150, loss = 150.76538530\n",
      "Iteration 33151, loss = 150.74993991\n",
      "Iteration 33152, loss = 150.73449586\n",
      "Iteration 33153, loss = 150.71905314\n",
      "Iteration 33154, loss = 150.70361176\n",
      "Iteration 33155, loss = 150.68817171\n",
      "Iteration 33156, loss = 150.67273299\n",
      "Iteration 33157, loss = 150.65729561\n",
      "Iteration 33158, loss = 150.64185956\n",
      "Iteration 33159, loss = 150.62642485\n",
      "Iteration 33160, loss = 150.61099146\n",
      "Iteration 33161, loss = 150.59555941\n",
      "Iteration 33162, loss = 150.58012870\n",
      "Iteration 33163, loss = 150.56469931\n",
      "Iteration 33164, loss = 150.54927126\n",
      "Iteration 33165, loss = 150.53384454\n",
      "Iteration 33166, loss = 150.51841916\n",
      "Iteration 33167, loss = 150.50299511\n",
      "Iteration 33168, loss = 150.48757239\n",
      "Iteration 33169, loss = 150.47215100\n",
      "Iteration 33170, loss = 150.45673095\n",
      "Iteration 33171, loss = 150.44131222\n",
      "Iteration 33172, loss = 150.42589484\n",
      "Iteration 33173, loss = 150.41047878\n",
      "Iteration 33174, loss = 150.39506405\n",
      "Iteration 33175, loss = 150.37965066\n",
      "Iteration 33176, loss = 150.36423860\n",
      "Iteration 33177, loss = 150.34882787\n",
      "Iteration 33178, loss = 150.33341848\n",
      "Iteration 33179, loss = 150.31801041\n",
      "Iteration 33180, loss = 150.30260368\n",
      "Iteration 33181, loss = 150.28719828\n",
      "Iteration 33182, loss = 150.27179421\n",
      "Iteration 33183, loss = 150.25639148\n",
      "Iteration 33184, loss = 150.24099007\n",
      "Iteration 33185, loss = 150.22559000\n",
      "Iteration 33186, loss = 150.21019125\n",
      "Iteration 33187, loss = 150.19479384\n",
      "Iteration 33188, loss = 150.17939777\n",
      "Iteration 33189, loss = 150.16400302\n",
      "Iteration 33190, loss = 150.14860960\n",
      "Iteration 33191, loss = 150.13321752\n",
      "Iteration 33192, loss = 150.11782676\n",
      "Iteration 33193, loss = 150.10243734\n",
      "Iteration 33194, loss = 150.08704925\n",
      "Iteration 33195, loss = 150.07166250\n",
      "Iteration 33196, loss = 150.05627707\n",
      "Iteration 33197, loss = 150.04089299\n",
      "Iteration 33198, loss = 150.02551024\n",
      "Iteration 33199, loss = 150.01012884\n",
      "Iteration 33200, loss = 149.99474879\n",
      "Iteration 33201, loss = 149.97937013\n",
      "Iteration 33202, loss = 149.96399287\n",
      "Iteration 33203, loss = 149.94861709\n",
      "Iteration 33204, loss = 149.93324289\n",
      "Iteration 33205, loss = 149.91787046\n",
      "Iteration 33206, loss = 149.90250015\n",
      "Iteration 33207, loss = 149.88713253\n",
      "Iteration 33208, loss = 149.87176852\n",
      "Iteration 33209, loss = 149.85640951\n",
      "Iteration 33210, loss = 149.84105696\n",
      "Iteration 33211, loss = 149.82571127\n",
      "Iteration 33212, loss = 149.81036836\n",
      "Iteration 33213, loss = 149.79501693\n",
      "Iteration 33214, loss = 149.77964267\n",
      "Iteration 33215, loss = 149.76424693\n",
      "Iteration 33216, loss = 149.74885508\n",
      "Iteration 33217, loss = 149.73349227\n",
      "Iteration 33218, loss = 149.71815537\n",
      "Iteration 33219, loss = 149.70281867\n",
      "Iteration 33220, loss = 149.68746115\n",
      "Iteration 33221, loss = 149.67208794\n",
      "Iteration 33222, loss = 149.65672342\n",
      "Iteration 33223, loss = 149.64138008\n",
      "Iteration 33224, loss = 149.62604518\n",
      "Iteration 33225, loss = 149.61069992\n",
      "Iteration 33226, loss = 149.59534287\n",
      "Iteration 33227, loss = 149.57998940\n",
      "Iteration 33228, loss = 149.56464961\n",
      "Iteration 33229, loss = 149.54931619\n",
      "Iteration 33230, loss = 149.53397686\n",
      "Iteration 33231, loss = 149.51863092\n",
      "Iteration 33232, loss = 149.50328824\n",
      "Iteration 33233, loss = 149.48795447\n",
      "Iteration 33234, loss = 149.47262433\n",
      "Iteration 33235, loss = 149.45729060\n",
      "Iteration 33236, loss = 149.44195390\n",
      "Iteration 33237, loss = 149.42662048\n",
      "Iteration 33238, loss = 149.41129291\n",
      "Iteration 33239, loss = 149.39596731\n",
      "Iteration 33240, loss = 149.38063976\n",
      "Iteration 33241, loss = 149.36531141\n",
      "Iteration 33242, loss = 149.34998606\n",
      "Iteration 33243, loss = 149.33466461\n",
      "Iteration 33244, loss = 149.31934441\n",
      "Iteration 33245, loss = 149.30402347\n",
      "Iteration 33246, loss = 149.28870288\n",
      "Iteration 33247, loss = 149.27338485\n",
      "Iteration 33248, loss = 149.25806955\n",
      "Iteration 33249, loss = 149.24275533\n",
      "Iteration 33250, loss = 149.22744117\n",
      "Iteration 33251, loss = 149.21212791\n",
      "Iteration 33252, loss = 149.19681679\n",
      "Iteration 33253, loss = 149.18150777\n",
      "Iteration 33254, loss = 149.16619985\n",
      "Iteration 33255, loss = 149.15089251\n",
      "Iteration 33256, loss = 149.13558629\n",
      "Iteration 33257, loss = 149.12028189\n",
      "Iteration 33258, loss = 149.10497927\n",
      "Iteration 33259, loss = 149.08967782\n",
      "Iteration 33260, loss = 149.07437725\n",
      "Iteration 33261, loss = 149.05907790\n",
      "Iteration 33262, loss = 149.04378017\n",
      "Iteration 33263, loss = 149.02848402\n",
      "Iteration 33264, loss = 149.01318912\n",
      "Iteration 33265, loss = 148.99789530\n",
      "Iteration 33266, loss = 148.98260271\n",
      "Iteration 33267, loss = 148.96731161\n",
      "Iteration 33268, loss = 148.95202200\n",
      "Iteration 33269, loss = 148.93673369\n",
      "Iteration 33270, loss = 148.92144656\n",
      "Iteration 33271, loss = 148.90616069\n",
      "Iteration 33272, loss = 148.89087622\n",
      "Iteration 33273, loss = 148.87559318\n",
      "Iteration 33274, loss = 148.86031147\n",
      "Iteration 33275, loss = 148.84503101\n",
      "Iteration 33276, loss = 148.82975182\n",
      "Iteration 33277, loss = 148.81447399\n",
      "Iteration 33278, loss = 148.79919754\n",
      "Iteration 33279, loss = 148.78392244\n",
      "Iteration 33280, loss = 148.76864863\n",
      "Iteration 33281, loss = 148.75337610\n",
      "Iteration 33282, loss = 148.73810490\n",
      "Iteration 33283, loss = 148.72283506\n",
      "Iteration 33284, loss = 148.70756657\n",
      "Iteration 33285, loss = 148.69229939\n",
      "Iteration 33286, loss = 148.67703351\n",
      "Iteration 33287, loss = 148.66176895\n",
      "Iteration 33288, loss = 148.64650573\n",
      "Iteration 33289, loss = 148.63124385\n",
      "Iteration 33290, loss = 148.61598330\n",
      "Iteration 33291, loss = 148.60072406\n",
      "Iteration 33292, loss = 148.58546614\n",
      "Iteration 33293, loss = 148.57020956\n",
      "Iteration 33294, loss = 148.55495431\n",
      "Iteration 33295, loss = 148.53970041\n",
      "Iteration 33296, loss = 148.52444785\n",
      "Iteration 33297, loss = 148.50919664\n",
      "Iteration 33298, loss = 148.49394679\n",
      "Iteration 33299, loss = 148.47869834\n",
      "Iteration 33300, loss = 148.46345132\n",
      "Iteration 33301, loss = 148.44820580\n",
      "Iteration 33302, loss = 148.43296179\n",
      "Iteration 33303, loss = 148.41771939\n",
      "Iteration 33304, loss = 148.40247856\n",
      "Iteration 33305, loss = 148.38723922\n",
      "Iteration 33306, loss = 148.37200089\n",
      "Iteration 33307, loss = 148.35676313\n",
      "Iteration 33308, loss = 148.34152528\n",
      "Iteration 33309, loss = 148.32628771\n",
      "Iteration 33310, loss = 148.31105136\n",
      "Iteration 33311, loss = 148.29581743\n",
      "Iteration 33312, loss = 148.28058630\n",
      "Iteration 33313, loss = 148.26535737\n",
      "Iteration 33314, loss = 148.25012961\n",
      "Iteration 33315, loss = 148.23490221\n",
      "Iteration 33316, loss = 148.21967519\n",
      "Iteration 33317, loss = 148.20444924\n",
      "Iteration 33318, loss = 148.18922520\n",
      "Iteration 33319, loss = 148.17400331\n",
      "Iteration 33320, loss = 148.15878312\n",
      "Iteration 33321, loss = 148.14356400\n",
      "Iteration 33322, loss = 148.12834561\n",
      "Iteration 33323, loss = 148.11312816\n",
      "Iteration 33324, loss = 148.09791215\n",
      "Iteration 33325, loss = 148.08269790\n",
      "Iteration 33326, loss = 148.06748531\n",
      "Iteration 33327, loss = 148.05227402\n",
      "Iteration 33328, loss = 148.03706377\n",
      "Iteration 33329, loss = 148.02185458\n",
      "Iteration 33330, loss = 148.00664668\n",
      "Iteration 33331, loss = 147.99144031\n",
      "Iteration 33332, loss = 147.97623547\n",
      "Iteration 33333, loss = 147.96103200\n",
      "Iteration 33334, loss = 147.94582974\n",
      "Iteration 33335, loss = 147.93062863\n",
      "Iteration 33336, loss = 147.91542880\n",
      "Iteration 33337, loss = 147.90023037\n",
      "Iteration 33338, loss = 147.88503337\n",
      "Iteration 33339, loss = 147.86983776\n",
      "Iteration 33340, loss = 147.85464343\n",
      "Iteration 33341, loss = 147.83945033\n",
      "Iteration 33342, loss = 147.82425851\n",
      "Iteration 33343, loss = 147.80906802\n",
      "Iteration 33344, loss = 147.79387892\n",
      "Iteration 33345, loss = 147.77869119\n",
      "Iteration 33346, loss = 147.76350477\n",
      "Iteration 33347, loss = 147.74831964\n",
      "Iteration 33348, loss = 147.73313579\n",
      "Iteration 33349, loss = 147.71795326\n",
      "Iteration 33350, loss = 147.70277207\n",
      "Iteration 33351, loss = 147.68759224\n",
      "Iteration 33352, loss = 147.67241374\n",
      "Iteration 33353, loss = 147.65723654\n",
      "Iteration 33354, loss = 147.64206065\n",
      "Iteration 33355, loss = 147.62688606\n",
      "Iteration 33356, loss = 147.61171280\n",
      "Iteration 33357, loss = 147.59654088\n",
      "Iteration 33358, loss = 147.58137029\n",
      "Iteration 33359, loss = 147.56620102\n",
      "Iteration 33360, loss = 147.55103306\n",
      "Iteration 33361, loss = 147.53586641\n",
      "Iteration 33362, loss = 147.52070108\n",
      "Iteration 33363, loss = 147.50553708\n",
      "Iteration 33364, loss = 147.49037440\n",
      "Iteration 33365, loss = 147.47521305\n",
      "Iteration 33366, loss = 147.46005302\n",
      "Iteration 33367, loss = 147.44489430\n",
      "Iteration 33368, loss = 147.42973690\n",
      "Iteration 33369, loss = 147.41458082\n",
      "Iteration 33370, loss = 147.39942606\n",
      "Iteration 33371, loss = 147.38427263\n",
      "Iteration 33372, loss = 147.36912051\n",
      "Iteration 33373, loss = 147.35396972\n",
      "Iteration 33374, loss = 147.33882024\n",
      "Iteration 33375, loss = 147.32367209\n",
      "Iteration 33376, loss = 147.30852525\n",
      "Iteration 33377, loss = 147.29337973\n",
      "Iteration 33378, loss = 147.27823553\n",
      "Iteration 33379, loss = 147.26309266\n",
      "Iteration 33380, loss = 147.24795110\n",
      "Iteration 33381, loss = 147.23281086\n",
      "Iteration 33382, loss = 147.21767194\n",
      "Iteration 33383, loss = 147.20253434\n",
      "Iteration 33384, loss = 147.18739806\n",
      "Iteration 33385, loss = 147.17226310\n",
      "Iteration 33386, loss = 147.15712946\n",
      "Iteration 33387, loss = 147.14199713\n",
      "Iteration 33388, loss = 147.12686613\n",
      "Iteration 33389, loss = 147.11173645\n",
      "Iteration 33390, loss = 147.09660808\n",
      "Iteration 33391, loss = 147.08148103\n",
      "Iteration 33392, loss = 147.06635531\n",
      "Iteration 33393, loss = 147.05123090\n",
      "Iteration 33394, loss = 147.03610781\n",
      "Iteration 33395, loss = 147.02098604\n",
      "Iteration 33396, loss = 147.00586558\n",
      "Iteration 33397, loss = 146.99074645\n",
      "Iteration 33398, loss = 146.97562863\n",
      "Iteration 33399, loss = 146.96051213\n",
      "Iteration 33400, loss = 146.94539695\n",
      "Iteration 33401, loss = 146.93028309\n",
      "Iteration 33402, loss = 146.91517055\n",
      "Iteration 33403, loss = 146.90005933\n",
      "Iteration 33404, loss = 146.88494942\n",
      "Iteration 33405, loss = 146.86984083\n",
      "Iteration 33406, loss = 146.85473356\n",
      "Iteration 33407, loss = 146.83962761\n",
      "Iteration 33408, loss = 146.82452298\n",
      "Iteration 33409, loss = 146.80941966\n",
      "Iteration 33410, loss = 146.79431766\n",
      "Iteration 33411, loss = 146.77921698\n",
      "Iteration 33412, loss = 146.76411762\n",
      "Iteration 33413, loss = 146.74901957\n",
      "Iteration 33414, loss = 146.73392285\n",
      "Iteration 33415, loss = 146.71882744\n",
      "Iteration 33416, loss = 146.70373334\n",
      "Iteration 33417, loss = 146.68864057\n",
      "Iteration 33418, loss = 146.67354911\n",
      "Iteration 33419, loss = 146.65845897\n",
      "Iteration 33420, loss = 146.64337015\n",
      "Iteration 33421, loss = 146.62828264\n",
      "Iteration 33422, loss = 146.61319645\n",
      "Iteration 33423, loss = 146.59811158\n",
      "Iteration 33424, loss = 146.58302802\n",
      "Iteration 33425, loss = 146.56794578\n",
      "Iteration 33426, loss = 146.55286486\n",
      "Iteration 33427, loss = 146.53778526\n",
      "Iteration 33428, loss = 146.52270697\n",
      "Iteration 33429, loss = 146.50763000\n",
      "Iteration 33430, loss = 146.49255435\n",
      "Iteration 33431, loss = 146.47748001\n",
      "Iteration 33432, loss = 146.46240699\n",
      "Iteration 33433, loss = 146.44733528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33434, loss = 146.43226489\n",
      "Iteration 33435, loss = 146.41719582\n",
      "Iteration 33436, loss = 146.40212807\n",
      "Iteration 33437, loss = 146.38706163\n",
      "Iteration 33438, loss = 146.37199650\n",
      "Iteration 33439, loss = 146.35693270\n",
      "Iteration 33440, loss = 146.34187021\n",
      "Iteration 33441, loss = 146.32680903\n",
      "Iteration 33442, loss = 146.31174917\n",
      "Iteration 33443, loss = 146.29669063\n",
      "Iteration 33444, loss = 146.28163340\n",
      "Iteration 33445, loss = 146.26657749\n",
      "Iteration 33446, loss = 146.25152290\n",
      "Iteration 33447, loss = 146.23646962\n",
      "Iteration 33448, loss = 146.22141765\n",
      "Iteration 33449, loss = 146.20636700\n",
      "Iteration 33450, loss = 146.19131767\n",
      "Iteration 33451, loss = 146.17626965\n",
      "Iteration 33452, loss = 146.16122295\n",
      "Iteration 33453, loss = 146.14617756\n",
      "Iteration 33454, loss = 146.13113349\n",
      "Iteration 33455, loss = 146.11609074\n",
      "Iteration 33456, loss = 146.10104929\n",
      "Iteration 33457, loss = 146.08600917\n",
      "Iteration 33458, loss = 146.07097036\n",
      "Iteration 33459, loss = 146.05593286\n",
      "Iteration 33460, loss = 146.04089668\n",
      "Iteration 33461, loss = 146.02586181\n",
      "Iteration 33462, loss = 146.01082826\n",
      "Iteration 33463, loss = 145.99579603\n",
      "Iteration 33464, loss = 145.98076510\n",
      "Iteration 33465, loss = 145.96573550\n",
      "Iteration 33466, loss = 145.95070720\n",
      "Iteration 33467, loss = 145.93568023\n",
      "Iteration 33468, loss = 145.92065456\n",
      "Iteration 33469, loss = 145.90563021\n",
      "Iteration 33470, loss = 145.89060718\n",
      "Iteration 33471, loss = 145.87558546\n",
      "Iteration 33472, loss = 145.86056505\n",
      "Iteration 33473, loss = 145.84554596\n",
      "Iteration 33474, loss = 145.83052818\n",
      "Iteration 33475, loss = 145.81551172\n",
      "Iteration 33476, loss = 145.80049657\n",
      "Iteration 33477, loss = 145.78548273\n",
      "Iteration 33478, loss = 145.77047021\n",
      "Iteration 33479, loss = 145.75545901\n",
      "Iteration 33480, loss = 145.74044911\n",
      "Iteration 33481, loss = 145.72544054\n",
      "Iteration 33482, loss = 145.71043328\n",
      "Iteration 33483, loss = 145.69542734\n",
      "Iteration 33484, loss = 145.68042272\n",
      "Iteration 33485, loss = 145.66541944\n",
      "Iteration 33486, loss = 145.65041750\n",
      "Iteration 33487, loss = 145.63541694\n",
      "Iteration 33488, loss = 145.62041781\n",
      "Iteration 33489, loss = 145.60542021\n",
      "Iteration 33490, loss = 145.59042431\n",
      "Iteration 33491, loss = 145.57543045\n",
      "Iteration 33492, loss = 145.56043925\n",
      "Iteration 33493, loss = 145.54545176\n",
      "Iteration 33494, loss = 145.53046973\n",
      "Iteration 33495, loss = 145.51549546\n",
      "Iteration 33496, loss = 145.50053068\n",
      "Iteration 33497, loss = 145.48557203\n",
      "Iteration 33498, loss = 145.47060546\n",
      "Iteration 33499, loss = 145.45560851\n",
      "Iteration 33500, loss = 145.44057883\n",
      "Iteration 33501, loss = 145.42555271\n",
      "Iteration 33502, loss = 145.41056798\n",
      "Iteration 33503, loss = 145.39561688\n",
      "Iteration 33504, loss = 145.38065843\n",
      "Iteration 33505, loss = 145.36566676\n",
      "Iteration 33506, loss = 145.35066163\n",
      "Iteration 33507, loss = 145.33568024\n",
      "Iteration 33508, loss = 145.32072470\n",
      "Iteration 33509, loss = 145.30576439\n",
      "Iteration 33510, loss = 145.29078229\n",
      "Iteration 33511, loss = 145.27579660\n",
      "Iteration 33512, loss = 145.26082983\n",
      "Iteration 33513, loss = 145.24587542\n",
      "Iteration 33514, loss = 145.23091216\n",
      "Iteration 33515, loss = 145.21593760\n",
      "Iteration 33516, loss = 145.20096858\n",
      "Iteration 33517, loss = 145.18601273\n",
      "Iteration 33518, loss = 145.17105868\n",
      "Iteration 33519, loss = 145.15609653\n",
      "Iteration 33520, loss = 145.14113248\n",
      "Iteration 33521, loss = 145.12617653\n",
      "Iteration 33522, loss = 145.11122662\n",
      "Iteration 33523, loss = 145.09627399\n",
      "Iteration 33524, loss = 145.08131767\n",
      "Iteration 33525, loss = 145.06636456\n",
      "Iteration 33526, loss = 145.05141742\n",
      "Iteration 33527, loss = 145.03647146\n",
      "Iteration 33528, loss = 145.02152304\n",
      "Iteration 33529, loss = 145.00657497\n",
      "Iteration 33530, loss = 144.99163102\n",
      "Iteration 33531, loss = 144.97669003\n",
      "Iteration 33532, loss = 144.96174861\n",
      "Iteration 33533, loss = 144.94680668\n",
      "Iteration 33534, loss = 144.93186695\n",
      "Iteration 33535, loss = 144.91693034\n",
      "Iteration 33536, loss = 144.90199492\n",
      "Iteration 33537, loss = 144.88705939\n",
      "Iteration 33538, loss = 144.87212488\n",
      "Iteration 33539, loss = 144.85719284\n",
      "Iteration 33540, loss = 144.84226284\n",
      "Iteration 33541, loss = 144.82733355\n",
      "Iteration 33542, loss = 144.81240492\n",
      "Iteration 33543, loss = 144.79747788\n",
      "Iteration 33544, loss = 144.78255277\n",
      "Iteration 33545, loss = 144.76762871\n",
      "Iteration 33546, loss = 144.75270508\n",
      "Iteration 33547, loss = 144.73778213\n",
      "Iteration 33548, loss = 144.72286064\n",
      "Iteration 33549, loss = 144.70794075\n",
      "Iteration 33550, loss = 144.69302226\n",
      "Iteration 33551, loss = 144.67810518\n",
      "Iteration 33552, loss = 144.66318981\n",
      "Iteration 33553, loss = 144.64827621\n",
      "Iteration 33554, loss = 144.63336398\n",
      "Iteration 33555, loss = 144.61845268\n",
      "Iteration 33556, loss = 144.60354230\n",
      "Iteration 33557, loss = 144.58863312\n",
      "Iteration 33558, loss = 144.57372534\n",
      "Iteration 33559, loss = 144.55881896\n",
      "Iteration 33560, loss = 144.54391394\n",
      "Iteration 33561, loss = 144.52901034\n",
      "Iteration 33562, loss = 144.51410822\n",
      "Iteration 33563, loss = 144.49920746\n",
      "Iteration 33564, loss = 144.48430788\n",
      "Iteration 33565, loss = 144.46940943\n",
      "Iteration 33566, loss = 144.45451221\n",
      "Iteration 33567, loss = 144.43961635\n",
      "Iteration 33568, loss = 144.42472188\n",
      "Iteration 33569, loss = 144.40982877\n",
      "Iteration 33570, loss = 144.39493699\n",
      "Iteration 33571, loss = 144.38004653\n",
      "Iteration 33572, loss = 144.36515741\n",
      "Iteration 33573, loss = 144.35026956\n",
      "Iteration 33574, loss = 144.33538297\n",
      "Iteration 33575, loss = 144.32049763\n",
      "Iteration 33576, loss = 144.30561362\n",
      "Iteration 33577, loss = 144.29073095\n",
      "Iteration 33578, loss = 144.27584962\n",
      "Iteration 33579, loss = 144.26096962\n",
      "Iteration 33580, loss = 144.24609092\n",
      "Iteration 33581, loss = 144.23121352\n",
      "Iteration 33582, loss = 144.21633742\n",
      "Iteration 33583, loss = 144.20146263\n",
      "Iteration 33584, loss = 144.18658912\n",
      "Iteration 33585, loss = 144.17171692\n",
      "Iteration 33586, loss = 144.15684603\n",
      "Iteration 33587, loss = 144.14197646\n",
      "Iteration 33588, loss = 144.12710822\n",
      "Iteration 33589, loss = 144.11224128\n",
      "Iteration 33590, loss = 144.09737564\n",
      "Iteration 33591, loss = 144.08251131\n",
      "Iteration 33592, loss = 144.06764829\n",
      "Iteration 33593, loss = 144.05278657\n",
      "Iteration 33594, loss = 144.03792615\n",
      "Iteration 33595, loss = 144.02306704\n",
      "Iteration 33596, loss = 144.00820924\n",
      "Iteration 33597, loss = 143.99335275\n",
      "Iteration 33598, loss = 143.97849757\n",
      "Iteration 33599, loss = 143.96364370\n",
      "Iteration 33600, loss = 143.94879114\n",
      "Iteration 33601, loss = 143.93393988\n",
      "Iteration 33602, loss = 143.91908992\n",
      "Iteration 33603, loss = 143.90424127\n",
      "Iteration 33604, loss = 143.88939393\n",
      "Iteration 33605, loss = 143.87454790\n",
      "Iteration 33606, loss = 143.85970317\n",
      "Iteration 33607, loss = 143.84485975\n",
      "Iteration 33608, loss = 143.83001763\n",
      "Iteration 33609, loss = 143.81517683\n",
      "Iteration 33610, loss = 143.80033733\n",
      "Iteration 33611, loss = 143.78549913\n",
      "Iteration 33612, loss = 143.77066225\n",
      "Iteration 33613, loss = 143.75582666\n",
      "Iteration 33614, loss = 143.74099239\n",
      "Iteration 33615, loss = 143.72615942\n",
      "Iteration 33616, loss = 143.71132775\n",
      "Iteration 33617, loss = 143.69649740\n",
      "Iteration 33618, loss = 143.68166834\n",
      "Iteration 33619, loss = 143.66684060\n",
      "Iteration 33620, loss = 143.65201416\n",
      "Iteration 33621, loss = 143.63718902\n",
      "Iteration 33622, loss = 143.62236520\n",
      "Iteration 33623, loss = 143.60754267\n",
      "Iteration 33624, loss = 143.59272146\n",
      "Iteration 33625, loss = 143.57790154\n",
      "Iteration 33626, loss = 143.56308294\n",
      "Iteration 33627, loss = 143.54826564\n",
      "Iteration 33628, loss = 143.53344964\n",
      "Iteration 33629, loss = 143.51863495\n",
      "Iteration 33630, loss = 143.50382157\n",
      "Iteration 33631, loss = 143.48900949\n",
      "Iteration 33632, loss = 143.47419871\n",
      "Iteration 33633, loss = 143.45938924\n",
      "Iteration 33634, loss = 143.44458108\n",
      "Iteration 33635, loss = 143.42977422\n",
      "Iteration 33636, loss = 143.41496866\n",
      "Iteration 33637, loss = 143.40016442\n",
      "Iteration 33638, loss = 143.38536147\n",
      "Iteration 33639, loss = 143.37055983\n",
      "Iteration 33640, loss = 143.35575949\n",
      "Iteration 33641, loss = 143.34096046\n",
      "Iteration 33642, loss = 143.32616274\n",
      "Iteration 33643, loss = 143.31136632\n",
      "Iteration 33644, loss = 143.29657120\n",
      "Iteration 33645, loss = 143.28177739\n",
      "Iteration 33646, loss = 143.26698488\n",
      "Iteration 33647, loss = 143.25219367\n",
      "Iteration 33648, loss = 143.23740377\n",
      "Iteration 33649, loss = 143.22261518\n",
      "Iteration 33650, loss = 143.20782788\n",
      "Iteration 33651, loss = 143.19304190\n",
      "Iteration 33652, loss = 143.17825721\n",
      "Iteration 33653, loss = 143.16347383\n",
      "Iteration 33654, loss = 143.14869175\n",
      "Iteration 33655, loss = 143.13391098\n",
      "Iteration 33656, loss = 143.11913151\n",
      "Iteration 33657, loss = 143.10435335\n",
      "Iteration 33658, loss = 143.08957649\n",
      "Iteration 33659, loss = 143.07480093\n",
      "Iteration 33660, loss = 143.06002667\n",
      "Iteration 33661, loss = 143.04525372\n",
      "Iteration 33662, loss = 143.03048208\n",
      "Iteration 33663, loss = 143.01571173\n",
      "Iteration 33664, loss = 143.00094269\n",
      "Iteration 33665, loss = 142.98617495\n",
      "Iteration 33666, loss = 142.97140852\n",
      "Iteration 33667, loss = 142.95664339\n",
      "Iteration 33668, loss = 142.94187956\n",
      "Iteration 33669, loss = 142.92711703\n",
      "Iteration 33670, loss = 142.91235581\n",
      "Iteration 33671, loss = 142.89759589\n",
      "Iteration 33672, loss = 142.88283727\n",
      "Iteration 33673, loss = 142.86807996\n",
      "Iteration 33674, loss = 142.85332395\n",
      "Iteration 33675, loss = 142.83856924\n",
      "Iteration 33676, loss = 142.82381583\n",
      "Iteration 33677, loss = 142.80906373\n",
      "Iteration 33678, loss = 142.79431293\n",
      "Iteration 33679, loss = 142.77956343\n",
      "Iteration 33680, loss = 142.76481523\n",
      "Iteration 33681, loss = 142.75006834\n",
      "Iteration 33682, loss = 142.73532275\n",
      "Iteration 33683, loss = 142.72057846\n",
      "Iteration 33684, loss = 142.70583547\n",
      "Iteration 33685, loss = 142.69109378\n",
      "Iteration 33686, loss = 142.67635340\n",
      "Iteration 33687, loss = 142.66161432\n",
      "Iteration 33688, loss = 142.64687654\n",
      "Iteration 33689, loss = 142.63214006\n",
      "Iteration 33690, loss = 142.61740488\n",
      "Iteration 33691, loss = 142.60267101\n",
      "Iteration 33692, loss = 142.58793844\n",
      "Iteration 33693, loss = 142.57320717\n",
      "Iteration 33694, loss = 142.55847720\n",
      "Iteration 33695, loss = 142.54374853\n",
      "Iteration 33696, loss = 142.52902117\n",
      "Iteration 33697, loss = 142.51429511\n",
      "Iteration 33698, loss = 142.49957035\n",
      "Iteration 33699, loss = 142.48484691\n",
      "Iteration 33700, loss = 142.47012477\n",
      "Iteration 33701, loss = 142.45540394\n",
      "Iteration 33702, loss = 142.44068443\n",
      "Iteration 33703, loss = 142.42596625\n",
      "Iteration 33704, loss = 142.41124942\n",
      "Iteration 33705, loss = 142.39653395\n",
      "Iteration 33706, loss = 142.38181989\n",
      "Iteration 33707, loss = 142.36710726\n",
      "Iteration 33708, loss = 142.35239614\n",
      "Iteration 33709, loss = 142.33768654\n",
      "Iteration 33710, loss = 142.32297849\n",
      "Iteration 33711, loss = 142.30827180\n",
      "Iteration 33712, loss = 142.29356621\n",
      "Iteration 33713, loss = 142.27886110\n",
      "Iteration 33714, loss = 142.26415621\n",
      "Iteration 33715, loss = 142.24945160\n",
      "Iteration 33716, loss = 142.23474823\n",
      "Iteration 33717, loss = 142.22004708\n",
      "Iteration 33718, loss = 142.20534850\n",
      "Iteration 33719, loss = 142.19065206\n",
      "Iteration 33720, loss = 142.17595685\n",
      "Iteration 33721, loss = 142.16126220\n",
      "Iteration 33722, loss = 142.14656797\n",
      "Iteration 33723, loss = 142.13187471\n",
      "Iteration 33724, loss = 142.11718314\n",
      "Iteration 33725, loss = 142.10249358\n",
      "Iteration 33726, loss = 142.08780577\n",
      "Iteration 33727, loss = 142.07311917\n",
      "Iteration 33728, loss = 142.05843340\n",
      "Iteration 33729, loss = 142.04374852\n",
      "Iteration 33730, loss = 142.02906489\n",
      "Iteration 33731, loss = 142.01438287\n",
      "Iteration 33732, loss = 141.99970250\n",
      "Iteration 33733, loss = 141.98502354\n",
      "Iteration 33734, loss = 141.97034572\n",
      "Iteration 33735, loss = 141.95566893\n",
      "Iteration 33736, loss = 141.94099332\n",
      "Iteration 33737, loss = 141.92631909\n",
      "Iteration 33738, loss = 141.91164635\n",
      "Iteration 33739, loss = 141.89697504\n",
      "Iteration 33740, loss = 141.88230500\n",
      "Iteration 33741, loss = 141.86763613\n",
      "Iteration 33742, loss = 141.85296846\n",
      "Iteration 33743, loss = 141.83830208\n",
      "Iteration 33744, loss = 141.82363707\n",
      "Iteration 33745, loss = 141.80897346\n",
      "Iteration 33746, loss = 141.79431117\n",
      "Iteration 33747, loss = 141.77965014\n",
      "Iteration 33748, loss = 141.76499033\n",
      "Iteration 33749, loss = 141.75033180\n",
      "Iteration 33750, loss = 141.73567458\n",
      "Iteration 33751, loss = 141.72101871\n",
      "Iteration 33752, loss = 141.70636417\n",
      "Iteration 33753, loss = 141.69171092\n",
      "Iteration 33754, loss = 141.67705894\n",
      "Iteration 33755, loss = 141.66240824\n",
      "Iteration 33756, loss = 141.64775882\n",
      "Iteration 33757, loss = 141.63311072\n",
      "Iteration 33758, loss = 141.61846394\n",
      "Iteration 33759, loss = 141.60381846\n",
      "Iteration 33760, loss = 141.58917428\n",
      "Iteration 33761, loss = 141.57453138\n",
      "Iteration 33762, loss = 141.55988977\n",
      "Iteration 33763, loss = 141.54524945\n",
      "Iteration 33764, loss = 141.53061044\n",
      "Iteration 33765, loss = 141.51597274\n",
      "Iteration 33766, loss = 141.50133634\n",
      "Iteration 33767, loss = 141.48670124\n",
      "Iteration 33768, loss = 141.47206742\n",
      "Iteration 33769, loss = 141.45743489\n",
      "Iteration 33770, loss = 141.44280366\n",
      "Iteration 33771, loss = 141.42817374\n",
      "Iteration 33772, loss = 141.41354511\n",
      "Iteration 33773, loss = 141.39891778\n",
      "Iteration 33774, loss = 141.38429175\n",
      "Iteration 33775, loss = 141.36966701\n",
      "Iteration 33776, loss = 141.35504357\n",
      "Iteration 33777, loss = 141.34042142\n",
      "Iteration 33778, loss = 141.32580057\n",
      "Iteration 33779, loss = 141.31118102\n",
      "Iteration 33780, loss = 141.29656277\n",
      "Iteration 33781, loss = 141.28194581\n",
      "Iteration 33782, loss = 141.26733015\n",
      "Iteration 33783, loss = 141.25271578\n",
      "Iteration 33784, loss = 141.23810271\n",
      "Iteration 33785, loss = 141.22349093\n",
      "Iteration 33786, loss = 141.20888046\n",
      "Iteration 33787, loss = 141.19427128\n",
      "Iteration 33788, loss = 141.17966341\n",
      "Iteration 33789, loss = 141.16505684\n",
      "Iteration 33790, loss = 141.15045158\n",
      "Iteration 33791, loss = 141.13584764\n",
      "Iteration 33792, loss = 141.12124503\n",
      "Iteration 33793, loss = 141.10664380\n",
      "Iteration 33794, loss = 141.09204399\n",
      "Iteration 33795, loss = 141.07744569\n",
      "Iteration 33796, loss = 141.06284908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33797, loss = 141.04825443\n",
      "Iteration 33798, loss = 141.03366224\n",
      "Iteration 33799, loss = 141.01907329\n",
      "Iteration 33800, loss = 141.00448879\n",
      "Iteration 33801, loss = 140.98991014\n",
      "Iteration 33802, loss = 140.97533826\n",
      "Iteration 33803, loss = 140.96077077\n",
      "Iteration 33804, loss = 140.94619935\n",
      "Iteration 33805, loss = 140.93160983\n",
      "Iteration 33806, loss = 140.91699674\n",
      "Iteration 33807, loss = 140.90237686\n",
      "Iteration 33808, loss = 140.88777797\n",
      "Iteration 33809, loss = 140.87320854\n",
      "Iteration 33810, loss = 140.85865046\n",
      "Iteration 33811, loss = 140.84407905\n",
      "Iteration 33812, loss = 140.82948715\n",
      "Iteration 33813, loss = 140.81489225\n",
      "Iteration 33814, loss = 140.80031466\n",
      "Iteration 33815, loss = 140.78575344\n",
      "Iteration 33816, loss = 140.77119092\n",
      "Iteration 33817, loss = 140.75661548\n",
      "Iteration 33818, loss = 140.74203440\n",
      "Iteration 33819, loss = 140.72746236\n",
      "Iteration 33820, loss = 140.71290214\n",
      "Iteration 33821, loss = 140.69834322\n",
      "Iteration 33822, loss = 140.68377707\n",
      "Iteration 33823, loss = 140.66920736\n",
      "Iteration 33824, loss = 140.65464331\n",
      "Iteration 33825, loss = 140.64008701\n",
      "Iteration 33826, loss = 140.62553210\n",
      "Iteration 33827, loss = 140.61097336\n",
      "Iteration 33828, loss = 140.59641304\n",
      "Iteration 33829, loss = 140.58185668\n",
      "Iteration 33830, loss = 140.56730545\n",
      "Iteration 33831, loss = 140.55275547\n",
      "Iteration 33832, loss = 140.53820368\n",
      "Iteration 33833, loss = 140.52365156\n",
      "Iteration 33834, loss = 140.50910239\n",
      "Iteration 33835, loss = 140.49455675\n",
      "Iteration 33836, loss = 140.48001233\n",
      "Iteration 33837, loss = 140.46546738\n",
      "Iteration 33838, loss = 140.45092276\n",
      "Iteration 33839, loss = 140.43638041\n",
      "Iteration 33840, loss = 140.42184067\n",
      "Iteration 33841, loss = 140.40730222\n",
      "Iteration 33842, loss = 140.39276399\n",
      "Iteration 33843, loss = 140.37822646\n",
      "Iteration 33844, loss = 140.36369075\n",
      "Iteration 33845, loss = 140.34915712\n",
      "Iteration 33846, loss = 140.33462485\n",
      "Iteration 33847, loss = 140.32009325\n",
      "Iteration 33848, loss = 140.30556256\n",
      "Iteration 33849, loss = 140.29103340\n",
      "Iteration 33850, loss = 140.27650601\n",
      "Iteration 33851, loss = 140.26198002\n",
      "Iteration 33852, loss = 140.24745500\n",
      "Iteration 33853, loss = 140.23293099\n",
      "Iteration 33854, loss = 140.21840836\n",
      "Iteration 33855, loss = 140.20388730\n",
      "Iteration 33856, loss = 140.18936765\n",
      "Iteration 33857, loss = 140.17484914\n",
      "Iteration 33858, loss = 140.16033173\n",
      "Iteration 33859, loss = 140.14581561\n",
      "Iteration 33860, loss = 140.13130094\n",
      "Iteration 33861, loss = 140.11678766\n",
      "Iteration 33862, loss = 140.10227562\n",
      "Iteration 33863, loss = 140.08776476\n",
      "Iteration 33864, loss = 140.07325515\n",
      "Iteration 33865, loss = 140.05874689\n",
      "Iteration 33866, loss = 140.04424001\n",
      "Iteration 33867, loss = 140.02973442\n",
      "Iteration 33868, loss = 140.01523006\n",
      "Iteration 33869, loss = 140.00072695\n",
      "Iteration 33870, loss = 139.98622514\n",
      "Iteration 33871, loss = 139.97172467\n",
      "Iteration 33872, loss = 139.95722551\n",
      "Iteration 33873, loss = 139.94272763\n",
      "Iteration 33874, loss = 139.92823100\n",
      "Iteration 33875, loss = 139.91373565\n",
      "Iteration 33876, loss = 139.89924161\n",
      "Iteration 33877, loss = 139.88474889\n",
      "Iteration 33878, loss = 139.87025746\n",
      "Iteration 33879, loss = 139.85576730\n",
      "Iteration 33880, loss = 139.84127841\n",
      "Iteration 33881, loss = 139.82679082\n",
      "Iteration 33882, loss = 139.81230453\n",
      "Iteration 33883, loss = 139.79781954\n",
      "Iteration 33884, loss = 139.78333584\n",
      "Iteration 33885, loss = 139.76885341\n",
      "Iteration 33886, loss = 139.75437227\n",
      "Iteration 33887, loss = 139.73989242\n",
      "Iteration 33888, loss = 139.72541387\n",
      "Iteration 33889, loss = 139.71093661\n",
      "Iteration 33890, loss = 139.69646064\n",
      "Iteration 33891, loss = 139.68198596\n",
      "Iteration 33892, loss = 139.66751255\n",
      "Iteration 33893, loss = 139.65304044\n",
      "Iteration 33894, loss = 139.63856963\n",
      "Iteration 33895, loss = 139.62410010\n",
      "Iteration 33896, loss = 139.60963186\n",
      "Iteration 33897, loss = 139.59516491\n",
      "Iteration 33898, loss = 139.58069924\n",
      "Iteration 33899, loss = 139.56623486\n",
      "Iteration 33900, loss = 139.55177178\n",
      "Iteration 33901, loss = 139.53730998\n",
      "Iteration 33902, loss = 139.52284947\n",
      "Iteration 33903, loss = 139.50839025\n",
      "Iteration 33904, loss = 139.49393232\n",
      "Iteration 33905, loss = 139.47947567\n",
      "Iteration 33906, loss = 139.46502031\n",
      "Iteration 33907, loss = 139.45056625\n",
      "Iteration 33908, loss = 139.43611346\n",
      "Iteration 33909, loss = 139.42166197\n",
      "Iteration 33910, loss = 139.40721177\n",
      "Iteration 33911, loss = 139.39276285\n",
      "Iteration 33912, loss = 139.37831522\n",
      "Iteration 33913, loss = 139.36386887\n",
      "Iteration 33914, loss = 139.34942382\n",
      "Iteration 33915, loss = 139.33498005\n",
      "Iteration 33916, loss = 139.32053757\n",
      "Iteration 33917, loss = 139.30609638\n",
      "Iteration 33918, loss = 139.29165647\n",
      "Iteration 33919, loss = 139.27721786\n",
      "Iteration 33920, loss = 139.26278052\n",
      "Iteration 33921, loss = 139.24834448\n",
      "Iteration 33922, loss = 139.23390972\n",
      "Iteration 33923, loss = 139.21947625\n",
      "Iteration 33924, loss = 139.20504407\n",
      "Iteration 33925, loss = 139.19061317\n",
      "Iteration 33926, loss = 139.17618356\n",
      "Iteration 33927, loss = 139.16175524\n",
      "Iteration 33928, loss = 139.14732820\n",
      "Iteration 33929, loss = 139.13290245\n",
      "Iteration 33930, loss = 139.11847799\n",
      "Iteration 33931, loss = 139.10405481\n",
      "Iteration 33932, loss = 139.08963292\n",
      "Iteration 33933, loss = 139.07521231\n",
      "Iteration 33934, loss = 139.06079300\n",
      "Iteration 33935, loss = 139.04637496\n",
      "Iteration 33936, loss = 139.03195822\n",
      "Iteration 33937, loss = 139.01754276\n",
      "Iteration 33938, loss = 139.00312858\n",
      "Iteration 33939, loss = 138.98871569\n",
      "Iteration 33940, loss = 138.97430409\n",
      "Iteration 33941, loss = 138.95989377\n",
      "Iteration 33942, loss = 138.94548474\n",
      "Iteration 33943, loss = 138.93107699\n",
      "Iteration 33944, loss = 138.91667053\n",
      "Iteration 33945, loss = 138.90226535\n",
      "Iteration 33946, loss = 138.88786146\n",
      "Iteration 33947, loss = 138.87345886\n",
      "Iteration 33948, loss = 138.85905754\n",
      "Iteration 33949, loss = 138.84465750\n",
      "Iteration 33950, loss = 138.83025875\n",
      "Iteration 33951, loss = 138.81586129\n",
      "Iteration 33952, loss = 138.80146511\n",
      "Iteration 33953, loss = 138.78707021\n",
      "Iteration 33954, loss = 138.77267660\n",
      "Iteration 33955, loss = 138.75828428\n",
      "Iteration 33956, loss = 138.74389324\n",
      "Iteration 33957, loss = 138.72950349\n",
      "Iteration 33958, loss = 138.71511502\n",
      "Iteration 33959, loss = 138.70072784\n",
      "Iteration 33960, loss = 138.68634196\n",
      "Iteration 33961, loss = 138.67195737\n",
      "Iteration 33962, loss = 138.65757410\n",
      "Iteration 33963, loss = 138.64319215\n",
      "Iteration 33964, loss = 138.62881156\n",
      "Iteration 33965, loss = 138.61443239\n",
      "Iteration 33966, loss = 138.60005472\n",
      "Iteration 33967, loss = 138.58567870\n",
      "Iteration 33968, loss = 138.57130447\n",
      "Iteration 33969, loss = 138.55693226\n",
      "Iteration 33970, loss = 138.54256179\n",
      "Iteration 33971, loss = 138.52819247\n",
      "Iteration 33972, loss = 138.51382230\n",
      "Iteration 33973, loss = 138.49945040\n",
      "Iteration 33974, loss = 138.48507765\n",
      "Iteration 33975, loss = 138.47070775\n",
      "Iteration 33976, loss = 138.45634279\n",
      "Iteration 33977, loss = 138.44198139\n",
      "Iteration 33978, loss = 138.42762034\n",
      "Iteration 33979, loss = 138.41325767\n",
      "Iteration 33980, loss = 138.39889481\n",
      "Iteration 33981, loss = 138.38453460\n",
      "Iteration 33982, loss = 138.37017798\n",
      "Iteration 33983, loss = 138.35582315\n",
      "Iteration 33984, loss = 138.34146800\n",
      "Iteration 33985, loss = 138.32711274\n",
      "Iteration 33986, loss = 138.31275918\n",
      "Iteration 33987, loss = 138.29840838\n",
      "Iteration 33988, loss = 138.28405939\n",
      "Iteration 33989, loss = 138.26971078\n",
      "Iteration 33990, loss = 138.25536254\n",
      "Iteration 33991, loss = 138.24101580\n",
      "Iteration 33992, loss = 138.22667123\n",
      "Iteration 33993, loss = 138.21232825\n",
      "Iteration 33994, loss = 138.19798601\n",
      "Iteration 33995, loss = 138.18364451\n",
      "Iteration 33996, loss = 138.16930446\n",
      "Iteration 33997, loss = 138.15496622\n",
      "Iteration 33998, loss = 138.14062942\n",
      "Iteration 33999, loss = 138.12629355\n",
      "Iteration 34000, loss = 138.11195866\n",
      "Iteration 34001, loss = 138.09762517\n",
      "Iteration 34002, loss = 138.08329329\n",
      "Iteration 34003, loss = 138.06896275\n",
      "Iteration 34004, loss = 138.05463327\n",
      "Iteration 34005, loss = 138.04030491\n",
      "Iteration 34006, loss = 138.02597792\n",
      "Iteration 34007, loss = 138.01165240\n",
      "Iteration 34008, loss = 137.99732818\n",
      "Iteration 34009, loss = 137.98300511\n",
      "Iteration 34010, loss = 137.96868323\n",
      "Iteration 34011, loss = 137.95436269\n",
      "Iteration 34012, loss = 137.94004354\n",
      "Iteration 34013, loss = 137.92572568\n",
      "Iteration 34014, loss = 137.91140902\n",
      "Iteration 34015, loss = 137.89709359\n",
      "Iteration 34016, loss = 137.88277948\n",
      "Iteration 34017, loss = 137.86846671\n",
      "Iteration 34018, loss = 137.85415522\n",
      "Iteration 34019, loss = 137.83984497\n",
      "Iteration 34020, loss = 137.82553597\n",
      "Iteration 34021, loss = 137.81122827\n",
      "Iteration 34022, loss = 137.79692188\n",
      "Iteration 34023, loss = 137.78261678\n",
      "Iteration 34024, loss = 137.76831294\n",
      "Iteration 34025, loss = 137.75401035\n",
      "Iteration 34026, loss = 137.73970905\n",
      "Iteration 34027, loss = 137.72540906\n",
      "Iteration 34028, loss = 137.71111034\n",
      "Iteration 34029, loss = 137.69681290\n",
      "Iteration 34030, loss = 137.68251672\n",
      "Iteration 34031, loss = 137.66822182\n",
      "Iteration 34032, loss = 137.65392821\n",
      "Iteration 34033, loss = 137.63963589\n",
      "Iteration 34034, loss = 137.62534484\n",
      "Iteration 34035, loss = 137.61105506\n",
      "Iteration 34036, loss = 137.59676656\n",
      "Iteration 34037, loss = 137.58247935\n",
      "Iteration 34038, loss = 137.56819342\n",
      "Iteration 34039, loss = 137.55390876\n",
      "Iteration 34040, loss = 137.53962538\n",
      "Iteration 34041, loss = 137.52534328\n",
      "Iteration 34042, loss = 137.51106246\n",
      "Iteration 34043, loss = 137.49678293\n",
      "Iteration 34044, loss = 137.48250467\n",
      "Iteration 34045, loss = 137.46822770\n",
      "Iteration 34046, loss = 137.45395202\n",
      "Iteration 34047, loss = 137.43967765\n",
      "Iteration 34048, loss = 137.42540459\n",
      "Iteration 34049, loss = 137.41113287\n",
      "Iteration 34050, loss = 137.39686255\n",
      "Iteration 34051, loss = 137.38259370\n",
      "Iteration 34052, loss = 137.36832647\n",
      "Iteration 34053, loss = 137.35406111\n",
      "Iteration 34054, loss = 137.33979804\n",
      "Iteration 34055, loss = 137.32553796\n",
      "Iteration 34056, loss = 137.31128190\n",
      "Iteration 34057, loss = 137.29703126\n",
      "Iteration 34058, loss = 137.28278699\n",
      "Iteration 34059, loss = 137.26854815\n",
      "Iteration 34060, loss = 137.25430802\n",
      "Iteration 34061, loss = 137.24005439\n",
      "Iteration 34062, loss = 137.22577750\n",
      "Iteration 34063, loss = 137.21148731\n",
      "Iteration 34064, loss = 137.19721001\n",
      "Iteration 34065, loss = 137.18296159\n",
      "Iteration 34066, loss = 137.16873172\n",
      "Iteration 34067, loss = 137.15449624\n",
      "Iteration 34068, loss = 137.14024074\n",
      "Iteration 34069, loss = 137.12597439\n",
      "Iteration 34070, loss = 137.11171882\n",
      "Iteration 34071, loss = 137.09748206\n",
      "Iteration 34072, loss = 137.08325153\n",
      "Iteration 34073, loss = 137.06901148\n",
      "Iteration 34074, loss = 137.05476113\n",
      "Iteration 34075, loss = 137.04051361\n",
      "Iteration 34076, loss = 137.02627813\n",
      "Iteration 34077, loss = 137.01204948\n",
      "Iteration 34078, loss = 136.99781688\n",
      "Iteration 34079, loss = 136.98357784\n",
      "Iteration 34080, loss = 136.96933981\n",
      "Iteration 34081, loss = 136.95510929\n",
      "Iteration 34082, loss = 136.94088399\n",
      "Iteration 34083, loss = 136.92665730\n",
      "Iteration 34084, loss = 136.91242714\n",
      "Iteration 34085, loss = 136.89819770\n",
      "Iteration 34086, loss = 136.88397314\n",
      "Iteration 34087, loss = 136.86975241\n",
      "Iteration 34088, loss = 136.85553158\n",
      "Iteration 34089, loss = 136.84130916\n",
      "Iteration 34090, loss = 136.82708750\n",
      "Iteration 34091, loss = 136.81286915\n",
      "Iteration 34092, loss = 136.79865370\n",
      "Iteration 34093, loss = 136.78443889\n",
      "Iteration 34094, loss = 136.77022365\n",
      "Iteration 34095, loss = 136.75600921\n",
      "Iteration 34096, loss = 136.74179714\n",
      "Iteration 34097, loss = 136.72758742\n",
      "Iteration 34098, loss = 136.71337874\n",
      "Iteration 34099, loss = 136.69917034\n",
      "Iteration 34100, loss = 136.68496280\n",
      "Iteration 34101, loss = 136.67075708\n",
      "Iteration 34102, loss = 136.65655332\n",
      "Iteration 34103, loss = 136.64235084\n",
      "Iteration 34104, loss = 136.62814908\n",
      "Iteration 34105, loss = 136.61394825\n",
      "Iteration 34106, loss = 136.59974891\n",
      "Iteration 34107, loss = 136.58555127\n",
      "Iteration 34108, loss = 136.57135502\n",
      "Iteration 34109, loss = 136.55715977\n",
      "Iteration 34110, loss = 136.54296552\n",
      "Iteration 34111, loss = 136.52877259\n",
      "Iteration 34112, loss = 136.51458117\n",
      "Iteration 34113, loss = 136.50039117\n",
      "Iteration 34114, loss = 136.48620234\n",
      "Iteration 34115, loss = 136.47201461\n",
      "Iteration 34116, loss = 136.45782810\n",
      "Iteration 34117, loss = 136.44364297\n",
      "Iteration 34118, loss = 136.42945924\n",
      "Iteration 34119, loss = 136.41527678\n",
      "Iteration 34120, loss = 136.40109549\n",
      "Iteration 34121, loss = 136.38691541\n",
      "Iteration 34122, loss = 136.37273662\n",
      "Iteration 34123, loss = 136.35855919\n",
      "Iteration 34124, loss = 136.34438306\n",
      "Iteration 34125, loss = 136.33020817\n",
      "Iteration 34126, loss = 136.31603450\n",
      "Iteration 34127, loss = 136.30186208\n",
      "Iteration 34128, loss = 136.28769097\n",
      "Iteration 34129, loss = 136.27352117\n",
      "Iteration 34130, loss = 136.25935264\n",
      "Iteration 34131, loss = 136.24518536\n",
      "Iteration 34132, loss = 136.23101932\n",
      "Iteration 34133, loss = 136.21685456\n",
      "Iteration 34134, loss = 136.20269109\n",
      "Iteration 34135, loss = 136.18852890\n",
      "Iteration 34136, loss = 136.17436798\n",
      "Iteration 34137, loss = 136.16020832\n",
      "Iteration 34138, loss = 136.14604992\n",
      "Iteration 34139, loss = 136.13189279\n",
      "Iteration 34140, loss = 136.11773695\n",
      "Iteration 34141, loss = 136.10358238\n",
      "Iteration 34142, loss = 136.08942908\n",
      "Iteration 34143, loss = 136.07527704\n",
      "Iteration 34144, loss = 136.06112627\n",
      "Iteration 34145, loss = 136.04697676\n",
      "Iteration 34146, loss = 136.03282854\n",
      "Iteration 34147, loss = 136.01868159\n",
      "Iteration 34148, loss = 136.00453590\n",
      "Iteration 34149, loss = 135.99039148\n",
      "Iteration 34150, loss = 135.97624833\n",
      "Iteration 34151, loss = 135.96210645\n",
      "Iteration 34152, loss = 135.94796584\n",
      "Iteration 34153, loss = 135.93382650\n",
      "Iteration 34154, loss = 135.91968844\n",
      "Iteration 34155, loss = 135.90555163\n",
      "Iteration 34156, loss = 135.89141610\n",
      "Iteration 34157, loss = 135.87728183\n",
      "Iteration 34158, loss = 135.86314884\n",
      "Iteration 34159, loss = 135.84901711\n",
      "Iteration 34160, loss = 135.83488666\n",
      "Iteration 34161, loss = 135.82075747\n",
      "Iteration 34162, loss = 135.80662955\n",
      "Iteration 34163, loss = 135.79250290\n",
      "Iteration 34164, loss = 135.77837751\n",
      "Iteration 34165, loss = 135.76425340\n",
      "Iteration 34166, loss = 135.75013055\n",
      "Iteration 34167, loss = 135.73600897\n",
      "Iteration 34168, loss = 135.72188866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34169, loss = 135.70776962\n",
      "Iteration 34170, loss = 135.69365184\n",
      "Iteration 34171, loss = 135.67953533\n",
      "Iteration 34172, loss = 135.66542009\n",
      "Iteration 34173, loss = 135.65130612\n",
      "Iteration 34174, loss = 135.63719342\n",
      "Iteration 34175, loss = 135.62308198\n",
      "Iteration 34176, loss = 135.60897181\n",
      "Iteration 34177, loss = 135.59486291\n",
      "Iteration 34178, loss = 135.58075527\n",
      "Iteration 34179, loss = 135.56664890\n",
      "Iteration 34180, loss = 135.55254380\n",
      "Iteration 34181, loss = 135.53843997\n",
      "Iteration 34182, loss = 135.52433740\n",
      "Iteration 34183, loss = 135.51023610\n",
      "Iteration 34184, loss = 135.49613606\n",
      "Iteration 34185, loss = 135.48203729\n",
      "Iteration 34186, loss = 135.46793979\n",
      "Iteration 34187, loss = 135.45384356\n",
      "Iteration 34188, loss = 135.43974859\n",
      "Iteration 34189, loss = 135.42565489\n",
      "Iteration 34190, loss = 135.41156245\n",
      "Iteration 34191, loss = 135.39747128\n",
      "Iteration 34192, loss = 135.38338137\n",
      "Iteration 34193, loss = 135.36929273\n",
      "Iteration 34194, loss = 135.35520536\n",
      "Iteration 34195, loss = 135.34111925\n",
      "Iteration 34196, loss = 135.32703441\n",
      "Iteration 34197, loss = 135.31295083\n",
      "Iteration 34198, loss = 135.29886852\n",
      "Iteration 34199, loss = 135.28478748\n",
      "Iteration 34200, loss = 135.27070770\n",
      "Iteration 34201, loss = 135.25662918\n",
      "Iteration 34202, loss = 135.24255193\n",
      "Iteration 34203, loss = 135.22847595\n",
      "Iteration 34204, loss = 135.21440123\n",
      "Iteration 34205, loss = 135.20032777\n",
      "Iteration 34206, loss = 135.18625558\n",
      "Iteration 34207, loss = 135.17218465\n",
      "Iteration 34208, loss = 135.15811499\n",
      "Iteration 34209, loss = 135.14404659\n",
      "Iteration 34210, loss = 135.12997946\n",
      "Iteration 34211, loss = 135.11591359\n",
      "Iteration 34212, loss = 135.10184899\n",
      "Iteration 34213, loss = 135.08778565\n",
      "Iteration 34214, loss = 135.07372357\n",
      "Iteration 34215, loss = 135.05966276\n",
      "Iteration 34216, loss = 135.04560321\n",
      "Iteration 34217, loss = 135.03154492\n",
      "Iteration 34218, loss = 135.01748790\n",
      "Iteration 34219, loss = 135.00343214\n",
      "Iteration 34220, loss = 134.98937765\n",
      "Iteration 34221, loss = 134.97532442\n",
      "Iteration 34222, loss = 134.96127245\n",
      "Iteration 34223, loss = 134.94722174\n",
      "Iteration 34224, loss = 134.93317230\n",
      "Iteration 34225, loss = 134.91912412\n",
      "Iteration 34226, loss = 134.90507721\n",
      "Iteration 34227, loss = 134.89103155\n",
      "Iteration 34228, loss = 134.87698716\n",
      "Iteration 34229, loss = 134.86294404\n",
      "Iteration 34230, loss = 134.84890217\n",
      "Iteration 34231, loss = 134.83486157\n",
      "Iteration 34232, loss = 134.82082223\n",
      "Iteration 34233, loss = 134.80678415\n",
      "Iteration 34234, loss = 134.79274734\n",
      "Iteration 34235, loss = 134.77871178\n",
      "Iteration 34236, loss = 134.76467749\n",
      "Iteration 34237, loss = 134.75064446\n",
      "Iteration 34238, loss = 134.73661269\n",
      "Iteration 34239, loss = 134.72258219\n",
      "Iteration 34240, loss = 134.70855294\n",
      "Iteration 34241, loss = 134.69452496\n",
      "Iteration 34242, loss = 134.68049824\n",
      "Iteration 34243, loss = 134.66647278\n",
      "Iteration 34244, loss = 134.65244858\n",
      "Iteration 34245, loss = 134.63842564\n",
      "Iteration 34246, loss = 134.62440397\n",
      "Iteration 34247, loss = 134.61038355\n",
      "Iteration 34248, loss = 134.59636440\n",
      "Iteration 34249, loss = 134.58234650\n",
      "Iteration 34250, loss = 134.56832987\n",
      "Iteration 34251, loss = 134.55431450\n",
      "Iteration 34252, loss = 134.54030039\n",
      "Iteration 34253, loss = 134.52628754\n",
      "Iteration 34254, loss = 134.51227594\n",
      "Iteration 34255, loss = 134.49826561\n",
      "Iteration 34256, loss = 134.48425654\n",
      "Iteration 34257, loss = 134.47024873\n",
      "Iteration 34258, loss = 134.45624218\n",
      "Iteration 34259, loss = 134.44223689\n",
      "Iteration 34260, loss = 134.42823286\n",
      "Iteration 34261, loss = 134.41423009\n",
      "Iteration 34262, loss = 134.40022858\n",
      "Iteration 34263, loss = 134.38622833\n",
      "Iteration 34264, loss = 134.37222934\n",
      "Iteration 34265, loss = 134.35823160\n",
      "Iteration 34266, loss = 134.34423513\n",
      "Iteration 34267, loss = 134.33023992\n",
      "Iteration 34268, loss = 134.31624596\n",
      "Iteration 34269, loss = 134.30225326\n",
      "Iteration 34270, loss = 134.28826183\n",
      "Iteration 34271, loss = 134.27427165\n",
      "Iteration 34272, loss = 134.26028273\n",
      "Iteration 34273, loss = 134.24629507\n",
      "Iteration 34274, loss = 134.23230866\n",
      "Iteration 34275, loss = 134.21832352\n",
      "Iteration 34276, loss = 134.20433963\n",
      "Iteration 34277, loss = 134.19035701\n",
      "Iteration 34278, loss = 134.17637564\n",
      "Iteration 34279, loss = 134.16239553\n",
      "Iteration 34280, loss = 134.14841667\n",
      "Iteration 34281, loss = 134.13443908\n",
      "Iteration 34282, loss = 134.12046274\n",
      "Iteration 34283, loss = 134.10648766\n",
      "Iteration 34284, loss = 134.09251383\n",
      "Iteration 34285, loss = 134.07854127\n",
      "Iteration 34286, loss = 134.06456996\n",
      "Iteration 34287, loss = 134.05059991\n",
      "Iteration 34288, loss = 134.03663112\n",
      "Iteration 34289, loss = 134.02266358\n",
      "Iteration 34290, loss = 134.00869730\n",
      "Iteration 34291, loss = 133.99473228\n",
      "Iteration 34292, loss = 133.98076852\n",
      "Iteration 34293, loss = 133.96680602\n",
      "Iteration 34294, loss = 133.95284477\n",
      "Iteration 34295, loss = 133.93888479\n",
      "Iteration 34296, loss = 133.92492607\n",
      "Iteration 34297, loss = 133.91096862\n",
      "Iteration 34298, loss = 133.89701245\n",
      "Iteration 34299, loss = 133.88305758\n",
      "Iteration 34300, loss = 133.86910405\n",
      "Iteration 34301, loss = 133.85515190\n",
      "Iteration 34302, loss = 133.84120124\n",
      "Iteration 34303, loss = 133.82725226\n",
      "Iteration 34304, loss = 133.81330529\n",
      "Iteration 34305, loss = 133.79936088\n",
      "Iteration 34306, loss = 133.78541998\n",
      "Iteration 34307, loss = 133.77148404\n",
      "Iteration 34308, loss = 133.75755478\n",
      "Iteration 34309, loss = 133.74363335\n",
      "Iteration 34310, loss = 133.72971667\n",
      "Iteration 34311, loss = 133.71579406\n",
      "Iteration 34312, loss = 133.70184815\n",
      "Iteration 34313, loss = 133.68787469\n",
      "Iteration 34314, loss = 133.67389759\n",
      "Iteration 34315, loss = 133.65994936\n",
      "Iteration 34316, loss = 133.64603397\n",
      "Iteration 34317, loss = 133.63212497\n",
      "Iteration 34318, loss = 133.61819461\n",
      "Iteration 34319, loss = 133.60424253\n",
      "Iteration 34320, loss = 133.59029534\n",
      "Iteration 34321, loss = 133.57637196\n",
      "Iteration 34322, loss = 133.56246164\n",
      "Iteration 34323, loss = 133.54854177\n",
      "Iteration 34324, loss = 133.53460699\n",
      "Iteration 34325, loss = 133.52067375\n",
      "Iteration 34326, loss = 133.50675598\n",
      "Iteration 34327, loss = 133.49284755\n",
      "Iteration 34328, loss = 133.47893317\n",
      "Iteration 34329, loss = 133.46500941\n",
      "Iteration 34330, loss = 133.45108583\n",
      "Iteration 34331, loss = 133.43717029\n",
      "Iteration 34332, loss = 133.42325905\n",
      "Iteration 34333, loss = 133.40934563\n",
      "Iteration 34334, loss = 133.39543052\n",
      "Iteration 34335, loss = 133.38151951\n",
      "Iteration 34336, loss = 133.36761411\n",
      "Iteration 34337, loss = 133.35370916\n",
      "Iteration 34338, loss = 133.33980081\n",
      "Iteration 34339, loss = 133.32589187\n",
      "Iteration 34340, loss = 133.31198753\n",
      "Iteration 34341, loss = 133.29808810\n",
      "Iteration 34342, loss = 133.28418919\n",
      "Iteration 34343, loss = 133.27028804\n",
      "Iteration 34344, loss = 133.25638671\n",
      "Iteration 34345, loss = 133.24248876\n",
      "Iteration 34346, loss = 133.22859450\n",
      "Iteration 34347, loss = 133.21470118\n",
      "Iteration 34348, loss = 133.20080702\n",
      "Iteration 34349, loss = 133.18691316\n",
      "Iteration 34350, loss = 133.17302171\n",
      "Iteration 34351, loss = 133.15913291\n",
      "Iteration 34352, loss = 133.14524527\n",
      "Iteration 34353, loss = 133.13135778\n",
      "Iteration 34354, loss = 133.11747097\n",
      "Iteration 34355, loss = 133.10358596\n",
      "Iteration 34356, loss = 133.08970295\n",
      "Iteration 34357, loss = 133.07582121\n",
      "Iteration 34358, loss = 133.06194017\n",
      "Iteration 34359, loss = 133.04806007\n",
      "Iteration 34360, loss = 133.03418145\n",
      "Iteration 34361, loss = 133.02030446\n",
      "Iteration 34362, loss = 133.00642876\n",
      "Iteration 34363, loss = 132.99255406\n",
      "Iteration 34364, loss = 132.97868044\n",
      "Iteration 34365, loss = 132.96480816\n",
      "Iteration 34366, loss = 132.95093732\n",
      "Iteration 34367, loss = 132.93706776\n",
      "Iteration 34368, loss = 132.92319934\n",
      "Iteration 34369, loss = 132.90933208\n",
      "Iteration 34370, loss = 132.89546610\n",
      "Iteration 34371, loss = 132.88160146\n",
      "Iteration 34372, loss = 132.86773809\n",
      "Iteration 34373, loss = 132.85387593\n",
      "Iteration 34374, loss = 132.84001497\n",
      "Iteration 34375, loss = 132.82615527\n",
      "Iteration 34376, loss = 132.81229686\n",
      "Iteration 34377, loss = 132.79843971\n",
      "Iteration 34378, loss = 132.78458379\n",
      "Iteration 34379, loss = 132.77072909\n",
      "Iteration 34380, loss = 132.75687565\n",
      "Iteration 34381, loss = 132.74302347\n",
      "Iteration 34382, loss = 132.72917256\n",
      "Iteration 34383, loss = 132.71532288\n",
      "Iteration 34384, loss = 132.70147443\n",
      "Iteration 34385, loss = 132.68762723\n",
      "Iteration 34386, loss = 132.67378129\n",
      "Iteration 34387, loss = 132.65993661\n",
      "Iteration 34388, loss = 132.64609317\n",
      "Iteration 34389, loss = 132.63225097\n",
      "Iteration 34390, loss = 132.61841001\n",
      "Iteration 34391, loss = 132.60457031\n",
      "Iteration 34392, loss = 132.59073185\n",
      "Iteration 34393, loss = 132.57689465\n",
      "Iteration 34394, loss = 132.56305869\n",
      "Iteration 34395, loss = 132.54922397\n",
      "Iteration 34396, loss = 132.53539049\n",
      "Iteration 34397, loss = 132.52155827\n",
      "Iteration 34398, loss = 132.50772730\n",
      "Iteration 34399, loss = 132.49389757\n",
      "Iteration 34400, loss = 132.48006908\n",
      "Iteration 34401, loss = 132.46624184\n",
      "Iteration 34402, loss = 132.45241584\n",
      "Iteration 34403, loss = 132.43859110\n",
      "Iteration 34404, loss = 132.42476760\n",
      "Iteration 34405, loss = 132.41094534\n",
      "Iteration 34406, loss = 132.39712433\n",
      "Iteration 34407, loss = 132.38330456\n",
      "Iteration 34408, loss = 132.36948604\n",
      "Iteration 34409, loss = 132.35566877\n",
      "Iteration 34410, loss = 132.34185274\n",
      "Iteration 34411, loss = 132.32803795\n",
      "Iteration 34412, loss = 132.31422441\n",
      "Iteration 34413, loss = 132.30041211\n",
      "Iteration 34414, loss = 132.28660106\n",
      "Iteration 34415, loss = 132.27279125\n",
      "Iteration 34416, loss = 132.25898269\n",
      "Iteration 34417, loss = 132.24517537\n",
      "Iteration 34418, loss = 132.23136929\n",
      "Iteration 34419, loss = 132.21756446\n",
      "Iteration 34420, loss = 132.20376087\n",
      "Iteration 34421, loss = 132.18995853\n",
      "Iteration 34422, loss = 132.17615743\n",
      "Iteration 34423, loss = 132.16235757\n",
      "Iteration 34424, loss = 132.14855896\n",
      "Iteration 34425, loss = 132.13476159\n",
      "Iteration 34426, loss = 132.12096546\n",
      "Iteration 34427, loss = 132.10717058\n",
      "Iteration 34428, loss = 132.09337694\n",
      "Iteration 34429, loss = 132.07958454\n",
      "Iteration 34430, loss = 132.06579339\n",
      "Iteration 34431, loss = 132.05200348\n",
      "Iteration 34432, loss = 132.03821481\n",
      "Iteration 34433, loss = 132.02442738\n",
      "Iteration 34434, loss = 132.01064120\n",
      "Iteration 34435, loss = 131.99685626\n",
      "Iteration 34436, loss = 131.98307256\n",
      "Iteration 34437, loss = 131.96929010\n",
      "Iteration 34438, loss = 131.95550888\n",
      "Iteration 34439, loss = 131.94172891\n",
      "Iteration 34440, loss = 131.92795017\n",
      "Iteration 34441, loss = 131.91417268\n",
      "Iteration 34442, loss = 131.90039644\n",
      "Iteration 34443, loss = 131.88662143\n",
      "Iteration 34444, loss = 131.87284766\n",
      "Iteration 34445, loss = 131.85907514\n",
      "Iteration 34446, loss = 131.84530385\n",
      "Iteration 34447, loss = 131.83153381\n",
      "Iteration 34448, loss = 131.81776501\n",
      "Iteration 34449, loss = 131.80399744\n",
      "Iteration 34450, loss = 131.79023112\n",
      "Iteration 34451, loss = 131.77646604\n",
      "Iteration 34452, loss = 131.76270220\n",
      "Iteration 34453, loss = 131.74893960\n",
      "Iteration 34454, loss = 131.73517824\n",
      "Iteration 34455, loss = 131.72141812\n",
      "Iteration 34456, loss = 131.70765925\n",
      "Iteration 34457, loss = 131.69390161\n",
      "Iteration 34458, loss = 131.68014521\n",
      "Iteration 34459, loss = 131.66639005\n",
      "Iteration 34460, loss = 131.65263613\n",
      "Iteration 34461, loss = 131.63888345\n",
      "Iteration 34462, loss = 131.62513200\n",
      "Iteration 34463, loss = 131.61138180\n",
      "Iteration 34464, loss = 131.59763284\n",
      "Iteration 34465, loss = 131.58388512\n",
      "Iteration 34466, loss = 131.57013863\n",
      "Iteration 34467, loss = 131.55639338\n",
      "Iteration 34468, loss = 131.54264938\n",
      "Iteration 34469, loss = 131.52890661\n",
      "Iteration 34470, loss = 131.51516508\n",
      "Iteration 34471, loss = 131.50142479\n",
      "Iteration 34472, loss = 131.48768573\n",
      "Iteration 34473, loss = 131.47394792\n",
      "Iteration 34474, loss = 131.46021134\n",
      "Iteration 34475, loss = 131.44647600\n",
      "Iteration 34476, loss = 131.43274190\n",
      "Iteration 34477, loss = 131.41900903\n",
      "Iteration 34478, loss = 131.40527741\n",
      "Iteration 34479, loss = 131.39154702\n",
      "Iteration 34480, loss = 131.37781787\n",
      "Iteration 34481, loss = 131.36408995\n",
      "Iteration 34482, loss = 131.35036328\n",
      "Iteration 34483, loss = 131.33663784\n",
      "Iteration 34484, loss = 131.32291363\n",
      "Iteration 34485, loss = 131.30919067\n",
      "Iteration 34486, loss = 131.29546894\n",
      "Iteration 34487, loss = 131.28174844\n",
      "Iteration 34488, loss = 131.26802919\n",
      "Iteration 34489, loss = 131.25431117\n",
      "Iteration 34490, loss = 131.24059438\n",
      "Iteration 34491, loss = 131.22687884\n",
      "Iteration 34492, loss = 131.21316453\n",
      "Iteration 34493, loss = 131.19945145\n",
      "Iteration 34494, loss = 131.18573961\n",
      "Iteration 34495, loss = 131.17202901\n",
      "Iteration 34496, loss = 131.15831964\n",
      "Iteration 34497, loss = 131.14461151\n",
      "Iteration 34498, loss = 131.13090461\n",
      "Iteration 34499, loss = 131.11719895\n",
      "Iteration 34500, loss = 131.10349452\n",
      "Iteration 34501, loss = 131.08979133\n",
      "Iteration 34502, loss = 131.07608937\n",
      "Iteration 34503, loss = 131.06238865\n",
      "Iteration 34504, loss = 131.04868916\n",
      "Iteration 34505, loss = 131.03499091\n",
      "Iteration 34506, loss = 131.02129389\n",
      "Iteration 34507, loss = 131.00759811\n",
      "Iteration 34508, loss = 130.99390356\n",
      "Iteration 34509, loss = 130.98021024\n",
      "Iteration 34510, loss = 130.96651816\n",
      "Iteration 34511, loss = 130.95282731\n",
      "Iteration 34512, loss = 130.93913770\n",
      "Iteration 34513, loss = 130.92544932\n",
      "Iteration 34514, loss = 130.91176217\n",
      "Iteration 34515, loss = 130.89807626\n",
      "Iteration 34516, loss = 130.88439158\n",
      "Iteration 34517, loss = 130.87070813\n",
      "Iteration 34518, loss = 130.85702592\n",
      "Iteration 34519, loss = 130.84334494\n",
      "Iteration 34520, loss = 130.82966519\n",
      "Iteration 34521, loss = 130.81598668\n",
      "Iteration 34522, loss = 130.80230940\n",
      "Iteration 34523, loss = 130.78863335\n",
      "Iteration 34524, loss = 130.77495853\n",
      "Iteration 34525, loss = 130.76128495\n",
      "Iteration 34526, loss = 130.74761260\n",
      "Iteration 34527, loss = 130.73394148\n",
      "Iteration 34528, loss = 130.72027159\n",
      "Iteration 34529, loss = 130.70660293\n",
      "Iteration 34530, loss = 130.69293551\n",
      "Iteration 34531, loss = 130.67926932\n",
      "Iteration 34532, loss = 130.66560436\n",
      "Iteration 34533, loss = 130.65194063\n",
      "Iteration 34534, loss = 130.63827813\n",
      "Iteration 34535, loss = 130.62461686\n",
      "Iteration 34536, loss = 130.61095683\n",
      "Iteration 34537, loss = 130.59729802\n",
      "Iteration 34538, loss = 130.58364045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34539, loss = 130.56998411\n",
      "Iteration 34540, loss = 130.55632899\n",
      "Iteration 34541, loss = 130.54267511\n",
      "Iteration 34542, loss = 130.52902246\n",
      "Iteration 34543, loss = 130.51537104\n",
      "Iteration 34544, loss = 130.50172085\n",
      "Iteration 34545, loss = 130.48807189\n",
      "Iteration 34546, loss = 130.47442415\n",
      "Iteration 34547, loss = 130.46077765\n",
      "Iteration 34548, loss = 130.44713238\n",
      "Iteration 34549, loss = 130.43348834\n",
      "Iteration 34550, loss = 130.41984553\n",
      "Iteration 34551, loss = 130.40620394\n",
      "Iteration 34552, loss = 130.39256359\n",
      "Iteration 34553, loss = 130.37892446\n",
      "Iteration 34554, loss = 130.36528657\n",
      "Iteration 34555, loss = 130.35164990\n",
      "Iteration 34556, loss = 130.33801446\n",
      "Iteration 34557, loss = 130.32438025\n",
      "Iteration 34558, loss = 130.31074727\n",
      "Iteration 34559, loss = 130.29711552\n",
      "Iteration 34560, loss = 130.28348500\n",
      "Iteration 34561, loss = 130.26985570\n",
      "Iteration 34562, loss = 130.25622764\n",
      "Iteration 34563, loss = 130.24260080\n",
      "Iteration 34564, loss = 130.22897519\n",
      "Iteration 34565, loss = 130.21535081\n",
      "Iteration 34566, loss = 130.20172766\n",
      "Iteration 34567, loss = 130.18810574\n",
      "Iteration 34568, loss = 130.17448506\n",
      "Iteration 34569, loss = 130.16086562\n",
      "Iteration 34570, loss = 130.14724745\n",
      "Iteration 34571, loss = 130.13363055\n",
      "Iteration 34572, loss = 130.12001498\n",
      "Iteration 34573, loss = 130.10640083\n",
      "Iteration 34574, loss = 130.09278825\n",
      "Iteration 34575, loss = 130.07917754\n",
      "Iteration 34576, loss = 130.06556924\n",
      "Iteration 34577, loss = 130.05196429\n",
      "Iteration 34578, loss = 130.03836435\n",
      "Iteration 34579, loss = 130.02477173\n",
      "Iteration 34580, loss = 130.01118891\n",
      "Iteration 34581, loss = 129.99761485\n",
      "Iteration 34582, loss = 129.98403930\n",
      "Iteration 34583, loss = 129.97043874\n",
      "Iteration 34584, loss = 129.95679868\n",
      "Iteration 34585, loss = 129.94314395\n",
      "Iteration 34586, loss = 129.92952273\n",
      "Iteration 34587, loss = 129.91594739\n",
      "Iteration 34588, loss = 129.90238202\n",
      "Iteration 34589, loss = 129.88878619\n",
      "Iteration 34590, loss = 129.87516158\n",
      "Iteration 34591, loss = 129.86154860\n",
      "Iteration 34592, loss = 129.84796870\n",
      "Iteration 34593, loss = 129.83439811\n",
      "Iteration 34594, loss = 129.82080672\n",
      "Iteration 34595, loss = 129.80719961\n",
      "Iteration 34596, loss = 129.79360512\n",
      "Iteration 34597, loss = 129.78003082\n",
      "Iteration 34598, loss = 129.76645608\n",
      "Iteration 34599, loss = 129.75286647\n",
      "Iteration 34600, loss = 129.73927373\n",
      "Iteration 34601, loss = 129.72569418\n",
      "Iteration 34602, loss = 129.71212357\n",
      "Iteration 34603, loss = 129.69854718\n",
      "Iteration 34604, loss = 129.68496360\n",
      "Iteration 34605, loss = 129.67138436\n",
      "Iteration 34606, loss = 129.65781435\n",
      "Iteration 34607, loss = 129.64424578\n",
      "Iteration 34608, loss = 129.63067216\n",
      "Iteration 34609, loss = 129.61709777\n",
      "Iteration 34610, loss = 129.60352928\n",
      "Iteration 34611, loss = 129.58996509\n",
      "Iteration 34612, loss = 129.57639922\n",
      "Iteration 34613, loss = 129.56283081\n",
      "Iteration 34614, loss = 129.54926442\n",
      "Iteration 34615, loss = 129.53570200\n",
      "Iteration 34616, loss = 129.52214082\n",
      "Iteration 34617, loss = 129.50857865\n",
      "Iteration 34618, loss = 129.49501730\n",
      "Iteration 34619, loss = 129.48145933\n",
      "Iteration 34620, loss = 129.46790410\n",
      "Iteration 34621, loss = 129.45434911\n",
      "Iteration 34622, loss = 129.44079375\n",
      "Iteration 34623, loss = 129.42723966\n",
      "Iteration 34624, loss = 129.41368779\n",
      "Iteration 34625, loss = 129.40013729\n",
      "Iteration 34626, loss = 129.38658723\n",
      "Iteration 34627, loss = 129.37303814\n",
      "Iteration 34628, loss = 129.35949100\n",
      "Iteration 34629, loss = 129.34594573\n",
      "Iteration 34630, loss = 129.33240140\n",
      "Iteration 34631, loss = 129.31885759\n",
      "Iteration 34632, loss = 129.30531486\n",
      "Iteration 34633, loss = 129.29177375\n",
      "Iteration 34634, loss = 129.27823410\n",
      "Iteration 34635, loss = 129.26469548\n",
      "Iteration 34636, loss = 129.25115788\n",
      "Iteration 34637, loss = 129.23762166\n",
      "Iteration 34638, loss = 129.22408691\n",
      "Iteration 34639, loss = 129.21055337\n",
      "Iteration 34640, loss = 129.19702079\n",
      "Iteration 34641, loss = 129.18348928\n",
      "Iteration 34642, loss = 129.16995910\n",
      "Iteration 34643, loss = 129.15643032\n",
      "Iteration 34644, loss = 129.14290277\n",
      "Iteration 34645, loss = 129.12937634\n",
      "Iteration 34646, loss = 129.11585109\n",
      "Iteration 34647, loss = 129.10232713\n",
      "Iteration 34648, loss = 129.08880444\n",
      "Iteration 34649, loss = 129.07528291\n",
      "Iteration 34650, loss = 129.06176253\n",
      "Iteration 34651, loss = 129.04824335\n",
      "Iteration 34652, loss = 129.03472545\n",
      "Iteration 34653, loss = 129.02120883\n",
      "Iteration 34654, loss = 129.00769341\n",
      "Iteration 34655, loss = 128.99417916\n",
      "Iteration 34656, loss = 128.98066612\n",
      "Iteration 34657, loss = 128.96715432\n",
      "Iteration 34658, loss = 128.95364375\n",
      "Iteration 34659, loss = 128.94013438\n",
      "Iteration 34660, loss = 128.92662620\n",
      "Iteration 34661, loss = 128.91311925\n",
      "Iteration 34662, loss = 128.89961353\n",
      "Iteration 34663, loss = 128.88610904\n",
      "Iteration 34664, loss = 128.87260576\n",
      "Iteration 34665, loss = 128.85910368\n",
      "Iteration 34666, loss = 128.84560282\n",
      "Iteration 34667, loss = 128.83210317\n",
      "Iteration 34668, loss = 128.81860475\n",
      "Iteration 34669, loss = 128.80510754\n",
      "Iteration 34670, loss = 128.79161153\n",
      "Iteration 34671, loss = 128.77811674\n",
      "Iteration 34672, loss = 128.76462317\n",
      "Iteration 34673, loss = 128.75113082\n",
      "Iteration 34674, loss = 128.73763968\n",
      "Iteration 34675, loss = 128.72414976\n",
      "Iteration 34676, loss = 128.71066104\n",
      "Iteration 34677, loss = 128.69717354\n",
      "Iteration 34678, loss = 128.68368726\n",
      "Iteration 34679, loss = 128.67020219\n",
      "Iteration 34680, loss = 128.65671833\n",
      "Iteration 34681, loss = 128.64323569\n",
      "Iteration 34682, loss = 128.62975426\n",
      "Iteration 34683, loss = 128.61627404\n",
      "Iteration 34684, loss = 128.60279504\n",
      "Iteration 34685, loss = 128.58931725\n",
      "Iteration 34686, loss = 128.57584067\n",
      "Iteration 34687, loss = 128.56236530\n",
      "Iteration 34688, loss = 128.54889115\n",
      "Iteration 34689, loss = 128.53541821\n",
      "Iteration 34690, loss = 128.52194648\n",
      "Iteration 34691, loss = 128.50847596\n",
      "Iteration 34692, loss = 128.49500666\n",
      "Iteration 34693, loss = 128.48153857\n",
      "Iteration 34694, loss = 128.46807169\n",
      "Iteration 34695, loss = 128.45460602\n",
      "Iteration 34696, loss = 128.44114156\n",
      "Iteration 34697, loss = 128.42767832\n",
      "Iteration 34698, loss = 128.41421628\n",
      "Iteration 34699, loss = 128.40075546\n",
      "Iteration 34700, loss = 128.38729584\n",
      "Iteration 34701, loss = 128.37383744\n",
      "Iteration 34702, loss = 128.36038025\n",
      "Iteration 34703, loss = 128.34692427\n",
      "Iteration 34704, loss = 128.33346950\n",
      "Iteration 34705, loss = 128.32001594\n",
      "Iteration 34706, loss = 128.30656359\n",
      "Iteration 34707, loss = 128.29311245\n",
      "Iteration 34708, loss = 128.27966253\n",
      "Iteration 34709, loss = 128.26621381\n",
      "Iteration 34710, loss = 128.25276630\n",
      "Iteration 34711, loss = 128.23932000\n",
      "Iteration 34712, loss = 128.22587491\n",
      "Iteration 34713, loss = 128.21243103\n",
      "Iteration 34714, loss = 128.19898835\n",
      "Iteration 34715, loss = 128.18554689\n",
      "Iteration 34716, loss = 128.17210664\n",
      "Iteration 34717, loss = 128.15866759\n",
      "Iteration 34718, loss = 128.14522976\n",
      "Iteration 34719, loss = 128.13179313\n",
      "Iteration 34720, loss = 128.11835771\n",
      "Iteration 34721, loss = 128.10492350\n",
      "Iteration 34722, loss = 128.09149049\n",
      "Iteration 34723, loss = 128.07805870\n",
      "Iteration 34724, loss = 128.06462811\n",
      "Iteration 34725, loss = 128.05119873\n",
      "Iteration 34726, loss = 128.03777056\n",
      "Iteration 34727, loss = 128.02434360\n",
      "Iteration 34728, loss = 128.01091784\n",
      "Iteration 34729, loss = 127.99749329\n",
      "Iteration 34730, loss = 127.98406995\n",
      "Iteration 34731, loss = 127.97064781\n",
      "Iteration 34732, loss = 127.95722689\n",
      "Iteration 34733, loss = 127.94380716\n",
      "Iteration 34734, loss = 127.93038865\n",
      "Iteration 34735, loss = 127.91697134\n",
      "Iteration 34736, loss = 127.90355524\n",
      "Iteration 34737, loss = 127.89014034\n",
      "Iteration 34738, loss = 127.87672665\n",
      "Iteration 34739, loss = 127.86331417\n",
      "Iteration 34740, loss = 127.84990289\n",
      "Iteration 34741, loss = 127.83649282\n",
      "Iteration 34742, loss = 127.82308395\n",
      "Iteration 34743, loss = 127.80967629\n",
      "Iteration 34744, loss = 127.79626984\n",
      "Iteration 34745, loss = 127.78286458\n",
      "Iteration 34746, loss = 127.76946054\n",
      "Iteration 34747, loss = 127.75605770\n",
      "Iteration 34748, loss = 127.74265606\n",
      "Iteration 34749, loss = 127.72925563\n",
      "Iteration 34750, loss = 127.71585640\n",
      "Iteration 34751, loss = 127.70245838\n",
      "Iteration 34752, loss = 127.68906156\n",
      "Iteration 34753, loss = 127.67566595\n",
      "Iteration 34754, loss = 127.66227154\n",
      "Iteration 34755, loss = 127.64887834\n",
      "Iteration 34756, loss = 127.63548634\n",
      "Iteration 34757, loss = 127.62209554\n",
      "Iteration 34758, loss = 127.60870595\n",
      "Iteration 34759, loss = 127.59531757\n",
      "Iteration 34760, loss = 127.58193039\n",
      "Iteration 34761, loss = 127.56854442\n",
      "Iteration 34762, loss = 127.55515967\n",
      "Iteration 34763, loss = 127.54177612\n",
      "Iteration 34764, loss = 127.52839380\n",
      "Iteration 34765, loss = 127.51501271\n",
      "Iteration 34766, loss = 127.50163286\n",
      "Iteration 34767, loss = 127.48825427\n",
      "Iteration 34768, loss = 127.47487696\n",
      "Iteration 34769, loss = 127.46150096\n",
      "Iteration 34770, loss = 127.44812631\n",
      "Iteration 34771, loss = 127.43475301\n",
      "Iteration 34772, loss = 127.42138106\n",
      "Iteration 34773, loss = 127.40801028\n",
      "Iteration 34774, loss = 127.39464053\n",
      "Iteration 34775, loss = 127.38127137\n",
      "Iteration 34776, loss = 127.36790272\n",
      "Iteration 34777, loss = 127.35453461\n",
      "Iteration 34778, loss = 127.34116763\n",
      "Iteration 34779, loss = 127.32780237\n",
      "Iteration 34780, loss = 127.31443914\n",
      "Iteration 34781, loss = 127.30107775\n",
      "Iteration 34782, loss = 127.28771771\n",
      "Iteration 34783, loss = 127.27435855\n",
      "Iteration 34784, loss = 127.26100002\n",
      "Iteration 34785, loss = 127.24764228\n",
      "Iteration 34786, loss = 127.23428571\n",
      "Iteration 34787, loss = 127.22093066\n",
      "Iteration 34788, loss = 127.20757723\n",
      "Iteration 34789, loss = 127.19422523\n",
      "Iteration 34790, loss = 127.18087436\n",
      "Iteration 34791, loss = 127.16752442\n",
      "Iteration 34792, loss = 127.15417542\n",
      "Iteration 34793, loss = 127.14082756\n",
      "Iteration 34794, loss = 127.12748102\n",
      "Iteration 34795, loss = 127.11413589\n",
      "Iteration 34796, loss = 127.10079210\n",
      "Iteration 34797, loss = 127.08744949\n",
      "Iteration 34798, loss = 127.07410795\n",
      "Iteration 34799, loss = 127.06076749\n",
      "Iteration 34800, loss = 127.04742817\n",
      "Iteration 34801, loss = 127.03409011\n",
      "Iteration 34802, loss = 127.02075334\n",
      "Iteration 34803, loss = 127.00741784\n",
      "Iteration 34804, loss = 126.99408354\n",
      "Iteration 34805, loss = 126.98075039\n",
      "Iteration 34806, loss = 126.96741837\n",
      "Iteration 34807, loss = 126.95408751\n",
      "Iteration 34808, loss = 126.94075787\n",
      "Iteration 34809, loss = 126.92742947\n",
      "Iteration 34810, loss = 126.91410231\n",
      "Iteration 34811, loss = 126.90077635\n",
      "Iteration 34812, loss = 126.88745157\n",
      "Iteration 34813, loss = 126.87412796\n",
      "Iteration 34814, loss = 126.86080552\n",
      "Iteration 34815, loss = 126.84748427\n",
      "Iteration 34816, loss = 126.83416425\n",
      "Iteration 34817, loss = 126.82084543\n",
      "Iteration 34818, loss = 126.80752782\n",
      "Iteration 34819, loss = 126.79421141\n",
      "Iteration 34820, loss = 126.78089617\n",
      "Iteration 34821, loss = 126.76758212\n",
      "Iteration 34822, loss = 126.75426926\n",
      "Iteration 34823, loss = 126.74095760\n",
      "Iteration 34824, loss = 126.72764714\n",
      "Iteration 34825, loss = 126.71433789\n",
      "Iteration 34826, loss = 126.70102983\n",
      "Iteration 34827, loss = 126.68772296\n",
      "Iteration 34828, loss = 126.67441728\n",
      "Iteration 34829, loss = 126.66111279\n",
      "Iteration 34830, loss = 126.64780949\n",
      "Iteration 34831, loss = 126.63450739\n",
      "Iteration 34832, loss = 126.62120648\n",
      "Iteration 34833, loss = 126.60790678\n",
      "Iteration 34834, loss = 126.59460826\n",
      "Iteration 34835, loss = 126.58131094\n",
      "Iteration 34836, loss = 126.56801481\n",
      "Iteration 34837, loss = 126.55471987\n",
      "Iteration 34838, loss = 126.54142612\n",
      "Iteration 34839, loss = 126.52813356\n",
      "Iteration 34840, loss = 126.51484220\n",
      "Iteration 34841, loss = 126.50155203\n",
      "Iteration 34842, loss = 126.48826305\n",
      "Iteration 34843, loss = 126.47497527\n",
      "Iteration 34844, loss = 126.46168868\n",
      "Iteration 34845, loss = 126.44840328\n",
      "Iteration 34846, loss = 126.43511906\n",
      "Iteration 34847, loss = 126.42183604\n",
      "Iteration 34848, loss = 126.40855422\n",
      "Iteration 34849, loss = 126.39527358\n",
      "Iteration 34850, loss = 126.38199414\n",
      "Iteration 34851, loss = 126.36871588\n",
      "Iteration 34852, loss = 126.35543882\n",
      "Iteration 34853, loss = 126.34216295\n",
      "Iteration 34854, loss = 126.32888827\n",
      "Iteration 34855, loss = 126.31561478\n",
      "Iteration 34856, loss = 126.30234249\n",
      "Iteration 34857, loss = 126.28907139\n",
      "Iteration 34858, loss = 126.27580149\n",
      "Iteration 34859, loss = 126.26253280\n",
      "Iteration 34860, loss = 126.24926532\n",
      "Iteration 34861, loss = 126.23599909\n",
      "Iteration 34862, loss = 126.22273413\n",
      "Iteration 34863, loss = 126.20947050\n",
      "Iteration 34864, loss = 126.19620832\n",
      "Iteration 34865, loss = 126.18294779\n",
      "Iteration 34866, loss = 126.16968923\n",
      "Iteration 34867, loss = 126.15643325\n",
      "Iteration 34868, loss = 126.14318075\n",
      "Iteration 34869, loss = 126.12993319\n",
      "Iteration 34870, loss = 126.11669217\n",
      "Iteration 34871, loss = 126.10345861\n",
      "Iteration 34872, loss = 126.09022930\n",
      "Iteration 34873, loss = 126.07699386\n",
      "Iteration 34874, loss = 126.06373597\n",
      "Iteration 34875, loss = 126.05045145\n",
      "Iteration 34876, loss = 126.03716222\n",
      "Iteration 34877, loss = 126.02389934\n",
      "Iteration 34878, loss = 126.01066885\n",
      "Iteration 34879, loss = 125.99744762\n",
      "Iteration 34880, loss = 125.98420832\n",
      "Iteration 34881, loss = 125.97094635\n",
      "Iteration 34882, loss = 125.95768420\n",
      "Iteration 34883, loss = 125.94444315\n",
      "Iteration 34884, loss = 125.93121848\n",
      "Iteration 34885, loss = 125.91798917\n",
      "Iteration 34886, loss = 125.90474460\n",
      "Iteration 34887, loss = 125.89149575\n",
      "Iteration 34888, loss = 125.87825865\n",
      "Iteration 34889, loss = 125.86503370\n",
      "Iteration 34890, loss = 125.85180780\n",
      "Iteration 34891, loss = 125.83857296\n",
      "Iteration 34892, loss = 125.82533543\n",
      "Iteration 34893, loss = 125.81210532\n",
      "Iteration 34894, loss = 125.79888306\n",
      "Iteration 34895, loss = 125.78566067\n",
      "Iteration 34896, loss = 125.77243337\n",
      "Iteration 34897, loss = 125.75920507\n",
      "Iteration 34898, loss = 125.74598180\n",
      "Iteration 34899, loss = 125.73276362\n",
      "Iteration 34900, loss = 125.71954563\n",
      "Iteration 34901, loss = 125.70632517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34902, loss = 125.69310477\n",
      "Iteration 34903, loss = 125.67988792\n",
      "Iteration 34904, loss = 125.66667449\n",
      "Iteration 34905, loss = 125.65346158\n",
      "Iteration 34906, loss = 125.64024769\n",
      "Iteration 34907, loss = 125.62703436\n",
      "Iteration 34908, loss = 125.61382361\n",
      "Iteration 34909, loss = 125.60061537\n",
      "Iteration 34910, loss = 125.58740794\n",
      "Iteration 34911, loss = 125.57420041\n",
      "Iteration 34912, loss = 125.56099366\n",
      "Iteration 34913, loss = 125.54778889\n",
      "Iteration 34914, loss = 125.53458610\n",
      "Iteration 34915, loss = 125.52138434\n",
      "Iteration 34916, loss = 125.50818302\n",
      "Iteration 34917, loss = 125.49498258\n",
      "Iteration 34918, loss = 125.48178373\n",
      "Iteration 34919, loss = 125.46858658\n",
      "Iteration 34920, loss = 125.45539058\n",
      "Iteration 34921, loss = 125.44219535\n",
      "Iteration 34922, loss = 125.42900106\n",
      "Iteration 34923, loss = 125.41580813\n",
      "Iteration 34924, loss = 125.40261671\n",
      "Iteration 34925, loss = 125.38942652\n",
      "Iteration 34926, loss = 125.37623729\n",
      "Iteration 34927, loss = 125.36304906\n",
      "Iteration 34928, loss = 125.34986206\n",
      "Iteration 34929, loss = 125.33667643\n",
      "Iteration 34930, loss = 125.32349206\n",
      "Iteration 34931, loss = 125.31030878\n",
      "Iteration 34932, loss = 125.29712655\n",
      "Iteration 34933, loss = 125.28394549\n",
      "Iteration 34934, loss = 125.27076569\n",
      "Iteration 34935, loss = 125.25758716\n",
      "Iteration 34936, loss = 125.24440979\n",
      "Iteration 34937, loss = 125.23123351\n",
      "Iteration 34938, loss = 125.21805838\n",
      "Iteration 34939, loss = 125.20488446\n",
      "Iteration 34940, loss = 125.19171177\n",
      "Iteration 34941, loss = 125.17854028\n",
      "Iteration 34942, loss = 125.16536993\n",
      "Iteration 34943, loss = 125.15220072\n",
      "Iteration 34944, loss = 125.13903269\n",
      "Iteration 34945, loss = 125.12586586\n",
      "Iteration 34946, loss = 125.11270023\n",
      "Iteration 34947, loss = 125.09953578\n",
      "Iteration 34948, loss = 125.08637248\n",
      "Iteration 34949, loss = 125.07321035\n",
      "Iteration 34950, loss = 125.06004940\n",
      "Iteration 34951, loss = 125.04688964\n",
      "Iteration 34952, loss = 125.03373106\n",
      "Iteration 34953, loss = 125.02057366\n",
      "Iteration 34954, loss = 125.00741742\n",
      "Iteration 34955, loss = 124.99426235\n",
      "Iteration 34956, loss = 124.98110846\n",
      "Iteration 34957, loss = 124.96795576\n",
      "Iteration 34958, loss = 124.95480423\n",
      "Iteration 34959, loss = 124.94165388\n",
      "Iteration 34960, loss = 124.92850470\n",
      "Iteration 34961, loss = 124.91535669\n",
      "Iteration 34962, loss = 124.90220986\n",
      "Iteration 34963, loss = 124.88906421\n",
      "Iteration 34964, loss = 124.87591975\n",
      "Iteration 34965, loss = 124.86277647\n",
      "Iteration 34966, loss = 124.84963437\n",
      "Iteration 34967, loss = 124.83649347\n",
      "Iteration 34968, loss = 124.82335378\n",
      "Iteration 34969, loss = 124.81021532\n",
      "Iteration 34970, loss = 124.79707813\n",
      "Iteration 34971, loss = 124.78394223\n",
      "Iteration 34972, loss = 124.77080769\n",
      "Iteration 34973, loss = 124.75767455\n",
      "Iteration 34974, loss = 124.74454288\n",
      "Iteration 34975, loss = 124.73141252\n",
      "Iteration 34976, loss = 124.71828328\n",
      "Iteration 34977, loss = 124.70515449\n",
      "Iteration 34978, loss = 124.69202577\n",
      "Iteration 34979, loss = 124.67889696\n",
      "Iteration 34980, loss = 124.66576906\n",
      "Iteration 34981, loss = 124.65264319\n",
      "Iteration 34982, loss = 124.63951992\n",
      "Iteration 34983, loss = 124.62639879\n",
      "Iteration 34984, loss = 124.61327879\n",
      "Iteration 34985, loss = 124.60015911\n",
      "Iteration 34986, loss = 124.58703962\n",
      "Iteration 34987, loss = 124.57392103\n",
      "Iteration 34988, loss = 124.56080414\n",
      "Iteration 34989, loss = 124.54768923\n",
      "Iteration 34990, loss = 124.53457587\n",
      "Iteration 34991, loss = 124.52146341\n",
      "Iteration 34992, loss = 124.50835154\n",
      "Iteration 34993, loss = 124.49524049\n",
      "Iteration 34994, loss = 124.48213076\n",
      "Iteration 34995, loss = 124.46902264\n",
      "Iteration 34996, loss = 124.45591599\n",
      "Iteration 34997, loss = 124.44281044\n",
      "Iteration 34998, loss = 124.42970576\n",
      "Iteration 34999, loss = 124.41660201\n",
      "Iteration 35000, loss = 124.40349947\n",
      "Iteration 35001, loss = 124.39039831\n",
      "Iteration 35002, loss = 124.37729851\n",
      "Iteration 35003, loss = 124.36419988\n",
      "Iteration 35004, loss = 124.35110226\n",
      "Iteration 35005, loss = 124.33800567\n",
      "Iteration 35006, loss = 124.32491025\n",
      "Iteration 35007, loss = 124.31181610\n",
      "Iteration 35008, loss = 124.29872322\n",
      "Iteration 35009, loss = 124.28563153\n",
      "Iteration 35010, loss = 124.27254094\n",
      "Iteration 35011, loss = 124.25945144\n",
      "Iteration 35012, loss = 124.24636308\n",
      "Iteration 35013, loss = 124.23327594\n",
      "Iteration 35014, loss = 124.22019002\n",
      "Iteration 35015, loss = 124.20710530\n",
      "Iteration 35016, loss = 124.19402171\n",
      "Iteration 35017, loss = 124.18093925\n",
      "Iteration 35018, loss = 124.16785793\n",
      "Iteration 35019, loss = 124.15477779\n",
      "Iteration 35020, loss = 124.14169886\n",
      "Iteration 35021, loss = 124.12862110\n",
      "Iteration 35022, loss = 124.11554451\n",
      "Iteration 35023, loss = 124.10246906\n",
      "Iteration 35024, loss = 124.08939476\n",
      "Iteration 35025, loss = 124.07632163\n",
      "Iteration 35026, loss = 124.06324968\n",
      "Iteration 35027, loss = 124.05017890\n",
      "Iteration 35028, loss = 124.03710930\n",
      "Iteration 35029, loss = 124.02404085\n",
      "Iteration 35030, loss = 124.01097355\n",
      "Iteration 35031, loss = 123.99790742\n",
      "Iteration 35032, loss = 123.98484245\n",
      "Iteration 35033, loss = 123.97177865\n",
      "Iteration 35034, loss = 123.95871603\n",
      "Iteration 35035, loss = 123.94565456\n",
      "Iteration 35036, loss = 123.93259426\n",
      "Iteration 35037, loss = 123.91953511\n",
      "Iteration 35038, loss = 123.90647713\n",
      "Iteration 35039, loss = 123.89342031\n",
      "Iteration 35040, loss = 123.88036466\n",
      "Iteration 35041, loss = 123.86731018\n",
      "Iteration 35042, loss = 123.85425685\n",
      "Iteration 35043, loss = 123.84120469\n",
      "Iteration 35044, loss = 123.82815368\n",
      "Iteration 35045, loss = 123.81510384\n",
      "Iteration 35046, loss = 123.80205517\n",
      "Iteration 35047, loss = 123.78900765\n",
      "Iteration 35048, loss = 123.77596130\n",
      "Iteration 35049, loss = 123.76291611\n",
      "Iteration 35050, loss = 123.74987208\n",
      "Iteration 35051, loss = 123.73682921\n",
      "Iteration 35052, loss = 123.72378750\n",
      "Iteration 35053, loss = 123.71074696\n",
      "Iteration 35054, loss = 123.69770757\n",
      "Iteration 35055, loss = 123.68466935\n",
      "Iteration 35056, loss = 123.67163229\n",
      "Iteration 35057, loss = 123.65859638\n",
      "Iteration 35058, loss = 123.64556164\n",
      "Iteration 35059, loss = 123.63252806\n",
      "Iteration 35060, loss = 123.61949564\n",
      "Iteration 35061, loss = 123.60646437\n",
      "Iteration 35062, loss = 123.59343427\n",
      "Iteration 35063, loss = 123.58040533\n",
      "Iteration 35064, loss = 123.56737754\n",
      "Iteration 35065, loss = 123.55435092\n",
      "Iteration 35066, loss = 123.54132545\n",
      "Iteration 35067, loss = 123.52830115\n",
      "Iteration 35068, loss = 123.51527800\n",
      "Iteration 35069, loss = 123.50225601\n",
      "Iteration 35070, loss = 123.48923518\n",
      "Iteration 35071, loss = 123.47621551\n",
      "Iteration 35072, loss = 123.46319699\n",
      "Iteration 35073, loss = 123.45017963\n",
      "Iteration 35074, loss = 123.43716344\n",
      "Iteration 35075, loss = 123.42414840\n",
      "Iteration 35076, loss = 123.41113451\n",
      "Iteration 35077, loss = 123.39812179\n",
      "Iteration 35078, loss = 123.38511022\n",
      "Iteration 35079, loss = 123.37209981\n",
      "Iteration 35080, loss = 123.35909055\n",
      "Iteration 35081, loss = 123.34608245\n",
      "Iteration 35082, loss = 123.33307551\n",
      "Iteration 35083, loss = 123.32006973\n",
      "Iteration 35084, loss = 123.30706510\n",
      "Iteration 35085, loss = 123.29406163\n",
      "Iteration 35086, loss = 123.28105931\n",
      "Iteration 35087, loss = 123.26805815\n",
      "Iteration 35088, loss = 123.25505815\n",
      "Iteration 35089, loss = 123.24205930\n",
      "Iteration 35090, loss = 123.22906160\n",
      "Iteration 35091, loss = 123.21606506\n",
      "Iteration 35092, loss = 123.20306968\n",
      "Iteration 35093, loss = 123.19007545\n",
      "Iteration 35094, loss = 123.17708238\n",
      "Iteration 35095, loss = 123.16409046\n",
      "Iteration 35096, loss = 123.15109969\n",
      "Iteration 35097, loss = 123.13811008\n",
      "Iteration 35098, loss = 123.12512163\n",
      "Iteration 35099, loss = 123.11213433\n",
      "Iteration 35100, loss = 123.09914818\n",
      "Iteration 35101, loss = 123.08616318\n",
      "Iteration 35102, loss = 123.07317934\n",
      "Iteration 35103, loss = 123.06019665\n",
      "Iteration 35104, loss = 123.04721512\n",
      "Iteration 35105, loss = 123.03423474\n",
      "Iteration 35106, loss = 123.02125551\n",
      "Iteration 35107, loss = 123.00827743\n",
      "Iteration 35108, loss = 122.99530051\n",
      "Iteration 35109, loss = 122.98232474\n",
      "Iteration 35110, loss = 122.96935013\n",
      "Iteration 35111, loss = 122.95637667\n",
      "Iteration 35112, loss = 122.94340437\n",
      "Iteration 35113, loss = 122.93043324\n",
      "Iteration 35114, loss = 122.91746327\n",
      "Iteration 35115, loss = 122.90449449\n",
      "Iteration 35116, loss = 122.89152692\n",
      "Iteration 35117, loss = 122.87856060\n",
      "Iteration 35118, loss = 122.86559561\n",
      "Iteration 35119, loss = 122.85263209\n",
      "Iteration 35120, loss = 122.83967028\n",
      "Iteration 35121, loss = 122.82671061\n",
      "Iteration 35122, loss = 122.81375384\n",
      "Iteration 35123, loss = 122.80080112\n",
      "Iteration 35124, loss = 122.78785424\n",
      "Iteration 35125, loss = 122.77491498\n",
      "Iteration 35126, loss = 122.76198366\n",
      "Iteration 35127, loss = 122.74905441\n",
      "Iteration 35128, loss = 122.73611253\n",
      "Iteration 35129, loss = 122.72314081\n",
      "Iteration 35130, loss = 122.71014410\n",
      "Iteration 35131, loss = 122.69715566\n",
      "Iteration 35132, loss = 122.68420397\n",
      "Iteration 35133, loss = 122.67128120\n",
      "Iteration 35134, loss = 122.65835440\n",
      "Iteration 35135, loss = 122.64540023\n",
      "Iteration 35136, loss = 122.63242906\n",
      "Iteration 35137, loss = 122.61947151\n",
      "Iteration 35138, loss = 122.60653921\n",
      "Iteration 35139, loss = 122.59361361\n",
      "Iteration 35140, loss = 122.58067303\n",
      "Iteration 35141, loss = 122.56771908\n",
      "Iteration 35142, loss = 122.55477160\n",
      "Iteration 35143, loss = 122.54184049\n",
      "Iteration 35144, loss = 122.52891462\n",
      "Iteration 35145, loss = 122.51597974\n",
      "Iteration 35146, loss = 122.50303739\n",
      "Iteration 35147, loss = 122.49010024\n",
      "Iteration 35148, loss = 122.47717341\n",
      "Iteration 35149, loss = 122.46424913\n",
      "Iteration 35150, loss = 122.45131934\n",
      "Iteration 35151, loss = 122.43838628\n",
      "Iteration 35152, loss = 122.42545769\n",
      "Iteration 35153, loss = 122.41253555\n",
      "Iteration 35154, loss = 122.39961448\n",
      "Iteration 35155, loss = 122.38669028\n",
      "Iteration 35156, loss = 122.37376522\n",
      "Iteration 35157, loss = 122.36084384\n",
      "Iteration 35158, loss = 122.34792650\n",
      "Iteration 35159, loss = 122.33500972\n",
      "Iteration 35160, loss = 122.32209149\n",
      "Iteration 35161, loss = 122.30917358\n",
      "Iteration 35162, loss = 122.29625854\n",
      "Iteration 35163, loss = 122.28334620\n",
      "Iteration 35164, loss = 122.27043442\n",
      "Iteration 35165, loss = 122.25752224\n",
      "Iteration 35166, loss = 122.24461090\n",
      "Iteration 35167, loss = 122.23170179\n",
      "Iteration 35168, loss = 122.21879467\n",
      "Iteration 35169, loss = 122.20588826\n",
      "Iteration 35170, loss = 122.19298210\n",
      "Iteration 35171, loss = 122.18007694\n",
      "Iteration 35172, loss = 122.16717359\n",
      "Iteration 35173, loss = 122.15427185\n",
      "Iteration 35174, loss = 122.14137101\n",
      "Iteration 35175, loss = 122.12847078\n",
      "Iteration 35176, loss = 122.11557160\n",
      "Iteration 35177, loss = 122.10267394\n",
      "Iteration 35178, loss = 122.08977772\n",
      "Iteration 35179, loss = 122.07688251\n",
      "Iteration 35180, loss = 122.06398813\n",
      "Iteration 35181, loss = 122.05109481\n",
      "Iteration 35182, loss = 122.03820284\n",
      "Iteration 35183, loss = 122.02531220\n",
      "Iteration 35184, loss = 122.01242265\n",
      "Iteration 35185, loss = 121.99953407\n",
      "Iteration 35186, loss = 121.98664655\n",
      "Iteration 35187, loss = 121.97376026\n",
      "Iteration 35188, loss = 121.96087525\n",
      "Iteration 35189, loss = 121.94799137\n",
      "Iteration 35190, loss = 121.93510854\n",
      "Iteration 35191, loss = 121.92222678\n",
      "Iteration 35192, loss = 121.90934620\n",
      "Iteration 35193, loss = 121.89646683\n",
      "Iteration 35194, loss = 121.88358863\n",
      "Iteration 35195, loss = 121.87071152\n",
      "Iteration 35196, loss = 121.85783551\n",
      "Iteration 35197, loss = 121.84496063\n",
      "Iteration 35198, loss = 121.83208694\n",
      "Iteration 35199, loss = 121.81921443\n",
      "Iteration 35200, loss = 121.80634305\n",
      "Iteration 35201, loss = 121.79347280\n",
      "Iteration 35202, loss = 121.78060369\n",
      "Iteration 35203, loss = 121.76773577\n",
      "Iteration 35204, loss = 121.75486907\n",
      "Iteration 35205, loss = 121.74200359\n",
      "Iteration 35206, loss = 121.72913934\n",
      "Iteration 35207, loss = 121.71627634\n",
      "Iteration 35208, loss = 121.70341464\n",
      "Iteration 35209, loss = 121.69055422\n",
      "Iteration 35210, loss = 121.67769499\n",
      "Iteration 35211, loss = 121.66483667\n",
      "Iteration 35212, loss = 121.65197900\n",
      "Iteration 35213, loss = 121.63912166\n",
      "Iteration 35214, loss = 121.62626485\n",
      "Iteration 35215, loss = 121.61340901\n",
      "Iteration 35216, loss = 121.60055481\n",
      "Iteration 35217, loss = 121.58770257\n",
      "Iteration 35218, loss = 121.57485213\n",
      "Iteration 35219, loss = 121.56200301\n",
      "Iteration 35220, loss = 121.54915470\n",
      "Iteration 35221, loss = 121.53630697\n",
      "Iteration 35222, loss = 121.52345994\n",
      "Iteration 35223, loss = 121.51061400\n",
      "Iteration 35224, loss = 121.49776953\n",
      "Iteration 35225, loss = 121.48492661\n",
      "Iteration 35226, loss = 121.47208506\n",
      "Iteration 35227, loss = 121.45924456\n",
      "Iteration 35228, loss = 121.44640493\n",
      "Iteration 35229, loss = 121.43356617\n",
      "Iteration 35230, loss = 121.42072849\n",
      "Iteration 35231, loss = 121.40789208\n",
      "Iteration 35232, loss = 121.39505701\n",
      "Iteration 35233, loss = 121.38222321\n",
      "Iteration 35234, loss = 121.36939051\n",
      "Iteration 35235, loss = 121.35655881\n",
      "Iteration 35236, loss = 121.34372812\n",
      "Iteration 35237, loss = 121.33089852\n",
      "Iteration 35238, loss = 121.31807011\n",
      "Iteration 35239, loss = 121.30524294\n",
      "Iteration 35240, loss = 121.29241697\n",
      "Iteration 35241, loss = 121.27959212\n",
      "Iteration 35242, loss = 121.26676835\n",
      "Iteration 35243, loss = 121.25394564\n",
      "Iteration 35244, loss = 121.24112404\n",
      "Iteration 35245, loss = 121.22830359\n",
      "Iteration 35246, loss = 121.21548432\n",
      "Iteration 35247, loss = 121.20266622\n",
      "Iteration 35248, loss = 121.18984925\n",
      "Iteration 35249, loss = 121.17703338\n",
      "Iteration 35250, loss = 121.16421861\n",
      "Iteration 35251, loss = 121.15140496\n",
      "Iteration 35252, loss = 121.13859244\n",
      "Iteration 35253, loss = 121.12578107\n",
      "Iteration 35254, loss = 121.11297085\n",
      "Iteration 35255, loss = 121.10016177\n",
      "Iteration 35256, loss = 121.08735380\n",
      "Iteration 35257, loss = 121.07454695\n",
      "Iteration 35258, loss = 121.06174122\n",
      "Iteration 35259, loss = 121.04893661\n",
      "Iteration 35260, loss = 121.03613314\n",
      "Iteration 35261, loss = 121.02333081\n",
      "Iteration 35262, loss = 121.01052961\n",
      "Iteration 35263, loss = 120.99772954\n",
      "Iteration 35264, loss = 120.98493058\n",
      "Iteration 35265, loss = 120.97213276\n",
      "Iteration 35266, loss = 120.95933605\n",
      "Iteration 35267, loss = 120.94654047\n",
      "Iteration 35268, loss = 120.93374602\n",
      "Iteration 35269, loss = 120.92095270\n",
      "Iteration 35270, loss = 120.90816051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35271, loss = 120.89536945\n",
      "Iteration 35272, loss = 120.88257950\n",
      "Iteration 35273, loss = 120.86979069\n",
      "Iteration 35274, loss = 120.85700299\n",
      "Iteration 35275, loss = 120.84421642\n",
      "Iteration 35276, loss = 120.83143098\n",
      "Iteration 35277, loss = 120.81864667\n",
      "Iteration 35278, loss = 120.80586348\n",
      "Iteration 35279, loss = 120.79308141\n",
      "Iteration 35280, loss = 120.78030047\n",
      "Iteration 35281, loss = 120.76752065\n",
      "Iteration 35282, loss = 120.75474196\n",
      "Iteration 35283, loss = 120.74196439\n",
      "Iteration 35284, loss = 120.72918794\n",
      "Iteration 35285, loss = 120.71641262\n",
      "Iteration 35286, loss = 120.70363842\n",
      "Iteration 35287, loss = 120.69086535\n",
      "Iteration 35288, loss = 120.67809340\n",
      "Iteration 35289, loss = 120.66532257\n",
      "Iteration 35290, loss = 120.65255286\n",
      "Iteration 35291, loss = 120.63978428\n",
      "Iteration 35292, loss = 120.62701682\n",
      "Iteration 35293, loss = 120.61425048\n",
      "Iteration 35294, loss = 120.60148526\n",
      "Iteration 35295, loss = 120.58872117\n",
      "Iteration 35296, loss = 120.57595819\n",
      "Iteration 35297, loss = 120.56319634\n",
      "Iteration 35298, loss = 120.55043561\n",
      "Iteration 35299, loss = 120.53767600\n",
      "Iteration 35300, loss = 120.52491752\n",
      "Iteration 35301, loss = 120.51216015\n",
      "Iteration 35302, loss = 120.49940390\n",
      "Iteration 35303, loss = 120.48664878\n",
      "Iteration 35304, loss = 120.47389477\n",
      "Iteration 35305, loss = 120.46114189\n",
      "Iteration 35306, loss = 120.44839013\n",
      "Iteration 35307, loss = 120.43563948\n",
      "Iteration 35308, loss = 120.42288996\n",
      "Iteration 35309, loss = 120.41014155\n",
      "Iteration 35310, loss = 120.39739427\n",
      "Iteration 35311, loss = 120.38464810\n",
      "Iteration 35312, loss = 120.37190306\n",
      "Iteration 35313, loss = 120.35915913\n",
      "Iteration 35314, loss = 120.34641632\n",
      "Iteration 35315, loss = 120.33367463\n",
      "Iteration 35316, loss = 120.32093406\n",
      "Iteration 35317, loss = 120.30819460\n",
      "Iteration 35318, loss = 120.29545627\n",
      "Iteration 35319, loss = 120.28271905\n",
      "Iteration 35320, loss = 120.26998295\n",
      "Iteration 35321, loss = 120.25724797\n",
      "Iteration 35322, loss = 120.24451410\n",
      "Iteration 35323, loss = 120.23178135\n",
      "Iteration 35324, loss = 120.21904972\n",
      "Iteration 35325, loss = 120.20631921\n",
      "Iteration 35326, loss = 120.19358981\n",
      "Iteration 35327, loss = 120.18086153\n",
      "Iteration 35328, loss = 120.16813437\n",
      "Iteration 35329, loss = 120.15540832\n",
      "Iteration 35330, loss = 120.14268339\n",
      "Iteration 35331, loss = 120.12995957\n",
      "Iteration 35332, loss = 120.11723687\n",
      "Iteration 35333, loss = 120.10451529\n",
      "Iteration 35334, loss = 120.09179482\n",
      "Iteration 35335, loss = 120.07907547\n",
      "Iteration 35336, loss = 120.06635723\n",
      "Iteration 35337, loss = 120.05364010\n",
      "Iteration 35338, loss = 120.04092409\n",
      "Iteration 35339, loss = 120.02820920\n",
      "Iteration 35340, loss = 120.01549542\n",
      "Iteration 35341, loss = 120.00278275\n",
      "Iteration 35342, loss = 119.99007120\n",
      "Iteration 35343, loss = 119.97736076\n",
      "Iteration 35344, loss = 119.96465144\n",
      "Iteration 35345, loss = 119.95194323\n",
      "Iteration 35346, loss = 119.93923613\n",
      "Iteration 35347, loss = 119.92653015\n",
      "Iteration 35348, loss = 119.91382527\n",
      "Iteration 35349, loss = 119.90112152\n",
      "Iteration 35350, loss = 119.88841887\n",
      "Iteration 35351, loss = 119.87571734\n",
      "Iteration 35352, loss = 119.86301691\n",
      "Iteration 35353, loss = 119.85031761\n",
      "Iteration 35354, loss = 119.83761941\n",
      "Iteration 35355, loss = 119.82492232\n",
      "Iteration 35356, loss = 119.81222635\n",
      "Iteration 35357, loss = 119.79953149\n",
      "Iteration 35358, loss = 119.78683774\n",
      "Iteration 35359, loss = 119.77414510\n",
      "Iteration 35360, loss = 119.76145357\n",
      "Iteration 35361, loss = 119.74876315\n",
      "Iteration 35362, loss = 119.73607384\n",
      "Iteration 35363, loss = 119.72338565\n",
      "Iteration 35364, loss = 119.71069856\n",
      "Iteration 35365, loss = 119.69801258\n",
      "Iteration 35366, loss = 119.68532772\n",
      "Iteration 35367, loss = 119.67264396\n",
      "Iteration 35368, loss = 119.65996131\n",
      "Iteration 35369, loss = 119.64727977\n",
      "Iteration 35370, loss = 119.63459935\n",
      "Iteration 35371, loss = 119.62192003\n",
      "Iteration 35372, loss = 119.60924182\n",
      "Iteration 35373, loss = 119.59656472\n",
      "Iteration 35374, loss = 119.58388873\n",
      "Iteration 35375, loss = 119.57121384\n",
      "Iteration 35376, loss = 119.55854007\n",
      "Iteration 35377, loss = 119.54586742\n",
      "Iteration 35378, loss = 119.53319588\n",
      "Iteration 35379, loss = 119.52052546\n",
      "Iteration 35380, loss = 119.50785617\n",
      "Iteration 35381, loss = 119.49518804\n",
      "Iteration 35382, loss = 119.48252109\n",
      "Iteration 35383, loss = 119.46985538\n",
      "Iteration 35384, loss = 119.45719103\n",
      "Iteration 35385, loss = 119.44452823\n",
      "Iteration 35386, loss = 119.43186733\n",
      "Iteration 35387, loss = 119.41920895\n",
      "Iteration 35388, loss = 119.40655412\n",
      "Iteration 35389, loss = 119.39390449\n",
      "Iteration 35390, loss = 119.38126217\n",
      "Iteration 35391, loss = 119.36862886\n",
      "Iteration 35392, loss = 119.35600199\n",
      "Iteration 35393, loss = 119.34337016\n",
      "Iteration 35394, loss = 119.33071251\n",
      "Iteration 35395, loss = 119.31802007\n",
      "Iteration 35396, loss = 119.30531799\n",
      "Iteration 35397, loss = 119.29264709\n",
      "Iteration 35398, loss = 119.28001694\n",
      "Iteration 35399, loss = 119.26739770\n",
      "Iteration 35400, loss = 119.25475403\n",
      "Iteration 35401, loss = 119.24208231\n",
      "Iteration 35402, loss = 119.22941389\n",
      "Iteration 35403, loss = 119.21677361\n",
      "Iteration 35404, loss = 119.20414984\n",
      "Iteration 35405, loss = 119.19151469\n",
      "Iteration 35406, loss = 119.17886071\n",
      "Iteration 35407, loss = 119.16620764\n",
      "Iteration 35408, loss = 119.15357260\n",
      "Iteration 35409, loss = 119.14094781\n",
      "Iteration 35410, loss = 119.12831463\n",
      "Iteration 35411, loss = 119.11566991\n",
      "Iteration 35412, loss = 119.10302713\n",
      "Iteration 35413, loss = 119.09039569\n",
      "Iteration 35414, loss = 119.07776924\n",
      "Iteration 35415, loss = 119.06513798\n",
      "Iteration 35416, loss = 119.05250277\n",
      "Iteration 35417, loss = 119.03987206\n",
      "Iteration 35418, loss = 119.02724843\n",
      "Iteration 35419, loss = 119.01462557\n",
      "Iteration 35420, loss = 119.00199835\n",
      "Iteration 35421, loss = 118.98936971\n",
      "Iteration 35422, loss = 118.97674558\n",
      "Iteration 35423, loss = 118.96412648\n",
      "Iteration 35424, loss = 118.95150788\n",
      "Iteration 35425, loss = 118.93888712\n",
      "Iteration 35426, loss = 118.92626629\n",
      "Iteration 35427, loss = 118.91364848\n",
      "Iteration 35428, loss = 118.90103347\n",
      "Iteration 35429, loss = 118.88841889\n",
      "Iteration 35430, loss = 118.87580390\n",
      "Iteration 35431, loss = 118.86319000\n",
      "Iteration 35432, loss = 118.85057844\n",
      "Iteration 35433, loss = 118.83796848\n",
      "Iteration 35434, loss = 118.82535879\n",
      "Iteration 35435, loss = 118.81274935\n",
      "Iteration 35436, loss = 118.80014134\n",
      "Iteration 35437, loss = 118.78753536\n",
      "Iteration 35438, loss = 118.77493074\n",
      "Iteration 35439, loss = 118.76232658\n",
      "Iteration 35440, loss = 118.74972292\n",
      "Iteration 35441, loss = 118.73712054\n",
      "Iteration 35442, loss = 118.72451984\n",
      "Iteration 35443, loss = 118.71192044\n",
      "Iteration 35444, loss = 118.69932182\n",
      "Iteration 35445, loss = 118.68672397\n",
      "Iteration 35446, loss = 118.67412727\n",
      "Iteration 35447, loss = 118.66153194\n",
      "Iteration 35448, loss = 118.64893781\n",
      "Iteration 35449, loss = 118.63634462\n",
      "Iteration 35450, loss = 118.62375238\n",
      "Iteration 35451, loss = 118.61116128\n",
      "Iteration 35452, loss = 118.59857143\n",
      "Iteration 35453, loss = 118.58598272\n",
      "Iteration 35454, loss = 118.57339498\n",
      "Iteration 35455, loss = 118.56080825\n",
      "Iteration 35456, loss = 118.54822264\n",
      "Iteration 35457, loss = 118.53563824\n",
      "Iteration 35458, loss = 118.52305498\n",
      "Iteration 35459, loss = 118.51047275\n",
      "Iteration 35460, loss = 118.49789154\n",
      "Iteration 35461, loss = 118.48531141\n",
      "Iteration 35462, loss = 118.47273243\n",
      "Iteration 35463, loss = 118.46015460\n",
      "Iteration 35464, loss = 118.44757784\n",
      "Iteration 35465, loss = 118.43500214\n",
      "Iteration 35466, loss = 118.42242750\n",
      "Iteration 35467, loss = 118.40985398\n",
      "Iteration 35468, loss = 118.39728158\n",
      "Iteration 35469, loss = 118.38471027\n",
      "Iteration 35470, loss = 118.37214003\n",
      "Iteration 35471, loss = 118.35957088\n",
      "Iteration 35472, loss = 118.34700282\n",
      "Iteration 35473, loss = 118.33443586\n",
      "Iteration 35474, loss = 118.32187001\n",
      "Iteration 35475, loss = 118.30930523\n",
      "Iteration 35476, loss = 118.29674153\n",
      "Iteration 35477, loss = 118.28417893\n",
      "Iteration 35478, loss = 118.27161742\n",
      "Iteration 35479, loss = 118.25905701\n",
      "Iteration 35480, loss = 118.24649769\n",
      "Iteration 35481, loss = 118.23393945\n",
      "Iteration 35482, loss = 118.22138230\n",
      "Iteration 35483, loss = 118.20882623\n",
      "Iteration 35484, loss = 118.19627126\n",
      "Iteration 35485, loss = 118.18371739\n",
      "Iteration 35486, loss = 118.17116460\n",
      "Iteration 35487, loss = 118.15861289\n",
      "Iteration 35488, loss = 118.14606227\n",
      "Iteration 35489, loss = 118.13351274\n",
      "Iteration 35490, loss = 118.12096431\n",
      "Iteration 35491, loss = 118.10841696\n",
      "Iteration 35492, loss = 118.09587069\n",
      "Iteration 35493, loss = 118.08332551\n",
      "Iteration 35494, loss = 118.07078142\n",
      "Iteration 35495, loss = 118.05823842\n",
      "Iteration 35496, loss = 118.04569651\n",
      "Iteration 35497, loss = 118.03315568\n",
      "Iteration 35498, loss = 118.02061594\n",
      "Iteration 35499, loss = 118.00807728\n",
      "Iteration 35500, loss = 117.99553971\n",
      "Iteration 35501, loss = 117.98300322\n",
      "Iteration 35502, loss = 117.97046783\n",
      "Iteration 35503, loss = 117.95793352\n",
      "Iteration 35504, loss = 117.94540029\n",
      "Iteration 35505, loss = 117.93286815\n",
      "Iteration 35506, loss = 117.92033709\n",
      "Iteration 35507, loss = 117.90780712\n",
      "Iteration 35508, loss = 117.89527823\n",
      "Iteration 35509, loss = 117.88275043\n",
      "Iteration 35510, loss = 117.87022371\n",
      "Iteration 35511, loss = 117.85769808\n",
      "Iteration 35512, loss = 117.84517353\n",
      "Iteration 35513, loss = 117.83265006\n",
      "Iteration 35514, loss = 117.82012768\n",
      "Iteration 35515, loss = 117.80760638\n",
      "Iteration 35516, loss = 117.79508617\n",
      "Iteration 35517, loss = 117.78256703\n",
      "Iteration 35518, loss = 117.77004898\n",
      "Iteration 35519, loss = 117.75753202\n",
      "Iteration 35520, loss = 117.74501613\n",
      "Iteration 35521, loss = 117.73250133\n",
      "Iteration 35522, loss = 117.71998761\n",
      "Iteration 35523, loss = 117.70747497\n",
      "Iteration 35524, loss = 117.69496342\n",
      "Iteration 35525, loss = 117.68245294\n",
      "Iteration 35526, loss = 117.66994355\n",
      "Iteration 35527, loss = 117.65743524\n",
      "Iteration 35528, loss = 117.64492801\n",
      "Iteration 35529, loss = 117.63242186\n",
      "Iteration 35530, loss = 117.61991679\n",
      "Iteration 35531, loss = 117.60741281\n",
      "Iteration 35532, loss = 117.59490990\n",
      "Iteration 35533, loss = 117.58240807\n",
      "Iteration 35534, loss = 117.56990733\n",
      "Iteration 35535, loss = 117.55740766\n",
      "Iteration 35536, loss = 117.54490907\n",
      "Iteration 35537, loss = 117.53241156\n",
      "Iteration 35538, loss = 117.51991514\n",
      "Iteration 35539, loss = 117.50741979\n",
      "Iteration 35540, loss = 117.49492552\n",
      "Iteration 35541, loss = 117.48243232\n",
      "Iteration 35542, loss = 117.46994021\n",
      "Iteration 35543, loss = 117.45744918\n",
      "Iteration 35544, loss = 117.44495922\n",
      "Iteration 35545, loss = 117.43247034\n",
      "Iteration 35546, loss = 117.41998254\n",
      "Iteration 35547, loss = 117.40749582\n",
      "Iteration 35548, loss = 117.39501018\n",
      "Iteration 35549, loss = 117.38252561\n",
      "Iteration 35550, loss = 117.37004212\n",
      "Iteration 35551, loss = 117.35755970\n",
      "Iteration 35552, loss = 117.34507837\n",
      "Iteration 35553, loss = 117.33259811\n",
      "Iteration 35554, loss = 117.32011892\n",
      "Iteration 35555, loss = 117.30764082\n",
      "Iteration 35556, loss = 117.29516379\n",
      "Iteration 35557, loss = 117.28268783\n",
      "Iteration 35558, loss = 117.27021295\n",
      "Iteration 35559, loss = 117.25773915\n",
      "Iteration 35560, loss = 117.24526642\n",
      "Iteration 35561, loss = 117.23279477\n",
      "Iteration 35562, loss = 117.22032419\n",
      "Iteration 35563, loss = 117.20785468\n",
      "Iteration 35564, loss = 117.19538625\n",
      "Iteration 35565, loss = 117.18291890\n",
      "Iteration 35566, loss = 117.17045262\n",
      "Iteration 35567, loss = 117.15798741\n",
      "Iteration 35568, loss = 117.14552328\n",
      "Iteration 35569, loss = 117.13306022\n",
      "Iteration 35570, loss = 117.12059824\n",
      "Iteration 35571, loss = 117.10813733\n",
      "Iteration 35572, loss = 117.09567749\n",
      "Iteration 35573, loss = 117.08321872\n",
      "Iteration 35574, loss = 117.07076103\n",
      "Iteration 35575, loss = 117.05830441\n",
      "Iteration 35576, loss = 117.04584886\n",
      "Iteration 35577, loss = 117.03339439\n",
      "Iteration 35578, loss = 117.02094098\n",
      "Iteration 35579, loss = 117.00848865\n",
      "Iteration 35580, loss = 116.99603739\n",
      "Iteration 35581, loss = 116.98358721\n",
      "Iteration 35582, loss = 116.97113809\n",
      "Iteration 35583, loss = 116.95869004\n",
      "Iteration 35584, loss = 116.94624307\n",
      "Iteration 35585, loss = 116.93379717\n",
      "Iteration 35586, loss = 116.92135233\n",
      "Iteration 35587, loss = 116.90890857\n",
      "Iteration 35588, loss = 116.89646588\n",
      "Iteration 35589, loss = 116.88402425\n",
      "Iteration 35590, loss = 116.87158370\n",
      "Iteration 35591, loss = 116.85914422\n",
      "Iteration 35592, loss = 116.84670581\n",
      "Iteration 35593, loss = 116.83426846\n",
      "Iteration 35594, loss = 116.82183219\n",
      "Iteration 35595, loss = 116.80939698\n",
      "Iteration 35596, loss = 116.79696285\n",
      "Iteration 35597, loss = 116.78452978\n",
      "Iteration 35598, loss = 116.77209778\n",
      "Iteration 35599, loss = 116.75966685\n",
      "Iteration 35600, loss = 116.74723698\n",
      "Iteration 35601, loss = 116.73480819\n",
      "Iteration 35602, loss = 116.72238046\n",
      "Iteration 35603, loss = 116.70995380\n",
      "Iteration 35604, loss = 116.69752821\n",
      "Iteration 35605, loss = 116.68510368\n",
      "Iteration 35606, loss = 116.67268022\n",
      "Iteration 35607, loss = 116.66025783\n",
      "Iteration 35608, loss = 116.64783650\n",
      "Iteration 35609, loss = 116.63541624\n",
      "Iteration 35610, loss = 116.62299705\n",
      "Iteration 35611, loss = 116.61057893\n",
      "Iteration 35612, loss = 116.59816186\n",
      "Iteration 35613, loss = 116.58574587\n",
      "Iteration 35614, loss = 116.57333094\n",
      "Iteration 35615, loss = 116.56091708\n",
      "Iteration 35616, loss = 116.54850428\n",
      "Iteration 35617, loss = 116.53609254\n",
      "Iteration 35618, loss = 116.52368187\n",
      "Iteration 35619, loss = 116.51127227\n",
      "Iteration 35620, loss = 116.49886373\n",
      "Iteration 35621, loss = 116.48645625\n",
      "Iteration 35622, loss = 116.47404985\n",
      "Iteration 35623, loss = 116.46164450\n",
      "Iteration 35624, loss = 116.44924023\n",
      "Iteration 35625, loss = 116.43683702\n",
      "Iteration 35626, loss = 116.42443488\n",
      "Iteration 35627, loss = 116.41203382\n",
      "Iteration 35628, loss = 116.39963385\n",
      "Iteration 35629, loss = 116.38723498\n",
      "Iteration 35630, loss = 116.37483723\n",
      "Iteration 35631, loss = 116.36244065\n",
      "Iteration 35632, loss = 116.35004528\n",
      "Iteration 35633, loss = 116.33765121\n",
      "Iteration 35634, loss = 116.32525852\n",
      "Iteration 35635, loss = 116.31286728\n",
      "Iteration 35636, loss = 116.30047732\n",
      "Iteration 35637, loss = 116.28808830\n",
      "Iteration 35638, loss = 116.27569922\n",
      "Iteration 35639, loss = 116.26330958\n",
      "Iteration 35640, loss = 116.25091952\n",
      "Iteration 35641, loss = 116.23853076\n",
      "Iteration 35642, loss = 116.22614480\n",
      "Iteration 35643, loss = 116.21376172\n",
      "Iteration 35644, loss = 116.20138023\n",
      "Iteration 35645, loss = 116.18899882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35646, loss = 116.17661702\n",
      "Iteration 35647, loss = 116.16423566\n",
      "Iteration 35648, loss = 116.15185611\n",
      "Iteration 35649, loss = 116.13947882\n",
      "Iteration 35650, loss = 116.12710306\n",
      "Iteration 35651, loss = 116.11472783\n",
      "Iteration 35652, loss = 116.10235283\n",
      "Iteration 35653, loss = 116.08997873\n",
      "Iteration 35654, loss = 116.07760636\n",
      "Iteration 35655, loss = 116.06523595\n",
      "Iteration 35656, loss = 116.05286716\n",
      "Iteration 35657, loss = 116.04049978\n",
      "Iteration 35658, loss = 116.02813440\n",
      "Iteration 35659, loss = 116.01577241\n",
      "Iteration 35660, loss = 116.00341555\n",
      "Iteration 35661, loss = 115.99106551\n",
      "Iteration 35662, loss = 115.97872295\n",
      "Iteration 35663, loss = 115.96638563\n",
      "Iteration 35664, loss = 115.95404384\n",
      "Iteration 35665, loss = 115.94168156\n",
      "Iteration 35666, loss = 115.92928973\n",
      "Iteration 35667, loss = 115.91688587\n",
      "Iteration 35668, loss = 115.90450352\n",
      "Iteration 35669, loss = 115.89215690\n",
      "Iteration 35670, loss = 115.87982752\n",
      "Iteration 35671, loss = 115.86748490\n",
      "Iteration 35672, loss = 115.85511636\n",
      "Iteration 35673, loss = 115.84273932\n",
      "Iteration 35674, loss = 115.83037999\n",
      "Iteration 35675, loss = 115.81804204\n",
      "Iteration 35676, loss = 115.80570600\n",
      "Iteration 35677, loss = 115.79335494\n",
      "Iteration 35678, loss = 115.78099347\n",
      "Iteration 35679, loss = 115.76863940\n",
      "Iteration 35680, loss = 115.75629998\n",
      "Iteration 35681, loss = 115.74396485\n",
      "Iteration 35682, loss = 115.73162174\n",
      "Iteration 35683, loss = 115.71927170\n",
      "Iteration 35684, loss = 115.70692559\n",
      "Iteration 35685, loss = 115.69458879\n",
      "Iteration 35686, loss = 115.68225555\n",
      "Iteration 35687, loss = 115.66991816\n",
      "Iteration 35688, loss = 115.65757683\n",
      "Iteration 35689, loss = 115.64523804\n",
      "Iteration 35690, loss = 115.63290527\n",
      "Iteration 35691, loss = 115.62057518\n",
      "Iteration 35692, loss = 115.60824310\n",
      "Iteration 35693, loss = 115.59590904\n",
      "Iteration 35694, loss = 115.58357682\n",
      "Iteration 35695, loss = 115.57124857\n",
      "Iteration 35696, loss = 115.55892245\n",
      "Iteration 35697, loss = 115.54659567\n",
      "Iteration 35698, loss = 115.53426809\n",
      "Iteration 35699, loss = 115.52194187\n",
      "Iteration 35700, loss = 115.50961843\n",
      "Iteration 35701, loss = 115.49729678\n",
      "Iteration 35702, loss = 115.48497528\n",
      "Iteration 35703, loss = 115.47265368\n",
      "Iteration 35704, loss = 115.46033318\n",
      "Iteration 35705, loss = 115.44801470\n",
      "Iteration 35706, loss = 115.43569782\n",
      "Iteration 35707, loss = 115.42338157\n",
      "Iteration 35708, loss = 115.41106566\n",
      "Iteration 35709, loss = 115.39875069\n",
      "Iteration 35710, loss = 115.38643730\n",
      "Iteration 35711, loss = 115.37412536\n",
      "Iteration 35712, loss = 115.36181432\n",
      "Iteration 35713, loss = 115.34950391\n",
      "Iteration 35714, loss = 115.33719439\n",
      "Iteration 35715, loss = 115.32488616\n",
      "Iteration 35716, loss = 115.31257926\n",
      "Iteration 35717, loss = 115.30027341\n",
      "Iteration 35718, loss = 115.28796838\n",
      "Iteration 35719, loss = 115.27566424\n",
      "Iteration 35720, loss = 115.26336122\n",
      "Iteration 35721, loss = 115.25105943\n",
      "Iteration 35722, loss = 115.23875875\n",
      "Iteration 35723, loss = 115.22645902\n",
      "Iteration 35724, loss = 115.21416022\n",
      "Iteration 35725, loss = 115.20186244\n",
      "Iteration 35726, loss = 115.18956580\n",
      "Iteration 35727, loss = 115.17727029\n",
      "Iteration 35728, loss = 115.16497580\n",
      "Iteration 35729, loss = 115.15268228\n",
      "Iteration 35730, loss = 115.14038977\n",
      "Iteration 35731, loss = 115.12809832\n",
      "Iteration 35732, loss = 115.11580797\n",
      "Iteration 35733, loss = 115.10351869\n",
      "Iteration 35734, loss = 115.09123043\n",
      "Iteration 35735, loss = 115.07894317\n",
      "Iteration 35736, loss = 115.06665694\n",
      "Iteration 35737, loss = 115.05437178\n",
      "Iteration 35738, loss = 115.04208768\n",
      "Iteration 35739, loss = 115.02980464\n",
      "Iteration 35740, loss = 115.01752261\n",
      "Iteration 35741, loss = 115.00524161\n",
      "Iteration 35742, loss = 114.99296165\n",
      "Iteration 35743, loss = 114.98068274\n",
      "Iteration 35744, loss = 114.96840489\n",
      "Iteration 35745, loss = 114.95612808\n",
      "Iteration 35746, loss = 114.94385230\n",
      "Iteration 35747, loss = 114.93157755\n",
      "Iteration 35748, loss = 114.91930384\n",
      "Iteration 35749, loss = 114.90703118\n",
      "Iteration 35750, loss = 114.89475957\n",
      "Iteration 35751, loss = 114.88248900\n",
      "Iteration 35752, loss = 114.87021945\n",
      "Iteration 35753, loss = 114.85795095\n",
      "Iteration 35754, loss = 114.84568348\n",
      "Iteration 35755, loss = 114.83341705\n",
      "Iteration 35756, loss = 114.82115167\n",
      "Iteration 35757, loss = 114.80888733\n",
      "Iteration 35758, loss = 114.79662402\n",
      "Iteration 35759, loss = 114.78436175\n",
      "Iteration 35760, loss = 114.77210051\n",
      "Iteration 35761, loss = 114.75984031\n",
      "Iteration 35762, loss = 114.74758116\n",
      "Iteration 35763, loss = 114.73532304\n",
      "Iteration 35764, loss = 114.72306596\n",
      "Iteration 35765, loss = 114.71080991\n",
      "Iteration 35766, loss = 114.69855490\n",
      "Iteration 35767, loss = 114.68630092\n",
      "Iteration 35768, loss = 114.67404799\n",
      "Iteration 35769, loss = 114.66179609\n",
      "Iteration 35770, loss = 114.64954522\n",
      "Iteration 35771, loss = 114.63729539\n",
      "Iteration 35772, loss = 114.62504660\n",
      "Iteration 35773, loss = 114.61279884\n",
      "Iteration 35774, loss = 114.60055212\n",
      "Iteration 35775, loss = 114.58830643\n",
      "Iteration 35776, loss = 114.57606178\n",
      "Iteration 35777, loss = 114.56381816\n",
      "Iteration 35778, loss = 114.55157558\n",
      "Iteration 35779, loss = 114.53933403\n",
      "Iteration 35780, loss = 114.52709351\n",
      "Iteration 35781, loss = 114.51485403\n",
      "Iteration 35782, loss = 114.50261558\n",
      "Iteration 35783, loss = 114.49037816\n",
      "Iteration 35784, loss = 114.47814178\n",
      "Iteration 35785, loss = 114.46590643\n",
      "Iteration 35786, loss = 114.45367212\n",
      "Iteration 35787, loss = 114.44143883\n",
      "Iteration 35788, loss = 114.42920658\n",
      "Iteration 35789, loss = 114.41697537\n",
      "Iteration 35790, loss = 114.40474518\n",
      "Iteration 35791, loss = 114.39251603\n",
      "Iteration 35792, loss = 114.38028790\n",
      "Iteration 35793, loss = 114.36806081\n",
      "Iteration 35794, loss = 114.35583475\n",
      "Iteration 35795, loss = 114.34360972\n",
      "Iteration 35796, loss = 114.33138573\n",
      "Iteration 35797, loss = 114.31916276\n",
      "Iteration 35798, loss = 114.30694082\n",
      "Iteration 35799, loss = 114.29471992\n",
      "Iteration 35800, loss = 114.28250004\n",
      "Iteration 35801, loss = 114.27028120\n",
      "Iteration 35802, loss = 114.25806338\n",
      "Iteration 35803, loss = 114.24584660\n",
      "Iteration 35804, loss = 114.23363084\n",
      "Iteration 35805, loss = 114.22141611\n",
      "Iteration 35806, loss = 114.20920241\n",
      "Iteration 35807, loss = 114.19698974\n",
      "Iteration 35808, loss = 114.18477810\n",
      "Iteration 35809, loss = 114.17256749\n",
      "Iteration 35810, loss = 114.16035791\n",
      "Iteration 35811, loss = 114.14814935\n",
      "Iteration 35812, loss = 114.13594182\n",
      "Iteration 35813, loss = 114.12373532\n",
      "Iteration 35814, loss = 114.11152985\n",
      "Iteration 35815, loss = 114.09932541\n",
      "Iteration 35816, loss = 114.08712199\n",
      "Iteration 35817, loss = 114.07491960\n",
      "Iteration 35818, loss = 114.06271823\n",
      "Iteration 35819, loss = 114.05051789\n",
      "Iteration 35820, loss = 114.03831858\n",
      "Iteration 35821, loss = 114.02612029\n",
      "Iteration 35822, loss = 114.01392303\n",
      "Iteration 35823, loss = 114.00172680\n",
      "Iteration 35824, loss = 113.98953159\n",
      "Iteration 35825, loss = 113.97733741\n",
      "Iteration 35826, loss = 113.96514425\n",
      "Iteration 35827, loss = 113.95295212\n",
      "Iteration 35828, loss = 113.94076101\n",
      "Iteration 35829, loss = 113.92857093\n",
      "Iteration 35830, loss = 113.91638187\n",
      "Iteration 35831, loss = 113.90419383\n",
      "Iteration 35832, loss = 113.89200682\n",
      "Iteration 35833, loss = 113.87982084\n",
      "Iteration 35834, loss = 113.86763587\n",
      "Iteration 35835, loss = 113.85545193\n",
      "Iteration 35836, loss = 113.84326902\n",
      "Iteration 35837, loss = 113.83108712\n",
      "Iteration 35838, loss = 113.81890625\n",
      "Iteration 35839, loss = 113.80672640\n",
      "Iteration 35840, loss = 113.79454758\n",
      "Iteration 35841, loss = 113.78236978\n",
      "Iteration 35842, loss = 113.77019299\n",
      "Iteration 35843, loss = 113.75801724\n",
      "Iteration 35844, loss = 113.74584250\n",
      "Iteration 35845, loss = 113.73366878\n",
      "Iteration 35846, loss = 113.72149609\n",
      "Iteration 35847, loss = 113.70932441\n",
      "Iteration 35848, loss = 113.69715376\n",
      "Iteration 35849, loss = 113.68498413\n",
      "Iteration 35850, loss = 113.67281552\n",
      "Iteration 35851, loss = 113.66064793\n",
      "Iteration 35852, loss = 113.64848136\n",
      "Iteration 35853, loss = 113.63631580\n",
      "Iteration 35854, loss = 113.62415127\n",
      "Iteration 35855, loss = 113.61198776\n",
      "Iteration 35856, loss = 113.59982527\n",
      "Iteration 35857, loss = 113.58766380\n",
      "Iteration 35858, loss = 113.57550334\n",
      "Iteration 35859, loss = 113.56334391\n",
      "Iteration 35860, loss = 113.55118549\n",
      "Iteration 35861, loss = 113.53902809\n",
      "Iteration 35862, loss = 113.52687171\n",
      "Iteration 35863, loss = 113.51471635\n",
      "Iteration 35864, loss = 113.50256201\n",
      "Iteration 35865, loss = 113.49040868\n",
      "Iteration 35866, loss = 113.47825637\n",
      "Iteration 35867, loss = 113.46610508\n",
      "Iteration 35868, loss = 113.45395480\n",
      "Iteration 35869, loss = 113.44180555\n",
      "Iteration 35870, loss = 113.42965731\n",
      "Iteration 35871, loss = 113.41751008\n",
      "Iteration 35872, loss = 113.40536387\n",
      "Iteration 35873, loss = 113.39321868\n",
      "Iteration 35874, loss = 113.38107450\n",
      "Iteration 35875, loss = 113.36893134\n",
      "Iteration 35876, loss = 113.35678920\n",
      "Iteration 35877, loss = 113.34464807\n",
      "Iteration 35878, loss = 113.33250795\n",
      "Iteration 35879, loss = 113.32036885\n",
      "Iteration 35880, loss = 113.30823076\n",
      "Iteration 35881, loss = 113.29609369\n",
      "Iteration 35882, loss = 113.28395764\n",
      "Iteration 35883, loss = 113.27182259\n",
      "Iteration 35884, loss = 113.25968857\n",
      "Iteration 35885, loss = 113.24755555\n",
      "Iteration 35886, loss = 113.23542355\n",
      "Iteration 35887, loss = 113.22329256\n",
      "Iteration 35888, loss = 113.21116259\n",
      "Iteration 35889, loss = 113.19903362\n",
      "Iteration 35890, loss = 113.18690567\n",
      "Iteration 35891, loss = 113.17477874\n",
      "Iteration 35892, loss = 113.16265281\n",
      "Iteration 35893, loss = 113.15052790\n",
      "Iteration 35894, loss = 113.13840400\n",
      "Iteration 35895, loss = 113.12628111\n",
      "Iteration 35896, loss = 113.11415923\n",
      "Iteration 35897, loss = 113.10203837\n",
      "Iteration 35898, loss = 113.08991851\n",
      "Iteration 35899, loss = 113.07779967\n",
      "Iteration 35900, loss = 113.06568184\n",
      "Iteration 35901, loss = 113.05356502\n",
      "Iteration 35902, loss = 113.04144921\n",
      "Iteration 35903, loss = 113.02933441\n",
      "Iteration 35904, loss = 113.01722062\n",
      "Iteration 35905, loss = 113.00510784\n",
      "Iteration 35906, loss = 112.99299607\n",
      "Iteration 35907, loss = 112.98088532\n",
      "Iteration 35908, loss = 112.96877558\n",
      "Iteration 35909, loss = 112.95666686\n",
      "Iteration 35910, loss = 112.94455917\n",
      "Iteration 35911, loss = 112.93245252\n",
      "Iteration 35912, loss = 112.92034694\n",
      "Iteration 35913, loss = 112.90824247\n",
      "Iteration 35914, loss = 112.89613919\n",
      "Iteration 35915, loss = 112.88403725\n",
      "Iteration 35916, loss = 112.87193692\n",
      "Iteration 35917, loss = 112.85983866\n",
      "Iteration 35918, loss = 112.84774331\n",
      "Iteration 35919, loss = 112.83565224\n",
      "Iteration 35920, loss = 112.82356759\n",
      "Iteration 35921, loss = 112.81149200\n",
      "Iteration 35922, loss = 112.79942688\n",
      "Iteration 35923, loss = 112.78736764\n",
      "Iteration 35924, loss = 112.77529719\n",
      "Iteration 35925, loss = 112.76319049\n",
      "Iteration 35926, loss = 112.75104364\n",
      "Iteration 35927, loss = 112.73889652\n",
      "Iteration 35928, loss = 112.72679519\n",
      "Iteration 35929, loss = 112.71473800\n",
      "Iteration 35930, loss = 112.70268078\n",
      "Iteration 35931, loss = 112.69058622\n",
      "Iteration 35932, loss = 112.67846493\n",
      "Iteration 35933, loss = 112.66636047\n",
      "Iteration 35934, loss = 112.65429087\n",
      "Iteration 35935, loss = 112.64222944\n",
      "Iteration 35936, loss = 112.63014543\n",
      "Iteration 35937, loss = 112.61804377\n",
      "Iteration 35938, loss = 112.60595355\n",
      "Iteration 35939, loss = 112.59388506\n",
      "Iteration 35940, loss = 112.58181902\n",
      "Iteration 35941, loss = 112.56973796\n",
      "Iteration 35942, loss = 112.55764980\n",
      "Iteration 35943, loss = 112.54557237\n",
      "Iteration 35944, loss = 112.53350664\n",
      "Iteration 35945, loss = 112.52143865\n",
      "Iteration 35946, loss = 112.50936187\n",
      "Iteration 35947, loss = 112.49728488\n",
      "Iteration 35948, loss = 112.48521641\n",
      "Iteration 35949, loss = 112.47315293\n",
      "Iteration 35950, loss = 112.46108600\n",
      "Iteration 35951, loss = 112.44901523\n",
      "Iteration 35952, loss = 112.43694728\n",
      "Iteration 35953, loss = 112.42488497\n",
      "Iteration 35954, loss = 112.41282400\n",
      "Iteration 35955, loss = 112.40076048\n",
      "Iteration 35956, loss = 112.38869634\n",
      "Iteration 35957, loss = 112.37663548\n",
      "Iteration 35958, loss = 112.36457789\n",
      "Iteration 35959, loss = 112.35252035\n",
      "Iteration 35960, loss = 112.34046161\n",
      "Iteration 35961, loss = 112.32840377\n",
      "Iteration 35962, loss = 112.31634871\n",
      "Iteration 35963, loss = 112.30429549\n",
      "Iteration 35964, loss = 112.29224219\n",
      "Iteration 35965, loss = 112.28018874\n",
      "Iteration 35966, loss = 112.26813669\n",
      "Iteration 35967, loss = 112.25608677\n",
      "Iteration 35968, loss = 112.24403803\n",
      "Iteration 35969, loss = 112.23198946\n",
      "Iteration 35970, loss = 112.21994136\n",
      "Iteration 35971, loss = 112.20789470\n",
      "Iteration 35972, loss = 112.19584967\n",
      "Iteration 35973, loss = 112.18380560\n",
      "Iteration 35974, loss = 112.17176199\n",
      "Iteration 35975, loss = 112.15971915\n",
      "Iteration 35976, loss = 112.14767763\n",
      "Iteration 35977, loss = 112.13563746\n",
      "Iteration 35978, loss = 112.12359820\n",
      "Iteration 35979, loss = 112.11155961\n",
      "Iteration 35980, loss = 112.09952193\n",
      "Iteration 35981, loss = 112.08748544\n",
      "Iteration 35982, loss = 112.07545014\n",
      "Iteration 35983, loss = 112.06341577\n",
      "Iteration 35984, loss = 112.05138221\n",
      "Iteration 35985, loss = 112.03934960\n",
      "Iteration 35986, loss = 112.02731811\n",
      "Iteration 35987, loss = 112.01528771\n",
      "Iteration 35988, loss = 112.00325826\n",
      "Iteration 35989, loss = 111.99122971\n",
      "Iteration 35990, loss = 111.97920212\n",
      "Iteration 35991, loss = 111.96717560\n",
      "Iteration 35992, loss = 111.95515012\n",
      "Iteration 35993, loss = 111.94312562\n",
      "Iteration 35994, loss = 111.93110205\n",
      "Iteration 35995, loss = 111.91907946\n",
      "Iteration 35996, loss = 111.90705789\n",
      "Iteration 35997, loss = 111.89503735\n",
      "Iteration 35998, loss = 111.88301780\n",
      "Iteration 35999, loss = 111.87099920\n",
      "Iteration 36000, loss = 111.85898158\n",
      "Iteration 36001, loss = 111.84696497\n",
      "Iteration 36002, loss = 111.83494937\n",
      "Iteration 36003, loss = 111.82293476\n",
      "Iteration 36004, loss = 111.81092112\n",
      "Iteration 36005, loss = 111.79890846\n",
      "Iteration 36006, loss = 111.78689680\n",
      "Iteration 36007, loss = 111.77488614\n",
      "Iteration 36008, loss = 111.76287648\n",
      "Iteration 36009, loss = 111.75086779\n",
      "Iteration 36010, loss = 111.73886009\n",
      "Iteration 36011, loss = 111.72685337\n",
      "Iteration 36012, loss = 111.71484765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36013, loss = 111.70284292\n",
      "Iteration 36014, loss = 111.69083918\n",
      "Iteration 36015, loss = 111.67883642\n",
      "Iteration 36016, loss = 111.66683464\n",
      "Iteration 36017, loss = 111.65483385\n",
      "Iteration 36018, loss = 111.64283406\n",
      "Iteration 36019, loss = 111.63083525\n",
      "Iteration 36020, loss = 111.61883743\n",
      "Iteration 36021, loss = 111.60684059\n",
      "Iteration 36022, loss = 111.59484474\n",
      "Iteration 36023, loss = 111.58284987\n",
      "Iteration 36024, loss = 111.57085600\n",
      "Iteration 36025, loss = 111.55886310\n",
      "Iteration 36026, loss = 111.54687120\n",
      "Iteration 36027, loss = 111.53488027\n",
      "Iteration 36028, loss = 111.52289033\n",
      "Iteration 36029, loss = 111.51090138\n",
      "Iteration 36030, loss = 111.49891341\n",
      "Iteration 36031, loss = 111.48692643\n",
      "Iteration 36032, loss = 111.47494043\n",
      "Iteration 36033, loss = 111.46295541\n",
      "Iteration 36034, loss = 111.45097138\n",
      "Iteration 36035, loss = 111.43898833\n",
      "Iteration 36036, loss = 111.42700627\n",
      "Iteration 36037, loss = 111.41502519\n",
      "Iteration 36038, loss = 111.40304509\n",
      "Iteration 36039, loss = 111.39106597\n",
      "Iteration 36040, loss = 111.37908784\n",
      "Iteration 36041, loss = 111.36711069\n",
      "Iteration 36042, loss = 111.35513452\n",
      "Iteration 36043, loss = 111.34315933\n",
      "Iteration 36044, loss = 111.33118513\n",
      "Iteration 36045, loss = 111.31921190\n",
      "Iteration 36046, loss = 111.30723966\n",
      "Iteration 36047, loss = 111.29526840\n",
      "Iteration 36048, loss = 111.28329812\n",
      "Iteration 36049, loss = 111.27132882\n",
      "Iteration 36050, loss = 111.25936050\n",
      "Iteration 36051, loss = 111.24739317\n",
      "Iteration 36052, loss = 111.23542681\n",
      "Iteration 36053, loss = 111.22346143\n",
      "Iteration 36054, loss = 111.21149703\n",
      "Iteration 36055, loss = 111.19953361\n",
      "Iteration 36056, loss = 111.18757117\n",
      "Iteration 36057, loss = 111.17560971\n",
      "Iteration 36058, loss = 111.16364923\n",
      "Iteration 36059, loss = 111.15168973\n",
      "Iteration 36060, loss = 111.13973121\n",
      "Iteration 36061, loss = 111.12777366\n",
      "Iteration 36062, loss = 111.11581709\n",
      "Iteration 36063, loss = 111.10386150\n",
      "Iteration 36064, loss = 111.09190689\n",
      "Iteration 36065, loss = 111.07995326\n",
      "Iteration 36066, loss = 111.06800060\n",
      "Iteration 36067, loss = 111.05604892\n",
      "Iteration 36068, loss = 111.04409822\n",
      "Iteration 36069, loss = 111.03214849\n",
      "Iteration 36070, loss = 111.02019974\n",
      "Iteration 36071, loss = 111.00825197\n",
      "Iteration 36072, loss = 110.99630517\n",
      "Iteration 36073, loss = 110.98435935\n",
      "Iteration 36074, loss = 110.97241451\n",
      "Iteration 36075, loss = 110.96047064\n",
      "Iteration 36076, loss = 110.94852774\n",
      "Iteration 36077, loss = 110.93658582\n",
      "Iteration 36078, loss = 110.92464488\n",
      "Iteration 36079, loss = 110.91270491\n",
      "Iteration 36080, loss = 110.90076591\n",
      "Iteration 36081, loss = 110.88882789\n",
      "Iteration 36082, loss = 110.87689084\n",
      "Iteration 36083, loss = 110.86495477\n",
      "Iteration 36084, loss = 110.85301967\n",
      "Iteration 36085, loss = 110.84108554\n",
      "Iteration 36086, loss = 110.82915239\n",
      "Iteration 36087, loss = 110.81722021\n",
      "Iteration 36088, loss = 110.80528901\n",
      "Iteration 36089, loss = 110.79335877\n",
      "Iteration 36090, loss = 110.78142951\n",
      "Iteration 36091, loss = 110.76950122\n",
      "Iteration 36092, loss = 110.75757390\n",
      "Iteration 36093, loss = 110.74564756\n",
      "Iteration 36094, loss = 110.73372218\n",
      "Iteration 36095, loss = 110.72179778\n",
      "Iteration 36096, loss = 110.70987435\n",
      "Iteration 36097, loss = 110.69795189\n",
      "Iteration 36098, loss = 110.68603040\n",
      "Iteration 36099, loss = 110.67410988\n",
      "Iteration 36100, loss = 110.66219034\n",
      "Iteration 36101, loss = 110.65027176\n",
      "Iteration 36102, loss = 110.63835415\n",
      "Iteration 36103, loss = 110.62643751\n",
      "Iteration 36104, loss = 110.61452185\n",
      "Iteration 36105, loss = 110.60260715\n",
      "Iteration 36106, loss = 110.59069342\n",
      "Iteration 36107, loss = 110.57878066\n",
      "Iteration 36108, loss = 110.56686886\n",
      "Iteration 36109, loss = 110.55495804\n",
      "Iteration 36110, loss = 110.54304819\n",
      "Iteration 36111, loss = 110.53113930\n",
      "Iteration 36112, loss = 110.51923138\n",
      "Iteration 36113, loss = 110.50732443\n",
      "Iteration 36114, loss = 110.49541845\n",
      "Iteration 36115, loss = 110.48351343\n",
      "Iteration 36116, loss = 110.47160938\n",
      "Iteration 36117, loss = 110.45970630\n",
      "Iteration 36118, loss = 110.44780419\n",
      "Iteration 36119, loss = 110.43590304\n",
      "Iteration 36120, loss = 110.42400286\n",
      "Iteration 36121, loss = 110.41210364\n",
      "Iteration 36122, loss = 110.40020539\n",
      "Iteration 36123, loss = 110.38830811\n",
      "Iteration 36124, loss = 110.37641179\n",
      "Iteration 36125, loss = 110.36451644\n",
      "Iteration 36126, loss = 110.35262205\n",
      "Iteration 36127, loss = 110.34072863\n",
      "Iteration 36128, loss = 110.32883617\n",
      "Iteration 36129, loss = 110.31694468\n",
      "Iteration 36130, loss = 110.30505415\n",
      "Iteration 36131, loss = 110.29316458\n",
      "Iteration 36132, loss = 110.28127598\n",
      "Iteration 36133, loss = 110.26938834\n",
      "Iteration 36134, loss = 110.25750167\n",
      "Iteration 36135, loss = 110.24561596\n",
      "Iteration 36136, loss = 110.23373121\n",
      "Iteration 36137, loss = 110.22184742\n",
      "Iteration 36138, loss = 110.20996460\n",
      "Iteration 36139, loss = 110.19808274\n",
      "Iteration 36140, loss = 110.18620185\n",
      "Iteration 36141, loss = 110.17432191\n",
      "Iteration 36142, loss = 110.16244294\n",
      "Iteration 36143, loss = 110.15056493\n",
      "Iteration 36144, loss = 110.13868788\n",
      "Iteration 36145, loss = 110.12681179\n",
      "Iteration 36146, loss = 110.11493666\n",
      "Iteration 36147, loss = 110.10306249\n",
      "Iteration 36148, loss = 110.09118929\n",
      "Iteration 36149, loss = 110.07931704\n",
      "Iteration 36150, loss = 110.06744575\n",
      "Iteration 36151, loss = 110.05557543\n",
      "Iteration 36152, loss = 110.04370606\n",
      "Iteration 36153, loss = 110.03183766\n",
      "Iteration 36154, loss = 110.01997021\n",
      "Iteration 36155, loss = 110.00810372\n",
      "Iteration 36156, loss = 109.99623819\n",
      "Iteration 36157, loss = 109.98437362\n",
      "Iteration 36158, loss = 109.97251001\n",
      "Iteration 36159, loss = 109.96064736\n",
      "Iteration 36160, loss = 109.94878566\n",
      "Iteration 36161, loss = 109.93692493\n",
      "Iteration 36162, loss = 109.92506515\n",
      "Iteration 36163, loss = 109.91320633\n",
      "Iteration 36164, loss = 109.90134846\n",
      "Iteration 36165, loss = 109.88949156\n",
      "Iteration 36166, loss = 109.87763561\n",
      "Iteration 36167, loss = 109.86578061\n",
      "Iteration 36168, loss = 109.85392658\n",
      "Iteration 36169, loss = 109.84207350\n",
      "Iteration 36170, loss = 109.83022137\n",
      "Iteration 36171, loss = 109.81837020\n",
      "Iteration 36172, loss = 109.80651999\n",
      "Iteration 36173, loss = 109.79467074\n",
      "Iteration 36174, loss = 109.78282243\n",
      "Iteration 36175, loss = 109.77097509\n",
      "Iteration 36176, loss = 109.75912870\n",
      "Iteration 36177, loss = 109.74728326\n",
      "Iteration 36178, loss = 109.73543878\n",
      "Iteration 36179, loss = 109.72359525\n",
      "Iteration 36180, loss = 109.71175267\n",
      "Iteration 36181, loss = 109.69991105\n",
      "Iteration 36182, loss = 109.68807039\n",
      "Iteration 36183, loss = 109.67623067\n",
      "Iteration 36184, loss = 109.66439191\n",
      "Iteration 36185, loss = 109.65255411\n",
      "Iteration 36186, loss = 109.64071725\n",
      "Iteration 36187, loss = 109.62888135\n",
      "Iteration 36188, loss = 109.61704640\n",
      "Iteration 36189, loss = 109.60521240\n",
      "Iteration 36190, loss = 109.59337936\n",
      "Iteration 36191, loss = 109.58154727\n",
      "Iteration 36192, loss = 109.56971613\n",
      "Iteration 36193, loss = 109.55788594\n",
      "Iteration 36194, loss = 109.54605670\n",
      "Iteration 36195, loss = 109.53422841\n",
      "Iteration 36196, loss = 109.52240107\n",
      "Iteration 36197, loss = 109.51057469\n",
      "Iteration 36198, loss = 109.49874925\n",
      "Iteration 36199, loss = 109.48692476\n",
      "Iteration 36200, loss = 109.47510123\n",
      "Iteration 36201, loss = 109.46327864\n",
      "Iteration 36202, loss = 109.45145701\n",
      "Iteration 36203, loss = 109.43963632\n",
      "Iteration 36204, loss = 109.42781659\n",
      "Iteration 36205, loss = 109.41599781\n",
      "Iteration 36206, loss = 109.40417998\n",
      "Iteration 36207, loss = 109.39236311\n",
      "Iteration 36208, loss = 109.38054722\n",
      "Iteration 36209, loss = 109.36873230\n",
      "Iteration 36210, loss = 109.35691841\n",
      "Iteration 36211, loss = 109.34510559\n",
      "Iteration 36212, loss = 109.33329396\n",
      "Iteration 36213, loss = 109.32148372\n",
      "Iteration 36214, loss = 109.30967526\n",
      "Iteration 36215, loss = 109.29786930\n",
      "Iteration 36216, loss = 109.28606711\n",
      "Iteration 36217, loss = 109.27427086\n",
      "Iteration 36218, loss = 109.26248374\n",
      "Iteration 36219, loss = 109.25070886\n",
      "Iteration 36220, loss = 109.23894489\n",
      "Iteration 36221, loss = 109.22717656\n",
      "Iteration 36222, loss = 109.21537279\n",
      "Iteration 36223, loss = 109.20351630\n",
      "Iteration 36224, loss = 109.19164522\n",
      "Iteration 36225, loss = 109.17982251\n",
      "Iteration 36226, loss = 109.16805717\n",
      "Iteration 36227, loss = 109.15629674\n",
      "Iteration 36228, loss = 109.14449131\n",
      "Iteration 36229, loss = 109.13265316\n",
      "Iteration 36230, loss = 109.12083819\n",
      "Iteration 36231, loss = 109.10906505\n",
      "Iteration 36232, loss = 109.09729508\n",
      "Iteration 36233, loss = 109.08549393\n",
      "Iteration 36234, loss = 109.07367872\n",
      "Iteration 36235, loss = 109.06188583\n",
      "Iteration 36236, loss = 109.05011398\n",
      "Iteration 36237, loss = 109.03833103\n",
      "Iteration 36238, loss = 109.02652691\n",
      "Iteration 36239, loss = 109.01472575\n",
      "Iteration 36240, loss = 109.00294528\n",
      "Iteration 36241, loss = 108.99117180\n",
      "Iteration 36242, loss = 108.97938661\n",
      "Iteration 36243, loss = 108.96759407\n",
      "Iteration 36244, loss = 108.95580955\n",
      "Iteration 36245, loss = 108.94403395\n",
      "Iteration 36246, loss = 108.93225577\n",
      "Iteration 36247, loss = 108.92047183\n",
      "Iteration 36248, loss = 108.90869067\n",
      "Iteration 36249, loss = 108.89691645\n",
      "Iteration 36250, loss = 108.88514288\n",
      "Iteration 36251, loss = 108.87336499\n",
      "Iteration 36252, loss = 108.86158706\n",
      "Iteration 36253, loss = 108.84981449\n",
      "Iteration 36254, loss = 108.83804510\n",
      "Iteration 36255, loss = 108.82627360\n",
      "Iteration 36256, loss = 108.81450011\n",
      "Iteration 36257, loss = 108.80272922\n",
      "Iteration 36258, loss = 108.79096231\n",
      "Iteration 36259, loss = 108.77919606\n",
      "Iteration 36260, loss = 108.76742821\n",
      "Iteration 36261, loss = 108.75566066\n",
      "Iteration 36262, loss = 108.74389584\n",
      "Iteration 36263, loss = 108.73213311\n",
      "Iteration 36264, loss = 108.72037034\n",
      "Iteration 36265, loss = 108.70860731\n",
      "Iteration 36266, loss = 108.69684557\n",
      "Iteration 36267, loss = 108.68508580\n",
      "Iteration 36268, loss = 108.67332704\n",
      "Iteration 36269, loss = 108.66156847\n",
      "Iteration 36270, loss = 108.64981057\n",
      "Iteration 36271, loss = 108.63805410\n",
      "Iteration 36272, loss = 108.62629891\n",
      "Iteration 36273, loss = 108.61454438\n",
      "Iteration 36274, loss = 108.60279043\n",
      "Iteration 36275, loss = 108.59103755\n",
      "Iteration 36276, loss = 108.57928594\n",
      "Iteration 36277, loss = 108.56753526\n",
      "Iteration 36278, loss = 108.55578523\n",
      "Iteration 36279, loss = 108.54403604\n",
      "Iteration 36280, loss = 108.53228800\n",
      "Iteration 36281, loss = 108.52054105\n",
      "Iteration 36282, loss = 108.50879493\n",
      "Iteration 36283, loss = 108.49704955\n",
      "Iteration 36284, loss = 108.48530512\n",
      "Iteration 36285, loss = 108.47356179\n",
      "Iteration 36286, loss = 108.46181945\n",
      "Iteration 36287, loss = 108.45007795\n",
      "Iteration 36288, loss = 108.43833726\n",
      "Iteration 36289, loss = 108.42659755\n",
      "Iteration 36290, loss = 108.41485887\n",
      "Iteration 36291, loss = 108.40312114\n",
      "Iteration 36292, loss = 108.39138428\n",
      "Iteration 36293, loss = 108.37964829\n",
      "Iteration 36294, loss = 108.36791326\n",
      "Iteration 36295, loss = 108.35617922\n",
      "Iteration 36296, loss = 108.34444611\n",
      "Iteration 36297, loss = 108.33271389\n",
      "Iteration 36298, loss = 108.32098258\n",
      "Iteration 36299, loss = 108.30925221\n",
      "Iteration 36300, loss = 108.29752281\n",
      "Iteration 36301, loss = 108.28579433\n",
      "Iteration 36302, loss = 108.27406675\n",
      "Iteration 36303, loss = 108.26234010\n",
      "Iteration 36304, loss = 108.25061439\n",
      "Iteration 36305, loss = 108.23888961\n",
      "Iteration 36306, loss = 108.22716576\n",
      "Iteration 36307, loss = 108.21544283\n",
      "Iteration 36308, loss = 108.20372082\n",
      "Iteration 36309, loss = 108.19199975\n",
      "Iteration 36310, loss = 108.18027961\n",
      "Iteration 36311, loss = 108.16856039\n",
      "Iteration 36312, loss = 108.15684209\n",
      "Iteration 36313, loss = 108.14512472\n",
      "Iteration 36314, loss = 108.13340827\n",
      "Iteration 36315, loss = 108.12169276\n",
      "Iteration 36316, loss = 108.10997817\n",
      "Iteration 36317, loss = 108.09826450\n",
      "Iteration 36318, loss = 108.08655176\n",
      "Iteration 36319, loss = 108.07483994\n",
      "Iteration 36320, loss = 108.06312905\n",
      "Iteration 36321, loss = 108.05141908\n",
      "Iteration 36322, loss = 108.03971004\n",
      "Iteration 36323, loss = 108.02800192\n",
      "Iteration 36324, loss = 108.01629472\n",
      "Iteration 36325, loss = 108.00458845\n",
      "Iteration 36326, loss = 107.99288310\n",
      "Iteration 36327, loss = 107.98117868\n",
      "Iteration 36328, loss = 107.96947517\n",
      "Iteration 36329, loss = 107.95777259\n",
      "Iteration 36330, loss = 107.94607093\n",
      "Iteration 36331, loss = 107.93437020\n",
      "Iteration 36332, loss = 107.92267038\n",
      "Iteration 36333, loss = 107.91097149\n",
      "Iteration 36334, loss = 107.89927352\n",
      "Iteration 36335, loss = 107.88757647\n",
      "Iteration 36336, loss = 107.87588034\n",
      "Iteration 36337, loss = 107.86418513\n",
      "Iteration 36338, loss = 107.85249085\n",
      "Iteration 36339, loss = 107.84079748\n",
      "Iteration 36340, loss = 107.82910504\n",
      "Iteration 36341, loss = 107.81741351\n",
      "Iteration 36342, loss = 107.80572291\n",
      "Iteration 36343, loss = 107.79403322\n",
      "Iteration 36344, loss = 107.78234445\n",
      "Iteration 36345, loss = 107.77065661\n",
      "Iteration 36346, loss = 107.75896968\n",
      "Iteration 36347, loss = 107.74728367\n",
      "Iteration 36348, loss = 107.73559858\n",
      "Iteration 36349, loss = 107.72391441\n",
      "Iteration 36350, loss = 107.71223116\n",
      "Iteration 36351, loss = 107.70054882\n",
      "Iteration 36352, loss = 107.68886740\n",
      "Iteration 36353, loss = 107.67718690\n",
      "Iteration 36354, loss = 107.66550732\n",
      "Iteration 36355, loss = 107.65382865\n",
      "Iteration 36356, loss = 107.64215091\n",
      "Iteration 36357, loss = 107.63047407\n",
      "Iteration 36358, loss = 107.61879816\n",
      "Iteration 36359, loss = 107.60712316\n",
      "Iteration 36360, loss = 107.59544908\n",
      "Iteration 36361, loss = 107.58377591\n",
      "Iteration 36362, loss = 107.57210366\n",
      "Iteration 36363, loss = 107.56043232\n",
      "Iteration 36364, loss = 107.54876190\n",
      "Iteration 36365, loss = 107.53709240\n",
      "Iteration 36366, loss = 107.52542381\n",
      "Iteration 36367, loss = 107.51375613\n",
      "Iteration 36368, loss = 107.50208937\n",
      "Iteration 36369, loss = 107.49042352\n",
      "Iteration 36370, loss = 107.47875859\n",
      "Iteration 36371, loss = 107.46709457\n",
      "Iteration 36372, loss = 107.45543146\n",
      "Iteration 36373, loss = 107.44376927\n",
      "Iteration 36374, loss = 107.43210799\n",
      "Iteration 36375, loss = 107.42044763\n",
      "Iteration 36376, loss = 107.40878817\n",
      "Iteration 36377, loss = 107.39712963\n",
      "Iteration 36378, loss = 107.38547201\n",
      "Iteration 36379, loss = 107.37381529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36380, loss = 107.36215948\n",
      "Iteration 36381, loss = 107.35050459\n",
      "Iteration 36382, loss = 107.33885061\n",
      "Iteration 36383, loss = 107.32719754\n",
      "Iteration 36384, loss = 107.31554538\n",
      "Iteration 36385, loss = 107.30389413\n",
      "Iteration 36386, loss = 107.29224380\n",
      "Iteration 36387, loss = 107.28059437\n",
      "Iteration 36388, loss = 107.26894585\n",
      "Iteration 36389, loss = 107.25729825\n",
      "Iteration 36390, loss = 107.24565155\n",
      "Iteration 36391, loss = 107.23400576\n",
      "Iteration 36392, loss = 107.22236088\n",
      "Iteration 36393, loss = 107.21071692\n",
      "Iteration 36394, loss = 107.19907386\n",
      "Iteration 36395, loss = 107.18743171\n",
      "Iteration 36396, loss = 107.17579046\n",
      "Iteration 36397, loss = 107.16415013\n",
      "Iteration 36398, loss = 107.15251070\n",
      "Iteration 36399, loss = 107.14087219\n",
      "Iteration 36400, loss = 107.12923457\n",
      "Iteration 36401, loss = 107.11759787\n",
      "Iteration 36402, loss = 107.10596208\n",
      "Iteration 36403, loss = 107.09432719\n",
      "Iteration 36404, loss = 107.08269321\n",
      "Iteration 36405, loss = 107.07106013\n",
      "Iteration 36406, loss = 107.05942796\n",
      "Iteration 36407, loss = 107.04779670\n",
      "Iteration 36408, loss = 107.03616634\n",
      "Iteration 36409, loss = 107.02453689\n",
      "Iteration 36410, loss = 107.01290835\n",
      "Iteration 36411, loss = 107.00128071\n",
      "Iteration 36412, loss = 106.98965397\n",
      "Iteration 36413, loss = 106.97802814\n",
      "Iteration 36414, loss = 106.96640322\n",
      "Iteration 36415, loss = 106.95477920\n",
      "Iteration 36416, loss = 106.94315608\n",
      "Iteration 36417, loss = 106.93153387\n",
      "Iteration 36418, loss = 106.91991256\n",
      "Iteration 36419, loss = 106.90829216\n",
      "Iteration 36420, loss = 106.89667266\n",
      "Iteration 36421, loss = 106.88505406\n",
      "Iteration 36422, loss = 106.87343637\n",
      "Iteration 36423, loss = 106.86181957\n",
      "Iteration 36424, loss = 106.85020369\n",
      "Iteration 36425, loss = 106.83858870\n",
      "Iteration 36426, loss = 106.82697461\n",
      "Iteration 36427, loss = 106.81536143\n",
      "Iteration 36428, loss = 106.80374915\n",
      "Iteration 36429, loss = 106.79213777\n",
      "Iteration 36430, loss = 106.78052729\n",
      "Iteration 36431, loss = 106.76891772\n",
      "Iteration 36432, loss = 106.75730904\n",
      "Iteration 36433, loss = 106.74570127\n",
      "Iteration 36434, loss = 106.73409439\n",
      "Iteration 36435, loss = 106.72248842\n",
      "Iteration 36436, loss = 106.71088334\n",
      "Iteration 36437, loss = 106.69927917\n",
      "Iteration 36438, loss = 106.68767589\n",
      "Iteration 36439, loss = 106.67607352\n",
      "Iteration 36440, loss = 106.66447204\n",
      "Iteration 36441, loss = 106.65287146\n",
      "Iteration 36442, loss = 106.64127179\n",
      "Iteration 36443, loss = 106.62967301\n",
      "Iteration 36444, loss = 106.61807513\n",
      "Iteration 36445, loss = 106.60647814\n",
      "Iteration 36446, loss = 106.59488206\n",
      "Iteration 36447, loss = 106.58328687\n",
      "Iteration 36448, loss = 106.57169258\n",
      "Iteration 36449, loss = 106.56009919\n",
      "Iteration 36450, loss = 106.54850669\n",
      "Iteration 36451, loss = 106.53691509\n",
      "Iteration 36452, loss = 106.52532439\n",
      "Iteration 36453, loss = 106.51373459\n",
      "Iteration 36454, loss = 106.50214568\n",
      "Iteration 36455, loss = 106.49055766\n",
      "Iteration 36456, loss = 106.47897055\n",
      "Iteration 36457, loss = 106.46738432\n",
      "Iteration 36458, loss = 106.45579900\n",
      "Iteration 36459, loss = 106.44421457\n",
      "Iteration 36460, loss = 106.43263103\n",
      "Iteration 36461, loss = 106.42104839\n",
      "Iteration 36462, loss = 106.40946664\n",
      "Iteration 36463, loss = 106.39788579\n",
      "Iteration 36464, loss = 106.38630583\n",
      "Iteration 36465, loss = 106.37472677\n",
      "Iteration 36466, loss = 106.36314860\n",
      "Iteration 36467, loss = 106.35157132\n",
      "Iteration 36468, loss = 106.33999493\n",
      "Iteration 36469, loss = 106.32841944\n",
      "Iteration 36470, loss = 106.31684485\n",
      "Iteration 36471, loss = 106.30527114\n",
      "Iteration 36472, loss = 106.29369833\n",
      "Iteration 36473, loss = 106.28212641\n",
      "Iteration 36474, loss = 106.27055538\n",
      "Iteration 36475, loss = 106.25898524\n",
      "Iteration 36476, loss = 106.24741599\n",
      "Iteration 36477, loss = 106.23584764\n",
      "Iteration 36478, loss = 106.22428018\n",
      "Iteration 36479, loss = 106.21271361\n",
      "Iteration 36480, loss = 106.20114792\n",
      "Iteration 36481, loss = 106.18958313\n",
      "Iteration 36482, loss = 106.17801923\n",
      "Iteration 36483, loss = 106.16645622\n",
      "Iteration 36484, loss = 106.15489410\n",
      "Iteration 36485, loss = 106.14333287\n",
      "Iteration 36486, loss = 106.13177253\n",
      "Iteration 36487, loss = 106.12021308\n",
      "Iteration 36488, loss = 106.10865451\n",
      "Iteration 36489, loss = 106.09709684\n",
      "Iteration 36490, loss = 106.08554005\n",
      "Iteration 36491, loss = 106.07398416\n",
      "Iteration 36492, loss = 106.06242915\n",
      "Iteration 36493, loss = 106.05087503\n",
      "Iteration 36494, loss = 106.03932179\n",
      "Iteration 36495, loss = 106.02776945\n",
      "Iteration 36496, loss = 106.01621799\n",
      "Iteration 36497, loss = 106.00466742\n",
      "Iteration 36498, loss = 105.99311773\n",
      "Iteration 36499, loss = 105.98156893\n",
      "Iteration 36500, loss = 105.97002102\n",
      "Iteration 36501, loss = 105.95847400\n",
      "Iteration 36502, loss = 105.94692786\n",
      "Iteration 36503, loss = 105.93538261\n",
      "Iteration 36504, loss = 105.92383824\n",
      "Iteration 36505, loss = 105.91229475\n",
      "Iteration 36506, loss = 105.90075216\n",
      "Iteration 36507, loss = 105.88921045\n",
      "Iteration 36508, loss = 105.87766962\n",
      "Iteration 36509, loss = 105.86612968\n",
      "Iteration 36510, loss = 105.85459062\n",
      "Iteration 36511, loss = 105.84305244\n",
      "Iteration 36512, loss = 105.83151515\n",
      "Iteration 36513, loss = 105.81997875\n",
      "Iteration 36514, loss = 105.80844322\n",
      "Iteration 36515, loss = 105.79690858\n",
      "Iteration 36516, loss = 105.78537482\n",
      "Iteration 36517, loss = 105.77384195\n",
      "Iteration 36518, loss = 105.76230996\n",
      "Iteration 36519, loss = 105.75077885\n",
      "Iteration 36520, loss = 105.73924862\n",
      "Iteration 36521, loss = 105.72771928\n",
      "Iteration 36522, loss = 105.71619081\n",
      "Iteration 36523, loss = 105.70466323\n",
      "Iteration 36524, loss = 105.69313653\n",
      "Iteration 36525, loss = 105.68161071\n",
      "Iteration 36526, loss = 105.67008578\n",
      "Iteration 36527, loss = 105.65856172\n",
      "Iteration 36528, loss = 105.64703854\n",
      "Iteration 36529, loss = 105.63551624\n",
      "Iteration 36530, loss = 105.62399483\n",
      "Iteration 36531, loss = 105.61247429\n",
      "Iteration 36532, loss = 105.60095463\n",
      "Iteration 36533, loss = 105.58943586\n",
      "Iteration 36534, loss = 105.57791796\n",
      "Iteration 36535, loss = 105.56640094\n",
      "Iteration 36536, loss = 105.55488480\n",
      "Iteration 36537, loss = 105.54336955\n",
      "Iteration 36538, loss = 105.53185517\n",
      "Iteration 36539, loss = 105.52034168\n",
      "Iteration 36540, loss = 105.50882908\n",
      "Iteration 36541, loss = 105.49731738\n",
      "Iteration 36542, loss = 105.48580659\n",
      "Iteration 36543, loss = 105.47429676\n",
      "Iteration 36544, loss = 105.46278794\n",
      "Iteration 36545, loss = 105.45128024\n",
      "Iteration 36546, loss = 105.43977389\n",
      "Iteration 36547, loss = 105.42826928\n",
      "Iteration 36548, loss = 105.41676715\n",
      "Iteration 36549, loss = 105.40526869\n",
      "Iteration 36550, loss = 105.39377604\n",
      "Iteration 36551, loss = 105.38229208\n",
      "Iteration 36552, loss = 105.37082109\n",
      "Iteration 36553, loss = 105.35936560\n",
      "Iteration 36554, loss = 105.34791874\n",
      "Iteration 36555, loss = 105.33644726\n",
      "Iteration 36556, loss = 105.32490541\n",
      "Iteration 36557, loss = 105.31331036\n",
      "Iteration 36558, loss = 105.30175701\n",
      "Iteration 36559, loss = 105.29029346\n",
      "Iteration 36560, loss = 105.27885466\n",
      "Iteration 36561, loss = 105.26735397\n",
      "Iteration 36562, loss = 105.25580116\n",
      "Iteration 36563, loss = 105.24428459\n",
      "Iteration 36564, loss = 105.23282765\n",
      "Iteration 36565, loss = 105.22136048\n",
      "Iteration 36566, loss = 105.20984232\n",
      "Iteration 36567, loss = 105.19832273\n",
      "Iteration 36568, loss = 105.18684776\n",
      "Iteration 36569, loss = 105.17538404\n",
      "Iteration 36570, loss = 105.16388692\n",
      "Iteration 36571, loss = 105.15237741\n",
      "Iteration 36572, loss = 105.14089612\n",
      "Iteration 36573, loss = 105.12942975\n",
      "Iteration 36574, loss = 105.11794356\n",
      "Iteration 36575, loss = 105.10644534\n",
      "Iteration 36576, loss = 105.09496396\n",
      "Iteration 36577, loss = 105.08349512\n",
      "Iteration 36578, loss = 105.07201529\n",
      "Iteration 36579, loss = 105.06052641\n",
      "Iteration 36580, loss = 105.04904763\n",
      "Iteration 36581, loss = 105.03757823\n",
      "Iteration 36582, loss = 105.02610264\n",
      "Iteration 36583, loss = 105.01462097\n",
      "Iteration 36584, loss = 105.00314583\n",
      "Iteration 36585, loss = 104.99167737\n",
      "Iteration 36586, loss = 104.98020542\n",
      "Iteration 36587, loss = 104.96872957\n",
      "Iteration 36588, loss = 104.95725804\n",
      "Iteration 36589, loss = 104.94579147\n",
      "Iteration 36590, loss = 104.93432318\n",
      "Iteration 36591, loss = 104.92285229\n",
      "Iteration 36592, loss = 104.91138426\n",
      "Iteration 36593, loss = 104.89992011\n",
      "Iteration 36594, loss = 104.88845539\n",
      "Iteration 36595, loss = 104.87698903\n",
      "Iteration 36596, loss = 104.86552455\n",
      "Iteration 36597, loss = 104.85406305\n",
      "Iteration 36598, loss = 104.84260179\n",
      "Iteration 36599, loss = 104.83113968\n",
      "Iteration 36600, loss = 104.81967879\n",
      "Iteration 36601, loss = 104.80822020\n",
      "Iteration 36602, loss = 104.79676232\n",
      "Iteration 36603, loss = 104.78530415\n",
      "Iteration 36604, loss = 104.77384689\n",
      "Iteration 36605, loss = 104.76239143\n",
      "Iteration 36606, loss = 104.75093688\n",
      "Iteration 36607, loss = 104.73948246\n",
      "Iteration 36608, loss = 104.72802880\n",
      "Iteration 36609, loss = 104.71657659\n",
      "Iteration 36610, loss = 104.70512540\n",
      "Iteration 36611, loss = 104.69367462\n",
      "Iteration 36612, loss = 104.68222452\n",
      "Iteration 36613, loss = 104.67077563\n",
      "Iteration 36614, loss = 104.65932781\n",
      "Iteration 36615, loss = 104.64788060\n",
      "Iteration 36616, loss = 104.63643404\n",
      "Iteration 36617, loss = 104.62498852\n",
      "Iteration 36618, loss = 104.61354406\n",
      "Iteration 36619, loss = 104.60210035\n",
      "Iteration 36620, loss = 104.59065733\n",
      "Iteration 36621, loss = 104.57921522\n",
      "Iteration 36622, loss = 104.56777412\n",
      "Iteration 36623, loss = 104.55633388\n",
      "Iteration 36624, loss = 104.54489436\n",
      "Iteration 36625, loss = 104.53345570\n",
      "Iteration 36626, loss = 104.52201799\n",
      "Iteration 36627, loss = 104.51058117\n",
      "Iteration 36628, loss = 104.49914514\n",
      "Iteration 36629, loss = 104.48770993\n",
      "Iteration 36630, loss = 104.47627562\n",
      "Iteration 36631, loss = 104.46484222\n",
      "Iteration 36632, loss = 104.45340964\n",
      "Iteration 36633, loss = 104.44197788\n",
      "Iteration 36634, loss = 104.43054700\n",
      "Iteration 36635, loss = 104.41911701\n",
      "Iteration 36636, loss = 104.40768787\n",
      "Iteration 36637, loss = 104.39625956\n",
      "Iteration 36638, loss = 104.38483209\n",
      "Iteration 36639, loss = 104.37340551\n",
      "Iteration 36640, loss = 104.36197980\n",
      "Iteration 36641, loss = 104.35055493\n",
      "Iteration 36642, loss = 104.33913090\n",
      "Iteration 36643, loss = 104.32770773\n",
      "Iteration 36644, loss = 104.31628543\n",
      "Iteration 36645, loss = 104.30486399\n",
      "Iteration 36646, loss = 104.29344338\n",
      "Iteration 36647, loss = 104.28202363\n",
      "Iteration 36648, loss = 104.27060475\n",
      "Iteration 36649, loss = 104.25918672\n",
      "Iteration 36650, loss = 104.24776954\n",
      "Iteration 36651, loss = 104.23635321\n",
      "Iteration 36652, loss = 104.22493773\n",
      "Iteration 36653, loss = 104.21352312\n",
      "Iteration 36654, loss = 104.20210935\n",
      "Iteration 36655, loss = 104.19069644\n",
      "Iteration 36656, loss = 104.17928437\n",
      "Iteration 36657, loss = 104.16787317\n",
      "Iteration 36658, loss = 104.15646281\n",
      "Iteration 36659, loss = 104.14505331\n",
      "Iteration 36660, loss = 104.13364466\n",
      "Iteration 36661, loss = 104.12223685\n",
      "Iteration 36662, loss = 104.11082991\n",
      "Iteration 36663, loss = 104.09942381\n",
      "Iteration 36664, loss = 104.08801856\n",
      "Iteration 36665, loss = 104.07661416\n",
      "Iteration 36666, loss = 104.06521062\n",
      "Iteration 36667, loss = 104.05380792\n",
      "Iteration 36668, loss = 104.04240608\n",
      "Iteration 36669, loss = 104.03100508\n",
      "Iteration 36670, loss = 104.01960494\n",
      "Iteration 36671, loss = 104.00820564\n",
      "Iteration 36672, loss = 103.99680719\n",
      "Iteration 36673, loss = 103.98540960\n",
      "Iteration 36674, loss = 103.97401285\n",
      "Iteration 36675, loss = 103.96261695\n",
      "Iteration 36676, loss = 103.95122189\n",
      "Iteration 36677, loss = 103.93982769\n",
      "Iteration 36678, loss = 103.92843433\n",
      "Iteration 36679, loss = 103.91704183\n",
      "Iteration 36680, loss = 103.90565016\n",
      "Iteration 36681, loss = 103.89425935\n",
      "Iteration 36682, loss = 103.88286939\n",
      "Iteration 36683, loss = 103.87148027\n",
      "Iteration 36684, loss = 103.86009199\n",
      "Iteration 36685, loss = 103.84870457\n",
      "Iteration 36686, loss = 103.83731799\n",
      "Iteration 36687, loss = 103.82593225\n",
      "Iteration 36688, loss = 103.81454737\n",
      "Iteration 36689, loss = 103.80316332\n",
      "Iteration 36690, loss = 103.79178013\n",
      "Iteration 36691, loss = 103.78039777\n",
      "Iteration 36692, loss = 103.76901627\n",
      "Iteration 36693, loss = 103.75763561\n",
      "Iteration 36694, loss = 103.74625579\n",
      "Iteration 36695, loss = 103.73487681\n",
      "Iteration 36696, loss = 103.72349869\n",
      "Iteration 36697, loss = 103.71212140\n",
      "Iteration 36698, loss = 103.70074496\n",
      "Iteration 36699, loss = 103.68936936\n",
      "Iteration 36700, loss = 103.67799461\n",
      "Iteration 36701, loss = 103.66662070\n",
      "Iteration 36702, loss = 103.65524763\n",
      "Iteration 36703, loss = 103.64387540\n",
      "Iteration 36704, loss = 103.63250402\n",
      "Iteration 36705, loss = 103.62113348\n",
      "Iteration 36706, loss = 103.60976378\n",
      "Iteration 36707, loss = 103.59839492\n",
      "Iteration 36708, loss = 103.58702690\n",
      "Iteration 36709, loss = 103.57565973\n",
      "Iteration 36710, loss = 103.56429340\n",
      "Iteration 36711, loss = 103.55292790\n",
      "Iteration 36712, loss = 103.54156325\n",
      "Iteration 36713, loss = 103.53019944\n",
      "Iteration 36714, loss = 103.51883647\n",
      "Iteration 36715, loss = 103.50747434\n",
      "Iteration 36716, loss = 103.49611305\n",
      "Iteration 36717, loss = 103.48475260\n",
      "Iteration 36718, loss = 103.47339298\n",
      "Iteration 36719, loss = 103.46203421\n",
      "Iteration 36720, loss = 103.45067628\n",
      "Iteration 36721, loss = 103.43931918\n",
      "Iteration 36722, loss = 103.42796293\n",
      "Iteration 36723, loss = 103.41660751\n",
      "Iteration 36724, loss = 103.40525293\n",
      "Iteration 36725, loss = 103.39389919\n",
      "Iteration 36726, loss = 103.38254628\n",
      "Iteration 36727, loss = 103.37119422\n",
      "Iteration 36728, loss = 103.35984299\n",
      "Iteration 36729, loss = 103.34849260\n",
      "Iteration 36730, loss = 103.33714304\n",
      "Iteration 36731, loss = 103.32579432\n",
      "Iteration 36732, loss = 103.31444644\n",
      "Iteration 36733, loss = 103.30309940\n",
      "Iteration 36734, loss = 103.29175319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36735, loss = 103.28040781\n",
      "Iteration 36736, loss = 103.26906328\n",
      "Iteration 36737, loss = 103.25771957\n",
      "Iteration 36738, loss = 103.24637671\n",
      "Iteration 36739, loss = 103.23503467\n",
      "Iteration 36740, loss = 103.22369348\n",
      "Iteration 36741, loss = 103.21235311\n",
      "Iteration 36742, loss = 103.20101358\n",
      "Iteration 36743, loss = 103.18967489\n",
      "Iteration 36744, loss = 103.17833703\n",
      "Iteration 36745, loss = 103.16700000\n",
      "Iteration 36746, loss = 103.15566381\n",
      "Iteration 36747, loss = 103.14432845\n",
      "Iteration 36748, loss = 103.13299392\n",
      "Iteration 36749, loss = 103.12166023\n",
      "Iteration 36750, loss = 103.11032737\n",
      "Iteration 36751, loss = 103.09899534\n",
      "Iteration 36752, loss = 103.08766414\n",
      "Iteration 36753, loss = 103.07633378\n",
      "Iteration 36754, loss = 103.06500424\n",
      "Iteration 36755, loss = 103.05367554\n",
      "Iteration 36756, loss = 103.04234767\n",
      "Iteration 36757, loss = 103.03102063\n",
      "Iteration 36758, loss = 103.01969442\n",
      "Iteration 36759, loss = 103.00836905\n",
      "Iteration 36760, loss = 102.99704450\n",
      "Iteration 36761, loss = 102.98572078\n",
      "Iteration 36762, loss = 102.97439790\n",
      "Iteration 36763, loss = 102.96307584\n",
      "Iteration 36764, loss = 102.95175462\n",
      "Iteration 36765, loss = 102.94043422\n",
      "Iteration 36766, loss = 102.92911465\n",
      "Iteration 36767, loss = 102.91779591\n",
      "Iteration 36768, loss = 102.90647800\n",
      "Iteration 36769, loss = 102.89516092\n",
      "Iteration 36770, loss = 102.88384467\n",
      "Iteration 36771, loss = 102.87252924\n",
      "Iteration 36772, loss = 102.86121465\n",
      "Iteration 36773, loss = 102.84990088\n",
      "Iteration 36774, loss = 102.83858794\n",
      "Iteration 36775, loss = 102.82727582\n",
      "Iteration 36776, loss = 102.81596453\n",
      "Iteration 36777, loss = 102.80465407\n",
      "Iteration 36778, loss = 102.79334444\n",
      "Iteration 36779, loss = 102.78203564\n",
      "Iteration 36780, loss = 102.77072765\n",
      "Iteration 36781, loss = 102.75942050\n",
      "Iteration 36782, loss = 102.74811417\n",
      "Iteration 36783, loss = 102.73680867\n",
      "Iteration 36784, loss = 102.72550399\n",
      "Iteration 36785, loss = 102.71420014\n",
      "Iteration 36786, loss = 102.70289711\n",
      "Iteration 36787, loss = 102.69159491\n",
      "Iteration 36788, loss = 102.68029353\n",
      "Iteration 36789, loss = 102.66899298\n",
      "Iteration 36790, loss = 102.65769325\n",
      "Iteration 36791, loss = 102.64639435\n",
      "Iteration 36792, loss = 102.63509626\n",
      "Iteration 36793, loss = 102.62379901\n",
      "Iteration 36794, loss = 102.61250257\n",
      "Iteration 36795, loss = 102.60120696\n",
      "Iteration 36796, loss = 102.58991217\n",
      "Iteration 36797, loss = 102.57861821\n",
      "Iteration 36798, loss = 102.56732506\n",
      "Iteration 36799, loss = 102.55603274\n",
      "Iteration 36800, loss = 102.54474124\n",
      "Iteration 36801, loss = 102.53345057\n",
      "Iteration 36802, loss = 102.52216071\n",
      "Iteration 36803, loss = 102.51087168\n",
      "Iteration 36804, loss = 102.49958346\n",
      "Iteration 36805, loss = 102.48829607\n",
      "Iteration 36806, loss = 102.47700950\n",
      "Iteration 36807, loss = 102.46572375\n",
      "Iteration 36808, loss = 102.45443882\n",
      "Iteration 36809, loss = 102.44315471\n",
      "Iteration 36810, loss = 102.43187142\n",
      "Iteration 36811, loss = 102.42058895\n",
      "Iteration 36812, loss = 102.40930730\n",
      "Iteration 36813, loss = 102.39802647\n",
      "Iteration 36814, loss = 102.38674646\n",
      "Iteration 36815, loss = 102.37546727\n",
      "Iteration 36816, loss = 102.36418889\n",
      "Iteration 36817, loss = 102.35291134\n",
      "Iteration 36818, loss = 102.34163460\n",
      "Iteration 36819, loss = 102.33035868\n",
      "Iteration 36820, loss = 102.31908358\n",
      "Iteration 36821, loss = 102.30780929\n",
      "Iteration 36822, loss = 102.29653583\n",
      "Iteration 36823, loss = 102.28526318\n",
      "Iteration 36824, loss = 102.27399134\n",
      "Iteration 36825, loss = 102.26272033\n",
      "Iteration 36826, loss = 102.25145013\n",
      "Iteration 36827, loss = 102.24018075\n",
      "Iteration 36828, loss = 102.22891218\n",
      "Iteration 36829, loss = 102.21764443\n",
      "Iteration 36830, loss = 102.20637749\n",
      "Iteration 36831, loss = 102.19511137\n",
      "Iteration 36832, loss = 102.18384607\n",
      "Iteration 36833, loss = 102.17258158\n",
      "Iteration 36834, loss = 102.16131791\n",
      "Iteration 36835, loss = 102.15005505\n",
      "Iteration 36836, loss = 102.13879300\n",
      "Iteration 36837, loss = 102.12753177\n",
      "Iteration 36838, loss = 102.11627136\n",
      "Iteration 36839, loss = 102.10501175\n",
      "Iteration 36840, loss = 102.09375296\n",
      "Iteration 36841, loss = 102.08249499\n",
      "Iteration 36842, loss = 102.07123783\n",
      "Iteration 36843, loss = 102.05998148\n",
      "Iteration 36844, loss = 102.04872594\n",
      "Iteration 36845, loss = 102.03747122\n",
      "Iteration 36846, loss = 102.02621730\n",
      "Iteration 36847, loss = 102.01496420\n",
      "Iteration 36848, loss = 102.00371192\n",
      "Iteration 36849, loss = 101.99246044\n",
      "Iteration 36850, loss = 101.98120978\n",
      "Iteration 36851, loss = 101.96995992\n",
      "Iteration 36852, loss = 101.95871088\n",
      "Iteration 36853, loss = 101.94746265\n",
      "Iteration 36854, loss = 101.93621523\n",
      "Iteration 36855, loss = 101.92496862\n",
      "Iteration 36856, loss = 101.91372282\n",
      "Iteration 36857, loss = 101.90247783\n",
      "Iteration 36858, loss = 101.89123365\n",
      "Iteration 36859, loss = 101.87999028\n",
      "Iteration 36860, loss = 101.86874772\n",
      "Iteration 36861, loss = 101.85750597\n",
      "Iteration 36862, loss = 101.84626503\n",
      "Iteration 36863, loss = 101.83502490\n",
      "Iteration 36864, loss = 101.82378557\n",
      "Iteration 36865, loss = 101.81254706\n",
      "Iteration 36866, loss = 101.80130935\n",
      "Iteration 36867, loss = 101.79007245\n",
      "Iteration 36868, loss = 101.77883636\n",
      "Iteration 36869, loss = 101.76760107\n",
      "Iteration 36870, loss = 101.75636659\n",
      "Iteration 36871, loss = 101.74513292\n",
      "Iteration 36872, loss = 101.73390006\n",
      "Iteration 36873, loss = 101.72266800\n",
      "Iteration 36874, loss = 101.71143675\n",
      "Iteration 36875, loss = 101.70020631\n",
      "Iteration 36876, loss = 101.68897667\n",
      "Iteration 36877, loss = 101.67774784\n",
      "Iteration 36878, loss = 101.66651981\n",
      "Iteration 36879, loss = 101.65529259\n",
      "Iteration 36880, loss = 101.64406618\n",
      "Iteration 36881, loss = 101.63284057\n",
      "Iteration 36882, loss = 101.62161576\n",
      "Iteration 36883, loss = 101.61039176\n",
      "Iteration 36884, loss = 101.59916857\n",
      "Iteration 36885, loss = 101.58794617\n",
      "Iteration 36886, loss = 101.57672459\n",
      "Iteration 36887, loss = 101.56550380\n",
      "Iteration 36888, loss = 101.55428382\n",
      "Iteration 36889, loss = 101.54306464\n",
      "Iteration 36890, loss = 101.53184627\n",
      "Iteration 36891, loss = 101.52062870\n",
      "Iteration 36892, loss = 101.50941193\n",
      "Iteration 36893, loss = 101.49819596\n",
      "Iteration 36894, loss = 101.48698080\n",
      "Iteration 36895, loss = 101.47576644\n",
      "Iteration 36896, loss = 101.46455288\n",
      "Iteration 36897, loss = 101.45334012\n",
      "Iteration 36898, loss = 101.44212816\n",
      "Iteration 36899, loss = 101.43091701\n",
      "Iteration 36900, loss = 101.41970666\n",
      "Iteration 36901, loss = 101.40849710\n",
      "Iteration 36902, loss = 101.39728835\n",
      "Iteration 36903, loss = 101.38608040\n",
      "Iteration 36904, loss = 101.37487325\n",
      "Iteration 36905, loss = 101.36366691\n",
      "Iteration 36906, loss = 101.35246137\n",
      "Iteration 36907, loss = 101.34125663\n",
      "Iteration 36908, loss = 101.33005272\n",
      "Iteration 36909, loss = 101.31884962\n",
      "Iteration 36910, loss = 101.30764738\n",
      "Iteration 36911, loss = 101.29644602\n",
      "Iteration 36912, loss = 101.28524562\n",
      "Iteration 36913, loss = 101.27404628\n",
      "Iteration 36914, loss = 101.26284815\n",
      "Iteration 36915, loss = 101.25165146\n",
      "Iteration 36916, loss = 101.24045618\n",
      "Iteration 36917, loss = 101.22926201\n",
      "Iteration 36918, loss = 101.21806730\n",
      "Iteration 36919, loss = 101.20687065\n",
      "Iteration 36920, loss = 101.19567196\n",
      "Iteration 36921, loss = 101.18447461\n",
      "Iteration 36922, loss = 101.17328150\n",
      "Iteration 36923, loss = 101.16209197\n",
      "Iteration 36924, loss = 101.15090279\n",
      "Iteration 36925, loss = 101.13971156\n",
      "Iteration 36926, loss = 101.12851954\n",
      "Iteration 36927, loss = 101.11732980\n",
      "Iteration 36928, loss = 101.10614344\n",
      "Iteration 36929, loss = 101.09495864\n",
      "Iteration 36930, loss = 101.08377376\n",
      "Iteration 36931, loss = 101.07259019\n",
      "Iteration 36932, loss = 101.06141148\n",
      "Iteration 36933, loss = 101.05024088\n",
      "Iteration 36934, loss = 101.03908104\n",
      "Iteration 36935, loss = 101.02793518\n",
      "Iteration 36936, loss = 101.01680298\n",
      "Iteration 36937, loss = 101.00566640\n",
      "Iteration 36938, loss = 100.99448446\n",
      "Iteration 36939, loss = 100.98323398\n",
      "Iteration 36940, loss = 100.97197005\n",
      "Iteration 36941, loss = 100.96077393\n",
      "Iteration 36942, loss = 100.94964596\n",
      "Iteration 36943, loss = 100.93850917\n",
      "Iteration 36944, loss = 100.92730791\n",
      "Iteration 36945, loss = 100.91608021\n",
      "Iteration 36946, loss = 100.90489856\n",
      "Iteration 36947, loss = 100.89376035\n",
      "Iteration 36948, loss = 100.88260263\n",
      "Iteration 36949, loss = 100.87140314\n",
      "Iteration 36950, loss = 100.86020829\n",
      "Iteration 36951, loss = 100.84905123\n",
      "Iteration 36952, loss = 100.83790211\n",
      "Iteration 36953, loss = 100.82672548\n",
      "Iteration 36954, loss = 100.81553742\n",
      "Iteration 36955, loss = 100.80437128\n",
      "Iteration 36956, loss = 100.79322026\n",
      "Iteration 36957, loss = 100.78205581\n",
      "Iteration 36958, loss = 100.77087812\n",
      "Iteration 36959, loss = 100.75971052\n",
      "Iteration 36960, loss = 100.74855683\n",
      "Iteration 36961, loss = 100.73739873\n",
      "Iteration 36962, loss = 100.72622999\n",
      "Iteration 36963, loss = 100.71506465\n",
      "Iteration 36964, loss = 100.70390990\n",
      "Iteration 36965, loss = 100.69275536\n",
      "Iteration 36966, loss = 100.68159366\n",
      "Iteration 36967, loss = 100.67043215\n",
      "Iteration 36968, loss = 100.65927782\n",
      "Iteration 36969, loss = 100.64812579\n",
      "Iteration 36970, loss = 100.63696966\n",
      "Iteration 36971, loss = 100.62581238\n",
      "Iteration 36972, loss = 100.61465960\n",
      "Iteration 36973, loss = 100.60350982\n",
      "Iteration 36974, loss = 100.59235818\n",
      "Iteration 36975, loss = 100.58120514\n",
      "Iteration 36976, loss = 100.57005471\n",
      "Iteration 36977, loss = 100.55890716\n",
      "Iteration 36978, loss = 100.54775930\n",
      "Iteration 36979, loss = 100.53661037\n",
      "Iteration 36980, loss = 100.52546278\n",
      "Iteration 36981, loss = 100.51431761\n",
      "Iteration 36982, loss = 100.50317309\n",
      "Iteration 36983, loss = 100.49202803\n",
      "Iteration 36984, loss = 100.48088359\n",
      "Iteration 36985, loss = 100.46974101\n",
      "Iteration 36986, loss = 100.45859956\n",
      "Iteration 36987, loss = 100.44745811\n",
      "Iteration 36988, loss = 100.43631700\n",
      "Iteration 36989, loss = 100.42517722\n",
      "Iteration 36990, loss = 100.41403870\n",
      "Iteration 36991, loss = 100.40290064\n",
      "Iteration 36992, loss = 100.39176291\n",
      "Iteration 36993, loss = 100.38062611\n",
      "Iteration 36994, loss = 100.36949051\n",
      "Iteration 36995, loss = 100.35835567\n",
      "Iteration 36996, loss = 100.34722127\n",
      "Iteration 36997, loss = 100.33608759\n",
      "Iteration 36998, loss = 100.32495494\n",
      "Iteration 36999, loss = 100.31382320\n",
      "Iteration 37000, loss = 100.30269207\n",
      "Iteration 37001, loss = 100.29156158\n",
      "Iteration 37002, loss = 100.28043196\n",
      "Iteration 37003, loss = 100.26930327\n",
      "Iteration 37004, loss = 100.25817532\n",
      "Iteration 37005, loss = 100.24704802\n",
      "Iteration 37006, loss = 100.23592150\n",
      "Iteration 37007, loss = 100.22479585\n",
      "Iteration 37008, loss = 100.21367102\n",
      "Iteration 37009, loss = 100.20254691\n",
      "Iteration 37010, loss = 100.19142351\n",
      "Iteration 37011, loss = 100.18030094\n",
      "Iteration 37012, loss = 100.16917919\n",
      "Iteration 37013, loss = 100.15805822\n",
      "Iteration 37014, loss = 100.14693797\n",
      "Iteration 37015, loss = 100.13581849\n",
      "Iteration 37016, loss = 100.12469982\n",
      "Iteration 37017, loss = 100.11358196\n",
      "Iteration 37018, loss = 100.10246484\n",
      "Iteration 37019, loss = 100.09134848\n",
      "Iteration 37020, loss = 100.08023290\n",
      "Iteration 37021, loss = 100.06911813\n",
      "Iteration 37022, loss = 100.05800413\n",
      "Iteration 37023, loss = 100.04689089\n",
      "Iteration 37024, loss = 100.03577841\n",
      "Iteration 37025, loss = 100.02466672\n",
      "Iteration 37026, loss = 100.01355582\n",
      "Iteration 37027, loss = 100.00244568\n",
      "Iteration 37028, loss = 99.99133632\n",
      "Iteration 37029, loss = 99.98022772\n",
      "Iteration 37030, loss = 99.96911991\n",
      "Iteration 37031, loss = 99.95801287\n",
      "Iteration 37032, loss = 99.94690660\n",
      "Iteration 37033, loss = 99.93580111\n",
      "Iteration 37034, loss = 99.92469638\n",
      "Iteration 37035, loss = 99.91359244\n",
      "Iteration 37036, loss = 99.90248926\n",
      "Iteration 37037, loss = 99.89138686\n",
      "Iteration 37038, loss = 99.88028523\n",
      "Iteration 37039, loss = 99.86918437\n",
      "Iteration 37040, loss = 99.85808429\n",
      "Iteration 37041, loss = 99.84698498\n",
      "Iteration 37042, loss = 99.83588643\n",
      "Iteration 37043, loss = 99.82478866\n",
      "Iteration 37044, loss = 99.81369166\n",
      "Iteration 37045, loss = 99.80259543\n",
      "Iteration 37046, loss = 99.79149998\n",
      "Iteration 37047, loss = 99.78040529\n",
      "Iteration 37048, loss = 99.76931137\n",
      "Iteration 37049, loss = 99.75821823\n",
      "Iteration 37050, loss = 99.74712585\n",
      "Iteration 37051, loss = 99.73603425\n",
      "Iteration 37052, loss = 99.72494341\n",
      "Iteration 37053, loss = 99.71385334\n",
      "Iteration 37054, loss = 99.70276405\n",
      "Iteration 37055, loss = 99.69167552\n",
      "Iteration 37056, loss = 99.68058776\n",
      "Iteration 37057, loss = 99.66950077\n",
      "Iteration 37058, loss = 99.65841454\n",
      "Iteration 37059, loss = 99.64732909\n",
      "Iteration 37060, loss = 99.63624440\n",
      "Iteration 37061, loss = 99.62516048\n",
      "Iteration 37062, loss = 99.61407733\n",
      "Iteration 37063, loss = 99.60299495\n",
      "Iteration 37064, loss = 99.59191333\n",
      "Iteration 37065, loss = 99.58083249\n",
      "Iteration 37066, loss = 99.56975240\n",
      "Iteration 37067, loss = 99.55867309\n",
      "Iteration 37068, loss = 99.54759454\n",
      "Iteration 37069, loss = 99.53651676\n",
      "Iteration 37070, loss = 99.52543974\n",
      "Iteration 37071, loss = 99.51436349\n",
      "Iteration 37072, loss = 99.50328800\n",
      "Iteration 37073, loss = 99.49221328\n",
      "Iteration 37074, loss = 99.48113933\n",
      "Iteration 37075, loss = 99.47006614\n",
      "Iteration 37076, loss = 99.45899372\n",
      "Iteration 37077, loss = 99.44792206\n",
      "Iteration 37078, loss = 99.43685116\n",
      "Iteration 37079, loss = 99.42578103\n",
      "Iteration 37080, loss = 99.41471166\n",
      "Iteration 37081, loss = 99.40364306\n",
      "Iteration 37082, loss = 99.39257522\n",
      "Iteration 37083, loss = 99.38150815\n",
      "Iteration 37084, loss = 99.37044183\n",
      "Iteration 37085, loss = 99.35937629\n",
      "Iteration 37086, loss = 99.34831150\n",
      "Iteration 37087, loss = 99.33724748\n",
      "Iteration 37088, loss = 99.32618422\n",
      "Iteration 37089, loss = 99.31512172\n",
      "Iteration 37090, loss = 99.30405998\n",
      "Iteration 37091, loss = 99.29299901\n",
      "Iteration 37092, loss = 99.28193879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37093, loss = 99.27087934\n",
      "Iteration 37094, loss = 99.25982065\n",
      "Iteration 37095, loss = 99.24876272\n",
      "Iteration 37096, loss = 99.23770556\n",
      "Iteration 37097, loss = 99.22664915\n",
      "Iteration 37098, loss = 99.21559350\n",
      "Iteration 37099, loss = 99.20453862\n",
      "Iteration 37100, loss = 99.19348449\n",
      "Iteration 37101, loss = 99.18243113\n",
      "Iteration 37102, loss = 99.17137852\n",
      "Iteration 37103, loss = 99.16032667\n",
      "Iteration 37104, loss = 99.14927559\n",
      "Iteration 37105, loss = 99.13822526\n",
      "Iteration 37106, loss = 99.12717569\n",
      "Iteration 37107, loss = 99.11612688\n",
      "Iteration 37108, loss = 99.10507883\n",
      "Iteration 37109, loss = 99.09403154\n",
      "Iteration 37110, loss = 99.08298500\n",
      "Iteration 37111, loss = 99.07193923\n",
      "Iteration 37112, loss = 99.06089421\n",
      "Iteration 37113, loss = 99.04984995\n",
      "Iteration 37114, loss = 99.03880644\n",
      "Iteration 37115, loss = 99.02776370\n",
      "Iteration 37116, loss = 99.01672171\n",
      "Iteration 37117, loss = 99.00568048\n",
      "Iteration 37118, loss = 98.99464000\n",
      "Iteration 37119, loss = 98.98360028\n",
      "Iteration 37120, loss = 98.97256132\n",
      "Iteration 37121, loss = 98.96152311\n",
      "Iteration 37122, loss = 98.95048566\n",
      "Iteration 37123, loss = 98.93944897\n",
      "Iteration 37124, loss = 98.92841303\n",
      "Iteration 37125, loss = 98.91737785\n",
      "Iteration 37126, loss = 98.90634342\n",
      "Iteration 37127, loss = 98.89530974\n",
      "Iteration 37128, loss = 98.88427682\n",
      "Iteration 37129, loss = 98.87324466\n",
      "Iteration 37130, loss = 98.86221325\n",
      "Iteration 37131, loss = 98.85118259\n",
      "Iteration 37132, loss = 98.84015269\n",
      "Iteration 37133, loss = 98.82912354\n",
      "Iteration 37134, loss = 98.81809515\n",
      "Iteration 37135, loss = 98.80706751\n",
      "Iteration 37136, loss = 98.79604062\n",
      "Iteration 37137, loss = 98.78501448\n",
      "Iteration 37138, loss = 98.77398910\n",
      "Iteration 37139, loss = 98.76296447\n",
      "Iteration 37140, loss = 98.75194060\n",
      "Iteration 37141, loss = 98.74091747\n",
      "Iteration 37142, loss = 98.72989510\n",
      "Iteration 37143, loss = 98.71887348\n",
      "Iteration 37144, loss = 98.70785261\n",
      "Iteration 37145, loss = 98.69683249\n",
      "Iteration 37146, loss = 98.68581312\n",
      "Iteration 37147, loss = 98.67479451\n",
      "Iteration 37148, loss = 98.66377665\n",
      "Iteration 37149, loss = 98.65275953\n",
      "Iteration 37150, loss = 98.64174317\n",
      "Iteration 37151, loss = 98.63072756\n",
      "Iteration 37152, loss = 98.61971269\n",
      "Iteration 37153, loss = 98.60869858\n",
      "Iteration 37154, loss = 98.59768522\n",
      "Iteration 37155, loss = 98.58667261\n",
      "Iteration 37156, loss = 98.57566074\n",
      "Iteration 37157, loss = 98.56464963\n",
      "Iteration 37158, loss = 98.55363926\n",
      "Iteration 37159, loss = 98.54262965\n",
      "Iteration 37160, loss = 98.53162078\n",
      "Iteration 37161, loss = 98.52061266\n",
      "Iteration 37162, loss = 98.50960529\n",
      "Iteration 37163, loss = 98.49859866\n",
      "Iteration 37164, loss = 98.48759279\n",
      "Iteration 37165, loss = 98.47658766\n",
      "Iteration 37166, loss = 98.46558328\n",
      "Iteration 37167, loss = 98.45457965\n",
      "Iteration 37168, loss = 98.44357676\n",
      "Iteration 37169, loss = 98.43257462\n",
      "Iteration 37170, loss = 98.42157323\n",
      "Iteration 37171, loss = 98.41057259\n",
      "Iteration 37172, loss = 98.39957269\n",
      "Iteration 37173, loss = 98.38857354\n",
      "Iteration 37174, loss = 98.37757513\n",
      "Iteration 37175, loss = 98.36657747\n",
      "Iteration 37176, loss = 98.35558055\n",
      "Iteration 37177, loss = 98.34458438\n",
      "Iteration 37178, loss = 98.33358896\n",
      "Iteration 37179, loss = 98.32259428\n",
      "Iteration 37180, loss = 98.31160034\n",
      "Iteration 37181, loss = 98.30060715\n",
      "Iteration 37182, loss = 98.28961471\n",
      "Iteration 37183, loss = 98.27862301\n",
      "Iteration 37184, loss = 98.26763205\n",
      "Iteration 37185, loss = 98.25664184\n",
      "Iteration 37186, loss = 98.24565237\n",
      "Iteration 37187, loss = 98.23466364\n",
      "Iteration 37188, loss = 98.22367566\n",
      "Iteration 37189, loss = 98.21268842\n",
      "Iteration 37190, loss = 98.20170192\n",
      "Iteration 37191, loss = 98.19071617\n",
      "Iteration 37192, loss = 98.17973116\n",
      "Iteration 37193, loss = 98.16874689\n",
      "Iteration 37194, loss = 98.15776336\n",
      "Iteration 37195, loss = 98.14678058\n",
      "Iteration 37196, loss = 98.13579854\n",
      "Iteration 37197, loss = 98.12481723\n",
      "Iteration 37198, loss = 98.11383668\n",
      "Iteration 37199, loss = 98.10285686\n",
      "Iteration 37200, loss = 98.09187778\n",
      "Iteration 37201, loss = 98.08089945\n",
      "Iteration 37202, loss = 98.06992185\n",
      "Iteration 37203, loss = 98.05894500\n",
      "Iteration 37204, loss = 98.04796888\n",
      "Iteration 37205, loss = 98.03699351\n",
      "Iteration 37206, loss = 98.02601887\n",
      "Iteration 37207, loss = 98.01504498\n",
      "Iteration 37208, loss = 98.00407183\n",
      "Iteration 37209, loss = 97.99309941\n",
      "Iteration 37210, loss = 97.98212773\n",
      "Iteration 37211, loss = 97.97115680\n",
      "Iteration 37212, loss = 97.96018660\n",
      "Iteration 37213, loss = 97.94921714\n",
      "Iteration 37214, loss = 97.93824842\n",
      "Iteration 37215, loss = 97.92728044\n",
      "Iteration 37216, loss = 97.91631319\n",
      "Iteration 37217, loss = 97.90534669\n",
      "Iteration 37218, loss = 97.89438092\n",
      "Iteration 37219, loss = 97.88341589\n",
      "Iteration 37220, loss = 97.87245160\n",
      "Iteration 37221, loss = 97.86148804\n",
      "Iteration 37222, loss = 97.85052522\n",
      "Iteration 37223, loss = 97.83956314\n",
      "Iteration 37224, loss = 97.82860180\n",
      "Iteration 37225, loss = 97.81764119\n",
      "Iteration 37226, loss = 97.80668131\n",
      "Iteration 37227, loss = 97.79572218\n",
      "Iteration 37228, loss = 97.78476378\n",
      "Iteration 37229, loss = 97.77380611\n",
      "Iteration 37230, loss = 97.76284918\n",
      "Iteration 37231, loss = 97.75189299\n",
      "Iteration 37232, loss = 97.74093753\n",
      "Iteration 37233, loss = 97.72998281\n",
      "Iteration 37234, loss = 97.71902882\n",
      "Iteration 37235, loss = 97.70807557\n",
      "Iteration 37236, loss = 97.69712305\n",
      "Iteration 37237, loss = 97.68617126\n",
      "Iteration 37238, loss = 97.67522021\n",
      "Iteration 37239, loss = 97.66426990\n",
      "Iteration 37240, loss = 97.65332031\n",
      "Iteration 37241, loss = 97.64237146\n",
      "Iteration 37242, loss = 97.63142335\n",
      "Iteration 37243, loss = 97.62047597\n",
      "Iteration 37244, loss = 97.60952932\n",
      "Iteration 37245, loss = 97.59858340\n",
      "Iteration 37246, loss = 97.58763822\n",
      "Iteration 37247, loss = 97.57669376\n",
      "Iteration 37248, loss = 97.56575004\n",
      "Iteration 37249, loss = 97.55480706\n",
      "Iteration 37250, loss = 97.54386480\n",
      "Iteration 37251, loss = 97.53292328\n",
      "Iteration 37252, loss = 97.52198249\n",
      "Iteration 37253, loss = 97.51104243\n",
      "Iteration 37254, loss = 97.50010310\n",
      "Iteration 37255, loss = 97.48916450\n",
      "Iteration 37256, loss = 97.47822663\n",
      "Iteration 37257, loss = 97.46728950\n",
      "Iteration 37258, loss = 97.45635309\n",
      "Iteration 37259, loss = 97.44541742\n",
      "Iteration 37260, loss = 97.43448247\n",
      "Iteration 37261, loss = 97.42354826\n",
      "Iteration 37262, loss = 97.41261477\n",
      "Iteration 37263, loss = 97.40168201\n",
      "Iteration 37264, loss = 97.39074999\n",
      "Iteration 37265, loss = 97.37981869\n",
      "Iteration 37266, loss = 97.36888812\n",
      "Iteration 37267, loss = 97.35795828\n",
      "Iteration 37268, loss = 97.34702917\n",
      "Iteration 37269, loss = 97.33610079\n",
      "Iteration 37270, loss = 97.32517314\n",
      "Iteration 37271, loss = 97.31424621\n",
      "Iteration 37272, loss = 97.30332002\n",
      "Iteration 37273, loss = 97.29239455\n",
      "Iteration 37274, loss = 97.28146980\n",
      "Iteration 37275, loss = 97.27054579\n",
      "Iteration 37276, loss = 97.25962250\n",
      "Iteration 37277, loss = 97.24869994\n",
      "Iteration 37278, loss = 97.23777811\n",
      "Iteration 37279, loss = 97.22685700\n",
      "Iteration 37280, loss = 97.21593663\n",
      "Iteration 37281, loss = 97.20501697\n",
      "Iteration 37282, loss = 97.19409805\n",
      "Iteration 37283, loss = 97.18317985\n",
      "Iteration 37284, loss = 97.17226237\n",
      "Iteration 37285, loss = 97.16134562\n",
      "Iteration 37286, loss = 97.15042960\n",
      "Iteration 37287, loss = 97.13951430\n",
      "Iteration 37288, loss = 97.12859974\n",
      "Iteration 37289, loss = 97.11768589\n",
      "Iteration 37290, loss = 97.10677278\n",
      "Iteration 37291, loss = 97.09586041\n",
      "Iteration 37292, loss = 97.08494878\n",
      "Iteration 37293, loss = 97.07403791\n",
      "Iteration 37294, loss = 97.06312783\n",
      "Iteration 37295, loss = 97.05221861\n",
      "Iteration 37296, loss = 97.04131036\n",
      "Iteration 37297, loss = 97.03040333\n",
      "Iteration 37298, loss = 97.01949794\n",
      "Iteration 37299, loss = 97.00859505\n",
      "Iteration 37300, loss = 96.99769620\n",
      "Iteration 37301, loss = 96.98680415\n",
      "Iteration 37302, loss = 96.97592306\n",
      "Iteration 37303, loss = 96.96505753\n",
      "Iteration 37304, loss = 96.95420629\n",
      "Iteration 37305, loss = 96.94334998\n",
      "Iteration 37306, loss = 96.93244528\n",
      "Iteration 37307, loss = 96.92147104\n",
      "Iteration 37308, loss = 96.91048321\n",
      "Iteration 37309, loss = 96.89956550\n",
      "Iteration 37310, loss = 96.88871733\n",
      "Iteration 37311, loss = 96.87785950\n",
      "Iteration 37312, loss = 96.86693595\n",
      "Iteration 37313, loss = 96.85598545\n",
      "Iteration 37314, loss = 96.84508254\n",
      "Iteration 37315, loss = 96.83422429\n",
      "Iteration 37316, loss = 96.82334607\n",
      "Iteration 37317, loss = 96.81242503\n",
      "Iteration 37318, loss = 96.80150808\n",
      "Iteration 37319, loss = 96.79062809\n",
      "Iteration 37320, loss = 96.77975440\n",
      "Iteration 37321, loss = 96.76885205\n",
      "Iteration 37322, loss = 96.75793984\n",
      "Iteration 37323, loss = 96.74705214\n",
      "Iteration 37324, loss = 96.73618034\n",
      "Iteration 37325, loss = 96.72529351\n",
      "Iteration 37326, loss = 96.71439143\n",
      "Iteration 37327, loss = 96.70349933\n",
      "Iteration 37328, loss = 96.69262237\n",
      "Iteration 37329, loss = 96.68174175\n",
      "Iteration 37330, loss = 96.67085034\n",
      "Iteration 37331, loss = 96.65996170\n",
      "Iteration 37332, loss = 96.64908311\n",
      "Iteration 37333, loss = 96.63820454\n",
      "Iteration 37334, loss = 96.62731916\n",
      "Iteration 37335, loss = 96.61643448\n",
      "Iteration 37336, loss = 96.60555697\n",
      "Iteration 37337, loss = 96.59468109\n",
      "Iteration 37338, loss = 96.58380060\n",
      "Iteration 37339, loss = 96.57291921\n",
      "Iteration 37340, loss = 96.56204283\n",
      "Iteration 37341, loss = 96.55116941\n",
      "Iteration 37342, loss = 96.54029363\n",
      "Iteration 37343, loss = 96.52941613\n",
      "Iteration 37344, loss = 96.51854136\n",
      "Iteration 37345, loss = 96.50766970\n",
      "Iteration 37346, loss = 96.49679767\n",
      "Iteration 37347, loss = 96.48592432\n",
      "Iteration 37348, loss = 96.47505214\n",
      "Iteration 37349, loss = 96.46418235\n",
      "Iteration 37350, loss = 96.45331322\n",
      "Iteration 37351, loss = 96.44244354\n",
      "Iteration 37352, loss = 96.43157442\n",
      "Iteration 37353, loss = 96.42070701\n",
      "Iteration 37354, loss = 96.40984059\n",
      "Iteration 37355, loss = 96.39897413\n",
      "Iteration 37356, loss = 96.38810804\n",
      "Iteration 37357, loss = 96.37724324\n",
      "Iteration 37358, loss = 96.36637957\n",
      "Iteration 37359, loss = 96.35551621\n",
      "Iteration 37360, loss = 96.34465313\n",
      "Iteration 37361, loss = 96.33379100\n",
      "Iteration 37362, loss = 96.32293001\n",
      "Iteration 37363, loss = 96.31206967\n",
      "Iteration 37364, loss = 96.30120966\n",
      "Iteration 37365, loss = 96.29035031\n",
      "Iteration 37366, loss = 96.27949197\n",
      "Iteration 37367, loss = 96.26863446\n",
      "Iteration 37368, loss = 96.25777748\n",
      "Iteration 37369, loss = 96.24692106\n",
      "Iteration 37370, loss = 96.23606545\n",
      "Iteration 37371, loss = 96.22521070\n",
      "Iteration 37372, loss = 96.21435663\n",
      "Iteration 37373, loss = 96.20350314\n",
      "Iteration 37374, loss = 96.19265036\n",
      "Iteration 37375, loss = 96.18179838\n",
      "Iteration 37376, loss = 96.17094715\n",
      "Iteration 37377, loss = 96.16009655\n",
      "Iteration 37378, loss = 96.14924663\n",
      "Iteration 37379, loss = 96.13839745\n",
      "Iteration 37380, loss = 96.12754904\n",
      "Iteration 37381, loss = 96.11670131\n",
      "Iteration 37382, loss = 96.10585425\n",
      "Iteration 37383, loss = 96.09500789\n",
      "Iteration 37384, loss = 96.08416229\n",
      "Iteration 37385, loss = 96.07331741\n",
      "Iteration 37386, loss = 96.06247321\n",
      "Iteration 37387, loss = 96.05162969\n",
      "Iteration 37388, loss = 96.04078689\n",
      "Iteration 37389, loss = 96.02994483\n",
      "Iteration 37390, loss = 96.01910348\n",
      "Iteration 37391, loss = 96.00826281\n",
      "Iteration 37392, loss = 95.99742284\n",
      "Iteration 37393, loss = 95.98658359\n",
      "Iteration 37394, loss = 95.97574506\n",
      "Iteration 37395, loss = 95.96490723\n",
      "Iteration 37396, loss = 95.95407010\n",
      "Iteration 37397, loss = 95.94323367\n",
      "Iteration 37398, loss = 95.93239796\n",
      "Iteration 37399, loss = 95.92156296\n",
      "Iteration 37400, loss = 95.91072866\n",
      "Iteration 37401, loss = 95.89989505\n",
      "Iteration 37402, loss = 95.88906216\n",
      "Iteration 37403, loss = 95.87822998\n",
      "Iteration 37404, loss = 95.86739850\n",
      "Iteration 37405, loss = 95.85656773\n",
      "Iteration 37406, loss = 95.84573765\n",
      "Iteration 37407, loss = 95.83490829\n",
      "Iteration 37408, loss = 95.82407963\n",
      "Iteration 37409, loss = 95.81325168\n",
      "Iteration 37410, loss = 95.80242442\n",
      "Iteration 37411, loss = 95.79159787\n",
      "Iteration 37412, loss = 95.78077203\n",
      "Iteration 37413, loss = 95.76994689\n",
      "Iteration 37414, loss = 95.75912246\n",
      "Iteration 37415, loss = 95.74829873\n",
      "Iteration 37416, loss = 95.73747570\n",
      "Iteration 37417, loss = 95.72665337\n",
      "Iteration 37418, loss = 95.71583175\n",
      "Iteration 37419, loss = 95.70501083\n",
      "Iteration 37420, loss = 95.69419061\n",
      "Iteration 37421, loss = 95.68337110\n",
      "Iteration 37422, loss = 95.67255229\n",
      "Iteration 37423, loss = 95.66173418\n",
      "Iteration 37424, loss = 95.65091677\n",
      "Iteration 37425, loss = 95.64010007\n",
      "Iteration 37426, loss = 95.62928406\n",
      "Iteration 37427, loss = 95.61846876\n",
      "Iteration 37428, loss = 95.60765416\n",
      "Iteration 37429, loss = 95.59684026\n",
      "Iteration 37430, loss = 95.58602707\n",
      "Iteration 37431, loss = 95.57521457\n",
      "Iteration 37432, loss = 95.56440277\n",
      "Iteration 37433, loss = 95.55359168\n",
      "Iteration 37434, loss = 95.54278128\n",
      "Iteration 37435, loss = 95.53197159\n",
      "Iteration 37436, loss = 95.52116260\n",
      "Iteration 37437, loss = 95.51035430\n",
      "Iteration 37438, loss = 95.49954671\n",
      "Iteration 37439, loss = 95.48873981\n",
      "Iteration 37440, loss = 95.47793362\n",
      "Iteration 37441, loss = 95.46712813\n",
      "Iteration 37442, loss = 95.45632333\n",
      "Iteration 37443, loss = 95.44551923\n",
      "Iteration 37444, loss = 95.43471584\n",
      "Iteration 37445, loss = 95.42391314\n",
      "Iteration 37446, loss = 95.41311114\n",
      "Iteration 37447, loss = 95.40230984\n",
      "Iteration 37448, loss = 95.39150924\n",
      "Iteration 37449, loss = 95.38070933\n",
      "Iteration 37450, loss = 95.36991012\n",
      "Iteration 37451, loss = 95.35911162\n",
      "Iteration 37452, loss = 95.34831381\n",
      "Iteration 37453, loss = 95.33751669\n",
      "Iteration 37454, loss = 95.32672028\n",
      "Iteration 37455, loss = 95.31592456\n",
      "Iteration 37456, loss = 95.30512954\n",
      "Iteration 37457, loss = 95.29433522\n",
      "Iteration 37458, loss = 95.28354159\n",
      "Iteration 37459, loss = 95.27274866\n",
      "Iteration 37460, loss = 95.26195642\n",
      "Iteration 37461, loss = 95.25116489\n",
      "Iteration 37462, loss = 95.24037405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37463, loss = 95.22958390\n",
      "Iteration 37464, loss = 95.21879445\n",
      "Iteration 37465, loss = 95.20800570\n",
      "Iteration 37466, loss = 95.19721764\n",
      "Iteration 37467, loss = 95.18643028\n",
      "Iteration 37468, loss = 95.17564362\n",
      "Iteration 37469, loss = 95.16485764\n",
      "Iteration 37470, loss = 95.15407237\n",
      "Iteration 37471, loss = 95.14328779\n",
      "Iteration 37472, loss = 95.13250390\n",
      "Iteration 37473, loss = 95.12172071\n",
      "Iteration 37474, loss = 95.11093821\n",
      "Iteration 37475, loss = 95.10015641\n",
      "Iteration 37476, loss = 95.08937530\n",
      "Iteration 37477, loss = 95.07859489\n",
      "Iteration 37478, loss = 95.06781517\n",
      "Iteration 37479, loss = 95.05703614\n",
      "Iteration 37480, loss = 95.04625781\n",
      "Iteration 37481, loss = 95.03548017\n",
      "Iteration 37482, loss = 95.02470322\n",
      "Iteration 37483, loss = 95.01392697\n",
      "Iteration 37484, loss = 95.00315141\n",
      "Iteration 37485, loss = 94.99237654\n",
      "Iteration 37486, loss = 94.98160237\n",
      "Iteration 37487, loss = 94.97082888\n",
      "Iteration 37488, loss = 94.96005609\n",
      "Iteration 37489, loss = 94.94928400\n",
      "Iteration 37490, loss = 94.93851259\n",
      "Iteration 37491, loss = 94.92774188\n",
      "Iteration 37492, loss = 94.91697186\n",
      "Iteration 37493, loss = 94.90620253\n",
      "Iteration 37494, loss = 94.89543389\n",
      "Iteration 37495, loss = 94.88466594\n",
      "Iteration 37496, loss = 94.87389869\n",
      "Iteration 37497, loss = 94.86313212\n",
      "Iteration 37498, loss = 94.85236625\n",
      "Iteration 37499, loss = 94.84160107\n",
      "Iteration 37500, loss = 94.83083657\n",
      "Iteration 37501, loss = 94.82007277\n",
      "Iteration 37502, loss = 94.80930966\n",
      "Iteration 37503, loss = 94.79854724\n",
      "Iteration 37504, loss = 94.78778551\n",
      "Iteration 37505, loss = 94.77702447\n",
      "Iteration 37506, loss = 94.76626412\n",
      "Iteration 37507, loss = 94.75550446\n",
      "Iteration 37508, loss = 94.74474548\n",
      "Iteration 37509, loss = 94.73398720\n",
      "Iteration 37510, loss = 94.72322961\n",
      "Iteration 37511, loss = 94.71247270\n",
      "Iteration 37512, loss = 94.70171649\n",
      "Iteration 37513, loss = 94.69096096\n",
      "Iteration 37514, loss = 94.68020613\n",
      "Iteration 37515, loss = 94.66945198\n",
      "Iteration 37516, loss = 94.65869852\n",
      "Iteration 37517, loss = 94.64794574\n",
      "Iteration 37518, loss = 94.63719366\n",
      "Iteration 37519, loss = 94.62644226\n",
      "Iteration 37520, loss = 94.61569155\n",
      "Iteration 37521, loss = 94.60494153\n",
      "Iteration 37522, loss = 94.59419220\n",
      "Iteration 37523, loss = 94.58344355\n",
      "Iteration 37524, loss = 94.57269559\n",
      "Iteration 37525, loss = 94.56194832\n",
      "Iteration 37526, loss = 94.55120174\n",
      "Iteration 37527, loss = 94.54045584\n",
      "Iteration 37528, loss = 94.52971063\n",
      "Iteration 37529, loss = 94.51896610\n",
      "Iteration 37530, loss = 94.50822227\n",
      "Iteration 37531, loss = 94.49747911\n",
      "Iteration 37532, loss = 94.48673665\n",
      "Iteration 37533, loss = 94.47599487\n",
      "Iteration 37534, loss = 94.46525377\n",
      "Iteration 37535, loss = 94.45451337\n",
      "Iteration 37536, loss = 94.44377364\n",
      "Iteration 37537, loss = 94.43303461\n",
      "Iteration 37538, loss = 94.42229625\n",
      "Iteration 37539, loss = 94.41155859\n",
      "Iteration 37540, loss = 94.40082161\n",
      "Iteration 37541, loss = 94.39008531\n",
      "Iteration 37542, loss = 94.37934970\n",
      "Iteration 37543, loss = 94.36861477\n",
      "Iteration 37544, loss = 94.35788053\n",
      "Iteration 37545, loss = 94.34714697\n",
      "Iteration 37546, loss = 94.33641409\n",
      "Iteration 37547, loss = 94.32568190\n",
      "Iteration 37548, loss = 94.31495040\n",
      "Iteration 37549, loss = 94.30421957\n",
      "Iteration 37550, loss = 94.29348943\n",
      "Iteration 37551, loss = 94.28275998\n",
      "Iteration 37552, loss = 94.27203121\n",
      "Iteration 37553, loss = 94.26130312\n",
      "Iteration 37554, loss = 94.25057571\n",
      "Iteration 37555, loss = 94.23984899\n",
      "Iteration 37556, loss = 94.22912295\n",
      "Iteration 37557, loss = 94.21839759\n",
      "Iteration 37558, loss = 94.20767291\n",
      "Iteration 37559, loss = 94.19694892\n",
      "Iteration 37560, loss = 94.18622561\n",
      "Iteration 37561, loss = 94.17550298\n",
      "Iteration 37562, loss = 94.16478104\n",
      "Iteration 37563, loss = 94.15405977\n",
      "Iteration 37564, loss = 94.14333919\n",
      "Iteration 37565, loss = 94.13261929\n",
      "Iteration 37566, loss = 94.12190007\n",
      "Iteration 37567, loss = 94.11118153\n",
      "Iteration 37568, loss = 94.10046368\n",
      "Iteration 37569, loss = 94.08974650\n",
      "Iteration 37570, loss = 94.07903001\n",
      "Iteration 37571, loss = 94.06831419\n",
      "Iteration 37572, loss = 94.05759906\n",
      "Iteration 37573, loss = 94.04688461\n",
      "Iteration 37574, loss = 94.03617083\n",
      "Iteration 37575, loss = 94.02545774\n",
      "Iteration 37576, loss = 94.01474533\n",
      "Iteration 37577, loss = 94.00403360\n",
      "Iteration 37578, loss = 93.99332255\n",
      "Iteration 37579, loss = 93.98261218\n",
      "Iteration 37580, loss = 93.97190248\n",
      "Iteration 37581, loss = 93.96119347\n",
      "Iteration 37582, loss = 93.95048514\n",
      "Iteration 37583, loss = 93.93977748\n",
      "Iteration 37584, loss = 93.92907051\n",
      "Iteration 37585, loss = 93.91836421\n",
      "Iteration 37586, loss = 93.90765859\n",
      "Iteration 37587, loss = 93.89695365\n",
      "Iteration 37588, loss = 93.88624939\n",
      "Iteration 37589, loss = 93.87554581\n",
      "Iteration 37590, loss = 93.86484291\n",
      "Iteration 37591, loss = 93.85414068\n",
      "Iteration 37592, loss = 93.84343914\n",
      "Iteration 37593, loss = 93.83273827\n",
      "Iteration 37594, loss = 93.82203808\n",
      "Iteration 37595, loss = 93.81133856\n",
      "Iteration 37596, loss = 93.80063973\n",
      "Iteration 37597, loss = 93.78994157\n",
      "Iteration 37598, loss = 93.77924409\n",
      "Iteration 37599, loss = 93.76854728\n",
      "Iteration 37600, loss = 93.75785116\n",
      "Iteration 37601, loss = 93.74715571\n",
      "Iteration 37602, loss = 93.73646093\n",
      "Iteration 37603, loss = 93.72576684\n",
      "Iteration 37604, loss = 93.71507342\n",
      "Iteration 37605, loss = 93.70438067\n",
      "Iteration 37606, loss = 93.69368860\n",
      "Iteration 37607, loss = 93.68299721\n",
      "Iteration 37608, loss = 93.67230650\n",
      "Iteration 37609, loss = 93.66161646\n",
      "Iteration 37610, loss = 93.65092709\n",
      "Iteration 37611, loss = 93.64023841\n",
      "Iteration 37612, loss = 93.62955039\n",
      "Iteration 37613, loss = 93.61886306\n",
      "Iteration 37614, loss = 93.60817639\n",
      "Iteration 37615, loss = 93.59749041\n",
      "Iteration 37616, loss = 93.58680510\n",
      "Iteration 37617, loss = 93.57612046\n",
      "Iteration 37618, loss = 93.56543650\n",
      "Iteration 37619, loss = 93.55475321\n",
      "Iteration 37620, loss = 93.54407060\n",
      "Iteration 37621, loss = 93.53338866\n",
      "Iteration 37622, loss = 93.52270739\n",
      "Iteration 37623, loss = 93.51202680\n",
      "Iteration 37624, loss = 93.50134689\n",
      "Iteration 37625, loss = 93.49066765\n",
      "Iteration 37626, loss = 93.47998908\n",
      "Iteration 37627, loss = 93.46931118\n",
      "Iteration 37628, loss = 93.45863396\n",
      "Iteration 37629, loss = 93.44795741\n",
      "Iteration 37630, loss = 93.43728154\n",
      "Iteration 37631, loss = 93.42660634\n",
      "Iteration 37632, loss = 93.41593181\n",
      "Iteration 37633, loss = 93.40525795\n",
      "Iteration 37634, loss = 93.39458477\n",
      "Iteration 37635, loss = 93.38391226\n",
      "Iteration 37636, loss = 93.37324043\n",
      "Iteration 37637, loss = 93.36256926\n",
      "Iteration 37638, loss = 93.35189877\n",
      "Iteration 37639, loss = 93.34122895\n",
      "Iteration 37640, loss = 93.33055980\n",
      "Iteration 37641, loss = 93.31989132\n",
      "Iteration 37642, loss = 93.30922352\n",
      "Iteration 37643, loss = 93.29855639\n",
      "Iteration 37644, loss = 93.28788992\n",
      "Iteration 37645, loss = 93.27722413\n",
      "Iteration 37646, loss = 93.26655902\n",
      "Iteration 37647, loss = 93.25589457\n",
      "Iteration 37648, loss = 93.24523079\n",
      "Iteration 37649, loss = 93.23456769\n",
      "Iteration 37650, loss = 93.22390526\n",
      "Iteration 37651, loss = 93.21324349\n",
      "Iteration 37652, loss = 93.20258240\n",
      "Iteration 37653, loss = 93.19192198\n",
      "Iteration 37654, loss = 93.18126223\n",
      "Iteration 37655, loss = 93.17060316\n",
      "Iteration 37656, loss = 93.15994476\n",
      "Iteration 37657, loss = 93.14928704\n",
      "Iteration 37658, loss = 93.13863001\n",
      "Iteration 37659, loss = 93.12797367\n",
      "Iteration 37660, loss = 93.11731805\n",
      "Iteration 37661, loss = 93.10666318\n",
      "Iteration 37662, loss = 93.09600911\n",
      "Iteration 37663, loss = 93.08535594\n",
      "Iteration 37664, loss = 93.07470377\n",
      "Iteration 37665, loss = 93.06405271\n",
      "Iteration 37666, loss = 93.05340279\n",
      "Iteration 37667, loss = 93.04275350\n",
      "Iteration 37668, loss = 93.03210406\n",
      "Iteration 37669, loss = 93.02145317\n",
      "Iteration 37670, loss = 93.01080128\n",
      "Iteration 37671, loss = 93.00015039\n",
      "Iteration 37672, loss = 92.98950273\n",
      "Iteration 37673, loss = 92.97885846\n",
      "Iteration 37674, loss = 92.96821615\n",
      "Iteration 37675, loss = 92.95757504\n",
      "Iteration 37676, loss = 92.94693693\n",
      "Iteration 37677, loss = 92.93630680\n",
      "Iteration 37678, loss = 92.92569044\n",
      "Iteration 37679, loss = 92.91509120\n",
      "Iteration 37680, loss = 92.90450241\n",
      "Iteration 37681, loss = 92.89389750\n",
      "Iteration 37682, loss = 92.88323298\n",
      "Iteration 37683, loss = 92.87250679\n",
      "Iteration 37684, loss = 92.86179141\n",
      "Iteration 37685, loss = 92.85115548\n",
      "Iteration 37686, loss = 92.84057281\n",
      "Iteration 37687, loss = 92.82996080\n",
      "Iteration 37688, loss = 92.81928421\n",
      "Iteration 37689, loss = 92.80859908\n",
      "Iteration 37690, loss = 92.79796846\n",
      "Iteration 37691, loss = 92.78736976\n",
      "Iteration 37692, loss = 92.77674001\n",
      "Iteration 37693, loss = 92.76607348\n",
      "Iteration 37694, loss = 92.75542233\n",
      "Iteration 37695, loss = 92.74480804\n",
      "Iteration 37696, loss = 92.73419283\n",
      "Iteration 37697, loss = 92.72354822\n",
      "Iteration 37698, loss = 92.71289858\n",
      "Iteration 37699, loss = 92.70227336\n",
      "Iteration 37700, loss = 92.69165886\n",
      "Iteration 37701, loss = 92.68102801\n",
      "Iteration 37702, loss = 92.67038634\n",
      "Iteration 37703, loss = 92.65975723\n",
      "Iteration 37704, loss = 92.64914051\n",
      "Iteration 37705, loss = 92.63851709\n",
      "Iteration 37706, loss = 92.62788362\n",
      "Iteration 37707, loss = 92.61725505\n",
      "Iteration 37708, loss = 92.60663668\n",
      "Iteration 37709, loss = 92.59601723\n",
      "Iteration 37710, loss = 92.58539054\n",
      "Iteration 37711, loss = 92.57476469\n",
      "Iteration 37712, loss = 92.56414599\n",
      "Iteration 37713, loss = 92.55352895\n",
      "Iteration 37714, loss = 92.54290756\n",
      "Iteration 37715, loss = 92.53228523\n",
      "Iteration 37716, loss = 92.52166740\n",
      "Iteration 37717, loss = 92.51105224\n",
      "Iteration 37718, loss = 92.50043501\n",
      "Iteration 37719, loss = 92.48981637\n",
      "Iteration 37720, loss = 92.47920027\n",
      "Iteration 37721, loss = 92.46858688\n",
      "Iteration 37722, loss = 92.45797305\n",
      "Iteration 37723, loss = 92.44735802\n",
      "Iteration 37724, loss = 92.43674421\n",
      "Iteration 37725, loss = 92.42613269\n",
      "Iteration 37726, loss = 92.41552175\n",
      "Iteration 37727, loss = 92.40491013\n",
      "Iteration 37728, loss = 92.39429897\n",
      "Iteration 37729, loss = 92.38368953\n",
      "Iteration 37730, loss = 92.37308115\n",
      "Iteration 37731, loss = 92.36247269\n",
      "Iteration 37732, loss = 92.35186440\n",
      "Iteration 37733, loss = 92.34125727\n",
      "Iteration 37734, loss = 92.33065131\n",
      "Iteration 37735, loss = 92.32004575\n",
      "Iteration 37736, loss = 92.30944038\n",
      "Iteration 37737, loss = 92.29883576\n",
      "Iteration 37738, loss = 92.28823222\n",
      "Iteration 37739, loss = 92.27762937\n",
      "Iteration 37740, loss = 92.26702686\n",
      "Iteration 37741, loss = 92.25642490\n",
      "Iteration 37742, loss = 92.24582384\n",
      "Iteration 37743, loss = 92.23522359\n",
      "Iteration 37744, loss = 92.22462386\n",
      "Iteration 37745, loss = 92.21402462\n",
      "Iteration 37746, loss = 92.20342611\n",
      "Iteration 37747, loss = 92.19282842\n",
      "Iteration 37748, loss = 92.18223139\n",
      "Iteration 37749, loss = 92.17163488\n",
      "Iteration 37750, loss = 92.16103900\n",
      "Iteration 37751, loss = 92.15044387\n",
      "Iteration 37752, loss = 92.13984947\n",
      "Iteration 37753, loss = 92.12925566\n",
      "Iteration 37754, loss = 92.11866245\n",
      "Iteration 37755, loss = 92.10806992\n",
      "Iteration 37756, loss = 92.09747811\n",
      "Iteration 37757, loss = 92.08688697\n",
      "Iteration 37758, loss = 92.07629643\n",
      "Iteration 37759, loss = 92.06570654\n",
      "Iteration 37760, loss = 92.05511733\n",
      "Iteration 37761, loss = 92.04452881\n",
      "Iteration 37762, loss = 92.03394094\n",
      "Iteration 37763, loss = 92.02335369\n",
      "Iteration 37764, loss = 92.01276711\n",
      "Iteration 37765, loss = 92.00218121\n",
      "Iteration 37766, loss = 91.99159597\n",
      "Iteration 37767, loss = 91.98101137\n",
      "Iteration 37768, loss = 91.97042742\n",
      "Iteration 37769, loss = 91.95984414\n",
      "Iteration 37770, loss = 91.94926153\n",
      "Iteration 37771, loss = 91.93867957\n",
      "Iteration 37772, loss = 91.92809826\n",
      "Iteration 37773, loss = 91.91751760\n",
      "Iteration 37774, loss = 91.90693761\n",
      "Iteration 37775, loss = 91.89635828\n",
      "Iteration 37776, loss = 91.88577961\n",
      "Iteration 37777, loss = 91.87520159\n",
      "Iteration 37778, loss = 91.86462422\n",
      "Iteration 37779, loss = 91.85404751\n",
      "Iteration 37780, loss = 91.84347147\n",
      "Iteration 37781, loss = 91.83289607\n",
      "Iteration 37782, loss = 91.82232133\n",
      "Iteration 37783, loss = 91.81174725\n",
      "Iteration 37784, loss = 91.80117383\n",
      "Iteration 37785, loss = 91.79060106\n",
      "Iteration 37786, loss = 91.78002895\n",
      "Iteration 37787, loss = 91.76945750\n",
      "Iteration 37788, loss = 91.75888669\n",
      "Iteration 37789, loss = 91.74831655\n",
      "Iteration 37790, loss = 91.73774706\n",
      "Iteration 37791, loss = 91.72717823\n",
      "Iteration 37792, loss = 91.71661005\n",
      "Iteration 37793, loss = 91.70604253\n",
      "Iteration 37794, loss = 91.69547567\n",
      "Iteration 37795, loss = 91.68490946\n",
      "Iteration 37796, loss = 91.67434390\n",
      "Iteration 37797, loss = 91.66377900\n",
      "Iteration 37798, loss = 91.65321476\n",
      "Iteration 37799, loss = 91.64265117\n",
      "Iteration 37800, loss = 91.63208823\n",
      "Iteration 37801, loss = 91.62152595\n",
      "Iteration 37802, loss = 91.61096432\n",
      "Iteration 37803, loss = 91.60040335\n",
      "Iteration 37804, loss = 91.58984303\n",
      "Iteration 37805, loss = 91.57928337\n",
      "Iteration 37806, loss = 91.56872436\n",
      "Iteration 37807, loss = 91.55816601\n",
      "Iteration 37808, loss = 91.54760831\n",
      "Iteration 37809, loss = 91.53705126\n",
      "Iteration 37810, loss = 91.52649487\n",
      "Iteration 37811, loss = 91.51593913\n",
      "Iteration 37812, loss = 91.50538405\n",
      "Iteration 37813, loss = 91.49482962\n",
      "Iteration 37814, loss = 91.48427584\n",
      "Iteration 37815, loss = 91.47372272\n",
      "Iteration 37816, loss = 91.46317025\n",
      "Iteration 37817, loss = 91.45261843\n",
      "Iteration 37818, loss = 91.44206727\n",
      "Iteration 37819, loss = 91.43151675\n",
      "Iteration 37820, loss = 91.42096690\n",
      "Iteration 37821, loss = 91.41041769\n",
      "Iteration 37822, loss = 91.39986914\n",
      "Iteration 37823, loss = 91.38932124\n",
      "Iteration 37824, loss = 91.37877400\n",
      "Iteration 37825, loss = 91.36822740\n",
      "Iteration 37826, loss = 91.35768146\n",
      "Iteration 37827, loss = 91.34713617\n",
      "Iteration 37828, loss = 91.33659154\n",
      "Iteration 37829, loss = 91.32604755\n",
      "Iteration 37830, loss = 91.31550422\n",
      "Iteration 37831, loss = 91.30496154\n",
      "Iteration 37832, loss = 91.29441952\n",
      "Iteration 37833, loss = 91.28387814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37834, loss = 91.27333742\n",
      "Iteration 37835, loss = 91.26279734\n",
      "Iteration 37836, loss = 91.25225792\n",
      "Iteration 37837, loss = 91.24171916\n",
      "Iteration 37838, loss = 91.23118104\n",
      "Iteration 37839, loss = 91.22064357\n",
      "Iteration 37840, loss = 91.21010676\n",
      "Iteration 37841, loss = 91.19957060\n",
      "Iteration 37842, loss = 91.18903509\n",
      "Iteration 37843, loss = 91.17850023\n",
      "Iteration 37844, loss = 91.16796602\n",
      "Iteration 37845, loss = 91.15743246\n",
      "Iteration 37846, loss = 91.14689955\n",
      "Iteration 37847, loss = 91.13636729\n",
      "Iteration 37848, loss = 91.12583569\n",
      "Iteration 37849, loss = 91.11530473\n",
      "Iteration 37850, loss = 91.10477443\n",
      "Iteration 37851, loss = 91.09424477\n",
      "Iteration 37852, loss = 91.08371577\n",
      "Iteration 37853, loss = 91.07318742\n",
      "Iteration 37854, loss = 91.06265971\n",
      "Iteration 37855, loss = 91.05213266\n",
      "Iteration 37856, loss = 91.04160626\n",
      "Iteration 37857, loss = 91.03108050\n",
      "Iteration 37858, loss = 91.02055540\n",
      "Iteration 37859, loss = 91.01003095\n",
      "Iteration 37860, loss = 90.99950714\n",
      "Iteration 37861, loss = 90.98898399\n",
      "Iteration 37862, loss = 90.97846148\n",
      "Iteration 37863, loss = 90.96793963\n",
      "Iteration 37864, loss = 90.95741842\n",
      "Iteration 37865, loss = 90.94689787\n",
      "Iteration 37866, loss = 90.93637796\n",
      "Iteration 37867, loss = 90.92585870\n",
      "Iteration 37868, loss = 90.91534010\n",
      "Iteration 37869, loss = 90.90482214\n",
      "Iteration 37870, loss = 90.89430483\n",
      "Iteration 37871, loss = 90.88378817\n",
      "Iteration 37872, loss = 90.87327215\n",
      "Iteration 37873, loss = 90.86275679\n",
      "Iteration 37874, loss = 90.85224207\n",
      "Iteration 37875, loss = 90.84172801\n",
      "Iteration 37876, loss = 90.83121459\n",
      "Iteration 37877, loss = 90.82070182\n",
      "Iteration 37878, loss = 90.81018970\n",
      "Iteration 37879, loss = 90.79967823\n",
      "Iteration 37880, loss = 90.78916740\n",
      "Iteration 37881, loss = 90.77865722\n",
      "Iteration 37882, loss = 90.76814770\n",
      "Iteration 37883, loss = 90.75763882\n",
      "Iteration 37884, loss = 90.74713058\n",
      "Iteration 37885, loss = 90.73662300\n",
      "Iteration 37886, loss = 90.72611606\n",
      "Iteration 37887, loss = 90.71560977\n",
      "Iteration 37888, loss = 90.70510413\n",
      "Iteration 37889, loss = 90.69459914\n",
      "Iteration 37890, loss = 90.68409479\n",
      "Iteration 37891, loss = 90.67359109\n",
      "Iteration 37892, loss = 90.66308804\n",
      "Iteration 37893, loss = 90.65258563\n",
      "Iteration 37894, loss = 90.64208388\n",
      "Iteration 37895, loss = 90.63158277\n",
      "Iteration 37896, loss = 90.62108230\n",
      "Iteration 37897, loss = 90.61058249\n",
      "Iteration 37898, loss = 90.60008332\n",
      "Iteration 37899, loss = 90.58958479\n",
      "Iteration 37900, loss = 90.57908692\n",
      "Iteration 37901, loss = 90.56858969\n",
      "Iteration 37902, loss = 90.55809311\n",
      "Iteration 37903, loss = 90.54759717\n",
      "Iteration 37904, loss = 90.53710188\n",
      "Iteration 37905, loss = 90.52660724\n",
      "Iteration 37906, loss = 90.51611324\n",
      "Iteration 37907, loss = 90.50561989\n",
      "Iteration 37908, loss = 90.49512719\n",
      "Iteration 37909, loss = 90.48463513\n",
      "Iteration 37910, loss = 90.47414372\n",
      "Iteration 37911, loss = 90.46365295\n",
      "Iteration 37912, loss = 90.45316283\n",
      "Iteration 37913, loss = 90.44267335\n",
      "Iteration 37914, loss = 90.43218453\n",
      "Iteration 37915, loss = 90.42169634\n",
      "Iteration 37916, loss = 90.41120880\n",
      "Iteration 37917, loss = 90.40072191\n",
      "Iteration 37918, loss = 90.39023567\n",
      "Iteration 37919, loss = 90.37975007\n",
      "Iteration 37920, loss = 90.36926511\n",
      "Iteration 37921, loss = 90.35878080\n",
      "Iteration 37922, loss = 90.34829713\n",
      "Iteration 37923, loss = 90.33781411\n",
      "Iteration 37924, loss = 90.32733174\n",
      "Iteration 37925, loss = 90.31685001\n",
      "Iteration 37926, loss = 90.30636892\n",
      "Iteration 37927, loss = 90.29588848\n",
      "Iteration 37928, loss = 90.28540869\n",
      "Iteration 37929, loss = 90.27492954\n",
      "Iteration 37930, loss = 90.26445103\n",
      "Iteration 37931, loss = 90.25397317\n",
      "Iteration 37932, loss = 90.24349596\n",
      "Iteration 37933, loss = 90.23301938\n",
      "Iteration 37934, loss = 90.22254346\n",
      "Iteration 37935, loss = 90.21206817\n",
      "Iteration 37936, loss = 90.20159353\n",
      "Iteration 37937, loss = 90.19111954\n",
      "Iteration 37938, loss = 90.18064619\n",
      "Iteration 37939, loss = 90.17017348\n",
      "Iteration 37940, loss = 90.15970142\n",
      "Iteration 37941, loss = 90.14923000\n",
      "Iteration 37942, loss = 90.13875923\n",
      "Iteration 37943, loss = 90.12828910\n",
      "Iteration 37944, loss = 90.11781961\n",
      "Iteration 37945, loss = 90.10735077\n",
      "Iteration 37946, loss = 90.09688257\n",
      "Iteration 37947, loss = 90.08641501\n",
      "Iteration 37948, loss = 90.07594810\n",
      "Iteration 37949, loss = 90.06548183\n",
      "Iteration 37950, loss = 90.05501620\n",
      "Iteration 37951, loss = 90.04455122\n",
      "Iteration 37952, loss = 90.03408688\n",
      "Iteration 37953, loss = 90.02362319\n",
      "Iteration 37954, loss = 90.01316013\n",
      "Iteration 37955, loss = 90.00269772\n",
      "Iteration 37956, loss = 89.99223596\n",
      "Iteration 37957, loss = 89.98177483\n",
      "Iteration 37958, loss = 89.97131435\n",
      "Iteration 37959, loss = 89.96085451\n",
      "Iteration 37960, loss = 89.95039532\n",
      "Iteration 37961, loss = 89.93993677\n",
      "Iteration 37962, loss = 89.92947886\n",
      "Iteration 37963, loss = 89.91902159\n",
      "Iteration 37964, loss = 89.90856497\n",
      "Iteration 37965, loss = 89.89810898\n",
      "Iteration 37966, loss = 89.88765365\n",
      "Iteration 37967, loss = 89.87719895\n",
      "Iteration 37968, loss = 89.86674489\n",
      "Iteration 37969, loss = 89.85629148\n",
      "Iteration 37970, loss = 89.84583871\n",
      "Iteration 37971, loss = 89.83538658\n",
      "Iteration 37972, loss = 89.82493510\n",
      "Iteration 37973, loss = 89.81448425\n",
      "Iteration 37974, loss = 89.80403405\n",
      "Iteration 37975, loss = 89.79358449\n",
      "Iteration 37976, loss = 89.78313557\n",
      "Iteration 37977, loss = 89.77268729\n",
      "Iteration 37978, loss = 89.76223966\n",
      "Iteration 37979, loss = 89.75179267\n",
      "Iteration 37980, loss = 89.74134631\n",
      "Iteration 37981, loss = 89.73090060\n",
      "Iteration 37982, loss = 89.72045554\n",
      "Iteration 37983, loss = 89.71001111\n",
      "Iteration 37984, loss = 89.69956732\n",
      "Iteration 37985, loss = 89.68912418\n",
      "Iteration 37986, loss = 89.67868168\n",
      "Iteration 37987, loss = 89.66823981\n",
      "Iteration 37988, loss = 89.65779859\n",
      "Iteration 37989, loss = 89.64735801\n",
      "Iteration 37990, loss = 89.63691808\n",
      "Iteration 37991, loss = 89.62647878\n",
      "Iteration 37992, loss = 89.61604012\n",
      "Iteration 37993, loss = 89.60560211\n",
      "Iteration 37994, loss = 89.59516473\n",
      "Iteration 37995, loss = 89.58472800\n",
      "Iteration 37996, loss = 89.57429190\n",
      "Iteration 37997, loss = 89.56385645\n",
      "Iteration 37998, loss = 89.55342164\n",
      "Iteration 37999, loss = 89.54298747\n",
      "Iteration 38000, loss = 89.53255394\n",
      "Iteration 38001, loss = 89.52212104\n",
      "Iteration 38002, loss = 89.51168879\n",
      "Iteration 38003, loss = 89.50125718\n",
      "Iteration 38004, loss = 89.49082622\n",
      "Iteration 38005, loss = 89.48039589\n",
      "Iteration 38006, loss = 89.46996620\n",
      "Iteration 38007, loss = 89.45953715\n",
      "Iteration 38008, loss = 89.44910874\n",
      "Iteration 38009, loss = 89.43868097\n",
      "Iteration 38010, loss = 89.42825384\n",
      "Iteration 38011, loss = 89.41782735\n",
      "Iteration 38012, loss = 89.40740150\n",
      "Iteration 38013, loss = 89.39697629\n",
      "Iteration 38014, loss = 89.38655173\n",
      "Iteration 38015, loss = 89.37612780\n",
      "Iteration 38016, loss = 89.36570451\n",
      "Iteration 38017, loss = 89.35528186\n",
      "Iteration 38018, loss = 89.34485984\n",
      "Iteration 38019, loss = 89.33443847\n",
      "Iteration 38020, loss = 89.32401774\n",
      "Iteration 38021, loss = 89.31359765\n",
      "Iteration 38022, loss = 89.30317820\n",
      "Iteration 38023, loss = 89.29275938\n",
      "Iteration 38024, loss = 89.28234121\n",
      "Iteration 38025, loss = 89.27192367\n",
      "Iteration 38026, loss = 89.26150678\n",
      "Iteration 38027, loss = 89.25109052\n",
      "Iteration 38028, loss = 89.24067490\n",
      "Iteration 38029, loss = 89.23025992\n",
      "Iteration 38030, loss = 89.21984559\n",
      "Iteration 38031, loss = 89.20943188\n",
      "Iteration 38032, loss = 89.19901882\n",
      "Iteration 38033, loss = 89.18860640\n",
      "Iteration 38034, loss = 89.17819462\n",
      "Iteration 38035, loss = 89.16778347\n",
      "Iteration 38036, loss = 89.15737296\n",
      "Iteration 38037, loss = 89.14696310\n",
      "Iteration 38038, loss = 89.13655387\n",
      "Iteration 38039, loss = 89.12614528\n",
      "Iteration 38040, loss = 89.11573732\n",
      "Iteration 38041, loss = 89.10533001\n",
      "Iteration 38042, loss = 89.09492333\n",
      "Iteration 38043, loss = 89.08451730\n",
      "Iteration 38044, loss = 89.07411190\n",
      "Iteration 38045, loss = 89.06370715\n",
      "Iteration 38046, loss = 89.05330303\n",
      "Iteration 38047, loss = 89.04289956\n",
      "Iteration 38048, loss = 89.03249674\n",
      "Iteration 38049, loss = 89.02209459\n",
      "Iteration 38050, loss = 89.01169311\n",
      "Iteration 38051, loss = 89.00129237\n",
      "Iteration 38052, loss = 88.99089242\n",
      "Iteration 38053, loss = 88.98049343\n",
      "Iteration 38054, loss = 88.97009568\n",
      "Iteration 38055, loss = 88.95969975\n",
      "Iteration 38056, loss = 88.94930669\n",
      "Iteration 38057, loss = 88.93891848\n",
      "Iteration 38058, loss = 88.92853845\n",
      "Iteration 38059, loss = 88.91817161\n",
      "Iteration 38060, loss = 88.90782204\n",
      "Iteration 38061, loss = 88.89748523\n",
      "Iteration 38062, loss = 88.88713111\n",
      "Iteration 38063, loss = 88.87671366\n",
      "Iteration 38064, loss = 88.86622804\n",
      "Iteration 38065, loss = 88.85575840\n",
      "Iteration 38066, loss = 88.84537737\n",
      "Iteration 38067, loss = 88.83504964\n",
      "Iteration 38068, loss = 88.82468240\n",
      "Iteration 38069, loss = 88.81424232\n",
      "Iteration 38070, loss = 88.80380104\n",
      "Iteration 38071, loss = 88.79342388\n",
      "Iteration 38072, loss = 88.78307588\n",
      "Iteration 38073, loss = 88.77268841\n",
      "Iteration 38074, loss = 88.76226517\n",
      "Iteration 38075, loss = 88.75186577\n",
      "Iteration 38076, loss = 88.74150253\n",
      "Iteration 38077, loss = 88.73112987\n",
      "Iteration 38078, loss = 88.72072749\n",
      "Iteration 38079, loss = 88.71032874\n",
      "Iteration 38080, loss = 88.69995630\n",
      "Iteration 38081, loss = 88.68958616\n",
      "Iteration 38082, loss = 88.67919615\n",
      "Iteration 38083, loss = 88.66880292\n",
      "Iteration 38084, loss = 88.65842693\n",
      "Iteration 38085, loss = 88.64805710\n",
      "Iteration 38086, loss = 88.63767504\n",
      "Iteration 38087, loss = 88.62728754\n",
      "Iteration 38088, loss = 88.61691080\n",
      "Iteration 38089, loss = 88.60654111\n",
      "Iteration 38090, loss = 88.59616459\n",
      "Iteration 38091, loss = 88.58578255\n",
      "Iteration 38092, loss = 88.57540661\n",
      "Iteration 38093, loss = 88.56503717\n",
      "Iteration 38094, loss = 88.55466477\n",
      "Iteration 38095, loss = 88.54428775\n",
      "Iteration 38096, loss = 88.53391364\n",
      "Iteration 38097, loss = 88.52354482\n",
      "Iteration 38098, loss = 88.51317552\n",
      "Iteration 38099, loss = 88.50280295\n",
      "Iteration 38100, loss = 88.49243139\n",
      "Iteration 38101, loss = 88.48206370\n",
      "Iteration 38102, loss = 88.47169686\n",
      "Iteration 38103, loss = 88.46132814\n",
      "Iteration 38104, loss = 88.45095950\n",
      "Iteration 38105, loss = 88.44059345\n",
      "Iteration 38106, loss = 88.43022881\n",
      "Iteration 38107, loss = 88.41986339\n",
      "Iteration 38108, loss = 88.40949778\n",
      "Iteration 38109, loss = 88.39913381\n",
      "Iteration 38110, loss = 88.38877131\n",
      "Iteration 38111, loss = 88.37840879\n",
      "Iteration 38112, loss = 88.36804615\n",
      "Iteration 38113, loss = 88.35768455\n",
      "Iteration 38114, loss = 88.34732426\n",
      "Iteration 38115, loss = 88.33696442\n",
      "Iteration 38116, loss = 88.32660464\n",
      "Iteration 38117, loss = 88.31624555\n",
      "Iteration 38118, loss = 88.30588756\n",
      "Iteration 38119, loss = 88.29553027\n",
      "Iteration 38120, loss = 88.28517325\n",
      "Iteration 38121, loss = 88.27481674\n",
      "Iteration 38122, loss = 88.26446115\n",
      "Iteration 38123, loss = 88.25410636\n",
      "Iteration 38124, loss = 88.24375200\n",
      "Iteration 38125, loss = 88.23339811\n",
      "Iteration 38126, loss = 88.22304498\n",
      "Iteration 38127, loss = 88.21269265\n",
      "Iteration 38128, loss = 88.20234090\n",
      "Iteration 38129, loss = 88.19198963\n",
      "Iteration 38130, loss = 88.18163901\n",
      "Iteration 38131, loss = 88.17128915\n",
      "Iteration 38132, loss = 88.16093996\n",
      "Iteration 38133, loss = 88.15059130\n",
      "Iteration 38134, loss = 88.14024323\n",
      "Iteration 38135, loss = 88.12989585\n",
      "Iteration 38136, loss = 88.11954918\n",
      "Iteration 38137, loss = 88.10920310\n",
      "Iteration 38138, loss = 88.09885760\n",
      "Iteration 38139, loss = 88.08851274\n",
      "Iteration 38140, loss = 88.07816857\n",
      "Iteration 38141, loss = 88.06782504\n",
      "Iteration 38142, loss = 88.05748211\n",
      "Iteration 38143, loss = 88.04713979\n",
      "Iteration 38144, loss = 88.03679813\n",
      "Iteration 38145, loss = 88.02645713\n",
      "Iteration 38146, loss = 88.01611676\n",
      "Iteration 38147, loss = 88.00577699\n",
      "Iteration 38148, loss = 87.99543786\n",
      "Iteration 38149, loss = 87.98509939\n",
      "Iteration 38150, loss = 87.97476155\n",
      "Iteration 38151, loss = 87.96442434\n",
      "Iteration 38152, loss = 87.95408775\n",
      "Iteration 38153, loss = 87.94375180\n",
      "Iteration 38154, loss = 87.93341649\n",
      "Iteration 38155, loss = 87.92308182\n",
      "Iteration 38156, loss = 87.91274777\n",
      "Iteration 38157, loss = 87.90241436\n",
      "Iteration 38158, loss = 87.89208159\n",
      "Iteration 38159, loss = 87.88174945\n",
      "Iteration 38160, loss = 87.87141794\n",
      "Iteration 38161, loss = 87.86108707\n",
      "Iteration 38162, loss = 87.85075682\n",
      "Iteration 38163, loss = 87.84042722\n",
      "Iteration 38164, loss = 87.83009825\n",
      "Iteration 38165, loss = 87.81976991\n",
      "Iteration 38166, loss = 87.80944221\n",
      "Iteration 38167, loss = 87.79911514\n",
      "Iteration 38168, loss = 87.78878870\n",
      "Iteration 38169, loss = 87.77846290\n",
      "Iteration 38170, loss = 87.76813773\n",
      "Iteration 38171, loss = 87.75781319\n",
      "Iteration 38172, loss = 87.74748929\n",
      "Iteration 38173, loss = 87.73716602\n",
      "Iteration 38174, loss = 87.72684339\n",
      "Iteration 38175, loss = 87.71652139\n",
      "Iteration 38176, loss = 87.70620002\n",
      "Iteration 38177, loss = 87.69587929\n",
      "Iteration 38178, loss = 87.68555919\n",
      "Iteration 38179, loss = 87.67523972\n",
      "Iteration 38180, loss = 87.66492089\n",
      "Iteration 38181, loss = 87.65460269\n",
      "Iteration 38182, loss = 87.64428512\n",
      "Iteration 38183, loss = 87.63396819\n",
      "Iteration 38184, loss = 87.62365189\n",
      "Iteration 38185, loss = 87.61333622\n",
      "Iteration 38186, loss = 87.60302119\n",
      "Iteration 38187, loss = 87.59270679\n",
      "Iteration 38188, loss = 87.58239302\n",
      "Iteration 38189, loss = 87.57207989\n",
      "Iteration 38190, loss = 87.56176738\n",
      "Iteration 38191, loss = 87.55145552\n",
      "Iteration 38192, loss = 87.54114428\n",
      "Iteration 38193, loss = 87.53083368\n",
      "Iteration 38194, loss = 87.52052371\n",
      "Iteration 38195, loss = 87.51021438\n",
      "Iteration 38196, loss = 87.49990568\n",
      "Iteration 38197, loss = 87.48959761\n",
      "Iteration 38198, loss = 87.47929017\n",
      "Iteration 38199, loss = 87.46898337\n",
      "Iteration 38200, loss = 87.45867720\n",
      "Iteration 38201, loss = 87.44837167\n",
      "Iteration 38202, loss = 87.43806676\n",
      "Iteration 38203, loss = 87.42776249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38204, loss = 87.41745885\n",
      "Iteration 38205, loss = 87.40715585\n",
      "Iteration 38206, loss = 87.39685348\n",
      "Iteration 38207, loss = 87.38655174\n",
      "Iteration 38208, loss = 87.37625063\n",
      "Iteration 38209, loss = 87.36595016\n",
      "Iteration 38210, loss = 87.35565032\n",
      "Iteration 38211, loss = 87.34535111\n",
      "Iteration 38212, loss = 87.33505253\n",
      "Iteration 38213, loss = 87.32475459\n",
      "Iteration 38214, loss = 87.31445728\n",
      "Iteration 38215, loss = 87.30416061\n",
      "Iteration 38216, loss = 87.29386456\n",
      "Iteration 38217, loss = 87.28356915\n",
      "Iteration 38218, loss = 87.27327437\n",
      "Iteration 38219, loss = 87.26298023\n",
      "Iteration 38220, loss = 87.25268671\n",
      "Iteration 38221, loss = 87.24239383\n",
      "Iteration 38222, loss = 87.23210158\n",
      "Iteration 38223, loss = 87.22180997\n",
      "Iteration 38224, loss = 87.21151899\n",
      "Iteration 38225, loss = 87.20122864\n",
      "Iteration 38226, loss = 87.19093892\n",
      "Iteration 38227, loss = 87.18064983\n",
      "Iteration 38228, loss = 87.17036138\n",
      "Iteration 38229, loss = 87.16007356\n",
      "Iteration 38230, loss = 87.14978637\n",
      "Iteration 38231, loss = 87.13949982\n",
      "Iteration 38232, loss = 87.12921389\n",
      "Iteration 38233, loss = 87.11892860\n",
      "Iteration 38234, loss = 87.10864394\n",
      "Iteration 38235, loss = 87.09835992\n",
      "Iteration 38236, loss = 87.08807652\n",
      "Iteration 38237, loss = 87.07779376\n",
      "Iteration 38238, loss = 87.06751163\n",
      "Iteration 38239, loss = 87.05723014\n",
      "Iteration 38240, loss = 87.04694927\n",
      "Iteration 38241, loss = 87.03666904\n",
      "Iteration 38242, loss = 87.02638944\n",
      "Iteration 38243, loss = 87.01611048\n",
      "Iteration 38244, loss = 87.00583214\n",
      "Iteration 38245, loss = 86.99555444\n",
      "Iteration 38246, loss = 86.98527737\n",
      "Iteration 38247, loss = 86.97500093\n",
      "Iteration 38248, loss = 86.96472512\n",
      "Iteration 38249, loss = 86.95444995\n",
      "Iteration 38250, loss = 86.94417541\n",
      "Iteration 38251, loss = 86.93390150\n",
      "Iteration 38252, loss = 86.92362822\n",
      "Iteration 38253, loss = 86.91335558\n",
      "Iteration 38254, loss = 86.90308356\n",
      "Iteration 38255, loss = 86.89281218\n",
      "Iteration 38256, loss = 86.88254143\n",
      "Iteration 38257, loss = 86.87227132\n",
      "Iteration 38258, loss = 86.86200183\n",
      "Iteration 38259, loss = 86.85173298\n",
      "Iteration 38260, loss = 86.84146476\n",
      "Iteration 38261, loss = 86.83119717\n",
      "Iteration 38262, loss = 86.82093021\n",
      "Iteration 38263, loss = 86.81066389\n",
      "Iteration 38264, loss = 86.80039820\n",
      "Iteration 38265, loss = 86.79013314\n",
      "Iteration 38266, loss = 86.77986871\n",
      "Iteration 38267, loss = 86.76960491\n",
      "Iteration 38268, loss = 86.75934175\n",
      "Iteration 38269, loss = 86.74907922\n",
      "Iteration 38270, loss = 86.73881731\n",
      "Iteration 38271, loss = 86.72855605\n",
      "Iteration 38272, loss = 86.71829541\n",
      "Iteration 38273, loss = 86.70803541\n",
      "Iteration 38274, loss = 86.69777603\n",
      "Iteration 38275, loss = 86.68751729\n",
      "Iteration 38276, loss = 86.67725918\n",
      "Iteration 38277, loss = 86.66700171\n",
      "Iteration 38278, loss = 86.65674486\n",
      "Iteration 38279, loss = 86.64648865\n",
      "Iteration 38280, loss = 86.63623307\n",
      "Iteration 38281, loss = 86.62597812\n",
      "Iteration 38282, loss = 86.61572380\n",
      "Iteration 38283, loss = 86.60547011\n",
      "Iteration 38284, loss = 86.59521706\n",
      "Iteration 38285, loss = 86.58496464\n",
      "Iteration 38286, loss = 86.57471285\n",
      "Iteration 38287, loss = 86.56446169\n",
      "Iteration 38288, loss = 86.55421116\n",
      "Iteration 38289, loss = 86.54396127\n",
      "Iteration 38290, loss = 86.53371200\n",
      "Iteration 38291, loss = 86.52346337\n",
      "Iteration 38292, loss = 86.51321537\n",
      "Iteration 38293, loss = 86.50296800\n",
      "Iteration 38294, loss = 86.49272127\n",
      "Iteration 38295, loss = 86.48247516\n",
      "Iteration 38296, loss = 86.47222969\n",
      "Iteration 38297, loss = 86.46198485\n",
      "Iteration 38298, loss = 86.45174064\n",
      "Iteration 38299, loss = 86.44149706\n",
      "Iteration 38300, loss = 86.43125412\n",
      "Iteration 38301, loss = 86.42101180\n",
      "Iteration 38302, loss = 86.41077012\n",
      "Iteration 38303, loss = 86.40052907\n",
      "Iteration 38304, loss = 86.39028865\n",
      "Iteration 38305, loss = 86.38004886\n",
      "Iteration 38306, loss = 86.36980971\n",
      "Iteration 38307, loss = 86.35957118\n",
      "Iteration 38308, loss = 86.34933329\n",
      "Iteration 38309, loss = 86.33909603\n",
      "Iteration 38310, loss = 86.32885940\n",
      "Iteration 38311, loss = 86.31862340\n",
      "Iteration 38312, loss = 86.30838804\n",
      "Iteration 38313, loss = 86.29815330\n",
      "Iteration 38314, loss = 86.28791920\n",
      "Iteration 38315, loss = 86.27768573\n",
      "Iteration 38316, loss = 86.26745289\n",
      "Iteration 38317, loss = 86.25722068\n",
      "Iteration 38318, loss = 86.24698911\n",
      "Iteration 38319, loss = 86.23675816\n",
      "Iteration 38320, loss = 86.22652785\n",
      "Iteration 38321, loss = 86.21629817\n",
      "Iteration 38322, loss = 86.20606912\n",
      "Iteration 38323, loss = 86.19584070\n",
      "Iteration 38324, loss = 86.18561291\n",
      "Iteration 38325, loss = 86.17538576\n",
      "Iteration 38326, loss = 86.16515923\n",
      "Iteration 38327, loss = 86.15493334\n",
      "Iteration 38328, loss = 86.14470808\n",
      "Iteration 38329, loss = 86.13448345\n",
      "Iteration 38330, loss = 86.12425946\n",
      "Iteration 38331, loss = 86.11403609\n",
      "Iteration 38332, loss = 86.10381336\n",
      "Iteration 38333, loss = 86.09359126\n",
      "Iteration 38334, loss = 86.08336978\n",
      "Iteration 38335, loss = 86.07314895\n",
      "Iteration 38336, loss = 86.06292874\n",
      "Iteration 38337, loss = 86.05270916\n",
      "Iteration 38338, loss = 86.04249022\n",
      "Iteration 38339, loss = 86.03227190\n",
      "Iteration 38340, loss = 86.02205422\n",
      "Iteration 38341, loss = 86.01183717\n",
      "Iteration 38342, loss = 86.00162076\n",
      "Iteration 38343, loss = 85.99140497\n",
      "Iteration 38344, loss = 85.98118981\n",
      "Iteration 38345, loss = 85.97097529\n",
      "Iteration 38346, loss = 85.96076140\n",
      "Iteration 38347, loss = 85.95054814\n",
      "Iteration 38348, loss = 85.94033551\n",
      "Iteration 38349, loss = 85.93012351\n",
      "Iteration 38350, loss = 85.91991215\n",
      "Iteration 38351, loss = 85.90970141\n",
      "Iteration 38352, loss = 85.89949131\n",
      "Iteration 38353, loss = 85.88928184\n",
      "Iteration 38354, loss = 85.87907300\n",
      "Iteration 38355, loss = 85.86886479\n",
      "Iteration 38356, loss = 85.85865721\n",
      "Iteration 38357, loss = 85.84845027\n",
      "Iteration 38358, loss = 85.83824395\n",
      "Iteration 38359, loss = 85.82803827\n",
      "Iteration 38360, loss = 85.81783322\n",
      "Iteration 38361, loss = 85.80762880\n",
      "Iteration 38362, loss = 85.79742502\n",
      "Iteration 38363, loss = 85.78722186\n",
      "Iteration 38364, loss = 85.77701934\n",
      "Iteration 38365, loss = 85.76681744\n",
      "Iteration 38366, loss = 85.75661618\n",
      "Iteration 38367, loss = 85.74641555\n",
      "Iteration 38368, loss = 85.73621556\n",
      "Iteration 38369, loss = 85.72601619\n",
      "Iteration 38370, loss = 85.71581745\n",
      "Iteration 38371, loss = 85.70561935\n",
      "Iteration 38372, loss = 85.69542188\n",
      "Iteration 38373, loss = 85.68522504\n",
      "Iteration 38374, loss = 85.67502883\n",
      "Iteration 38375, loss = 85.66483325\n",
      "Iteration 38376, loss = 85.65463831\n",
      "Iteration 38377, loss = 85.64444400\n",
      "Iteration 38378, loss = 85.63425031\n",
      "Iteration 38379, loss = 85.62405726\n",
      "Iteration 38380, loss = 85.61386484\n",
      "Iteration 38381, loss = 85.60367306\n",
      "Iteration 38382, loss = 85.59348190\n",
      "Iteration 38383, loss = 85.58329138\n",
      "Iteration 38384, loss = 85.57310148\n",
      "Iteration 38385, loss = 85.56291222\n",
      "Iteration 38386, loss = 85.55272359\n",
      "Iteration 38387, loss = 85.54253560\n",
      "Iteration 38388, loss = 85.53234823\n",
      "Iteration 38389, loss = 85.52216149\n",
      "Iteration 38390, loss = 85.51197539\n",
      "Iteration 38391, loss = 85.50178992\n",
      "Iteration 38392, loss = 85.49160508\n",
      "Iteration 38393, loss = 85.48142087\n",
      "Iteration 38394, loss = 85.47123730\n",
      "Iteration 38395, loss = 85.46105435\n",
      "Iteration 38396, loss = 85.45087204\n",
      "Iteration 38397, loss = 85.44069036\n",
      "Iteration 38398, loss = 85.43050931\n",
      "Iteration 38399, loss = 85.42032889\n",
      "Iteration 38400, loss = 85.41014910\n",
      "Iteration 38401, loss = 85.39996995\n",
      "Iteration 38402, loss = 85.38979143\n",
      "Iteration 38403, loss = 85.37961354\n",
      "Iteration 38404, loss = 85.36943628\n",
      "Iteration 38405, loss = 85.35925965\n",
      "Iteration 38406, loss = 85.34908365\n",
      "Iteration 38407, loss = 85.33890829\n",
      "Iteration 38408, loss = 85.32873355\n",
      "Iteration 38409, loss = 85.31855945\n",
      "Iteration 38410, loss = 85.30838598\n",
      "Iteration 38411, loss = 85.29821315\n",
      "Iteration 38412, loss = 85.28804094\n",
      "Iteration 38413, loss = 85.27786937\n",
      "Iteration 38414, loss = 85.26769843\n",
      "Iteration 38415, loss = 85.25752811\n",
      "Iteration 38416, loss = 85.24735844\n",
      "Iteration 38417, loss = 85.23718939\n",
      "Iteration 38418, loss = 85.22702097\n",
      "Iteration 38419, loss = 85.21685319\n",
      "Iteration 38420, loss = 85.20668604\n",
      "Iteration 38421, loss = 85.19651952\n",
      "Iteration 38422, loss = 85.18635363\n",
      "Iteration 38423, loss = 85.17618838\n",
      "Iteration 38424, loss = 85.16602375\n",
      "Iteration 38425, loss = 85.15585976\n",
      "Iteration 38426, loss = 85.14569640\n",
      "Iteration 38427, loss = 85.13553367\n",
      "Iteration 38428, loss = 85.12537157\n",
      "Iteration 38429, loss = 85.11521011\n",
      "Iteration 38430, loss = 85.10504927\n",
      "Iteration 38431, loss = 85.09488907\n",
      "Iteration 38432, loss = 85.08472950\n",
      "Iteration 38433, loss = 85.07457057\n",
      "Iteration 38434, loss = 85.06441226\n",
      "Iteration 38435, loss = 85.05425459\n",
      "Iteration 38436, loss = 85.04409755\n",
      "Iteration 38437, loss = 85.03394114\n",
      "Iteration 38438, loss = 85.02378536\n",
      "Iteration 38439, loss = 85.01363021\n",
      "Iteration 38440, loss = 85.00347570\n",
      "Iteration 38441, loss = 84.99332182\n",
      "Iteration 38442, loss = 84.98316857\n",
      "Iteration 38443, loss = 84.97301595\n",
      "Iteration 38444, loss = 84.96286397\n",
      "Iteration 38445, loss = 84.95271262\n",
      "Iteration 38446, loss = 84.94256190\n",
      "Iteration 38447, loss = 84.93241182\n",
      "Iteration 38448, loss = 84.92226237\n",
      "Iteration 38449, loss = 84.91211358\n",
      "Iteration 38450, loss = 84.90196544\n",
      "Iteration 38451, loss = 84.89181799\n",
      "Iteration 38452, loss = 84.88167127\n",
      "Iteration 38453, loss = 84.87152538\n",
      "Iteration 38454, loss = 84.86138051\n",
      "Iteration 38455, loss = 84.85123704\n",
      "Iteration 38456, loss = 84.84109569\n",
      "Iteration 38457, loss = 84.83095787\n",
      "Iteration 38458, loss = 84.82082617\n",
      "Iteration 38459, loss = 84.81070507\n",
      "Iteration 38460, loss = 84.80060046\n",
      "Iteration 38461, loss = 84.79051616\n",
      "Iteration 38462, loss = 84.78043857\n",
      "Iteration 38463, loss = 84.77032415\n",
      "Iteration 38464, loss = 84.76012188\n",
      "Iteration 38465, loss = 84.74987017\n",
      "Iteration 38466, loss = 84.73968072\n",
      "Iteration 38467, loss = 84.72959112\n",
      "Iteration 38468, loss = 84.71951510\n",
      "Iteration 38469, loss = 84.70936110\n",
      "Iteration 38470, loss = 84.69915739\n",
      "Iteration 38471, loss = 84.68900362\n",
      "Iteration 38472, loss = 84.67891191\n",
      "Iteration 38473, loss = 84.66880000\n",
      "Iteration 38474, loss = 84.65863194\n",
      "Iteration 38475, loss = 84.64846956\n",
      "Iteration 38476, loss = 84.63835659\n",
      "Iteration 38477, loss = 84.62824911\n",
      "Iteration 38478, loss = 84.61810309\n",
      "Iteration 38479, loss = 84.60794797\n",
      "Iteration 38480, loss = 84.59782470\n",
      "Iteration 38481, loss = 84.58771321\n",
      "Iteration 38482, loss = 84.57757835\n",
      "Iteration 38483, loss = 84.56743384\n",
      "Iteration 38484, loss = 84.55730963\n",
      "Iteration 38485, loss = 84.54719629\n",
      "Iteration 38486, loss = 84.53706846\n",
      "Iteration 38487, loss = 84.52693196\n",
      "Iteration 38488, loss = 84.51680777\n",
      "Iteration 38489, loss = 84.50669221\n",
      "Iteration 38490, loss = 84.49656826\n",
      "Iteration 38491, loss = 84.48643843\n",
      "Iteration 38492, loss = 84.47631666\n",
      "Iteration 38493, loss = 84.46620135\n",
      "Iteration 38494, loss = 84.45608094\n",
      "Iteration 38495, loss = 84.44595612\n",
      "Iteration 38496, loss = 84.43583629\n",
      "Iteration 38497, loss = 84.42572135\n",
      "Iteration 38498, loss = 84.41560382\n",
      "Iteration 38499, loss = 84.40548349\n",
      "Iteration 38500, loss = 84.39536640\n",
      "Iteration 38501, loss = 84.38525291\n",
      "Iteration 38502, loss = 84.37513808\n",
      "Iteration 38503, loss = 84.36502132\n",
      "Iteration 38504, loss = 84.35490662\n",
      "Iteration 38505, loss = 84.34479475\n",
      "Iteration 38506, loss = 84.33468256\n",
      "Iteration 38507, loss = 84.32456925\n",
      "Iteration 38508, loss = 84.31445725\n",
      "Iteration 38509, loss = 84.30434737\n",
      "Iteration 38510, loss = 84.29423766\n",
      "Iteration 38511, loss = 84.28412734\n",
      "Iteration 38512, loss = 84.27401791\n",
      "Iteration 38513, loss = 84.26391017\n",
      "Iteration 38514, loss = 84.25380299\n",
      "Iteration 38515, loss = 84.24369560\n",
      "Iteration 38516, loss = 84.23358884\n",
      "Iteration 38517, loss = 84.22348339\n",
      "Iteration 38518, loss = 84.21337864\n",
      "Iteration 38519, loss = 84.20327398\n",
      "Iteration 38520, loss = 84.19316983\n",
      "Iteration 38521, loss = 84.18306676\n",
      "Iteration 38522, loss = 84.17296448\n",
      "Iteration 38523, loss = 84.16286252\n",
      "Iteration 38524, loss = 84.15276101\n",
      "Iteration 38525, loss = 84.14266038\n",
      "Iteration 38526, loss = 84.13256054\n",
      "Iteration 38527, loss = 84.12246117\n",
      "Iteration 38528, loss = 84.11236228\n",
      "Iteration 38529, loss = 84.10226413\n",
      "Iteration 38530, loss = 84.09216677\n",
      "Iteration 38531, loss = 84.08206998\n",
      "Iteration 38532, loss = 84.07197369\n",
      "Iteration 38533, loss = 84.06187806\n",
      "Iteration 38534, loss = 84.05178317\n",
      "Iteration 38535, loss = 84.04168892\n",
      "Iteration 38536, loss = 84.03159521\n",
      "Iteration 38537, loss = 84.02150211\n",
      "Iteration 38538, loss = 84.01140973\n",
      "Iteration 38539, loss = 84.00131800\n",
      "Iteration 38540, loss = 83.99122686\n",
      "Iteration 38541, loss = 83.98113631\n",
      "Iteration 38542, loss = 83.97104643\n",
      "Iteration 38543, loss = 83.96095722\n",
      "Iteration 38544, loss = 83.95086863\n",
      "Iteration 38545, loss = 83.94078063\n",
      "Iteration 38546, loss = 83.93069328\n",
      "Iteration 38547, loss = 83.92060659\n",
      "Iteration 38548, loss = 83.91052053\n",
      "Iteration 38549, loss = 83.90043509\n",
      "Iteration 38550, loss = 83.89035027\n",
      "Iteration 38551, loss = 83.88026610\n",
      "Iteration 38552, loss = 83.87018257\n",
      "Iteration 38553, loss = 83.86009967\n",
      "Iteration 38554, loss = 83.85001739\n",
      "Iteration 38555, loss = 83.83993575\n",
      "Iteration 38556, loss = 83.82985475\n",
      "Iteration 38557, loss = 83.81977439\n",
      "Iteration 38558, loss = 83.80969465\n",
      "Iteration 38559, loss = 83.79961554\n",
      "Iteration 38560, loss = 83.78953707\n",
      "Iteration 38561, loss = 83.77945924\n",
      "Iteration 38562, loss = 83.76938204\n",
      "Iteration 38563, loss = 83.75930547\n",
      "Iteration 38564, loss = 83.74922953\n",
      "Iteration 38565, loss = 83.73915423\n",
      "Iteration 38566, loss = 83.72907957\n",
      "Iteration 38567, loss = 83.71900553\n",
      "Iteration 38568, loss = 83.70893213\n",
      "Iteration 38569, loss = 83.69885937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38570, loss = 83.68878723\n",
      "Iteration 38571, loss = 83.67871574\n",
      "Iteration 38572, loss = 83.66864487\n",
      "Iteration 38573, loss = 83.65857464\n",
      "Iteration 38574, loss = 83.64850504\n",
      "Iteration 38575, loss = 83.63843608\n",
      "Iteration 38576, loss = 83.62836775\n",
      "Iteration 38577, loss = 83.61830005\n",
      "Iteration 38578, loss = 83.60823299\n",
      "Iteration 38579, loss = 83.59816657\n",
      "Iteration 38580, loss = 83.58810077\n",
      "Iteration 38581, loss = 83.57803561\n",
      "Iteration 38582, loss = 83.56797109\n",
      "Iteration 38583, loss = 83.55790720\n",
      "Iteration 38584, loss = 83.54784394\n",
      "Iteration 38585, loss = 83.53778131\n",
      "Iteration 38586, loss = 83.52771933\n",
      "Iteration 38587, loss = 83.51765797\n",
      "Iteration 38588, loss = 83.50759725\n",
      "Iteration 38589, loss = 83.49753716\n",
      "Iteration 38590, loss = 83.48747771\n",
      "Iteration 38591, loss = 83.47741889\n",
      "Iteration 38592, loss = 83.46736071\n",
      "Iteration 38593, loss = 83.45730316\n",
      "Iteration 38594, loss = 83.44724624\n",
      "Iteration 38595, loss = 83.43718996\n",
      "Iteration 38596, loss = 83.42713431\n",
      "Iteration 38597, loss = 83.41707930\n",
      "Iteration 38598, loss = 83.40702492\n",
      "Iteration 38599, loss = 83.39697118\n",
      "Iteration 38600, loss = 83.38691807\n",
      "Iteration 38601, loss = 83.37686559\n",
      "Iteration 38602, loss = 83.36681375\n",
      "Iteration 38603, loss = 83.35676254\n",
      "Iteration 38604, loss = 83.34671197\n",
      "Iteration 38605, loss = 83.33666203\n",
      "Iteration 38606, loss = 83.32661273\n",
      "Iteration 38607, loss = 83.31656406\n",
      "Iteration 38608, loss = 83.30651603\n",
      "Iteration 38609, loss = 83.29646863\n",
      "Iteration 38610, loss = 83.28642187\n",
      "Iteration 38611, loss = 83.27637574\n",
      "Iteration 38612, loss = 83.26633024\n",
      "Iteration 38613, loss = 83.25628538\n",
      "Iteration 38614, loss = 83.24624115\n",
      "Iteration 38615, loss = 83.23619756\n",
      "Iteration 38616, loss = 83.22615461\n",
      "Iteration 38617, loss = 83.21611229\n",
      "Iteration 38618, loss = 83.20607060\n",
      "Iteration 38619, loss = 83.19602955\n",
      "Iteration 38620, loss = 83.18598913\n",
      "Iteration 38621, loss = 83.17594935\n",
      "Iteration 38622, loss = 83.16591020\n",
      "Iteration 38623, loss = 83.15587169\n",
      "Iteration 38624, loss = 83.14583381\n",
      "Iteration 38625, loss = 83.13579657\n",
      "Iteration 38626, loss = 83.12575996\n",
      "Iteration 38627, loss = 83.11572399\n",
      "Iteration 38628, loss = 83.10568865\n",
      "Iteration 38629, loss = 83.09565395\n",
      "Iteration 38630, loss = 83.08561988\n",
      "Iteration 38631, loss = 83.07558645\n",
      "Iteration 38632, loss = 83.06555365\n",
      "Iteration 38633, loss = 83.05552149\n",
      "Iteration 38634, loss = 83.04548996\n",
      "Iteration 38635, loss = 83.03545907\n",
      "Iteration 38636, loss = 83.02542882\n",
      "Iteration 38637, loss = 83.01539920\n",
      "Iteration 38638, loss = 83.00537021\n",
      "Iteration 38639, loss = 82.99534186\n",
      "Iteration 38640, loss = 82.98531414\n",
      "Iteration 38641, loss = 82.97528706\n",
      "Iteration 38642, loss = 82.96526062\n",
      "Iteration 38643, loss = 82.95523481\n",
      "Iteration 38644, loss = 82.94520964\n",
      "Iteration 38645, loss = 82.93518510\n",
      "Iteration 38646, loss = 82.92516120\n",
      "Iteration 38647, loss = 82.91513793\n",
      "Iteration 38648, loss = 82.90511530\n",
      "Iteration 38649, loss = 82.89509330\n",
      "Iteration 38650, loss = 82.88507194\n",
      "Iteration 38651, loss = 82.87505122\n",
      "Iteration 38652, loss = 82.86503113\n",
      "Iteration 38653, loss = 82.85501168\n",
      "Iteration 38654, loss = 82.84499286\n",
      "Iteration 38655, loss = 82.83497468\n",
      "Iteration 38656, loss = 82.82495713\n",
      "Iteration 38657, loss = 82.81494022\n",
      "Iteration 38658, loss = 82.80492394\n",
      "Iteration 38659, loss = 82.79490831\n",
      "Iteration 38660, loss = 82.78489330\n",
      "Iteration 38661, loss = 82.77487894\n",
      "Iteration 38662, loss = 82.76486520\n",
      "Iteration 38663, loss = 82.75485211\n",
      "Iteration 38664, loss = 82.74483965\n",
      "Iteration 38665, loss = 82.73482783\n",
      "Iteration 38666, loss = 82.72481664\n",
      "Iteration 38667, loss = 82.71480609\n",
      "Iteration 38668, loss = 82.70479617\n",
      "Iteration 38669, loss = 82.69478689\n",
      "Iteration 38670, loss = 82.68477825\n",
      "Iteration 38671, loss = 82.67477024\n",
      "Iteration 38672, loss = 82.66476287\n",
      "Iteration 38673, loss = 82.65475614\n",
      "Iteration 38674, loss = 82.64475004\n",
      "Iteration 38675, loss = 82.63474457\n",
      "Iteration 38676, loss = 82.62473975\n",
      "Iteration 38677, loss = 82.61473556\n",
      "Iteration 38678, loss = 82.60473200\n",
      "Iteration 38679, loss = 82.59472909\n",
      "Iteration 38680, loss = 82.58472681\n",
      "Iteration 38681, loss = 82.57472516\n",
      "Iteration 38682, loss = 82.56472415\n",
      "Iteration 38683, loss = 82.55472378\n",
      "Iteration 38684, loss = 82.54472405\n",
      "Iteration 38685, loss = 82.53472495\n",
      "Iteration 38686, loss = 82.52472649\n",
      "Iteration 38687, loss = 82.51472867\n",
      "Iteration 38688, loss = 82.50473148\n",
      "Iteration 38689, loss = 82.49473494\n",
      "Iteration 38690, loss = 82.48473903\n",
      "Iteration 38691, loss = 82.47474377\n",
      "Iteration 38692, loss = 82.46474916\n",
      "Iteration 38693, loss = 82.45475519\n",
      "Iteration 38694, loss = 82.44476190\n",
      "Iteration 38695, loss = 82.43476928\n",
      "Iteration 38696, loss = 82.42477736\n",
      "Iteration 38697, loss = 82.41478618\n",
      "Iteration 38698, loss = 82.40479579\n",
      "Iteration 38699, loss = 82.39480621\n",
      "Iteration 38700, loss = 82.38481748\n",
      "Iteration 38701, loss = 82.37482948\n",
      "Iteration 38702, loss = 82.36484198\n",
      "Iteration 38703, loss = 82.35485447\n",
      "Iteration 38704, loss = 82.34486667\n",
      "Iteration 38705, loss = 82.33487874\n",
      "Iteration 38706, loss = 82.32489154\n",
      "Iteration 38707, loss = 82.31490588\n",
      "Iteration 38708, loss = 82.30492188\n",
      "Iteration 38709, loss = 82.29493894\n",
      "Iteration 38710, loss = 82.28495626\n",
      "Iteration 38711, loss = 82.27497344\n",
      "Iteration 38712, loss = 82.26499073\n",
      "Iteration 38713, loss = 82.25500883\n",
      "Iteration 38714, loss = 82.24502818\n",
      "Iteration 38715, loss = 82.23504863\n",
      "Iteration 38716, loss = 82.22506966\n",
      "Iteration 38717, loss = 82.21509090\n",
      "Iteration 38718, loss = 82.20511242\n",
      "Iteration 38719, loss = 82.19513461\n",
      "Iteration 38720, loss = 82.18515777\n",
      "Iteration 38721, loss = 82.17518184\n",
      "Iteration 38722, loss = 82.16520653\n",
      "Iteration 38723, loss = 82.15523161\n",
      "Iteration 38724, loss = 82.14525713\n",
      "Iteration 38725, loss = 82.13528333\n",
      "Iteration 38726, loss = 82.12531035\n",
      "Iteration 38727, loss = 82.11533814\n",
      "Iteration 38728, loss = 82.10536655\n",
      "Iteration 38729, loss = 82.09539545\n",
      "Iteration 38730, loss = 82.08542490\n",
      "Iteration 38731, loss = 82.07545502\n",
      "Iteration 38732, loss = 82.06548588\n",
      "Iteration 38733, loss = 82.05551745\n",
      "Iteration 38734, loss = 82.04554962\n",
      "Iteration 38735, loss = 82.03558236\n",
      "Iteration 38736, loss = 82.02561569\n",
      "Iteration 38737, loss = 82.01564969\n",
      "Iteration 38738, loss = 82.00568438\n",
      "Iteration 38739, loss = 81.99571973\n",
      "Iteration 38740, loss = 81.98575571\n",
      "Iteration 38741, loss = 81.97579229\n",
      "Iteration 38742, loss = 81.96582948\n",
      "Iteration 38743, loss = 81.95586733\n",
      "Iteration 38744, loss = 81.94590584\n",
      "Iteration 38745, loss = 81.93594500\n",
      "Iteration 38746, loss = 81.92598480\n",
      "Iteration 38747, loss = 81.91602521\n",
      "Iteration 38748, loss = 81.90606625\n",
      "Iteration 38749, loss = 81.89610794\n",
      "Iteration 38750, loss = 81.88615027\n",
      "Iteration 38751, loss = 81.87619326\n",
      "Iteration 38752, loss = 81.86623688\n",
      "Iteration 38753, loss = 81.85628113\n",
      "Iteration 38754, loss = 81.84632601\n",
      "Iteration 38755, loss = 81.83637153\n",
      "Iteration 38756, loss = 81.82641769\n",
      "Iteration 38757, loss = 81.81646450\n",
      "Iteration 38758, loss = 81.80651195\n",
      "Iteration 38759, loss = 81.79656003\n",
      "Iteration 38760, loss = 81.78660875\n",
      "Iteration 38761, loss = 81.77665810\n",
      "Iteration 38762, loss = 81.76670810\n",
      "Iteration 38763, loss = 81.75675874\n",
      "Iteration 38764, loss = 81.74681002\n",
      "Iteration 38765, loss = 81.73686193\n",
      "Iteration 38766, loss = 81.72691448\n",
      "Iteration 38767, loss = 81.71696767\n",
      "Iteration 38768, loss = 81.70702150\n",
      "Iteration 38769, loss = 81.69707597\n",
      "Iteration 38770, loss = 81.68713108\n",
      "Iteration 38771, loss = 81.67718683\n",
      "Iteration 38772, loss = 81.66724321\n",
      "Iteration 38773, loss = 81.65730023\n",
      "Iteration 38774, loss = 81.64735790\n",
      "Iteration 38775, loss = 81.63741620\n",
      "Iteration 38776, loss = 81.62747514\n",
      "Iteration 38777, loss = 81.61753472\n",
      "Iteration 38778, loss = 81.60759494\n",
      "Iteration 38779, loss = 81.59765580\n",
      "Iteration 38780, loss = 81.58771730\n",
      "Iteration 38781, loss = 81.57777944\n",
      "Iteration 38782, loss = 81.56784221\n",
      "Iteration 38783, loss = 81.55790563\n",
      "Iteration 38784, loss = 81.54796969\n",
      "Iteration 38785, loss = 81.53803438\n",
      "Iteration 38786, loss = 81.52809972\n",
      "Iteration 38787, loss = 81.51816569\n",
      "Iteration 38788, loss = 81.50823230\n",
      "Iteration 38789, loss = 81.49829955\n",
      "Iteration 38790, loss = 81.48836745\n",
      "Iteration 38791, loss = 81.47843598\n",
      "Iteration 38792, loss = 81.46850515\n",
      "Iteration 38793, loss = 81.45857496\n",
      "Iteration 38794, loss = 81.44864541\n",
      "Iteration 38795, loss = 81.43871650\n",
      "Iteration 38796, loss = 81.42878823\n",
      "Iteration 38797, loss = 81.41886060\n",
      "Iteration 38798, loss = 81.40893361\n",
      "Iteration 38799, loss = 81.39900726\n",
      "Iteration 38800, loss = 81.38908154\n",
      "Iteration 38801, loss = 81.37915647\n",
      "Iteration 38802, loss = 81.36923204\n",
      "Iteration 38803, loss = 81.35930825\n",
      "Iteration 38804, loss = 81.34938510\n",
      "Iteration 38805, loss = 81.33946258\n",
      "Iteration 38806, loss = 81.32954071\n",
      "Iteration 38807, loss = 81.31961948\n",
      "Iteration 38808, loss = 81.30969889\n",
      "Iteration 38809, loss = 81.29977893\n",
      "Iteration 38810, loss = 81.28985962\n",
      "Iteration 38811, loss = 81.27994095\n",
      "Iteration 38812, loss = 81.27002292\n",
      "Iteration 38813, loss = 81.26010553\n",
      "Iteration 38814, loss = 81.25018878\n",
      "Iteration 38815, loss = 81.24027267\n",
      "Iteration 38816, loss = 81.23035719\n",
      "Iteration 38817, loss = 81.22044236\n",
      "Iteration 38818, loss = 81.21052817\n",
      "Iteration 38819, loss = 81.20061462\n",
      "Iteration 38820, loss = 81.19070171\n",
      "Iteration 38821, loss = 81.18078945\n",
      "Iteration 38822, loss = 81.17087782\n",
      "Iteration 38823, loss = 81.16096683\n",
      "Iteration 38824, loss = 81.15105648\n",
      "Iteration 38825, loss = 81.14114677\n",
      "Iteration 38826, loss = 81.13123771\n",
      "Iteration 38827, loss = 81.12132928\n",
      "Iteration 38828, loss = 81.11142150\n",
      "Iteration 38829, loss = 81.10151435\n",
      "Iteration 38830, loss = 81.09160785\n",
      "Iteration 38831, loss = 81.08170199\n",
      "Iteration 38832, loss = 81.07179676\n",
      "Iteration 38833, loss = 81.06189218\n",
      "Iteration 38834, loss = 81.05198824\n",
      "Iteration 38835, loss = 81.04208494\n",
      "Iteration 38836, loss = 81.03218228\n",
      "Iteration 38837, loss = 81.02228026\n",
      "Iteration 38838, loss = 81.01237889\n",
      "Iteration 38839, loss = 81.00247815\n",
      "Iteration 38840, loss = 80.99257806\n",
      "Iteration 38841, loss = 80.98267860\n",
      "Iteration 38842, loss = 80.97277979\n",
      "Iteration 38843, loss = 80.96288162\n",
      "Iteration 38844, loss = 80.95298409\n",
      "Iteration 38845, loss = 80.94308720\n",
      "Iteration 38846, loss = 80.93319095\n",
      "Iteration 38847, loss = 80.92329534\n",
      "Iteration 38848, loss = 80.91340038\n",
      "Iteration 38849, loss = 80.90350605\n",
      "Iteration 38850, loss = 80.89361237\n",
      "Iteration 38851, loss = 80.88371933\n",
      "Iteration 38852, loss = 80.87382693\n",
      "Iteration 38853, loss = 80.86393518\n",
      "Iteration 38854, loss = 80.85404406\n",
      "Iteration 38855, loss = 80.84415360\n",
      "Iteration 38856, loss = 80.83426378\n",
      "Iteration 38857, loss = 80.82437462\n",
      "Iteration 38858, loss = 80.81448613\n",
      "Iteration 38859, loss = 80.80459831\n",
      "Iteration 38860, loss = 80.79471122\n",
      "Iteration 38861, loss = 80.78482490\n",
      "Iteration 38862, loss = 80.77493946\n",
      "Iteration 38863, loss = 80.76505509\n",
      "Iteration 38864, loss = 80.75517213\n",
      "Iteration 38865, loss = 80.74529120\n",
      "Iteration 38866, loss = 80.73541335\n",
      "Iteration 38867, loss = 80.72554036\n",
      "Iteration 38868, loss = 80.71567479\n",
      "Iteration 38869, loss = 80.70581977\n",
      "Iteration 38870, loss = 80.69597584\n",
      "Iteration 38871, loss = 80.68613599\n",
      "Iteration 38872, loss = 80.67627647\n",
      "Iteration 38873, loss = 80.66637137\n",
      "Iteration 38874, loss = 80.65642412\n",
      "Iteration 38875, loss = 80.64648806\n",
      "Iteration 38876, loss = 80.63660850\n",
      "Iteration 38877, loss = 80.62677194\n",
      "Iteration 38878, loss = 80.61692532\n",
      "Iteration 38879, loss = 80.60703335\n",
      "Iteration 38880, loss = 80.59711782\n",
      "Iteration 38881, loss = 80.58722738\n",
      "Iteration 38882, loss = 80.57737402\n",
      "Iteration 38883, loss = 80.56752316\n",
      "Iteration 38884, loss = 80.55764387\n",
      "Iteration 38885, loss = 80.54774809\n",
      "Iteration 38886, loss = 80.53786866\n",
      "Iteration 38887, loss = 80.52801217\n",
      "Iteration 38888, loss = 80.51815445\n",
      "Iteration 38889, loss = 80.50827829\n",
      "Iteration 38890, loss = 80.49839585\n",
      "Iteration 38891, loss = 80.48852679\n",
      "Iteration 38892, loss = 80.47866975\n",
      "Iteration 38893, loss = 80.46880804\n",
      "Iteration 38894, loss = 80.45893552\n",
      "Iteration 38895, loss = 80.44906331\n",
      "Iteration 38896, loss = 80.43920104\n",
      "Iteration 38897, loss = 80.42934361\n",
      "Iteration 38898, loss = 80.41948108\n",
      "Iteration 38899, loss = 80.40961350\n",
      "Iteration 38900, loss = 80.39974898\n",
      "Iteration 38901, loss = 80.38989077\n",
      "Iteration 38902, loss = 80.38003361\n",
      "Iteration 38903, loss = 80.37017272\n",
      "Iteration 38904, loss = 80.36031038\n",
      "Iteration 38905, loss = 80.35045143\n",
      "Iteration 38906, loss = 80.34059596\n",
      "Iteration 38907, loss = 80.33074015\n",
      "Iteration 38908, loss = 80.32088229\n",
      "Iteration 38909, loss = 80.31102476\n",
      "Iteration 38910, loss = 80.30116995\n",
      "Iteration 38911, loss = 80.29131694\n",
      "Iteration 38912, loss = 80.28146341\n",
      "Iteration 38913, loss = 80.27160911\n",
      "Iteration 38914, loss = 80.26175578\n",
      "Iteration 38915, loss = 80.25190439\n",
      "Iteration 38916, loss = 80.24205399\n",
      "Iteration 38917, loss = 80.23220333\n",
      "Iteration 38918, loss = 80.22235264\n",
      "Iteration 38919, loss = 80.21250303\n",
      "Iteration 38920, loss = 80.20265481\n",
      "Iteration 38921, loss = 80.19280724\n",
      "Iteration 38922, loss = 80.18295972\n",
      "Iteration 38923, loss = 80.17311257\n",
      "Iteration 38924, loss = 80.16326640\n",
      "Iteration 38925, loss = 80.15342128\n",
      "Iteration 38926, loss = 80.14357672\n",
      "Iteration 38927, loss = 80.13373245\n",
      "Iteration 38928, loss = 80.12388871\n",
      "Iteration 38929, loss = 80.11404585\n",
      "Iteration 38930, loss = 80.10420385\n",
      "Iteration 38931, loss = 80.09436241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38932, loss = 80.08452140\n",
      "Iteration 38933, loss = 80.07468100\n",
      "Iteration 38934, loss = 80.06484138\n",
      "Iteration 38935, loss = 80.05500253\n",
      "Iteration 38936, loss = 80.04516427\n",
      "Iteration 38937, loss = 80.03532652\n",
      "Iteration 38938, loss = 80.02548940\n",
      "Iteration 38939, loss = 80.01565301\n",
      "Iteration 38940, loss = 80.00581734\n",
      "Iteration 38941, loss = 79.99598227\n",
      "Iteration 38942, loss = 79.98614778\n",
      "Iteration 38943, loss = 79.97631392\n",
      "Iteration 38944, loss = 79.96648075\n",
      "Iteration 38945, loss = 79.95664826\n",
      "Iteration 38946, loss = 79.94681641\n",
      "Iteration 38947, loss = 79.93698516\n",
      "Iteration 38948, loss = 79.92715454\n",
      "Iteration 38949, loss = 79.91732459\n",
      "Iteration 38950, loss = 79.90749531\n",
      "Iteration 38951, loss = 79.89766667\n",
      "Iteration 38952, loss = 79.88783865\n",
      "Iteration 38953, loss = 79.87801127\n",
      "Iteration 38954, loss = 79.86818454\n",
      "Iteration 38955, loss = 79.85835848\n",
      "Iteration 38956, loss = 79.84853306\n",
      "Iteration 38957, loss = 79.83870827\n",
      "Iteration 38958, loss = 79.82888412\n",
      "Iteration 38959, loss = 79.81906061\n",
      "Iteration 38960, loss = 79.80923776\n",
      "Iteration 38961, loss = 79.79941556\n",
      "Iteration 38962, loss = 79.78959400\n",
      "Iteration 38963, loss = 79.77977308\n",
      "Iteration 38964, loss = 79.76995280\n",
      "Iteration 38965, loss = 79.76013317\n",
      "Iteration 38966, loss = 79.75031420\n",
      "Iteration 38967, loss = 79.74049586\n",
      "Iteration 38968, loss = 79.73067817\n",
      "Iteration 38969, loss = 79.72086112\n",
      "Iteration 38970, loss = 79.71104472\n",
      "Iteration 38971, loss = 79.70122898\n",
      "Iteration 38972, loss = 79.69141388\n",
      "Iteration 38973, loss = 79.68159943\n",
      "Iteration 38974, loss = 79.67178562\n",
      "Iteration 38975, loss = 79.66197248\n",
      "Iteration 38976, loss = 79.65216000\n",
      "Iteration 38977, loss = 79.64234818\n",
      "Iteration 38978, loss = 79.63253704\n",
      "Iteration 38979, loss = 79.62272659\n",
      "Iteration 38980, loss = 79.61291683\n",
      "Iteration 38981, loss = 79.60310778\n",
      "Iteration 38982, loss = 79.59329945\n",
      "Iteration 38983, loss = 79.58349181\n",
      "Iteration 38984, loss = 79.57368481\n",
      "Iteration 38985, loss = 79.56387835\n",
      "Iteration 38986, loss = 79.55407231\n",
      "Iteration 38987, loss = 79.54426657\n",
      "Iteration 38988, loss = 79.53446121\n",
      "Iteration 38989, loss = 79.52465638\n",
      "Iteration 38990, loss = 79.51485236\n",
      "Iteration 38991, loss = 79.50504931\n",
      "Iteration 38992, loss = 79.49524723\n",
      "Iteration 38993, loss = 79.48544598\n",
      "Iteration 38994, loss = 79.47564535\n",
      "Iteration 38995, loss = 79.46584518\n",
      "Iteration 38996, loss = 79.45604543\n",
      "Iteration 38997, loss = 79.44624618\n",
      "Iteration 38998, loss = 79.43644758\n",
      "Iteration 38999, loss = 79.42664977\n",
      "Iteration 39000, loss = 79.41685278\n",
      "Iteration 39001, loss = 79.40705653\n",
      "Iteration 39002, loss = 79.39726091\n",
      "Iteration 39003, loss = 79.38746585\n",
      "Iteration 39004, loss = 79.37767133\n",
      "Iteration 39005, loss = 79.36787740\n",
      "Iteration 39006, loss = 79.35808413\n",
      "Iteration 39007, loss = 79.34829158\n",
      "Iteration 39008, loss = 79.33849974\n",
      "Iteration 39009, loss = 79.32870859\n",
      "Iteration 39010, loss = 79.31891807\n",
      "Iteration 39011, loss = 79.30912814\n",
      "Iteration 39012, loss = 79.29933882\n",
      "Iteration 39013, loss = 79.28955013\n",
      "Iteration 39014, loss = 79.27976210\n",
      "Iteration 39015, loss = 79.26997475\n",
      "Iteration 39016, loss = 79.26018807\n",
      "Iteration 39017, loss = 79.25040205\n",
      "Iteration 39018, loss = 79.24061667\n",
      "Iteration 39019, loss = 79.23083191\n",
      "Iteration 39020, loss = 79.22104778\n",
      "Iteration 39021, loss = 79.21126430\n",
      "Iteration 39022, loss = 79.20148146\n",
      "Iteration 39023, loss = 79.19169929\n",
      "Iteration 39024, loss = 79.18191777\n",
      "Iteration 39025, loss = 79.17213691\n",
      "Iteration 39026, loss = 79.16235669\n",
      "Iteration 39027, loss = 79.15257711\n",
      "Iteration 39028, loss = 79.14279817\n",
      "Iteration 39029, loss = 79.13301987\n",
      "Iteration 39030, loss = 79.12324222\n",
      "Iteration 39031, loss = 79.11346522\n",
      "Iteration 39032, loss = 79.10368888\n",
      "Iteration 39033, loss = 79.09391318\n",
      "Iteration 39034, loss = 79.08413814\n",
      "Iteration 39035, loss = 79.07436373\n",
      "Iteration 39036, loss = 79.06458997\n",
      "Iteration 39037, loss = 79.05481685\n",
      "Iteration 39038, loss = 79.04504439\n",
      "Iteration 39039, loss = 79.03527257\n",
      "Iteration 39040, loss = 79.02550139\n",
      "Iteration 39041, loss = 79.01573087\n",
      "Iteration 39042, loss = 79.00596100\n",
      "Iteration 39043, loss = 78.99619177\n",
      "Iteration 39044, loss = 78.98642319\n",
      "Iteration 39045, loss = 78.97665526\n",
      "Iteration 39046, loss = 78.96688797\n",
      "Iteration 39047, loss = 78.95712133\n",
      "Iteration 39048, loss = 78.94735534\n",
      "Iteration 39049, loss = 78.93758999\n",
      "Iteration 39050, loss = 78.92782530\n",
      "Iteration 39051, loss = 78.91806125\n",
      "Iteration 39052, loss = 78.90829785\n",
      "Iteration 39053, loss = 78.89853510\n",
      "Iteration 39054, loss = 78.88877299\n",
      "Iteration 39055, loss = 78.87901153\n",
      "Iteration 39056, loss = 78.86925072\n",
      "Iteration 39057, loss = 78.85949056\n",
      "Iteration 39058, loss = 78.84973104\n",
      "Iteration 39059, loss = 78.83997218\n",
      "Iteration 39060, loss = 78.83021396\n",
      "Iteration 39061, loss = 78.82045639\n",
      "Iteration 39062, loss = 78.81069946\n",
      "Iteration 39063, loss = 78.80094319\n",
      "Iteration 39064, loss = 78.79118756\n",
      "Iteration 39065, loss = 78.78143258\n",
      "Iteration 39066, loss = 78.77167825\n",
      "Iteration 39067, loss = 78.76192457\n",
      "Iteration 39068, loss = 78.75217153\n",
      "Iteration 39069, loss = 78.74241914\n",
      "Iteration 39070, loss = 78.73266741\n",
      "Iteration 39071, loss = 78.72291632\n",
      "Iteration 39072, loss = 78.71316587\n",
      "Iteration 39073, loss = 78.70341608\n",
      "Iteration 39074, loss = 78.69366693\n",
      "Iteration 39075, loss = 78.68391843\n",
      "Iteration 39076, loss = 78.67417058\n",
      "Iteration 39077, loss = 78.66442338\n",
      "Iteration 39078, loss = 78.65467683\n",
      "Iteration 39079, loss = 78.64493093\n",
      "Iteration 39080, loss = 78.63518567\n",
      "Iteration 39081, loss = 78.62544106\n",
      "Iteration 39082, loss = 78.61569710\n",
      "Iteration 39083, loss = 78.60595379\n",
      "Iteration 39084, loss = 78.59621113\n",
      "Iteration 39085, loss = 78.58646912\n",
      "Iteration 39086, loss = 78.57672775\n",
      "Iteration 39087, loss = 78.56698704\n",
      "Iteration 39088, loss = 78.55724697\n",
      "Iteration 39089, loss = 78.54750755\n",
      "Iteration 39090, loss = 78.53776878\n",
      "Iteration 39091, loss = 78.52803066\n",
      "Iteration 39092, loss = 78.51829319\n",
      "Iteration 39093, loss = 78.50855637\n",
      "Iteration 39094, loss = 78.49882019\n",
      "Iteration 39095, loss = 78.48908467\n",
      "Iteration 39096, loss = 78.47934979\n",
      "Iteration 39097, loss = 78.46961556\n",
      "Iteration 39098, loss = 78.45988198\n",
      "Iteration 39099, loss = 78.45014905\n",
      "Iteration 39100, loss = 78.44041677\n",
      "Iteration 39101, loss = 78.43068514\n",
      "Iteration 39102, loss = 78.42095416\n",
      "Iteration 39103, loss = 78.41122383\n",
      "Iteration 39104, loss = 78.40149414\n",
      "Iteration 39105, loss = 78.39176511\n",
      "Iteration 39106, loss = 78.38203672\n",
      "Iteration 39107, loss = 78.37230898\n",
      "Iteration 39108, loss = 78.36258190\n",
      "Iteration 39109, loss = 78.35285546\n",
      "Iteration 39110, loss = 78.34312967\n",
      "Iteration 39111, loss = 78.33340453\n",
      "Iteration 39112, loss = 78.32368004\n",
      "Iteration 39113, loss = 78.31395620\n",
      "Iteration 39114, loss = 78.30423301\n",
      "Iteration 39115, loss = 78.29451047\n",
      "Iteration 39116, loss = 78.28478858\n",
      "Iteration 39117, loss = 78.27506733\n",
      "Iteration 39118, loss = 78.26534674\n",
      "Iteration 39119, loss = 78.25562680\n",
      "Iteration 39120, loss = 78.24590750\n",
      "Iteration 39121, loss = 78.23618886\n",
      "Iteration 39122, loss = 78.22647086\n",
      "Iteration 39123, loss = 78.21675352\n",
      "Iteration 39124, loss = 78.20703682\n",
      "Iteration 39125, loss = 78.19732078\n",
      "Iteration 39126, loss = 78.18760538\n",
      "Iteration 39127, loss = 78.17789064\n",
      "Iteration 39128, loss = 78.16817654\n",
      "Iteration 39129, loss = 78.15846310\n",
      "Iteration 39130, loss = 78.14875030\n",
      "Iteration 39131, loss = 78.13903815\n",
      "Iteration 39132, loss = 78.12932666\n",
      "Iteration 39133, loss = 78.11961581\n",
      "Iteration 39134, loss = 78.10990562\n",
      "Iteration 39135, loss = 78.10019607\n",
      "Iteration 39136, loss = 78.09048717\n",
      "Iteration 39137, loss = 78.08077893\n",
      "Iteration 39138, loss = 78.07107133\n",
      "Iteration 39139, loss = 78.06136439\n",
      "Iteration 39140, loss = 78.05165809\n",
      "Iteration 39141, loss = 78.04195245\n",
      "Iteration 39142, loss = 78.03224745\n",
      "Iteration 39143, loss = 78.02254311\n",
      "Iteration 39144, loss = 78.01283941\n",
      "Iteration 39145, loss = 78.00313637\n",
      "Iteration 39146, loss = 77.99343397\n",
      "Iteration 39147, loss = 77.98373223\n",
      "Iteration 39148, loss = 77.97403114\n",
      "Iteration 39149, loss = 77.96433070\n",
      "Iteration 39150, loss = 77.95463090\n",
      "Iteration 39151, loss = 77.94493176\n",
      "Iteration 39152, loss = 77.93523327\n",
      "Iteration 39153, loss = 77.92553543\n",
      "Iteration 39154, loss = 77.91583824\n",
      "Iteration 39155, loss = 77.90614170\n",
      "Iteration 39156, loss = 77.89644581\n",
      "Iteration 39157, loss = 77.88675058\n",
      "Iteration 39158, loss = 77.87705599\n",
      "Iteration 39159, loss = 77.86736205\n",
      "Iteration 39160, loss = 77.85766877\n",
      "Iteration 39161, loss = 77.84797613\n",
      "Iteration 39162, loss = 77.83828415\n",
      "Iteration 39163, loss = 77.82859281\n",
      "Iteration 39164, loss = 77.81890213\n",
      "Iteration 39165, loss = 77.80921210\n",
      "Iteration 39166, loss = 77.79952272\n",
      "Iteration 39167, loss = 77.78983399\n",
      "Iteration 39168, loss = 77.78014591\n",
      "Iteration 39169, loss = 77.77045848\n",
      "Iteration 39170, loss = 77.76077171\n",
      "Iteration 39171, loss = 77.75108559\n",
      "Iteration 39172, loss = 77.74140011\n",
      "Iteration 39173, loss = 77.73171530\n",
      "Iteration 39174, loss = 77.72203113\n",
      "Iteration 39175, loss = 77.71234763\n",
      "Iteration 39176, loss = 77.70266478\n",
      "Iteration 39177, loss = 77.69298259\n",
      "Iteration 39178, loss = 77.68330108\n",
      "Iteration 39179, loss = 77.67362024\n",
      "Iteration 39180, loss = 77.66394011\n",
      "Iteration 39181, loss = 77.65426069\n",
      "Iteration 39182, loss = 77.64458201\n",
      "Iteration 39183, loss = 77.63490412\n",
      "Iteration 39184, loss = 77.62522701\n",
      "Iteration 39185, loss = 77.61555068\n",
      "Iteration 39186, loss = 77.60587499\n",
      "Iteration 39187, loss = 77.59619971\n",
      "Iteration 39188, loss = 77.58652453\n",
      "Iteration 39189, loss = 77.57684941\n",
      "Iteration 39190, loss = 77.56717467\n",
      "Iteration 39191, loss = 77.55750103\n",
      "Iteration 39192, loss = 77.54782904\n",
      "Iteration 39193, loss = 77.53815890\n",
      "Iteration 39194, loss = 77.52849056\n",
      "Iteration 39195, loss = 77.51882424\n",
      "Iteration 39196, loss = 77.50916090\n",
      "Iteration 39197, loss = 77.49950256\n",
      "Iteration 39198, loss = 77.48985226\n",
      "Iteration 39199, loss = 77.48021240\n",
      "Iteration 39200, loss = 77.47058203\n",
      "Iteration 39201, loss = 77.46094898\n",
      "Iteration 39202, loss = 77.45129061\n",
      "Iteration 39203, loss = 77.44158621\n",
      "Iteration 39204, loss = 77.43185518\n",
      "Iteration 39205, loss = 77.42214786\n",
      "Iteration 39206, loss = 77.41249372\n",
      "Iteration 39207, loss = 77.40286952\n",
      "Iteration 39208, loss = 77.39322764\n",
      "Iteration 39209, loss = 77.38354553\n",
      "Iteration 39210, loss = 77.37384794\n",
      "Iteration 39211, loss = 77.36417621\n",
      "Iteration 39212, loss = 77.35453589\n",
      "Iteration 39213, loss = 77.34489569\n",
      "Iteration 39214, loss = 77.33523067\n",
      "Iteration 39215, loss = 77.32555130\n",
      "Iteration 39216, loss = 77.31588574\n",
      "Iteration 39217, loss = 77.30624063\n",
      "Iteration 39218, loss = 77.29659636\n",
      "Iteration 39219, loss = 77.28693687\n",
      "Iteration 39220, loss = 77.27726965\n",
      "Iteration 39221, loss = 77.26761214\n",
      "Iteration 39222, loss = 77.25796674\n",
      "Iteration 39223, loss = 77.24832042\n",
      "Iteration 39224, loss = 77.23866475\n",
      "Iteration 39225, loss = 77.22900620\n",
      "Iteration 39226, loss = 77.21935490\n",
      "Iteration 39227, loss = 77.20971037\n",
      "Iteration 39228, loss = 77.20006416\n",
      "Iteration 39229, loss = 77.19041256\n",
      "Iteration 39230, loss = 77.18076066\n",
      "Iteration 39231, loss = 77.17111392\n",
      "Iteration 39232, loss = 77.16147082\n",
      "Iteration 39233, loss = 77.15182621\n",
      "Iteration 39234, loss = 77.14217883\n",
      "Iteration 39235, loss = 77.13253223\n",
      "Iteration 39236, loss = 77.12288913\n",
      "Iteration 39237, loss = 77.11324801\n",
      "Iteration 39238, loss = 77.10360591\n",
      "Iteration 39239, loss = 77.09396262\n",
      "Iteration 39240, loss = 77.08432040\n",
      "Iteration 39241, loss = 77.07468055\n",
      "Iteration 39242, loss = 77.06504190\n",
      "Iteration 39243, loss = 77.05540280\n",
      "Iteration 39244, loss = 77.04576337\n",
      "Iteration 39245, loss = 77.03612497\n",
      "Iteration 39246, loss = 77.02648825\n",
      "Iteration 39247, loss = 77.01685241\n",
      "Iteration 39248, loss = 77.00721654\n",
      "Iteration 39249, loss = 76.99758076\n",
      "Iteration 39250, loss = 76.98794591\n",
      "Iteration 39251, loss = 76.97831230\n",
      "Iteration 39252, loss = 76.96867947\n",
      "Iteration 39253, loss = 76.95904688\n",
      "Iteration 39254, loss = 76.94941462\n",
      "Iteration 39255, loss = 76.93978317\n",
      "Iteration 39256, loss = 76.93015273\n",
      "Iteration 39257, loss = 76.92052301\n",
      "Iteration 39258, loss = 76.91089371\n",
      "Iteration 39259, loss = 76.90126487\n",
      "Iteration 39260, loss = 76.89163676\n",
      "Iteration 39261, loss = 76.88200952\n",
      "Iteration 39262, loss = 76.87238298\n",
      "Iteration 39263, loss = 76.86275697\n",
      "Iteration 39264, loss = 76.85313149\n",
      "Iteration 39265, loss = 76.84350669\n",
      "Iteration 39266, loss = 76.83388266\n",
      "Iteration 39267, loss = 76.82425934\n",
      "Iteration 39268, loss = 76.81463661\n",
      "Iteration 39269, loss = 76.80501446\n",
      "Iteration 39270, loss = 76.79539295\n",
      "Iteration 39271, loss = 76.78577217\n",
      "Iteration 39272, loss = 76.77615208\n",
      "Iteration 39273, loss = 76.76653262\n",
      "Iteration 39274, loss = 76.75691377\n",
      "Iteration 39275, loss = 76.74729555\n",
      "Iteration 39276, loss = 76.73767802\n",
      "Iteration 39277, loss = 76.72806118\n",
      "Iteration 39278, loss = 76.71844499\n",
      "Iteration 39279, loss = 76.70882942\n",
      "Iteration 39280, loss = 76.69921449\n",
      "Iteration 39281, loss = 76.68960022\n",
      "Iteration 39282, loss = 76.67998663\n",
      "Iteration 39283, loss = 76.67037370\n",
      "Iteration 39284, loss = 76.66076142\n",
      "Iteration 39285, loss = 76.65114977\n",
      "Iteration 39286, loss = 76.64153877\n",
      "Iteration 39287, loss = 76.63192844\n",
      "Iteration 39288, loss = 76.62231878\n",
      "Iteration 39289, loss = 76.61270976\n",
      "Iteration 39290, loss = 76.60310139\n",
      "Iteration 39291, loss = 76.59349367\n",
      "Iteration 39292, loss = 76.58388660\n",
      "Iteration 39293, loss = 76.57428020\n",
      "Iteration 39294, loss = 76.56467445\n",
      "Iteration 39295, loss = 76.55506936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39296, loss = 76.54546491\n",
      "Iteration 39297, loss = 76.53586112\n",
      "Iteration 39298, loss = 76.52625798\n",
      "Iteration 39299, loss = 76.51665550\n",
      "Iteration 39300, loss = 76.50705368\n",
      "Iteration 39301, loss = 76.49745250\n",
      "Iteration 39302, loss = 76.48785198\n",
      "Iteration 39303, loss = 76.47825211\n",
      "Iteration 39304, loss = 76.46865290\n",
      "Iteration 39305, loss = 76.45905435\n",
      "Iteration 39306, loss = 76.44945645\n",
      "Iteration 39307, loss = 76.43985920\n",
      "Iteration 39308, loss = 76.43026260\n",
      "Iteration 39309, loss = 76.42066666\n",
      "Iteration 39310, loss = 76.41107138\n",
      "Iteration 39311, loss = 76.40147675\n",
      "Iteration 39312, loss = 76.39188277\n",
      "Iteration 39313, loss = 76.38228945\n",
      "Iteration 39314, loss = 76.37269678\n",
      "Iteration 39315, loss = 76.36310477\n",
      "Iteration 39316, loss = 76.35351341\n",
      "Iteration 39317, loss = 76.34392271\n",
      "Iteration 39318, loss = 76.33433266\n",
      "Iteration 39319, loss = 76.32474326\n",
      "Iteration 39320, loss = 76.31515452\n",
      "Iteration 39321, loss = 76.30556643\n",
      "Iteration 39322, loss = 76.29597900\n",
      "Iteration 39323, loss = 76.28639222\n",
      "Iteration 39324, loss = 76.27680610\n",
      "Iteration 39325, loss = 76.26722064\n",
      "Iteration 39326, loss = 76.25763582\n",
      "Iteration 39327, loss = 76.24805166\n",
      "Iteration 39328, loss = 76.23846816\n",
      "Iteration 39329, loss = 76.22888531\n",
      "Iteration 39330, loss = 76.21930312\n",
      "Iteration 39331, loss = 76.20972158\n",
      "Iteration 39332, loss = 76.20014069\n",
      "Iteration 39333, loss = 76.19056046\n",
      "Iteration 39334, loss = 76.18098089\n",
      "Iteration 39335, loss = 76.17140197\n",
      "Iteration 39336, loss = 76.16182370\n",
      "Iteration 39337, loss = 76.15224609\n",
      "Iteration 39338, loss = 76.14266914\n",
      "Iteration 39339, loss = 76.13309284\n",
      "Iteration 39340, loss = 76.12351719\n",
      "Iteration 39341, loss = 76.11394220\n",
      "Iteration 39342, loss = 76.10436787\n",
      "Iteration 39343, loss = 76.09479418\n",
      "Iteration 39344, loss = 76.08522116\n",
      "Iteration 39345, loss = 76.07564879\n",
      "Iteration 39346, loss = 76.06607707\n",
      "Iteration 39347, loss = 76.05650601\n",
      "Iteration 39348, loss = 76.04693561\n",
      "Iteration 39349, loss = 76.03736586\n",
      "Iteration 39350, loss = 76.02779676\n",
      "Iteration 39351, loss = 76.01822832\n",
      "Iteration 39352, loss = 76.00866054\n",
      "Iteration 39353, loss = 75.99909341\n",
      "Iteration 39354, loss = 75.98952694\n",
      "Iteration 39355, loss = 75.97996112\n",
      "Iteration 39356, loss = 75.97039596\n",
      "Iteration 39357, loss = 75.96083145\n",
      "Iteration 39358, loss = 75.95126760\n",
      "Iteration 39359, loss = 75.94170440\n",
      "Iteration 39360, loss = 75.93214186\n",
      "Iteration 39361, loss = 75.92257997\n",
      "Iteration 39362, loss = 75.91301874\n",
      "Iteration 39363, loss = 75.90345816\n",
      "Iteration 39364, loss = 75.89389824\n",
      "Iteration 39365, loss = 75.88433898\n",
      "Iteration 39366, loss = 75.87478037\n",
      "Iteration 39367, loss = 75.86522242\n",
      "Iteration 39368, loss = 75.85566512\n",
      "Iteration 39369, loss = 75.84610848\n",
      "Iteration 39370, loss = 75.83655249\n",
      "Iteration 39371, loss = 75.82699716\n",
      "Iteration 39372, loss = 75.81744248\n",
      "Iteration 39373, loss = 75.80788846\n",
      "Iteration 39374, loss = 75.79833510\n",
      "Iteration 39375, loss = 75.78878239\n",
      "Iteration 39376, loss = 75.77923034\n",
      "Iteration 39377, loss = 75.76967894\n",
      "Iteration 39378, loss = 75.76012820\n",
      "Iteration 39379, loss = 75.75057811\n",
      "Iteration 39380, loss = 75.74102868\n",
      "Iteration 39381, loss = 75.73147991\n",
      "Iteration 39382, loss = 75.72193179\n",
      "Iteration 39383, loss = 75.71238433\n",
      "Iteration 39384, loss = 75.70283752\n",
      "Iteration 39385, loss = 75.69329137\n",
      "Iteration 39386, loss = 75.68374588\n",
      "Iteration 39387, loss = 75.67420104\n",
      "Iteration 39388, loss = 75.66465686\n",
      "Iteration 39389, loss = 75.65511333\n",
      "Iteration 39390, loss = 75.64557046\n",
      "Iteration 39391, loss = 75.63602825\n",
      "Iteration 39392, loss = 75.62648669\n",
      "Iteration 39393, loss = 75.61694579\n",
      "Iteration 39394, loss = 75.60740554\n",
      "Iteration 39395, loss = 75.59786595\n",
      "Iteration 39396, loss = 75.58832702\n",
      "Iteration 39397, loss = 75.57878874\n",
      "Iteration 39398, loss = 75.56925112\n",
      "Iteration 39399, loss = 75.55971416\n",
      "Iteration 39400, loss = 75.55017785\n",
      "Iteration 39401, loss = 75.54064220\n",
      "Iteration 39402, loss = 75.53110720\n",
      "Iteration 39403, loss = 75.52157286\n",
      "Iteration 39404, loss = 75.51203918\n",
      "Iteration 39405, loss = 75.50250615\n",
      "Iteration 39406, loss = 75.49297378\n",
      "Iteration 39407, loss = 75.48344207\n",
      "Iteration 39408, loss = 75.47391101\n",
      "Iteration 39409, loss = 75.46438061\n",
      "Iteration 39410, loss = 75.45485086\n",
      "Iteration 39411, loss = 75.44532177\n",
      "Iteration 39412, loss = 75.43579334\n",
      "Iteration 39413, loss = 75.42626557\n",
      "Iteration 39414, loss = 75.41673845\n",
      "Iteration 39415, loss = 75.40721199\n",
      "Iteration 39416, loss = 75.39768618\n",
      "Iteration 39417, loss = 75.38816103\n",
      "Iteration 39418, loss = 75.37863654\n",
      "Iteration 39419, loss = 75.36911271\n",
      "Iteration 39420, loss = 75.35958953\n",
      "Iteration 39421, loss = 75.35006701\n",
      "Iteration 39422, loss = 75.34054514\n",
      "Iteration 39423, loss = 75.33102393\n",
      "Iteration 39424, loss = 75.32150338\n",
      "Iteration 39425, loss = 75.31198349\n",
      "Iteration 39426, loss = 75.30246425\n",
      "Iteration 39427, loss = 75.29294567\n",
      "Iteration 39428, loss = 75.28342774\n",
      "Iteration 39429, loss = 75.27391048\n",
      "Iteration 39430, loss = 75.26439387\n",
      "Iteration 39431, loss = 75.25487791\n",
      "Iteration 39432, loss = 75.24536262\n",
      "Iteration 39433, loss = 75.23584798\n",
      "Iteration 39434, loss = 75.22633400\n",
      "Iteration 39435, loss = 75.21682067\n",
      "Iteration 39436, loss = 75.20730801\n",
      "Iteration 39437, loss = 75.19779600\n",
      "Iteration 39438, loss = 75.18828464\n",
      "Iteration 39439, loss = 75.17877395\n",
      "Iteration 39440, loss = 75.16926391\n",
      "Iteration 39441, loss = 75.15975454\n",
      "Iteration 39442, loss = 75.15024582\n",
      "Iteration 39443, loss = 75.14073777\n",
      "Iteration 39444, loss = 75.13123039\n",
      "Iteration 39445, loss = 75.12172368\n",
      "Iteration 39446, loss = 75.11221766\n",
      "Iteration 39447, loss = 75.10271234\n",
      "Iteration 39448, loss = 75.09320774\n",
      "Iteration 39449, loss = 75.08370391\n",
      "Iteration 39450, loss = 75.07420090\n",
      "Iteration 39451, loss = 75.06469873\n",
      "Iteration 39452, loss = 75.05519742\n",
      "Iteration 39453, loss = 75.04569680\n",
      "Iteration 39454, loss = 75.03619657\n",
      "Iteration 39455, loss = 75.02669622\n",
      "Iteration 39456, loss = 75.01719558\n",
      "Iteration 39457, loss = 75.00769511\n",
      "Iteration 39458, loss = 74.99819578\n",
      "Iteration 39459, loss = 74.98869817\n",
      "Iteration 39460, loss = 74.97920203\n",
      "Iteration 39461, loss = 74.96970656\n",
      "Iteration 39462, loss = 74.96021107\n",
      "Iteration 39463, loss = 74.95071551\n",
      "Iteration 39464, loss = 74.94122047\n",
      "Iteration 39465, loss = 74.93172660\n",
      "Iteration 39466, loss = 74.92223399\n",
      "Iteration 39467, loss = 74.91274217\n",
      "Iteration 39468, loss = 74.90325064\n",
      "Iteration 39469, loss = 74.89375933\n",
      "Iteration 39470, loss = 74.88426861\n",
      "Iteration 39471, loss = 74.87477884\n",
      "Iteration 39472, loss = 74.86529007\n",
      "Iteration 39473, loss = 74.85580198\n",
      "Iteration 39474, loss = 74.84631432\n",
      "Iteration 39475, loss = 74.83682711\n",
      "Iteration 39476, loss = 74.82734057\n",
      "Iteration 39477, loss = 74.81785490\n",
      "Iteration 39478, loss = 74.80837006\n",
      "Iteration 39479, loss = 74.79888587\n",
      "Iteration 39480, loss = 74.78940224\n",
      "Iteration 39481, loss = 74.77991924\n",
      "Iteration 39482, loss = 74.77043703\n",
      "Iteration 39483, loss = 74.76095572\n",
      "Iteration 39484, loss = 74.75147533\n",
      "Iteration 39485, loss = 74.74199586\n",
      "Iteration 39486, loss = 74.73251740\n",
      "Iteration 39487, loss = 74.72304022\n",
      "Iteration 39488, loss = 74.71356466\n",
      "Iteration 39489, loss = 74.70409114\n",
      "Iteration 39490, loss = 74.69461998\n",
      "Iteration 39491, loss = 74.68515155\n",
      "Iteration 39492, loss = 74.67568571\n",
      "Iteration 39493, loss = 74.66622175\n",
      "Iteration 39494, loss = 74.65675704\n",
      "Iteration 39495, loss = 74.64728796\n",
      "Iteration 39496, loss = 74.63781005\n",
      "Iteration 39497, loss = 74.62832284\n",
      "Iteration 39498, loss = 74.61883080\n",
      "Iteration 39499, loss = 74.60934277\n",
      "Iteration 39500, loss = 74.59986547\n",
      "Iteration 39501, loss = 74.59039954\n",
      "Iteration 39502, loss = 74.58093994\n",
      "Iteration 39503, loss = 74.57147953\n",
      "Iteration 39504, loss = 74.56201317\n",
      "Iteration 39505, loss = 74.55254014\n",
      "Iteration 39506, loss = 74.54306447\n",
      "Iteration 39507, loss = 74.53359173\n",
      "Iteration 39508, loss = 74.52412527\n",
      "Iteration 39509, loss = 74.51466427\n",
      "Iteration 39510, loss = 74.50520508\n",
      "Iteration 39511, loss = 74.49574405\n",
      "Iteration 39512, loss = 74.48627978\n",
      "Iteration 39513, loss = 74.47681371\n",
      "Iteration 39514, loss = 74.46734866\n",
      "Iteration 39515, loss = 74.45788677\n",
      "Iteration 39516, loss = 74.44842812\n",
      "Iteration 39517, loss = 74.43897114\n",
      "Iteration 39518, loss = 74.42951392\n",
      "Iteration 39519, loss = 74.42005550\n",
      "Iteration 39520, loss = 74.41059634\n",
      "Iteration 39521, loss = 74.40113773\n",
      "Iteration 39522, loss = 74.39168082\n",
      "Iteration 39523, loss = 74.38222585\n",
      "Iteration 39524, loss = 74.37277224\n",
      "Iteration 39525, loss = 74.36331905\n",
      "Iteration 39526, loss = 74.35386571\n",
      "Iteration 39527, loss = 74.34441227\n",
      "Iteration 39528, loss = 74.33495925\n",
      "Iteration 39529, loss = 74.32550723\n",
      "Iteration 39530, loss = 74.31605646\n",
      "Iteration 39531, loss = 74.30660680\n",
      "Iteration 39532, loss = 74.29715786\n",
      "Iteration 39533, loss = 74.28770929\n",
      "Iteration 39534, loss = 74.27826100\n",
      "Iteration 39535, loss = 74.26881314\n",
      "Iteration 39536, loss = 74.25936595\n",
      "Iteration 39537, loss = 74.24991965\n",
      "Iteration 39538, loss = 74.24047427\n",
      "Iteration 39539, loss = 74.23102968\n",
      "Iteration 39540, loss = 74.22158571\n",
      "Iteration 39541, loss = 74.21214226\n",
      "Iteration 39542, loss = 74.20269931\n",
      "Iteration 39543, loss = 74.19325695\n",
      "Iteration 39544, loss = 74.18381527\n",
      "Iteration 39545, loss = 74.17437435\n",
      "Iteration 39546, loss = 74.16493419\n",
      "Iteration 39547, loss = 74.15549475\n",
      "Iteration 39548, loss = 74.14605596\n",
      "Iteration 39549, loss = 74.13661776\n",
      "Iteration 39550, loss = 74.12718016\n",
      "Iteration 39551, loss = 74.11774318\n",
      "Iteration 39552, loss = 74.10830687\n",
      "Iteration 39553, loss = 74.09887125\n",
      "Iteration 39554, loss = 74.08943633\n",
      "Iteration 39555, loss = 74.08000210\n",
      "Iteration 39556, loss = 74.07056854\n",
      "Iteration 39557, loss = 74.06113562\n",
      "Iteration 39558, loss = 74.05170333\n",
      "Iteration 39559, loss = 74.04227169\n",
      "Iteration 39560, loss = 74.03284069\n",
      "Iteration 39561, loss = 74.02341036\n",
      "Iteration 39562, loss = 74.01398070\n",
      "Iteration 39563, loss = 74.00455172\n",
      "Iteration 39564, loss = 73.99512340\n",
      "Iteration 39565, loss = 73.98569575\n",
      "Iteration 39566, loss = 73.97626876\n",
      "Iteration 39567, loss = 73.96684241\n",
      "Iteration 39568, loss = 73.95741672\n",
      "Iteration 39569, loss = 73.94799168\n",
      "Iteration 39570, loss = 73.93856730\n",
      "Iteration 39571, loss = 73.92914358\n",
      "Iteration 39572, loss = 73.91972053\n",
      "Iteration 39573, loss = 73.91029815\n",
      "Iteration 39574, loss = 73.90087643\n",
      "Iteration 39575, loss = 73.89145536\n",
      "Iteration 39576, loss = 73.88203496\n",
      "Iteration 39577, loss = 73.87261521\n",
      "Iteration 39578, loss = 73.86319612\n",
      "Iteration 39579, loss = 73.85377769\n",
      "Iteration 39580, loss = 73.84435991\n",
      "Iteration 39581, loss = 73.83494280\n",
      "Iteration 39582, loss = 73.82552635\n",
      "Iteration 39583, loss = 73.81611056\n",
      "Iteration 39584, loss = 73.80669543\n",
      "Iteration 39585, loss = 73.79728097\n",
      "Iteration 39586, loss = 73.78786716\n",
      "Iteration 39587, loss = 73.77845401\n",
      "Iteration 39588, loss = 73.76904152\n",
      "Iteration 39589, loss = 73.75962969\n",
      "Iteration 39590, loss = 73.75021852\n",
      "Iteration 39591, loss = 73.74080801\n",
      "Iteration 39592, loss = 73.73139816\n",
      "Iteration 39593, loss = 73.72198897\n",
      "Iteration 39594, loss = 73.71258045\n",
      "Iteration 39595, loss = 73.70317258\n",
      "Iteration 39596, loss = 73.69376537\n",
      "Iteration 39597, loss = 73.68435882\n",
      "Iteration 39598, loss = 73.67495294\n",
      "Iteration 39599, loss = 73.66554771\n",
      "Iteration 39600, loss = 73.65614314\n",
      "Iteration 39601, loss = 73.64673924\n",
      "Iteration 39602, loss = 73.63733599\n",
      "Iteration 39603, loss = 73.62793340\n",
      "Iteration 39604, loss = 73.61853148\n",
      "Iteration 39605, loss = 73.60913021\n",
      "Iteration 39606, loss = 73.59972961\n",
      "Iteration 39607, loss = 73.59032966\n",
      "Iteration 39608, loss = 73.58093038\n",
      "Iteration 39609, loss = 73.57153175\n",
      "Iteration 39610, loss = 73.56213379\n",
      "Iteration 39611, loss = 73.55273649\n",
      "Iteration 39612, loss = 73.54333984\n",
      "Iteration 39613, loss = 73.53394386\n",
      "Iteration 39614, loss = 73.52454854\n",
      "Iteration 39615, loss = 73.51515388\n",
      "Iteration 39616, loss = 73.50575988\n",
      "Iteration 39617, loss = 73.49636654\n",
      "Iteration 39618, loss = 73.48697386\n",
      "Iteration 39619, loss = 73.47758184\n",
      "Iteration 39620, loss = 73.46819048\n",
      "Iteration 39621, loss = 73.45879978\n",
      "Iteration 39622, loss = 73.44940975\n",
      "Iteration 39623, loss = 73.44002037\n",
      "Iteration 39624, loss = 73.43063165\n",
      "Iteration 39625, loss = 73.42124360\n",
      "Iteration 39626, loss = 73.41185620\n",
      "Iteration 39627, loss = 73.40246947\n",
      "Iteration 39628, loss = 73.39308340\n",
      "Iteration 39629, loss = 73.38369799\n",
      "Iteration 39630, loss = 73.37431323\n",
      "Iteration 39631, loss = 73.36492914\n",
      "Iteration 39632, loss = 73.35554571\n",
      "Iteration 39633, loss = 73.34616294\n",
      "Iteration 39634, loss = 73.33678084\n",
      "Iteration 39635, loss = 73.32739939\n",
      "Iteration 39636, loss = 73.31801860\n",
      "Iteration 39637, loss = 73.30863848\n",
      "Iteration 39638, loss = 73.29925901\n",
      "Iteration 39639, loss = 73.28988021\n",
      "Iteration 39640, loss = 73.28050207\n",
      "Iteration 39641, loss = 73.27112458\n",
      "Iteration 39642, loss = 73.26174777\n",
      "Iteration 39643, loss = 73.25237161\n",
      "Iteration 39644, loss = 73.24299611\n",
      "Iteration 39645, loss = 73.23362128\n",
      "Iteration 39646, loss = 73.22424711\n",
      "Iteration 39647, loss = 73.21487361\n",
      "Iteration 39648, loss = 73.20550078\n",
      "Iteration 39649, loss = 73.19612861\n",
      "Iteration 39650, loss = 73.18675712\n",
      "Iteration 39651, loss = 73.17738631\n",
      "Iteration 39652, loss = 73.16801619\n",
      "Iteration 39653, loss = 73.15864678\n",
      "Iteration 39654, loss = 73.14927811\n",
      "Iteration 39655, loss = 73.13991020\n",
      "Iteration 39656, loss = 73.13054312\n",
      "Iteration 39657, loss = 73.12117697\n",
      "Iteration 39658, loss = 73.11181187\n",
      "Iteration 39659, loss = 73.10244805\n",
      "Iteration 39660, loss = 73.09308583\n",
      "Iteration 39661, loss = 73.08372565\n",
      "Iteration 39662, loss = 73.07436814\n",
      "Iteration 39663, loss = 73.06501391\n",
      "Iteration 39664, loss = 73.05566352\n",
      "Iteration 39665, loss = 73.04631638\n",
      "Iteration 39666, loss = 73.03697042\n",
      "Iteration 39667, loss = 73.02762006\n",
      "Iteration 39668, loss = 73.01825908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39669, loss = 73.00888327\n",
      "Iteration 39670, loss = 72.99949833\n",
      "Iteration 39671, loss = 72.99011700\n",
      "Iteration 39672, loss = 72.98075086\n",
      "Iteration 39673, loss = 72.97140121\n",
      "Iteration 39674, loss = 72.96205955\n",
      "Iteration 39675, loss = 72.95271442\n",
      "Iteration 39676, loss = 72.94335853\n",
      "Iteration 39677, loss = 72.93399363\n",
      "Iteration 39678, loss = 72.92462826\n",
      "Iteration 39679, loss = 72.91527086\n",
      "Iteration 39680, loss = 72.90592299\n",
      "Iteration 39681, loss = 72.89657937\n",
      "Iteration 39682, loss = 72.88723308\n",
      "Iteration 39683, loss = 72.87788094\n",
      "Iteration 39684, loss = 72.86852547\n",
      "Iteration 39685, loss = 72.85917192\n",
      "Iteration 39686, loss = 72.84982372\n",
      "Iteration 39687, loss = 72.84047996\n",
      "Iteration 39688, loss = 72.83113700\n",
      "Iteration 39689, loss = 72.82179180\n",
      "Iteration 39690, loss = 72.81244420\n",
      "Iteration 39691, loss = 72.80309654\n",
      "Iteration 39692, loss = 72.79375131\n",
      "Iteration 39693, loss = 72.78440917\n",
      "Iteration 39694, loss = 72.77506875\n",
      "Iteration 39695, loss = 72.76572815\n",
      "Iteration 39696, loss = 72.75638650\n",
      "Iteration 39697, loss = 72.74704444\n",
      "Iteration 39698, loss = 72.73770335\n",
      "Iteration 39699, loss = 72.72836412\n",
      "Iteration 39700, loss = 72.71902654\n",
      "Iteration 39701, loss = 72.70968971\n",
      "Iteration 39702, loss = 72.70035284\n",
      "Iteration 39703, loss = 72.69101584\n",
      "Iteration 39704, loss = 72.68167924\n",
      "Iteration 39705, loss = 72.67234366\n",
      "Iteration 39706, loss = 72.66300935\n",
      "Iteration 39707, loss = 72.65367607\n",
      "Iteration 39708, loss = 72.64434335\n",
      "Iteration 39709, loss = 72.63501091\n",
      "Iteration 39710, loss = 72.62567879\n",
      "Iteration 39711, loss = 72.61634728\n",
      "Iteration 39712, loss = 72.60701666\n",
      "Iteration 39713, loss = 72.59768699\n",
      "Iteration 39714, loss = 72.58835813\n",
      "Iteration 39715, loss = 72.57902987\n",
      "Iteration 39716, loss = 72.56970209\n",
      "Iteration 39717, loss = 72.56037483\n",
      "Iteration 39718, loss = 72.55104823\n",
      "Iteration 39719, loss = 72.54172241\n",
      "Iteration 39720, loss = 72.53239741\n",
      "Iteration 39721, loss = 72.52307315\n",
      "Iteration 39722, loss = 72.51374954\n",
      "Iteration 39723, loss = 72.50442650\n",
      "Iteration 39724, loss = 72.49510401\n",
      "Iteration 39725, loss = 72.48578211\n",
      "Iteration 39726, loss = 72.47646082\n",
      "Iteration 39727, loss = 72.46714017\n",
      "Iteration 39728, loss = 72.45782016\n",
      "Iteration 39729, loss = 72.44850078\n",
      "Iteration 39730, loss = 72.43918205\n",
      "Iteration 39731, loss = 72.42986401\n",
      "Iteration 39732, loss = 72.42054671\n",
      "Iteration 39733, loss = 72.41123014\n",
      "Iteration 39734, loss = 72.40191432\n",
      "Iteration 39735, loss = 72.39259920\n",
      "Iteration 39736, loss = 72.38328473\n",
      "Iteration 39737, loss = 72.37397089\n",
      "Iteration 39738, loss = 72.36465764\n",
      "Iteration 39739, loss = 72.35534501\n",
      "Iteration 39740, loss = 72.34603300\n",
      "Iteration 39741, loss = 72.33672167\n",
      "Iteration 39742, loss = 72.32741103\n",
      "Iteration 39743, loss = 72.31810109\n",
      "Iteration 39744, loss = 72.30879184\n",
      "Iteration 39745, loss = 72.29948328\n",
      "Iteration 39746, loss = 72.29017538\n",
      "Iteration 39747, loss = 72.28086812\n",
      "Iteration 39748, loss = 72.27156152\n",
      "Iteration 39749, loss = 72.26225556\n",
      "Iteration 39750, loss = 72.25295025\n",
      "Iteration 39751, loss = 72.24364560\n",
      "Iteration 39752, loss = 72.23434162\n",
      "Iteration 39753, loss = 72.22503831\n",
      "Iteration 39754, loss = 72.21573566\n",
      "Iteration 39755, loss = 72.20643369\n",
      "Iteration 39756, loss = 72.19713238\n",
      "Iteration 39757, loss = 72.18783174\n",
      "Iteration 39758, loss = 72.17853176\n",
      "Iteration 39759, loss = 72.16923244\n",
      "Iteration 39760, loss = 72.15993378\n",
      "Iteration 39761, loss = 72.15063578\n",
      "Iteration 39762, loss = 72.14133844\n",
      "Iteration 39763, loss = 72.13204176\n",
      "Iteration 39764, loss = 72.12274574\n",
      "Iteration 39765, loss = 72.11345038\n",
      "Iteration 39766, loss = 72.10415569\n",
      "Iteration 39767, loss = 72.09486166\n",
      "Iteration 39768, loss = 72.08556830\n",
      "Iteration 39769, loss = 72.07627560\n",
      "Iteration 39770, loss = 72.06698357\n",
      "Iteration 39771, loss = 72.05769220\n",
      "Iteration 39772, loss = 72.04840149\n",
      "Iteration 39773, loss = 72.03911144\n",
      "Iteration 39774, loss = 72.02982205\n",
      "Iteration 39775, loss = 72.02053333\n",
      "Iteration 39776, loss = 72.01124527\n",
      "Iteration 39777, loss = 72.00195787\n",
      "Iteration 39778, loss = 71.99267113\n",
      "Iteration 39779, loss = 71.98338505\n",
      "Iteration 39780, loss = 71.97409964\n",
      "Iteration 39781, loss = 71.96481489\n",
      "Iteration 39782, loss = 71.95553081\n",
      "Iteration 39783, loss = 71.94624739\n",
      "Iteration 39784, loss = 71.93696463\n",
      "Iteration 39785, loss = 71.92768253\n",
      "Iteration 39786, loss = 71.91840110\n",
      "Iteration 39787, loss = 71.90912033\n",
      "Iteration 39788, loss = 71.89984022\n",
      "Iteration 39789, loss = 71.89056077\n",
      "Iteration 39790, loss = 71.88128199\n",
      "Iteration 39791, loss = 71.87200387\n",
      "Iteration 39792, loss = 71.86272641\n",
      "Iteration 39793, loss = 71.85344962\n",
      "Iteration 39794, loss = 71.84417349\n",
      "Iteration 39795, loss = 71.83489802\n",
      "Iteration 39796, loss = 71.82562321\n",
      "Iteration 39797, loss = 71.81634907\n",
      "Iteration 39798, loss = 71.80707559\n",
      "Iteration 39799, loss = 71.79780277\n",
      "Iteration 39800, loss = 71.78853061\n",
      "Iteration 39801, loss = 71.77925912\n",
      "Iteration 39802, loss = 71.76998829\n",
      "Iteration 39803, loss = 71.76071813\n",
      "Iteration 39804, loss = 71.75144862\n",
      "Iteration 39805, loss = 71.74217978\n",
      "Iteration 39806, loss = 71.73291161\n",
      "Iteration 39807, loss = 71.72364409\n",
      "Iteration 39808, loss = 71.71437724\n",
      "Iteration 39809, loss = 71.70511105\n",
      "Iteration 39810, loss = 71.69584553\n",
      "Iteration 39811, loss = 71.68658067\n",
      "Iteration 39812, loss = 71.67731647\n",
      "Iteration 39813, loss = 71.66805293\n",
      "Iteration 39814, loss = 71.65879006\n",
      "Iteration 39815, loss = 71.64952785\n",
      "Iteration 39816, loss = 71.64026630\n",
      "Iteration 39817, loss = 71.63100542\n",
      "Iteration 39818, loss = 71.62174519\n",
      "Iteration 39819, loss = 71.61248564\n",
      "Iteration 39820, loss = 71.60322674\n",
      "Iteration 39821, loss = 71.59396851\n",
      "Iteration 39822, loss = 71.58471094\n",
      "Iteration 39823, loss = 71.57545403\n",
      "Iteration 39824, loss = 71.56619779\n",
      "Iteration 39825, loss = 71.55694221\n",
      "Iteration 39826, loss = 71.54768730\n",
      "Iteration 39827, loss = 71.53843304\n",
      "Iteration 39828, loss = 71.52917945\n",
      "Iteration 39829, loss = 71.51992653\n",
      "Iteration 39830, loss = 71.51067426\n",
      "Iteration 39831, loss = 71.50142266\n",
      "Iteration 39832, loss = 71.49217173\n",
      "Iteration 39833, loss = 71.48292145\n",
      "Iteration 39834, loss = 71.47367184\n",
      "Iteration 39835, loss = 71.46442290\n",
      "Iteration 39836, loss = 71.45517461\n",
      "Iteration 39837, loss = 71.44592699\n",
      "Iteration 39838, loss = 71.43668004\n",
      "Iteration 39839, loss = 71.42743375\n",
      "Iteration 39840, loss = 71.41818812\n",
      "Iteration 39841, loss = 71.40894316\n",
      "Iteration 39842, loss = 71.39969887\n",
      "Iteration 39843, loss = 71.39045525\n",
      "Iteration 39844, loss = 71.38121231\n",
      "Iteration 39845, loss = 71.37197004\n",
      "Iteration 39846, loss = 71.36272846\n",
      "Iteration 39847, loss = 71.35348757\n",
      "Iteration 39848, loss = 71.34424740\n",
      "Iteration 39849, loss = 71.33500796\n",
      "Iteration 39850, loss = 71.32576926\n",
      "Iteration 39851, loss = 71.31653133\n",
      "Iteration 39852, loss = 71.30729414\n",
      "Iteration 39853, loss = 71.29805763\n",
      "Iteration 39854, loss = 71.28882165\n",
      "Iteration 39855, loss = 71.27958604\n",
      "Iteration 39856, loss = 71.27035070\n",
      "Iteration 39857, loss = 71.26111580\n",
      "Iteration 39858, loss = 71.25188172\n",
      "Iteration 39859, loss = 71.24264891\n",
      "Iteration 39860, loss = 71.23341763\n",
      "Iteration 39861, loss = 71.22418797\n",
      "Iteration 39862, loss = 71.21496003\n",
      "Iteration 39863, loss = 71.20573413\n",
      "Iteration 39864, loss = 71.19651107\n",
      "Iteration 39865, loss = 71.18729214\n",
      "Iteration 39866, loss = 71.17807858\n",
      "Iteration 39867, loss = 71.16887085\n",
      "Iteration 39868, loss = 71.15966573\n",
      "Iteration 39869, loss = 71.15045570\n",
      "Iteration 39870, loss = 71.14122816\n",
      "Iteration 39871, loss = 71.13197760\n",
      "Iteration 39872, loss = 71.12271365\n",
      "Iteration 39873, loss = 71.11346027\n",
      "Iteration 39874, loss = 71.10423357\n",
      "Iteration 39875, loss = 71.09502889\n",
      "Iteration 39876, loss = 71.08582687\n",
      "Iteration 39877, loss = 71.07660945\n",
      "Iteration 39878, loss = 71.06737407\n",
      "Iteration 39879, loss = 71.05813456\n",
      "Iteration 39880, loss = 71.04890769\n",
      "Iteration 39881, loss = 71.03969674\n",
      "Iteration 39882, loss = 71.03049072\n",
      "Iteration 39883, loss = 71.02127690\n",
      "Iteration 39884, loss = 71.01205252\n",
      "Iteration 39885, loss = 71.00282620\n",
      "Iteration 39886, loss = 70.99360768\n",
      "Iteration 39887, loss = 70.98439813\n",
      "Iteration 39888, loss = 70.97519056\n",
      "Iteration 39889, loss = 70.96597806\n",
      "Iteration 39890, loss = 70.95676052\n",
      "Iteration 39891, loss = 70.94754349\n",
      "Iteration 39892, loss = 70.93833176\n",
      "Iteration 39893, loss = 70.92912465\n",
      "Iteration 39894, loss = 70.91991780\n",
      "Iteration 39895, loss = 70.91070809\n",
      "Iteration 39896, loss = 70.90149649\n",
      "Iteration 39897, loss = 70.89228635\n",
      "Iteration 39898, loss = 70.88307962\n",
      "Iteration 39899, loss = 70.87387522\n",
      "Iteration 39900, loss = 70.86467068\n",
      "Iteration 39901, loss = 70.85546479\n",
      "Iteration 39902, loss = 70.84625856\n",
      "Iteration 39903, loss = 70.83705378\n",
      "Iteration 39904, loss = 70.82785118\n",
      "Iteration 39905, loss = 70.81864988\n",
      "Iteration 39906, loss = 70.80944859\n",
      "Iteration 39907, loss = 70.80024690\n",
      "Iteration 39908, loss = 70.79104550\n",
      "Iteration 39909, loss = 70.78184529\n",
      "Iteration 39910, loss = 70.77264654\n",
      "Iteration 39911, loss = 70.76344870\n",
      "Iteration 39912, loss = 70.75425113\n",
      "Iteration 39913, loss = 70.74505367\n",
      "Iteration 39914, loss = 70.73585671\n",
      "Iteration 39915, loss = 70.72666072\n",
      "Iteration 39916, loss = 70.71746580\n",
      "Iteration 39917, loss = 70.70827167\n",
      "Iteration 39918, loss = 70.69907800\n",
      "Iteration 39919, loss = 70.68988470\n",
      "Iteration 39920, loss = 70.68069197\n",
      "Iteration 39921, loss = 70.67150005\n",
      "Iteration 39922, loss = 70.66230901\n",
      "Iteration 39923, loss = 70.65311872\n",
      "Iteration 39924, loss = 70.64392900\n",
      "Iteration 39925, loss = 70.63473978\n",
      "Iteration 39926, loss = 70.62555117\n",
      "Iteration 39927, loss = 70.61636327\n",
      "Iteration 39928, loss = 70.60717616\n",
      "Iteration 39929, loss = 70.59798977\n",
      "Iteration 39930, loss = 70.58880401\n",
      "Iteration 39931, loss = 70.57961884\n",
      "Iteration 39932, loss = 70.57043429\n",
      "Iteration 39933, loss = 70.56125040\n",
      "Iteration 39934, loss = 70.55206724\n",
      "Iteration 39935, loss = 70.54288478\n",
      "Iteration 39936, loss = 70.53370299\n",
      "Iteration 39937, loss = 70.52452183\n",
      "Iteration 39938, loss = 70.51534131\n",
      "Iteration 39939, loss = 70.50616143\n",
      "Iteration 39940, loss = 70.49698224\n",
      "Iteration 39941, loss = 70.48780373\n",
      "Iteration 39942, loss = 70.47862591\n",
      "Iteration 39943, loss = 70.46944874\n",
      "Iteration 39944, loss = 70.46027222\n",
      "Iteration 39945, loss = 70.45109635\n",
      "Iteration 39946, loss = 70.44192115\n",
      "Iteration 39947, loss = 70.43274661\n",
      "Iteration 39948, loss = 70.42357276\n",
      "Iteration 39949, loss = 70.41439957\n",
      "Iteration 39950, loss = 70.40522704\n",
      "Iteration 39951, loss = 70.39605517\n",
      "Iteration 39952, loss = 70.38688395\n",
      "Iteration 39953, loss = 70.37771340\n",
      "Iteration 39954, loss = 70.36854352\n",
      "Iteration 39955, loss = 70.35937431\n",
      "Iteration 39956, loss = 70.35020577\n",
      "Iteration 39957, loss = 70.34103788\n",
      "Iteration 39958, loss = 70.33187066\n",
      "Iteration 39959, loss = 70.32270410\n",
      "Iteration 39960, loss = 70.31353820\n",
      "Iteration 39961, loss = 70.30437297\n",
      "Iteration 39962, loss = 70.29520840\n",
      "Iteration 39963, loss = 70.28604450\n",
      "Iteration 39964, loss = 70.27688126\n",
      "Iteration 39965, loss = 70.26771869\n",
      "Iteration 39966, loss = 70.25855678\n",
      "Iteration 39967, loss = 70.24939553\n",
      "Iteration 39968, loss = 70.24023494\n",
      "Iteration 39969, loss = 70.23107503\n",
      "Iteration 39970, loss = 70.22191577\n",
      "Iteration 39971, loss = 70.21275718\n",
      "Iteration 39972, loss = 70.20359926\n",
      "Iteration 39973, loss = 70.19444199\n",
      "Iteration 39974, loss = 70.18528539\n",
      "Iteration 39975, loss = 70.17612946\n",
      "Iteration 39976, loss = 70.16697419\n",
      "Iteration 39977, loss = 70.15781958\n",
      "Iteration 39978, loss = 70.14866564\n",
      "Iteration 39979, loss = 70.13951236\n",
      "Iteration 39980, loss = 70.13035975\n",
      "Iteration 39981, loss = 70.12120779\n",
      "Iteration 39982, loss = 70.11205651\n",
      "Iteration 39983, loss = 70.10290588\n",
      "Iteration 39984, loss = 70.09375593\n",
      "Iteration 39985, loss = 70.08460663\n",
      "Iteration 39986, loss = 70.07545800\n",
      "Iteration 39987, loss = 70.06631004\n",
      "Iteration 39988, loss = 70.05716273\n",
      "Iteration 39989, loss = 70.04801610\n",
      "Iteration 39990, loss = 70.03887012\n",
      "Iteration 39991, loss = 70.02972481\n",
      "Iteration 39992, loss = 70.02058016\n",
      "Iteration 39993, loss = 70.01143618\n",
      "Iteration 39994, loss = 70.00229286\n",
      "Iteration 39995, loss = 69.99315021\n",
      "Iteration 39996, loss = 69.98400822\n",
      "Iteration 39997, loss = 69.97486689\n",
      "Iteration 39998, loss = 69.96572623\n",
      "Iteration 39999, loss = 69.95658624\n",
      "Iteration 40000, loss = 69.94744690\n",
      "Iteration 40001, loss = 69.93830823\n",
      "Iteration 40002, loss = 69.92917023\n",
      "Iteration 40003, loss = 69.92003289\n",
      "Iteration 40004, loss = 69.91089621\n",
      "Iteration 40005, loss = 69.90176019\n",
      "Iteration 40006, loss = 69.89262485\n",
      "Iteration 40007, loss = 69.88349016\n",
      "Iteration 40008, loss = 69.87435614\n",
      "Iteration 40009, loss = 69.86522278\n",
      "Iteration 40010, loss = 69.85609009\n",
      "Iteration 40011, loss = 69.84695806\n",
      "Iteration 40012, loss = 69.83782670\n",
      "Iteration 40013, loss = 69.82869599\n",
      "Iteration 40014, loss = 69.81956596\n",
      "Iteration 40015, loss = 69.81043659\n",
      "Iteration 40016, loss = 69.80130788\n",
      "Iteration 40017, loss = 69.79217983\n",
      "Iteration 40018, loss = 69.78305245\n",
      "Iteration 40019, loss = 69.77392574\n",
      "Iteration 40020, loss = 69.76479968\n",
      "Iteration 40021, loss = 69.75567430\n",
      "Iteration 40022, loss = 69.74654957\n",
      "Iteration 40023, loss = 69.73742551\n",
      "Iteration 40024, loss = 69.72830212\n",
      "Iteration 40025, loss = 69.71917938\n",
      "Iteration 40026, loss = 69.71005732\n",
      "Iteration 40027, loss = 69.70093591\n",
      "Iteration 40028, loss = 69.69181517\n",
      "Iteration 40029, loss = 69.68269510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40030, loss = 69.67357569\n",
      "Iteration 40031, loss = 69.66445694\n",
      "Iteration 40032, loss = 69.65533886\n",
      "Iteration 40033, loss = 69.64622144\n",
      "Iteration 40034, loss = 69.63710468\n",
      "Iteration 40035, loss = 69.62798859\n",
      "Iteration 40036, loss = 69.61887316\n",
      "Iteration 40037, loss = 69.60975840\n",
      "Iteration 40038, loss = 69.60064430\n",
      "Iteration 40039, loss = 69.59153087\n",
      "Iteration 40040, loss = 69.58241809\n",
      "Iteration 40041, loss = 69.57330599\n",
      "Iteration 40042, loss = 69.56419455\n",
      "Iteration 40043, loss = 69.55508377\n",
      "Iteration 40044, loss = 69.54597365\n",
      "Iteration 40045, loss = 69.53686420\n",
      "Iteration 40046, loss = 69.52775541\n",
      "Iteration 40047, loss = 69.51864729\n",
      "Iteration 40048, loss = 69.50953983\n",
      "Iteration 40049, loss = 69.50043304\n",
      "Iteration 40050, loss = 69.49132691\n",
      "Iteration 40051, loss = 69.48222144\n",
      "Iteration 40052, loss = 69.47311664\n",
      "Iteration 40053, loss = 69.46401251\n",
      "Iteration 40054, loss = 69.45490903\n",
      "Iteration 40055, loss = 69.44580623\n",
      "Iteration 40056, loss = 69.43670408\n",
      "Iteration 40057, loss = 69.42760261\n",
      "Iteration 40058, loss = 69.41850180\n",
      "Iteration 40059, loss = 69.40940166\n",
      "Iteration 40060, loss = 69.40030220\n",
      "Iteration 40061, loss = 69.39120341\n",
      "Iteration 40062, loss = 69.38210531\n",
      "Iteration 40063, loss = 69.37300791\n",
      "Iteration 40064, loss = 69.36391123\n",
      "Iteration 40065, loss = 69.35481531\n",
      "Iteration 40066, loss = 69.34572016\n",
      "Iteration 40067, loss = 69.33662583\n",
      "Iteration 40068, loss = 69.32753230\n",
      "Iteration 40069, loss = 69.31843950\n",
      "Iteration 40070, loss = 69.30934715\n",
      "Iteration 40071, loss = 69.30025495\n",
      "Iteration 40072, loss = 69.29116265\n",
      "Iteration 40073, loss = 69.28207056\n",
      "Iteration 40074, loss = 69.27297931\n",
      "Iteration 40075, loss = 69.26388949\n",
      "Iteration 40076, loss = 69.25480106\n",
      "Iteration 40077, loss = 69.24571353\n",
      "Iteration 40078, loss = 69.23662632\n",
      "Iteration 40079, loss = 69.22753918\n",
      "Iteration 40080, loss = 69.21845236\n",
      "Iteration 40081, loss = 69.20936640\n",
      "Iteration 40082, loss = 69.20028158\n",
      "Iteration 40083, loss = 69.19119778\n",
      "Iteration 40084, loss = 69.18211461\n",
      "Iteration 40085, loss = 69.17303184\n",
      "Iteration 40086, loss = 69.16394955\n",
      "Iteration 40087, loss = 69.15486809\n",
      "Iteration 40088, loss = 69.14578773\n",
      "Iteration 40089, loss = 69.13670855\n",
      "Iteration 40090, loss = 69.12763051\n",
      "Iteration 40091, loss = 69.11855368\n",
      "Iteration 40092, loss = 69.10947847\n",
      "Iteration 40093, loss = 69.10040554\n",
      "Iteration 40094, loss = 69.09133572\n",
      "Iteration 40095, loss = 69.08226959\n",
      "Iteration 40096, loss = 69.07320741\n",
      "Iteration 40097, loss = 69.06414789\n",
      "Iteration 40098, loss = 69.05508793\n",
      "Iteration 40099, loss = 69.04602085\n",
      "Iteration 40100, loss = 69.03694076\n",
      "Iteration 40101, loss = 69.02784620\n",
      "Iteration 40102, loss = 69.01874670\n",
      "Iteration 40103, loss = 69.00965628\n",
      "Iteration 40104, loss = 69.00058346\n",
      "Iteration 40105, loss = 68.99152510\n",
      "Iteration 40106, loss = 68.98247018\n",
      "Iteration 40107, loss = 68.97340780\n",
      "Iteration 40108, loss = 68.96433376\n",
      "Iteration 40109, loss = 68.95525349\n",
      "Iteration 40110, loss = 68.94617689\n",
      "Iteration 40111, loss = 68.93711026\n",
      "Iteration 40112, loss = 68.92805179\n",
      "Iteration 40113, loss = 68.91899442\n",
      "Iteration 40114, loss = 68.90993211\n",
      "Iteration 40115, loss = 68.90086417\n",
      "Iteration 40116, loss = 68.89179514\n",
      "Iteration 40117, loss = 68.88273020\n",
      "Iteration 40118, loss = 68.87367092\n",
      "Iteration 40119, loss = 68.86461464\n",
      "Iteration 40120, loss = 68.85555738\n",
      "Iteration 40121, loss = 68.84649726\n",
      "Iteration 40122, loss = 68.83743558\n",
      "Iteration 40123, loss = 68.82837521\n",
      "Iteration 40124, loss = 68.81931802\n",
      "Iteration 40125, loss = 68.81026351\n",
      "Iteration 40126, loss = 68.80120972\n",
      "Iteration 40127, loss = 68.79215503\n",
      "Iteration 40128, loss = 68.78309938\n",
      "Iteration 40129, loss = 68.77404403\n",
      "Iteration 40130, loss = 68.76499029\n",
      "Iteration 40131, loss = 68.75593848\n",
      "Iteration 40132, loss = 68.74688791\n",
      "Iteration 40133, loss = 68.73783757\n",
      "Iteration 40134, loss = 68.72878700\n",
      "Iteration 40135, loss = 68.71973652\n",
      "Iteration 40136, loss = 68.71068682\n",
      "Iteration 40137, loss = 68.70163839\n",
      "Iteration 40138, loss = 68.69259116\n",
      "Iteration 40139, loss = 68.68354470\n",
      "Iteration 40140, loss = 68.67449857\n",
      "Iteration 40141, loss = 68.66545267\n",
      "Iteration 40142, loss = 68.65640726\n",
      "Iteration 40143, loss = 68.64736265\n",
      "Iteration 40144, loss = 68.63831901\n",
      "Iteration 40145, loss = 68.62927625\n",
      "Iteration 40146, loss = 68.62023417\n",
      "Iteration 40147, loss = 68.61119257\n",
      "Iteration 40148, loss = 68.60215144\n",
      "Iteration 40149, loss = 68.59311090\n",
      "Iteration 40150, loss = 68.58407110\n",
      "Iteration 40151, loss = 68.57503211\n",
      "Iteration 40152, loss = 68.56599389\n",
      "Iteration 40153, loss = 68.55695633\n",
      "Iteration 40154, loss = 68.54791936\n",
      "Iteration 40155, loss = 68.53888296\n",
      "Iteration 40156, loss = 68.52984718\n",
      "Iteration 40157, loss = 68.52081210\n",
      "Iteration 40158, loss = 68.51177773\n",
      "Iteration 40159, loss = 68.50274409\n",
      "Iteration 40160, loss = 68.49371113\n",
      "Iteration 40161, loss = 68.48467880\n",
      "Iteration 40162, loss = 68.47564709\n",
      "Iteration 40163, loss = 68.46661602\n",
      "Iteration 40164, loss = 68.45758561\n",
      "Iteration 40165, loss = 68.44855588\n",
      "Iteration 40166, loss = 68.43952685\n",
      "Iteration 40167, loss = 68.43049849\n",
      "Iteration 40168, loss = 68.42147080\n",
      "Iteration 40169, loss = 68.41244376\n",
      "Iteration 40170, loss = 68.40341736\n",
      "Iteration 40171, loss = 68.39439162\n",
      "Iteration 40172, loss = 68.38536654\n",
      "Iteration 40173, loss = 68.37634214\n",
      "Iteration 40174, loss = 68.36731841\n",
      "Iteration 40175, loss = 68.35829535\n",
      "Iteration 40176, loss = 68.34927295\n",
      "Iteration 40177, loss = 68.34025121\n",
      "Iteration 40178, loss = 68.33123013\n",
      "Iteration 40179, loss = 68.32220971\n",
      "Iteration 40180, loss = 68.31318994\n",
      "Iteration 40181, loss = 68.30417085\n",
      "Iteration 40182, loss = 68.29515242\n",
      "Iteration 40183, loss = 68.28613466\n",
      "Iteration 40184, loss = 68.27711757\n",
      "Iteration 40185, loss = 68.26810113\n",
      "Iteration 40186, loss = 68.25908536\n",
      "Iteration 40187, loss = 68.25007025\n",
      "Iteration 40188, loss = 68.24105580\n",
      "Iteration 40189, loss = 68.23204201\n",
      "Iteration 40190, loss = 68.22302889\n",
      "Iteration 40191, loss = 68.21401643\n",
      "Iteration 40192, loss = 68.20500464\n",
      "Iteration 40193, loss = 68.19599351\n",
      "Iteration 40194, loss = 68.18698304\n",
      "Iteration 40195, loss = 68.17797323\n",
      "Iteration 40196, loss = 68.16896409\n",
      "Iteration 40197, loss = 68.15995561\n",
      "Iteration 40198, loss = 68.15094779\n",
      "Iteration 40199, loss = 68.14194064\n",
      "Iteration 40200, loss = 68.13293415\n",
      "Iteration 40201, loss = 68.12392832\n",
      "Iteration 40202, loss = 68.11492316\n",
      "Iteration 40203, loss = 68.10591866\n",
      "Iteration 40204, loss = 68.09691482\n",
      "Iteration 40205, loss = 68.08791165\n",
      "Iteration 40206, loss = 68.07890914\n",
      "Iteration 40207, loss = 68.06990729\n",
      "Iteration 40208, loss = 68.06090610\n",
      "Iteration 40209, loss = 68.05190558\n",
      "Iteration 40210, loss = 68.04290572\n",
      "Iteration 40211, loss = 68.03390652\n",
      "Iteration 40212, loss = 68.02490799\n",
      "Iteration 40213, loss = 68.01591011\n",
      "Iteration 40214, loss = 68.00691291\n",
      "Iteration 40215, loss = 67.99791636\n",
      "Iteration 40216, loss = 67.98892048\n",
      "Iteration 40217, loss = 67.97992526\n",
      "Iteration 40218, loss = 67.97093070\n",
      "Iteration 40219, loss = 67.96193681\n",
      "Iteration 40220, loss = 67.95294358\n",
      "Iteration 40221, loss = 67.94395101\n",
      "Iteration 40222, loss = 67.93495910\n",
      "Iteration 40223, loss = 67.92596786\n",
      "Iteration 40224, loss = 67.91697728\n",
      "Iteration 40225, loss = 67.90798736\n",
      "Iteration 40226, loss = 67.89899811\n",
      "Iteration 40227, loss = 67.89000952\n",
      "Iteration 40228, loss = 67.88102159\n",
      "Iteration 40229, loss = 67.87203433\n",
      "Iteration 40230, loss = 67.86304772\n",
      "Iteration 40231, loss = 67.85406178\n",
      "Iteration 40232, loss = 67.84507650\n",
      "Iteration 40233, loss = 67.83609189\n",
      "Iteration 40234, loss = 67.82710794\n",
      "Iteration 40235, loss = 67.81812465\n",
      "Iteration 40236, loss = 67.80914202\n",
      "Iteration 40237, loss = 67.80016006\n",
      "Iteration 40238, loss = 67.79117876\n",
      "Iteration 40239, loss = 67.78219812\n",
      "Iteration 40240, loss = 67.77321814\n",
      "Iteration 40241, loss = 67.76423883\n",
      "Iteration 40242, loss = 67.75526018\n",
      "Iteration 40243, loss = 67.74628219\n",
      "Iteration 40244, loss = 67.73730487\n",
      "Iteration 40245, loss = 67.72832821\n",
      "Iteration 40246, loss = 67.71935221\n",
      "Iteration 40247, loss = 67.71037687\n",
      "Iteration 40248, loss = 67.70140219\n",
      "Iteration 40249, loss = 67.69242818\n",
      "Iteration 40250, loss = 67.68345483\n",
      "Iteration 40251, loss = 67.67448215\n",
      "Iteration 40252, loss = 67.66551012\n",
      "Iteration 40253, loss = 67.65653876\n",
      "Iteration 40254, loss = 67.64756806\n",
      "Iteration 40255, loss = 67.63859803\n",
      "Iteration 40256, loss = 67.62962865\n",
      "Iteration 40257, loss = 67.62065994\n",
      "Iteration 40258, loss = 67.61169190\n",
      "Iteration 40259, loss = 67.60272451\n",
      "Iteration 40260, loss = 67.59375779\n",
      "Iteration 40261, loss = 67.58479173\n",
      "Iteration 40262, loss = 67.57582633\n",
      "Iteration 40263, loss = 67.56686159\n",
      "Iteration 40264, loss = 67.55789752\n",
      "Iteration 40265, loss = 67.54893411\n",
      "Iteration 40266, loss = 67.53997136\n",
      "Iteration 40267, loss = 67.53100928\n",
      "Iteration 40268, loss = 67.52204786\n",
      "Iteration 40269, loss = 67.51308710\n",
      "Iteration 40270, loss = 67.50412700\n",
      "Iteration 40271, loss = 67.49516757\n",
      "Iteration 40272, loss = 67.48620879\n",
      "Iteration 40273, loss = 67.47725069\n",
      "Iteration 40274, loss = 67.46829324\n",
      "Iteration 40275, loss = 67.45933646\n",
      "Iteration 40276, loss = 67.45038034\n",
      "Iteration 40277, loss = 67.44142489\n",
      "Iteration 40278, loss = 67.43247010\n",
      "Iteration 40279, loss = 67.42351598\n",
      "Iteration 40280, loss = 67.41456253\n",
      "Iteration 40281, loss = 67.40560975\n",
      "Iteration 40282, loss = 67.39665765\n",
      "Iteration 40283, loss = 67.38770624\n",
      "Iteration 40284, loss = 67.37875554\n",
      "Iteration 40285, loss = 67.36980556\n",
      "Iteration 40286, loss = 67.36085635\n",
      "Iteration 40287, loss = 67.35190798\n",
      "Iteration 40288, loss = 67.34296054\n",
      "Iteration 40289, loss = 67.33401421\n",
      "Iteration 40290, loss = 67.32506926\n",
      "Iteration 40291, loss = 67.31612610\n",
      "Iteration 40292, loss = 67.30718537\n",
      "Iteration 40293, loss = 67.29824800\n",
      "Iteration 40294, loss = 67.28931502\n",
      "Iteration 40295, loss = 67.28038744\n",
      "Iteration 40296, loss = 67.27146462\n",
      "Iteration 40297, loss = 67.26254324\n",
      "Iteration 40298, loss = 67.25361402\n",
      "Iteration 40299, loss = 67.24466697\n",
      "Iteration 40300, loss = 67.23569791\n",
      "Iteration 40301, loss = 67.22672070\n",
      "Iteration 40302, loss = 67.21775741\n",
      "Iteration 40303, loss = 67.20882018\n",
      "Iteration 40304, loss = 67.19990141\n",
      "Iteration 40305, loss = 67.19098210\n",
      "Iteration 40306, loss = 67.18204711\n",
      "Iteration 40307, loss = 67.17309595\n",
      "Iteration 40308, loss = 67.16414300\n",
      "Iteration 40309, loss = 67.15520281\n",
      "Iteration 40310, loss = 67.14627690\n",
      "Iteration 40311, loss = 67.13735452\n",
      "Iteration 40312, loss = 67.12842430\n",
      "Iteration 40313, loss = 67.11948466\n",
      "Iteration 40314, loss = 67.11054379\n",
      "Iteration 40315, loss = 67.10161053\n",
      "Iteration 40316, loss = 67.09268574\n",
      "Iteration 40317, loss = 67.08376288\n",
      "Iteration 40318, loss = 67.07483552\n",
      "Iteration 40319, loss = 67.06590326\n",
      "Iteration 40320, loss = 67.05697113\n",
      "Iteration 40321, loss = 67.04804374\n",
      "Iteration 40322, loss = 67.03912098\n",
      "Iteration 40323, loss = 67.03019901\n",
      "Iteration 40324, loss = 67.02127470\n",
      "Iteration 40325, loss = 67.01234844\n",
      "Iteration 40326, loss = 67.00342309\n",
      "Iteration 40327, loss = 66.99450075\n",
      "Iteration 40328, loss = 66.98558091\n",
      "Iteration 40329, loss = 66.97666140\n",
      "Iteration 40330, loss = 66.96774080\n",
      "Iteration 40331, loss = 66.95881962\n",
      "Iteration 40332, loss = 66.94989945\n",
      "Iteration 40333, loss = 66.94098131\n",
      "Iteration 40334, loss = 66.93206476\n",
      "Iteration 40335, loss = 66.92314861\n",
      "Iteration 40336, loss = 66.91423216\n",
      "Iteration 40337, loss = 66.90531571\n",
      "Iteration 40338, loss = 66.89640012\n",
      "Iteration 40339, loss = 66.88748590\n",
      "Iteration 40340, loss = 66.87857283\n",
      "Iteration 40341, loss = 66.86966031\n",
      "Iteration 40342, loss = 66.86074797\n",
      "Iteration 40343, loss = 66.85183595\n",
      "Iteration 40344, loss = 66.84292467\n",
      "Iteration 40345, loss = 66.83401441\n",
      "Iteration 40346, loss = 66.82510507\n",
      "Iteration 40347, loss = 66.81619637\n",
      "Iteration 40348, loss = 66.80728808\n",
      "Iteration 40349, loss = 66.79838026\n",
      "Iteration 40350, loss = 66.78947310\n",
      "Iteration 40351, loss = 66.78056678\n",
      "Iteration 40352, loss = 66.77166129\n",
      "Iteration 40353, loss = 66.76275649\n",
      "Iteration 40354, loss = 66.75385224\n",
      "Iteration 40355, loss = 66.74494854\n",
      "Iteration 40356, loss = 66.73604546\n",
      "Iteration 40357, loss = 66.72714310\n",
      "Iteration 40358, loss = 66.71824150\n",
      "Iteration 40359, loss = 66.70934061\n",
      "Iteration 40360, loss = 66.70044036\n",
      "Iteration 40361, loss = 66.69154070\n",
      "Iteration 40362, loss = 66.68264167\n",
      "Iteration 40363, loss = 66.67374331\n",
      "Iteration 40364, loss = 66.66484566\n",
      "Iteration 40365, loss = 66.65594870\n",
      "Iteration 40366, loss = 66.64705242\n",
      "Iteration 40367, loss = 66.63815678\n",
      "Iteration 40368, loss = 66.62926177\n",
      "Iteration 40369, loss = 66.62036741\n",
      "Iteration 40370, loss = 66.61147373\n",
      "Iteration 40371, loss = 66.60258073\n",
      "Iteration 40372, loss = 66.59368841\n",
      "Iteration 40373, loss = 66.58479675\n",
      "Iteration 40374, loss = 66.57590575\n",
      "Iteration 40375, loss = 66.56701539\n",
      "Iteration 40376, loss = 66.55812570\n",
      "Iteration 40377, loss = 66.54923667\n",
      "Iteration 40378, loss = 66.54034832\n",
      "Iteration 40379, loss = 66.53146063\n",
      "Iteration 40380, loss = 66.52257362\n",
      "Iteration 40381, loss = 66.51368726\n",
      "Iteration 40382, loss = 66.50480155\n",
      "Iteration 40383, loss = 66.49591651\n",
      "Iteration 40384, loss = 66.48703214\n",
      "Iteration 40385, loss = 66.47814843\n",
      "Iteration 40386, loss = 66.46926539\n",
      "Iteration 40387, loss = 66.46038301\n",
      "Iteration 40388, loss = 66.45150130\n",
      "Iteration 40389, loss = 66.44262025\n",
      "Iteration 40390, loss = 66.43373986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40391, loss = 66.42486013\n",
      "Iteration 40392, loss = 66.41598107\n",
      "Iteration 40393, loss = 66.40710268\n",
      "Iteration 40394, loss = 66.39822495\n",
      "Iteration 40395, loss = 66.38934788\n",
      "Iteration 40396, loss = 66.38047148\n",
      "Iteration 40397, loss = 66.37159574\n",
      "Iteration 40398, loss = 66.36272066\n",
      "Iteration 40399, loss = 66.35384625\n",
      "Iteration 40400, loss = 66.34497250\n",
      "Iteration 40401, loss = 66.33609942\n",
      "Iteration 40402, loss = 66.32722700\n",
      "Iteration 40403, loss = 66.31835524\n",
      "Iteration 40404, loss = 66.30948415\n",
      "Iteration 40405, loss = 66.30061373\n",
      "Iteration 40406, loss = 66.29174396\n",
      "Iteration 40407, loss = 66.28287486\n",
      "Iteration 40408, loss = 66.27400643\n",
      "Iteration 40409, loss = 66.26513866\n",
      "Iteration 40410, loss = 66.25627155\n",
      "Iteration 40411, loss = 66.24740511\n",
      "Iteration 40412, loss = 66.23853934\n",
      "Iteration 40413, loss = 66.22967422\n",
      "Iteration 40414, loss = 66.22080977\n",
      "Iteration 40415, loss = 66.21194599\n",
      "Iteration 40416, loss = 66.20308287\n",
      "Iteration 40417, loss = 66.19422041\n",
      "Iteration 40418, loss = 66.18535862\n",
      "Iteration 40419, loss = 66.17649749\n",
      "Iteration 40420, loss = 66.16763703\n",
      "Iteration 40421, loss = 66.15877723\n",
      "Iteration 40422, loss = 66.14991809\n",
      "Iteration 40423, loss = 66.14105962\n",
      "Iteration 40424, loss = 66.13220182\n",
      "Iteration 40425, loss = 66.12334468\n",
      "Iteration 40426, loss = 66.11448820\n",
      "Iteration 40427, loss = 66.10563239\n",
      "Iteration 40428, loss = 66.09677724\n",
      "Iteration 40429, loss = 66.08792275\n",
      "Iteration 40430, loss = 66.07906894\n",
      "Iteration 40431, loss = 66.07021578\n",
      "Iteration 40432, loss = 66.06136329\n",
      "Iteration 40433, loss = 66.05251146\n",
      "Iteration 40434, loss = 66.04366030\n",
      "Iteration 40435, loss = 66.03480980\n",
      "Iteration 40436, loss = 66.02595997\n",
      "Iteration 40437, loss = 66.01711080\n",
      "Iteration 40438, loss = 66.00826230\n",
      "Iteration 40439, loss = 65.99941446\n",
      "Iteration 40440, loss = 65.99056729\n",
      "Iteration 40441, loss = 65.98172078\n",
      "Iteration 40442, loss = 65.97287493\n",
      "Iteration 40443, loss = 65.96402975\n",
      "Iteration 40444, loss = 65.95518524\n",
      "Iteration 40445, loss = 65.94634139\n",
      "Iteration 40446, loss = 65.93749820\n",
      "Iteration 40447, loss = 65.92865568\n",
      "Iteration 40448, loss = 65.91981383\n",
      "Iteration 40449, loss = 65.91097265\n",
      "Iteration 40450, loss = 65.90213213\n",
      "Iteration 40451, loss = 65.89329229\n",
      "Iteration 40452, loss = 65.88445312\n",
      "Iteration 40453, loss = 65.87561462\n",
      "Iteration 40454, loss = 65.86677682\n",
      "Iteration 40455, loss = 65.85793970\n",
      "Iteration 40456, loss = 65.84910329\n",
      "Iteration 40457, loss = 65.84026760\n",
      "Iteration 40458, loss = 65.83143264\n",
      "Iteration 40459, loss = 65.82259841\n",
      "Iteration 40460, loss = 65.81376490\n",
      "Iteration 40461, loss = 65.80493203\n",
      "Iteration 40462, loss = 65.79609970\n",
      "Iteration 40463, loss = 65.78726777\n",
      "Iteration 40464, loss = 65.77843616\n",
      "Iteration 40465, loss = 65.76960497\n",
      "Iteration 40466, loss = 65.76077444\n",
      "Iteration 40467, loss = 65.75194483\n",
      "Iteration 40468, loss = 65.74311625\n",
      "Iteration 40469, loss = 65.73428860\n",
      "Iteration 40470, loss = 65.72546168\n",
      "Iteration 40471, loss = 65.71663528\n",
      "Iteration 40472, loss = 65.70780930\n",
      "Iteration 40473, loss = 65.69898380\n",
      "Iteration 40474, loss = 65.69015893\n",
      "Iteration 40475, loss = 65.68133487\n",
      "Iteration 40476, loss = 65.67251165\n",
      "Iteration 40477, loss = 65.66368922\n",
      "Iteration 40478, loss = 65.65486743\n",
      "Iteration 40479, loss = 65.64604621\n",
      "Iteration 40480, loss = 65.63722553\n",
      "Iteration 40481, loss = 65.62840546\n",
      "Iteration 40482, loss = 65.61958610\n",
      "Iteration 40483, loss = 65.61076749\n",
      "Iteration 40484, loss = 65.60194962\n",
      "Iteration 40485, loss = 65.59313242\n",
      "Iteration 40486, loss = 65.58431586\n",
      "Iteration 40487, loss = 65.57549990\n",
      "Iteration 40488, loss = 65.56668457\n",
      "Iteration 40489, loss = 65.55786990\n",
      "Iteration 40490, loss = 65.54905594\n",
      "Iteration 40491, loss = 65.54024269\n",
      "Iteration 40492, loss = 65.53143012\n",
      "Iteration 40493, loss = 65.52261821\n",
      "Iteration 40494, loss = 65.51380695\n",
      "Iteration 40495, loss = 65.50499633\n",
      "Iteration 40496, loss = 65.49618639\n",
      "Iteration 40497, loss = 65.48737715\n",
      "Iteration 40498, loss = 65.47856861\n",
      "Iteration 40499, loss = 65.46976080\n",
      "Iteration 40500, loss = 65.46095373\n",
      "Iteration 40501, loss = 65.45214740\n",
      "Iteration 40502, loss = 65.44334188\n",
      "Iteration 40503, loss = 65.43453725\n",
      "Iteration 40504, loss = 65.42573363\n",
      "Iteration 40505, loss = 65.41693120\n",
      "Iteration 40506, loss = 65.40813023\n",
      "Iteration 40507, loss = 65.39933108\n",
      "Iteration 40508, loss = 65.39053424\n",
      "Iteration 40509, loss = 65.38174023\n",
      "Iteration 40510, loss = 65.37294957\n",
      "Iteration 40511, loss = 65.36416201\n",
      "Iteration 40512, loss = 65.35537630\n",
      "Iteration 40513, loss = 65.34658844\n",
      "Iteration 40514, loss = 65.33779338\n",
      "Iteration 40515, loss = 65.32898599\n",
      "Iteration 40516, loss = 65.32016806\n",
      "Iteration 40517, loss = 65.31134817\n",
      "Iteration 40518, loss = 65.30253784\n",
      "Iteration 40519, loss = 65.29374249\n",
      "Iteration 40520, loss = 65.28495859\n",
      "Iteration 40521, loss = 65.27617711\n",
      "Iteration 40522, loss = 65.26738943\n",
      "Iteration 40523, loss = 65.25859249\n",
      "Iteration 40524, loss = 65.24979007\n",
      "Iteration 40525, loss = 65.24098997\n",
      "Iteration 40526, loss = 65.23219769\n",
      "Iteration 40527, loss = 65.22341280\n",
      "Iteration 40528, loss = 65.21463035\n",
      "Iteration 40529, loss = 65.20584507\n",
      "Iteration 40530, loss = 65.19705518\n",
      "Iteration 40531, loss = 65.18826298\n",
      "Iteration 40532, loss = 65.17947268\n",
      "Iteration 40533, loss = 65.17068682\n",
      "Iteration 40534, loss = 65.16190476\n",
      "Iteration 40535, loss = 65.15312374\n",
      "Iteration 40536, loss = 65.14434127\n",
      "Iteration 40537, loss = 65.13555689\n",
      "Iteration 40538, loss = 65.12677212\n",
      "Iteration 40539, loss = 65.11798900\n",
      "Iteration 40540, loss = 65.10920848\n",
      "Iteration 40541, loss = 65.10042993\n",
      "Iteration 40542, loss = 65.09165196\n",
      "Iteration 40543, loss = 65.08287348\n",
      "Iteration 40544, loss = 65.07409449\n",
      "Iteration 40545, loss = 65.06531582\n",
      "Iteration 40546, loss = 65.05653839\n",
      "Iteration 40547, loss = 65.04776256\n",
      "Iteration 40548, loss = 65.03898796\n",
      "Iteration 40549, loss = 65.03021392\n",
      "Iteration 40550, loss = 65.02143998\n",
      "Iteration 40551, loss = 65.01266616\n",
      "Iteration 40552, loss = 65.00389284\n",
      "Iteration 40553, loss = 64.99512045\n",
      "Iteration 40554, loss = 64.98634916\n",
      "Iteration 40555, loss = 64.97757882\n",
      "Iteration 40556, loss = 64.96880913\n",
      "Iteration 40557, loss = 64.96003986\n",
      "Iteration 40558, loss = 64.95127099\n",
      "Iteration 40559, loss = 64.94250266\n",
      "Iteration 40560, loss = 64.93373508\n",
      "Iteration 40561, loss = 64.92496836\n",
      "Iteration 40562, loss = 64.91620247\n",
      "Iteration 40563, loss = 64.90743727\n",
      "Iteration 40564, loss = 64.89867267\n",
      "Iteration 40565, loss = 64.88990859\n",
      "Iteration 40566, loss = 64.88114510\n",
      "Iteration 40567, loss = 64.87238227\n",
      "Iteration 40568, loss = 64.86362016\n",
      "Iteration 40569, loss = 64.85485881\n",
      "Iteration 40570, loss = 64.84609817\n",
      "Iteration 40571, loss = 64.83733819\n",
      "Iteration 40572, loss = 64.82857883\n",
      "Iteration 40573, loss = 64.81982008\n",
      "Iteration 40574, loss = 64.81106197\n",
      "Iteration 40575, loss = 64.80230453\n",
      "Iteration 40576, loss = 64.79354778\n",
      "Iteration 40577, loss = 64.78479172\n",
      "Iteration 40578, loss = 64.77603636\n",
      "Iteration 40579, loss = 64.76728165\n",
      "Iteration 40580, loss = 64.75852760\n",
      "Iteration 40581, loss = 64.74977418\n",
      "Iteration 40582, loss = 64.74102142\n",
      "Iteration 40583, loss = 64.73226931\n",
      "Iteration 40584, loss = 64.72351788\n",
      "Iteration 40585, loss = 64.71476713\n",
      "Iteration 40586, loss = 64.70601706\n",
      "Iteration 40587, loss = 64.69726765\n",
      "Iteration 40588, loss = 64.68851890\n",
      "Iteration 40589, loss = 64.67977081\n",
      "Iteration 40590, loss = 64.67102337\n",
      "Iteration 40591, loss = 64.66227660\n",
      "Iteration 40592, loss = 64.65353048\n",
      "Iteration 40593, loss = 64.64478504\n",
      "Iteration 40594, loss = 64.63604026\n",
      "Iteration 40595, loss = 64.62729616\n",
      "Iteration 40596, loss = 64.61855271\n",
      "Iteration 40597, loss = 64.60980993\n",
      "Iteration 40598, loss = 64.60106782\n",
      "Iteration 40599, loss = 64.59232636\n",
      "Iteration 40600, loss = 64.58358557\n",
      "Iteration 40601, loss = 64.57484543\n",
      "Iteration 40602, loss = 64.56610597\n",
      "Iteration 40603, loss = 64.55736716\n",
      "Iteration 40604, loss = 64.54862903\n",
      "Iteration 40605, loss = 64.53989155\n",
      "Iteration 40606, loss = 64.53115475\n",
      "Iteration 40607, loss = 64.52241860\n",
      "Iteration 40608, loss = 64.51368312\n",
      "Iteration 40609, loss = 64.50494830\n",
      "Iteration 40610, loss = 64.49621415\n",
      "Iteration 40611, loss = 64.48748066\n",
      "Iteration 40612, loss = 64.47874783\n",
      "Iteration 40613, loss = 64.47001566\n",
      "Iteration 40614, loss = 64.46128416\n",
      "Iteration 40615, loss = 64.45255333\n",
      "Iteration 40616, loss = 64.44382316\n",
      "Iteration 40617, loss = 64.43509365\n",
      "Iteration 40618, loss = 64.42636481\n",
      "Iteration 40619, loss = 64.41763662\n",
      "Iteration 40620, loss = 64.40890911\n",
      "Iteration 40621, loss = 64.40018225\n",
      "Iteration 40622, loss = 64.39145606\n",
      "Iteration 40623, loss = 64.38273054\n",
      "Iteration 40624, loss = 64.37400567\n",
      "Iteration 40625, loss = 64.36528147\n",
      "Iteration 40626, loss = 64.35655794\n",
      "Iteration 40627, loss = 64.34783507\n",
      "Iteration 40628, loss = 64.33911286\n",
      "Iteration 40629, loss = 64.33039131\n",
      "Iteration 40630, loss = 64.32167043\n",
      "Iteration 40631, loss = 64.31295022\n",
      "Iteration 40632, loss = 64.30423066\n",
      "Iteration 40633, loss = 64.29551177\n",
      "Iteration 40634, loss = 64.28679355\n",
      "Iteration 40635, loss = 64.27807598\n",
      "Iteration 40636, loss = 64.26935908\n",
      "Iteration 40637, loss = 64.26064285\n",
      "Iteration 40638, loss = 64.25192728\n",
      "Iteration 40639, loss = 64.24321237\n",
      "Iteration 40640, loss = 64.23449812\n",
      "Iteration 40641, loss = 64.22578454\n",
      "Iteration 40642, loss = 64.21707163\n",
      "Iteration 40643, loss = 64.20835938\n",
      "Iteration 40644, loss = 64.19964779\n",
      "Iteration 40645, loss = 64.19093688\n",
      "Iteration 40646, loss = 64.18222663\n",
      "Iteration 40647, loss = 64.17351705\n",
      "Iteration 40648, loss = 64.16480815\n",
      "Iteration 40649, loss = 64.15609994\n",
      "Iteration 40650, loss = 64.14739242\n",
      "Iteration 40651, loss = 64.13868562\n",
      "Iteration 40652, loss = 64.12997955\n",
      "Iteration 40653, loss = 64.12127424\n",
      "Iteration 40654, loss = 64.11256971\n",
      "Iteration 40655, loss = 64.10386596\n",
      "Iteration 40656, loss = 64.09516290\n",
      "Iteration 40657, loss = 64.08646034\n",
      "Iteration 40658, loss = 64.07775803\n",
      "Iteration 40659, loss = 64.06905579\n",
      "Iteration 40660, loss = 64.06035382\n",
      "Iteration 40661, loss = 64.05165261\n",
      "Iteration 40662, loss = 64.04295261\n",
      "Iteration 40663, loss = 64.03425389\n",
      "Iteration 40664, loss = 64.02555610\n",
      "Iteration 40665, loss = 64.01685881\n",
      "Iteration 40666, loss = 64.00816173\n",
      "Iteration 40667, loss = 63.99946496\n",
      "Iteration 40668, loss = 63.99076886\n",
      "Iteration 40669, loss = 63.98207372\n",
      "Iteration 40670, loss = 63.97337959\n",
      "Iteration 40671, loss = 63.96468622\n",
      "Iteration 40672, loss = 63.95599337\n",
      "Iteration 40673, loss = 63.94730094\n",
      "Iteration 40674, loss = 63.93860910\n",
      "Iteration 40675, loss = 63.92991806\n",
      "Iteration 40676, loss = 63.92122795\n",
      "Iteration 40677, loss = 63.91253871\n",
      "Iteration 40678, loss = 63.90385024\n",
      "Iteration 40679, loss = 63.89516252\n",
      "Iteration 40680, loss = 63.88647571\n",
      "Iteration 40681, loss = 63.87779008\n",
      "Iteration 40682, loss = 63.86910596\n",
      "Iteration 40683, loss = 63.86042366\n",
      "Iteration 40684, loss = 63.85174355\n",
      "Iteration 40685, loss = 63.84306608\n",
      "Iteration 40686, loss = 63.83439157\n",
      "Iteration 40687, loss = 63.82572008\n",
      "Iteration 40688, loss = 63.81705013\n",
      "Iteration 40689, loss = 63.80837882\n",
      "Iteration 40690, loss = 63.79970079\n",
      "Iteration 40691, loss = 63.79101226\n",
      "Iteration 40692, loss = 63.78231333\n",
      "Iteration 40693, loss = 63.77361183\n",
      "Iteration 40694, loss = 63.76491787\n",
      "Iteration 40695, loss = 63.75623739\n",
      "Iteration 40696, loss = 63.74756836\n",
      "Iteration 40697, loss = 63.73890318\n",
      "Iteration 40698, loss = 63.73023387\n",
      "Iteration 40699, loss = 63.72155628\n",
      "Iteration 40700, loss = 63.71287258\n",
      "Iteration 40701, loss = 63.70418909\n",
      "Iteration 40702, loss = 63.69551170\n",
      "Iteration 40703, loss = 63.68684164\n",
      "Iteration 40704, loss = 63.67817553\n",
      "Iteration 40705, loss = 63.66950847\n",
      "Iteration 40706, loss = 63.66083754\n",
      "Iteration 40707, loss = 63.65216351\n",
      "Iteration 40708, loss = 63.64348964\n",
      "Iteration 40709, loss = 63.63481903\n",
      "Iteration 40710, loss = 63.62615241\n",
      "Iteration 40711, loss = 63.61748811\n",
      "Iteration 40712, loss = 63.60882364\n",
      "Iteration 40713, loss = 63.60015759\n",
      "Iteration 40714, loss = 63.59149040\n",
      "Iteration 40715, loss = 63.58282367\n",
      "Iteration 40716, loss = 63.57415887\n",
      "Iteration 40717, loss = 63.56549635\n",
      "Iteration 40718, loss = 63.55683526\n",
      "Iteration 40719, loss = 63.54817445\n",
      "Iteration 40720, loss = 63.53951324\n",
      "Iteration 40721, loss = 63.53085182\n",
      "Iteration 40722, loss = 63.52219092\n",
      "Iteration 40723, loss = 63.51353125\n",
      "Iteration 40724, loss = 63.50487301\n",
      "Iteration 40725, loss = 63.49621585\n",
      "Iteration 40726, loss = 63.48755925\n",
      "Iteration 40727, loss = 63.47890284\n",
      "Iteration 40728, loss = 63.47024665\n",
      "Iteration 40729, loss = 63.46159098\n",
      "Iteration 40730, loss = 63.45293616\n",
      "Iteration 40731, loss = 63.44428235\n",
      "Iteration 40732, loss = 63.43562946\n",
      "Iteration 40733, loss = 63.42697727\n",
      "Iteration 40734, loss = 63.41832558\n",
      "Iteration 40735, loss = 63.40967433\n",
      "Iteration 40736, loss = 63.40102361\n",
      "Iteration 40737, loss = 63.39237357\n",
      "Iteration 40738, loss = 63.38372432\n",
      "Iteration 40739, loss = 63.37507588\n",
      "Iteration 40740, loss = 63.36642819\n",
      "Iteration 40741, loss = 63.35778113\n",
      "Iteration 40742, loss = 63.34913465\n",
      "Iteration 40743, loss = 63.34048875\n",
      "Iteration 40744, loss = 63.33184346\n",
      "Iteration 40745, loss = 63.32319886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40746, loss = 63.31455498\n",
      "Iteration 40747, loss = 63.30591181\n",
      "Iteration 40748, loss = 63.29726935\n",
      "Iteration 40749, loss = 63.28862753\n",
      "Iteration 40750, loss = 63.27998635\n",
      "Iteration 40751, loss = 63.27134580\n",
      "Iteration 40752, loss = 63.26270588\n",
      "Iteration 40753, loss = 63.25406663\n",
      "Iteration 40754, loss = 63.24542806\n",
      "Iteration 40755, loss = 63.23679018\n",
      "Iteration 40756, loss = 63.22815298\n",
      "Iteration 40757, loss = 63.21951645\n",
      "Iteration 40758, loss = 63.21088057\n",
      "Iteration 40759, loss = 63.20224534\n",
      "Iteration 40760, loss = 63.19361076\n",
      "Iteration 40761, loss = 63.18497684\n",
      "Iteration 40762, loss = 63.17634358\n",
      "Iteration 40763, loss = 63.16771100\n",
      "Iteration 40764, loss = 63.15907908\n",
      "Iteration 40765, loss = 63.15044784\n",
      "Iteration 40766, loss = 63.14181726\n",
      "Iteration 40767, loss = 63.13318734\n",
      "Iteration 40768, loss = 63.12455808\n",
      "Iteration 40769, loss = 63.11592947\n",
      "Iteration 40770, loss = 63.10730153\n",
      "Iteration 40771, loss = 63.09867425\n",
      "Iteration 40772, loss = 63.09004763\n",
      "Iteration 40773, loss = 63.08142168\n",
      "Iteration 40774, loss = 63.07279639\n",
      "Iteration 40775, loss = 63.06417177\n",
      "Iteration 40776, loss = 63.05554782\n",
      "Iteration 40777, loss = 63.04692452\n",
      "Iteration 40778, loss = 63.03830189\n",
      "Iteration 40779, loss = 63.02967992\n",
      "Iteration 40780, loss = 63.02105861\n",
      "Iteration 40781, loss = 63.01243796\n",
      "Iteration 40782, loss = 63.00381797\n",
      "Iteration 40783, loss = 62.99519865\n",
      "Iteration 40784, loss = 62.98657999\n",
      "Iteration 40785, loss = 62.97796200\n",
      "Iteration 40786, loss = 62.96934467\n",
      "Iteration 40787, loss = 62.96072800\n",
      "Iteration 40788, loss = 62.95211199\n",
      "Iteration 40789, loss = 62.94349665\n",
      "Iteration 40790, loss = 62.93488197\n",
      "Iteration 40791, loss = 62.92626795\n",
      "Iteration 40792, loss = 62.91765460\n",
      "Iteration 40793, loss = 62.90904190\n",
      "Iteration 40794, loss = 62.90042987\n",
      "Iteration 40795, loss = 62.89181851\n",
      "Iteration 40796, loss = 62.88320780\n",
      "Iteration 40797, loss = 62.87459776\n",
      "Iteration 40798, loss = 62.86598838\n",
      "Iteration 40799, loss = 62.85737967\n",
      "Iteration 40800, loss = 62.84877161\n",
      "Iteration 40801, loss = 62.84016422\n",
      "Iteration 40802, loss = 62.83155750\n",
      "Iteration 40803, loss = 62.82295143\n",
      "Iteration 40804, loss = 62.81434603\n",
      "Iteration 40805, loss = 62.80574129\n",
      "Iteration 40806, loss = 62.79713721\n",
      "Iteration 40807, loss = 62.78853380\n",
      "Iteration 40808, loss = 62.77993105\n",
      "Iteration 40809, loss = 62.77132896\n",
      "Iteration 40810, loss = 62.76272753\n",
      "Iteration 40811, loss = 62.75412677\n",
      "Iteration 40812, loss = 62.74552667\n",
      "Iteration 40813, loss = 62.73692723\n",
      "Iteration 40814, loss = 62.72832846\n",
      "Iteration 40815, loss = 62.71973035\n",
      "Iteration 40816, loss = 62.71113290\n",
      "Iteration 40817, loss = 62.70253611\n",
      "Iteration 40818, loss = 62.69393998\n",
      "Iteration 40819, loss = 62.68534452\n",
      "Iteration 40820, loss = 62.67674972\n",
      "Iteration 40821, loss = 62.66815559\n",
      "Iteration 40822, loss = 62.65956211\n",
      "Iteration 40823, loss = 62.65096930\n",
      "Iteration 40824, loss = 62.64237715\n",
      "Iteration 40825, loss = 62.63378567\n",
      "Iteration 40826, loss = 62.62519484\n",
      "Iteration 40827, loss = 62.61660468\n",
      "Iteration 40828, loss = 62.60801518\n",
      "Iteration 40829, loss = 62.59942635\n",
      "Iteration 40830, loss = 62.59083818\n",
      "Iteration 40831, loss = 62.58225067\n",
      "Iteration 40832, loss = 62.57366382\n",
      "Iteration 40833, loss = 62.56507763\n",
      "Iteration 40834, loss = 62.55649211\n",
      "Iteration 40835, loss = 62.54790725\n",
      "Iteration 40836, loss = 62.53932305\n",
      "Iteration 40837, loss = 62.53073952\n",
      "Iteration 40838, loss = 62.52215665\n",
      "Iteration 40839, loss = 62.51357444\n",
      "Iteration 40840, loss = 62.50499289\n",
      "Iteration 40841, loss = 62.49641200\n",
      "Iteration 40842, loss = 62.48783178\n",
      "Iteration 40843, loss = 62.47925222\n",
      "Iteration 40844, loss = 62.47067333\n",
      "Iteration 40845, loss = 62.46209510\n",
      "Iteration 40846, loss = 62.45351753\n",
      "Iteration 40847, loss = 62.44494062\n",
      "Iteration 40848, loss = 62.43636438\n",
      "Iteration 40849, loss = 62.42778881\n",
      "Iteration 40850, loss = 62.41921390\n",
      "Iteration 40851, loss = 62.41063967\n",
      "Iteration 40852, loss = 62.40206611\n",
      "Iteration 40853, loss = 62.39349324\n",
      "Iteration 40854, loss = 62.38492106\n",
      "Iteration 40855, loss = 62.37634959\n",
      "Iteration 40856, loss = 62.36777888\n",
      "Iteration 40857, loss = 62.35920896\n",
      "Iteration 40858, loss = 62.35063993\n",
      "Iteration 40859, loss = 62.34207191\n",
      "Iteration 40860, loss = 62.33350513\n",
      "Iteration 40861, loss = 62.32493994\n",
      "Iteration 40862, loss = 62.31637686\n",
      "Iteration 40863, loss = 62.30781670\n",
      "Iteration 40864, loss = 62.29926047\n",
      "Iteration 40865, loss = 62.29070935\n",
      "Iteration 40866, loss = 62.28216359\n",
      "Iteration 40867, loss = 62.27362158\n",
      "Iteration 40868, loss = 62.26507639\n",
      "Iteration 40869, loss = 62.25651795\n",
      "Iteration 40870, loss = 62.24793686\n",
      "Iteration 40871, loss = 62.23933928\n",
      "Iteration 40872, loss = 62.23074548\n",
      "Iteration 40873, loss = 62.22217507\n",
      "Iteration 40874, loss = 62.21362920\n",
      "Iteration 40875, loss = 62.20509185\n",
      "Iteration 40876, loss = 62.19654391\n",
      "Iteration 40877, loss = 62.18797715\n",
      "Iteration 40878, loss = 62.17940092\n",
      "Iteration 40879, loss = 62.17083216\n",
      "Iteration 40880, loss = 62.16227941\n",
      "Iteration 40881, loss = 62.15373617\n",
      "Iteration 40882, loss = 62.14518943\n",
      "Iteration 40883, loss = 62.13663244\n",
      "Iteration 40884, loss = 62.12806980\n",
      "Iteration 40885, loss = 62.11951158\n",
      "Iteration 40886, loss = 62.11096252\n",
      "Iteration 40887, loss = 62.10241844\n",
      "Iteration 40888, loss = 62.09387186\n",
      "Iteration 40889, loss = 62.08531969\n",
      "Iteration 40890, loss = 62.07676551\n",
      "Iteration 40891, loss = 62.06821492\n",
      "Iteration 40892, loss = 62.05966977\n",
      "Iteration 40893, loss = 62.05112702\n",
      "Iteration 40894, loss = 62.04258257\n",
      "Iteration 40895, loss = 62.03403536\n",
      "Iteration 40896, loss = 62.02548781\n",
      "Iteration 40897, loss = 62.01694288\n",
      "Iteration 40898, loss = 62.00840113\n",
      "Iteration 40899, loss = 61.99986067\n",
      "Iteration 40900, loss = 61.99131940\n",
      "Iteration 40901, loss = 61.98277706\n",
      "Iteration 40902, loss = 61.97423506\n",
      "Iteration 40903, loss = 61.96569486\n",
      "Iteration 40904, loss = 61.95715657\n",
      "Iteration 40905, loss = 61.94861912\n",
      "Iteration 40906, loss = 61.94008152\n",
      "Iteration 40907, loss = 61.93154373\n",
      "Iteration 40908, loss = 61.92300652\n",
      "Iteration 40909, loss = 61.91447059\n",
      "Iteration 40910, loss = 61.90593595\n",
      "Iteration 40911, loss = 61.89740204\n",
      "Iteration 40912, loss = 61.88886834\n",
      "Iteration 40913, loss = 61.88033486\n",
      "Iteration 40914, loss = 61.87180199\n",
      "Iteration 40915, loss = 61.86327012\n",
      "Iteration 40916, loss = 61.85473925\n",
      "Iteration 40917, loss = 61.84620910\n",
      "Iteration 40918, loss = 61.83767941\n",
      "Iteration 40919, loss = 61.82915011\n",
      "Iteration 40920, loss = 61.82062141\n",
      "Iteration 40921, loss = 61.81209352\n",
      "Iteration 40922, loss = 61.80356648\n",
      "Iteration 40923, loss = 61.79504019\n",
      "Iteration 40924, loss = 61.78651448\n",
      "Iteration 40925, loss = 61.77798929\n",
      "Iteration 40926, loss = 61.76946469\n",
      "Iteration 40927, loss = 61.76094079\n",
      "Iteration 40928, loss = 61.75241766\n",
      "Iteration 40929, loss = 61.74389525\n",
      "Iteration 40930, loss = 61.73537349\n",
      "Iteration 40931, loss = 61.72685234\n",
      "Iteration 40932, loss = 61.71833179\n",
      "Iteration 40933, loss = 61.70981190\n",
      "Iteration 40934, loss = 61.70129271\n",
      "Iteration 40935, loss = 61.69277423\n",
      "Iteration 40936, loss = 61.68425642\n",
      "Iteration 40937, loss = 61.67573926\n",
      "Iteration 40938, loss = 61.66722272\n",
      "Iteration 40939, loss = 61.65870683\n",
      "Iteration 40940, loss = 61.65019161\n",
      "Iteration 40941, loss = 61.64167707\n",
      "Iteration 40942, loss = 61.63316321\n",
      "Iteration 40943, loss = 61.62465002\n",
      "Iteration 40944, loss = 61.61613748\n",
      "Iteration 40945, loss = 61.60762559\n",
      "Iteration 40946, loss = 61.59911435\n",
      "Iteration 40947, loss = 61.59060377\n",
      "Iteration 40948, loss = 61.58209387\n",
      "Iteration 40949, loss = 61.57358464\n",
      "Iteration 40950, loss = 61.56507607\n",
      "Iteration 40951, loss = 61.55656816\n",
      "Iteration 40952, loss = 61.54806091\n",
      "Iteration 40953, loss = 61.53955431\n",
      "Iteration 40954, loss = 61.53104838\n",
      "Iteration 40955, loss = 61.52254311\n",
      "Iteration 40956, loss = 61.51403851\n",
      "Iteration 40957, loss = 61.50553457\n",
      "Iteration 40958, loss = 61.49703129\n",
      "Iteration 40959, loss = 61.48852867\n",
      "Iteration 40960, loss = 61.48002671\n",
      "Iteration 40961, loss = 61.47152541\n",
      "Iteration 40962, loss = 61.46302478\n",
      "Iteration 40963, loss = 61.45452481\n",
      "Iteration 40964, loss = 61.44602550\n",
      "Iteration 40965, loss = 61.43752685\n",
      "Iteration 40966, loss = 61.42902887\n",
      "Iteration 40967, loss = 61.42053154\n",
      "Iteration 40968, loss = 61.41203488\n",
      "Iteration 40969, loss = 61.40353888\n",
      "Iteration 40970, loss = 61.39504354\n",
      "Iteration 40971, loss = 61.38654886\n",
      "Iteration 40972, loss = 61.37805485\n",
      "Iteration 40973, loss = 61.36956150\n",
      "Iteration 40974, loss = 61.36106881\n",
      "Iteration 40975, loss = 61.35257678\n",
      "Iteration 40976, loss = 61.34408541\n",
      "Iteration 40977, loss = 61.33559470\n",
      "Iteration 40978, loss = 61.32710466\n",
      "Iteration 40979, loss = 61.31861527\n",
      "Iteration 40980, loss = 61.31012655\n",
      "Iteration 40981, loss = 61.30163850\n",
      "Iteration 40982, loss = 61.29315110\n",
      "Iteration 40983, loss = 61.28466436\n",
      "Iteration 40984, loss = 61.27617829\n",
      "Iteration 40985, loss = 61.26769288\n",
      "Iteration 40986, loss = 61.25920813\n",
      "Iteration 40987, loss = 61.25072404\n",
      "Iteration 40988, loss = 61.24224061\n",
      "Iteration 40989, loss = 61.23375785\n",
      "Iteration 40990, loss = 61.22527575\n",
      "Iteration 40991, loss = 61.21679430\n",
      "Iteration 40992, loss = 61.20831352\n",
      "Iteration 40993, loss = 61.19983341\n",
      "Iteration 40994, loss = 61.19135395\n",
      "Iteration 40995, loss = 61.18287516\n",
      "Iteration 40996, loss = 61.17439702\n",
      "Iteration 40997, loss = 61.16591955\n",
      "Iteration 40998, loss = 61.15744274\n",
      "Iteration 40999, loss = 61.14896659\n",
      "Iteration 41000, loss = 61.14049111\n",
      "Iteration 41001, loss = 61.13201628\n",
      "Iteration 41002, loss = 61.12354212\n",
      "Iteration 41003, loss = 61.11506862\n",
      "Iteration 41004, loss = 61.10659578\n",
      "Iteration 41005, loss = 61.09812360\n",
      "Iteration 41006, loss = 61.08965208\n",
      "Iteration 41007, loss = 61.08118123\n",
      "Iteration 41008, loss = 61.07271104\n",
      "Iteration 41009, loss = 61.06424150\n",
      "Iteration 41010, loss = 61.05577263\n",
      "Iteration 41011, loss = 61.04730443\n",
      "Iteration 41012, loss = 61.03883688\n",
      "Iteration 41013, loss = 61.03036999\n",
      "Iteration 41014, loss = 61.02190377\n",
      "Iteration 41015, loss = 61.01343821\n",
      "Iteration 41016, loss = 61.00497331\n",
      "Iteration 41017, loss = 60.99650907\n",
      "Iteration 41018, loss = 60.98804549\n",
      "Iteration 41019, loss = 60.97958257\n",
      "Iteration 41020, loss = 60.97112032\n",
      "Iteration 41021, loss = 60.96265873\n",
      "Iteration 41022, loss = 60.95419780\n",
      "Iteration 41023, loss = 60.94573753\n",
      "Iteration 41024, loss = 60.93727792\n",
      "Iteration 41025, loss = 60.92881897\n",
      "Iteration 41026, loss = 60.92036069\n",
      "Iteration 41027, loss = 60.91190306\n",
      "Iteration 41028, loss = 60.90344610\n",
      "Iteration 41029, loss = 60.89498980\n",
      "Iteration 41030, loss = 60.88653416\n",
      "Iteration 41031, loss = 60.87807918\n",
      "Iteration 41032, loss = 60.86962487\n",
      "Iteration 41033, loss = 60.86117121\n",
      "Iteration 41034, loss = 60.85271822\n",
      "Iteration 41035, loss = 60.84426589\n",
      "Iteration 41036, loss = 60.83581421\n",
      "Iteration 41037, loss = 60.82736321\n",
      "Iteration 41038, loss = 60.81891286\n",
      "Iteration 41039, loss = 60.81046317\n",
      "Iteration 41040, loss = 60.80201415\n",
      "Iteration 41041, loss = 60.79356579\n",
      "Iteration 41042, loss = 60.78511809\n",
      "Iteration 41043, loss = 60.77667105\n",
      "Iteration 41044, loss = 60.76822468\n",
      "Iteration 41045, loss = 60.75977897\n",
      "Iteration 41046, loss = 60.75133392\n",
      "Iteration 41047, loss = 60.74288954\n",
      "Iteration 41048, loss = 60.73444584\n",
      "Iteration 41049, loss = 60.72600281\n",
      "Iteration 41050, loss = 60.71756047\n",
      "Iteration 41051, loss = 60.70911882\n",
      "Iteration 41052, loss = 60.70067790\n",
      "Iteration 41053, loss = 60.69223771\n",
      "Iteration 41054, loss = 60.68379829\n",
      "Iteration 41055, loss = 60.67535964\n",
      "Iteration 41056, loss = 60.66692175\n",
      "Iteration 41057, loss = 60.65848448\n",
      "Iteration 41058, loss = 60.65004763\n",
      "Iteration 41059, loss = 60.64161094\n",
      "Iteration 41060, loss = 60.63317437\n",
      "Iteration 41061, loss = 60.62473825\n",
      "Iteration 41062, loss = 60.61630308\n",
      "Iteration 41063, loss = 60.60786919\n",
      "Iteration 41064, loss = 60.59943645\n",
      "Iteration 41065, loss = 60.59100447\n",
      "Iteration 41066, loss = 60.58257284\n",
      "Iteration 41067, loss = 60.57414144\n",
      "Iteration 41068, loss = 60.56571048\n",
      "Iteration 41069, loss = 60.55728034\n",
      "Iteration 41070, loss = 60.54885123\n",
      "Iteration 41071, loss = 60.54042306\n",
      "Iteration 41072, loss = 60.53199558\n",
      "Iteration 41073, loss = 60.52356860\n",
      "Iteration 41074, loss = 60.51514219\n",
      "Iteration 41075, loss = 60.50671660\n",
      "Iteration 41076, loss = 60.49829209\n",
      "Iteration 41077, loss = 60.48986882\n",
      "Iteration 41078, loss = 60.48144687\n",
      "Iteration 41079, loss = 60.47302644\n",
      "Iteration 41080, loss = 60.46460791\n",
      "Iteration 41081, loss = 60.45619197\n",
      "Iteration 41082, loss = 60.44777932\n",
      "Iteration 41083, loss = 60.43937048\n",
      "Iteration 41084, loss = 60.43096479\n",
      "Iteration 41085, loss = 60.42256011\n",
      "Iteration 41086, loss = 60.41415101\n",
      "Iteration 41087, loss = 60.40573163\n",
      "Iteration 41088, loss = 60.39729800\n",
      "Iteration 41089, loss = 60.38885556\n",
      "Iteration 41090, loss = 60.38041631\n",
      "Iteration 41091, loss = 60.37199143\n",
      "Iteration 41092, loss = 60.36358256\n",
      "Iteration 41093, loss = 60.35518201\n",
      "Iteration 41094, loss = 60.34677893\n",
      "Iteration 41095, loss = 60.33836592\n",
      "Iteration 41096, loss = 60.32994383\n",
      "Iteration 41097, loss = 60.32152023\n",
      "Iteration 41098, loss = 60.31310349\n",
      "Iteration 41099, loss = 60.30469609\n",
      "Iteration 41100, loss = 60.29629379\n",
      "Iteration 41101, loss = 60.28789001\n",
      "Iteration 41102, loss = 60.27948088\n",
      "Iteration 41103, loss = 60.27106783\n",
      "Iteration 41104, loss = 60.26265554\n",
      "Iteration 41105, loss = 60.25424788\n",
      "Iteration 41106, loss = 60.24584500\n",
      "Iteration 41107, loss = 60.23744391\n",
      "Iteration 41108, loss = 60.22904138\n",
      "Iteration 41109, loss = 60.22063639\n",
      "Iteration 41110, loss = 60.21223054\n",
      "Iteration 41111, loss = 60.20382633\n",
      "Iteration 41112, loss = 60.19542505\n",
      "Iteration 41113, loss = 60.18702605\n",
      "Iteration 41114, loss = 60.17862760\n",
      "Iteration 41115, loss = 60.17022839\n",
      "Iteration 41116, loss = 60.16182846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41117, loss = 60.15342889\n",
      "Iteration 41118, loss = 60.14503077\n",
      "Iteration 41119, loss = 60.13663443\n",
      "Iteration 41120, loss = 60.12823931\n",
      "Iteration 41121, loss = 60.11984455\n",
      "Iteration 41122, loss = 60.11144971\n",
      "Iteration 41123, loss = 60.10305495\n",
      "Iteration 41124, loss = 60.09466084\n",
      "Iteration 41125, loss = 60.08626785\n",
      "Iteration 41126, loss = 60.07787603\n",
      "Iteration 41127, loss = 60.06948508\n",
      "Iteration 41128, loss = 60.06109460\n",
      "Iteration 41129, loss = 60.05270443\n",
      "Iteration 41130, loss = 60.04431466\n",
      "Iteration 41131, loss = 60.03592556\n",
      "Iteration 41132, loss = 60.02753733\n",
      "Iteration 41133, loss = 60.01915001\n",
      "Iteration 41134, loss = 60.01076345\n",
      "Iteration 41135, loss = 60.00237748\n",
      "Iteration 41136, loss = 59.99399200\n",
      "Iteration 41137, loss = 59.98560706\n",
      "Iteration 41138, loss = 59.97722276\n",
      "Iteration 41139, loss = 59.96883920\n",
      "Iteration 41140, loss = 59.96045642\n",
      "Iteration 41141, loss = 59.95207437\n",
      "Iteration 41142, loss = 59.94369297\n",
      "Iteration 41143, loss = 59.93531216\n",
      "Iteration 41144, loss = 59.92693195\n",
      "Iteration 41145, loss = 59.91855237\n",
      "Iteration 41146, loss = 59.91017346\n",
      "Iteration 41147, loss = 59.90179527\n",
      "Iteration 41148, loss = 59.89341777\n",
      "Iteration 41149, loss = 59.88504096\n",
      "Iteration 41150, loss = 59.87666479\n",
      "Iteration 41151, loss = 59.86828926\n",
      "Iteration 41152, loss = 59.85991435\n",
      "Iteration 41153, loss = 59.85154010\n",
      "Iteration 41154, loss = 59.84316652\n",
      "Iteration 41155, loss = 59.83479362\n",
      "Iteration 41156, loss = 59.82642140\n",
      "Iteration 41157, loss = 59.81804985\n",
      "Iteration 41158, loss = 59.80967895\n",
      "Iteration 41159, loss = 59.80130870\n",
      "Iteration 41160, loss = 59.79293910\n",
      "Iteration 41161, loss = 59.78457016\n",
      "Iteration 41162, loss = 59.77620188\n",
      "Iteration 41163, loss = 59.76783427\n",
      "Iteration 41164, loss = 59.75946732\n",
      "Iteration 41165, loss = 59.75110104\n",
      "Iteration 41166, loss = 59.74273542\n",
      "Iteration 41167, loss = 59.73437046\n",
      "Iteration 41168, loss = 59.72600616\n",
      "Iteration 41169, loss = 59.71764251\n",
      "Iteration 41170, loss = 59.70927952\n",
      "Iteration 41171, loss = 59.70091719\n",
      "Iteration 41172, loss = 59.69255553\n",
      "Iteration 41173, loss = 59.68419453\n",
      "Iteration 41174, loss = 59.67583419\n",
      "Iteration 41175, loss = 59.66747451\n",
      "Iteration 41176, loss = 59.65911550\n",
      "Iteration 41177, loss = 59.65075714\n",
      "Iteration 41178, loss = 59.64239944\n",
      "Iteration 41179, loss = 59.63404240\n",
      "Iteration 41180, loss = 59.62568602\n",
      "Iteration 41181, loss = 59.61733030\n",
      "Iteration 41182, loss = 59.60897525\n",
      "Iteration 41183, loss = 59.60062085\n",
      "Iteration 41184, loss = 59.59226712\n",
      "Iteration 41185, loss = 59.58391404\n",
      "Iteration 41186, loss = 59.57556163\n",
      "Iteration 41187, loss = 59.56720988\n",
      "Iteration 41188, loss = 59.55885879\n",
      "Iteration 41189, loss = 59.55050835\n",
      "Iteration 41190, loss = 59.54215858\n",
      "Iteration 41191, loss = 59.53380947\n",
      "Iteration 41192, loss = 59.52546102\n",
      "Iteration 41193, loss = 59.51711323\n",
      "Iteration 41194, loss = 59.50876610\n",
      "Iteration 41195, loss = 59.50041963\n",
      "Iteration 41196, loss = 59.49207382\n",
      "Iteration 41197, loss = 59.48372867\n",
      "Iteration 41198, loss = 59.47538419\n",
      "Iteration 41199, loss = 59.46704036\n",
      "Iteration 41200, loss = 59.45869719\n",
      "Iteration 41201, loss = 59.45035469\n",
      "Iteration 41202, loss = 59.44201284\n",
      "Iteration 41203, loss = 59.43367165\n",
      "Iteration 41204, loss = 59.42533113\n",
      "Iteration 41205, loss = 59.41699126\n",
      "Iteration 41206, loss = 59.40865206\n",
      "Iteration 41207, loss = 59.40031351\n",
      "Iteration 41208, loss = 59.39197563\n",
      "Iteration 41209, loss = 59.38363841\n",
      "Iteration 41210, loss = 59.37530185\n",
      "Iteration 41211, loss = 59.36696594\n",
      "Iteration 41212, loss = 59.35863070\n",
      "Iteration 41213, loss = 59.35029612\n",
      "Iteration 41214, loss = 59.34196220\n",
      "Iteration 41215, loss = 59.33362894\n",
      "Iteration 41216, loss = 59.32529634\n",
      "Iteration 41217, loss = 59.31696440\n",
      "Iteration 41218, loss = 59.30863312\n",
      "Iteration 41219, loss = 59.30030250\n",
      "Iteration 41220, loss = 59.29197254\n",
      "Iteration 41221, loss = 59.28364324\n",
      "Iteration 41222, loss = 59.27531460\n",
      "Iteration 41223, loss = 59.26698662\n",
      "Iteration 41224, loss = 59.25865930\n",
      "Iteration 41225, loss = 59.25033265\n",
      "Iteration 41226, loss = 59.24200665\n",
      "Iteration 41227, loss = 59.23368131\n",
      "Iteration 41228, loss = 59.22535663\n",
      "Iteration 41229, loss = 59.21703262\n",
      "Iteration 41230, loss = 59.20870926\n",
      "Iteration 41231, loss = 59.20038656\n",
      "Iteration 41232, loss = 59.19206453\n",
      "Iteration 41233, loss = 59.18374315\n",
      "Iteration 41234, loss = 59.17542244\n",
      "Iteration 41235, loss = 59.16710238\n",
      "Iteration 41236, loss = 59.15878299\n",
      "Iteration 41237, loss = 59.15046425\n",
      "Iteration 41238, loss = 59.14214618\n",
      "Iteration 41239, loss = 59.13382876\n",
      "Iteration 41240, loss = 59.12551201\n",
      "Iteration 41241, loss = 59.11719592\n",
      "Iteration 41242, loss = 59.10888048\n",
      "Iteration 41243, loss = 59.10056571\n",
      "Iteration 41244, loss = 59.09225159\n",
      "Iteration 41245, loss = 59.08393814\n",
      "Iteration 41246, loss = 59.07562535\n",
      "Iteration 41247, loss = 59.06731322\n",
      "Iteration 41248, loss = 59.05900174\n",
      "Iteration 41249, loss = 59.05069093\n",
      "Iteration 41250, loss = 59.04238078\n",
      "Iteration 41251, loss = 59.03407128\n",
      "Iteration 41252, loss = 59.02576245\n",
      "Iteration 41253, loss = 59.01745428\n",
      "Iteration 41254, loss = 59.00914677\n",
      "Iteration 41255, loss = 59.00083992\n",
      "Iteration 41256, loss = 58.99253372\n",
      "Iteration 41257, loss = 58.98422819\n",
      "Iteration 41258, loss = 58.97592332\n",
      "Iteration 41259, loss = 58.96761911\n",
      "Iteration 41260, loss = 58.95931556\n",
      "Iteration 41261, loss = 58.95101267\n",
      "Iteration 41262, loss = 58.94271044\n",
      "Iteration 41263, loss = 58.93440886\n",
      "Iteration 41264, loss = 58.92610795\n",
      "Iteration 41265, loss = 58.91780770\n",
      "Iteration 41266, loss = 58.90950812\n",
      "Iteration 41267, loss = 58.90120919\n",
      "Iteration 41268, loss = 58.89291092\n",
      "Iteration 41269, loss = 58.88461332\n",
      "Iteration 41270, loss = 58.87631639\n",
      "Iteration 41271, loss = 58.86802013\n",
      "Iteration 41272, loss = 58.85972455\n",
      "Iteration 41273, loss = 58.85142966\n",
      "Iteration 41274, loss = 58.84313550\n",
      "Iteration 41275, loss = 58.83484209\n",
      "Iteration 41276, loss = 58.82654952\n",
      "Iteration 41277, loss = 58.81825792\n",
      "Iteration 41278, loss = 58.80996751\n",
      "Iteration 41279, loss = 58.80167870\n",
      "Iteration 41280, loss = 58.79339215\n",
      "Iteration 41281, loss = 58.78510898\n",
      "Iteration 41282, loss = 58.77683099\n",
      "Iteration 41283, loss = 58.76856048\n",
      "Iteration 41284, loss = 58.76029989\n",
      "Iteration 41285, loss = 58.75204814\n",
      "Iteration 41286, loss = 58.74379676\n",
      "Iteration 41287, loss = 58.73552314\n",
      "Iteration 41288, loss = 58.72720772\n",
      "Iteration 41289, loss = 58.71885890\n",
      "Iteration 41290, loss = 58.71052400\n",
      "Iteration 41291, loss = 58.70223913\n",
      "Iteration 41292, loss = 58.69399193\n",
      "Iteration 41293, loss = 58.68573834\n",
      "Iteration 41294, loss = 58.67744668\n",
      "Iteration 41295, loss = 58.66913020\n",
      "Iteration 41296, loss = 58.66082909\n",
      "Iteration 41297, loss = 58.65256143\n",
      "Iteration 41298, loss = 58.64430507\n",
      "Iteration 41299, loss = 58.63602964\n",
      "Iteration 41300, loss = 58.62773359\n",
      "Iteration 41301, loss = 58.61944159\n",
      "Iteration 41302, loss = 58.61117022\n",
      "Iteration 41303, loss = 58.60290844\n",
      "Iteration 41304, loss = 58.59463634\n",
      "Iteration 41305, loss = 58.58635164\n",
      "Iteration 41306, loss = 58.57806943\n",
      "Iteration 41307, loss = 58.56979989\n",
      "Iteration 41308, loss = 58.56153600\n",
      "Iteration 41309, loss = 58.55326575\n",
      "Iteration 41310, loss = 58.54498851\n",
      "Iteration 41311, loss = 58.53671375\n",
      "Iteration 41312, loss = 58.52844694\n",
      "Iteration 41313, loss = 58.52018316\n",
      "Iteration 41314, loss = 58.51191539\n",
      "Iteration 41315, loss = 58.50364398\n",
      "Iteration 41316, loss = 58.49537483\n",
      "Iteration 41317, loss = 58.48711074\n",
      "Iteration 41318, loss = 58.47884837\n",
      "Iteration 41319, loss = 58.47058368\n",
      "Iteration 41320, loss = 58.46231722\n",
      "Iteration 41321, loss = 58.45405258\n",
      "Iteration 41322, loss = 58.44579122\n",
      "Iteration 41323, loss = 58.43753103\n",
      "Iteration 41324, loss = 58.42926969\n",
      "Iteration 41325, loss = 58.42100761\n",
      "Iteration 41326, loss = 58.41274690\n",
      "Iteration 41327, loss = 58.40448839\n",
      "Iteration 41328, loss = 58.39623084\n",
      "Iteration 41329, loss = 58.38797290\n",
      "Iteration 41330, loss = 58.37971479\n",
      "Iteration 41331, loss = 58.37145773\n",
      "Iteration 41332, loss = 58.36320221\n",
      "Iteration 41333, loss = 58.35494758\n",
      "Iteration 41334, loss = 58.34669302\n",
      "Iteration 41335, loss = 58.33843861\n",
      "Iteration 41336, loss = 58.33018504\n",
      "Iteration 41337, loss = 58.32193264\n",
      "Iteration 41338, loss = 58.31368108\n",
      "Iteration 41339, loss = 58.30542986\n",
      "Iteration 41340, loss = 58.29717899\n",
      "Iteration 41341, loss = 58.28892883\n",
      "Iteration 41342, loss = 58.28067962\n",
      "Iteration 41343, loss = 58.27243122\n",
      "Iteration 41344, loss = 58.26418334\n",
      "Iteration 41345, loss = 58.25593590\n",
      "Iteration 41346, loss = 58.24768911\n",
      "Iteration 41347, loss = 58.23944314\n",
      "Iteration 41348, loss = 58.23119796\n",
      "Iteration 41349, loss = 58.22295338\n",
      "Iteration 41350, loss = 58.21470933\n",
      "Iteration 41351, loss = 58.20646589\n",
      "Iteration 41352, loss = 58.19822319\n",
      "Iteration 41353, loss = 58.18998123\n",
      "Iteration 41354, loss = 58.18173994\n",
      "Iteration 41355, loss = 58.17349924\n",
      "Iteration 41356, loss = 58.16525915\n",
      "Iteration 41357, loss = 58.15701974\n",
      "Iteration 41358, loss = 58.14878104\n",
      "Iteration 41359, loss = 58.14054303\n",
      "Iteration 41360, loss = 58.13230565\n",
      "Iteration 41361, loss = 58.12406889\n",
      "Iteration 41362, loss = 58.11583278\n",
      "Iteration 41363, loss = 58.10759736\n",
      "Iteration 41364, loss = 58.09936262\n",
      "Iteration 41365, loss = 58.09112854\n",
      "Iteration 41366, loss = 58.08289510\n",
      "Iteration 41367, loss = 58.07466230\n",
      "Iteration 41368, loss = 58.06643017\n",
      "Iteration 41369, loss = 58.05819872\n",
      "Iteration 41370, loss = 58.04996793\n",
      "Iteration 41371, loss = 58.04173779\n",
      "Iteration 41372, loss = 58.03350831\n",
      "Iteration 41373, loss = 58.02527947\n",
      "Iteration 41374, loss = 58.01705131\n",
      "Iteration 41375, loss = 58.00882381\n",
      "Iteration 41376, loss = 58.00059697\n",
      "Iteration 41377, loss = 57.99237079\n",
      "Iteration 41378, loss = 57.98414526\n",
      "Iteration 41379, loss = 57.97592038\n",
      "Iteration 41380, loss = 57.96769618\n",
      "Iteration 41381, loss = 57.95947263\n",
      "Iteration 41382, loss = 57.95124975\n",
      "Iteration 41383, loss = 57.94302752\n",
      "Iteration 41384, loss = 57.93480594\n",
      "Iteration 41385, loss = 57.92658503\n",
      "Iteration 41386, loss = 57.91836478\n",
      "Iteration 41387, loss = 57.91014519\n",
      "Iteration 41388, loss = 57.90192625\n",
      "Iteration 41389, loss = 57.89370798\n",
      "Iteration 41390, loss = 57.88549036\n",
      "Iteration 41391, loss = 57.87727341\n",
      "Iteration 41392, loss = 57.86905711\n",
      "Iteration 41393, loss = 57.86084147\n",
      "Iteration 41394, loss = 57.85262650\n",
      "Iteration 41395, loss = 57.84441218\n",
      "Iteration 41396, loss = 57.83619852\n",
      "Iteration 41397, loss = 57.82798551\n",
      "Iteration 41398, loss = 57.81977317\n",
      "Iteration 41399, loss = 57.81156149\n",
      "Iteration 41400, loss = 57.80335047\n",
      "Iteration 41401, loss = 57.79514010\n",
      "Iteration 41402, loss = 57.78693040\n",
      "Iteration 41403, loss = 57.77872135\n",
      "Iteration 41404, loss = 57.77051296\n",
      "Iteration 41405, loss = 57.76230523\n",
      "Iteration 41406, loss = 57.75409816\n",
      "Iteration 41407, loss = 57.74589175\n",
      "Iteration 41408, loss = 57.73768600\n",
      "Iteration 41409, loss = 57.72948091\n",
      "Iteration 41410, loss = 57.72127648\n",
      "Iteration 41411, loss = 57.71307270\n",
      "Iteration 41412, loss = 57.70486959\n",
      "Iteration 41413, loss = 57.69666713\n",
      "Iteration 41414, loss = 57.68846534\n",
      "Iteration 41415, loss = 57.68026420\n",
      "Iteration 41416, loss = 57.67206372\n",
      "Iteration 41417, loss = 57.66386390\n",
      "Iteration 41418, loss = 57.65566474\n",
      "Iteration 41419, loss = 57.64746624\n",
      "Iteration 41420, loss = 57.63926839\n",
      "Iteration 41421, loss = 57.63107121\n",
      "Iteration 41422, loss = 57.62287468\n",
      "Iteration 41423, loss = 57.61467882\n",
      "Iteration 41424, loss = 57.60648361\n",
      "Iteration 41425, loss = 57.59828906\n",
      "Iteration 41426, loss = 57.59009517\n",
      "Iteration 41427, loss = 57.58190194\n",
      "Iteration 41428, loss = 57.57370937\n",
      "Iteration 41429, loss = 57.56551746\n",
      "Iteration 41430, loss = 57.55732621\n",
      "Iteration 41431, loss = 57.54913561\n",
      "Iteration 41432, loss = 57.54094568\n",
      "Iteration 41433, loss = 57.53275640\n",
      "Iteration 41434, loss = 57.52456778\n",
      "Iteration 41435, loss = 57.51637982\n",
      "Iteration 41436, loss = 57.50819252\n",
      "Iteration 41437, loss = 57.50000588\n",
      "Iteration 41438, loss = 57.49181990\n",
      "Iteration 41439, loss = 57.48363457\n",
      "Iteration 41440, loss = 57.47544991\n",
      "Iteration 41441, loss = 57.46726590\n",
      "Iteration 41442, loss = 57.45908256\n",
      "Iteration 41443, loss = 57.45089987\n",
      "Iteration 41444, loss = 57.44271784\n",
      "Iteration 41445, loss = 57.43453647\n",
      "Iteration 41446, loss = 57.42635576\n",
      "Iteration 41447, loss = 57.41817570\n",
      "Iteration 41448, loss = 57.40999631\n",
      "Iteration 41449, loss = 57.40181757\n",
      "Iteration 41450, loss = 57.39363950\n",
      "Iteration 41451, loss = 57.38546208\n",
      "Iteration 41452, loss = 57.37728532\n",
      "Iteration 41453, loss = 57.36910922\n",
      "Iteration 41454, loss = 57.36093378\n",
      "Iteration 41455, loss = 57.35275899\n",
      "Iteration 41456, loss = 57.34458487\n",
      "Iteration 41457, loss = 57.33641140\n",
      "Iteration 41458, loss = 57.32823860\n",
      "Iteration 41459, loss = 57.32006645\n",
      "Iteration 41460, loss = 57.31189496\n",
      "Iteration 41461, loss = 57.30372413\n",
      "Iteration 41462, loss = 57.29555396\n",
      "Iteration 41463, loss = 57.28738444\n",
      "Iteration 41464, loss = 57.27921559\n",
      "Iteration 41465, loss = 57.27104739\n",
      "Iteration 41466, loss = 57.26287985\n",
      "Iteration 41467, loss = 57.25471298\n",
      "Iteration 41468, loss = 57.24654676\n",
      "Iteration 41469, loss = 57.23838119\n",
      "Iteration 41470, loss = 57.23021629\n",
      "Iteration 41471, loss = 57.22205205\n",
      "Iteration 41472, loss = 57.21388846\n",
      "Iteration 41473, loss = 57.20572554\n",
      "Iteration 41474, loss = 57.19756327\n",
      "Iteration 41475, loss = 57.18940166\n",
      "Iteration 41476, loss = 57.18124071\n",
      "Iteration 41477, loss = 57.17308041\n",
      "Iteration 41478, loss = 57.16492078\n",
      "Iteration 41479, loss = 57.15676181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41480, loss = 57.14860349\n",
      "Iteration 41481, loss = 57.14044583\n",
      "Iteration 41482, loss = 57.13228883\n",
      "Iteration 41483, loss = 57.12413249\n",
      "Iteration 41484, loss = 57.11597681\n",
      "Iteration 41485, loss = 57.10782178\n",
      "Iteration 41486, loss = 57.09966742\n",
      "Iteration 41487, loss = 57.09151371\n",
      "Iteration 41488, loss = 57.08336066\n",
      "Iteration 41489, loss = 57.07520827\n",
      "Iteration 41490, loss = 57.06705654\n",
      "Iteration 41491, loss = 57.05890547\n",
      "Iteration 41492, loss = 57.05075506\n",
      "Iteration 41493, loss = 57.04260530\n",
      "Iteration 41494, loss = 57.03445620\n",
      "Iteration 41495, loss = 57.02630776\n",
      "Iteration 41496, loss = 57.01815998\n",
      "Iteration 41497, loss = 57.01001286\n",
      "Iteration 41498, loss = 57.00186640\n",
      "Iteration 41499, loss = 56.99372059\n",
      "Iteration 41500, loss = 56.98557545\n",
      "Iteration 41501, loss = 56.97743096\n",
      "Iteration 41502, loss = 56.96928713\n",
      "Iteration 41503, loss = 56.96114396\n",
      "Iteration 41504, loss = 56.95300144\n",
      "Iteration 41505, loss = 56.94485959\n",
      "Iteration 41506, loss = 56.93671839\n",
      "Iteration 41507, loss = 56.92857786\n",
      "Iteration 41508, loss = 56.92043798\n",
      "Iteration 41509, loss = 56.91229876\n",
      "Iteration 41510, loss = 56.90416019\n",
      "Iteration 41511, loss = 56.89602229\n",
      "Iteration 41512, loss = 56.88788504\n",
      "Iteration 41513, loss = 56.87974846\n",
      "Iteration 41514, loss = 56.87161253\n",
      "Iteration 41515, loss = 56.86347726\n",
      "Iteration 41516, loss = 56.85534264\n",
      "Iteration 41517, loss = 56.84720869\n",
      "Iteration 41518, loss = 56.83907540\n",
      "Iteration 41519, loss = 56.83094276\n",
      "Iteration 41520, loss = 56.82281078\n",
      "Iteration 41521, loss = 56.81467946\n",
      "Iteration 41522, loss = 56.80654880\n",
      "Iteration 41523, loss = 56.79841879\n",
      "Iteration 41524, loss = 56.79028945\n",
      "Iteration 41525, loss = 56.78216076\n",
      "Iteration 41526, loss = 56.77403273\n",
      "Iteration 41527, loss = 56.76590536\n",
      "Iteration 41528, loss = 56.75777864\n",
      "Iteration 41529, loss = 56.74965259\n",
      "Iteration 41530, loss = 56.74152719\n",
      "Iteration 41531, loss = 56.73340245\n",
      "Iteration 41532, loss = 56.72527838\n",
      "Iteration 41533, loss = 56.71715495\n",
      "Iteration 41534, loss = 56.70903219\n",
      "Iteration 41535, loss = 56.70091008\n",
      "Iteration 41536, loss = 56.69278864\n",
      "Iteration 41537, loss = 56.68466785\n",
      "Iteration 41538, loss = 56.67654772\n",
      "Iteration 41539, loss = 56.66842825\n",
      "Iteration 41540, loss = 56.66030943\n",
      "Iteration 41541, loss = 56.65219128\n",
      "Iteration 41542, loss = 56.64407378\n",
      "Iteration 41543, loss = 56.63595695\n",
      "Iteration 41544, loss = 56.62784078\n",
      "Iteration 41545, loss = 56.61972527\n",
      "Iteration 41546, loss = 56.61161043\n",
      "Iteration 41547, loss = 56.60349626\n",
      "Iteration 41548, loss = 56.59538279\n",
      "Iteration 41549, loss = 56.58727003\n",
      "Iteration 41550, loss = 56.57915803\n",
      "Iteration 41551, loss = 56.57104685\n",
      "Iteration 41552, loss = 56.56293655\n",
      "Iteration 41553, loss = 56.55482720\n",
      "Iteration 41554, loss = 56.54671874\n",
      "Iteration 41555, loss = 56.53861076\n",
      "Iteration 41556, loss = 56.53050257\n",
      "Iteration 41557, loss = 56.52239365\n",
      "Iteration 41558, loss = 56.51428467\n",
      "Iteration 41559, loss = 56.50617714\n",
      "Iteration 41560, loss = 56.49807184\n",
      "Iteration 41561, loss = 56.48996808\n",
      "Iteration 41562, loss = 56.48186447\n",
      "Iteration 41563, loss = 56.47376039\n",
      "Iteration 41564, loss = 56.46565657\n",
      "Iteration 41565, loss = 56.45755432\n",
      "Iteration 41566, loss = 56.44945405\n",
      "Iteration 41567, loss = 56.44135516\n",
      "Iteration 41568, loss = 56.43325731\n",
      "Iteration 41569, loss = 56.42516142\n",
      "Iteration 41570, loss = 56.41706946\n",
      "Iteration 41571, loss = 56.40898352\n",
      "Iteration 41572, loss = 56.40090503\n",
      "Iteration 41573, loss = 56.39283476\n",
      "Iteration 41574, loss = 56.38476932\n",
      "Iteration 41575, loss = 56.37669850\n",
      "Iteration 41576, loss = 56.36860202\n",
      "Iteration 41577, loss = 56.36046992\n",
      "Iteration 41578, loss = 56.35231975\n",
      "Iteration 41579, loss = 56.34419181\n",
      "Iteration 41580, loss = 56.33610657\n",
      "Iteration 41581, loss = 56.32804624\n",
      "Iteration 41582, loss = 56.31997507\n",
      "Iteration 41583, loss = 56.31187215\n",
      "Iteration 41584, loss = 56.30375172\n",
      "Iteration 41585, loss = 56.29564548\n",
      "Iteration 41586, loss = 56.28756643\n",
      "Iteration 41587, loss = 56.27949725\n",
      "Iteration 41588, loss = 56.27141387\n",
      "Iteration 41589, loss = 56.26331281\n",
      "Iteration 41590, loss = 56.25521197\n",
      "Iteration 41591, loss = 56.24712706\n",
      "Iteration 41592, loss = 56.23905350\n",
      "Iteration 41593, loss = 56.23097541\n",
      "Iteration 41594, loss = 56.22288594\n",
      "Iteration 41595, loss = 56.21479361\n",
      "Iteration 41596, loss = 56.20670975\n",
      "Iteration 41597, loss = 56.19863442\n",
      "Iteration 41598, loss = 56.19055848\n",
      "Iteration 41599, loss = 56.18247609\n",
      "Iteration 41600, loss = 56.17439095\n",
      "Iteration 41601, loss = 56.16631022\n",
      "Iteration 41602, loss = 56.15823531\n",
      "Iteration 41603, loss = 56.15016129\n",
      "Iteration 41604, loss = 56.14208395\n",
      "Iteration 41605, loss = 56.13400460\n",
      "Iteration 41606, loss = 56.12592752\n",
      "Iteration 41607, loss = 56.11785429\n",
      "Iteration 41608, loss = 56.10978247\n",
      "Iteration 41609, loss = 56.10170923\n",
      "Iteration 41610, loss = 56.09363474\n",
      "Iteration 41611, loss = 56.08556138\n",
      "Iteration 41612, loss = 56.07749055\n",
      "Iteration 41613, loss = 56.06942123\n",
      "Iteration 41614, loss = 56.06135162\n",
      "Iteration 41615, loss = 56.05328139\n",
      "Iteration 41616, loss = 56.04521172\n",
      "Iteration 41617, loss = 56.03714372\n",
      "Iteration 41618, loss = 56.02907712\n",
      "Iteration 41619, loss = 56.02101088\n",
      "Iteration 41620, loss = 56.01294451\n",
      "Iteration 41621, loss = 56.00487850\n",
      "Iteration 41622, loss = 55.99681358\n",
      "Iteration 41623, loss = 55.98874988\n",
      "Iteration 41624, loss = 55.98068687\n",
      "Iteration 41625, loss = 55.97262410\n",
      "Iteration 41626, loss = 55.96456167\n",
      "Iteration 41627, loss = 55.95650001\n",
      "Iteration 41628, loss = 55.94843934\n",
      "Iteration 41629, loss = 55.94037950\n",
      "Iteration 41630, loss = 55.93232015\n",
      "Iteration 41631, loss = 55.92426123\n",
      "Iteration 41632, loss = 55.91620291\n",
      "Iteration 41633, loss = 55.90814541\n",
      "Iteration 41634, loss = 55.90008872\n",
      "Iteration 41635, loss = 55.89203269\n",
      "Iteration 41636, loss = 55.88397719\n",
      "Iteration 41637, loss = 55.87592225\n",
      "Iteration 41638, loss = 55.86786799\n",
      "Iteration 41639, loss = 55.85981450\n",
      "Iteration 41640, loss = 55.85176172\n",
      "Iteration 41641, loss = 55.84370956\n",
      "Iteration 41642, loss = 55.83565799\n",
      "Iteration 41643, loss = 55.82760704\n",
      "Iteration 41644, loss = 55.81955678\n",
      "Iteration 41645, loss = 55.81150724\n",
      "Iteration 41646, loss = 55.80345837\n",
      "Iteration 41647, loss = 55.79541013\n",
      "Iteration 41648, loss = 55.78736251\n",
      "Iteration 41649, loss = 55.77931554\n",
      "Iteration 41650, loss = 55.77126925\n",
      "Iteration 41651, loss = 55.76322364\n",
      "Iteration 41652, loss = 55.75517870\n",
      "Iteration 41653, loss = 55.74713439\n",
      "Iteration 41654, loss = 55.73909073\n",
      "Iteration 41655, loss = 55.73104772\n",
      "Iteration 41656, loss = 55.72300538\n",
      "Iteration 41657, loss = 55.71496371\n",
      "Iteration 41658, loss = 55.70692270\n",
      "Iteration 41659, loss = 55.69888234\n",
      "Iteration 41660, loss = 55.69084262\n",
      "Iteration 41661, loss = 55.68280356\n",
      "Iteration 41662, loss = 55.67476517\n",
      "Iteration 41663, loss = 55.66672744\n",
      "Iteration 41664, loss = 55.65869037\n",
      "Iteration 41665, loss = 55.65065395\n",
      "Iteration 41666, loss = 55.64261819\n",
      "Iteration 41667, loss = 55.63458307\n",
      "Iteration 41668, loss = 55.62654862\n",
      "Iteration 41669, loss = 55.61851484\n",
      "Iteration 41670, loss = 55.61048171\n",
      "Iteration 41671, loss = 55.60244923\n",
      "Iteration 41672, loss = 55.59441741\n",
      "Iteration 41673, loss = 55.58638625\n",
      "Iteration 41674, loss = 55.57835574\n",
      "Iteration 41675, loss = 55.57032589\n",
      "Iteration 41676, loss = 55.56229670\n",
      "Iteration 41677, loss = 55.55426817\n",
      "Iteration 41678, loss = 55.54624029\n",
      "Iteration 41679, loss = 55.53821307\n",
      "Iteration 41680, loss = 55.53018651\n",
      "Iteration 41681, loss = 55.52216061\n",
      "Iteration 41682, loss = 55.51413536\n",
      "Iteration 41683, loss = 55.50611077\n",
      "Iteration 41684, loss = 55.49808684\n",
      "Iteration 41685, loss = 55.49006356\n",
      "Iteration 41686, loss = 55.48204094\n",
      "Iteration 41687, loss = 55.47401898\n",
      "Iteration 41688, loss = 55.46599767\n",
      "Iteration 41689, loss = 55.45797703\n",
      "Iteration 41690, loss = 55.44995704\n",
      "Iteration 41691, loss = 55.44193770\n",
      "Iteration 41692, loss = 55.43391903\n",
      "Iteration 41693, loss = 55.42590101\n",
      "Iteration 41694, loss = 55.41788364\n",
      "Iteration 41695, loss = 55.40986694\n",
      "Iteration 41696, loss = 55.40185089\n",
      "Iteration 41697, loss = 55.39383550\n",
      "Iteration 41698, loss = 55.38582077\n",
      "Iteration 41699, loss = 55.37780669\n",
      "Iteration 41700, loss = 55.36979327\n",
      "Iteration 41701, loss = 55.36178050\n",
      "Iteration 41702, loss = 55.35376840\n",
      "Iteration 41703, loss = 55.34575695\n",
      "Iteration 41704, loss = 55.33774616\n",
      "Iteration 41705, loss = 55.32973602\n",
      "Iteration 41706, loss = 55.32172654\n",
      "Iteration 41707, loss = 55.31371772\n",
      "Iteration 41708, loss = 55.30570956\n",
      "Iteration 41709, loss = 55.29770205\n",
      "Iteration 41710, loss = 55.28969520\n",
      "Iteration 41711, loss = 55.28168901\n",
      "Iteration 41712, loss = 55.27368347\n",
      "Iteration 41713, loss = 55.26567859\n",
      "Iteration 41714, loss = 55.25767437\n",
      "Iteration 41715, loss = 55.24967080\n",
      "Iteration 41716, loss = 55.24166789\n",
      "Iteration 41717, loss = 55.23366564\n",
      "Iteration 41718, loss = 55.22566404\n",
      "Iteration 41719, loss = 55.21766311\n",
      "Iteration 41720, loss = 55.20966282\n",
      "Iteration 41721, loss = 55.20166320\n",
      "Iteration 41722, loss = 55.19366423\n",
      "Iteration 41723, loss = 55.18566592\n",
      "Iteration 41724, loss = 55.17766827\n",
      "Iteration 41725, loss = 55.16967127\n",
      "Iteration 41726, loss = 55.16167493\n",
      "Iteration 41727, loss = 55.15367925\n",
      "Iteration 41728, loss = 55.14568422\n",
      "Iteration 41729, loss = 55.13768985\n",
      "Iteration 41730, loss = 55.12969613\n",
      "Iteration 41731, loss = 55.12170308\n",
      "Iteration 41732, loss = 55.11371068\n",
      "Iteration 41733, loss = 55.10571894\n",
      "Iteration 41734, loss = 55.09772785\n",
      "Iteration 41735, loss = 55.08973742\n",
      "Iteration 41736, loss = 55.08174765\n",
      "Iteration 41737, loss = 55.07375853\n",
      "Iteration 41738, loss = 55.06577007\n",
      "Iteration 41739, loss = 55.05778227\n",
      "Iteration 41740, loss = 55.04979512\n",
      "Iteration 41741, loss = 55.04180864\n",
      "Iteration 41742, loss = 55.03382280\n",
      "Iteration 41743, loss = 55.02583763\n",
      "Iteration 41744, loss = 55.01785311\n",
      "Iteration 41745, loss = 55.00986925\n",
      "Iteration 41746, loss = 55.00188604\n",
      "Iteration 41747, loss = 54.99390349\n",
      "Iteration 41748, loss = 54.98592160\n",
      "Iteration 41749, loss = 54.97794036\n",
      "Iteration 41750, loss = 54.96995979\n",
      "Iteration 41751, loss = 54.96197986\n",
      "Iteration 41752, loss = 54.95400060\n",
      "Iteration 41753, loss = 54.94602199\n",
      "Iteration 41754, loss = 54.93804404\n",
      "Iteration 41755, loss = 54.93006674\n",
      "Iteration 41756, loss = 54.92209010\n",
      "Iteration 41757, loss = 54.91411412\n",
      "Iteration 41758, loss = 54.90613879\n",
      "Iteration 41759, loss = 54.89816412\n",
      "Iteration 41760, loss = 54.89019011\n",
      "Iteration 41761, loss = 54.88221676\n",
      "Iteration 41762, loss = 54.87424406\n",
      "Iteration 41763, loss = 54.86627201\n",
      "Iteration 41764, loss = 54.85830063\n",
      "Iteration 41765, loss = 54.85032990\n",
      "Iteration 41766, loss = 54.84235982\n",
      "Iteration 41767, loss = 54.83439041\n",
      "Iteration 41768, loss = 54.82642165\n",
      "Iteration 41769, loss = 54.81845354\n",
      "Iteration 41770, loss = 54.81048610\n",
      "Iteration 41771, loss = 54.80251931\n",
      "Iteration 41772, loss = 54.79455317\n",
      "Iteration 41773, loss = 54.78658769\n",
      "Iteration 41774, loss = 54.77862287\n",
      "Iteration 41775, loss = 54.77065871\n",
      "Iteration 41776, loss = 54.76269520\n",
      "Iteration 41777, loss = 54.75473235\n",
      "Iteration 41778, loss = 54.74677015\n",
      "Iteration 41779, loss = 54.73880861\n",
      "Iteration 41780, loss = 54.73084773\n",
      "Iteration 41781, loss = 54.72288750\n",
      "Iteration 41782, loss = 54.71492793\n",
      "Iteration 41783, loss = 54.70696902\n",
      "Iteration 41784, loss = 54.69901077\n",
      "Iteration 41785, loss = 54.69105316\n",
      "Iteration 41786, loss = 54.68309622\n",
      "Iteration 41787, loss = 54.67513993\n",
      "Iteration 41788, loss = 54.66718430\n",
      "Iteration 41789, loss = 54.65922933\n",
      "Iteration 41790, loss = 54.65127501\n",
      "Iteration 41791, loss = 54.64332135\n",
      "Iteration 41792, loss = 54.63536834\n",
      "Iteration 41793, loss = 54.62741599\n",
      "Iteration 41794, loss = 54.61946430\n",
      "Iteration 41795, loss = 54.61151326\n",
      "Iteration 41796, loss = 54.60356288\n",
      "Iteration 41797, loss = 54.59561316\n",
      "Iteration 41798, loss = 54.58766409\n",
      "Iteration 41799, loss = 54.57971568\n",
      "Iteration 41800, loss = 54.57176792\n",
      "Iteration 41801, loss = 54.56382082\n",
      "Iteration 41802, loss = 54.55587438\n",
      "Iteration 41803, loss = 54.54792860\n",
      "Iteration 41804, loss = 54.53998347\n",
      "Iteration 41805, loss = 54.53203899\n",
      "Iteration 41806, loss = 54.52409517\n",
      "Iteration 41807, loss = 54.51615201\n",
      "Iteration 41808, loss = 54.50820951\n",
      "Iteration 41809, loss = 54.50026766\n",
      "Iteration 41810, loss = 54.49232647\n",
      "Iteration 41811, loss = 54.48438593\n",
      "Iteration 41812, loss = 54.47644605\n",
      "Iteration 41813, loss = 54.46850683\n",
      "Iteration 41814, loss = 54.46056826\n",
      "Iteration 41815, loss = 54.45263035\n",
      "Iteration 41816, loss = 54.44469309\n",
      "Iteration 41817, loss = 54.43675649\n",
      "Iteration 41818, loss = 54.42882055\n",
      "Iteration 41819, loss = 54.42088526\n",
      "Iteration 41820, loss = 54.41295063\n",
      "Iteration 41821, loss = 54.40501666\n",
      "Iteration 41822, loss = 54.39708334\n",
      "Iteration 41823, loss = 54.38915068\n",
      "Iteration 41824, loss = 54.38121867\n",
      "Iteration 41825, loss = 54.37328732\n",
      "Iteration 41826, loss = 54.36535663\n",
      "Iteration 41827, loss = 54.35742659\n",
      "Iteration 41828, loss = 54.34949721\n",
      "Iteration 41829, loss = 54.34156849\n",
      "Iteration 41830, loss = 54.33364043\n",
      "Iteration 41831, loss = 54.32571302\n",
      "Iteration 41832, loss = 54.31778628\n",
      "Iteration 41833, loss = 54.30986020\n",
      "Iteration 41834, loss = 54.30193480\n",
      "Iteration 41835, loss = 54.29401009\n",
      "Iteration 41836, loss = 54.28608608\n",
      "Iteration 41837, loss = 54.27816283\n",
      "Iteration 41838, loss = 54.27024039\n",
      "Iteration 41839, loss = 54.26231890\n",
      "Iteration 41840, loss = 54.25439859\n",
      "Iteration 41841, loss = 54.24647984\n",
      "Iteration 41842, loss = 54.23856335\n",
      "Iteration 41843, loss = 54.23065028\n",
      "Iteration 41844, loss = 54.22274253\n",
      "Iteration 41845, loss = 54.21484264\n",
      "Iteration 41846, loss = 54.20695342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41847, loss = 54.19907402\n",
      "Iteration 41848, loss = 54.19119543\n",
      "Iteration 41849, loss = 54.18329276\n",
      "Iteration 41850, loss = 54.17534449\n",
      "Iteration 41851, loss = 54.16736122\n",
      "Iteration 41852, loss = 54.15939597\n",
      "Iteration 41853, loss = 54.15148600\n",
      "Iteration 41854, loss = 54.14361336\n",
      "Iteration 41855, loss = 54.13572826\n",
      "Iteration 41856, loss = 54.12780015\n",
      "Iteration 41857, loss = 54.11985041\n",
      "Iteration 41858, loss = 54.11192373\n",
      "Iteration 41859, loss = 54.10403209\n",
      "Iteration 41860, loss = 54.09614504\n",
      "Iteration 41861, loss = 54.08823277\n",
      "Iteration 41862, loss = 54.08030271\n",
      "Iteration 41863, loss = 54.07238479\n",
      "Iteration 41864, loss = 54.06448965\n",
      "Iteration 41865, loss = 54.05659797\n",
      "Iteration 41866, loss = 54.04869036\n",
      "Iteration 41867, loss = 54.04077258\n",
      "Iteration 41868, loss = 54.03286362\n",
      "Iteration 41869, loss = 54.02496837\n",
      "Iteration 41870, loss = 54.01707375\n",
      "Iteration 41871, loss = 54.00916932\n",
      "Iteration 41872, loss = 54.00126070\n",
      "Iteration 41873, loss = 53.99335906\n",
      "Iteration 41874, loss = 53.98546511\n",
      "Iteration 41875, loss = 53.97757006\n",
      "Iteration 41876, loss = 53.96966913\n",
      "Iteration 41877, loss = 53.96176722\n",
      "Iteration 41878, loss = 53.95387056\n",
      "Iteration 41879, loss = 53.94597818\n",
      "Iteration 41880, loss = 53.93808455\n",
      "Iteration 41881, loss = 53.93018777\n",
      "Iteration 41882, loss = 53.92229139\n",
      "Iteration 41883, loss = 53.91439862\n",
      "Iteration 41884, loss = 53.90650816\n",
      "Iteration 41885, loss = 53.89861681\n",
      "Iteration 41886, loss = 53.89072404\n",
      "Iteration 41887, loss = 53.88283219\n",
      "Iteration 41888, loss = 53.87494283\n",
      "Iteration 41889, loss = 53.86705488\n",
      "Iteration 41890, loss = 53.85916648\n",
      "Iteration 41891, loss = 53.85127757\n",
      "Iteration 41892, loss = 53.84338961\n",
      "Iteration 41893, loss = 53.83550340\n",
      "Iteration 41894, loss = 53.82761821\n",
      "Iteration 41895, loss = 53.81973299\n",
      "Iteration 41896, loss = 53.81184779\n",
      "Iteration 41897, loss = 53.80396346\n",
      "Iteration 41898, loss = 53.79608043\n",
      "Iteration 41899, loss = 53.78819823\n",
      "Iteration 41900, loss = 53.78031627\n",
      "Iteration 41901, loss = 53.77243459\n",
      "Iteration 41902, loss = 53.76455369\n",
      "Iteration 41903, loss = 53.75667383\n",
      "Iteration 41904, loss = 53.74879475\n",
      "Iteration 41905, loss = 53.74091610\n",
      "Iteration 41906, loss = 53.73303787\n",
      "Iteration 41907, loss = 53.72516034\n",
      "Iteration 41908, loss = 53.71728369\n",
      "Iteration 41909, loss = 53.70940778\n",
      "Iteration 41910, loss = 53.70153241\n",
      "Iteration 41911, loss = 53.69365755\n",
      "Iteration 41912, loss = 53.68578336\n",
      "Iteration 41913, loss = 53.67790994\n",
      "Iteration 41914, loss = 53.67003726\n",
      "Iteration 41915, loss = 53.66216518\n",
      "Iteration 41916, loss = 53.65429366\n",
      "Iteration 41917, loss = 53.64642278\n",
      "Iteration 41918, loss = 53.63855261\n",
      "Iteration 41919, loss = 53.63068316\n",
      "Iteration 41920, loss = 53.62281435\n",
      "Iteration 41921, loss = 53.61494615\n",
      "Iteration 41922, loss = 53.60707857\n",
      "Iteration 41923, loss = 53.59921168\n",
      "Iteration 41924, loss = 53.59134548\n",
      "Iteration 41925, loss = 53.58347994\n",
      "Iteration 41926, loss = 53.57561503\n",
      "Iteration 41927, loss = 53.56775075\n",
      "Iteration 41928, loss = 53.55988714\n",
      "Iteration 41929, loss = 53.55202420\n",
      "Iteration 41930, loss = 53.54416192\n",
      "Iteration 41931, loss = 53.53630030\n",
      "Iteration 41932, loss = 53.52843931\n",
      "Iteration 41933, loss = 53.52057898\n",
      "Iteration 41934, loss = 53.51271931\n",
      "Iteration 41935, loss = 53.50486030\n",
      "Iteration 41936, loss = 53.49700195\n",
      "Iteration 41937, loss = 53.48914425\n",
      "Iteration 41938, loss = 53.48128720\n",
      "Iteration 41939, loss = 53.47343080\n",
      "Iteration 41940, loss = 53.46557507\n",
      "Iteration 41941, loss = 53.45771999\n",
      "Iteration 41942, loss = 53.44986557\n",
      "Iteration 41943, loss = 53.44201180\n",
      "Iteration 41944, loss = 53.43415868\n",
      "Iteration 41945, loss = 53.42630622\n",
      "Iteration 41946, loss = 53.41845441\n",
      "Iteration 41947, loss = 53.41060327\n",
      "Iteration 41948, loss = 53.40275278\n",
      "Iteration 41949, loss = 53.39490294\n",
      "Iteration 41950, loss = 53.38705375\n",
      "Iteration 41951, loss = 53.37920522\n",
      "Iteration 41952, loss = 53.37135735\n",
      "Iteration 41953, loss = 53.36351013\n",
      "Iteration 41954, loss = 53.35566357\n",
      "Iteration 41955, loss = 53.34781766\n",
      "Iteration 41956, loss = 53.33997241\n",
      "Iteration 41957, loss = 53.33212781\n",
      "Iteration 41958, loss = 53.32428387\n",
      "Iteration 41959, loss = 53.31644058\n",
      "Iteration 41960, loss = 53.30859795\n",
      "Iteration 41961, loss = 53.30075597\n",
      "Iteration 41962, loss = 53.29291465\n",
      "Iteration 41963, loss = 53.28507398\n",
      "Iteration 41964, loss = 53.27723397\n",
      "Iteration 41965, loss = 53.26939461\n",
      "Iteration 41966, loss = 53.26155591\n",
      "Iteration 41967, loss = 53.25371786\n",
      "Iteration 41968, loss = 53.24588047\n",
      "Iteration 41969, loss = 53.23804373\n",
      "Iteration 41970, loss = 53.23020765\n",
      "Iteration 41971, loss = 53.22237222\n",
      "Iteration 41972, loss = 53.21453745\n",
      "Iteration 41973, loss = 53.20670333\n",
      "Iteration 41974, loss = 53.19886987\n",
      "Iteration 41975, loss = 53.19103706\n",
      "Iteration 41976, loss = 53.18320491\n",
      "Iteration 41977, loss = 53.17537341\n",
      "Iteration 41978, loss = 53.16754257\n",
      "Iteration 41979, loss = 53.15971238\n",
      "Iteration 41980, loss = 53.15188285\n",
      "Iteration 41981, loss = 53.14405397\n",
      "Iteration 41982, loss = 53.13622575\n",
      "Iteration 41983, loss = 53.12839818\n",
      "Iteration 41984, loss = 53.12057127\n",
      "Iteration 41985, loss = 53.11274501\n",
      "Iteration 41986, loss = 53.10491941\n",
      "Iteration 41987, loss = 53.09709446\n",
      "Iteration 41988, loss = 53.08927017\n",
      "Iteration 41989, loss = 53.08144653\n",
      "Iteration 41990, loss = 53.07362354\n",
      "Iteration 41991, loss = 53.06580122\n",
      "Iteration 41992, loss = 53.05797954\n",
      "Iteration 41993, loss = 53.05015852\n",
      "Iteration 41994, loss = 53.04233816\n",
      "Iteration 41995, loss = 53.03451845\n",
      "Iteration 41996, loss = 53.02669939\n",
      "Iteration 41997, loss = 53.01888099\n",
      "Iteration 41998, loss = 53.01106325\n",
      "Iteration 41999, loss = 53.00324616\n",
      "Iteration 42000, loss = 52.99542973\n",
      "Iteration 42001, loss = 52.98761395\n",
      "Iteration 42002, loss = 52.97979882\n",
      "Iteration 42003, loss = 52.97198435\n",
      "Iteration 42004, loss = 52.96417054\n",
      "Iteration 42005, loss = 52.95635738\n",
      "Iteration 42006, loss = 52.94854489\n",
      "Iteration 42007, loss = 52.94073305\n",
      "Iteration 42008, loss = 52.93292187\n",
      "Iteration 42009, loss = 52.92511135\n",
      "Iteration 42010, loss = 52.91730150\n",
      "Iteration 42011, loss = 52.90949233\n",
      "Iteration 42012, loss = 52.90168384\n",
      "Iteration 42013, loss = 52.89387605\n",
      "Iteration 42014, loss = 52.88606897\n",
      "Iteration 42015, loss = 52.87826262\n",
      "Iteration 42016, loss = 52.87045699\n",
      "Iteration 42017, loss = 52.86265206\n",
      "Iteration 42018, loss = 52.85484777\n",
      "Iteration 42019, loss = 52.84704396\n",
      "Iteration 42020, loss = 52.83924049\n",
      "Iteration 42021, loss = 52.83143733\n",
      "Iteration 42022, loss = 52.82363461\n",
      "Iteration 42023, loss = 52.81583265\n",
      "Iteration 42024, loss = 52.80803169\n",
      "Iteration 42025, loss = 52.80023176\n",
      "Iteration 42026, loss = 52.79243268\n",
      "Iteration 42027, loss = 52.78463419\n",
      "Iteration 42028, loss = 52.77683612\n",
      "Iteration 42029, loss = 52.76903845\n",
      "Iteration 42030, loss = 52.76124134\n",
      "Iteration 42031, loss = 52.75344499\n",
      "Iteration 42032, loss = 52.74564949\n",
      "Iteration 42033, loss = 52.73785481\n",
      "Iteration 42034, loss = 52.73006079\n",
      "Iteration 42035, loss = 52.72226731\n",
      "Iteration 42036, loss = 52.71447435\n",
      "Iteration 42037, loss = 52.70668199\n",
      "Iteration 42038, loss = 52.69889032\n",
      "Iteration 42039, loss = 52.69109941\n",
      "Iteration 42040, loss = 52.68330923\n",
      "Iteration 42041, loss = 52.67551971\n",
      "Iteration 42042, loss = 52.66773079\n",
      "Iteration 42043, loss = 52.65994246\n",
      "Iteration 42044, loss = 52.65215475\n",
      "Iteration 42045, loss = 52.64436772\n",
      "Iteration 42046, loss = 52.63658140\n",
      "Iteration 42047, loss = 52.62879576\n",
      "Iteration 42048, loss = 52.62101079\n",
      "Iteration 42049, loss = 52.61322644\n",
      "Iteration 42050, loss = 52.60544271\n",
      "Iteration 42051, loss = 52.59765963\n",
      "Iteration 42052, loss = 52.58987720\n",
      "Iteration 42053, loss = 52.58209546\n",
      "Iteration 42054, loss = 52.57431439\n",
      "Iteration 42055, loss = 52.56653397\n",
      "Iteration 42056, loss = 52.55875420\n",
      "Iteration 42057, loss = 52.55097507\n",
      "Iteration 42058, loss = 52.54319658\n",
      "Iteration 42059, loss = 52.53541875\n",
      "Iteration 42060, loss = 52.52764158\n",
      "Iteration 42061, loss = 52.51986508\n",
      "Iteration 42062, loss = 52.51208924\n",
      "Iteration 42063, loss = 52.50431405\n",
      "Iteration 42064, loss = 52.49653950\n",
      "Iteration 42065, loss = 52.48876560\n",
      "Iteration 42066, loss = 52.48099236\n",
      "Iteration 42067, loss = 52.47321977\n",
      "Iteration 42068, loss = 52.46544785\n",
      "Iteration 42069, loss = 52.45767658\n",
      "Iteration 42070, loss = 52.44990596\n",
      "Iteration 42071, loss = 52.44213600\n",
      "Iteration 42072, loss = 52.43436669\n",
      "Iteration 42073, loss = 52.42659803\n",
      "Iteration 42074, loss = 52.41883002\n",
      "Iteration 42075, loss = 52.41106268\n",
      "Iteration 42076, loss = 52.40329598\n",
      "Iteration 42077, loss = 52.39552995\n",
      "Iteration 42078, loss = 52.38776456\n",
      "Iteration 42079, loss = 52.37999983\n",
      "Iteration 42080, loss = 52.37223575\n",
      "Iteration 42081, loss = 52.36447233\n",
      "Iteration 42082, loss = 52.35670956\n",
      "Iteration 42083, loss = 52.34894745\n",
      "Iteration 42084, loss = 52.34118599\n",
      "Iteration 42085, loss = 52.33342518\n",
      "Iteration 42086, loss = 52.32566503\n",
      "Iteration 42087, loss = 52.31790553\n",
      "Iteration 42088, loss = 52.31014669\n",
      "Iteration 42089, loss = 52.30238850\n",
      "Iteration 42090, loss = 52.29463096\n",
      "Iteration 42091, loss = 52.28687408\n",
      "Iteration 42092, loss = 52.27911786\n",
      "Iteration 42093, loss = 52.27136228\n",
      "Iteration 42094, loss = 52.26360736\n",
      "Iteration 42095, loss = 52.25585310\n",
      "Iteration 42096, loss = 52.24809949\n",
      "Iteration 42097, loss = 52.24034653\n",
      "Iteration 42098, loss = 52.23259423\n",
      "Iteration 42099, loss = 52.22484258\n",
      "Iteration 42100, loss = 52.21709159\n",
      "Iteration 42101, loss = 52.20934125\n",
      "Iteration 42102, loss = 52.20159156\n",
      "Iteration 42103, loss = 52.19384253\n",
      "Iteration 42104, loss = 52.18609415\n",
      "Iteration 42105, loss = 52.17834642\n",
      "Iteration 42106, loss = 52.17059935\n",
      "Iteration 42107, loss = 52.16285294\n",
      "Iteration 42108, loss = 52.15510718\n",
      "Iteration 42109, loss = 52.14736207\n",
      "Iteration 42110, loss = 52.13961761\n",
      "Iteration 42111, loss = 52.13187381\n",
      "Iteration 42112, loss = 52.12413066\n",
      "Iteration 42113, loss = 52.11638817\n",
      "Iteration 42114, loss = 52.10864633\n",
      "Iteration 42115, loss = 52.10090515\n",
      "Iteration 42116, loss = 52.09316462\n",
      "Iteration 42117, loss = 52.08542474\n",
      "Iteration 42118, loss = 52.07768552\n",
      "Iteration 42119, loss = 52.06994695\n",
      "Iteration 42120, loss = 52.06220904\n",
      "Iteration 42121, loss = 52.05447178\n",
      "Iteration 42122, loss = 52.04673518\n",
      "Iteration 42123, loss = 52.03899923\n",
      "Iteration 42124, loss = 52.03126395\n",
      "Iteration 42125, loss = 52.02352932\n",
      "Iteration 42126, loss = 52.01579537\n",
      "Iteration 42127, loss = 52.00806209\n",
      "Iteration 42128, loss = 52.00032950\n",
      "Iteration 42129, loss = 51.99259763\n",
      "Iteration 42130, loss = 51.98486652\n",
      "Iteration 42131, loss = 51.97713623\n",
      "Iteration 42132, loss = 51.96940690\n",
      "Iteration 42133, loss = 51.96167873\n",
      "Iteration 42134, loss = 51.95395206\n",
      "Iteration 42135, loss = 51.94622746\n",
      "Iteration 42136, loss = 51.93850587\n",
      "Iteration 42137, loss = 51.93078864\n",
      "Iteration 42138, loss = 51.92307766\n",
      "Iteration 42139, loss = 51.91537438\n",
      "Iteration 42140, loss = 51.90767855\n",
      "Iteration 42141, loss = 51.89998301\n",
      "Iteration 42142, loss = 51.89227334\n",
      "Iteration 42143, loss = 51.88453141\n",
      "Iteration 42144, loss = 51.87676035\n",
      "Iteration 42145, loss = 51.86899002\n",
      "Iteration 42146, loss = 51.86125392\n",
      "Iteration 42147, loss = 51.85355445\n",
      "Iteration 42148, loss = 51.84586400\n",
      "Iteration 42149, loss = 51.83815217\n",
      "Iteration 42150, loss = 51.83041215\n",
      "Iteration 42151, loss = 51.82266715\n",
      "Iteration 42152, loss = 51.81494329\n",
      "Iteration 42153, loss = 51.80724159\n",
      "Iteration 42154, loss = 51.79954085\n",
      "Iteration 42155, loss = 51.79182325\n",
      "Iteration 42156, loss = 51.78409305\n",
      "Iteration 42157, loss = 51.77636854\n",
      "Iteration 42158, loss = 51.76865951\n",
      "Iteration 42159, loss = 51.76095755\n",
      "Iteration 42160, loss = 51.75324873\n",
      "Iteration 42161, loss = 51.74553025\n",
      "Iteration 42162, loss = 51.73781159\n",
      "Iteration 42163, loss = 51.73010161\n",
      "Iteration 42164, loss = 51.72239841\n",
      "Iteration 42165, loss = 51.71469354\n",
      "Iteration 42166, loss = 51.70698284\n",
      "Iteration 42167, loss = 51.69927041\n",
      "Iteration 42168, loss = 51.69156242\n",
      "Iteration 42169, loss = 51.68385954\n",
      "Iteration 42170, loss = 51.67615729\n",
      "Iteration 42171, loss = 51.66845209\n",
      "Iteration 42172, loss = 51.66074520\n",
      "Iteration 42173, loss = 51.65304034\n",
      "Iteration 42174, loss = 51.64533899\n",
      "Iteration 42175, loss = 51.63763914\n",
      "Iteration 42176, loss = 51.62993823\n",
      "Iteration 42177, loss = 51.62223614\n",
      "Iteration 42178, loss = 51.61453486\n",
      "Iteration 42179, loss = 51.60683584\n",
      "Iteration 42180, loss = 51.59913846\n",
      "Iteration 42181, loss = 51.59144116\n",
      "Iteration 42182, loss = 51.58374331\n",
      "Iteration 42183, loss = 51.57604575\n",
      "Iteration 42184, loss = 51.56834957\n",
      "Iteration 42185, loss = 51.56065485\n",
      "Iteration 42186, loss = 51.55296081\n",
      "Iteration 42187, loss = 51.54526677\n",
      "Iteration 42188, loss = 51.53757292\n",
      "Iteration 42189, loss = 51.52987989\n",
      "Iteration 42190, loss = 51.52218804\n",
      "Iteration 42191, loss = 51.51449709\n",
      "Iteration 42192, loss = 51.50680656\n",
      "Iteration 42193, loss = 51.49911632\n",
      "Iteration 42194, loss = 51.49142664\n",
      "Iteration 42195, loss = 51.48373784\n",
      "Iteration 42196, loss = 51.47604995\n",
      "Iteration 42197, loss = 51.46836273\n",
      "Iteration 42198, loss = 51.46067597\n",
      "Iteration 42199, loss = 51.45298971\n",
      "Iteration 42200, loss = 51.44530412\n",
      "Iteration 42201, loss = 51.43761934\n",
      "Iteration 42202, loss = 51.42993532\n",
      "Iteration 42203, loss = 51.42225191\n",
      "Iteration 42204, loss = 51.41456905\n",
      "Iteration 42205, loss = 51.40688678\n",
      "Iteration 42206, loss = 51.39920521\n",
      "Iteration 42207, loss = 51.39152438\n",
      "Iteration 42208, loss = 51.38384425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42209, loss = 51.37616475\n",
      "Iteration 42210, loss = 51.36848585\n",
      "Iteration 42211, loss = 51.36080761\n",
      "Iteration 42212, loss = 51.35313007\n",
      "Iteration 42213, loss = 51.34545327\n",
      "Iteration 42214, loss = 51.33777719\n",
      "Iteration 42215, loss = 51.33010179\n",
      "Iteration 42216, loss = 51.32242705\n",
      "Iteration 42217, loss = 51.31475297\n",
      "Iteration 42218, loss = 51.30707950\n",
      "Iteration 42219, loss = 51.29940656\n",
      "Iteration 42220, loss = 51.29173403\n",
      "Iteration 42221, loss = 51.28406191\n",
      "Iteration 42222, loss = 51.27639031\n",
      "Iteration 42223, loss = 51.26871945\n",
      "Iteration 42224, loss = 51.26104948\n",
      "Iteration 42225, loss = 51.25338045\n",
      "Iteration 42226, loss = 51.24571222\n",
      "Iteration 42227, loss = 51.23804465\n",
      "Iteration 42228, loss = 51.23037758\n",
      "Iteration 42229, loss = 51.22271098\n",
      "Iteration 42230, loss = 51.21504491\n",
      "Iteration 42231, loss = 51.20737951\n",
      "Iteration 42232, loss = 51.19971488\n",
      "Iteration 42233, loss = 51.19205102\n",
      "Iteration 42234, loss = 51.18438790\n",
      "Iteration 42235, loss = 51.17672541\n",
      "Iteration 42236, loss = 51.16906351\n",
      "Iteration 42237, loss = 51.16140217\n",
      "Iteration 42238, loss = 51.15374145\n",
      "Iteration 42239, loss = 51.14608140\n",
      "Iteration 42240, loss = 51.13842205\n",
      "Iteration 42241, loss = 51.13076342\n",
      "Iteration 42242, loss = 51.12310546\n",
      "Iteration 42243, loss = 51.11544813\n",
      "Iteration 42244, loss = 51.10779143\n",
      "Iteration 42245, loss = 51.10013534\n",
      "Iteration 42246, loss = 51.09247989\n",
      "Iteration 42247, loss = 51.08482512\n",
      "Iteration 42248, loss = 51.07717102\n",
      "Iteration 42249, loss = 51.06951759\n",
      "Iteration 42250, loss = 51.06186483\n",
      "Iteration 42251, loss = 51.05421270\n",
      "Iteration 42252, loss = 51.04656122\n",
      "Iteration 42253, loss = 51.03891037\n",
      "Iteration 42254, loss = 51.03126017\n",
      "Iteration 42255, loss = 51.02361064\n",
      "Iteration 42256, loss = 51.01596176\n",
      "Iteration 42257, loss = 51.00831355\n",
      "Iteration 42258, loss = 51.00066599\n",
      "Iteration 42259, loss = 50.99301909\n",
      "Iteration 42260, loss = 50.98537283\n",
      "Iteration 42261, loss = 50.97772721\n",
      "Iteration 42262, loss = 50.97008225\n",
      "Iteration 42263, loss = 50.96243794\n",
      "Iteration 42264, loss = 50.95479429\n",
      "Iteration 42265, loss = 50.94715129\n",
      "Iteration 42266, loss = 50.93950895\n",
      "Iteration 42267, loss = 50.93186726\n",
      "Iteration 42268, loss = 50.92422623\n",
      "Iteration 42269, loss = 50.91658584\n",
      "Iteration 42270, loss = 50.90894610\n",
      "Iteration 42271, loss = 50.90130702\n",
      "Iteration 42272, loss = 50.89366859\n",
      "Iteration 42273, loss = 50.88603081\n",
      "Iteration 42274, loss = 50.87839369\n",
      "Iteration 42275, loss = 50.87075722\n",
      "Iteration 42276, loss = 50.86312140\n",
      "Iteration 42277, loss = 50.85548624\n",
      "Iteration 42278, loss = 50.84785173\n",
      "Iteration 42279, loss = 50.84021787\n",
      "Iteration 42280, loss = 50.83258466\n",
      "Iteration 42281, loss = 50.82495210\n",
      "Iteration 42282, loss = 50.81732020\n",
      "Iteration 42283, loss = 50.80968895\n",
      "Iteration 42284, loss = 50.80205835\n",
      "Iteration 42285, loss = 50.79442841\n",
      "Iteration 42286, loss = 50.78679912\n",
      "Iteration 42287, loss = 50.77917048\n",
      "Iteration 42288, loss = 50.77154249\n",
      "Iteration 42289, loss = 50.76391516\n",
      "Iteration 42290, loss = 50.75628848\n",
      "Iteration 42291, loss = 50.74866245\n",
      "Iteration 42292, loss = 50.74103707\n",
      "Iteration 42293, loss = 50.73341235\n",
      "Iteration 42294, loss = 50.72578827\n",
      "Iteration 42295, loss = 50.71816485\n",
      "Iteration 42296, loss = 50.71054209\n",
      "Iteration 42297, loss = 50.70291997\n",
      "Iteration 42298, loss = 50.69529851\n",
      "Iteration 42299, loss = 50.68767770\n",
      "Iteration 42300, loss = 50.68005755\n",
      "Iteration 42301, loss = 50.67243804\n",
      "Iteration 42302, loss = 50.66481919\n",
      "Iteration 42303, loss = 50.65720099\n",
      "Iteration 42304, loss = 50.64958344\n",
      "Iteration 42305, loss = 50.64196655\n",
      "Iteration 42306, loss = 50.63435031\n",
      "Iteration 42307, loss = 50.62673472\n",
      "Iteration 42308, loss = 50.61911978\n",
      "Iteration 42309, loss = 50.61150549\n",
      "Iteration 42310, loss = 50.60389186\n",
      "Iteration 42311, loss = 50.59627888\n",
      "Iteration 42312, loss = 50.58866655\n",
      "Iteration 42313, loss = 50.58105488\n",
      "Iteration 42314, loss = 50.57344385\n",
      "Iteration 42315, loss = 50.56583348\n",
      "Iteration 42316, loss = 50.55822376\n",
      "Iteration 42317, loss = 50.55061470\n",
      "Iteration 42318, loss = 50.54300628\n",
      "Iteration 42319, loss = 50.53539852\n",
      "Iteration 42320, loss = 50.52779141\n",
      "Iteration 42321, loss = 50.52018495\n",
      "Iteration 42322, loss = 50.51257915\n",
      "Iteration 42323, loss = 50.50497400\n",
      "Iteration 42324, loss = 50.49736950\n",
      "Iteration 42325, loss = 50.48976565\n",
      "Iteration 42326, loss = 50.48216245\n",
      "Iteration 42327, loss = 50.47455991\n",
      "Iteration 42328, loss = 50.46695802\n",
      "Iteration 42329, loss = 50.45935678\n",
      "Iteration 42330, loss = 50.45175619\n",
      "Iteration 42331, loss = 50.44415626\n",
      "Iteration 42332, loss = 50.43655697\n",
      "Iteration 42333, loss = 50.42895834\n",
      "Iteration 42334, loss = 50.42136036\n",
      "Iteration 42335, loss = 50.41376304\n",
      "Iteration 42336, loss = 50.40616636\n",
      "Iteration 42337, loss = 50.39857034\n",
      "Iteration 42338, loss = 50.39097497\n",
      "Iteration 42339, loss = 50.38338026\n",
      "Iteration 42340, loss = 50.37578619\n",
      "Iteration 42341, loss = 50.36819278\n",
      "Iteration 42342, loss = 50.36060002\n",
      "Iteration 42343, loss = 50.35300791\n",
      "Iteration 42344, loss = 50.34541645\n",
      "Iteration 42345, loss = 50.33782565\n",
      "Iteration 42346, loss = 50.33023549\n",
      "Iteration 42347, loss = 50.32264599\n",
      "Iteration 42348, loss = 50.31505714\n",
      "Iteration 42349, loss = 50.30746895\n",
      "Iteration 42350, loss = 50.29988140\n",
      "Iteration 42351, loss = 50.29229451\n",
      "Iteration 42352, loss = 50.28470827\n",
      "Iteration 42353, loss = 50.27712268\n",
      "Iteration 42354, loss = 50.26953775\n",
      "Iteration 42355, loss = 50.26195346\n",
      "Iteration 42356, loss = 50.25436983\n",
      "Iteration 42357, loss = 50.24678685\n",
      "Iteration 42358, loss = 50.23920452\n",
      "Iteration 42359, loss = 50.23162285\n",
      "Iteration 42360, loss = 50.22404182\n",
      "Iteration 42361, loss = 50.21646145\n",
      "Iteration 42362, loss = 50.20888173\n",
      "Iteration 42363, loss = 50.20130266\n",
      "Iteration 42364, loss = 50.19372424\n",
      "Iteration 42365, loss = 50.18614648\n",
      "Iteration 42366, loss = 50.17856937\n",
      "Iteration 42367, loss = 50.17099291\n",
      "Iteration 42368, loss = 50.16341710\n",
      "Iteration 42369, loss = 50.15584194\n",
      "Iteration 42370, loss = 50.14826744\n",
      "Iteration 42371, loss = 50.14069359\n",
      "Iteration 42372, loss = 50.13312039\n",
      "Iteration 42373, loss = 50.12554784\n",
      "Iteration 42374, loss = 50.11797594\n",
      "Iteration 42375, loss = 50.11040470\n",
      "Iteration 42376, loss = 50.10283411\n",
      "Iteration 42377, loss = 50.09526418\n",
      "Iteration 42378, loss = 50.08769490\n",
      "Iteration 42379, loss = 50.08012628\n",
      "Iteration 42380, loss = 50.07255833\n",
      "Iteration 42381, loss = 50.06499104\n",
      "Iteration 42382, loss = 50.05742444\n",
      "Iteration 42383, loss = 50.04985852\n",
      "Iteration 42384, loss = 50.04229332\n",
      "Iteration 42385, loss = 50.03472886\n",
      "Iteration 42386, loss = 50.02716517\n",
      "Iteration 42387, loss = 50.01960227\n",
      "Iteration 42388, loss = 50.01204011\n",
      "Iteration 42389, loss = 50.00447859\n",
      "Iteration 42390, loss = 49.99691751\n",
      "Iteration 42391, loss = 49.98935674\n",
      "Iteration 42392, loss = 49.98179649\n",
      "Iteration 42393, loss = 49.97423739\n",
      "Iteration 42394, loss = 49.96668030\n",
      "Iteration 42395, loss = 49.95912604\n",
      "Iteration 42396, loss = 49.95157547\n",
      "Iteration 42397, loss = 49.94402977\n",
      "Iteration 42398, loss = 49.93649088\n",
      "Iteration 42399, loss = 49.92896052\n",
      "Iteration 42400, loss = 49.92143835\n",
      "Iteration 42401, loss = 49.91391516\n",
      "Iteration 42402, loss = 49.90637278\n",
      "Iteration 42403, loss = 49.89879128\n",
      "Iteration 42404, loss = 49.89118047\n",
      "Iteration 42405, loss = 49.88358022\n",
      "Iteration 42406, loss = 49.87602419\n",
      "Iteration 42407, loss = 49.86850425\n",
      "Iteration 42408, loss = 49.86098259\n",
      "Iteration 42409, loss = 49.85342918\n",
      "Iteration 42410, loss = 49.84584938\n",
      "Iteration 42411, loss = 49.83827755\n",
      "Iteration 42412, loss = 49.83073530\n",
      "Iteration 42413, loss = 49.82320931\n",
      "Iteration 42414, loss = 49.81567177\n",
      "Iteration 42415, loss = 49.80811325\n",
      "Iteration 42416, loss = 49.80055122\n",
      "Iteration 42417, loss = 49.79300528\n",
      "Iteration 42418, loss = 49.78547349\n",
      "Iteration 42419, loss = 49.77793852\n",
      "Iteration 42420, loss = 49.77039080\n",
      "Iteration 42421, loss = 49.76283879\n",
      "Iteration 42422, loss = 49.75529552\n",
      "Iteration 42423, loss = 49.74776195\n",
      "Iteration 42424, loss = 49.74022797\n",
      "Iteration 42425, loss = 49.73268668\n",
      "Iteration 42426, loss = 49.72514228\n",
      "Iteration 42427, loss = 49.71760284\n",
      "Iteration 42428, loss = 49.71006977\n",
      "Iteration 42429, loss = 49.70253728\n",
      "Iteration 42430, loss = 49.69500081\n",
      "Iteration 42431, loss = 49.68746234\n",
      "Iteration 42432, loss = 49.67992673\n",
      "Iteration 42433, loss = 49.67239529\n",
      "Iteration 42434, loss = 49.66486487\n",
      "Iteration 42435, loss = 49.65733250\n",
      "Iteration 42436, loss = 49.64979894\n",
      "Iteration 42437, loss = 49.64226702\n",
      "Iteration 42438, loss = 49.63473789\n",
      "Iteration 42439, loss = 49.62720993\n",
      "Iteration 42440, loss = 49.61968125\n",
      "Iteration 42441, loss = 49.61215197\n",
      "Iteration 42442, loss = 49.60462366\n",
      "Iteration 42443, loss = 49.59709724\n",
      "Iteration 42444, loss = 49.58957200\n",
      "Iteration 42445, loss = 49.58204677\n",
      "Iteration 42446, loss = 49.57452135\n",
      "Iteration 42447, loss = 49.56699658\n",
      "Iteration 42448, loss = 49.55947313\n",
      "Iteration 42449, loss = 49.55195079\n",
      "Iteration 42450, loss = 49.54442887\n",
      "Iteration 42451, loss = 49.53690708\n",
      "Iteration 42452, loss = 49.52938578\n",
      "Iteration 42453, loss = 49.52186546\n",
      "Iteration 42454, loss = 49.51434613\n",
      "Iteration 42455, loss = 49.50682744\n",
      "Iteration 42456, loss = 49.49930911\n",
      "Iteration 42457, loss = 49.49179125\n",
      "Iteration 42458, loss = 49.48427414\n",
      "Iteration 42459, loss = 49.47675791\n",
      "Iteration 42460, loss = 49.46924241\n",
      "Iteration 42461, loss = 49.46172744\n",
      "Iteration 42462, loss = 49.45421297\n",
      "Iteration 42463, loss = 49.44669914\n",
      "Iteration 42464, loss = 49.43918607\n",
      "Iteration 42465, loss = 49.43167375\n",
      "Iteration 42466, loss = 49.42416207\n",
      "Iteration 42467, loss = 49.41665095\n",
      "Iteration 42468, loss = 49.40914042\n",
      "Iteration 42469, loss = 49.40163058\n",
      "Iteration 42470, loss = 49.39412145\n",
      "Iteration 42471, loss = 49.38661301\n",
      "Iteration 42472, loss = 49.37910518\n",
      "Iteration 42473, loss = 49.37159796\n",
      "Iteration 42474, loss = 49.36409138\n",
      "Iteration 42475, loss = 49.35658547\n",
      "Iteration 42476, loss = 49.34908025\n",
      "Iteration 42477, loss = 49.34157569\n",
      "Iteration 42478, loss = 49.33407176\n",
      "Iteration 42479, loss = 49.32656845\n",
      "Iteration 42480, loss = 49.31906579\n",
      "Iteration 42481, loss = 49.31156381\n",
      "Iteration 42482, loss = 49.30406249\n",
      "Iteration 42483, loss = 49.29656182\n",
      "Iteration 42484, loss = 49.28906178\n",
      "Iteration 42485, loss = 49.28156239\n",
      "Iteration 42486, loss = 49.27406365\n",
      "Iteration 42487, loss = 49.26656557\n",
      "Iteration 42488, loss = 49.25906815\n",
      "Iteration 42489, loss = 49.25157138\n",
      "Iteration 42490, loss = 49.24407526\n",
      "Iteration 42491, loss = 49.23657978\n",
      "Iteration 42492, loss = 49.22908495\n",
      "Iteration 42493, loss = 49.22159077\n",
      "Iteration 42494, loss = 49.21409726\n",
      "Iteration 42495, loss = 49.20660439\n",
      "Iteration 42496, loss = 49.19911217\n",
      "Iteration 42497, loss = 49.19162060\n",
      "Iteration 42498, loss = 49.18412967\n",
      "Iteration 42499, loss = 49.17663941\n",
      "Iteration 42500, loss = 49.16914979\n",
      "Iteration 42501, loss = 49.16166083\n",
      "Iteration 42502, loss = 49.15417251\n",
      "Iteration 42503, loss = 49.14668485\n",
      "Iteration 42504, loss = 49.13919783\n",
      "Iteration 42505, loss = 49.13171147\n",
      "Iteration 42506, loss = 49.12422575\n",
      "Iteration 42507, loss = 49.11674069\n",
      "Iteration 42508, loss = 49.10925628\n",
      "Iteration 42509, loss = 49.10177252\n",
      "Iteration 42510, loss = 49.09428941\n",
      "Iteration 42511, loss = 49.08680695\n",
      "Iteration 42512, loss = 49.07932515\n",
      "Iteration 42513, loss = 49.07184399\n",
      "Iteration 42514, loss = 49.06436348\n",
      "Iteration 42515, loss = 49.05688363\n",
      "Iteration 42516, loss = 49.04940442\n",
      "Iteration 42517, loss = 49.04192587\n",
      "Iteration 42518, loss = 49.03444796\n",
      "Iteration 42519, loss = 49.02697071\n",
      "Iteration 42520, loss = 49.01949411\n",
      "Iteration 42521, loss = 49.01201816\n",
      "Iteration 42522, loss = 49.00454286\n",
      "Iteration 42523, loss = 48.99706821\n",
      "Iteration 42524, loss = 48.98959421\n",
      "Iteration 42525, loss = 48.98212086\n",
      "Iteration 42526, loss = 48.97464816\n",
      "Iteration 42527, loss = 48.96717611\n",
      "Iteration 42528, loss = 48.95970471\n",
      "Iteration 42529, loss = 48.95223397\n",
      "Iteration 42530, loss = 48.94476387\n",
      "Iteration 42531, loss = 48.93729442\n",
      "Iteration 42532, loss = 48.92982563\n",
      "Iteration 42533, loss = 48.92235748\n",
      "Iteration 42534, loss = 48.91488999\n",
      "Iteration 42535, loss = 48.90742315\n",
      "Iteration 42536, loss = 48.89995695\n",
      "Iteration 42537, loss = 48.89249141\n",
      "Iteration 42538, loss = 48.88502652\n",
      "Iteration 42539, loss = 48.87756228\n",
      "Iteration 42540, loss = 48.87009868\n",
      "Iteration 42541, loss = 48.86263574\n",
      "Iteration 42542, loss = 48.85517345\n",
      "Iteration 42543, loss = 48.84771181\n",
      "Iteration 42544, loss = 48.84025083\n",
      "Iteration 42545, loss = 48.83279049\n",
      "Iteration 42546, loss = 48.82533080\n",
      "Iteration 42547, loss = 48.81787176\n",
      "Iteration 42548, loss = 48.81041337\n",
      "Iteration 42549, loss = 48.80295564\n",
      "Iteration 42550, loss = 48.79549855\n",
      "Iteration 42551, loss = 48.78804211\n",
      "Iteration 42552, loss = 48.78058633\n",
      "Iteration 42553, loss = 48.77313119\n",
      "Iteration 42554, loss = 48.76567671\n",
      "Iteration 42555, loss = 48.75822287\n",
      "Iteration 42556, loss = 48.75076969\n",
      "Iteration 42557, loss = 48.74331715\n",
      "Iteration 42558, loss = 48.73586527\n",
      "Iteration 42559, loss = 48.72841404\n",
      "Iteration 42560, loss = 48.72096345\n",
      "Iteration 42561, loss = 48.71351352\n",
      "Iteration 42562, loss = 48.70606424\n",
      "Iteration 42563, loss = 48.69861561\n",
      "Iteration 42564, loss = 48.69116762\n",
      "Iteration 42565, loss = 48.68372029\n",
      "Iteration 42566, loss = 48.67627361\n",
      "Iteration 42567, loss = 48.66882758\n",
      "Iteration 42568, loss = 48.66138220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42569, loss = 48.65393747\n",
      "Iteration 42570, loss = 48.64649339\n",
      "Iteration 42571, loss = 48.63904996\n",
      "Iteration 42572, loss = 48.63160718\n",
      "Iteration 42573, loss = 48.62416505\n",
      "Iteration 42574, loss = 48.61672357\n",
      "Iteration 42575, loss = 48.60928274\n",
      "Iteration 42576, loss = 48.60184256\n",
      "Iteration 42577, loss = 48.59440303\n",
      "Iteration 42578, loss = 48.58696416\n",
      "Iteration 42579, loss = 48.57952593\n",
      "Iteration 42580, loss = 48.57208835\n",
      "Iteration 42581, loss = 48.56465142\n",
      "Iteration 42582, loss = 48.55721514\n",
      "Iteration 42583, loss = 48.54977952\n",
      "Iteration 42584, loss = 48.54234454\n",
      "Iteration 42585, loss = 48.53491021\n",
      "Iteration 42586, loss = 48.52747653\n",
      "Iteration 42587, loss = 48.52004351\n",
      "Iteration 42588, loss = 48.51261113\n",
      "Iteration 42589, loss = 48.50517940\n",
      "Iteration 42590, loss = 48.49774833\n",
      "Iteration 42591, loss = 48.49031790\n",
      "Iteration 42592, loss = 48.48288812\n",
      "Iteration 42593, loss = 48.47545900\n",
      "Iteration 42594, loss = 48.46803052\n",
      "Iteration 42595, loss = 48.46060269\n",
      "Iteration 42596, loss = 48.45317552\n",
      "Iteration 42597, loss = 48.44574899\n",
      "Iteration 42598, loss = 48.43832311\n",
      "Iteration 42599, loss = 48.43089789\n",
      "Iteration 42600, loss = 48.42347331\n",
      "Iteration 42601, loss = 48.41604938\n",
      "Iteration 42602, loss = 48.40862611\n",
      "Iteration 42603, loss = 48.40120348\n",
      "Iteration 42604, loss = 48.39378151\n",
      "Iteration 42605, loss = 48.38636018\n",
      "Iteration 42606, loss = 48.37893950\n",
      "Iteration 42607, loss = 48.37151948\n",
      "Iteration 42608, loss = 48.36410010\n",
      "Iteration 42609, loss = 48.35668137\n",
      "Iteration 42610, loss = 48.34926330\n",
      "Iteration 42611, loss = 48.34184587\n",
      "Iteration 42612, loss = 48.33442909\n",
      "Iteration 42613, loss = 48.32701297\n",
      "Iteration 42614, loss = 48.31959749\n",
      "Iteration 42615, loss = 48.31218266\n",
      "Iteration 42616, loss = 48.30476848\n",
      "Iteration 42617, loss = 48.29735496\n",
      "Iteration 42618, loss = 48.28994208\n",
      "Iteration 42619, loss = 48.28252985\n",
      "Iteration 42620, loss = 48.27511827\n",
      "Iteration 42621, loss = 48.26770735\n",
      "Iteration 42622, loss = 48.26029707\n",
      "Iteration 42623, loss = 48.25288744\n",
      "Iteration 42624, loss = 48.24547847\n",
      "Iteration 42625, loss = 48.23807015\n",
      "Iteration 42626, loss = 48.23066248\n",
      "Iteration 42627, loss = 48.22325547\n",
      "Iteration 42628, loss = 48.21584912\n",
      "Iteration 42629, loss = 48.20844344\n",
      "Iteration 42630, loss = 48.20103844\n",
      "Iteration 42631, loss = 48.19363415\n",
      "Iteration 42632, loss = 48.18623060\n",
      "Iteration 42633, loss = 48.17882784\n",
      "Iteration 42634, loss = 48.17142592\n",
      "Iteration 42635, loss = 48.16402485\n",
      "Iteration 42636, loss = 48.15662454\n",
      "Iteration 42637, loss = 48.14922463\n",
      "Iteration 42638, loss = 48.14182462\n",
      "Iteration 42639, loss = 48.13442427\n",
      "Iteration 42640, loss = 48.12702416\n",
      "Iteration 42641, loss = 48.11962533\n",
      "Iteration 42642, loss = 48.11222828\n",
      "Iteration 42643, loss = 48.10483252\n",
      "Iteration 42644, loss = 48.09743713\n",
      "Iteration 42645, loss = 48.09004157\n",
      "Iteration 42646, loss = 48.08264616\n",
      "Iteration 42647, loss = 48.07525174\n",
      "Iteration 42648, loss = 48.06785874\n",
      "Iteration 42649, loss = 48.06046683\n",
      "Iteration 42650, loss = 48.05307544\n",
      "Iteration 42651, loss = 48.04568446\n",
      "Iteration 42652, loss = 48.03829444\n",
      "Iteration 42653, loss = 48.03090607\n",
      "Iteration 42654, loss = 48.02351974\n",
      "Iteration 42655, loss = 48.01613562\n",
      "Iteration 42656, loss = 48.00875411\n",
      "Iteration 42657, loss = 48.00137622\n",
      "Iteration 42658, loss = 47.99400281\n",
      "Iteration 42659, loss = 47.98663383\n",
      "Iteration 42660, loss = 47.97926608\n",
      "Iteration 42661, loss = 47.97189349\n",
      "Iteration 42662, loss = 47.96450698\n",
      "Iteration 42663, loss = 47.95710295\n",
      "Iteration 42664, loss = 47.94968794\n",
      "Iteration 42665, loss = 47.94227886\n",
      "Iteration 42666, loss = 47.93488899\n",
      "Iteration 42667, loss = 47.92751826\n",
      "Iteration 42668, loss = 47.92015486\n",
      "Iteration 42669, loss = 47.91278455\n",
      "Iteration 42670, loss = 47.90540037\n",
      "Iteration 42671, loss = 47.89800678\n",
      "Iteration 42672, loss = 47.89061590\n",
      "Iteration 42673, loss = 47.88323651\n",
      "Iteration 42674, loss = 47.87586739\n",
      "Iteration 42675, loss = 47.86850006\n",
      "Iteration 42676, loss = 47.86112665\n",
      "Iteration 42677, loss = 47.85374621\n",
      "Iteration 42678, loss = 47.84636434\n",
      "Iteration 42679, loss = 47.83898753\n",
      "Iteration 42680, loss = 47.83161747\n",
      "Iteration 42681, loss = 47.82425046\n",
      "Iteration 42682, loss = 47.81688158\n",
      "Iteration 42683, loss = 47.80950894\n",
      "Iteration 42684, loss = 47.80213477\n",
      "Iteration 42685, loss = 47.79476274\n",
      "Iteration 42686, loss = 47.78739464\n",
      "Iteration 42687, loss = 47.78002917\n",
      "Iteration 42688, loss = 47.77266367\n",
      "Iteration 42689, loss = 47.76529659\n",
      "Iteration 42690, loss = 47.75792852\n",
      "Iteration 42691, loss = 47.75056135\n",
      "Iteration 42692, loss = 47.74319639\n",
      "Iteration 42693, loss = 47.73583344\n",
      "Iteration 42694, loss = 47.72847125\n",
      "Iteration 42695, loss = 47.72110872\n",
      "Iteration 42696, loss = 47.71374580\n",
      "Iteration 42697, loss = 47.70638327\n",
      "Iteration 42698, loss = 47.69902198\n",
      "Iteration 42699, loss = 47.69166217\n",
      "Iteration 42700, loss = 47.68430336\n",
      "Iteration 42701, loss = 47.67694492\n",
      "Iteration 42702, loss = 47.66958655\n",
      "Iteration 42703, loss = 47.66222848\n",
      "Iteration 42704, loss = 47.65487114\n",
      "Iteration 42705, loss = 47.64751485\n",
      "Iteration 42706, loss = 47.64015954\n",
      "Iteration 42707, loss = 47.63280493\n",
      "Iteration 42708, loss = 47.62545075\n",
      "Iteration 42709, loss = 47.61809695\n",
      "Iteration 42710, loss = 47.61074368\n",
      "Iteration 42711, loss = 47.60339117\n",
      "Iteration 42712, loss = 47.59603951\n",
      "Iteration 42713, loss = 47.58868863\n",
      "Iteration 42714, loss = 47.58133839\n",
      "Iteration 42715, loss = 47.57398869\n",
      "Iteration 42716, loss = 47.56663952\n",
      "Iteration 42717, loss = 47.55929095\n",
      "Iteration 42718, loss = 47.55194308\n",
      "Iteration 42719, loss = 47.54459595\n",
      "Iteration 42720, loss = 47.53724954\n",
      "Iteration 42721, loss = 47.52990378\n",
      "Iteration 42722, loss = 47.52255861\n",
      "Iteration 42723, loss = 47.51521404\n",
      "Iteration 42724, loss = 47.50787009\n",
      "Iteration 42725, loss = 47.50052680\n",
      "Iteration 42726, loss = 47.49318421\n",
      "Iteration 42727, loss = 47.48584229\n",
      "Iteration 42728, loss = 47.47850104\n",
      "Iteration 42729, loss = 47.47116042\n",
      "Iteration 42730, loss = 47.46382042\n",
      "Iteration 42731, loss = 47.45648105\n",
      "Iteration 42732, loss = 47.44914232\n",
      "Iteration 42733, loss = 47.44180427\n",
      "Iteration 42734, loss = 47.43446687\n",
      "Iteration 42735, loss = 47.42713014\n",
      "Iteration 42736, loss = 47.41979406\n",
      "Iteration 42737, loss = 47.41245861\n",
      "Iteration 42738, loss = 47.40512381\n",
      "Iteration 42739, loss = 47.39778964\n",
      "Iteration 42740, loss = 47.39045613\n",
      "Iteration 42741, loss = 47.38312327\n",
      "Iteration 42742, loss = 47.37579106\n",
      "Iteration 42743, loss = 47.36845951\n",
      "Iteration 42744, loss = 47.36112861\n",
      "Iteration 42745, loss = 47.35379836\n",
      "Iteration 42746, loss = 47.34646874\n",
      "Iteration 42747, loss = 47.33913978\n",
      "Iteration 42748, loss = 47.33181146\n",
      "Iteration 42749, loss = 47.32448379\n",
      "Iteration 42750, loss = 47.31715678\n",
      "Iteration 42751, loss = 47.30983041\n",
      "Iteration 42752, loss = 47.30250470\n",
      "Iteration 42753, loss = 47.29517963\n",
      "Iteration 42754, loss = 47.28785521\n",
      "Iteration 42755, loss = 47.28053144\n",
      "Iteration 42756, loss = 47.27320831\n",
      "Iteration 42757, loss = 47.26588584\n",
      "Iteration 42758, loss = 47.25856401\n",
      "Iteration 42759, loss = 47.25124283\n",
      "Iteration 42760, loss = 47.24392231\n",
      "Iteration 42761, loss = 47.23660243\n",
      "Iteration 42762, loss = 47.22928320\n",
      "Iteration 42763, loss = 47.22196462\n",
      "Iteration 42764, loss = 47.21464668\n",
      "Iteration 42765, loss = 47.20732940\n",
      "Iteration 42766, loss = 47.20001276\n",
      "Iteration 42767, loss = 47.19269677\n",
      "Iteration 42768, loss = 47.18538143\n",
      "Iteration 42769, loss = 47.17806674\n",
      "Iteration 42770, loss = 47.17075270\n",
      "Iteration 42771, loss = 47.16343931\n",
      "Iteration 42772, loss = 47.15612656\n",
      "Iteration 42773, loss = 47.14881447\n",
      "Iteration 42774, loss = 47.14150302\n",
      "Iteration 42775, loss = 47.13419222\n",
      "Iteration 42776, loss = 47.12688207\n",
      "Iteration 42777, loss = 47.11957257\n",
      "Iteration 42778, loss = 47.11226371\n",
      "Iteration 42779, loss = 47.10495551\n",
      "Iteration 42780, loss = 47.09764795\n",
      "Iteration 42781, loss = 47.09034104\n",
      "Iteration 42782, loss = 47.08303478\n",
      "Iteration 42783, loss = 47.07572917\n",
      "Iteration 42784, loss = 47.06842421\n",
      "Iteration 42785, loss = 47.06111989\n",
      "Iteration 42786, loss = 47.05381623\n",
      "Iteration 42787, loss = 47.04651321\n",
      "Iteration 42788, loss = 47.03921084\n",
      "Iteration 42789, loss = 47.03190912\n",
      "Iteration 42790, loss = 47.02460805\n",
      "Iteration 42791, loss = 47.01730762\n",
      "Iteration 42792, loss = 47.01000785\n",
      "Iteration 42793, loss = 47.00270872\n",
      "Iteration 42794, loss = 46.99541024\n",
      "Iteration 42795, loss = 46.98811241\n",
      "Iteration 42796, loss = 46.98081523\n",
      "Iteration 42797, loss = 46.97351870\n",
      "Iteration 42798, loss = 46.96622281\n",
      "Iteration 42799, loss = 46.95892757\n",
      "Iteration 42800, loss = 46.95163298\n",
      "Iteration 42801, loss = 46.94433904\n",
      "Iteration 42802, loss = 46.93704575\n",
      "Iteration 42803, loss = 46.92975311\n",
      "Iteration 42804, loss = 46.92246111\n",
      "Iteration 42805, loss = 46.91516977\n",
      "Iteration 42806, loss = 46.90787907\n",
      "Iteration 42807, loss = 46.90058902\n",
      "Iteration 42808, loss = 46.89329961\n",
      "Iteration 42809, loss = 46.88601086\n",
      "Iteration 42810, loss = 46.87872275\n",
      "Iteration 42811, loss = 46.87143530\n",
      "Iteration 42812, loss = 46.86414849\n",
      "Iteration 42813, loss = 46.85686233\n",
      "Iteration 42814, loss = 46.84957681\n",
      "Iteration 42815, loss = 46.84229195\n",
      "Iteration 42816, loss = 46.83500773\n",
      "Iteration 42817, loss = 46.82772416\n",
      "Iteration 42818, loss = 46.82044124\n",
      "Iteration 42819, loss = 46.81315897\n",
      "Iteration 42820, loss = 46.80587735\n",
      "Iteration 42821, loss = 46.79859637\n",
      "Iteration 42822, loss = 46.79131604\n",
      "Iteration 42823, loss = 46.78403636\n",
      "Iteration 42824, loss = 46.77675733\n",
      "Iteration 42825, loss = 46.76947895\n",
      "Iteration 42826, loss = 46.76220121\n",
      "Iteration 42827, loss = 46.75492413\n",
      "Iteration 42828, loss = 46.74764769\n",
      "Iteration 42829, loss = 46.74037190\n",
      "Iteration 42830, loss = 46.73309675\n",
      "Iteration 42831, loss = 46.72582226\n",
      "Iteration 42832, loss = 46.71854841\n",
      "Iteration 42833, loss = 46.71127522\n",
      "Iteration 42834, loss = 46.70400267\n",
      "Iteration 42835, loss = 46.69673076\n",
      "Iteration 42836, loss = 46.68945951\n",
      "Iteration 42837, loss = 46.68218891\n",
      "Iteration 42838, loss = 46.67491895\n",
      "Iteration 42839, loss = 46.66764965\n",
      "Iteration 42840, loss = 46.66038099\n",
      "Iteration 42841, loss = 46.65311299\n",
      "Iteration 42842, loss = 46.64584564\n",
      "Iteration 42843, loss = 46.63857895\n",
      "Iteration 42844, loss = 46.63131292\n",
      "Iteration 42845, loss = 46.62404756\n",
      "Iteration 42846, loss = 46.61678290\n",
      "Iteration 42847, loss = 46.60951894\n",
      "Iteration 42848, loss = 46.60225573\n",
      "Iteration 42849, loss = 46.59499333\n",
      "Iteration 42850, loss = 46.58773186\n",
      "Iteration 42851, loss = 46.58047147\n",
      "Iteration 42852, loss = 46.57321245\n",
      "Iteration 42853, loss = 46.56595526\n",
      "Iteration 42854, loss = 46.55870059\n",
      "Iteration 42855, loss = 46.55144946\n",
      "Iteration 42856, loss = 46.54420324\n",
      "Iteration 42857, loss = 46.53696311\n",
      "Iteration 42858, loss = 46.52972928\n",
      "Iteration 42859, loss = 46.52249770\n",
      "Iteration 42860, loss = 46.51525921\n",
      "Iteration 42861, loss = 46.50799926\n",
      "Iteration 42862, loss = 46.50071297\n",
      "Iteration 42863, loss = 46.49341442\n",
      "Iteration 42864, loss = 46.48613184\n",
      "Iteration 42865, loss = 46.47888077\n",
      "Iteration 42866, loss = 46.47165166\n",
      "Iteration 42867, loss = 46.46442062\n",
      "Iteration 42868, loss = 46.45716900\n",
      "Iteration 42869, loss = 46.44989869\n",
      "Iteration 42870, loss = 46.44262886\n",
      "Iteration 42871, loss = 46.43537659\n",
      "Iteration 42872, loss = 46.42814044\n",
      "Iteration 42873, loss = 46.42090497\n",
      "Iteration 42874, loss = 46.41365760\n",
      "Iteration 42875, loss = 46.40639997\n",
      "Iteration 42876, loss = 46.39914453\n",
      "Iteration 42877, loss = 46.39190012\n",
      "Iteration 42878, loss = 46.38466373\n",
      "Iteration 42879, loss = 46.37742568\n",
      "Iteration 42880, loss = 46.37018038\n",
      "Iteration 42881, loss = 46.36293134\n",
      "Iteration 42882, loss = 46.35568590\n",
      "Iteration 42883, loss = 46.34844714\n",
      "Iteration 42884, loss = 46.34121147\n",
      "Iteration 42885, loss = 46.33397357\n",
      "Iteration 42886, loss = 46.32673209\n",
      "Iteration 42887, loss = 46.31949026\n",
      "Iteration 42888, loss = 46.31225177\n",
      "Iteration 42889, loss = 46.30501692\n",
      "Iteration 42890, loss = 46.29778298\n",
      "Iteration 42891, loss = 46.29054750\n",
      "Iteration 42892, loss = 46.28331071\n",
      "Iteration 42893, loss = 46.27607478\n",
      "Iteration 42894, loss = 46.26884126\n",
      "Iteration 42895, loss = 46.26160967\n",
      "Iteration 42896, loss = 46.25437837\n",
      "Iteration 42897, loss = 46.24714641\n",
      "Iteration 42898, loss = 46.23991430\n",
      "Iteration 42899, loss = 46.23268325\n",
      "Iteration 42900, loss = 46.22545385\n",
      "Iteration 42901, loss = 46.21822561\n",
      "Iteration 42902, loss = 46.21099767\n",
      "Iteration 42903, loss = 46.20376966\n",
      "Iteration 42904, loss = 46.19654199\n",
      "Iteration 42905, loss = 46.18931527\n",
      "Iteration 42906, loss = 46.18208972\n",
      "Iteration 42907, loss = 46.17486503\n",
      "Iteration 42908, loss = 46.16764076\n",
      "Iteration 42909, loss = 46.16041677\n",
      "Iteration 42910, loss = 46.15319328\n",
      "Iteration 42911, loss = 46.14597061\n",
      "Iteration 42912, loss = 46.13874887\n",
      "Iteration 42913, loss = 46.13152788\n",
      "Iteration 42914, loss = 46.12430742\n",
      "Iteration 42915, loss = 46.11708742\n",
      "Iteration 42916, loss = 46.10986798\n",
      "Iteration 42917, loss = 46.10264926\n",
      "Iteration 42918, loss = 46.09543134\n",
      "Iteration 42919, loss = 46.08821414\n",
      "Iteration 42920, loss = 46.08099754\n",
      "Iteration 42921, loss = 46.07378148\n",
      "Iteration 42922, loss = 46.06656602\n",
      "Iteration 42923, loss = 46.05935122\n",
      "Iteration 42924, loss = 46.05213715\n",
      "Iteration 42925, loss = 46.04492377\n",
      "Iteration 42926, loss = 46.03771104\n",
      "Iteration 42927, loss = 46.03049890\n",
      "Iteration 42928, loss = 46.02328737\n",
      "Iteration 42929, loss = 46.01607649\n",
      "Iteration 42930, loss = 46.00886628\n",
      "Iteration 42931, loss = 46.00165675\n",
      "Iteration 42932, loss = 45.99444788\n",
      "Iteration 42933, loss = 45.98723965\n",
      "Iteration 42934, loss = 45.98003203\n",
      "Iteration 42935, loss = 45.97282505\n",
      "Iteration 42936, loss = 45.96561872\n",
      "Iteration 42937, loss = 45.95841306\n",
      "Iteration 42938, loss = 45.95120806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42939, loss = 45.94400370\n",
      "Iteration 42940, loss = 45.93679998\n",
      "Iteration 42941, loss = 45.92959690\n",
      "Iteration 42942, loss = 45.92239446\n",
      "Iteration 42943, loss = 45.91519268\n",
      "Iteration 42944, loss = 45.90799155\n",
      "Iteration 42945, loss = 45.90079107\n",
      "Iteration 42946, loss = 45.89359124\n",
      "Iteration 42947, loss = 45.88639205\n",
      "Iteration 42948, loss = 45.87919350\n",
      "Iteration 42949, loss = 45.87199561\n",
      "Iteration 42950, loss = 45.86479836\n",
      "Iteration 42951, loss = 45.85760176\n",
      "Iteration 42952, loss = 45.85040582\n",
      "Iteration 42953, loss = 45.84321054\n",
      "Iteration 42954, loss = 45.83601590\n",
      "Iteration 42955, loss = 45.82882193\n",
      "Iteration 42956, loss = 45.82162862\n",
      "Iteration 42957, loss = 45.81443598\n",
      "Iteration 42958, loss = 45.80724404\n",
      "Iteration 42959, loss = 45.80005279\n",
      "Iteration 42960, loss = 45.79286224\n",
      "Iteration 42961, loss = 45.78567240\n",
      "Iteration 42962, loss = 45.77848323\n",
      "Iteration 42963, loss = 45.77129467\n",
      "Iteration 42964, loss = 45.76410661\n",
      "Iteration 42965, loss = 45.75691893\n",
      "Iteration 42966, loss = 45.74973161\n",
      "Iteration 42967, loss = 45.74254478\n",
      "Iteration 42968, loss = 45.73535868\n",
      "Iteration 42969, loss = 45.72817351\n",
      "Iteration 42970, loss = 45.72098929\n",
      "Iteration 42971, loss = 45.71380589\n",
      "Iteration 42972, loss = 45.70662312\n",
      "Iteration 42973, loss = 45.69944082\n",
      "Iteration 42974, loss = 45.69225896\n",
      "Iteration 42975, loss = 45.68507763\n",
      "Iteration 42976, loss = 45.67789698\n",
      "Iteration 42977, loss = 45.67071713\n",
      "Iteration 42978, loss = 45.66353807\n",
      "Iteration 42979, loss = 45.65635971\n",
      "Iteration 42980, loss = 45.64918196\n",
      "Iteration 42981, loss = 45.64200475\n",
      "Iteration 42982, loss = 45.63482809\n",
      "Iteration 42983, loss = 45.62765207\n",
      "Iteration 42984, loss = 45.62047676\n",
      "Iteration 42985, loss = 45.61330216\n",
      "Iteration 42986, loss = 45.60612826\n",
      "Iteration 42987, loss = 45.59895500\n",
      "Iteration 42988, loss = 45.59178234\n",
      "Iteration 42989, loss = 45.58461028\n",
      "Iteration 42990, loss = 45.57743884\n",
      "Iteration 42991, loss = 45.57026807\n",
      "Iteration 42992, loss = 45.56309799\n",
      "Iteration 42993, loss = 45.55592857\n",
      "Iteration 42994, loss = 45.54875981\n",
      "Iteration 42995, loss = 45.54159168\n",
      "Iteration 42996, loss = 45.53442418\n",
      "Iteration 42997, loss = 45.52725730\n",
      "Iteration 42998, loss = 45.52009108\n",
      "Iteration 42999, loss = 45.51292551\n",
      "Iteration 43000, loss = 45.50576060\n",
      "Iteration 43001, loss = 45.49859635\n",
      "Iteration 43002, loss = 45.49143275\n",
      "Iteration 43003, loss = 45.48426978\n",
      "Iteration 43004, loss = 45.47710745\n",
      "Iteration 43005, loss = 45.46994576\n",
      "Iteration 43006, loss = 45.46278472\n",
      "Iteration 43007, loss = 45.45562433\n",
      "Iteration 43008, loss = 45.44846460\n",
      "Iteration 43009, loss = 45.44130551\n",
      "Iteration 43010, loss = 45.43414707\n",
      "Iteration 43011, loss = 45.42698928\n",
      "Iteration 43012, loss = 45.41983212\n",
      "Iteration 43013, loss = 45.41267561\n",
      "Iteration 43014, loss = 45.40551975\n",
      "Iteration 43015, loss = 45.39836453\n",
      "Iteration 43016, loss = 45.39120997\n",
      "Iteration 43017, loss = 45.38405605\n",
      "Iteration 43018, loss = 45.37690278\n",
      "Iteration 43019, loss = 45.36975016\n",
      "Iteration 43020, loss = 45.36259817\n",
      "Iteration 43021, loss = 45.35544684\n",
      "Iteration 43022, loss = 45.34829615\n",
      "Iteration 43023, loss = 45.34114611\n",
      "Iteration 43024, loss = 45.33399671\n",
      "Iteration 43025, loss = 45.32684797\n",
      "Iteration 43026, loss = 45.31969986\n",
      "Iteration 43027, loss = 45.31255241\n",
      "Iteration 43028, loss = 45.30540560\n",
      "Iteration 43029, loss = 45.29825944\n",
      "Iteration 43030, loss = 45.29111392\n",
      "Iteration 43031, loss = 45.28396905\n",
      "Iteration 43032, loss = 45.27682483\n",
      "Iteration 43033, loss = 45.26968125\n",
      "Iteration 43034, loss = 45.26253832\n",
      "Iteration 43035, loss = 45.25539603\n",
      "Iteration 43036, loss = 45.24825439\n",
      "Iteration 43037, loss = 45.24111340\n",
      "Iteration 43038, loss = 45.23397305\n",
      "Iteration 43039, loss = 45.22683335\n",
      "Iteration 43040, loss = 45.21969430\n",
      "Iteration 43041, loss = 45.21255589\n",
      "Iteration 43042, loss = 45.20541813\n",
      "Iteration 43043, loss = 45.19828102\n",
      "Iteration 43044, loss = 45.19114455\n",
      "Iteration 43045, loss = 45.18400873\n",
      "Iteration 43046, loss = 45.17687355\n",
      "Iteration 43047, loss = 45.16973902\n",
      "Iteration 43048, loss = 45.16260513\n",
      "Iteration 43049, loss = 45.15547190\n",
      "Iteration 43050, loss = 45.14833930\n",
      "Iteration 43051, loss = 45.14120736\n",
      "Iteration 43052, loss = 45.13407606\n",
      "Iteration 43053, loss = 45.12694541\n",
      "Iteration 43054, loss = 45.11981540\n",
      "Iteration 43055, loss = 45.11268604\n",
      "Iteration 43056, loss = 45.10555732\n",
      "Iteration 43057, loss = 45.09842925\n",
      "Iteration 43058, loss = 45.09130183\n",
      "Iteration 43059, loss = 45.08417505\n",
      "Iteration 43060, loss = 45.07704892\n",
      "Iteration 43061, loss = 45.06992344\n",
      "Iteration 43062, loss = 45.06279860\n",
      "Iteration 43063, loss = 45.05567441\n",
      "Iteration 43064, loss = 45.04855086\n",
      "Iteration 43065, loss = 45.04142796\n",
      "Iteration 43066, loss = 45.03430571\n",
      "Iteration 43067, loss = 45.02718410\n",
      "Iteration 43068, loss = 45.02006314\n",
      "Iteration 43069, loss = 45.01294282\n",
      "Iteration 43070, loss = 45.00582315\n",
      "Iteration 43071, loss = 44.99870413\n",
      "Iteration 43072, loss = 44.99158576\n",
      "Iteration 43073, loss = 44.98446803\n",
      "Iteration 43074, loss = 44.97735096\n",
      "Iteration 43075, loss = 44.97023453\n",
      "Iteration 43076, loss = 44.96311877\n",
      "Iteration 43077, loss = 44.95600366\n",
      "Iteration 43078, loss = 44.94888923\n",
      "Iteration 43079, loss = 44.94177550\n",
      "Iteration 43080, loss = 44.93466248\n",
      "Iteration 43081, loss = 44.92755025\n",
      "Iteration 43082, loss = 44.92043888\n",
      "Iteration 43083, loss = 44.91332853\n",
      "Iteration 43084, loss = 44.90621945\n",
      "Iteration 43085, loss = 44.89911208\n",
      "Iteration 43086, loss = 44.89200714\n",
      "Iteration 43087, loss = 44.88490573\n",
      "Iteration 43088, loss = 44.87780950\n",
      "Iteration 43089, loss = 44.87072031\n",
      "Iteration 43090, loss = 44.86363957\n",
      "Iteration 43091, loss = 44.85656461\n",
      "Iteration 43092, loss = 44.84948599\n",
      "Iteration 43093, loss = 44.84238450\n",
      "Iteration 43094, loss = 44.83524795\n",
      "Iteration 43095, loss = 44.82808880\n",
      "Iteration 43096, loss = 44.82094521\n",
      "Iteration 43097, loss = 44.81384259\n",
      "Iteration 43098, loss = 44.80677004\n",
      "Iteration 43099, loss = 44.79969403\n",
      "Iteration 43100, loss = 44.79258901\n",
      "Iteration 43101, loss = 44.78546087\n",
      "Iteration 43102, loss = 44.77833888\n",
      "Iteration 43103, loss = 44.77124298\n",
      "Iteration 43104, loss = 44.76416355\n",
      "Iteration 43105, loss = 44.75707643\n",
      "Iteration 43106, loss = 44.74997064\n",
      "Iteration 43107, loss = 44.74285811\n",
      "Iteration 43108, loss = 44.73575738\n",
      "Iteration 43109, loss = 44.72867137\n",
      "Iteration 43110, loss = 44.72158692\n",
      "Iteration 43111, loss = 44.71449237\n",
      "Iteration 43112, loss = 44.70739033\n",
      "Iteration 43113, loss = 44.70029237\n",
      "Iteration 43114, loss = 44.69320407\n",
      "Iteration 43115, loss = 44.68611976\n",
      "Iteration 43116, loss = 44.67903110\n",
      "Iteration 43117, loss = 44.67193709\n",
      "Iteration 43118, loss = 44.66484390\n",
      "Iteration 43119, loss = 44.65775641\n",
      "Iteration 43120, loss = 44.65067284\n",
      "Iteration 43121, loss = 44.64358804\n",
      "Iteration 43122, loss = 44.63650003\n",
      "Iteration 43123, loss = 44.62941163\n",
      "Iteration 43124, loss = 44.62232633\n",
      "Iteration 43125, loss = 44.61524419\n",
      "Iteration 43126, loss = 44.60816244\n",
      "Iteration 43127, loss = 44.60107914\n",
      "Iteration 43128, loss = 44.59399524\n",
      "Iteration 43129, loss = 44.58691290\n",
      "Iteration 43130, loss = 44.57983289\n",
      "Iteration 43131, loss = 44.57275396\n",
      "Iteration 43132, loss = 44.56567465\n",
      "Iteration 43133, loss = 44.55859491\n",
      "Iteration 43134, loss = 44.55151591\n",
      "Iteration 43135, loss = 44.54443849\n",
      "Iteration 43136, loss = 44.53736232\n",
      "Iteration 43137, loss = 44.53028648\n",
      "Iteration 43138, loss = 44.52321058\n",
      "Iteration 43139, loss = 44.51613507\n",
      "Iteration 43140, loss = 44.50906059\n",
      "Iteration 43141, loss = 44.50198724\n",
      "Iteration 43142, loss = 44.49491462\n",
      "Iteration 43143, loss = 44.48784230\n",
      "Iteration 43144, loss = 44.48077031\n",
      "Iteration 43145, loss = 44.47369900\n",
      "Iteration 43146, loss = 44.46662863\n",
      "Iteration 43147, loss = 44.45955910\n",
      "Iteration 43148, loss = 44.45249014\n",
      "Iteration 43149, loss = 44.44542160\n",
      "Iteration 43150, loss = 44.43835361\n",
      "Iteration 43151, loss = 44.43128635\n",
      "Iteration 43152, loss = 44.42421989\n",
      "Iteration 43153, loss = 44.41715414\n",
      "Iteration 43154, loss = 44.41008895\n",
      "Iteration 43155, loss = 44.40302430\n",
      "Iteration 43156, loss = 44.39596026\n",
      "Iteration 43157, loss = 44.38889694\n",
      "Iteration 43158, loss = 44.38183435\n",
      "Iteration 43159, loss = 44.37477241\n",
      "Iteration 43160, loss = 44.36771106\n",
      "Iteration 43161, loss = 44.36065031\n",
      "Iteration 43162, loss = 44.35359019\n",
      "Iteration 43163, loss = 44.34653076\n",
      "Iteration 43164, loss = 44.33947202\n",
      "Iteration 43165, loss = 44.33241392\n",
      "Iteration 43166, loss = 44.32535644\n",
      "Iteration 43167, loss = 44.31829958\n",
      "Iteration 43168, loss = 44.31124336\n",
      "Iteration 43169, loss = 44.30418781\n",
      "Iteration 43170, loss = 44.29713292\n",
      "Iteration 43171, loss = 44.29007868\n",
      "Iteration 43172, loss = 44.28302507\n",
      "Iteration 43173, loss = 44.27597210\n",
      "Iteration 43174, loss = 44.26891976\n",
      "Iteration 43175, loss = 44.26186808\n",
      "Iteration 43176, loss = 44.25481705\n",
      "Iteration 43177, loss = 44.24776668\n",
      "Iteration 43178, loss = 44.24071694\n",
      "Iteration 43179, loss = 44.23366784\n",
      "Iteration 43180, loss = 44.22661938\n",
      "Iteration 43181, loss = 44.21957157\n",
      "Iteration 43182, loss = 44.21252441\n",
      "Iteration 43183, loss = 44.20547790\n",
      "Iteration 43184, loss = 44.19843203\n",
      "Iteration 43185, loss = 44.19138681\n",
      "Iteration 43186, loss = 44.18434223\n",
      "Iteration 43187, loss = 44.17729829\n",
      "Iteration 43188, loss = 44.17025501\n",
      "Iteration 43189, loss = 44.16321238\n",
      "Iteration 43190, loss = 44.15617039\n",
      "Iteration 43191, loss = 44.14912906\n",
      "Iteration 43192, loss = 44.14208839\n",
      "Iteration 43193, loss = 44.13504837\n",
      "Iteration 43194, loss = 44.12800902\n",
      "Iteration 43195, loss = 44.12097034\n",
      "Iteration 43196, loss = 44.11393235\n",
      "Iteration 43197, loss = 44.10689505\n",
      "Iteration 43198, loss = 44.09985843\n",
      "Iteration 43199, loss = 44.09282249\n",
      "Iteration 43200, loss = 44.08578719\n",
      "Iteration 43201, loss = 44.07875244\n",
      "Iteration 43202, loss = 44.07171816\n",
      "Iteration 43203, loss = 44.06468430\n",
      "Iteration 43204, loss = 44.05765090\n",
      "Iteration 43205, loss = 44.05061810\n",
      "Iteration 43206, loss = 44.04358608\n",
      "Iteration 43207, loss = 44.03655496\n",
      "Iteration 43208, loss = 44.02952468\n",
      "Iteration 43209, loss = 44.02249516\n",
      "Iteration 43210, loss = 44.01546622\n",
      "Iteration 43211, loss = 44.00843780\n",
      "Iteration 43212, loss = 44.00140986\n",
      "Iteration 43213, loss = 43.99438249\n",
      "Iteration 43214, loss = 43.98735579\n",
      "Iteration 43215, loss = 43.98032984\n",
      "Iteration 43216, loss = 43.97330465\n",
      "Iteration 43217, loss = 43.96628016\n",
      "Iteration 43218, loss = 43.95925629\n",
      "Iteration 43219, loss = 43.95223300\n",
      "Iteration 43220, loss = 43.94521028\n",
      "Iteration 43221, loss = 43.93818818\n",
      "Iteration 43222, loss = 43.93116673\n",
      "Iteration 43223, loss = 43.92414599\n",
      "Iteration 43224, loss = 43.91712593\n",
      "Iteration 43225, loss = 43.91010654\n",
      "Iteration 43226, loss = 43.90308778\n",
      "Iteration 43227, loss = 43.89606964\n",
      "Iteration 43228, loss = 43.88905210\n",
      "Iteration 43229, loss = 43.88203521\n",
      "Iteration 43230, loss = 43.87501896\n",
      "Iteration 43231, loss = 43.86800338\n",
      "Iteration 43232, loss = 43.86098847\n",
      "Iteration 43233, loss = 43.85397421\n",
      "Iteration 43234, loss = 43.84696059\n",
      "Iteration 43235, loss = 43.83994760\n",
      "Iteration 43236, loss = 43.83293524\n",
      "Iteration 43237, loss = 43.82592352\n",
      "Iteration 43238, loss = 43.81891245\n",
      "Iteration 43239, loss = 43.81190203\n",
      "Iteration 43240, loss = 43.80489227\n",
      "Iteration 43241, loss = 43.79788315\n",
      "Iteration 43242, loss = 43.79087468\n",
      "Iteration 43243, loss = 43.78386684\n",
      "Iteration 43244, loss = 43.77685965\n",
      "Iteration 43245, loss = 43.76985309\n",
      "Iteration 43246, loss = 43.76284718\n",
      "Iteration 43247, loss = 43.75584192\n",
      "Iteration 43248, loss = 43.74883731\n",
      "Iteration 43249, loss = 43.74183334\n",
      "Iteration 43250, loss = 43.73483002\n",
      "Iteration 43251, loss = 43.72782734\n",
      "Iteration 43252, loss = 43.72082530\n",
      "Iteration 43253, loss = 43.71382391\n",
      "Iteration 43254, loss = 43.70682316\n",
      "Iteration 43255, loss = 43.69982305\n",
      "Iteration 43256, loss = 43.69282359\n",
      "Iteration 43257, loss = 43.68582478\n",
      "Iteration 43258, loss = 43.67882660\n",
      "Iteration 43259, loss = 43.67182908\n",
      "Iteration 43260, loss = 43.66483220\n",
      "Iteration 43261, loss = 43.65783596\n",
      "Iteration 43262, loss = 43.65084037\n",
      "Iteration 43263, loss = 43.64384542\n",
      "Iteration 43264, loss = 43.63685111\n",
      "Iteration 43265, loss = 43.62985745\n",
      "Iteration 43266, loss = 43.62286443\n",
      "Iteration 43267, loss = 43.61587206\n",
      "Iteration 43268, loss = 43.60888033\n",
      "Iteration 43269, loss = 43.60188924\n",
      "Iteration 43270, loss = 43.59489880\n",
      "Iteration 43271, loss = 43.58790901\n",
      "Iteration 43272, loss = 43.58091986\n",
      "Iteration 43273, loss = 43.57393135\n",
      "Iteration 43274, loss = 43.56694348\n",
      "Iteration 43275, loss = 43.55995626\n",
      "Iteration 43276, loss = 43.55296969\n",
      "Iteration 43277, loss = 43.54598376\n",
      "Iteration 43278, loss = 43.53899847\n",
      "Iteration 43279, loss = 43.53201383\n",
      "Iteration 43280, loss = 43.52502983\n",
      "Iteration 43281, loss = 43.51804647\n",
      "Iteration 43282, loss = 43.51106376\n",
      "Iteration 43283, loss = 43.50408170\n",
      "Iteration 43284, loss = 43.49710027\n",
      "Iteration 43285, loss = 43.49011949\n",
      "Iteration 43286, loss = 43.48313936\n",
      "Iteration 43287, loss = 43.47615987\n",
      "Iteration 43288, loss = 43.46918102\n",
      "Iteration 43289, loss = 43.46220282\n",
      "Iteration 43290, loss = 43.45522526\n",
      "Iteration 43291, loss = 43.44824834\n",
      "Iteration 43292, loss = 43.44127207\n",
      "Iteration 43293, loss = 43.43429645\n",
      "Iteration 43294, loss = 43.42732146\n",
      "Iteration 43295, loss = 43.42034713\n",
      "Iteration 43296, loss = 43.41337343\n",
      "Iteration 43297, loss = 43.40640038\n",
      "Iteration 43298, loss = 43.39942797\n",
      "Iteration 43299, loss = 43.39245621\n",
      "Iteration 43300, loss = 43.38548509\n",
      "Iteration 43301, loss = 43.37851461\n",
      "Iteration 43302, loss = 43.37154478\n",
      "Iteration 43303, loss = 43.36457559\n",
      "Iteration 43304, loss = 43.35760705\n",
      "Iteration 43305, loss = 43.35063915\n",
      "Iteration 43306, loss = 43.34367189\n",
      "Iteration 43307, loss = 43.33670528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43308, loss = 43.32973931\n",
      "Iteration 43309, loss = 43.32277399\n",
      "Iteration 43310, loss = 43.31580931\n",
      "Iteration 43311, loss = 43.30884527\n",
      "Iteration 43312, loss = 43.30188188\n",
      "Iteration 43313, loss = 43.29491913\n",
      "Iteration 43314, loss = 43.28795702\n",
      "Iteration 43315, loss = 43.28099556\n",
      "Iteration 43316, loss = 43.27403474\n",
      "Iteration 43317, loss = 43.26707457\n",
      "Iteration 43318, loss = 43.26011504\n",
      "Iteration 43319, loss = 43.25315615\n",
      "Iteration 43320, loss = 43.24619791\n",
      "Iteration 43321, loss = 43.23924031\n",
      "Iteration 43322, loss = 43.23228336\n",
      "Iteration 43323, loss = 43.22532704\n",
      "Iteration 43324, loss = 43.21837138\n",
      "Iteration 43325, loss = 43.21141635\n",
      "Iteration 43326, loss = 43.20446198\n",
      "Iteration 43327, loss = 43.19750824\n",
      "Iteration 43328, loss = 43.19055516\n",
      "Iteration 43329, loss = 43.18360272\n",
      "Iteration 43330, loss = 43.17665093\n",
      "Iteration 43331, loss = 43.16969979\n",
      "Iteration 43332, loss = 43.16274931\n",
      "Iteration 43333, loss = 43.15579950\n",
      "Iteration 43334, loss = 43.14885038\n",
      "Iteration 43335, loss = 43.14190198\n",
      "Iteration 43336, loss = 43.13495434\n",
      "Iteration 43337, loss = 43.12800756\n",
      "Iteration 43338, loss = 43.12106177\n",
      "Iteration 43339, loss = 43.11411722\n",
      "Iteration 43340, loss = 43.10717433\n",
      "Iteration 43341, loss = 43.10023378\n",
      "Iteration 43342, loss = 43.09329668\n",
      "Iteration 43343, loss = 43.08636460\n",
      "Iteration 43344, loss = 43.07943966\n",
      "Iteration 43345, loss = 43.07252319\n",
      "Iteration 43346, loss = 43.06561390\n",
      "Iteration 43347, loss = 43.05870198\n",
      "Iteration 43348, loss = 43.05176998\n",
      "Iteration 43349, loss = 43.04480107\n",
      "Iteration 43350, loss = 43.03780634\n",
      "Iteration 43351, loss = 43.03082306\n",
      "Iteration 43352, loss = 43.02388111\n",
      "Iteration 43353, loss = 43.01697248\n",
      "Iteration 43354, loss = 43.01006274\n",
      "Iteration 43355, loss = 43.00312401\n",
      "Iteration 43356, loss = 42.99615967\n",
      "Iteration 43357, loss = 42.98920029\n",
      "Iteration 43358, loss = 42.98226812\n",
      "Iteration 43359, loss = 42.97535427\n",
      "Iteration 43360, loss = 42.96843311\n",
      "Iteration 43361, loss = 42.96149174\n",
      "Iteration 43362, loss = 42.95454248\n",
      "Iteration 43363, loss = 42.94760537\n",
      "Iteration 43364, loss = 42.94068424\n",
      "Iteration 43365, loss = 42.93376517\n",
      "Iteration 43366, loss = 42.92683526\n",
      "Iteration 43367, loss = 42.91989715\n",
      "Iteration 43368, loss = 42.91296324\n",
      "Iteration 43369, loss = 42.90603970\n",
      "Iteration 43370, loss = 42.89912044\n",
      "Iteration 43371, loss = 42.89219641\n",
      "Iteration 43372, loss = 42.88526657\n",
      "Iteration 43373, loss = 42.87833762\n",
      "Iteration 43374, loss = 42.87141476\n",
      "Iteration 43375, loss = 42.86449597\n",
      "Iteration 43376, loss = 42.85757571\n",
      "Iteration 43377, loss = 42.85065199\n",
      "Iteration 43378, loss = 42.84372795\n",
      "Iteration 43379, loss = 42.83680729\n",
      "Iteration 43380, loss = 42.82988987\n",
      "Iteration 43381, loss = 42.82297266\n",
      "Iteration 43382, loss = 42.81605372\n",
      "Iteration 43383, loss = 42.80913422\n",
      "Iteration 43384, loss = 42.80221648\n",
      "Iteration 43385, loss = 42.79530113\n",
      "Iteration 43386, loss = 42.78838673\n",
      "Iteration 43387, loss = 42.78147179\n",
      "Iteration 43388, loss = 42.77455645\n",
      "Iteration 43389, loss = 42.76764198\n",
      "Iteration 43390, loss = 42.76072918\n",
      "Iteration 43391, loss = 42.75381756\n",
      "Iteration 43392, loss = 42.74690615\n",
      "Iteration 43393, loss = 42.73999465\n",
      "Iteration 43394, loss = 42.73308363\n",
      "Iteration 43395, loss = 42.72617372\n",
      "Iteration 43396, loss = 42.71926494\n",
      "Iteration 43397, loss = 42.71235678\n",
      "Iteration 43398, loss = 42.70544887\n",
      "Iteration 43399, loss = 42.69854132\n",
      "Iteration 43400, loss = 42.69163453\n",
      "Iteration 43401, loss = 42.68472870\n",
      "Iteration 43402, loss = 42.67782366\n",
      "Iteration 43403, loss = 42.67091913\n",
      "Iteration 43404, loss = 42.66401502\n",
      "Iteration 43405, loss = 42.65711149\n",
      "Iteration 43406, loss = 42.65020873\n",
      "Iteration 43407, loss = 42.64330678\n",
      "Iteration 43408, loss = 42.63640549\n",
      "Iteration 43409, loss = 42.62950473\n",
      "Iteration 43410, loss = 42.62260451\n",
      "Iteration 43411, loss = 42.61570494\n",
      "Iteration 43412, loss = 42.60880610\n",
      "Iteration 43413, loss = 42.60190797\n",
      "Iteration 43414, loss = 42.59501047\n",
      "Iteration 43415, loss = 42.58811355\n",
      "Iteration 43416, loss = 42.58121723\n",
      "Iteration 43417, loss = 42.57432157\n",
      "Iteration 43418, loss = 42.56742660\n",
      "Iteration 43419, loss = 42.56053230\n",
      "Iteration 43420, loss = 42.55363863\n",
      "Iteration 43421, loss = 42.54674557\n",
      "Iteration 43422, loss = 42.53985314\n",
      "Iteration 43423, loss = 42.53296135\n",
      "Iteration 43424, loss = 42.52607023\n",
      "Iteration 43425, loss = 42.51917978\n",
      "Iteration 43426, loss = 42.51228996\n",
      "Iteration 43427, loss = 42.50540076\n",
      "Iteration 43428, loss = 42.49851219\n",
      "Iteration 43429, loss = 42.49162427\n",
      "Iteration 43430, loss = 42.48473701\n",
      "Iteration 43431, loss = 42.47785040\n",
      "Iteration 43432, loss = 42.47096443\n",
      "Iteration 43433, loss = 42.46407909\n",
      "Iteration 43434, loss = 42.45719439\n",
      "Iteration 43435, loss = 42.45031033\n",
      "Iteration 43436, loss = 42.44342692\n",
      "Iteration 43437, loss = 42.43654416\n",
      "Iteration 43438, loss = 42.42966204\n",
      "Iteration 43439, loss = 42.42278056\n",
      "Iteration 43440, loss = 42.41589972\n",
      "Iteration 43441, loss = 42.40901952\n",
      "Iteration 43442, loss = 42.40213997\n",
      "Iteration 43443, loss = 42.39526106\n",
      "Iteration 43444, loss = 42.38838280\n",
      "Iteration 43445, loss = 42.38150517\n",
      "Iteration 43446, loss = 42.37462819\n",
      "Iteration 43447, loss = 42.36775185\n",
      "Iteration 43448, loss = 42.36087615\n",
      "Iteration 43449, loss = 42.35400110\n",
      "Iteration 43450, loss = 42.34712668\n",
      "Iteration 43451, loss = 42.34025292\n",
      "Iteration 43452, loss = 42.33337979\n",
      "Iteration 43453, loss = 42.32650730\n",
      "Iteration 43454, loss = 42.31963546\n",
      "Iteration 43455, loss = 42.31276426\n",
      "Iteration 43456, loss = 42.30589370\n",
      "Iteration 43457, loss = 42.29902379\n",
      "Iteration 43458, loss = 42.29215452\n",
      "Iteration 43459, loss = 42.28528589\n",
      "Iteration 43460, loss = 42.27841790\n",
      "Iteration 43461, loss = 42.27155055\n",
      "Iteration 43462, loss = 42.26468385\n",
      "Iteration 43463, loss = 42.25781779\n",
      "Iteration 43464, loss = 42.25095237\n",
      "Iteration 43465, loss = 42.24408759\n",
      "Iteration 43466, loss = 42.23722346\n",
      "Iteration 43467, loss = 42.23035997\n",
      "Iteration 43468, loss = 42.22349712\n",
      "Iteration 43469, loss = 42.21663491\n",
      "Iteration 43470, loss = 42.20977335\n",
      "Iteration 43471, loss = 42.20291243\n",
      "Iteration 43472, loss = 42.19605215\n",
      "Iteration 43473, loss = 42.18919251\n",
      "Iteration 43474, loss = 42.18233352\n",
      "Iteration 43475, loss = 42.17547516\n",
      "Iteration 43476, loss = 42.16861745\n",
      "Iteration 43477, loss = 42.16176038\n",
      "Iteration 43478, loss = 42.15490396\n",
      "Iteration 43479, loss = 42.14804817\n",
      "Iteration 43480, loss = 42.14119303\n",
      "Iteration 43481, loss = 42.13433853\n",
      "Iteration 43482, loss = 42.12748467\n",
      "Iteration 43483, loss = 42.12063146\n",
      "Iteration 43484, loss = 42.11377889\n",
      "Iteration 43485, loss = 42.10692696\n",
      "Iteration 43486, loss = 42.10007567\n",
      "Iteration 43487, loss = 42.09322502\n",
      "Iteration 43488, loss = 42.08637502\n",
      "Iteration 43489, loss = 42.07952565\n",
      "Iteration 43490, loss = 42.07267693\n",
      "Iteration 43491, loss = 42.06582886\n",
      "Iteration 43492, loss = 42.05898142\n",
      "Iteration 43493, loss = 42.05213463\n",
      "Iteration 43494, loss = 42.04528847\n",
      "Iteration 43495, loss = 42.03844296\n",
      "Iteration 43496, loss = 42.03159810\n",
      "Iteration 43497, loss = 42.02475387\n",
      "Iteration 43498, loss = 42.01791029\n",
      "Iteration 43499, loss = 42.01106735\n",
      "Iteration 43500, loss = 42.00422505\n",
      "Iteration 43501, loss = 41.99738339\n",
      "Iteration 43502, loss = 41.99054238\n",
      "Iteration 43503, loss = 41.98370200\n",
      "Iteration 43504, loss = 41.97686227\n",
      "Iteration 43505, loss = 41.97002318\n",
      "Iteration 43506, loss = 41.96318473\n",
      "Iteration 43507, loss = 41.95634693\n",
      "Iteration 43508, loss = 41.94950977\n",
      "Iteration 43509, loss = 41.94267324\n",
      "Iteration 43510, loss = 41.93583736\n",
      "Iteration 43511, loss = 41.92900213\n",
      "Iteration 43512, loss = 41.92216753\n",
      "Iteration 43513, loss = 41.91533358\n",
      "Iteration 43514, loss = 41.90850027\n",
      "Iteration 43515, loss = 41.90166760\n",
      "Iteration 43516, loss = 41.89483557\n",
      "Iteration 43517, loss = 41.88800418\n",
      "Iteration 43518, loss = 41.88117344\n",
      "Iteration 43519, loss = 41.87434333\n",
      "Iteration 43520, loss = 41.86751387\n",
      "Iteration 43521, loss = 41.86068506\n",
      "Iteration 43522, loss = 41.85385688\n",
      "Iteration 43523, loss = 41.84702934\n",
      "Iteration 43524, loss = 41.84020245\n",
      "Iteration 43525, loss = 41.83337620\n",
      "Iteration 43526, loss = 41.82655059\n",
      "Iteration 43527, loss = 41.81972562\n",
      "Iteration 43528, loss = 41.81290130\n",
      "Iteration 43529, loss = 41.80607761\n",
      "Iteration 43530, loss = 41.79925457\n",
      "Iteration 43531, loss = 41.79243217\n",
      "Iteration 43532, loss = 41.78561041\n",
      "Iteration 43533, loss = 41.77878929\n",
      "Iteration 43534, loss = 41.77196882\n",
      "Iteration 43535, loss = 41.76514898\n",
      "Iteration 43536, loss = 41.75832979\n",
      "Iteration 43537, loss = 41.75151124\n",
      "Iteration 43538, loss = 41.74469333\n",
      "Iteration 43539, loss = 41.73787606\n",
      "Iteration 43540, loss = 41.73105944\n",
      "Iteration 43541, loss = 41.72424346\n",
      "Iteration 43542, loss = 41.71742811\n",
      "Iteration 43543, loss = 41.71061341\n",
      "Iteration 43544, loss = 41.70379935\n",
      "Iteration 43545, loss = 41.69698594\n",
      "Iteration 43546, loss = 41.69017316\n",
      "Iteration 43547, loss = 41.68336103\n",
      "Iteration 43548, loss = 41.67654954\n",
      "Iteration 43549, loss = 41.66973868\n",
      "Iteration 43550, loss = 41.66292848\n",
      "Iteration 43551, loss = 41.65611891\n",
      "Iteration 43552, loss = 41.64930998\n",
      "Iteration 43553, loss = 41.64250170\n",
      "Iteration 43554, loss = 41.63569405\n",
      "Iteration 43555, loss = 41.62888705\n",
      "Iteration 43556, loss = 41.62208069\n",
      "Iteration 43557, loss = 41.61527497\n",
      "Iteration 43558, loss = 41.60846990\n",
      "Iteration 43559, loss = 41.60166546\n",
      "Iteration 43560, loss = 41.59486167\n",
      "Iteration 43561, loss = 41.58805852\n",
      "Iteration 43562, loss = 41.58125601\n",
      "Iteration 43563, loss = 41.57445414\n",
      "Iteration 43564, loss = 41.56765291\n",
      "Iteration 43565, loss = 41.56085232\n",
      "Iteration 43566, loss = 41.55405238\n",
      "Iteration 43567, loss = 41.54725307\n",
      "Iteration 43568, loss = 41.54045441\n",
      "Iteration 43569, loss = 41.53365639\n",
      "Iteration 43570, loss = 41.52685901\n",
      "Iteration 43571, loss = 41.52006227\n",
      "Iteration 43572, loss = 41.51326618\n",
      "Iteration 43573, loss = 41.50647072\n",
      "Iteration 43574, loss = 41.49967591\n",
      "Iteration 43575, loss = 41.49288173\n",
      "Iteration 43576, loss = 41.48608820\n",
      "Iteration 43577, loss = 41.47929531\n",
      "Iteration 43578, loss = 41.47250306\n",
      "Iteration 43579, loss = 41.46571146\n",
      "Iteration 43580, loss = 41.45892049\n",
      "Iteration 43581, loss = 41.45213017\n",
      "Iteration 43582, loss = 41.44534048\n",
      "Iteration 43583, loss = 41.43855144\n",
      "Iteration 43584, loss = 41.43176304\n",
      "Iteration 43585, loss = 41.42497528\n",
      "Iteration 43586, loss = 41.41818816\n",
      "Iteration 43587, loss = 41.41140169\n",
      "Iteration 43588, loss = 41.40461585\n",
      "Iteration 43589, loss = 41.39783066\n",
      "Iteration 43590, loss = 41.39104611\n",
      "Iteration 43591, loss = 41.38426220\n",
      "Iteration 43592, loss = 41.37747894\n",
      "Iteration 43593, loss = 41.37069632\n",
      "Iteration 43594, loss = 41.36391436\n",
      "Iteration 43595, loss = 41.35713305\n",
      "Iteration 43596, loss = 41.35035240\n",
      "Iteration 43597, loss = 41.34357244\n",
      "Iteration 43598, loss = 41.33679320\n",
      "Iteration 43599, loss = 41.33001473\n",
      "Iteration 43600, loss = 41.32323712\n",
      "Iteration 43601, loss = 41.31646054\n",
      "Iteration 43602, loss = 41.30968525\n",
      "Iteration 43603, loss = 41.30291168\n",
      "Iteration 43604, loss = 41.29614053\n",
      "Iteration 43605, loss = 41.28937278\n",
      "Iteration 43606, loss = 41.28261000\n",
      "Iteration 43607, loss = 41.27585443\n",
      "Iteration 43608, loss = 41.26910928\n",
      "Iteration 43609, loss = 41.26237555\n",
      "Iteration 43610, loss = 41.25564628\n",
      "Iteration 43611, loss = 41.24889658\n",
      "Iteration 43612, loss = 41.24209871\n",
      "Iteration 43613, loss = 41.23525574\n",
      "Iteration 43614, loss = 41.22842247\n",
      "Iteration 43615, loss = 41.22164773\n",
      "Iteration 43616, loss = 41.21492071\n",
      "Iteration 43617, loss = 41.20818740\n",
      "Iteration 43618, loss = 41.20140772\n",
      "Iteration 43619, loss = 41.19459854\n",
      "Iteration 43620, loss = 41.18781030\n",
      "Iteration 43621, loss = 41.18106240\n",
      "Iteration 43622, loss = 41.17432386\n",
      "Iteration 43623, loss = 41.16755869\n",
      "Iteration 43624, loss = 41.16077114\n",
      "Iteration 43625, loss = 41.15399438\n",
      "Iteration 43626, loss = 41.14724312\n",
      "Iteration 43627, loss = 41.14049746\n",
      "Iteration 43628, loss = 41.13373486\n",
      "Iteration 43629, loss = 41.12696023\n",
      "Iteration 43630, loss = 41.12019461\n",
      "Iteration 43631, loss = 41.11344417\n",
      "Iteration 43632, loss = 41.10669465\n",
      "Iteration 43633, loss = 41.09993422\n",
      "Iteration 43634, loss = 41.09316894\n",
      "Iteration 43635, loss = 41.08641125\n",
      "Iteration 43636, loss = 41.07966196\n",
      "Iteration 43637, loss = 41.07291132\n",
      "Iteration 43638, loss = 41.06615423\n",
      "Iteration 43639, loss = 41.05939621\n",
      "Iteration 43640, loss = 41.05264392\n",
      "Iteration 43641, loss = 41.04589592\n",
      "Iteration 43642, loss = 41.03914620\n",
      "Iteration 43643, loss = 41.03239312\n",
      "Iteration 43644, loss = 41.02564078\n",
      "Iteration 43645, loss = 41.01889240\n",
      "Iteration 43646, loss = 41.01214615\n",
      "Iteration 43647, loss = 41.00539863\n",
      "Iteration 43648, loss = 40.99864964\n",
      "Iteration 43649, loss = 40.99190187\n",
      "Iteration 43650, loss = 40.98515673\n",
      "Iteration 43651, loss = 40.97841275\n",
      "Iteration 43652, loss = 40.97166810\n",
      "Iteration 43653, loss = 40.96492302\n",
      "Iteration 43654, loss = 40.95817913\n",
      "Iteration 43655, loss = 40.95143702\n",
      "Iteration 43656, loss = 40.94469571\n",
      "Iteration 43657, loss = 40.93795421\n",
      "Iteration 43658, loss = 40.93121280\n",
      "Iteration 43659, loss = 40.92447243\n",
      "Iteration 43660, loss = 40.91773335\n",
      "Iteration 43661, loss = 40.91099495\n",
      "Iteration 43662, loss = 40.90425669\n",
      "Iteration 43663, loss = 40.89751878\n",
      "Iteration 43664, loss = 40.89078175\n",
      "Iteration 43665, loss = 40.88404574\n",
      "Iteration 43666, loss = 40.87731038\n",
      "Iteration 43667, loss = 40.87057538\n",
      "Iteration 43668, loss = 40.86384085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43669, loss = 40.85710708\n",
      "Iteration 43670, loss = 40.85037418\n",
      "Iteration 43671, loss = 40.84364195\n",
      "Iteration 43672, loss = 40.83691019\n",
      "Iteration 43673, loss = 40.83017896\n",
      "Iteration 43674, loss = 40.82344844\n",
      "Iteration 43675, loss = 40.81671868\n",
      "Iteration 43676, loss = 40.80998960\n",
      "Iteration 43677, loss = 40.80326107\n",
      "Iteration 43678, loss = 40.79653310\n",
      "Iteration 43679, loss = 40.78980580\n",
      "Iteration 43680, loss = 40.78307921\n",
      "Iteration 43681, loss = 40.77635330\n",
      "Iteration 43682, loss = 40.76962798\n",
      "Iteration 43683, loss = 40.76290326\n",
      "Iteration 43684, loss = 40.75617918\n",
      "Iteration 43685, loss = 40.74945577\n",
      "Iteration 43686, loss = 40.74273303\n",
      "Iteration 43687, loss = 40.73601093\n",
      "Iteration 43688, loss = 40.72928943\n",
      "Iteration 43689, loss = 40.72256856\n",
      "Iteration 43690, loss = 40.71584835\n",
      "Iteration 43691, loss = 40.70912879\n",
      "Iteration 43692, loss = 40.70240989\n",
      "Iteration 43693, loss = 40.69569160\n",
      "Iteration 43694, loss = 40.68897394\n",
      "Iteration 43695, loss = 40.68225693\n",
      "Iteration 43696, loss = 40.67554057\n",
      "Iteration 43697, loss = 40.66882486\n",
      "Iteration 43698, loss = 40.66210978\n",
      "Iteration 43699, loss = 40.65539533\n",
      "Iteration 43700, loss = 40.64868152\n",
      "Iteration 43701, loss = 40.64196836\n",
      "Iteration 43702, loss = 40.63525584\n",
      "Iteration 43703, loss = 40.62854396\n",
      "Iteration 43704, loss = 40.62183272\n",
      "Iteration 43705, loss = 40.61512212\n",
      "Iteration 43706, loss = 40.60841215\n",
      "Iteration 43707, loss = 40.60170283\n",
      "Iteration 43708, loss = 40.59499415\n",
      "Iteration 43709, loss = 40.58828611\n",
      "Iteration 43710, loss = 40.58157871\n",
      "Iteration 43711, loss = 40.57487195\n",
      "Iteration 43712, loss = 40.56816582\n",
      "Iteration 43713, loss = 40.56146034\n",
      "Iteration 43714, loss = 40.55475550\n",
      "Iteration 43715, loss = 40.54805130\n",
      "Iteration 43716, loss = 40.54134774\n",
      "Iteration 43717, loss = 40.53464482\n",
      "Iteration 43718, loss = 40.52794254\n",
      "Iteration 43719, loss = 40.52124089\n",
      "Iteration 43720, loss = 40.51453989\n",
      "Iteration 43721, loss = 40.50783953\n",
      "Iteration 43722, loss = 40.50113981\n",
      "Iteration 43723, loss = 40.49444073\n",
      "Iteration 43724, loss = 40.48774228\n",
      "Iteration 43725, loss = 40.48104448\n",
      "Iteration 43726, loss = 40.47434732\n",
      "Iteration 43727, loss = 40.46765080\n",
      "Iteration 43728, loss = 40.46095492\n",
      "Iteration 43729, loss = 40.45425967\n",
      "Iteration 43730, loss = 40.44756507\n",
      "Iteration 43731, loss = 40.44087111\n",
      "Iteration 43732, loss = 40.43417778\n",
      "Iteration 43733, loss = 40.42748510\n",
      "Iteration 43734, loss = 40.42079306\n",
      "Iteration 43735, loss = 40.41410165\n",
      "Iteration 43736, loss = 40.40741089\n",
      "Iteration 43737, loss = 40.40072076\n",
      "Iteration 43738, loss = 40.39403128\n",
      "Iteration 43739, loss = 40.38734243\n",
      "Iteration 43740, loss = 40.38065423\n",
      "Iteration 43741, loss = 40.37396666\n",
      "Iteration 43742, loss = 40.36727974\n",
      "Iteration 43743, loss = 40.36059345\n",
      "Iteration 43744, loss = 40.35390780\n",
      "Iteration 43745, loss = 40.34722280\n",
      "Iteration 43746, loss = 40.34053843\n",
      "Iteration 43747, loss = 40.33385470\n",
      "Iteration 43748, loss = 40.32717161\n",
      "Iteration 43749, loss = 40.32048917\n",
      "Iteration 43750, loss = 40.31380736\n",
      "Iteration 43751, loss = 40.30712619\n",
      "Iteration 43752, loss = 40.30044566\n",
      "Iteration 43753, loss = 40.29376577\n",
      "Iteration 43754, loss = 40.28708652\n",
      "Iteration 43755, loss = 40.28040791\n",
      "Iteration 43756, loss = 40.27372994\n",
      "Iteration 43757, loss = 40.26705261\n",
      "Iteration 43758, loss = 40.26037592\n",
      "Iteration 43759, loss = 40.25369986\n",
      "Iteration 43760, loss = 40.24702445\n",
      "Iteration 43761, loss = 40.24034968\n",
      "Iteration 43762, loss = 40.23367554\n",
      "Iteration 43763, loss = 40.22700205\n",
      "Iteration 43764, loss = 40.22032920\n",
      "Iteration 43765, loss = 40.21365698\n",
      "Iteration 43766, loss = 40.20698540\n",
      "Iteration 43767, loss = 40.20031447\n",
      "Iteration 43768, loss = 40.19364417\n",
      "Iteration 43769, loss = 40.18697451\n",
      "Iteration 43770, loss = 40.18030550\n",
      "Iteration 43771, loss = 40.17363712\n",
      "Iteration 43772, loss = 40.16696938\n",
      "Iteration 43773, loss = 40.16030228\n",
      "Iteration 43774, loss = 40.15363582\n",
      "Iteration 43775, loss = 40.14697000\n",
      "Iteration 43776, loss = 40.14030482\n",
      "Iteration 43777, loss = 40.13364028\n",
      "Iteration 43778, loss = 40.12697637\n",
      "Iteration 43779, loss = 40.12031311\n",
      "Iteration 43780, loss = 40.11365049\n",
      "Iteration 43781, loss = 40.10698850\n",
      "Iteration 43782, loss = 40.10032716\n",
      "Iteration 43783, loss = 40.09366645\n",
      "Iteration 43784, loss = 40.08700639\n",
      "Iteration 43785, loss = 40.08034696\n",
      "Iteration 43786, loss = 40.07368817\n",
      "Iteration 43787, loss = 40.06703002\n",
      "Iteration 43788, loss = 40.06037251\n",
      "Iteration 43789, loss = 40.05371564\n",
      "Iteration 43790, loss = 40.04705941\n",
      "Iteration 43791, loss = 40.04040382\n",
      "Iteration 43792, loss = 40.03374887\n",
      "Iteration 43793, loss = 40.02709456\n",
      "Iteration 43794, loss = 40.02044088\n",
      "Iteration 43795, loss = 40.01378785\n",
      "Iteration 43796, loss = 40.00713545\n",
      "Iteration 43797, loss = 40.00048370\n",
      "Iteration 43798, loss = 39.99383258\n",
      "Iteration 43799, loss = 39.98718210\n",
      "Iteration 43800, loss = 39.98053227\n",
      "Iteration 43801, loss = 39.97388307\n",
      "Iteration 43802, loss = 39.96723451\n",
      "Iteration 43803, loss = 39.96058659\n",
      "Iteration 43804, loss = 39.95393930\n",
      "Iteration 43805, loss = 39.94729266\n",
      "Iteration 43806, loss = 39.94064666\n",
      "Iteration 43807, loss = 39.93400129\n",
      "Iteration 43808, loss = 39.92735657\n",
      "Iteration 43809, loss = 39.92071248\n",
      "Iteration 43810, loss = 39.91406903\n",
      "Iteration 43811, loss = 39.90742623\n",
      "Iteration 43812, loss = 39.90078406\n",
      "Iteration 43813, loss = 39.89414253\n",
      "Iteration 43814, loss = 39.88750164\n",
      "Iteration 43815, loss = 39.88086138\n",
      "Iteration 43816, loss = 39.87422177\n",
      "Iteration 43817, loss = 39.86758280\n",
      "Iteration 43818, loss = 39.86094446\n",
      "Iteration 43819, loss = 39.85430677\n",
      "Iteration 43820, loss = 39.84766971\n",
      "Iteration 43821, loss = 39.84103329\n",
      "Iteration 43822, loss = 39.83439751\n",
      "Iteration 43823, loss = 39.82776237\n",
      "Iteration 43824, loss = 39.82112787\n",
      "Iteration 43825, loss = 39.81449401\n",
      "Iteration 43826, loss = 39.80786078\n",
      "Iteration 43827, loss = 39.80122820\n",
      "Iteration 43828, loss = 39.79459626\n",
      "Iteration 43829, loss = 39.78796495\n",
      "Iteration 43830, loss = 39.78133428\n",
      "Iteration 43831, loss = 39.77470425\n",
      "Iteration 43832, loss = 39.76807486\n",
      "Iteration 43833, loss = 39.76144611\n",
      "Iteration 43834, loss = 39.75481800\n",
      "Iteration 43835, loss = 39.74819053\n",
      "Iteration 43836, loss = 39.74156369\n",
      "Iteration 43837, loss = 39.73493750\n",
      "Iteration 43838, loss = 39.72831194\n",
      "Iteration 43839, loss = 39.72168702\n",
      "Iteration 43840, loss = 39.71506274\n",
      "Iteration 43841, loss = 39.70843910\n",
      "Iteration 43842, loss = 39.70181610\n",
      "Iteration 43843, loss = 39.69519374\n",
      "Iteration 43844, loss = 39.68857201\n",
      "Iteration 43845, loss = 39.68195093\n",
      "Iteration 43846, loss = 39.67533048\n",
      "Iteration 43847, loss = 39.66871067\n",
      "Iteration 43848, loss = 39.66209150\n",
      "Iteration 43849, loss = 39.65547297\n",
      "Iteration 43850, loss = 39.64885508\n",
      "Iteration 43851, loss = 39.64223783\n",
      "Iteration 43852, loss = 39.63562121\n",
      "Iteration 43853, loss = 39.62900524\n",
      "Iteration 43854, loss = 39.62238990\n",
      "Iteration 43855, loss = 39.61577520\n",
      "Iteration 43856, loss = 39.60916114\n",
      "Iteration 43857, loss = 39.60254772\n",
      "Iteration 43858, loss = 39.59593494\n",
      "Iteration 43859, loss = 39.58932280\n",
      "Iteration 43860, loss = 39.58271129\n",
      "Iteration 43861, loss = 39.57610043\n",
      "Iteration 43862, loss = 39.56949020\n",
      "Iteration 43863, loss = 39.56288061\n",
      "Iteration 43864, loss = 39.55627166\n",
      "Iteration 43865, loss = 39.54966335\n",
      "Iteration 43866, loss = 39.54305567\n",
      "Iteration 43867, loss = 39.53644864\n",
      "Iteration 43868, loss = 39.52984224\n",
      "Iteration 43869, loss = 39.52323648\n",
      "Iteration 43870, loss = 39.51663136\n",
      "Iteration 43871, loss = 39.51002688\n",
      "Iteration 43872, loss = 39.50342304\n",
      "Iteration 43873, loss = 39.49681983\n",
      "Iteration 43874, loss = 39.49021727\n",
      "Iteration 43875, loss = 39.48361534\n",
      "Iteration 43876, loss = 39.47701405\n",
      "Iteration 43877, loss = 39.47041340\n",
      "Iteration 43878, loss = 39.46381339\n",
      "Iteration 43879, loss = 39.45721402\n",
      "Iteration 43880, loss = 39.45061528\n",
      "Iteration 43881, loss = 39.44401719\n",
      "Iteration 43882, loss = 39.43741973\n",
      "Iteration 43883, loss = 39.43082291\n",
      "Iteration 43884, loss = 39.42422673\n",
      "Iteration 43885, loss = 39.41763119\n",
      "Iteration 43886, loss = 39.41103628\n",
      "Iteration 43887, loss = 39.40444202\n",
      "Iteration 43888, loss = 39.39784839\n",
      "Iteration 43889, loss = 39.39125540\n",
      "Iteration 43890, loss = 39.38466305\n",
      "Iteration 43891, loss = 39.37807134\n",
      "Iteration 43892, loss = 39.37148027\n",
      "Iteration 43893, loss = 39.36488985\n",
      "Iteration 43894, loss = 39.35830007\n",
      "Iteration 43895, loss = 39.35171094\n",
      "Iteration 43896, loss = 39.34512247\n",
      "Iteration 43897, loss = 39.33853468\n",
      "Iteration 43898, loss = 39.33194760\n",
      "Iteration 43899, loss = 39.32536129\n",
      "Iteration 43900, loss = 39.31877585\n",
      "Iteration 43901, loss = 39.31219147\n",
      "Iteration 43902, loss = 39.30560850\n",
      "Iteration 43903, loss = 39.29902756\n",
      "Iteration 43904, loss = 39.29244975\n",
      "Iteration 43905, loss = 39.28587698\n",
      "Iteration 43906, loss = 39.27931217\n",
      "Iteration 43907, loss = 39.27275929\n",
      "Iteration 43908, loss = 39.26622058\n",
      "Iteration 43909, loss = 39.25969112\n",
      "Iteration 43910, loss = 39.25314659\n",
      "Iteration 43911, loss = 39.24655211\n",
      "Iteration 43912, loss = 39.23989816\n",
      "Iteration 43913, loss = 39.23324099\n",
      "Iteration 43914, loss = 39.22664609\n",
      "Iteration 43915, loss = 39.22011175\n",
      "Iteration 43916, loss = 39.21357650\n",
      "Iteration 43917, loss = 39.20698902\n",
      "Iteration 43918, loss = 39.20036591\n",
      "Iteration 43919, loss = 39.19376717\n",
      "Iteration 43920, loss = 39.18721480\n",
      "Iteration 43921, loss = 39.18066949\n",
      "Iteration 43922, loss = 39.17409076\n",
      "Iteration 43923, loss = 39.16749018\n",
      "Iteration 43924, loss = 39.16090826\n",
      "Iteration 43925, loss = 39.15435427\n",
      "Iteration 43926, loss = 39.14779865\n",
      "Iteration 43927, loss = 39.14122054\n",
      "Iteration 43928, loss = 39.13463546\n",
      "Iteration 43929, loss = 39.12806712\n",
      "Iteration 43930, loss = 39.12151223\n",
      "Iteration 43931, loss = 39.11495019\n",
      "Iteration 43932, loss = 39.10837545\n",
      "Iteration 43933, loss = 39.10180276\n",
      "Iteration 43934, loss = 39.09524217\n",
      "Iteration 43935, loss = 39.08868553\n",
      "Iteration 43936, loss = 39.08212165\n",
      "Iteration 43937, loss = 39.07555282\n",
      "Iteration 43938, loss = 39.06898905\n",
      "Iteration 43939, loss = 39.06243212\n",
      "Iteration 43940, loss = 39.05587468\n",
      "Iteration 43941, loss = 39.04931253\n",
      "Iteration 43942, loss = 39.04274995\n",
      "Iteration 43943, loss = 39.03619197\n",
      "Iteration 43944, loss = 39.02963706\n",
      "Iteration 43945, loss = 39.02308057\n",
      "Iteration 43946, loss = 39.01652196\n",
      "Iteration 43947, loss = 39.00996469\n",
      "Iteration 43948, loss = 39.00341060\n",
      "Iteration 43949, loss = 38.99685763\n",
      "Iteration 43950, loss = 38.99030348\n",
      "Iteration 43951, loss = 38.98374885\n",
      "Iteration 43952, loss = 38.97719588\n",
      "Iteration 43953, loss = 38.97064489\n",
      "Iteration 43954, loss = 38.96409430\n",
      "Iteration 43955, loss = 38.95754319\n",
      "Iteration 43956, loss = 38.95099240\n",
      "Iteration 43957, loss = 38.94444307\n",
      "Iteration 43958, loss = 38.93789500\n",
      "Iteration 43959, loss = 38.93134720\n",
      "Iteration 43960, loss = 38.92479937\n",
      "Iteration 43961, loss = 38.91825219\n",
      "Iteration 43962, loss = 38.91170617\n",
      "Iteration 43963, loss = 38.90516106\n",
      "Iteration 43964, loss = 38.89861629\n",
      "Iteration 43965, loss = 38.89207179\n",
      "Iteration 43966, loss = 38.88552801\n",
      "Iteration 43967, loss = 38.87898520\n",
      "Iteration 43968, loss = 38.87244313\n",
      "Iteration 43969, loss = 38.86590148\n",
      "Iteration 43970, loss = 38.85936029\n",
      "Iteration 43971, loss = 38.85281980\n",
      "Iteration 43972, loss = 38.84628015\n",
      "Iteration 43973, loss = 38.83974119\n",
      "Iteration 43974, loss = 38.83320272\n",
      "Iteration 43975, loss = 38.82666479\n",
      "Iteration 43976, loss = 38.82012754\n",
      "Iteration 43977, loss = 38.81359106\n",
      "Iteration 43978, loss = 38.80705523\n",
      "Iteration 43979, loss = 38.80051996\n",
      "Iteration 43980, loss = 38.79398526\n",
      "Iteration 43981, loss = 38.78745123\n",
      "Iteration 43982, loss = 38.78091791\n",
      "Iteration 43983, loss = 38.77438524\n",
      "Iteration 43984, loss = 38.76785316\n",
      "Iteration 43985, loss = 38.76132168\n",
      "Iteration 43986, loss = 38.75479085\n",
      "Iteration 43987, loss = 38.74826070\n",
      "Iteration 43988, loss = 38.74173120\n",
      "Iteration 43989, loss = 38.73520231\n",
      "Iteration 43990, loss = 38.72867404\n",
      "Iteration 43991, loss = 38.72214640\n",
      "Iteration 43992, loss = 38.71561943\n",
      "Iteration 43993, loss = 38.70909311\n",
      "Iteration 43994, loss = 38.70256741\n",
      "Iteration 43995, loss = 38.69604233\n",
      "Iteration 43996, loss = 38.68951789\n",
      "Iteration 43997, loss = 38.68299410\n",
      "Iteration 43998, loss = 38.67647096\n",
      "Iteration 43999, loss = 38.66994845\n",
      "Iteration 44000, loss = 38.66342656\n",
      "Iteration 44001, loss = 38.65690531\n",
      "Iteration 44002, loss = 38.65038471\n",
      "Iteration 44003, loss = 38.64386474\n",
      "Iteration 44004, loss = 38.63734542\n",
      "Iteration 44005, loss = 38.63082672\n",
      "Iteration 44006, loss = 38.62430866\n",
      "Iteration 44007, loss = 38.61779124\n",
      "Iteration 44008, loss = 38.61127446\n",
      "Iteration 44009, loss = 38.60475832\n",
      "Iteration 44010, loss = 38.59824282\n",
      "Iteration 44011, loss = 38.59172794\n",
      "Iteration 44012, loss = 38.58521371\n",
      "Iteration 44013, loss = 38.57870011\n",
      "Iteration 44014, loss = 38.57218716\n",
      "Iteration 44015, loss = 38.56567484\n",
      "Iteration 44016, loss = 38.55916315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44017, loss = 38.55265210\n",
      "Iteration 44018, loss = 38.54614169\n",
      "Iteration 44019, loss = 38.53963192\n",
      "Iteration 44020, loss = 38.53312278\n",
      "Iteration 44021, loss = 38.52661428\n",
      "Iteration 44022, loss = 38.52010642\n",
      "Iteration 44023, loss = 38.51359920\n",
      "Iteration 44024, loss = 38.50709261\n",
      "Iteration 44025, loss = 38.50058666\n",
      "Iteration 44026, loss = 38.49408134\n",
      "Iteration 44027, loss = 38.48757667\n",
      "Iteration 44028, loss = 38.48107263\n",
      "Iteration 44029, loss = 38.47456922\n",
      "Iteration 44030, loss = 38.46806646\n",
      "Iteration 44031, loss = 38.46156433\n",
      "Iteration 44032, loss = 38.45506284\n",
      "Iteration 44033, loss = 38.44856198\n",
      "Iteration 44034, loss = 38.44206176\n",
      "Iteration 44035, loss = 38.43556218\n",
      "Iteration 44036, loss = 38.42906324\n",
      "Iteration 44037, loss = 38.42256493\n",
      "Iteration 44038, loss = 38.41606726\n",
      "Iteration 44039, loss = 38.40957023\n",
      "Iteration 44040, loss = 38.40307383\n",
      "Iteration 44041, loss = 38.39657807\n",
      "Iteration 44042, loss = 38.39008295\n",
      "Iteration 44043, loss = 38.38358846\n",
      "Iteration 44044, loss = 38.37709461\n",
      "Iteration 44045, loss = 38.37060140\n",
      "Iteration 44046, loss = 38.36410883\n",
      "Iteration 44047, loss = 38.35761689\n",
      "Iteration 44048, loss = 38.35112558\n",
      "Iteration 44049, loss = 38.34463492\n",
      "Iteration 44050, loss = 38.33814489\n",
      "Iteration 44051, loss = 38.33165550\n",
      "Iteration 44052, loss = 38.32516675\n",
      "Iteration 44053, loss = 38.31867863\n",
      "Iteration 44054, loss = 38.31219115\n",
      "Iteration 44055, loss = 38.30570430\n",
      "Iteration 44056, loss = 38.29921809\n",
      "Iteration 44057, loss = 38.29273252\n",
      "Iteration 44058, loss = 38.28624759\n",
      "Iteration 44059, loss = 38.27976329\n",
      "Iteration 44060, loss = 38.27327963\n",
      "Iteration 44061, loss = 38.26679661\n",
      "Iteration 44062, loss = 38.26031422\n",
      "Iteration 44063, loss = 38.25383247\n",
      "Iteration 44064, loss = 38.24735136\n",
      "Iteration 44065, loss = 38.24087088\n",
      "Iteration 44066, loss = 38.23439104\n",
      "Iteration 44067, loss = 38.22791184\n",
      "Iteration 44068, loss = 38.22143327\n",
      "Iteration 44069, loss = 38.21495534\n",
      "Iteration 44070, loss = 38.20847805\n",
      "Iteration 44071, loss = 38.20200139\n",
      "Iteration 44072, loss = 38.19552537\n",
      "Iteration 44073, loss = 38.18904998\n",
      "Iteration 44074, loss = 38.18257524\n",
      "Iteration 44075, loss = 38.17610113\n",
      "Iteration 44076, loss = 38.16962765\n",
      "Iteration 44077, loss = 38.16315482\n",
      "Iteration 44078, loss = 38.15668261\n",
      "Iteration 44079, loss = 38.15021105\n",
      "Iteration 44080, loss = 38.14374012\n",
      "Iteration 44081, loss = 38.13726983\n",
      "Iteration 44082, loss = 38.13080018\n",
      "Iteration 44083, loss = 38.12433116\n",
      "Iteration 44084, loss = 38.11786278\n",
      "Iteration 44085, loss = 38.11139503\n",
      "Iteration 44086, loss = 38.10492793\n",
      "Iteration 44087, loss = 38.09846145\n",
      "Iteration 44088, loss = 38.09199562\n",
      "Iteration 44089, loss = 38.08553042\n",
      "Iteration 44090, loss = 38.07906586\n",
      "Iteration 44091, loss = 38.07260193\n",
      "Iteration 44092, loss = 38.06613864\n",
      "Iteration 44093, loss = 38.05967599\n",
      "Iteration 44094, loss = 38.05321397\n",
      "Iteration 44095, loss = 38.04675259\n",
      "Iteration 44096, loss = 38.04029185\n",
      "Iteration 44097, loss = 38.03383174\n",
      "Iteration 44098, loss = 38.02737227\n",
      "Iteration 44099, loss = 38.02091344\n",
      "Iteration 44100, loss = 38.01445524\n",
      "Iteration 44101, loss = 38.00799768\n",
      "Iteration 44102, loss = 38.00154076\n",
      "Iteration 44103, loss = 37.99508447\n",
      "Iteration 44104, loss = 37.98862882\n",
      "Iteration 44105, loss = 37.98217380\n",
      "Iteration 44106, loss = 37.97571942\n",
      "Iteration 44107, loss = 37.96926568\n",
      "Iteration 44108, loss = 37.96281257\n",
      "Iteration 44109, loss = 37.95636010\n",
      "Iteration 44110, loss = 37.94990827\n",
      "Iteration 44111, loss = 37.94345707\n",
      "Iteration 44112, loss = 37.93700651\n",
      "Iteration 44113, loss = 37.93055659\n",
      "Iteration 44114, loss = 37.92410730\n",
      "Iteration 44115, loss = 37.91765865\n",
      "Iteration 44116, loss = 37.91121064\n",
      "Iteration 44117, loss = 37.90476326\n",
      "Iteration 44118, loss = 37.89831651\n",
      "Iteration 44119, loss = 37.89187041\n",
      "Iteration 44120, loss = 37.88542494\n",
      "Iteration 44121, loss = 37.87898010\n",
      "Iteration 44122, loss = 37.87253591\n",
      "Iteration 44123, loss = 37.86609235\n",
      "Iteration 44124, loss = 37.85964942\n",
      "Iteration 44125, loss = 37.85320713\n",
      "Iteration 44126, loss = 37.84676548\n",
      "Iteration 44127, loss = 37.84032447\n",
      "Iteration 44128, loss = 37.83388409\n",
      "Iteration 44129, loss = 37.82744434\n",
      "Iteration 44130, loss = 37.82100524\n",
      "Iteration 44131, loss = 37.81456677\n",
      "Iteration 44132, loss = 37.80812893\n",
      "Iteration 44133, loss = 37.80169173\n",
      "Iteration 44134, loss = 37.79525517\n",
      "Iteration 44135, loss = 37.78881925\n",
      "Iteration 44136, loss = 37.78238396\n",
      "Iteration 44137, loss = 37.77594931\n",
      "Iteration 44138, loss = 37.76951529\n",
      "Iteration 44139, loss = 37.76308191\n",
      "Iteration 44140, loss = 37.75664916\n",
      "Iteration 44141, loss = 37.75021706\n",
      "Iteration 44142, loss = 37.74378558\n",
      "Iteration 44143, loss = 37.73735475\n",
      "Iteration 44144, loss = 37.73092455\n",
      "Iteration 44145, loss = 37.72449499\n",
      "Iteration 44146, loss = 37.71806606\n",
      "Iteration 44147, loss = 37.71163777\n",
      "Iteration 44148, loss = 37.70521011\n",
      "Iteration 44149, loss = 37.69878310\n",
      "Iteration 44150, loss = 37.69235671\n",
      "Iteration 44151, loss = 37.68593097\n",
      "Iteration 44152, loss = 37.67950586\n",
      "Iteration 44153, loss = 37.67308139\n",
      "Iteration 44154, loss = 37.66665755\n",
      "Iteration 44155, loss = 37.66023435\n",
      "Iteration 44156, loss = 37.65381178\n",
      "Iteration 44157, loss = 37.64738985\n",
      "Iteration 44158, loss = 37.64096856\n",
      "Iteration 44159, loss = 37.63454791\n",
      "Iteration 44160, loss = 37.62812789\n",
      "Iteration 44161, loss = 37.62170850\n",
      "Iteration 44162, loss = 37.61528975\n",
      "Iteration 44163, loss = 37.60887164\n",
      "Iteration 44164, loss = 37.60245417\n",
      "Iteration 44165, loss = 37.59603733\n",
      "Iteration 44166, loss = 37.58962113\n",
      "Iteration 44167, loss = 37.58320556\n",
      "Iteration 44168, loss = 37.57679063\n",
      "Iteration 44169, loss = 37.57037633\n",
      "Iteration 44170, loss = 37.56396268\n",
      "Iteration 44171, loss = 37.55754965\n",
      "Iteration 44172, loss = 37.55113727\n",
      "Iteration 44173, loss = 37.54472552\n",
      "Iteration 44174, loss = 37.53831440\n",
      "Iteration 44175, loss = 37.53190393\n",
      "Iteration 44176, loss = 37.52549409\n",
      "Iteration 44177, loss = 37.51908488\n",
      "Iteration 44178, loss = 37.51267631\n",
      "Iteration 44179, loss = 37.50626838\n",
      "Iteration 44180, loss = 37.49986108\n",
      "Iteration 44181, loss = 37.49345442\n",
      "Iteration 44182, loss = 37.48704840\n",
      "Iteration 44183, loss = 37.48064301\n",
      "Iteration 44184, loss = 37.47423826\n",
      "Iteration 44185, loss = 37.46783414\n",
      "Iteration 44186, loss = 37.46143067\n",
      "Iteration 44187, loss = 37.45502782\n",
      "Iteration 44188, loss = 37.44862562\n",
      "Iteration 44189, loss = 37.44222405\n",
      "Iteration 44190, loss = 37.43582311\n",
      "Iteration 44191, loss = 37.42942281\n",
      "Iteration 44192, loss = 37.42302315\n",
      "Iteration 44193, loss = 37.41662413\n",
      "Iteration 44194, loss = 37.41022574\n",
      "Iteration 44195, loss = 37.40382798\n",
      "Iteration 44196, loss = 37.39743087\n",
      "Iteration 44197, loss = 37.39103439\n",
      "Iteration 44198, loss = 37.38463854\n",
      "Iteration 44199, loss = 37.37824333\n",
      "Iteration 44200, loss = 37.37184876\n",
      "Iteration 44201, loss = 37.36545483\n",
      "Iteration 44202, loss = 37.35906153\n",
      "Iteration 44203, loss = 37.35266887\n",
      "Iteration 44204, loss = 37.34627684\n",
      "Iteration 44205, loss = 37.33988545\n",
      "Iteration 44206, loss = 37.33349471\n",
      "Iteration 44207, loss = 37.32710460\n",
      "Iteration 44208, loss = 37.32071514\n",
      "Iteration 44209, loss = 37.31432632\n",
      "Iteration 44210, loss = 37.30793818\n",
      "Iteration 44211, loss = 37.30155071\n",
      "Iteration 44212, loss = 37.29516397\n",
      "Iteration 44213, loss = 37.28877803\n",
      "Iteration 44214, loss = 37.28239303\n",
      "Iteration 44215, loss = 37.27600922\n",
      "Iteration 44216, loss = 37.26962707\n",
      "Iteration 44217, loss = 37.26324746\n",
      "Iteration 44218, loss = 37.25687193\n",
      "Iteration 44219, loss = 37.25050316\n",
      "Iteration 44220, loss = 37.24414511\n",
      "Iteration 44221, loss = 37.23780253\n",
      "Iteration 44222, loss = 37.23147539\n",
      "Iteration 44223, loss = 37.22514980\n",
      "Iteration 44224, loss = 37.21878585\n",
      "Iteration 44225, loss = 37.21235029\n",
      "Iteration 44226, loss = 37.20587197\n",
      "Iteration 44227, loss = 37.19943947\n",
      "Iteration 44228, loss = 37.19309202\n",
      "Iteration 44229, loss = 37.18677497\n",
      "Iteration 44230, loss = 37.18040912\n",
      "Iteration 44231, loss = 37.17398223\n",
      "Iteration 44232, loss = 37.16756320\n",
      "Iteration 44233, loss = 37.16120281\n",
      "Iteration 44234, loss = 37.15486753\n",
      "Iteration 44235, loss = 37.14849764\n",
      "Iteration 44236, loss = 37.14209193\n",
      "Iteration 44237, loss = 37.13570164\n",
      "Iteration 44238, loss = 37.12934822\n",
      "Iteration 44239, loss = 37.12299726\n",
      "Iteration 44240, loss = 37.11661823\n",
      "Iteration 44241, loss = 37.11022861\n",
      "Iteration 44242, loss = 37.10386008\n",
      "Iteration 44243, loss = 37.09750822\n",
      "Iteration 44244, loss = 37.09114556\n",
      "Iteration 44245, loss = 37.08476700\n",
      "Iteration 44246, loss = 37.07839348\n",
      "Iteration 44247, loss = 37.07203561\n",
      "Iteration 44248, loss = 37.06567946\n",
      "Iteration 44249, loss = 37.05931225\n",
      "Iteration 44250, loss = 37.05294153\n",
      "Iteration 44251, loss = 37.04657981\n",
      "Iteration 44252, loss = 37.04022456\n",
      "Iteration 44253, loss = 37.03386489\n",
      "Iteration 44254, loss = 37.02749979\n",
      "Iteration 44255, loss = 37.02113778\n",
      "Iteration 44256, loss = 37.01478212\n",
      "Iteration 44257, loss = 37.00842685\n",
      "Iteration 44258, loss = 37.00206753\n",
      "Iteration 44259, loss = 36.99570767\n",
      "Iteration 44260, loss = 36.98935193\n",
      "Iteration 44261, loss = 36.98299889\n",
      "Iteration 44262, loss = 36.97664436\n",
      "Iteration 44263, loss = 36.97028817\n",
      "Iteration 44264, loss = 36.96393365\n",
      "Iteration 44265, loss = 36.95758196\n",
      "Iteration 44266, loss = 36.95123078\n",
      "Iteration 44267, loss = 36.94487845\n",
      "Iteration 44268, loss = 36.93852630\n",
      "Iteration 44269, loss = 36.93217609\n",
      "Iteration 44270, loss = 36.92582736\n",
      "Iteration 44271, loss = 36.91947851\n",
      "Iteration 44272, loss = 36.91312935\n",
      "Iteration 44273, loss = 36.90678112\n",
      "Iteration 44274, loss = 36.90043439\n",
      "Iteration 44275, loss = 36.89408840\n",
      "Iteration 44276, loss = 36.88774240\n",
      "Iteration 44277, loss = 36.88139671\n",
      "Iteration 44278, loss = 36.87505208\n",
      "Iteration 44279, loss = 36.86870850\n",
      "Iteration 44280, loss = 36.86236538\n",
      "Iteration 44281, loss = 36.85602251\n",
      "Iteration 44282, loss = 36.84968025\n",
      "Iteration 44283, loss = 36.84333896\n",
      "Iteration 44284, loss = 36.83699845\n",
      "Iteration 44285, loss = 36.83065838\n",
      "Iteration 44286, loss = 36.82431875\n",
      "Iteration 44287, loss = 36.81797983\n",
      "Iteration 44288, loss = 36.81164174\n",
      "Iteration 44289, loss = 36.80530432\n",
      "Iteration 44290, loss = 36.79896740\n",
      "Iteration 44291, loss = 36.79263102\n",
      "Iteration 44292, loss = 36.78629536\n",
      "Iteration 44293, loss = 36.77996045\n",
      "Iteration 44294, loss = 36.77362616\n",
      "Iteration 44295, loss = 36.76729241\n",
      "Iteration 44296, loss = 36.76095928\n",
      "Iteration 44297, loss = 36.75462683\n",
      "Iteration 44298, loss = 36.74829508\n",
      "Iteration 44299, loss = 36.74196395\n",
      "Iteration 44300, loss = 36.73563341\n",
      "Iteration 44301, loss = 36.72930349\n",
      "Iteration 44302, loss = 36.72297424\n",
      "Iteration 44303, loss = 36.71664566\n",
      "Iteration 44304, loss = 36.71031771\n",
      "Iteration 44305, loss = 36.70399036\n",
      "Iteration 44306, loss = 36.69766364\n",
      "Iteration 44307, loss = 36.69133759\n",
      "Iteration 44308, loss = 36.68501219\n",
      "Iteration 44309, loss = 36.67868742\n",
      "Iteration 44310, loss = 36.67236327\n",
      "Iteration 44311, loss = 36.66603975\n",
      "Iteration 44312, loss = 36.65971689\n",
      "Iteration 44313, loss = 36.65339467\n",
      "Iteration 44314, loss = 36.64707309\n",
      "Iteration 44315, loss = 36.64075213\n",
      "Iteration 44316, loss = 36.63443181\n",
      "Iteration 44317, loss = 36.62811213\n",
      "Iteration 44318, loss = 36.62179310\n",
      "Iteration 44319, loss = 36.61547471\n",
      "Iteration 44320, loss = 36.60915695\n",
      "Iteration 44321, loss = 36.60283982\n",
      "Iteration 44322, loss = 36.59652334\n",
      "Iteration 44323, loss = 36.59020749\n",
      "Iteration 44324, loss = 36.58389229\n",
      "Iteration 44325, loss = 36.57757772\n",
      "Iteration 44326, loss = 36.57126379\n",
      "Iteration 44327, loss = 36.56495050\n",
      "Iteration 44328, loss = 36.55863784\n",
      "Iteration 44329, loss = 36.55232583\n",
      "Iteration 44330, loss = 36.54601446\n",
      "Iteration 44331, loss = 36.53970372\n",
      "Iteration 44332, loss = 36.53339362\n",
      "Iteration 44333, loss = 36.52708416\n",
      "Iteration 44334, loss = 36.52077534\n",
      "Iteration 44335, loss = 36.51446715\n",
      "Iteration 44336, loss = 36.50815961\n",
      "Iteration 44337, loss = 36.50185270\n",
      "Iteration 44338, loss = 36.49554644\n",
      "Iteration 44339, loss = 36.48924081\n",
      "Iteration 44340, loss = 36.48293582\n",
      "Iteration 44341, loss = 36.47663147\n",
      "Iteration 44342, loss = 36.47032776\n",
      "Iteration 44343, loss = 36.46402469\n",
      "Iteration 44344, loss = 36.45772225\n",
      "Iteration 44345, loss = 36.45142046\n",
      "Iteration 44346, loss = 36.44511930\n",
      "Iteration 44347, loss = 36.43881879\n",
      "Iteration 44348, loss = 36.43251891\n",
      "Iteration 44349, loss = 36.42621967\n",
      "Iteration 44350, loss = 36.41992107\n",
      "Iteration 44351, loss = 36.41362311\n",
      "Iteration 44352, loss = 36.40732579\n",
      "Iteration 44353, loss = 36.40102911\n",
      "Iteration 44354, loss = 36.39473306\n",
      "Iteration 44355, loss = 36.38843766\n",
      "Iteration 44356, loss = 36.38214290\n",
      "Iteration 44357, loss = 36.37584877\n",
      "Iteration 44358, loss = 36.36955529\n",
      "Iteration 44359, loss = 36.36326244\n",
      "Iteration 44360, loss = 36.35697023\n",
      "Iteration 44361, loss = 36.35067866\n",
      "Iteration 44362, loss = 36.34438773\n",
      "Iteration 44363, loss = 36.33809745\n",
      "Iteration 44364, loss = 36.33180780\n",
      "Iteration 44365, loss = 36.32551879\n",
      "Iteration 44366, loss = 36.31923042\n",
      "Iteration 44367, loss = 36.31294268\n",
      "Iteration 44368, loss = 36.30665559\n",
      "Iteration 44369, loss = 36.30036914\n",
      "Iteration 44370, loss = 36.29408333\n",
      "Iteration 44371, loss = 36.28779815\n",
      "Iteration 44372, loss = 36.28151362\n",
      "Iteration 44373, loss = 36.27522973\n",
      "Iteration 44374, loss = 36.26894647\n",
      "Iteration 44375, loss = 36.26266386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44376, loss = 36.25638188\n",
      "Iteration 44377, loss = 36.25010055\n",
      "Iteration 44378, loss = 36.24381985\n",
      "Iteration 44379, loss = 36.23753979\n",
      "Iteration 44380, loss = 36.23126038\n",
      "Iteration 44381, loss = 36.22498160\n",
      "Iteration 44382, loss = 36.21870346\n",
      "Iteration 44383, loss = 36.21242597\n",
      "Iteration 44384, loss = 36.20614911\n",
      "Iteration 44385, loss = 36.19987289\n",
      "Iteration 44386, loss = 36.19359731\n",
      "Iteration 44387, loss = 36.18732237\n",
      "Iteration 44388, loss = 36.18104808\n",
      "Iteration 44389, loss = 36.17477442\n",
      "Iteration 44390, loss = 36.16850140\n",
      "Iteration 44391, loss = 36.16222902\n",
      "Iteration 44392, loss = 36.15595728\n",
      "Iteration 44393, loss = 36.14968618\n",
      "Iteration 44394, loss = 36.14341572\n",
      "Iteration 44395, loss = 36.13714590\n",
      "Iteration 44396, loss = 36.13087671\n",
      "Iteration 44397, loss = 36.12460817\n",
      "Iteration 44398, loss = 36.11834027\n",
      "Iteration 44399, loss = 36.11207301\n",
      "Iteration 44400, loss = 36.10580639\n",
      "Iteration 44401, loss = 36.09954041\n",
      "Iteration 44402, loss = 36.09327506\n",
      "Iteration 44403, loss = 36.08701036\n",
      "Iteration 44404, loss = 36.08074630\n",
      "Iteration 44405, loss = 36.07448287\n",
      "Iteration 44406, loss = 36.06822009\n",
      "Iteration 44407, loss = 36.06195794\n",
      "Iteration 44408, loss = 36.05569644\n",
      "Iteration 44409, loss = 36.04943557\n",
      "Iteration 44410, loss = 36.04317535\n",
      "Iteration 44411, loss = 36.03691576\n",
      "Iteration 44412, loss = 36.03065682\n",
      "Iteration 44413, loss = 36.02439851\n",
      "Iteration 44414, loss = 36.01814085\n",
      "Iteration 44415, loss = 36.01188382\n",
      "Iteration 44416, loss = 36.00562744\n",
      "Iteration 44417, loss = 35.99937170\n",
      "Iteration 44418, loss = 35.99311661\n",
      "Iteration 44419, loss = 35.98686217\n",
      "Iteration 44420, loss = 35.98060840\n",
      "Iteration 44421, loss = 35.97435530\n",
      "Iteration 44422, loss = 35.96810290\n",
      "Iteration 44423, loss = 35.96185123\n",
      "Iteration 44424, loss = 35.95560036\n",
      "Iteration 44425, loss = 35.94935033\n",
      "Iteration 44426, loss = 35.94310116\n",
      "Iteration 44427, loss = 35.93685268\n",
      "Iteration 44428, loss = 35.93060450\n",
      "Iteration 44429, loss = 35.92435608\n",
      "Iteration 44430, loss = 35.91810733\n",
      "Iteration 44431, loss = 35.91185900\n",
      "Iteration 44432, loss = 35.90561216\n",
      "Iteration 44433, loss = 35.89936709\n",
      "Iteration 44434, loss = 35.89312309\n",
      "Iteration 44435, loss = 35.88687921\n",
      "Iteration 44436, loss = 35.88063508\n",
      "Iteration 44437, loss = 35.87439127\n",
      "Iteration 44438, loss = 35.86814861\n",
      "Iteration 44439, loss = 35.86190729\n",
      "Iteration 44440, loss = 35.85566672\n",
      "Iteration 44441, loss = 35.84942631\n",
      "Iteration 44442, loss = 35.84318609\n",
      "Iteration 44443, loss = 35.83694658\n",
      "Iteration 44444, loss = 35.83070814\n",
      "Iteration 44445, loss = 35.82447059\n",
      "Iteration 44446, loss = 35.81823349\n",
      "Iteration 44447, loss = 35.81199671\n",
      "Iteration 44448, loss = 35.80576051\n",
      "Iteration 44449, loss = 35.79952517\n",
      "Iteration 44450, loss = 35.79329067\n",
      "Iteration 44451, loss = 35.78705675\n",
      "Iteration 44452, loss = 35.78082328\n",
      "Iteration 44453, loss = 35.77459037\n",
      "Iteration 44454, loss = 35.76835820\n",
      "Iteration 44455, loss = 35.76212680\n",
      "Iteration 44456, loss = 35.75589604\n",
      "Iteration 44457, loss = 35.74966582\n",
      "Iteration 44458, loss = 35.74343617\n",
      "Iteration 44459, loss = 35.73720719\n",
      "Iteration 44460, loss = 35.73097893\n",
      "Iteration 44461, loss = 35.72475133\n",
      "Iteration 44462, loss = 35.71852433\n",
      "Iteration 44463, loss = 35.71229790\n",
      "Iteration 44464, loss = 35.70607212\n",
      "Iteration 44465, loss = 35.69984702\n",
      "Iteration 44466, loss = 35.69362259\n",
      "Iteration 44467, loss = 35.68739878\n",
      "Iteration 44468, loss = 35.68117557\n",
      "Iteration 44469, loss = 35.67495298\n",
      "Iteration 44470, loss = 35.66873106\n",
      "Iteration 44471, loss = 35.66250980\n",
      "Iteration 44472, loss = 35.65628917\n",
      "Iteration 44473, loss = 35.65006916\n",
      "Iteration 44474, loss = 35.64384977\n",
      "Iteration 44475, loss = 35.63763103\n",
      "Iteration 44476, loss = 35.63141294\n",
      "Iteration 44477, loss = 35.62519549\n",
      "Iteration 44478, loss = 35.61897867\n",
      "Iteration 44479, loss = 35.61276247\n",
      "Iteration 44480, loss = 35.60654691\n",
      "Iteration 44481, loss = 35.60033200\n",
      "Iteration 44482, loss = 35.59411772\n",
      "Iteration 44483, loss = 35.58790409\n",
      "Iteration 44484, loss = 35.58169108\n",
      "Iteration 44485, loss = 35.57547870\n",
      "Iteration 44486, loss = 35.56926696\n",
      "Iteration 44487, loss = 35.56305587\n",
      "Iteration 44488, loss = 35.55684541\n",
      "Iteration 44489, loss = 35.55063558\n",
      "Iteration 44490, loss = 35.54442639\n",
      "Iteration 44491, loss = 35.53821783\n",
      "Iteration 44492, loss = 35.53200991\n",
      "Iteration 44493, loss = 35.52580263\n",
      "Iteration 44494, loss = 35.51959598\n",
      "Iteration 44495, loss = 35.51338997\n",
      "Iteration 44496, loss = 35.50718459\n",
      "Iteration 44497, loss = 35.50097985\n",
      "Iteration 44498, loss = 35.49477574\n",
      "Iteration 44499, loss = 35.48857227\n",
      "Iteration 44500, loss = 35.48236943\n",
      "Iteration 44501, loss = 35.47616723\n",
      "Iteration 44502, loss = 35.46996566\n",
      "Iteration 44503, loss = 35.46376473\n",
      "Iteration 44504, loss = 35.45756443\n",
      "Iteration 44505, loss = 35.45136477\n",
      "Iteration 44506, loss = 35.44516575\n",
      "Iteration 44507, loss = 35.43896735\n",
      "Iteration 44508, loss = 35.43276960\n",
      "Iteration 44509, loss = 35.42657247\n",
      "Iteration 44510, loss = 35.42037598\n",
      "Iteration 44511, loss = 35.41418013\n",
      "Iteration 44512, loss = 35.40798491\n",
      "Iteration 44513, loss = 35.40179033\n",
      "Iteration 44514, loss = 35.39559638\n",
      "Iteration 44515, loss = 35.38940306\n",
      "Iteration 44516, loss = 35.38321038\n",
      "Iteration 44517, loss = 35.37701833\n",
      "Iteration 44518, loss = 35.37082692\n",
      "Iteration 44519, loss = 35.36463615\n",
      "Iteration 44520, loss = 35.35844600\n",
      "Iteration 44521, loss = 35.35225650\n",
      "Iteration 44522, loss = 35.34606763\n",
      "Iteration 44523, loss = 35.33987940\n",
      "Iteration 44524, loss = 35.33369180\n",
      "Iteration 44525, loss = 35.32750486\n",
      "Iteration 44526, loss = 35.32131856\n",
      "Iteration 44527, loss = 35.31513292\n",
      "Iteration 44528, loss = 35.30894795\n",
      "Iteration 44529, loss = 35.30276367\n",
      "Iteration 44530, loss = 35.29658013\n",
      "Iteration 44531, loss = 35.29039739\n",
      "Iteration 44532, loss = 35.28421554\n",
      "Iteration 44533, loss = 35.27803475\n",
      "Iteration 44534, loss = 35.27185529\n",
      "Iteration 44535, loss = 35.26567760\n",
      "Iteration 44536, loss = 35.25950234\n",
      "Iteration 44537, loss = 35.25333052\n",
      "Iteration 44538, loss = 35.24716346\n",
      "Iteration 44539, loss = 35.24100257\n",
      "Iteration 44540, loss = 35.23484818\n",
      "Iteration 44541, loss = 35.22869769\n",
      "Iteration 44542, loss = 35.22254213\n",
      "Iteration 44543, loss = 35.21636801\n",
      "Iteration 44544, loss = 35.21016558\n",
      "Iteration 44545, loss = 35.20394511\n",
      "Iteration 44546, loss = 35.19773392\n",
      "Iteration 44547, loss = 35.19155362\n",
      "Iteration 44548, loss = 35.18540094\n",
      "Iteration 44549, loss = 35.17925335\n",
      "Iteration 44550, loss = 35.17308845\n",
      "Iteration 44551, loss = 35.16690118\n",
      "Iteration 44552, loss = 35.16070762\n",
      "Iteration 44553, loss = 35.15452827\n",
      "Iteration 44554, loss = 35.14836808\n",
      "Iteration 44555, loss = 35.14221427\n",
      "Iteration 44556, loss = 35.13605117\n",
      "Iteration 44557, loss = 35.12987521\n",
      "Iteration 44558, loss = 35.12369657\n",
      "Iteration 44559, loss = 35.11752716\n",
      "Iteration 44560, loss = 35.11136837\n",
      "Iteration 44561, loss = 35.10521161\n",
      "Iteration 44562, loss = 35.09904863\n",
      "Iteration 44563, loss = 35.09287949\n",
      "Iteration 44564, loss = 35.08671113\n",
      "Iteration 44565, loss = 35.08054916\n",
      "Iteration 44566, loss = 35.07439242\n",
      "Iteration 44567, loss = 35.06823545\n",
      "Iteration 44568, loss = 35.06207472\n",
      "Iteration 44569, loss = 35.05591178\n",
      "Iteration 44570, loss = 35.04975078\n",
      "Iteration 44571, loss = 35.04359381\n",
      "Iteration 44572, loss = 35.03743922\n",
      "Iteration 44573, loss = 35.03128398\n",
      "Iteration 44574, loss = 35.02512693\n",
      "Iteration 44575, loss = 35.01896956\n",
      "Iteration 44576, loss = 35.01281403\n",
      "Iteration 44577, loss = 35.00666093\n",
      "Iteration 44578, loss = 35.00050898\n",
      "Iteration 44579, loss = 34.99435668\n",
      "Iteration 44580, loss = 34.98820378\n",
      "Iteration 44581, loss = 34.98205126\n",
      "Iteration 44582, loss = 34.97590019\n",
      "Iteration 44583, loss = 34.96975064\n",
      "Iteration 44584, loss = 34.96360184\n",
      "Iteration 44585, loss = 34.95745307\n",
      "Iteration 44586, loss = 34.95130431\n",
      "Iteration 44587, loss = 34.94515615\n",
      "Iteration 44588, loss = 34.93900909\n",
      "Iteration 44589, loss = 34.93286310\n",
      "Iteration 44590, loss = 34.92671778\n",
      "Iteration 44591, loss = 34.92057275\n",
      "Iteration 44592, loss = 34.91442803\n",
      "Iteration 44593, loss = 34.90828394\n",
      "Iteration 44594, loss = 34.90214072\n",
      "Iteration 44595, loss = 34.89599837\n",
      "Iteration 44596, loss = 34.88985667\n",
      "Iteration 44597, loss = 34.88371544\n",
      "Iteration 44598, loss = 34.87757467\n",
      "Iteration 44599, loss = 34.87143451\n",
      "Iteration 44600, loss = 34.86529509\n",
      "Iteration 44601, loss = 34.85915644\n",
      "Iteration 44602, loss = 34.85301845\n",
      "Iteration 44603, loss = 34.84688102\n",
      "Iteration 44604, loss = 34.84074413\n",
      "Iteration 44605, loss = 34.83460783\n",
      "Iteration 44606, loss = 34.82847221\n",
      "Iteration 44607, loss = 34.82233730\n",
      "Iteration 44608, loss = 34.81620305\n",
      "Iteration 44609, loss = 34.81006941\n",
      "Iteration 44610, loss = 34.80393635\n",
      "Iteration 44611, loss = 34.79780389\n",
      "Iteration 44612, loss = 34.79167207\n",
      "Iteration 44613, loss = 34.78554092\n",
      "Iteration 44614, loss = 34.77941042\n",
      "Iteration 44615, loss = 34.77328056\n",
      "Iteration 44616, loss = 34.76715132\n",
      "Iteration 44617, loss = 34.76102268\n",
      "Iteration 44618, loss = 34.75489466\n",
      "Iteration 44619, loss = 34.74876728\n",
      "Iteration 44620, loss = 34.74264056\n",
      "Iteration 44621, loss = 34.73651447\n",
      "Iteration 44622, loss = 34.73038902\n",
      "Iteration 44623, loss = 34.72426418\n",
      "Iteration 44624, loss = 34.71813997\n",
      "Iteration 44625, loss = 34.71201638\n",
      "Iteration 44626, loss = 34.70589343\n",
      "Iteration 44627, loss = 34.69977113\n",
      "Iteration 44628, loss = 34.69364945\n",
      "Iteration 44629, loss = 34.68752841\n",
      "Iteration 44630, loss = 34.68140799\n",
      "Iteration 44631, loss = 34.67528820\n",
      "Iteration 44632, loss = 34.66916904\n",
      "Iteration 44633, loss = 34.66305051\n",
      "Iteration 44634, loss = 34.65693262\n",
      "Iteration 44635, loss = 34.65081536\n",
      "Iteration 44636, loss = 34.64469873\n",
      "Iteration 44637, loss = 34.63858273\n",
      "Iteration 44638, loss = 34.63246735\n",
      "Iteration 44639, loss = 34.62635261\n",
      "Iteration 44640, loss = 34.62023850\n",
      "Iteration 44641, loss = 34.61412503\n",
      "Iteration 44642, loss = 34.60801218\n",
      "Iteration 44643, loss = 34.60189997\n",
      "Iteration 44644, loss = 34.59578838\n",
      "Iteration 44645, loss = 34.58967743\n",
      "Iteration 44646, loss = 34.58356711\n",
      "Iteration 44647, loss = 34.57745741\n",
      "Iteration 44648, loss = 34.57134835\n",
      "Iteration 44649, loss = 34.56523992\n",
      "Iteration 44650, loss = 34.55913212\n",
      "Iteration 44651, loss = 34.55302496\n",
      "Iteration 44652, loss = 34.54691842\n",
      "Iteration 44653, loss = 34.54081251\n",
      "Iteration 44654, loss = 34.53470724\n",
      "Iteration 44655, loss = 34.52860259\n",
      "Iteration 44656, loss = 34.52249857\n",
      "Iteration 44657, loss = 34.51639519\n",
      "Iteration 44658, loss = 34.51029244\n",
      "Iteration 44659, loss = 34.50419032\n",
      "Iteration 44660, loss = 34.49808882\n",
      "Iteration 44661, loss = 34.49198796\n",
      "Iteration 44662, loss = 34.48588773\n",
      "Iteration 44663, loss = 34.47978813\n",
      "Iteration 44664, loss = 34.47368916\n",
      "Iteration 44665, loss = 34.46759082\n",
      "Iteration 44666, loss = 34.46149312\n",
      "Iteration 44667, loss = 34.45539604\n",
      "Iteration 44668, loss = 34.44929959\n",
      "Iteration 44669, loss = 34.44320378\n",
      "Iteration 44670, loss = 34.43710859\n",
      "Iteration 44671, loss = 34.43101404\n",
      "Iteration 44672, loss = 34.42492011\n",
      "Iteration 44673, loss = 34.41882682\n",
      "Iteration 44674, loss = 34.41273415\n",
      "Iteration 44675, loss = 34.40664212\n",
      "Iteration 44676, loss = 34.40055072\n",
      "Iteration 44677, loss = 34.39445995\n",
      "Iteration 44678, loss = 34.38836980\n",
      "Iteration 44679, loss = 34.38228029\n",
      "Iteration 44680, loss = 34.37619141\n",
      "Iteration 44681, loss = 34.37010316\n",
      "Iteration 44682, loss = 34.36401554\n",
      "Iteration 44683, loss = 34.35792855\n",
      "Iteration 44684, loss = 34.35184220\n",
      "Iteration 44685, loss = 34.34575647\n",
      "Iteration 44686, loss = 34.33967137\n",
      "Iteration 44687, loss = 34.33358690\n",
      "Iteration 44688, loss = 34.32750307\n",
      "Iteration 44689, loss = 34.32141986\n",
      "Iteration 44690, loss = 34.31533729\n",
      "Iteration 44691, loss = 34.30925535\n",
      "Iteration 44692, loss = 34.30317405\n",
      "Iteration 44693, loss = 34.29709338\n",
      "Iteration 44694, loss = 34.29101335\n",
      "Iteration 44695, loss = 34.28493397\n",
      "Iteration 44696, loss = 34.27885525\n",
      "Iteration 44697, loss = 34.27277719\n",
      "Iteration 44698, loss = 34.26669982\n",
      "Iteration 44699, loss = 34.26062316\n",
      "Iteration 44700, loss = 34.25454723\n",
      "Iteration 44701, loss = 34.24847203\n",
      "Iteration 44702, loss = 34.24239754\n",
      "Iteration 44703, loss = 34.23632360\n",
      "Iteration 44704, loss = 34.23024998\n",
      "Iteration 44705, loss = 34.22417649\n",
      "Iteration 44706, loss = 34.21810318\n",
      "Iteration 44707, loss = 34.21203042\n",
      "Iteration 44708, loss = 34.20595871\n",
      "Iteration 44709, loss = 34.19988821\n",
      "Iteration 44710, loss = 34.19381870\n",
      "Iteration 44711, loss = 34.18774975\n",
      "Iteration 44712, loss = 34.18168105\n",
      "Iteration 44713, loss = 34.17561261\n",
      "Iteration 44714, loss = 34.16954472\n",
      "Iteration 44715, loss = 34.16347770\n",
      "Iteration 44716, loss = 34.15741162\n",
      "Iteration 44717, loss = 34.15134632\n",
      "Iteration 44718, loss = 34.14528153\n",
      "Iteration 44719, loss = 34.13921713\n",
      "Iteration 44720, loss = 34.13315323\n",
      "Iteration 44721, loss = 34.12709002\n",
      "Iteration 44722, loss = 34.12102762\n",
      "Iteration 44723, loss = 34.11496596\n",
      "Iteration 44724, loss = 34.10890492\n",
      "Iteration 44725, loss = 34.10284438\n",
      "Iteration 44726, loss = 34.09678438\n",
      "Iteration 44727, loss = 34.09072501\n",
      "Iteration 44728, loss = 34.08466636\n",
      "Iteration 44729, loss = 34.07860841\n",
      "Iteration 44730, loss = 34.07255111\n",
      "Iteration 44731, loss = 34.06649438\n",
      "Iteration 44732, loss = 34.06043822\n",
      "Iteration 44733, loss = 34.05438267\n",
      "Iteration 44734, loss = 34.04832780\n",
      "Iteration 44735, loss = 34.04227359\n",
      "Iteration 44736, loss = 34.03622004\n",
      "Iteration 44737, loss = 34.03016709\n",
      "Iteration 44738, loss = 34.02411475\n",
      "Iteration 44739, loss = 34.01806301\n",
      "Iteration 44740, loss = 34.01201192\n",
      "Iteration 44741, loss = 34.00596148\n",
      "Iteration 44742, loss = 33.99991168\n",
      "Iteration 44743, loss = 33.99386251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44744, loss = 33.98781396\n",
      "Iteration 44745, loss = 33.98176602\n",
      "Iteration 44746, loss = 33.97571872\n",
      "Iteration 44747, loss = 33.96967205\n",
      "Iteration 44748, loss = 33.96362603\n",
      "Iteration 44749, loss = 33.95758064\n",
      "Iteration 44750, loss = 33.95153588\n",
      "Iteration 44751, loss = 33.94549174\n",
      "Iteration 44752, loss = 33.93944824\n",
      "Iteration 44753, loss = 33.93340537\n",
      "Iteration 44754, loss = 33.92736315\n",
      "Iteration 44755, loss = 33.92132158\n",
      "Iteration 44756, loss = 33.91528067\n",
      "Iteration 44757, loss = 33.90924041\n",
      "Iteration 44758, loss = 33.90320084\n",
      "Iteration 44759, loss = 33.89716196\n",
      "Iteration 44760, loss = 33.89112383\n",
      "Iteration 44761, loss = 33.88508651\n",
      "Iteration 44762, loss = 33.87905006\n",
      "Iteration 44763, loss = 33.87301462\n",
      "Iteration 44764, loss = 33.86698038\n",
      "Iteration 44765, loss = 33.86094760\n",
      "Iteration 44766, loss = 33.85491667\n",
      "Iteration 44767, loss = 33.84888807\n",
      "Iteration 44768, loss = 33.84286237\n",
      "Iteration 44769, loss = 33.83684002\n",
      "Iteration 44770, loss = 33.83082089\n",
      "Iteration 44771, loss = 33.82480366\n",
      "Iteration 44772, loss = 33.81878474\n",
      "Iteration 44773, loss = 33.81275884\n",
      "Iteration 44774, loss = 33.80672080\n",
      "Iteration 44775, loss = 33.80067092\n",
      "Iteration 44776, loss = 33.79461689\n",
      "Iteration 44777, loss = 33.78857038\n",
      "Iteration 44778, loss = 33.78253868\n",
      "Iteration 44779, loss = 33.77652033\n",
      "Iteration 44780, loss = 33.77050727\n",
      "Iteration 44781, loss = 33.76449026\n",
      "Iteration 44782, loss = 33.75846410\n",
      "Iteration 44783, loss = 33.75243028\n",
      "Iteration 44784, loss = 33.74639564\n",
      "Iteration 44785, loss = 33.74036708\n",
      "Iteration 44786, loss = 33.73434677\n",
      "Iteration 44787, loss = 33.72833147\n",
      "Iteration 44788, loss = 33.72231573\n",
      "Iteration 44789, loss = 33.71629584\n",
      "Iteration 44790, loss = 33.71027200\n",
      "Iteration 44791, loss = 33.70424760\n",
      "Iteration 44792, loss = 33.69822631\n",
      "Iteration 44793, loss = 33.69220941\n",
      "Iteration 44794, loss = 33.68619540\n",
      "Iteration 44795, loss = 33.68018152\n",
      "Iteration 44796, loss = 33.67416593\n",
      "Iteration 44797, loss = 33.66814875\n",
      "Iteration 44798, loss = 33.66213165\n",
      "Iteration 44799, loss = 33.65611637\n",
      "Iteration 44800, loss = 33.65010352\n",
      "Iteration 44801, loss = 33.64409239\n",
      "Iteration 44802, loss = 33.63808167\n",
      "Iteration 44803, loss = 33.63207048\n",
      "Iteration 44804, loss = 33.62605885\n",
      "Iteration 44805, loss = 33.62004753\n",
      "Iteration 44806, loss = 33.61403735\n",
      "Iteration 44807, loss = 33.60802865\n",
      "Iteration 44808, loss = 33.60202115\n",
      "Iteration 44809, loss = 33.59601427\n",
      "Iteration 44810, loss = 33.59000755\n",
      "Iteration 44811, loss = 33.58400092\n",
      "Iteration 44812, loss = 33.57799468\n",
      "Iteration 44813, loss = 33.57198922\n",
      "Iteration 44814, loss = 33.56598477\n",
      "Iteration 44815, loss = 33.55998127\n",
      "Iteration 44816, loss = 33.55397850\n",
      "Iteration 44817, loss = 33.54797620\n",
      "Iteration 44818, loss = 33.54197428\n",
      "Iteration 44819, loss = 33.53597281\n",
      "Iteration 44820, loss = 33.52997195\n",
      "Iteration 44821, loss = 33.52397185\n",
      "Iteration 44822, loss = 33.51797255\n",
      "Iteration 44823, loss = 33.51197398\n",
      "Iteration 44824, loss = 33.50597604\n",
      "Iteration 44825, loss = 33.49997865\n",
      "Iteration 44826, loss = 33.49398178\n",
      "Iteration 44827, loss = 33.48798548\n",
      "Iteration 44828, loss = 33.48198981\n",
      "Iteration 44829, loss = 33.47599482\n",
      "Iteration 44830, loss = 33.47000054\n",
      "Iteration 44831, loss = 33.46400693\n",
      "Iteration 44832, loss = 33.45801394\n",
      "Iteration 44833, loss = 33.45202156\n",
      "Iteration 44834, loss = 33.44602976\n",
      "Iteration 44835, loss = 33.44003856\n",
      "Iteration 44836, loss = 33.43404798\n",
      "Iteration 44837, loss = 33.42805805\n",
      "Iteration 44838, loss = 33.42206878\n",
      "Iteration 44839, loss = 33.41608016\n",
      "Iteration 44840, loss = 33.41009217\n",
      "Iteration 44841, loss = 33.40410481\n",
      "Iteration 44842, loss = 33.39811806\n",
      "Iteration 44843, loss = 33.39213192\n",
      "Iteration 44844, loss = 33.38614640\n",
      "Iteration 44845, loss = 33.38016152\n",
      "Iteration 44846, loss = 33.37417727\n",
      "Iteration 44847, loss = 33.36819366\n",
      "Iteration 44848, loss = 33.36221069\n",
      "Iteration 44849, loss = 33.35622834\n",
      "Iteration 44850, loss = 33.35024663\n",
      "Iteration 44851, loss = 33.34426553\n",
      "Iteration 44852, loss = 33.33828506\n",
      "Iteration 44853, loss = 33.33230522\n",
      "Iteration 44854, loss = 33.32632600\n",
      "Iteration 44855, loss = 33.32034741\n",
      "Iteration 44856, loss = 33.31436946\n",
      "Iteration 44857, loss = 33.30839214\n",
      "Iteration 44858, loss = 33.30241544\n",
      "Iteration 44859, loss = 33.29643938\n",
      "Iteration 44860, loss = 33.29046394\n",
      "Iteration 44861, loss = 33.28448914\n",
      "Iteration 44862, loss = 33.27851495\n",
      "Iteration 44863, loss = 33.27254140\n",
      "Iteration 44864, loss = 33.26656847\n",
      "Iteration 44865, loss = 33.26059617\n",
      "Iteration 44866, loss = 33.25462450\n",
      "Iteration 44867, loss = 33.24865346\n",
      "Iteration 44868, loss = 33.24268305\n",
      "Iteration 44869, loss = 33.23671327\n",
      "Iteration 44870, loss = 33.23074412\n",
      "Iteration 44871, loss = 33.22477559\n",
      "Iteration 44872, loss = 33.21880770\n",
      "Iteration 44873, loss = 33.21284043\n",
      "Iteration 44874, loss = 33.20687379\n",
      "Iteration 44875, loss = 33.20090778\n",
      "Iteration 44876, loss = 33.19494239\n",
      "Iteration 44877, loss = 33.18897764\n",
      "Iteration 44878, loss = 33.18301351\n",
      "Iteration 44879, loss = 33.17705001\n",
      "Iteration 44880, loss = 33.17108714\n",
      "Iteration 44881, loss = 33.16512490\n",
      "Iteration 44882, loss = 33.15916328\n",
      "Iteration 44883, loss = 33.15320230\n",
      "Iteration 44884, loss = 33.14724194\n",
      "Iteration 44885, loss = 33.14128221\n",
      "Iteration 44886, loss = 33.13532311\n",
      "Iteration 44887, loss = 33.12936464\n",
      "Iteration 44888, loss = 33.12340679\n",
      "Iteration 44889, loss = 33.11744958\n",
      "Iteration 44890, loss = 33.11149299\n",
      "Iteration 44891, loss = 33.10553703\n",
      "Iteration 44892, loss = 33.09958170\n",
      "Iteration 44893, loss = 33.09362700\n",
      "Iteration 44894, loss = 33.08767292\n",
      "Iteration 44895, loss = 33.08171947\n",
      "Iteration 44896, loss = 33.07576665\n",
      "Iteration 44897, loss = 33.06981446\n",
      "Iteration 44898, loss = 33.06386290\n",
      "Iteration 44899, loss = 33.05791197\n",
      "Iteration 44900, loss = 33.05196166\n",
      "Iteration 44901, loss = 33.04601198\n",
      "Iteration 44902, loss = 33.04006293\n",
      "Iteration 44903, loss = 33.03411451\n",
      "Iteration 44904, loss = 33.02816672\n",
      "Iteration 44905, loss = 33.02221955\n",
      "Iteration 44906, loss = 33.01627301\n",
      "Iteration 44907, loss = 33.01032710\n",
      "Iteration 44908, loss = 33.00438182\n",
      "Iteration 44909, loss = 32.99843717\n",
      "Iteration 44910, loss = 32.99249314\n",
      "Iteration 44911, loss = 32.98654974\n",
      "Iteration 44912, loss = 32.98060697\n",
      "Iteration 44913, loss = 32.97466483\n",
      "Iteration 44914, loss = 32.96872332\n",
      "Iteration 44915, loss = 32.96278243\n",
      "Iteration 44916, loss = 32.95684218\n",
      "Iteration 44917, loss = 32.95090255\n",
      "Iteration 44918, loss = 32.94496356\n",
      "Iteration 44919, loss = 32.93902519\n",
      "Iteration 44920, loss = 32.93308746\n",
      "Iteration 44921, loss = 32.92715036\n",
      "Iteration 44922, loss = 32.92121391\n",
      "Iteration 44923, loss = 32.91527811\n",
      "Iteration 44924, loss = 32.90934299\n",
      "Iteration 44925, loss = 32.90340855\n",
      "Iteration 44926, loss = 32.89747485\n",
      "Iteration 44927, loss = 32.89154193\n",
      "Iteration 44928, loss = 32.88560983\n",
      "Iteration 44929, loss = 32.87967853\n",
      "Iteration 44930, loss = 32.87374783\n",
      "Iteration 44931, loss = 32.86781737\n",
      "Iteration 44932, loss = 32.86188672\n",
      "Iteration 44933, loss = 32.85595596\n",
      "Iteration 44934, loss = 32.85002585\n",
      "Iteration 44935, loss = 32.84409726\n",
      "Iteration 44936, loss = 32.83817035\n",
      "Iteration 44937, loss = 32.83224452\n",
      "Iteration 44938, loss = 32.82631907\n",
      "Iteration 44939, loss = 32.82039384\n",
      "Iteration 44940, loss = 32.81446948\n",
      "Iteration 44941, loss = 32.80854693\n",
      "Iteration 44942, loss = 32.80262673\n",
      "Iteration 44943, loss = 32.79670897\n",
      "Iteration 44944, loss = 32.79079369\n",
      "Iteration 44945, loss = 32.78488138\n",
      "Iteration 44946, loss = 32.77897250\n",
      "Iteration 44947, loss = 32.77306650\n",
      "Iteration 44948, loss = 32.76716017\n",
      "Iteration 44949, loss = 32.76124794\n",
      "Iteration 44950, loss = 32.75532359\n",
      "Iteration 44951, loss = 32.74938585\n",
      "Iteration 44952, loss = 32.74344139\n",
      "Iteration 44953, loss = 32.73750257\n",
      "Iteration 44954, loss = 32.73157856\n",
      "Iteration 44955, loss = 32.72566946\n",
      "Iteration 44956, loss = 32.71976754\n",
      "Iteration 44957, loss = 32.71386287\n",
      "Iteration 44958, loss = 32.70794902\n",
      "Iteration 44959, loss = 32.70202640\n",
      "Iteration 44960, loss = 32.69610168\n",
      "Iteration 44961, loss = 32.69018257\n",
      "Iteration 44962, loss = 32.68427223\n",
      "Iteration 44963, loss = 32.67836782\n",
      "Iteration 44964, loss = 32.67246349\n",
      "Iteration 44965, loss = 32.66655485\n",
      "Iteration 44966, loss = 32.66064169\n",
      "Iteration 44967, loss = 32.65472754\n",
      "Iteration 44968, loss = 32.64881654\n",
      "Iteration 44969, loss = 32.64291032\n",
      "Iteration 44970, loss = 32.63700729\n",
      "Iteration 44971, loss = 32.63110440\n",
      "Iteration 44972, loss = 32.62519954\n",
      "Iteration 44973, loss = 32.61929285\n",
      "Iteration 44974, loss = 32.61338622\n",
      "Iteration 44975, loss = 32.60748160\n",
      "Iteration 44976, loss = 32.60157962\n",
      "Iteration 44977, loss = 32.59567937\n",
      "Iteration 44978, loss = 32.58977942\n",
      "Iteration 44979, loss = 32.58387882\n",
      "Iteration 44980, loss = 32.57797772\n",
      "Iteration 44981, loss = 32.57207701\n",
      "Iteration 44982, loss = 32.56617758\n",
      "Iteration 44983, loss = 32.56027971\n",
      "Iteration 44984, loss = 32.55438301\n",
      "Iteration 44985, loss = 32.54848683\n",
      "Iteration 44986, loss = 32.54259070\n",
      "Iteration 44987, loss = 32.53669465\n",
      "Iteration 44988, loss = 32.53079905\n",
      "Iteration 44989, loss = 32.52490432\n",
      "Iteration 44990, loss = 32.51901065\n",
      "Iteration 44991, loss = 32.51311792\n",
      "Iteration 44992, loss = 32.50722584\n",
      "Iteration 44993, loss = 32.50133417\n",
      "Iteration 44994, loss = 32.49544284\n",
      "Iteration 44995, loss = 32.48955199\n",
      "Iteration 44996, loss = 32.48366182\n",
      "Iteration 44997, loss = 32.47777245\n",
      "Iteration 44998, loss = 32.47188389\n",
      "Iteration 44999, loss = 32.46599603\n",
      "Iteration 45000, loss = 32.46010875\n",
      "Iteration 45001, loss = 32.45422197\n",
      "Iteration 45002, loss = 32.44833571\n",
      "Iteration 45003, loss = 32.44245005\n",
      "Iteration 45004, loss = 32.43656506\n",
      "Iteration 45005, loss = 32.43068078\n",
      "Iteration 45006, loss = 32.42479720\n",
      "Iteration 45007, loss = 32.41891426\n",
      "Iteration 45008, loss = 32.41303192\n",
      "Iteration 45009, loss = 32.40715016\n",
      "Iteration 45010, loss = 32.40126898\n",
      "Iteration 45011, loss = 32.39538841\n",
      "Iteration 45012, loss = 32.38950849\n",
      "Iteration 45013, loss = 32.38362923\n",
      "Iteration 45014, loss = 32.37775063\n",
      "Iteration 45015, loss = 32.37187266\n",
      "Iteration 45016, loss = 32.36599532\n",
      "Iteration 45017, loss = 32.36011858\n",
      "Iteration 45018, loss = 32.35424245\n",
      "Iteration 45019, loss = 32.34836694\n",
      "Iteration 45020, loss = 32.34249206\n",
      "Iteration 45021, loss = 32.33661781\n",
      "Iteration 45022, loss = 32.33074420\n",
      "Iteration 45023, loss = 32.32487123\n",
      "Iteration 45024, loss = 32.31899889\n",
      "Iteration 45025, loss = 32.31312717\n",
      "Iteration 45026, loss = 32.30725607\n",
      "Iteration 45027, loss = 32.30138559\n",
      "Iteration 45028, loss = 32.29551574\n",
      "Iteration 45029, loss = 32.28964651\n",
      "Iteration 45030, loss = 32.28377791\n",
      "Iteration 45031, loss = 32.27790994\n",
      "Iteration 45032, loss = 32.27204260\n",
      "Iteration 45033, loss = 32.26617590\n",
      "Iteration 45034, loss = 32.26030981\n",
      "Iteration 45035, loss = 32.25444436\n",
      "Iteration 45036, loss = 32.24857952\n",
      "Iteration 45037, loss = 32.24271531\n",
      "Iteration 45038, loss = 32.23685173\n",
      "Iteration 45039, loss = 32.23098878\n",
      "Iteration 45040, loss = 32.22512645\n",
      "Iteration 45041, loss = 32.21926475\n",
      "Iteration 45042, loss = 32.21340368\n",
      "Iteration 45043, loss = 32.20754323\n",
      "Iteration 45044, loss = 32.20168341\n",
      "Iteration 45045, loss = 32.19582422\n",
      "Iteration 45046, loss = 32.18996566\n",
      "Iteration 45047, loss = 32.18410772\n",
      "Iteration 45048, loss = 32.17825040\n",
      "Iteration 45049, loss = 32.17239371\n",
      "Iteration 45050, loss = 32.16653765\n",
      "Iteration 45051, loss = 32.16068222\n",
      "Iteration 45052, loss = 32.15482741\n",
      "Iteration 45053, loss = 32.14897323\n",
      "Iteration 45054, loss = 32.14311968\n",
      "Iteration 45055, loss = 32.13726675\n",
      "Iteration 45056, loss = 32.13141445\n",
      "Iteration 45057, loss = 32.12556278\n",
      "Iteration 45058, loss = 32.11971173\n",
      "Iteration 45059, loss = 32.11386131\n",
      "Iteration 45060, loss = 32.10801151\n",
      "Iteration 45061, loss = 32.10216234\n",
      "Iteration 45062, loss = 32.09631380\n",
      "Iteration 45063, loss = 32.09046588\n",
      "Iteration 45064, loss = 32.08461859\n",
      "Iteration 45065, loss = 32.07877193\n",
      "Iteration 45066, loss = 32.07292589\n",
      "Iteration 45067, loss = 32.06708048\n",
      "Iteration 45068, loss = 32.06123570\n",
      "Iteration 45069, loss = 32.05539154\n",
      "Iteration 45070, loss = 32.04954801\n",
      "Iteration 45071, loss = 32.04370511\n",
      "Iteration 45072, loss = 32.03786283\n",
      "Iteration 45073, loss = 32.03202118\n",
      "Iteration 45074, loss = 32.02618015\n",
      "Iteration 45075, loss = 32.02033975\n",
      "Iteration 45076, loss = 32.01449998\n",
      "Iteration 45077, loss = 32.00866083\n",
      "Iteration 45078, loss = 32.00282231\n",
      "Iteration 45079, loss = 31.99698442\n",
      "Iteration 45080, loss = 31.99114715\n",
      "Iteration 45081, loss = 31.98531051\n",
      "Iteration 45082, loss = 31.97947449\n",
      "Iteration 45083, loss = 31.97363910\n",
      "Iteration 45084, loss = 31.96780434\n",
      "Iteration 45085, loss = 31.96197020\n",
      "Iteration 45086, loss = 31.95613669\n",
      "Iteration 45087, loss = 31.95030380\n",
      "Iteration 45088, loss = 31.94447155\n",
      "Iteration 45089, loss = 31.93863991\n",
      "Iteration 45090, loss = 31.93280891\n",
      "Iteration 45091, loss = 31.92697853\n",
      "Iteration 45092, loss = 31.92114877\n",
      "Iteration 45093, loss = 31.91531965\n",
      "Iteration 45094, loss = 31.90949115\n",
      "Iteration 45095, loss = 31.90366327\n",
      "Iteration 45096, loss = 31.89783602\n",
      "Iteration 45097, loss = 31.89200940\n",
      "Iteration 45098, loss = 31.88618340\n",
      "Iteration 45099, loss = 31.88035803\n",
      "Iteration 45100, loss = 31.87453328\n",
      "Iteration 45101, loss = 31.86870916\n",
      "Iteration 45102, loss = 31.86288567\n",
      "Iteration 45103, loss = 31.85706280\n",
      "Iteration 45104, loss = 31.85124056\n",
      "Iteration 45105, loss = 31.84541895\n",
      "Iteration 45106, loss = 31.83959796\n",
      "Iteration 45107, loss = 31.83377760\n",
      "Iteration 45108, loss = 31.82795786\n",
      "Iteration 45109, loss = 31.82213875\n",
      "Iteration 45110, loss = 31.81632027\n",
      "Iteration 45111, loss = 31.81050241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45112, loss = 31.80468517\n",
      "Iteration 45113, loss = 31.79886857\n",
      "Iteration 45114, loss = 31.79305259\n",
      "Iteration 45115, loss = 31.78723724\n",
      "Iteration 45116, loss = 31.78142251\n",
      "Iteration 45117, loss = 31.77560841\n",
      "Iteration 45118, loss = 31.76979494\n",
      "Iteration 45119, loss = 31.76398210\n",
      "Iteration 45120, loss = 31.75816989\n",
      "Iteration 45121, loss = 31.75235831\n",
      "Iteration 45122, loss = 31.74654738\n",
      "Iteration 45123, loss = 31.74073709\n",
      "Iteration 45124, loss = 31.73492747\n",
      "Iteration 45125, loss = 31.72911852\n",
      "Iteration 45126, loss = 31.72331030\n",
      "Iteration 45127, loss = 31.71750285\n",
      "Iteration 45128, loss = 31.71169626\n",
      "Iteration 45129, loss = 31.70589070\n",
      "Iteration 45130, loss = 31.70008641\n",
      "Iteration 45131, loss = 31.69428380\n",
      "Iteration 45132, loss = 31.68848349\n",
      "Iteration 45133, loss = 31.68268646\n",
      "Iteration 45134, loss = 31.67689398\n",
      "Iteration 45135, loss = 31.67110757\n",
      "Iteration 45136, loss = 31.66532794\n",
      "Iteration 45137, loss = 31.65955331\n",
      "Iteration 45138, loss = 31.65377600\n",
      "Iteration 45139, loss = 31.64798259\n",
      "Iteration 45140, loss = 31.64216088\n",
      "Iteration 45141, loss = 31.63631660\n",
      "Iteration 45142, loss = 31.63047571\n",
      "Iteration 45143, loss = 31.62466387\n",
      "Iteration 45144, loss = 31.61888286\n",
      "Iteration 45145, loss = 31.61311181\n",
      "Iteration 45146, loss = 31.60732614\n",
      "Iteration 45147, loss = 31.60151679\n",
      "Iteration 45148, loss = 31.59569736\n",
      "Iteration 45149, loss = 31.58988987\n",
      "Iteration 45150, loss = 31.58410279\n",
      "Iteration 45151, loss = 31.57832499\n",
      "Iteration 45152, loss = 31.57253936\n",
      "Iteration 45153, loss = 31.56673973\n",
      "Iteration 45154, loss = 31.56093521\n",
      "Iteration 45155, loss = 31.55513901\n",
      "Iteration 45156, loss = 31.54935455\n",
      "Iteration 45157, loss = 31.54357377\n",
      "Iteration 45158, loss = 31.53778723\n",
      "Iteration 45159, loss = 31.53199357\n",
      "Iteration 45160, loss = 31.52619954\n",
      "Iteration 45161, loss = 31.52041170\n",
      "Iteration 45162, loss = 31.51462985\n",
      "Iteration 45163, loss = 31.50884851\n",
      "Iteration 45164, loss = 31.50306342\n",
      "Iteration 45165, loss = 31.49727559\n",
      "Iteration 45166, loss = 31.49148924\n",
      "Iteration 45167, loss = 31.48570699\n",
      "Iteration 45168, loss = 31.47992747\n",
      "Iteration 45169, loss = 31.47414752\n",
      "Iteration 45170, loss = 31.46836566\n",
      "Iteration 45171, loss = 31.46258325\n",
      "Iteration 45172, loss = 31.45680259\n",
      "Iteration 45173, loss = 31.45102445\n",
      "Iteration 45174, loss = 31.44524758\n",
      "Iteration 45175, loss = 31.43947037\n",
      "Iteration 45176, loss = 31.43369246\n",
      "Iteration 45177, loss = 31.42791487\n",
      "Iteration 45178, loss = 31.42213874\n",
      "Iteration 45179, loss = 31.41636419\n",
      "Iteration 45180, loss = 31.41059042\n",
      "Iteration 45181, loss = 31.40481664\n",
      "Iteration 45182, loss = 31.39904282\n",
      "Iteration 45183, loss = 31.39326957\n",
      "Iteration 45184, loss = 31.38749744\n",
      "Iteration 45185, loss = 31.38172642\n",
      "Iteration 45186, loss = 31.37595605\n",
      "Iteration 45187, loss = 31.37018595\n",
      "Iteration 45188, loss = 31.36441614\n",
      "Iteration 45189, loss = 31.35864695\n",
      "Iteration 45190, loss = 31.35287865\n",
      "Iteration 45191, loss = 31.34711121\n",
      "Iteration 45192, loss = 31.34134442\n",
      "Iteration 45193, loss = 31.33557807\n",
      "Iteration 45194, loss = 31.32981217\n",
      "Iteration 45195, loss = 31.32404688\n",
      "Iteration 45196, loss = 31.31828235\n",
      "Iteration 45197, loss = 31.31251857\n",
      "Iteration 45198, loss = 31.30675544\n",
      "Iteration 45199, loss = 31.30099285\n",
      "Iteration 45200, loss = 31.29523079\n",
      "Iteration 45201, loss = 31.28946933\n",
      "Iteration 45202, loss = 31.28370855\n",
      "Iteration 45203, loss = 31.27794847\n",
      "Iteration 45204, loss = 31.27218905\n",
      "Iteration 45205, loss = 31.26643021\n",
      "Iteration 45206, loss = 31.26067195\n",
      "Iteration 45207, loss = 31.25491429\n",
      "Iteration 45208, loss = 31.24915726\n",
      "Iteration 45209, loss = 31.24340090\n",
      "Iteration 45210, loss = 31.23764520\n",
      "Iteration 45211, loss = 31.23189011\n",
      "Iteration 45212, loss = 31.22613562\n",
      "Iteration 45213, loss = 31.22038174\n",
      "Iteration 45214, loss = 31.21462847\n",
      "Iteration 45215, loss = 31.20887585\n",
      "Iteration 45216, loss = 31.20312387\n",
      "Iteration 45217, loss = 31.19737252\n",
      "Iteration 45218, loss = 31.19162179\n",
      "Iteration 45219, loss = 31.18587168\n",
      "Iteration 45220, loss = 31.18012217\n",
      "Iteration 45221, loss = 31.17437330\n",
      "Iteration 45222, loss = 31.16862506\n",
      "Iteration 45223, loss = 31.16287745\n",
      "Iteration 45224, loss = 31.15713047\n",
      "Iteration 45225, loss = 31.15138411\n",
      "Iteration 45226, loss = 31.14563836\n",
      "Iteration 45227, loss = 31.13989324\n",
      "Iteration 45228, loss = 31.13414874\n",
      "Iteration 45229, loss = 31.12840488\n",
      "Iteration 45230, loss = 31.12266164\n",
      "Iteration 45231, loss = 31.11691902\n",
      "Iteration 45232, loss = 31.11117703\n",
      "Iteration 45233, loss = 31.10543566\n",
      "Iteration 45234, loss = 31.09969492\n",
      "Iteration 45235, loss = 31.09395480\n",
      "Iteration 45236, loss = 31.08821530\n",
      "Iteration 45237, loss = 31.08247643\n",
      "Iteration 45238, loss = 31.07673819\n",
      "Iteration 45239, loss = 31.07100057\n",
      "Iteration 45240, loss = 31.06526358\n",
      "Iteration 45241, loss = 31.05952720\n",
      "Iteration 45242, loss = 31.05379146\n",
      "Iteration 45243, loss = 31.04805633\n",
      "Iteration 45244, loss = 31.04232184\n",
      "Iteration 45245, loss = 31.03658796\n",
      "Iteration 45246, loss = 31.03085472\n",
      "Iteration 45247, loss = 31.02512209\n",
      "Iteration 45248, loss = 31.01939009\n",
      "Iteration 45249, loss = 31.01365872\n",
      "Iteration 45250, loss = 31.00792797\n",
      "Iteration 45251, loss = 31.00219784\n",
      "Iteration 45252, loss = 30.99646834\n",
      "Iteration 45253, loss = 30.99073946\n",
      "Iteration 45254, loss = 30.98501121\n",
      "Iteration 45255, loss = 30.97928358\n",
      "Iteration 45256, loss = 30.97355658\n",
      "Iteration 45257, loss = 30.96783020\n",
      "Iteration 45258, loss = 30.96210444\n",
      "Iteration 45259, loss = 30.95637931\n",
      "Iteration 45260, loss = 30.95065480\n",
      "Iteration 45261, loss = 30.94493092\n",
      "Iteration 45262, loss = 30.93920766\n",
      "Iteration 45263, loss = 30.93348503\n",
      "Iteration 45264, loss = 30.92776302\n",
      "Iteration 45265, loss = 30.92204164\n",
      "Iteration 45266, loss = 30.91632088\n",
      "Iteration 45267, loss = 30.91060074\n",
      "Iteration 45268, loss = 30.90488123\n",
      "Iteration 45269, loss = 30.89916234\n",
      "Iteration 45270, loss = 30.89344408\n",
      "Iteration 45271, loss = 30.88772644\n",
      "Iteration 45272, loss = 30.88200942\n",
      "Iteration 45273, loss = 30.87629303\n",
      "Iteration 45274, loss = 30.87057726\n",
      "Iteration 45275, loss = 30.86486212\n",
      "Iteration 45276, loss = 30.85914760\n",
      "Iteration 45277, loss = 30.85343371\n",
      "Iteration 45278, loss = 30.84772044\n",
      "Iteration 45279, loss = 30.84200779\n",
      "Iteration 45280, loss = 30.83629577\n",
      "Iteration 45281, loss = 30.83058437\n",
      "Iteration 45282, loss = 30.82487360\n",
      "Iteration 45283, loss = 30.81916345\n",
      "Iteration 45284, loss = 30.81345393\n",
      "Iteration 45285, loss = 30.80774503\n",
      "Iteration 45286, loss = 30.80203675\n",
      "Iteration 45287, loss = 30.79632910\n",
      "Iteration 45288, loss = 30.79062207\n",
      "Iteration 45289, loss = 30.78491566\n",
      "Iteration 45290, loss = 30.77920988\n",
      "Iteration 45291, loss = 30.77350473\n",
      "Iteration 45292, loss = 30.76780020\n",
      "Iteration 45293, loss = 30.76209629\n",
      "Iteration 45294, loss = 30.75639300\n",
      "Iteration 45295, loss = 30.75069035\n",
      "Iteration 45296, loss = 30.74498831\n",
      "Iteration 45297, loss = 30.73928690\n",
      "Iteration 45298, loss = 30.73358611\n",
      "Iteration 45299, loss = 30.72788595\n",
      "Iteration 45300, loss = 30.72218642\n",
      "Iteration 45301, loss = 30.71648752\n",
      "Iteration 45302, loss = 30.71078924\n",
      "Iteration 45303, loss = 30.70509160\n",
      "Iteration 45304, loss = 30.69939460\n",
      "Iteration 45305, loss = 30.69369824\n",
      "Iteration 45306, loss = 30.68800254\n",
      "Iteration 45307, loss = 30.68230753\n",
      "Iteration 45308, loss = 30.67661321\n",
      "Iteration 45309, loss = 30.67091961\n",
      "Iteration 45310, loss = 30.66522676\n",
      "Iteration 45311, loss = 30.65953460\n",
      "Iteration 45312, loss = 30.65384304\n",
      "Iteration 45313, loss = 30.64815183\n",
      "Iteration 45314, loss = 30.64246076\n",
      "Iteration 45315, loss = 30.63676980\n",
      "Iteration 45316, loss = 30.63107930\n",
      "Iteration 45317, loss = 30.62538978\n",
      "Iteration 45318, loss = 30.61970147\n",
      "Iteration 45319, loss = 30.61401421\n",
      "Iteration 45320, loss = 30.60832760\n",
      "Iteration 45321, loss = 30.60264126\n",
      "Iteration 45322, loss = 30.59695513\n",
      "Iteration 45323, loss = 30.59126947\n",
      "Iteration 45324, loss = 30.58558463\n",
      "Iteration 45325, loss = 30.57990076\n",
      "Iteration 45326, loss = 30.57421770\n",
      "Iteration 45327, loss = 30.56853518\n",
      "Iteration 45328, loss = 30.56285305\n",
      "Iteration 45329, loss = 30.55717137\n",
      "Iteration 45330, loss = 30.55149034\n",
      "Iteration 45331, loss = 30.54581012\n",
      "Iteration 45332, loss = 30.54013066\n",
      "Iteration 45333, loss = 30.53445183\n",
      "Iteration 45334, loss = 30.52877350\n",
      "Iteration 45335, loss = 30.52309569\n",
      "Iteration 45336, loss = 30.51741849\n",
      "Iteration 45337, loss = 30.51174199\n",
      "Iteration 45338, loss = 30.50606620\n",
      "Iteration 45339, loss = 30.50039106\n",
      "Iteration 45340, loss = 30.49471650\n",
      "Iteration 45341, loss = 30.48904249\n",
      "Iteration 45342, loss = 30.48336908\n",
      "Iteration 45343, loss = 30.47769633\n",
      "Iteration 45344, loss = 30.47202425\n",
      "Iteration 45345, loss = 30.46635282\n",
      "Iteration 45346, loss = 30.46068199\n",
      "Iteration 45347, loss = 30.45501176\n",
      "Iteration 45348, loss = 30.44934212\n",
      "Iteration 45349, loss = 30.44367312\n",
      "Iteration 45350, loss = 30.43800477\n",
      "Iteration 45351, loss = 30.43233705\n",
      "Iteration 45352, loss = 30.42666996\n",
      "Iteration 45353, loss = 30.42100348\n",
      "Iteration 45354, loss = 30.41533761\n",
      "Iteration 45355, loss = 30.40967236\n",
      "Iteration 45356, loss = 30.40400774\n",
      "Iteration 45357, loss = 30.39834376\n",
      "Iteration 45358, loss = 30.39268041\n",
      "Iteration 45359, loss = 30.38701768\n",
      "Iteration 45360, loss = 30.38135557\n",
      "Iteration 45361, loss = 30.37569409\n",
      "Iteration 45362, loss = 30.37003324\n",
      "Iteration 45363, loss = 30.36437303\n",
      "Iteration 45364, loss = 30.35871348\n",
      "Iteration 45365, loss = 30.35305459\n",
      "Iteration 45366, loss = 30.34739639\n",
      "Iteration 45367, loss = 30.34173890\n",
      "Iteration 45368, loss = 30.33608218\n",
      "Iteration 45369, loss = 30.33042634\n",
      "Iteration 45370, loss = 30.32477151\n",
      "Iteration 45371, loss = 30.31911794\n",
      "Iteration 45372, loss = 30.31346600\n",
      "Iteration 45373, loss = 30.30781624\n",
      "Iteration 45374, loss = 30.30216952\n",
      "Iteration 45375, loss = 30.29652690\n",
      "Iteration 45376, loss = 30.29088959\n",
      "Iteration 45377, loss = 30.28525806\n",
      "Iteration 45378, loss = 30.27963065\n",
      "Iteration 45379, loss = 30.27400095\n",
      "Iteration 45380, loss = 30.26835807\n",
      "Iteration 45381, loss = 30.26269166\n",
      "Iteration 45382, loss = 30.25700490\n",
      "Iteration 45383, loss = 30.25131770\n",
      "Iteration 45384, loss = 30.24565266\n",
      "Iteration 45385, loss = 30.24001540\n",
      "Iteration 45386, loss = 30.23439195\n",
      "Iteration 45387, loss = 30.22876150\n",
      "Iteration 45388, loss = 30.22311173\n",
      "Iteration 45389, loss = 30.21744783\n",
      "Iteration 45390, loss = 30.21178700\n",
      "Iteration 45391, loss = 30.20614207\n",
      "Iteration 45392, loss = 30.20051061\n",
      "Iteration 45393, loss = 30.19487969\n",
      "Iteration 45394, loss = 30.18923888\n",
      "Iteration 45395, loss = 30.18358890\n",
      "Iteration 45396, loss = 30.17793945\n",
      "Iteration 45397, loss = 30.17229871\n",
      "Iteration 45398, loss = 30.16666603\n",
      "Iteration 45399, loss = 30.16103414\n",
      "Iteration 45400, loss = 30.15539701\n",
      "Iteration 45401, loss = 30.14975521\n",
      "Iteration 45402, loss = 30.14411419\n",
      "Iteration 45403, loss = 30.13847833\n",
      "Iteration 45404, loss = 30.13284701\n",
      "Iteration 45405, loss = 30.12721613\n",
      "Iteration 45406, loss = 30.12158258\n",
      "Iteration 45407, loss = 30.11594690\n",
      "Iteration 45408, loss = 30.11031211\n",
      "Iteration 45409, loss = 30.10468046\n",
      "Iteration 45410, loss = 30.09905146\n",
      "Iteration 45411, loss = 30.09342290\n",
      "Iteration 45412, loss = 30.08779317\n",
      "Iteration 45413, loss = 30.08216263\n",
      "Iteration 45414, loss = 30.07653288\n",
      "Iteration 45415, loss = 30.07090508\n",
      "Iteration 45416, loss = 30.06527897\n",
      "Iteration 45417, loss = 30.05965341\n",
      "Iteration 45418, loss = 30.05402756\n",
      "Iteration 45419, loss = 30.04840156\n",
      "Iteration 45420, loss = 30.04277621\n",
      "Iteration 45421, loss = 30.03715214\n",
      "Iteration 45422, loss = 30.03152930\n",
      "Iteration 45423, loss = 30.02590711\n",
      "Iteration 45424, loss = 30.02028510\n",
      "Iteration 45425, loss = 30.01466327\n",
      "Iteration 45426, loss = 30.00904200\n",
      "Iteration 45427, loss = 30.00342166\n",
      "Iteration 45428, loss = 29.99780229\n",
      "Iteration 45429, loss = 29.99218363\n",
      "Iteration 45430, loss = 29.98656541\n",
      "Iteration 45431, loss = 29.98094756\n",
      "Iteration 45432, loss = 29.97533023\n",
      "Iteration 45433, loss = 29.96971364\n",
      "Iteration 45434, loss = 29.96409785\n",
      "Iteration 45435, loss = 29.95848280\n",
      "Iteration 45436, loss = 29.95286832\n",
      "Iteration 45437, loss = 29.94725433\n",
      "Iteration 45438, loss = 29.94164088\n",
      "Iteration 45439, loss = 29.93602805\n",
      "Iteration 45440, loss = 29.93041593\n",
      "Iteration 45441, loss = 29.92480452\n",
      "Iteration 45442, loss = 29.91919374\n",
      "Iteration 45443, loss = 29.91358355\n",
      "Iteration 45444, loss = 29.90797391\n",
      "Iteration 45445, loss = 29.90236487\n",
      "Iteration 45446, loss = 29.89675647\n",
      "Iteration 45447, loss = 29.89114874\n",
      "Iteration 45448, loss = 29.88554166\n",
      "Iteration 45449, loss = 29.87993520\n",
      "Iteration 45450, loss = 29.87432934\n",
      "Iteration 45451, loss = 29.86872407\n",
      "Iteration 45452, loss = 29.86311942\n",
      "Iteration 45453, loss = 29.85751540\n",
      "Iteration 45454, loss = 29.85191203\n",
      "Iteration 45455, loss = 29.84630929\n",
      "Iteration 45456, loss = 29.84070717\n",
      "Iteration 45457, loss = 29.83510566\n",
      "Iteration 45458, loss = 29.82950477\n",
      "Iteration 45459, loss = 29.82390449\n",
      "Iteration 45460, loss = 29.81830483\n",
      "Iteration 45461, loss = 29.81270581\n",
      "Iteration 45462, loss = 29.80710742\n",
      "Iteration 45463, loss = 29.80150965\n",
      "Iteration 45464, loss = 29.79591250\n",
      "Iteration 45465, loss = 29.79031596\n",
      "Iteration 45466, loss = 29.78472005\n",
      "Iteration 45467, loss = 29.77912475\n",
      "Iteration 45468, loss = 29.77353008\n",
      "Iteration 45469, loss = 29.76793604\n",
      "Iteration 45470, loss = 29.76234263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45471, loss = 29.75674983\n",
      "Iteration 45472, loss = 29.75115765\n",
      "Iteration 45473, loss = 29.74556609\n",
      "Iteration 45474, loss = 29.73997516\n",
      "Iteration 45475, loss = 29.73438485\n",
      "Iteration 45476, loss = 29.72879516\n",
      "Iteration 45477, loss = 29.72320609\n",
      "Iteration 45478, loss = 29.71761765\n",
      "Iteration 45479, loss = 29.71202983\n",
      "Iteration 45480, loss = 29.70644263\n",
      "Iteration 45481, loss = 29.70085605\n",
      "Iteration 45482, loss = 29.69527009\n",
      "Iteration 45483, loss = 29.68968475\n",
      "Iteration 45484, loss = 29.68410004\n",
      "Iteration 45485, loss = 29.67851595\n",
      "Iteration 45486, loss = 29.67293248\n",
      "Iteration 45487, loss = 29.66734964\n",
      "Iteration 45488, loss = 29.66176741\n",
      "Iteration 45489, loss = 29.65618581\n",
      "Iteration 45490, loss = 29.65060483\n",
      "Iteration 45491, loss = 29.64502447\n",
      "Iteration 45492, loss = 29.63944473\n",
      "Iteration 45493, loss = 29.63386561\n",
      "Iteration 45494, loss = 29.62828712\n",
      "Iteration 45495, loss = 29.62270925\n",
      "Iteration 45496, loss = 29.61713200\n",
      "Iteration 45497, loss = 29.61155537\n",
      "Iteration 45498, loss = 29.60597937\n",
      "Iteration 45499, loss = 29.60040398\n",
      "Iteration 45500, loss = 29.59482922\n",
      "Iteration 45501, loss = 29.58925508\n",
      "Iteration 45502, loss = 29.58368156\n",
      "Iteration 45503, loss = 29.57810867\n",
      "Iteration 45504, loss = 29.57253639\n",
      "Iteration 45505, loss = 29.56696474\n",
      "Iteration 45506, loss = 29.56139371\n",
      "Iteration 45507, loss = 29.55582330\n",
      "Iteration 45508, loss = 29.55025351\n",
      "Iteration 45509, loss = 29.54468435\n",
      "Iteration 45510, loss = 29.53911580\n",
      "Iteration 45511, loss = 29.53354788\n",
      "Iteration 45512, loss = 29.52798058\n",
      "Iteration 45513, loss = 29.52241390\n",
      "Iteration 45514, loss = 29.51684784\n",
      "Iteration 45515, loss = 29.51128241\n",
      "Iteration 45516, loss = 29.50571759\n",
      "Iteration 45517, loss = 29.50015340\n",
      "Iteration 45518, loss = 29.49458983\n",
      "Iteration 45519, loss = 29.48902689\n",
      "Iteration 45520, loss = 29.48346456\n",
      "Iteration 45521, loss = 29.47790286\n",
      "Iteration 45522, loss = 29.47234178\n",
      "Iteration 45523, loss = 29.46678133\n",
      "Iteration 45524, loss = 29.46122150\n",
      "Iteration 45525, loss = 29.45566231\n",
      "Iteration 45526, loss = 29.45010375\n",
      "Iteration 45527, loss = 29.44454583\n",
      "Iteration 45528, loss = 29.43898856\n",
      "Iteration 45529, loss = 29.43343196\n",
      "Iteration 45530, loss = 29.42787604\n",
      "Iteration 45531, loss = 29.42232083\n",
      "Iteration 45532, loss = 29.41676633\n",
      "Iteration 45533, loss = 29.41121255\n",
      "Iteration 45534, loss = 29.40565939\n",
      "Iteration 45535, loss = 29.40010670\n",
      "Iteration 45536, loss = 29.39455425\n",
      "Iteration 45537, loss = 29.38900195\n",
      "Iteration 45538, loss = 29.38344997\n",
      "Iteration 45539, loss = 29.37789872\n",
      "Iteration 45540, loss = 29.37234856\n",
      "Iteration 45541, loss = 29.36679951\n",
      "Iteration 45542, loss = 29.36125129\n",
      "Iteration 45543, loss = 29.35570355\n",
      "Iteration 45544, loss = 29.35015607\n",
      "Iteration 45545, loss = 29.34460892\n",
      "Iteration 45546, loss = 29.33906236\n",
      "Iteration 45547, loss = 29.33351667\n",
      "Iteration 45548, loss = 29.32797187\n",
      "Iteration 45549, loss = 29.32242779\n",
      "Iteration 45550, loss = 29.31688423\n",
      "Iteration 45551, loss = 29.31134108\n",
      "Iteration 45552, loss = 29.30579844\n",
      "Iteration 45553, loss = 29.30025646\n",
      "Iteration 45554, loss = 29.29471525\n",
      "Iteration 45555, loss = 29.28917478\n",
      "Iteration 45556, loss = 29.28363493\n",
      "Iteration 45557, loss = 29.27809561\n",
      "Iteration 45558, loss = 29.27255682\n",
      "Iteration 45559, loss = 29.26701863\n",
      "Iteration 45560, loss = 29.26148111\n",
      "Iteration 45561, loss = 29.25594429\n",
      "Iteration 45562, loss = 29.25040812\n",
      "Iteration 45563, loss = 29.24487255\n",
      "Iteration 45564, loss = 29.23933755\n",
      "Iteration 45565, loss = 29.23380314\n",
      "Iteration 45566, loss = 29.22826935\n",
      "Iteration 45567, loss = 29.22273623\n",
      "Iteration 45568, loss = 29.21720376\n",
      "Iteration 45569, loss = 29.21167191\n",
      "Iteration 45570, loss = 29.20614066\n",
      "Iteration 45571, loss = 29.20061002\n",
      "Iteration 45572, loss = 29.19507998\n",
      "Iteration 45573, loss = 29.18955058\n",
      "Iteration 45574, loss = 29.18402182\n",
      "Iteration 45575, loss = 29.17849370\n",
      "Iteration 45576, loss = 29.17296621\n",
      "Iteration 45577, loss = 29.16743933\n",
      "Iteration 45578, loss = 29.16191308\n",
      "Iteration 45579, loss = 29.15638746\n",
      "Iteration 45580, loss = 29.15086250\n",
      "Iteration 45581, loss = 29.14533821\n",
      "Iteration 45582, loss = 29.13981460\n",
      "Iteration 45583, loss = 29.13429169\n",
      "Iteration 45584, loss = 29.12876951\n",
      "Iteration 45585, loss = 29.12324814\n",
      "Iteration 45586, loss = 29.11772764\n",
      "Iteration 45587, loss = 29.11220817\n",
      "Iteration 45588, loss = 29.10668989\n",
      "Iteration 45589, loss = 29.10117307\n",
      "Iteration 45590, loss = 29.09565805\n",
      "Iteration 45591, loss = 29.09014529\n",
      "Iteration 45592, loss = 29.08463525\n",
      "Iteration 45593, loss = 29.07912823\n",
      "Iteration 45594, loss = 29.07362404\n",
      "Iteration 45595, loss = 29.06812118\n",
      "Iteration 45596, loss = 29.06261651\n",
      "Iteration 45597, loss = 29.05710515\n",
      "Iteration 45598, loss = 29.05158318\n",
      "Iteration 45599, loss = 29.04605084\n",
      "Iteration 45600, loss = 29.04051503\n",
      "Iteration 45601, loss = 29.03498561\n",
      "Iteration 45602, loss = 29.02946906\n",
      "Iteration 45603, loss = 29.02396464\n",
      "Iteration 45604, loss = 29.01846584\n",
      "Iteration 45605, loss = 29.01296480\n",
      "Iteration 45606, loss = 29.00745637\n",
      "Iteration 45607, loss = 29.00194072\n",
      "Iteration 45608, loss = 28.99642280\n",
      "Iteration 45609, loss = 28.99090877\n",
      "Iteration 45610, loss = 28.98540179\n",
      "Iteration 45611, loss = 28.97990047\n",
      "Iteration 45612, loss = 28.97440062\n",
      "Iteration 45613, loss = 28.96889837\n",
      "Iteration 45614, loss = 28.96339245\n",
      "Iteration 45615, loss = 28.95788460\n",
      "Iteration 45616, loss = 28.95237795\n",
      "Iteration 45617, loss = 28.94687470\n",
      "Iteration 45618, loss = 28.94137487\n",
      "Iteration 45619, loss = 28.93587671\n",
      "Iteration 45620, loss = 28.93037817\n",
      "Iteration 45621, loss = 28.92487826\n",
      "Iteration 45622, loss = 28.91937746\n",
      "Iteration 45623, loss = 28.91387715\n",
      "Iteration 45624, loss = 28.90837852\n",
      "Iteration 45625, loss = 28.90288190\n",
      "Iteration 45626, loss = 28.89738667\n",
      "Iteration 45627, loss = 28.89189188\n",
      "Iteration 45628, loss = 28.88639688\n",
      "Iteration 45629, loss = 28.88090169\n",
      "Iteration 45630, loss = 28.87540680\n",
      "Iteration 45631, loss = 28.86991284\n",
      "Iteration 45632, loss = 28.86442011\n",
      "Iteration 45633, loss = 28.85892850\n",
      "Iteration 45634, loss = 28.85343763\n",
      "Iteration 45635, loss = 28.84794713\n",
      "Iteration 45636, loss = 28.84245685\n",
      "Iteration 45637, loss = 28.83696692\n",
      "Iteration 45638, loss = 28.83147758\n",
      "Iteration 45639, loss = 28.82598906\n",
      "Iteration 45640, loss = 28.82050143\n",
      "Iteration 45641, loss = 28.81501460\n",
      "Iteration 45642, loss = 28.80952839\n",
      "Iteration 45643, loss = 28.80404268\n",
      "Iteration 45644, loss = 28.79855742\n",
      "Iteration 45645, loss = 28.79307267\n",
      "Iteration 45646, loss = 28.78758854\n",
      "Iteration 45647, loss = 28.78210512\n",
      "Iteration 45648, loss = 28.77662243\n",
      "Iteration 45649, loss = 28.77114044\n",
      "Iteration 45650, loss = 28.76565908\n",
      "Iteration 45651, loss = 28.76017829\n",
      "Iteration 45652, loss = 28.75469806\n",
      "Iteration 45653, loss = 28.74921839\n",
      "Iteration 45654, loss = 28.74373932\n",
      "Iteration 45655, loss = 28.73826091\n",
      "Iteration 45656, loss = 28.73278315\n",
      "Iteration 45657, loss = 28.72730606\n",
      "Iteration 45658, loss = 28.72182960\n",
      "Iteration 45659, loss = 28.71635376\n",
      "Iteration 45660, loss = 28.71087852\n",
      "Iteration 45661, loss = 28.70540387\n",
      "Iteration 45662, loss = 28.69992982\n",
      "Iteration 45663, loss = 28.69445639\n",
      "Iteration 45664, loss = 28.68898359\n",
      "Iteration 45665, loss = 28.68351143\n",
      "Iteration 45666, loss = 28.67803990\n",
      "Iteration 45667, loss = 28.67256900\n",
      "Iteration 45668, loss = 28.66709872\n",
      "Iteration 45669, loss = 28.66162905\n",
      "Iteration 45670, loss = 28.65616000\n",
      "Iteration 45671, loss = 28.65069155\n",
      "Iteration 45672, loss = 28.64522373\n",
      "Iteration 45673, loss = 28.63975652\n",
      "Iteration 45674, loss = 28.63428994\n",
      "Iteration 45675, loss = 28.62882398\n",
      "Iteration 45676, loss = 28.62335864\n",
      "Iteration 45677, loss = 28.61789393\n",
      "Iteration 45678, loss = 28.61242984\n",
      "Iteration 45679, loss = 28.60696637\n",
      "Iteration 45680, loss = 28.60150352\n",
      "Iteration 45681, loss = 28.59604128\n",
      "Iteration 45682, loss = 28.59057966\n",
      "Iteration 45683, loss = 28.58511866\n",
      "Iteration 45684, loss = 28.57965828\n",
      "Iteration 45685, loss = 28.57419852\n",
      "Iteration 45686, loss = 28.56873939\n",
      "Iteration 45687, loss = 28.56328087\n",
      "Iteration 45688, loss = 28.55782297\n",
      "Iteration 45689, loss = 28.55236570\n",
      "Iteration 45690, loss = 28.54690904\n",
      "Iteration 45691, loss = 28.54145301\n",
      "Iteration 45692, loss = 28.53599759\n",
      "Iteration 45693, loss = 28.53054279\n",
      "Iteration 45694, loss = 28.52508861\n",
      "Iteration 45695, loss = 28.51963505\n",
      "Iteration 45696, loss = 28.51418211\n",
      "Iteration 45697, loss = 28.50872979\n",
      "Iteration 45698, loss = 28.50327809\n",
      "Iteration 45699, loss = 28.49782701\n",
      "Iteration 45700, loss = 28.49237655\n",
      "Iteration 45701, loss = 28.48692671\n",
      "Iteration 45702, loss = 28.48147749\n",
      "Iteration 45703, loss = 28.47602889\n",
      "Iteration 45704, loss = 28.47058091\n",
      "Iteration 45705, loss = 28.46513355\n",
      "Iteration 45706, loss = 28.45968681\n",
      "Iteration 45707, loss = 28.45424069\n",
      "Iteration 45708, loss = 28.44879519\n",
      "Iteration 45709, loss = 28.44335030\n",
      "Iteration 45710, loss = 28.43790604\n",
      "Iteration 45711, loss = 28.43246240\n",
      "Iteration 45712, loss = 28.42701937\n",
      "Iteration 45713, loss = 28.42157697\n",
      "Iteration 45714, loss = 28.41613518\n",
      "Iteration 45715, loss = 28.41069402\n",
      "Iteration 45716, loss = 28.40525347\n",
      "Iteration 45717, loss = 28.39981354\n",
      "Iteration 45718, loss = 28.39437424\n",
      "Iteration 45719, loss = 28.38893555\n",
      "Iteration 45720, loss = 28.38349748\n",
      "Iteration 45721, loss = 28.37806003\n",
      "Iteration 45722, loss = 28.37262321\n",
      "Iteration 45723, loss = 28.36718700\n",
      "Iteration 45724, loss = 28.36175141\n",
      "Iteration 45725, loss = 28.35631644\n",
      "Iteration 45726, loss = 28.35088209\n",
      "Iteration 45727, loss = 28.34544836\n",
      "Iteration 45728, loss = 28.34001525\n",
      "Iteration 45729, loss = 28.33458276\n",
      "Iteration 45730, loss = 28.32915089\n",
      "Iteration 45731, loss = 28.32371964\n",
      "Iteration 45732, loss = 28.31828902\n",
      "Iteration 45733, loss = 28.31285902\n",
      "Iteration 45734, loss = 28.30742965\n",
      "Iteration 45735, loss = 28.30200090\n",
      "Iteration 45736, loss = 28.29657280\n",
      "Iteration 45737, loss = 28.29114533\n",
      "Iteration 45738, loss = 28.28571852\n",
      "Iteration 45739, loss = 28.28029238\n",
      "Iteration 45740, loss = 28.27486691\n",
      "Iteration 45741, loss = 28.26944214\n",
      "Iteration 45742, loss = 28.26401805\n",
      "Iteration 45743, loss = 28.25859459\n",
      "Iteration 45744, loss = 28.25317169\n",
      "Iteration 45745, loss = 28.24774919\n",
      "Iteration 45746, loss = 28.24232699\n",
      "Iteration 45747, loss = 28.23690514\n",
      "Iteration 45748, loss = 28.23148385\n",
      "Iteration 45749, loss = 28.22606343\n",
      "Iteration 45750, loss = 28.22064404\n",
      "Iteration 45751, loss = 28.21522566\n",
      "Iteration 45752, loss = 28.20980811\n",
      "Iteration 45753, loss = 28.20439125\n",
      "Iteration 45754, loss = 28.19897504\n",
      "Iteration 45755, loss = 28.19355968\n",
      "Iteration 45756, loss = 28.18814554\n",
      "Iteration 45757, loss = 28.18273309\n",
      "Iteration 45758, loss = 28.17732283\n",
      "Iteration 45759, loss = 28.17191522\n",
      "Iteration 45760, loss = 28.16651076\n",
      "Iteration 45761, loss = 28.16110978\n",
      "Iteration 45762, loss = 28.15571201\n",
      "Iteration 45763, loss = 28.15031559\n",
      "Iteration 45764, loss = 28.14491640\n",
      "Iteration 45765, loss = 28.13950815\n",
      "Iteration 45766, loss = 28.13408632\n",
      "Iteration 45767, loss = 28.12865273\n",
      "Iteration 45768, loss = 28.12321775\n",
      "Iteration 45769, loss = 28.11779372\n",
      "Iteration 45770, loss = 28.11238628\n",
      "Iteration 45771, loss = 28.10699129\n",
      "Iteration 45772, loss = 28.10159873\n",
      "Iteration 45773, loss = 28.09619923\n",
      "Iteration 45774, loss = 28.09078924\n",
      "Iteration 45775, loss = 28.08537299\n",
      "Iteration 45776, loss = 28.07995889\n",
      "Iteration 45777, loss = 28.07455318\n",
      "Iteration 45778, loss = 28.06915570\n",
      "Iteration 45779, loss = 28.06376121\n",
      "Iteration 45780, loss = 28.05836388\n",
      "Iteration 45781, loss = 28.05296133\n",
      "Iteration 45782, loss = 28.04755577\n",
      "Iteration 45783, loss = 28.04215167\n",
      "Iteration 45784, loss = 28.03675217\n",
      "Iteration 45785, loss = 28.03135697\n",
      "Iteration 45786, loss = 28.02596327\n",
      "Iteration 45787, loss = 28.02056821\n",
      "Iteration 45788, loss = 28.01517090\n",
      "Iteration 45789, loss = 28.00977269\n",
      "Iteration 45790, loss = 28.00437579\n",
      "Iteration 45791, loss = 27.99898151\n",
      "Iteration 45792, loss = 27.99358952\n",
      "Iteration 45793, loss = 27.98819839\n",
      "Iteration 45794, loss = 27.98280681\n",
      "Iteration 45795, loss = 27.97741450\n",
      "Iteration 45796, loss = 27.97202216\n",
      "Iteration 45797, loss = 27.96663084\n",
      "Iteration 45798, loss = 27.96124111\n",
      "Iteration 45799, loss = 27.95585277\n",
      "Iteration 45800, loss = 27.95046515\n",
      "Iteration 45801, loss = 27.94507765\n",
      "Iteration 45802, loss = 27.93969012\n",
      "Iteration 45803, loss = 27.93430289\n",
      "Iteration 45804, loss = 27.92891643\n",
      "Iteration 45805, loss = 27.92353102\n",
      "Iteration 45806, loss = 27.91814663\n",
      "Iteration 45807, loss = 27.91276296\n",
      "Iteration 45808, loss = 27.90737971\n",
      "Iteration 45809, loss = 27.90199679\n",
      "Iteration 45810, loss = 27.89661428\n",
      "Iteration 45811, loss = 27.89123240\n",
      "Iteration 45812, loss = 27.88585131\n",
      "Iteration 45813, loss = 27.88047103\n",
      "Iteration 45814, loss = 27.87509148\n",
      "Iteration 45815, loss = 27.86971252\n",
      "Iteration 45816, loss = 27.86433406\n",
      "Iteration 45817, loss = 27.85895609\n",
      "Iteration 45818, loss = 27.85357869\n",
      "Iteration 45819, loss = 27.84820194\n",
      "Iteration 45820, loss = 27.84282590\n",
      "Iteration 45821, loss = 27.83745056\n",
      "Iteration 45822, loss = 27.83207586\n",
      "Iteration 45823, loss = 27.82670176\n",
      "Iteration 45824, loss = 27.82132822\n",
      "Iteration 45825, loss = 27.81595525\n",
      "Iteration 45826, loss = 27.81058288\n",
      "Iteration 45827, loss = 27.80521115\n",
      "Iteration 45828, loss = 27.79984007\n",
      "Iteration 45829, loss = 27.79446964\n",
      "Iteration 45830, loss = 27.78909985\n",
      "Iteration 45831, loss = 27.78373066\n",
      "Iteration 45832, loss = 27.77836208\n",
      "Iteration 45833, loss = 27.77299409\n",
      "Iteration 45834, loss = 27.76762670\n",
      "Iteration 45835, loss = 27.76225994\n",
      "Iteration 45836, loss = 27.75689381\n",
      "Iteration 45837, loss = 27.75152831\n",
      "Iteration 45838, loss = 27.74616344\n",
      "Iteration 45839, loss = 27.74079919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45840, loss = 27.73543555\n",
      "Iteration 45841, loss = 27.73007252\n",
      "Iteration 45842, loss = 27.72471010\n",
      "Iteration 45843, loss = 27.71934830\n",
      "Iteration 45844, loss = 27.71398712\n",
      "Iteration 45845, loss = 27.70862656\n",
      "Iteration 45846, loss = 27.70326662\n",
      "Iteration 45847, loss = 27.69790730\n",
      "Iteration 45848, loss = 27.69254861\n",
      "Iteration 45849, loss = 27.68719053\n",
      "Iteration 45850, loss = 27.68183306\n",
      "Iteration 45851, loss = 27.67647621\n",
      "Iteration 45852, loss = 27.67111998\n",
      "Iteration 45853, loss = 27.66576436\n",
      "Iteration 45854, loss = 27.66040937\n",
      "Iteration 45855, loss = 27.65505499\n",
      "Iteration 45856, loss = 27.64970123\n",
      "Iteration 45857, loss = 27.64434809\n",
      "Iteration 45858, loss = 27.63899557\n",
      "Iteration 45859, loss = 27.63364367\n",
      "Iteration 45860, loss = 27.62829239\n",
      "Iteration 45861, loss = 27.62294172\n",
      "Iteration 45862, loss = 27.61759167\n",
      "Iteration 45863, loss = 27.61224223\n",
      "Iteration 45864, loss = 27.60689342\n",
      "Iteration 45865, loss = 27.60154522\n",
      "Iteration 45866, loss = 27.59619764\n",
      "Iteration 45867, loss = 27.59085068\n",
      "Iteration 45868, loss = 27.58550434\n",
      "Iteration 45869, loss = 27.58015861\n",
      "Iteration 45870, loss = 27.57481351\n",
      "Iteration 45871, loss = 27.56946902\n",
      "Iteration 45872, loss = 27.56412515\n",
      "Iteration 45873, loss = 27.55878189\n",
      "Iteration 45874, loss = 27.55343926\n",
      "Iteration 45875, loss = 27.54809724\n",
      "Iteration 45876, loss = 27.54275584\n",
      "Iteration 45877, loss = 27.53741506\n",
      "Iteration 45878, loss = 27.53207489\n",
      "Iteration 45879, loss = 27.52673534\n",
      "Iteration 45880, loss = 27.52139641\n",
      "Iteration 45881, loss = 27.51605810\n",
      "Iteration 45882, loss = 27.51072041\n",
      "Iteration 45883, loss = 27.50538333\n",
      "Iteration 45884, loss = 27.50004687\n",
      "Iteration 45885, loss = 27.49471103\n",
      "Iteration 45886, loss = 27.48937581\n",
      "Iteration 45887, loss = 27.48404120\n",
      "Iteration 45888, loss = 27.47870721\n",
      "Iteration 45889, loss = 27.47337384\n",
      "Iteration 45890, loss = 27.46804109\n",
      "Iteration 45891, loss = 27.46270896\n",
      "Iteration 45892, loss = 27.45737744\n",
      "Iteration 45893, loss = 27.45204654\n",
      "Iteration 45894, loss = 27.44671626\n",
      "Iteration 45895, loss = 27.44138659\n",
      "Iteration 45896, loss = 27.43605755\n",
      "Iteration 45897, loss = 27.43072912\n",
      "Iteration 45898, loss = 27.42540132\n",
      "Iteration 45899, loss = 27.42007413\n",
      "Iteration 45900, loss = 27.41474757\n",
      "Iteration 45901, loss = 27.40942163\n",
      "Iteration 45902, loss = 27.40409631\n",
      "Iteration 45903, loss = 27.39877163\n",
      "Iteration 45904, loss = 27.39344760\n",
      "Iteration 45905, loss = 27.38812421\n",
      "Iteration 45906, loss = 27.38280149\n",
      "Iteration 45907, loss = 27.37747945\n",
      "Iteration 45908, loss = 27.37215812\n",
      "Iteration 45909, loss = 27.36683748\n",
      "Iteration 45910, loss = 27.36151752\n",
      "Iteration 45911, loss = 27.35619813\n",
      "Iteration 45912, loss = 27.35087913\n",
      "Iteration 45913, loss = 27.34556036\n",
      "Iteration 45914, loss = 27.34024183\n",
      "Iteration 45915, loss = 27.33492376\n",
      "Iteration 45916, loss = 27.32960654\n",
      "Iteration 45917, loss = 27.32429040\n",
      "Iteration 45918, loss = 27.31897527\n",
      "Iteration 45919, loss = 27.31366090\n",
      "Iteration 45920, loss = 27.30834698\n",
      "Iteration 45921, loss = 27.30303341\n",
      "Iteration 45922, loss = 27.29772026\n",
      "Iteration 45923, loss = 27.29240781\n",
      "Iteration 45924, loss = 27.28709629\n",
      "Iteration 45925, loss = 27.28178574\n",
      "Iteration 45926, loss = 27.27647609\n",
      "Iteration 45927, loss = 27.27116723\n",
      "Iteration 45928, loss = 27.26585919\n",
      "Iteration 45929, loss = 27.26055216\n",
      "Iteration 45930, loss = 27.25524645\n",
      "Iteration 45931, loss = 27.24994239\n",
      "Iteration 45932, loss = 27.24464021\n",
      "Iteration 45933, loss = 27.23934001\n",
      "Iteration 45934, loss = 27.23404171\n",
      "Iteration 45935, loss = 27.22874485\n",
      "Iteration 45936, loss = 27.22344839\n",
      "Iteration 45937, loss = 27.21815038\n",
      "Iteration 45938, loss = 27.21284846\n",
      "Iteration 45939, loss = 27.20754063\n",
      "Iteration 45940, loss = 27.20222717\n",
      "Iteration 45941, loss = 27.19691113\n",
      "Iteration 45942, loss = 27.19159749\n",
      "Iteration 45943, loss = 27.18629034\n",
      "Iteration 45944, loss = 27.18099088\n",
      "Iteration 45945, loss = 27.17569724\n",
      "Iteration 45946, loss = 27.17040582\n",
      "Iteration 45947, loss = 27.16511301\n",
      "Iteration 45948, loss = 27.15981665\n",
      "Iteration 45949, loss = 27.15451673\n",
      "Iteration 45950, loss = 27.14921522\n",
      "Iteration 45951, loss = 27.14391492\n",
      "Iteration 45952, loss = 27.13861792\n",
      "Iteration 45953, loss = 27.13332467\n",
      "Iteration 45954, loss = 27.12803408\n",
      "Iteration 45955, loss = 27.12274433\n",
      "Iteration 45956, loss = 27.11745385\n",
      "Iteration 45957, loss = 27.11216204\n",
      "Iteration 45958, loss = 27.10686932\n",
      "Iteration 45959, loss = 27.10157678\n",
      "Iteration 45960, loss = 27.09628555\n",
      "Iteration 45961, loss = 27.09099623\n",
      "Iteration 45962, loss = 27.08570868\n",
      "Iteration 45963, loss = 27.08042228\n",
      "Iteration 45964, loss = 27.07513631\n",
      "Iteration 45965, loss = 27.06985027\n",
      "Iteration 45966, loss = 27.06456407\n",
      "Iteration 45967, loss = 27.05927802\n",
      "Iteration 45968, loss = 27.05399255\n",
      "Iteration 45969, loss = 27.04870806\n",
      "Iteration 45970, loss = 27.04342469\n",
      "Iteration 45971, loss = 27.03814235\n",
      "Iteration 45972, loss = 27.03286080\n",
      "Iteration 45973, loss = 27.02757977\n",
      "Iteration 45974, loss = 27.02229909\n",
      "Iteration 45975, loss = 27.01701875\n",
      "Iteration 45976, loss = 27.01173883\n",
      "Iteration 45977, loss = 27.00645950\n",
      "Iteration 45978, loss = 27.00118090\n",
      "Iteration 45979, loss = 26.99590309\n",
      "Iteration 45980, loss = 26.99062606\n",
      "Iteration 45981, loss = 26.98534975\n",
      "Iteration 45982, loss = 26.98007406\n",
      "Iteration 45983, loss = 26.97479892\n",
      "Iteration 45984, loss = 26.96952430\n",
      "Iteration 45985, loss = 26.96425020\n",
      "Iteration 45986, loss = 26.95897667\n",
      "Iteration 45987, loss = 26.95370376\n",
      "Iteration 45988, loss = 26.94843150\n",
      "Iteration 45989, loss = 26.94315992\n",
      "Iteration 45990, loss = 26.93788901\n",
      "Iteration 45991, loss = 26.93261874\n",
      "Iteration 45992, loss = 26.92734911\n",
      "Iteration 45993, loss = 26.92208008\n",
      "Iteration 45994, loss = 26.91681164\n",
      "Iteration 45995, loss = 26.91154378\n",
      "Iteration 45996, loss = 26.90627652\n",
      "Iteration 45997, loss = 26.90100987\n",
      "Iteration 45998, loss = 26.89574383\n",
      "Iteration 45999, loss = 26.89047842\n",
      "Iteration 46000, loss = 26.88521364\n",
      "Iteration 46001, loss = 26.87994949\n",
      "Iteration 46002, loss = 26.87468597\n",
      "Iteration 46003, loss = 26.86942307\n",
      "Iteration 46004, loss = 26.86416079\n",
      "Iteration 46005, loss = 26.85889912\n",
      "Iteration 46006, loss = 26.85363807\n",
      "Iteration 46007, loss = 26.84837762\n",
      "Iteration 46008, loss = 26.84311778\n",
      "Iteration 46009, loss = 26.83785856\n",
      "Iteration 46010, loss = 26.83259994\n",
      "Iteration 46011, loss = 26.82734195\n",
      "Iteration 46012, loss = 26.82208457\n",
      "Iteration 46013, loss = 26.81682782\n",
      "Iteration 46014, loss = 26.81157168\n",
      "Iteration 46015, loss = 26.80631616\n",
      "Iteration 46016, loss = 26.80106126\n",
      "Iteration 46017, loss = 26.79580698\n",
      "Iteration 46018, loss = 26.79055331\n",
      "Iteration 46019, loss = 26.78530026\n",
      "Iteration 46020, loss = 26.78004783\n",
      "Iteration 46021, loss = 26.77479601\n",
      "Iteration 46022, loss = 26.76954481\n",
      "Iteration 46023, loss = 26.76429422\n",
      "Iteration 46024, loss = 26.75904425\n",
      "Iteration 46025, loss = 26.75379489\n",
      "Iteration 46026, loss = 26.74854615\n",
      "Iteration 46027, loss = 26.74329802\n",
      "Iteration 46028, loss = 26.73805051\n",
      "Iteration 46029, loss = 26.73280362\n",
      "Iteration 46030, loss = 26.72755734\n",
      "Iteration 46031, loss = 26.72231168\n",
      "Iteration 46032, loss = 26.71706664\n",
      "Iteration 46033, loss = 26.71182221\n",
      "Iteration 46034, loss = 26.70657839\n",
      "Iteration 46035, loss = 26.70133520\n",
      "Iteration 46036, loss = 26.69609262\n",
      "Iteration 46037, loss = 26.69085065\n",
      "Iteration 46038, loss = 26.68560930\n",
      "Iteration 46039, loss = 26.68036857\n",
      "Iteration 46040, loss = 26.67512846\n",
      "Iteration 46041, loss = 26.66988896\n",
      "Iteration 46042, loss = 26.66465007\n",
      "Iteration 46043, loss = 26.65941180\n",
      "Iteration 46044, loss = 26.65417415\n",
      "Iteration 46045, loss = 26.64893711\n",
      "Iteration 46046, loss = 26.64370069\n",
      "Iteration 46047, loss = 26.63846489\n",
      "Iteration 46048, loss = 26.63322970\n",
      "Iteration 46049, loss = 26.62799513\n",
      "Iteration 46050, loss = 26.62276117\n",
      "Iteration 46051, loss = 26.61752783\n",
      "Iteration 46052, loss = 26.61229510\n",
      "Iteration 46053, loss = 26.60706299\n",
      "Iteration 46054, loss = 26.60183150\n",
      "Iteration 46055, loss = 26.59660062\n",
      "Iteration 46056, loss = 26.59137036\n",
      "Iteration 46057, loss = 26.58614071\n",
      "Iteration 46058, loss = 26.58091168\n",
      "Iteration 46059, loss = 26.57568327\n",
      "Iteration 46060, loss = 26.57045547\n",
      "Iteration 46061, loss = 26.56522829\n",
      "Iteration 46062, loss = 26.56000172\n",
      "Iteration 46063, loss = 26.55477578\n",
      "Iteration 46064, loss = 26.54955045\n",
      "Iteration 46065, loss = 26.54432574\n",
      "Iteration 46066, loss = 26.53910166\n",
      "Iteration 46067, loss = 26.53387820\n",
      "Iteration 46068, loss = 26.52865537\n",
      "Iteration 46069, loss = 26.52343319\n",
      "Iteration 46070, loss = 26.51821166\n",
      "Iteration 46071, loss = 26.51299081\n",
      "Iteration 46072, loss = 26.50777067\n",
      "Iteration 46073, loss = 26.50255131\n",
      "Iteration 46074, loss = 26.49733282\n",
      "Iteration 46075, loss = 26.49211534\n",
      "Iteration 46076, loss = 26.48689914\n",
      "Iteration 46077, loss = 26.48168457\n",
      "Iteration 46078, loss = 26.47647224\n",
      "Iteration 46079, loss = 26.47126299\n",
      "Iteration 46080, loss = 26.46605797\n",
      "Iteration 46081, loss = 26.46085833\n",
      "Iteration 46082, loss = 26.45566467\n",
      "Iteration 46083, loss = 26.45047509\n",
      "Iteration 46084, loss = 26.44528336\n",
      "Iteration 46085, loss = 26.44007789\n",
      "Iteration 46086, loss = 26.43484872\n",
      "Iteration 46087, loss = 26.42959849\n",
      "Iteration 46088, loss = 26.42434765\n",
      "Iteration 46089, loss = 26.41911898\n",
      "Iteration 46090, loss = 26.41391848\n",
      "Iteration 46091, loss = 26.40873237\n",
      "Iteration 46092, loss = 26.40353956\n",
      "Iteration 46093, loss = 26.39832739\n",
      "Iteration 46094, loss = 26.39310058\n",
      "Iteration 46095, loss = 26.38787642\n",
      "Iteration 46096, loss = 26.38266809\n",
      "Iteration 46097, loss = 26.37747365\n",
      "Iteration 46098, loss = 26.37228026\n",
      "Iteration 46099, loss = 26.36707705\n",
      "Iteration 46100, loss = 26.36186430\n",
      "Iteration 46101, loss = 26.35665155\n",
      "Iteration 46102, loss = 26.35144744\n",
      "Iteration 46103, loss = 26.34625177\n",
      "Iteration 46104, loss = 26.34105731\n",
      "Iteration 46105, loss = 26.33585768\n",
      "Iteration 46106, loss = 26.33065302\n",
      "Iteration 46107, loss = 26.32544879\n",
      "Iteration 46108, loss = 26.32024968\n",
      "Iteration 46109, loss = 26.31505538\n",
      "Iteration 46110, loss = 26.30986179\n",
      "Iteration 46111, loss = 26.30466551\n",
      "Iteration 46112, loss = 26.29946688\n",
      "Iteration 46113, loss = 26.29426898\n",
      "Iteration 46114, loss = 26.28907421\n",
      "Iteration 46115, loss = 26.28388225\n",
      "Iteration 46116, loss = 26.27869082\n",
      "Iteration 46117, loss = 26.27349819\n",
      "Iteration 46118, loss = 26.26830463\n",
      "Iteration 46119, loss = 26.26311180\n",
      "Iteration 46120, loss = 26.25792093\n",
      "Iteration 46121, loss = 26.25273182\n",
      "Iteration 46122, loss = 26.24754329\n",
      "Iteration 46123, loss = 26.24235445\n",
      "Iteration 46124, loss = 26.23716539\n",
      "Iteration 46125, loss = 26.23197696\n",
      "Iteration 46126, loss = 26.22678981\n",
      "Iteration 46127, loss = 26.22160390\n",
      "Iteration 46128, loss = 26.21641866\n",
      "Iteration 46129, loss = 26.21123360\n",
      "Iteration 46130, loss = 26.20604870\n",
      "Iteration 46131, loss = 26.20086433\n",
      "Iteration 46132, loss = 26.19568087\n",
      "Iteration 46133, loss = 26.19049837\n",
      "Iteration 46134, loss = 26.18531659\n",
      "Iteration 46135, loss = 26.18013527\n",
      "Iteration 46136, loss = 26.17495430\n",
      "Iteration 46137, loss = 26.16977385\n",
      "Iteration 46138, loss = 26.16459409\n",
      "Iteration 46139, loss = 26.15941514\n",
      "Iteration 46140, loss = 26.15423691\n",
      "Iteration 46141, loss = 26.14905927\n",
      "Iteration 46142, loss = 26.14388212\n",
      "Iteration 46143, loss = 26.13870549\n",
      "Iteration 46144, loss = 26.13352947\n",
      "Iteration 46145, loss = 26.12835414\n",
      "Iteration 46146, loss = 26.12317951\n",
      "Iteration 46147, loss = 26.11800552\n",
      "Iteration 46148, loss = 26.11283210\n",
      "Iteration 46149, loss = 26.10765924\n",
      "Iteration 46150, loss = 26.10248696\n",
      "Iteration 46151, loss = 26.09731531\n",
      "Iteration 46152, loss = 26.09214432\n",
      "Iteration 46153, loss = 26.08697397\n",
      "Iteration 46154, loss = 26.08180425\n",
      "Iteration 46155, loss = 26.07663511\n",
      "Iteration 46156, loss = 26.07146657\n",
      "Iteration 46157, loss = 26.06629862\n",
      "Iteration 46158, loss = 26.06113130\n",
      "Iteration 46159, loss = 26.05596461\n",
      "Iteration 46160, loss = 26.05079855\n",
      "Iteration 46161, loss = 26.04563311\n",
      "Iteration 46162, loss = 26.04046827\n",
      "Iteration 46163, loss = 26.03530404\n",
      "Iteration 46164, loss = 26.03014041\n",
      "Iteration 46165, loss = 26.02497740\n",
      "Iteration 46166, loss = 26.01981501\n",
      "Iteration 46167, loss = 26.01465325\n",
      "Iteration 46168, loss = 26.00949210\n",
      "Iteration 46169, loss = 26.00433156\n",
      "Iteration 46170, loss = 25.99917163\n",
      "Iteration 46171, loss = 25.99401231\n",
      "Iteration 46172, loss = 25.98885361\n",
      "Iteration 46173, loss = 25.98369552\n",
      "Iteration 46174, loss = 25.97853805\n",
      "Iteration 46175, loss = 25.97338120\n",
      "Iteration 46176, loss = 25.96822496\n",
      "Iteration 46177, loss = 25.96306934\n",
      "Iteration 46178, loss = 25.95791432\n",
      "Iteration 46179, loss = 25.95275992\n",
      "Iteration 46180, loss = 25.94760613\n",
      "Iteration 46181, loss = 25.94245296\n",
      "Iteration 46182, loss = 25.93730041\n",
      "Iteration 46183, loss = 25.93214847\n",
      "Iteration 46184, loss = 25.92699714\n",
      "Iteration 46185, loss = 25.92184643\n",
      "Iteration 46186, loss = 25.91669633\n",
      "Iteration 46187, loss = 25.91154685\n",
      "Iteration 46188, loss = 25.90639797\n",
      "Iteration 46189, loss = 25.90124972\n",
      "Iteration 46190, loss = 25.89610208\n",
      "Iteration 46191, loss = 25.89095505\n",
      "Iteration 46192, loss = 25.88580864\n",
      "Iteration 46193, loss = 25.88066284\n",
      "Iteration 46194, loss = 25.87551765\n",
      "Iteration 46195, loss = 25.87037308\n",
      "Iteration 46196, loss = 25.86522912\n",
      "Iteration 46197, loss = 25.86008578\n",
      "Iteration 46198, loss = 25.85494305\n",
      "Iteration 46199, loss = 25.84980093\n",
      "Iteration 46200, loss = 25.84465943\n",
      "Iteration 46201, loss = 25.83951855\n",
      "Iteration 46202, loss = 25.83437828\n",
      "Iteration 46203, loss = 25.82923862\n",
      "Iteration 46204, loss = 25.82409957\n",
      "Iteration 46205, loss = 25.81896114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46206, loss = 25.81382332\n",
      "Iteration 46207, loss = 25.80868612\n",
      "Iteration 46208, loss = 25.80354953\n",
      "Iteration 46209, loss = 25.79841356\n",
      "Iteration 46210, loss = 25.79327820\n",
      "Iteration 46211, loss = 25.78814345\n",
      "Iteration 46212, loss = 25.78300932\n",
      "Iteration 46213, loss = 25.77787580\n",
      "Iteration 46214, loss = 25.77274289\n",
      "Iteration 46215, loss = 25.76761060\n",
      "Iteration 46216, loss = 25.76247892\n",
      "Iteration 46217, loss = 25.75734786\n",
      "Iteration 46218, loss = 25.75221741\n",
      "Iteration 46219, loss = 25.74708757\n",
      "Iteration 46220, loss = 25.74195835\n",
      "Iteration 46221, loss = 25.73682974\n",
      "Iteration 46222, loss = 25.73170175\n",
      "Iteration 46223, loss = 25.72657437\n",
      "Iteration 46224, loss = 25.72144760\n",
      "Iteration 46225, loss = 25.71632145\n",
      "Iteration 46226, loss = 25.71119591\n",
      "Iteration 46227, loss = 25.70607098\n",
      "Iteration 46228, loss = 25.70094667\n",
      "Iteration 46229, loss = 25.69582297\n",
      "Iteration 46230, loss = 25.69069989\n",
      "Iteration 46231, loss = 25.68557742\n",
      "Iteration 46232, loss = 25.68045556\n",
      "Iteration 46233, loss = 25.67533432\n",
      "Iteration 46234, loss = 25.67021369\n",
      "Iteration 46235, loss = 25.66509367\n",
      "Iteration 46236, loss = 25.65997427\n",
      "Iteration 46237, loss = 25.65485548\n",
      "Iteration 46238, loss = 25.64973731\n",
      "Iteration 46239, loss = 25.64461975\n",
      "Iteration 46240, loss = 25.63950280\n",
      "Iteration 46241, loss = 25.63438646\n",
      "Iteration 46242, loss = 25.62927074\n",
      "Iteration 46243, loss = 25.62415564\n",
      "Iteration 46244, loss = 25.61904114\n",
      "Iteration 46245, loss = 25.61392726\n",
      "Iteration 46246, loss = 25.60881400\n",
      "Iteration 46247, loss = 25.60370134\n",
      "Iteration 46248, loss = 25.59858931\n",
      "Iteration 46249, loss = 25.59347788\n",
      "Iteration 46250, loss = 25.58836707\n",
      "Iteration 46251, loss = 25.58325687\n",
      "Iteration 46252, loss = 25.57814728\n",
      "Iteration 46253, loss = 25.57303831\n",
      "Iteration 46254, loss = 25.56792995\n",
      "Iteration 46255, loss = 25.56282221\n",
      "Iteration 46256, loss = 25.55771508\n",
      "Iteration 46257, loss = 25.55260856\n",
      "Iteration 46258, loss = 25.54750265\n",
      "Iteration 46259, loss = 25.54239736\n",
      "Iteration 46260, loss = 25.53729269\n",
      "Iteration 46261, loss = 25.53218862\n",
      "Iteration 46262, loss = 25.52708517\n",
      "Iteration 46263, loss = 25.52198233\n",
      "Iteration 46264, loss = 25.51688011\n",
      "Iteration 46265, loss = 25.51177850\n",
      "Iteration 46266, loss = 25.50667750\n",
      "Iteration 46267, loss = 25.50157712\n",
      "Iteration 46268, loss = 25.49647735\n",
      "Iteration 46269, loss = 25.49137819\n",
      "Iteration 46270, loss = 25.48627964\n",
      "Iteration 46271, loss = 25.48118171\n",
      "Iteration 46272, loss = 25.47608439\n",
      "Iteration 46273, loss = 25.47098769\n",
      "Iteration 46274, loss = 25.46589160\n",
      "Iteration 46275, loss = 25.46079612\n",
      "Iteration 46276, loss = 25.45570126\n",
      "Iteration 46277, loss = 25.45060700\n",
      "Iteration 46278, loss = 25.44551336\n",
      "Iteration 46279, loss = 25.44042034\n",
      "Iteration 46280, loss = 25.43532793\n",
      "Iteration 46281, loss = 25.43023613\n",
      "Iteration 46282, loss = 25.42514494\n",
      "Iteration 46283, loss = 25.42005437\n",
      "Iteration 46284, loss = 25.41496441\n",
      "Iteration 46285, loss = 25.40987506\n",
      "Iteration 46286, loss = 25.40478633\n",
      "Iteration 46287, loss = 25.39969821\n",
      "Iteration 46288, loss = 25.39461070\n",
      "Iteration 46289, loss = 25.38952381\n",
      "Iteration 46290, loss = 25.38443753\n",
      "Iteration 46291, loss = 25.37935186\n",
      "Iteration 46292, loss = 25.37426681\n",
      "Iteration 46293, loss = 25.36918237\n",
      "Iteration 46294, loss = 25.36409854\n",
      "Iteration 46295, loss = 25.35901533\n",
      "Iteration 46296, loss = 25.35393273\n",
      "Iteration 46297, loss = 25.34885075\n",
      "Iteration 46298, loss = 25.34376939\n",
      "Iteration 46299, loss = 25.33868865\n",
      "Iteration 46300, loss = 25.33360854\n",
      "Iteration 46301, loss = 25.32852906\n",
      "Iteration 46302, loss = 25.32345023\n",
      "Iteration 46303, loss = 25.31837208\n",
      "Iteration 46304, loss = 25.31329464\n",
      "Iteration 46305, loss = 25.30821798\n",
      "Iteration 46306, loss = 25.30314221\n",
      "Iteration 46307, loss = 25.29806752\n",
      "Iteration 46308, loss = 25.29299422\n",
      "Iteration 46309, loss = 25.28792280\n",
      "Iteration 46310, loss = 25.28285409\n",
      "Iteration 46311, loss = 25.27778933\n",
      "Iteration 46312, loss = 25.27273019\n",
      "Iteration 46313, loss = 25.26767854\n",
      "Iteration 46314, loss = 25.26263497\n",
      "Iteration 46315, loss = 25.25759605\n",
      "Iteration 46316, loss = 25.25255003\n",
      "Iteration 46317, loss = 25.24747916\n",
      "Iteration 46318, loss = 25.24237293\n",
      "Iteration 46319, loss = 25.23724839\n",
      "Iteration 46320, loss = 25.23214169\n",
      "Iteration 46321, loss = 25.22707483\n",
      "Iteration 46322, loss = 25.22203617\n",
      "Iteration 46323, loss = 25.21699430\n",
      "Iteration 46324, loss = 25.21192569\n",
      "Iteration 46325, loss = 25.20683432\n",
      "Iteration 46326, loss = 25.20174660\n",
      "Iteration 46327, loss = 25.19668228\n",
      "Iteration 46328, loss = 25.19163554\n",
      "Iteration 46329, loss = 25.18658517\n",
      "Iteration 46330, loss = 25.18151797\n",
      "Iteration 46331, loss = 25.17644112\n",
      "Iteration 46332, loss = 25.17137152\n",
      "Iteration 46333, loss = 25.16631626\n",
      "Iteration 46334, loss = 25.16126678\n",
      "Iteration 46335, loss = 25.15621075\n",
      "Iteration 46336, loss = 25.15114578\n",
      "Iteration 46337, loss = 25.14608030\n",
      "Iteration 46338, loss = 25.14102258\n",
      "Iteration 46339, loss = 25.13597171\n",
      "Iteration 46340, loss = 25.13092028\n",
      "Iteration 46341, loss = 25.12586355\n",
      "Iteration 46342, loss = 25.12080412\n",
      "Iteration 46343, loss = 25.11574782\n",
      "Iteration 46344, loss = 25.11069673\n",
      "Iteration 46345, loss = 25.10564758\n",
      "Iteration 46346, loss = 25.10059629\n",
      "Iteration 46347, loss = 25.09554255\n",
      "Iteration 46348, loss = 25.09048947\n",
      "Iteration 46349, loss = 25.08543960\n",
      "Iteration 46350, loss = 25.08039220\n",
      "Iteration 46351, loss = 25.07534469\n",
      "Iteration 46352, loss = 25.07029578\n",
      "Iteration 46353, loss = 25.06524659\n",
      "Iteration 46354, loss = 25.06019902\n",
      "Iteration 46355, loss = 25.05515354\n",
      "Iteration 46356, loss = 25.05010897\n",
      "Iteration 46357, loss = 25.04506406\n",
      "Iteration 46358, loss = 25.04001882\n",
      "Iteration 46359, loss = 25.03497425\n",
      "Iteration 46360, loss = 25.02993111\n",
      "Iteration 46361, loss = 25.02488915\n",
      "Iteration 46362, loss = 25.01984762\n",
      "Iteration 46363, loss = 25.01480609\n",
      "Iteration 46364, loss = 25.00976487\n",
      "Iteration 46365, loss = 25.00472450\n",
      "Iteration 46366, loss = 24.99968517\n",
      "Iteration 46367, loss = 24.99464663\n",
      "Iteration 46368, loss = 24.98960849\n",
      "Iteration 46369, loss = 24.98457066\n",
      "Iteration 46370, loss = 24.97953337\n",
      "Iteration 46371, loss = 24.97449687\n",
      "Iteration 46372, loss = 24.96946118\n",
      "Iteration 46373, loss = 24.96442616\n",
      "Iteration 46374, loss = 24.95939161\n",
      "Iteration 46375, loss = 24.95435753\n",
      "Iteration 46376, loss = 24.94932404\n",
      "Iteration 46377, loss = 24.94429127\n",
      "Iteration 46378, loss = 24.93925921\n",
      "Iteration 46379, loss = 24.93422778\n",
      "Iteration 46380, loss = 24.92919689\n",
      "Iteration 46381, loss = 24.92416654\n",
      "Iteration 46382, loss = 24.91913679\n",
      "Iteration 46383, loss = 24.91410770\n",
      "Iteration 46384, loss = 24.90907929\n",
      "Iteration 46385, loss = 24.90405149\n",
      "Iteration 46386, loss = 24.89902427\n",
      "Iteration 46387, loss = 24.89399762\n",
      "Iteration 46388, loss = 24.88897157\n",
      "Iteration 46389, loss = 24.88394617\n",
      "Iteration 46390, loss = 24.87892140\n",
      "Iteration 46391, loss = 24.87389726\n",
      "Iteration 46392, loss = 24.86887371\n",
      "Iteration 46393, loss = 24.86385075\n",
      "Iteration 46394, loss = 24.85882839\n",
      "Iteration 46395, loss = 24.85380666\n",
      "Iteration 46396, loss = 24.84878555\n",
      "Iteration 46397, loss = 24.84376507\n",
      "Iteration 46398, loss = 24.83874519\n",
      "Iteration 46399, loss = 24.83372591\n",
      "Iteration 46400, loss = 24.82870723\n",
      "Iteration 46401, loss = 24.82368917\n",
      "Iteration 46402, loss = 24.81867173\n",
      "Iteration 46403, loss = 24.81365491\n",
      "Iteration 46404, loss = 24.80863870\n",
      "Iteration 46405, loss = 24.80362309\n",
      "Iteration 46406, loss = 24.79860809\n",
      "Iteration 46407, loss = 24.79359370\n",
      "Iteration 46408, loss = 24.78857993\n",
      "Iteration 46409, loss = 24.78356677\n",
      "Iteration 46410, loss = 24.77855423\n",
      "Iteration 46411, loss = 24.77354229\n",
      "Iteration 46412, loss = 24.76853097\n",
      "Iteration 46413, loss = 24.76352025\n",
      "Iteration 46414, loss = 24.75851015\n",
      "Iteration 46415, loss = 24.75350066\n",
      "Iteration 46416, loss = 24.74849178\n",
      "Iteration 46417, loss = 24.74348351\n",
      "Iteration 46418, loss = 24.73847586\n",
      "Iteration 46419, loss = 24.73346881\n",
      "Iteration 46420, loss = 24.72846238\n",
      "Iteration 46421, loss = 24.72345656\n",
      "Iteration 46422, loss = 24.71845135\n",
      "Iteration 46423, loss = 24.71344675\n",
      "Iteration 46424, loss = 24.70844276\n",
      "Iteration 46425, loss = 24.70343939\n",
      "Iteration 46426, loss = 24.69843662\n",
      "Iteration 46427, loss = 24.69343447\n",
      "Iteration 46428, loss = 24.68843293\n",
      "Iteration 46429, loss = 24.68343200\n",
      "Iteration 46430, loss = 24.67843168\n",
      "Iteration 46431, loss = 24.67343197\n",
      "Iteration 46432, loss = 24.66843287\n",
      "Iteration 46433, loss = 24.66343439\n",
      "Iteration 46434, loss = 24.65843651\n",
      "Iteration 46435, loss = 24.65343925\n",
      "Iteration 46436, loss = 24.64844260\n",
      "Iteration 46437, loss = 24.64344656\n",
      "Iteration 46438, loss = 24.63845113\n",
      "Iteration 46439, loss = 24.63345631\n",
      "Iteration 46440, loss = 24.62846211\n",
      "Iteration 46441, loss = 24.62346851\n",
      "Iteration 46442, loss = 24.61847553\n",
      "Iteration 46443, loss = 24.61348316\n",
      "Iteration 46444, loss = 24.60849139\n",
      "Iteration 46445, loss = 24.60350024\n",
      "Iteration 46446, loss = 24.59850970\n",
      "Iteration 46447, loss = 24.59351978\n",
      "Iteration 46448, loss = 24.58853046\n",
      "Iteration 46449, loss = 24.58354175\n",
      "Iteration 46450, loss = 24.57855366\n",
      "Iteration 46451, loss = 24.57356617\n",
      "Iteration 46452, loss = 24.56857930\n",
      "Iteration 46453, loss = 24.56359304\n",
      "Iteration 46454, loss = 24.55860739\n",
      "Iteration 46455, loss = 24.55362235\n",
      "Iteration 46456, loss = 24.54863792\n",
      "Iteration 46457, loss = 24.54365410\n",
      "Iteration 46458, loss = 24.53867090\n",
      "Iteration 46459, loss = 24.53368830\n",
      "Iteration 46460, loss = 24.52870632\n",
      "Iteration 46461, loss = 24.52372494\n",
      "Iteration 46462, loss = 24.51874418\n",
      "Iteration 46463, loss = 24.51376403\n",
      "Iteration 46464, loss = 24.50878449\n",
      "Iteration 46465, loss = 24.50380556\n",
      "Iteration 46466, loss = 24.49882724\n",
      "Iteration 46467, loss = 24.49384953\n",
      "Iteration 46468, loss = 24.48887244\n",
      "Iteration 46469, loss = 24.48389595\n",
      "Iteration 46470, loss = 24.47892008\n",
      "Iteration 46471, loss = 24.47394481\n",
      "Iteration 46472, loss = 24.46897016\n",
      "Iteration 46473, loss = 24.46399612\n",
      "Iteration 46474, loss = 24.45902268\n",
      "Iteration 46475, loss = 24.45404986\n",
      "Iteration 46476, loss = 24.44907765\n",
      "Iteration 46477, loss = 24.44410605\n",
      "Iteration 46478, loss = 24.43913507\n",
      "Iteration 46479, loss = 24.43416469\n",
      "Iteration 46480, loss = 24.42919492\n",
      "Iteration 46481, loss = 24.42422576\n",
      "Iteration 46482, loss = 24.41925722\n",
      "Iteration 46483, loss = 24.41428928\n",
      "Iteration 46484, loss = 24.40932196\n",
      "Iteration 46485, loss = 24.40435525\n",
      "Iteration 46486, loss = 24.39938914\n",
      "Iteration 46487, loss = 24.39442365\n",
      "Iteration 46488, loss = 24.38945877\n",
      "Iteration 46489, loss = 24.38449450\n",
      "Iteration 46490, loss = 24.37953084\n",
      "Iteration 46491, loss = 24.37456779\n",
      "Iteration 46492, loss = 24.36960535\n",
      "Iteration 46493, loss = 24.36464352\n",
      "Iteration 46494, loss = 24.35968231\n",
      "Iteration 46495, loss = 24.35472170\n",
      "Iteration 46496, loss = 24.34976170\n",
      "Iteration 46497, loss = 24.34480232\n",
      "Iteration 46498, loss = 24.33984354\n",
      "Iteration 46499, loss = 24.33488538\n",
      "Iteration 46500, loss = 24.32992782\n",
      "Iteration 46501, loss = 24.32497088\n",
      "Iteration 46502, loss = 24.32001455\n",
      "Iteration 46503, loss = 24.31505883\n",
      "Iteration 46504, loss = 24.31010371\n",
      "Iteration 46505, loss = 24.30514921\n",
      "Iteration 46506, loss = 24.30019532\n",
      "Iteration 46507, loss = 24.29524204\n",
      "Iteration 46508, loss = 24.29028937\n",
      "Iteration 46509, loss = 24.28533731\n",
      "Iteration 46510, loss = 24.28038586\n",
      "Iteration 46511, loss = 24.27543502\n",
      "Iteration 46512, loss = 24.27048479\n",
      "Iteration 46513, loss = 24.26553518\n",
      "Iteration 46514, loss = 24.26058617\n",
      "Iteration 46515, loss = 24.25563777\n",
      "Iteration 46516, loss = 24.25068998\n",
      "Iteration 46517, loss = 24.24574281\n",
      "Iteration 46518, loss = 24.24079624\n",
      "Iteration 46519, loss = 24.23585028\n",
      "Iteration 46520, loss = 24.23090494\n",
      "Iteration 46521, loss = 24.22596020\n",
      "Iteration 46522, loss = 24.22101608\n",
      "Iteration 46523, loss = 24.21607256\n",
      "Iteration 46524, loss = 24.21112966\n",
      "Iteration 46525, loss = 24.20618737\n",
      "Iteration 46526, loss = 24.20124568\n",
      "Iteration 46527, loss = 24.19630461\n",
      "Iteration 46528, loss = 24.19136414\n",
      "Iteration 46529, loss = 24.18642429\n",
      "Iteration 46530, loss = 24.18148505\n",
      "Iteration 46531, loss = 24.17654641\n",
      "Iteration 46532, loss = 24.17160839\n",
      "Iteration 46533, loss = 24.16667098\n",
      "Iteration 46534, loss = 24.16173418\n",
      "Iteration 46535, loss = 24.15679798\n",
      "Iteration 46536, loss = 24.15186240\n",
      "Iteration 46537, loss = 24.14692743\n",
      "Iteration 46538, loss = 24.14199307\n",
      "Iteration 46539, loss = 24.13705932\n",
      "Iteration 46540, loss = 24.13212617\n",
      "Iteration 46541, loss = 24.12719364\n",
      "Iteration 46542, loss = 24.12226172\n",
      "Iteration 46543, loss = 24.11733041\n",
      "Iteration 46544, loss = 24.11239971\n",
      "Iteration 46545, loss = 24.10746962\n",
      "Iteration 46546, loss = 24.10254013\n",
      "Iteration 46547, loss = 24.09761126\n",
      "Iteration 46548, loss = 24.09268300\n",
      "Iteration 46549, loss = 24.08775535\n",
      "Iteration 46550, loss = 24.08282831\n",
      "Iteration 46551, loss = 24.07790188\n",
      "Iteration 46552, loss = 24.07297606\n",
      "Iteration 46553, loss = 24.06805084\n",
      "Iteration 46554, loss = 24.06312624\n",
      "Iteration 46555, loss = 24.05820225\n",
      "Iteration 46556, loss = 24.05327887\n",
      "Iteration 46557, loss = 24.04835610\n",
      "Iteration 46558, loss = 24.04343394\n",
      "Iteration 46559, loss = 24.03851238\n",
      "Iteration 46560, loss = 24.03359144\n",
      "Iteration 46561, loss = 24.02867112\n",
      "Iteration 46562, loss = 24.02375140\n",
      "Iteration 46563, loss = 24.01883229\n",
      "Iteration 46564, loss = 24.01391380\n",
      "Iteration 46565, loss = 24.00899593\n",
      "Iteration 46566, loss = 24.00407869\n",
      "Iteration 46567, loss = 23.99916208\n",
      "Iteration 46568, loss = 23.99424611\n",
      "Iteration 46569, loss = 23.98933083\n",
      "Iteration 46570, loss = 23.98441628\n",
      "Iteration 46571, loss = 23.97950253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46572, loss = 23.97458974\n",
      "Iteration 46573, loss = 23.96967815\n",
      "Iteration 46574, loss = 23.96476818\n",
      "Iteration 46575, loss = 23.95986052\n",
      "Iteration 46576, loss = 23.95495634\n",
      "Iteration 46577, loss = 23.95005736\n",
      "Iteration 46578, loss = 23.94516595\n",
      "Iteration 46579, loss = 23.94028424\n",
      "Iteration 46580, loss = 23.93541174\n",
      "Iteration 46581, loss = 23.93053989\n",
      "Iteration 46582, loss = 23.92564913\n",
      "Iteration 46583, loss = 23.92071748\n",
      "Iteration 46584, loss = 23.91574952\n",
      "Iteration 46585, loss = 23.91078560\n",
      "Iteration 46586, loss = 23.90586608\n",
      "Iteration 46587, loss = 23.90098957\n",
      "Iteration 46588, loss = 23.89611896\n",
      "Iteration 46589, loss = 23.89121826\n",
      "Iteration 46590, loss = 23.88628561\n",
      "Iteration 46591, loss = 23.88135382\n",
      "Iteration 46592, loss = 23.87645097\n",
      "Iteration 46593, loss = 23.87157019\n",
      "Iteration 46594, loss = 23.86668314\n",
      "Iteration 46595, loss = 23.86177417\n",
      "Iteration 46596, loss = 23.85685593\n",
      "Iteration 46597, loss = 23.85195048\n",
      "Iteration 46598, loss = 23.84706197\n",
      "Iteration 46599, loss = 23.84217514\n",
      "Iteration 46600, loss = 23.83727653\n",
      "Iteration 46601, loss = 23.83236981\n",
      "Iteration 46602, loss = 23.82746838\n",
      "Iteration 46603, loss = 23.82257773\n",
      "Iteration 46604, loss = 23.81769039\n",
      "Iteration 46605, loss = 23.81279724\n",
      "Iteration 46606, loss = 23.80789856\n",
      "Iteration 46607, loss = 23.80300195\n",
      "Iteration 46608, loss = 23.79811193\n",
      "Iteration 46609, loss = 23.79322514\n",
      "Iteration 46610, loss = 23.78833581\n",
      "Iteration 46611, loss = 23.78344300\n",
      "Iteration 46612, loss = 23.77855085\n",
      "Iteration 46613, loss = 23.77366275\n",
      "Iteration 46614, loss = 23.76877742\n",
      "Iteration 46615, loss = 23.76389129\n",
      "Iteration 46616, loss = 23.75900312\n",
      "Iteration 46617, loss = 23.75411507\n",
      "Iteration 46618, loss = 23.74922951\n",
      "Iteration 46619, loss = 23.74434621\n",
      "Iteration 46620, loss = 23.73946304\n",
      "Iteration 46621, loss = 23.73457882\n",
      "Iteration 46622, loss = 23.72969456\n",
      "Iteration 46623, loss = 23.72481187\n",
      "Iteration 46624, loss = 23.71993096\n",
      "Iteration 46625, loss = 23.71505063\n",
      "Iteration 46626, loss = 23.71016996\n",
      "Iteration 46627, loss = 23.70528930\n",
      "Iteration 46628, loss = 23.70040965\n",
      "Iteration 46629, loss = 23.69553136\n",
      "Iteration 46630, loss = 23.69065386\n",
      "Iteration 46631, loss = 23.68577649\n",
      "Iteration 46632, loss = 23.68089927\n",
      "Iteration 46633, loss = 23.67602273\n",
      "Iteration 46634, loss = 23.67114723\n",
      "Iteration 46635, loss = 23.66627257\n",
      "Iteration 46636, loss = 23.66139835\n",
      "Iteration 46637, loss = 23.65652443\n",
      "Iteration 46638, loss = 23.65165106\n",
      "Iteration 46639, loss = 23.64677848\n",
      "Iteration 46640, loss = 23.64190670\n",
      "Iteration 46641, loss = 23.63703552\n",
      "Iteration 46642, loss = 23.63216480\n",
      "Iteration 46643, loss = 23.62729458\n",
      "Iteration 46644, loss = 23.62242501\n",
      "Iteration 46645, loss = 23.61755617\n",
      "Iteration 46646, loss = 23.61268799\n",
      "Iteration 46647, loss = 23.60782038\n",
      "Iteration 46648, loss = 23.60295329\n",
      "Iteration 46649, loss = 23.59808679\n",
      "Iteration 46650, loss = 23.59322094\n",
      "Iteration 46651, loss = 23.58835575\n",
      "Iteration 46652, loss = 23.58349119\n",
      "Iteration 46653, loss = 23.57862719\n",
      "Iteration 46654, loss = 23.57376377\n",
      "Iteration 46655, loss = 23.56890095\n",
      "Iteration 46656, loss = 23.56403877\n",
      "Iteration 46657, loss = 23.55917723\n",
      "Iteration 46658, loss = 23.55431630\n",
      "Iteration 46659, loss = 23.54945595\n",
      "Iteration 46660, loss = 23.54459619\n",
      "Iteration 46661, loss = 23.53973704\n",
      "Iteration 46662, loss = 23.53487852\n",
      "Iteration 46663, loss = 23.53002063\n",
      "Iteration 46664, loss = 23.52516333\n",
      "Iteration 46665, loss = 23.52030663\n",
      "Iteration 46666, loss = 23.51545053\n",
      "Iteration 46667, loss = 23.51059505\n",
      "Iteration 46668, loss = 23.50574018\n",
      "Iteration 46669, loss = 23.50088592\n",
      "Iteration 46670, loss = 23.49603228\n",
      "Iteration 46671, loss = 23.49117923\n",
      "Iteration 46672, loss = 23.48632679\n",
      "Iteration 46673, loss = 23.48147495\n",
      "Iteration 46674, loss = 23.47662374\n",
      "Iteration 46675, loss = 23.47177313\n",
      "Iteration 46676, loss = 23.46692313\n",
      "Iteration 46677, loss = 23.46207373\n",
      "Iteration 46678, loss = 23.45722494\n",
      "Iteration 46679, loss = 23.45237676\n",
      "Iteration 46680, loss = 23.44752919\n",
      "Iteration 46681, loss = 23.44268223\n",
      "Iteration 46682, loss = 23.43783588\n",
      "Iteration 46683, loss = 23.43299014\n",
      "Iteration 46684, loss = 23.42814500\n",
      "Iteration 46685, loss = 23.42330047\n",
      "Iteration 46686, loss = 23.41845655\n",
      "Iteration 46687, loss = 23.41361324\n",
      "Iteration 46688, loss = 23.40877053\n",
      "Iteration 46689, loss = 23.40392844\n",
      "Iteration 46690, loss = 23.39908695\n",
      "Iteration 46691, loss = 23.39424607\n",
      "Iteration 46692, loss = 23.38940580\n",
      "Iteration 46693, loss = 23.38456614\n",
      "Iteration 46694, loss = 23.37972708\n",
      "Iteration 46695, loss = 23.37488864\n",
      "Iteration 46696, loss = 23.37005080\n",
      "Iteration 46697, loss = 23.36521357\n",
      "Iteration 46698, loss = 23.36037694\n",
      "Iteration 46699, loss = 23.35554093\n",
      "Iteration 46700, loss = 23.35070552\n",
      "Iteration 46701, loss = 23.34587072\n",
      "Iteration 46702, loss = 23.34103653\n",
      "Iteration 46703, loss = 23.33620295\n",
      "Iteration 46704, loss = 23.33136998\n",
      "Iteration 46705, loss = 23.32653761\n",
      "Iteration 46706, loss = 23.32170585\n",
      "Iteration 46707, loss = 23.31687470\n",
      "Iteration 46708, loss = 23.31204416\n",
      "Iteration 46709, loss = 23.30721422\n",
      "Iteration 46710, loss = 23.30238490\n",
      "Iteration 46711, loss = 23.29755618\n",
      "Iteration 46712, loss = 23.29272807\n",
      "Iteration 46713, loss = 23.28790056\n",
      "Iteration 46714, loss = 23.28307367\n",
      "Iteration 46715, loss = 23.27824738\n",
      "Iteration 46716, loss = 23.27342170\n",
      "Iteration 46717, loss = 23.26859663\n",
      "Iteration 46718, loss = 23.26377217\n",
      "Iteration 46719, loss = 23.25894831\n",
      "Iteration 46720, loss = 23.25412506\n",
      "Iteration 46721, loss = 23.24930242\n",
      "Iteration 46722, loss = 23.24448039\n",
      "Iteration 46723, loss = 23.23965896\n",
      "Iteration 46724, loss = 23.23483815\n",
      "Iteration 46725, loss = 23.23001794\n",
      "Iteration 46726, loss = 23.22519834\n",
      "Iteration 46727, loss = 23.22037934\n",
      "Iteration 46728, loss = 23.21556096\n",
      "Iteration 46729, loss = 23.21074318\n",
      "Iteration 46730, loss = 23.20592601\n",
      "Iteration 46731, loss = 23.20110944\n",
      "Iteration 46732, loss = 23.19629349\n",
      "Iteration 46733, loss = 23.19147814\n",
      "Iteration 46734, loss = 23.18666340\n",
      "Iteration 46735, loss = 23.18184927\n",
      "Iteration 46736, loss = 23.17703574\n",
      "Iteration 46737, loss = 23.17222283\n",
      "Iteration 46738, loss = 23.16741052\n",
      "Iteration 46739, loss = 23.16259882\n",
      "Iteration 46740, loss = 23.15778772\n",
      "Iteration 46741, loss = 23.15297723\n",
      "Iteration 46742, loss = 23.14816735\n",
      "Iteration 46743, loss = 23.14335808\n",
      "Iteration 46744, loss = 23.13854942\n",
      "Iteration 46745, loss = 23.13374136\n",
      "Iteration 46746, loss = 23.12893391\n",
      "Iteration 46747, loss = 23.12412707\n",
      "Iteration 46748, loss = 23.11932084\n",
      "Iteration 46749, loss = 23.11451521\n",
      "Iteration 46750, loss = 23.10971019\n",
      "Iteration 46751, loss = 23.10490578\n",
      "Iteration 46752, loss = 23.10010197\n",
      "Iteration 46753, loss = 23.09529878\n",
      "Iteration 46754, loss = 23.09049619\n",
      "Iteration 46755, loss = 23.08569421\n",
      "Iteration 46756, loss = 23.08089283\n",
      "Iteration 46757, loss = 23.07609206\n",
      "Iteration 46758, loss = 23.07129190\n",
      "Iteration 46759, loss = 23.06649235\n",
      "Iteration 46760, loss = 23.06169341\n",
      "Iteration 46761, loss = 23.05689507\n",
      "Iteration 46762, loss = 23.05209734\n",
      "Iteration 46763, loss = 23.04730021\n",
      "Iteration 46764, loss = 23.04250370\n",
      "Iteration 46765, loss = 23.03770779\n",
      "Iteration 46766, loss = 23.03291249\n",
      "Iteration 46767, loss = 23.02811779\n",
      "Iteration 46768, loss = 23.02332371\n",
      "Iteration 46769, loss = 23.01853023\n",
      "Iteration 46770, loss = 23.01373735\n",
      "Iteration 46771, loss = 23.00894509\n",
      "Iteration 46772, loss = 23.00415343\n",
      "Iteration 46773, loss = 22.99936238\n",
      "Iteration 46774, loss = 22.99457194\n",
      "Iteration 46775, loss = 22.98978210\n",
      "Iteration 46776, loss = 22.98499287\n",
      "Iteration 46777, loss = 22.98020425\n",
      "Iteration 46778, loss = 22.97541623\n",
      "Iteration 46779, loss = 22.97062882\n",
      "Iteration 46780, loss = 22.96584202\n",
      "Iteration 46781, loss = 22.96105583\n",
      "Iteration 46782, loss = 22.95627024\n",
      "Iteration 46783, loss = 22.95148526\n",
      "Iteration 46784, loss = 22.94670089\n",
      "Iteration 46785, loss = 22.94191712\n",
      "Iteration 46786, loss = 22.93713397\n",
      "Iteration 46787, loss = 22.93235141\n",
      "Iteration 46788, loss = 22.92756947\n",
      "Iteration 46789, loss = 22.92278813\n",
      "Iteration 46790, loss = 22.91800740\n",
      "Iteration 46791, loss = 22.91322728\n",
      "Iteration 46792, loss = 22.90844776\n",
      "Iteration 46793, loss = 22.90366885\n",
      "Iteration 46794, loss = 22.89889055\n",
      "Iteration 46795, loss = 22.89411285\n",
      "Iteration 46796, loss = 22.88933576\n",
      "Iteration 46797, loss = 22.88455928\n",
      "Iteration 46798, loss = 22.87978341\n",
      "Iteration 46799, loss = 22.87500814\n",
      "Iteration 46800, loss = 22.87023348\n",
      "Iteration 46801, loss = 22.86545942\n",
      "Iteration 46802, loss = 22.86068598\n",
      "Iteration 46803, loss = 22.85591313\n",
      "Iteration 46804, loss = 22.85114090\n",
      "Iteration 46805, loss = 22.84636927\n",
      "Iteration 46806, loss = 22.84159825\n",
      "Iteration 46807, loss = 22.83682784\n",
      "Iteration 46808, loss = 22.83205803\n",
      "Iteration 46809, loss = 22.82728883\n",
      "Iteration 46810, loss = 22.82252024\n",
      "Iteration 46811, loss = 22.81775225\n",
      "Iteration 46812, loss = 22.81298487\n",
      "Iteration 46813, loss = 22.80821810\n",
      "Iteration 46814, loss = 22.80345193\n",
      "Iteration 46815, loss = 22.79868637\n",
      "Iteration 46816, loss = 22.79392142\n",
      "Iteration 46817, loss = 22.78915708\n",
      "Iteration 46818, loss = 22.78439334\n",
      "Iteration 46819, loss = 22.77963020\n",
      "Iteration 46820, loss = 22.77486768\n",
      "Iteration 46821, loss = 22.77010576\n",
      "Iteration 46822, loss = 22.76534444\n",
      "Iteration 46823, loss = 22.76058374\n",
      "Iteration 46824, loss = 22.75582364\n",
      "Iteration 46825, loss = 22.75106414\n",
      "Iteration 46826, loss = 22.74630526\n",
      "Iteration 46827, loss = 22.74154698\n",
      "Iteration 46828, loss = 22.73678930\n",
      "Iteration 46829, loss = 22.73203224\n",
      "Iteration 46830, loss = 22.72727578\n",
      "Iteration 46831, loss = 22.72251992\n",
      "Iteration 46832, loss = 22.71776467\n",
      "Iteration 46833, loss = 22.71301003\n",
      "Iteration 46834, loss = 22.70825600\n",
      "Iteration 46835, loss = 22.70350257\n",
      "Iteration 46836, loss = 22.69874975\n",
      "Iteration 46837, loss = 22.69399753\n",
      "Iteration 46838, loss = 22.68924592\n",
      "Iteration 46839, loss = 22.68449492\n",
      "Iteration 46840, loss = 22.67974452\n",
      "Iteration 46841, loss = 22.67499473\n",
      "Iteration 46842, loss = 22.67024555\n",
      "Iteration 46843, loss = 22.66549697\n",
      "Iteration 46844, loss = 22.66074900\n",
      "Iteration 46845, loss = 22.65600164\n",
      "Iteration 46846, loss = 22.65125488\n",
      "Iteration 46847, loss = 22.64650873\n",
      "Iteration 46848, loss = 22.64176319\n",
      "Iteration 46849, loss = 22.63701825\n",
      "Iteration 46850, loss = 22.63227391\n",
      "Iteration 46851, loss = 22.62753019\n",
      "Iteration 46852, loss = 22.62278707\n",
      "Iteration 46853, loss = 22.61804456\n",
      "Iteration 46854, loss = 22.61330265\n",
      "Iteration 46855, loss = 22.60856136\n",
      "Iteration 46856, loss = 22.60382067\n",
      "Iteration 46857, loss = 22.59908060\n",
      "Iteration 46858, loss = 22.59434115\n",
      "Iteration 46859, loss = 22.58960233\n",
      "Iteration 46860, loss = 22.58486415\n",
      "Iteration 46861, loss = 22.58012664\n",
      "Iteration 46862, loss = 22.57538986\n",
      "Iteration 46863, loss = 22.57065390\n",
      "Iteration 46864, loss = 22.56591891\n",
      "Iteration 46865, loss = 22.56118518\n",
      "Iteration 46866, loss = 22.55645322\n",
      "Iteration 46867, loss = 22.55172390\n",
      "Iteration 46868, loss = 22.54699872\n",
      "Iteration 46869, loss = 22.54228001\n",
      "Iteration 46870, loss = 22.53757098\n",
      "Iteration 46871, loss = 22.53287459\n",
      "Iteration 46872, loss = 22.52818928\n",
      "Iteration 46873, loss = 22.52350164\n",
      "Iteration 46874, loss = 22.51878170\n",
      "Iteration 46875, loss = 22.51400582\n",
      "Iteration 46876, loss = 22.50919539\n",
      "Iteration 46877, loss = 22.50441380\n",
      "Iteration 46878, loss = 22.49969683\n",
      "Iteration 46879, loss = 22.49501596\n",
      "Iteration 46880, loss = 22.49031361\n",
      "Iteration 46881, loss = 22.48556244\n",
      "Iteration 46882, loss = 22.48079397\n",
      "Iteration 46883, loss = 22.47605694\n",
      "Iteration 46884, loss = 22.47135622\n",
      "Iteration 46885, loss = 22.46665406\n",
      "Iteration 46886, loss = 22.46192205\n",
      "Iteration 46887, loss = 22.45717462\n",
      "Iteration 46888, loss = 22.45244439\n",
      "Iteration 46889, loss = 22.44773725\n",
      "Iteration 46890, loss = 22.44302956\n",
      "Iteration 46891, loss = 22.43830374\n",
      "Iteration 46892, loss = 22.43356997\n",
      "Iteration 46893, loss = 22.42884804\n",
      "Iteration 46894, loss = 22.42413946\n",
      "Iteration 46895, loss = 22.41942886\n",
      "Iteration 46896, loss = 22.41470727\n",
      "Iteration 46897, loss = 22.40998290\n",
      "Iteration 46898, loss = 22.40526712\n",
      "Iteration 46899, loss = 22.40055867\n",
      "Iteration 46900, loss = 22.39584764\n",
      "Iteration 46901, loss = 22.39113022\n",
      "Iteration 46902, loss = 22.38641275\n",
      "Iteration 46903, loss = 22.38170142\n",
      "Iteration 46904, loss = 22.37699393\n",
      "Iteration 46905, loss = 22.37228409\n",
      "Iteration 46906, loss = 22.36757083\n",
      "Iteration 46907, loss = 22.36285873\n",
      "Iteration 46908, loss = 22.35815088\n",
      "Iteration 46909, loss = 22.35344492\n",
      "Iteration 46910, loss = 22.34873725\n",
      "Iteration 46911, loss = 22.34402803\n",
      "Iteration 46912, loss = 22.33932032\n",
      "Iteration 46913, loss = 22.33461543\n",
      "Iteration 46914, loss = 22.32991150\n",
      "Iteration 46915, loss = 22.32520656\n",
      "Iteration 46916, loss = 22.32050118\n",
      "Iteration 46917, loss = 22.31579720\n",
      "Iteration 46918, loss = 22.31109509\n",
      "Iteration 46919, loss = 22.30639357\n",
      "Iteration 46920, loss = 22.30169166\n",
      "Iteration 46921, loss = 22.29698987\n",
      "Iteration 46922, loss = 22.29228924\n",
      "Iteration 46923, loss = 22.28758988\n",
      "Iteration 46924, loss = 22.28289107\n",
      "Iteration 46925, loss = 22.27819229\n",
      "Iteration 46926, loss = 22.27349387\n",
      "Iteration 46927, loss = 22.26879638\n",
      "Iteration 46928, loss = 22.26409986\n",
      "Iteration 46929, loss = 22.25940392\n",
      "Iteration 46930, loss = 22.25470826\n",
      "Iteration 46931, loss = 22.25001307\n",
      "Iteration 46932, loss = 22.24531864\n",
      "Iteration 46933, loss = 22.24062503\n",
      "Iteration 46934, loss = 22.23593204\n",
      "Iteration 46935, loss = 22.23123947\n",
      "Iteration 46936, loss = 22.22654741\n",
      "Iteration 46937, loss = 22.22185603\n",
      "Iteration 46938, loss = 22.21716538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46939, loss = 22.21247537\n",
      "Iteration 46940, loss = 22.20778587\n",
      "Iteration 46941, loss = 22.20309689\n",
      "Iteration 46942, loss = 22.19840855\n",
      "Iteration 46943, loss = 22.19372089\n",
      "Iteration 46944, loss = 22.18903387\n",
      "Iteration 46945, loss = 22.18434741\n",
      "Iteration 46946, loss = 22.17966150\n",
      "Iteration 46947, loss = 22.17497619\n",
      "Iteration 46948, loss = 22.17029154\n",
      "Iteration 46949, loss = 22.16560753\n",
      "Iteration 46950, loss = 22.16092410\n",
      "Iteration 46951, loss = 22.15624124\n",
      "Iteration 46952, loss = 22.15155897\n",
      "Iteration 46953, loss = 22.14687733\n",
      "Iteration 46954, loss = 22.14219632\n",
      "Iteration 46955, loss = 22.13751591\n",
      "Iteration 46956, loss = 22.13283609\n",
      "Iteration 46957, loss = 22.12815686\n",
      "Iteration 46958, loss = 22.12347824\n",
      "Iteration 46959, loss = 22.11880025\n",
      "Iteration 46960, loss = 22.11412286\n",
      "Iteration 46961, loss = 22.10944607\n",
      "Iteration 46962, loss = 22.10476987\n",
      "Iteration 46963, loss = 22.10009428\n",
      "Iteration 46964, loss = 22.09541930\n",
      "Iteration 46965, loss = 22.09074493\n",
      "Iteration 46966, loss = 22.08607117\n",
      "Iteration 46967, loss = 22.08139800\n",
      "Iteration 46968, loss = 22.07672543\n",
      "Iteration 46969, loss = 22.07205347\n",
      "Iteration 46970, loss = 22.06738212\n",
      "Iteration 46971, loss = 22.06271138\n",
      "Iteration 46972, loss = 22.05804124\n",
      "Iteration 46973, loss = 22.05337170\n",
      "Iteration 46974, loss = 22.04870277\n",
      "Iteration 46975, loss = 22.04403444\n",
      "Iteration 46976, loss = 22.03936671\n",
      "Iteration 46977, loss = 22.03469960\n",
      "Iteration 46978, loss = 22.03003308\n",
      "Iteration 46979, loss = 22.02536717\n",
      "Iteration 46980, loss = 22.02070186\n",
      "Iteration 46981, loss = 22.01603716\n",
      "Iteration 46982, loss = 22.01137306\n",
      "Iteration 46983, loss = 22.00670957\n",
      "Iteration 46984, loss = 22.00204668\n",
      "Iteration 46985, loss = 21.99738440\n",
      "Iteration 46986, loss = 21.99272272\n",
      "Iteration 46987, loss = 21.98806165\n",
      "Iteration 46988, loss = 21.98340118\n",
      "Iteration 46989, loss = 21.97874131\n",
      "Iteration 46990, loss = 21.97408205\n",
      "Iteration 46991, loss = 21.96942339\n",
      "Iteration 46992, loss = 21.96476534\n",
      "Iteration 46993, loss = 21.96010789\n",
      "Iteration 46994, loss = 21.95545104\n",
      "Iteration 46995, loss = 21.95079481\n",
      "Iteration 46996, loss = 21.94613917\n",
      "Iteration 46997, loss = 21.94148414\n",
      "Iteration 46998, loss = 21.93682971\n",
      "Iteration 46999, loss = 21.93217589\n",
      "Iteration 47000, loss = 21.92752267\n",
      "Iteration 47001, loss = 21.92287005\n",
      "Iteration 47002, loss = 21.91821804\n",
      "Iteration 47003, loss = 21.91356664\n",
      "Iteration 47004, loss = 21.90891584\n",
      "Iteration 47005, loss = 21.90426564\n",
      "Iteration 47006, loss = 21.89961605\n",
      "Iteration 47007, loss = 21.89496706\n",
      "Iteration 47008, loss = 21.89031867\n",
      "Iteration 47009, loss = 21.88567089\n",
      "Iteration 47010, loss = 21.88102371\n",
      "Iteration 47011, loss = 21.87637714\n",
      "Iteration 47012, loss = 21.87173117\n",
      "Iteration 47013, loss = 21.86708581\n",
      "Iteration 47014, loss = 21.86244105\n",
      "Iteration 47015, loss = 21.85779689\n",
      "Iteration 47016, loss = 21.85315334\n",
      "Iteration 47017, loss = 21.84851039\n",
      "Iteration 47018, loss = 21.84386805\n",
      "Iteration 47019, loss = 21.83922631\n",
      "Iteration 47020, loss = 21.83458517\n",
      "Iteration 47021, loss = 21.82994464\n",
      "Iteration 47022, loss = 21.82530471\n",
      "Iteration 47023, loss = 21.82066538\n",
      "Iteration 47024, loss = 21.81602666\n",
      "Iteration 47025, loss = 21.81138855\n",
      "Iteration 47026, loss = 21.80675103\n",
      "Iteration 47027, loss = 21.80211413\n",
      "Iteration 47028, loss = 21.79747782\n",
      "Iteration 47029, loss = 21.79284212\n",
      "Iteration 47030, loss = 21.78820702\n",
      "Iteration 47031, loss = 21.78357253\n",
      "Iteration 47032, loss = 21.77893864\n",
      "Iteration 47033, loss = 21.77430536\n",
      "Iteration 47034, loss = 21.76967267\n",
      "Iteration 47035, loss = 21.76504060\n",
      "Iteration 47036, loss = 21.76040912\n",
      "Iteration 47037, loss = 21.75577825\n",
      "Iteration 47038, loss = 21.75114799\n",
      "Iteration 47039, loss = 21.74651832\n",
      "Iteration 47040, loss = 21.74188926\n",
      "Iteration 47041, loss = 21.73726081\n",
      "Iteration 47042, loss = 21.73263296\n",
      "Iteration 47043, loss = 21.72800571\n",
      "Iteration 47044, loss = 21.72337907\n",
      "Iteration 47045, loss = 21.71875303\n",
      "Iteration 47046, loss = 21.71412759\n",
      "Iteration 47047, loss = 21.70950276\n",
      "Iteration 47048, loss = 21.70487853\n",
      "Iteration 47049, loss = 21.70025490\n",
      "Iteration 47050, loss = 21.69563188\n",
      "Iteration 47051, loss = 21.69100946\n",
      "Iteration 47052, loss = 21.68638765\n",
      "Iteration 47053, loss = 21.68176644\n",
      "Iteration 47054, loss = 21.67714583\n",
      "Iteration 47055, loss = 21.67252582\n",
      "Iteration 47056, loss = 21.66790642\n",
      "Iteration 47057, loss = 21.66328763\n",
      "Iteration 47058, loss = 21.65866943\n",
      "Iteration 47059, loss = 21.65405184\n",
      "Iteration 47060, loss = 21.64943486\n",
      "Iteration 47061, loss = 21.64481847\n",
      "Iteration 47062, loss = 21.64020270\n",
      "Iteration 47063, loss = 21.63558752\n",
      "Iteration 47064, loss = 21.63097295\n",
      "Iteration 47065, loss = 21.62635898\n",
      "Iteration 47066, loss = 21.62174561\n",
      "Iteration 47067, loss = 21.61713285\n",
      "Iteration 47068, loss = 21.61252069\n",
      "Iteration 47069, loss = 21.60790914\n",
      "Iteration 47070, loss = 21.60329819\n",
      "Iteration 47071, loss = 21.59868784\n",
      "Iteration 47072, loss = 21.59407809\n",
      "Iteration 47073, loss = 21.58946895\n",
      "Iteration 47074, loss = 21.58486041\n",
      "Iteration 47075, loss = 21.58025248\n",
      "Iteration 47076, loss = 21.57564514\n",
      "Iteration 47077, loss = 21.57103842\n",
      "Iteration 47078, loss = 21.56643229\n",
      "Iteration 47079, loss = 21.56182677\n",
      "Iteration 47080, loss = 21.55722185\n",
      "Iteration 47081, loss = 21.55261754\n",
      "Iteration 47082, loss = 21.54801382\n",
      "Iteration 47083, loss = 21.54341071\n",
      "Iteration 47084, loss = 21.53880821\n",
      "Iteration 47085, loss = 21.53420631\n",
      "Iteration 47086, loss = 21.52960501\n",
      "Iteration 47087, loss = 21.52500431\n",
      "Iteration 47088, loss = 21.52040422\n",
      "Iteration 47089, loss = 21.51580473\n",
      "Iteration 47090, loss = 21.51120584\n",
      "Iteration 47091, loss = 21.50660756\n",
      "Iteration 47092, loss = 21.50200988\n",
      "Iteration 47093, loss = 21.49741280\n",
      "Iteration 47094, loss = 21.49281633\n",
      "Iteration 47095, loss = 21.48822046\n",
      "Iteration 47096, loss = 21.48362519\n",
      "Iteration 47097, loss = 21.47903052\n",
      "Iteration 47098, loss = 21.47443646\n",
      "Iteration 47099, loss = 21.46984300\n",
      "Iteration 47100, loss = 21.46525015\n",
      "Iteration 47101, loss = 21.46065789\n",
      "Iteration 47102, loss = 21.45606624\n",
      "Iteration 47103, loss = 21.45147520\n",
      "Iteration 47104, loss = 21.44688475\n",
      "Iteration 47105, loss = 21.44229491\n",
      "Iteration 47106, loss = 21.43770567\n",
      "Iteration 47107, loss = 21.43311704\n",
      "Iteration 47108, loss = 21.42852901\n",
      "Iteration 47109, loss = 21.42394158\n",
      "Iteration 47110, loss = 21.41935475\n",
      "Iteration 47111, loss = 21.41476853\n",
      "Iteration 47112, loss = 21.41018291\n",
      "Iteration 47113, loss = 21.40559789\n",
      "Iteration 47114, loss = 21.40101348\n",
      "Iteration 47115, loss = 21.39642966\n",
      "Iteration 47116, loss = 21.39184645\n",
      "Iteration 47117, loss = 21.38726385\n",
      "Iteration 47118, loss = 21.38268184\n",
      "Iteration 47119, loss = 21.37810044\n",
      "Iteration 47120, loss = 21.37351965\n",
      "Iteration 47121, loss = 21.36893945\n",
      "Iteration 47122, loss = 21.36435986\n",
      "Iteration 47123, loss = 21.35978087\n",
      "Iteration 47124, loss = 21.35520248\n",
      "Iteration 47125, loss = 21.35062470\n",
      "Iteration 47126, loss = 21.34604752\n",
      "Iteration 47127, loss = 21.34147094\n",
      "Iteration 47128, loss = 21.33689496\n",
      "Iteration 47129, loss = 21.33231959\n",
      "Iteration 47130, loss = 21.32774482\n",
      "Iteration 47131, loss = 21.32317065\n",
      "Iteration 47132, loss = 21.31859708\n",
      "Iteration 47133, loss = 21.31402412\n",
      "Iteration 47134, loss = 21.30945176\n",
      "Iteration 47135, loss = 21.30488000\n",
      "Iteration 47136, loss = 21.30030885\n",
      "Iteration 47137, loss = 21.29573829\n",
      "Iteration 47138, loss = 21.29116834\n",
      "Iteration 47139, loss = 21.28659900\n",
      "Iteration 47140, loss = 21.28203025\n",
      "Iteration 47141, loss = 21.27746211\n",
      "Iteration 47142, loss = 21.27289457\n",
      "Iteration 47143, loss = 21.26832763\n",
      "Iteration 47144, loss = 21.26376130\n",
      "Iteration 47145, loss = 21.25919556\n",
      "Iteration 47146, loss = 21.25463043\n",
      "Iteration 47147, loss = 21.25006590\n",
      "Iteration 47148, loss = 21.24550198\n",
      "Iteration 47149, loss = 21.24093866\n",
      "Iteration 47150, loss = 21.23637594\n",
      "Iteration 47151, loss = 21.23181382\n",
      "Iteration 47152, loss = 21.22725230\n",
      "Iteration 47153, loss = 21.22269139\n",
      "Iteration 47154, loss = 21.21813108\n",
      "Iteration 47155, loss = 21.21357137\n",
      "Iteration 47156, loss = 21.20901226\n",
      "Iteration 47157, loss = 21.20445376\n",
      "Iteration 47158, loss = 21.19989586\n",
      "Iteration 47159, loss = 21.19533856\n",
      "Iteration 47160, loss = 21.19078186\n",
      "Iteration 47161, loss = 21.18622577\n",
      "Iteration 47162, loss = 21.18167027\n",
      "Iteration 47163, loss = 21.17711538\n",
      "Iteration 47164, loss = 21.17256110\n",
      "Iteration 47165, loss = 21.16800741\n",
      "Iteration 47166, loss = 21.16345433\n",
      "Iteration 47167, loss = 21.15890184\n",
      "Iteration 47168, loss = 21.15434997\n",
      "Iteration 47169, loss = 21.14979869\n",
      "Iteration 47170, loss = 21.14524801\n",
      "Iteration 47171, loss = 21.14069794\n",
      "Iteration 47172, loss = 21.13614847\n",
      "Iteration 47173, loss = 21.13159960\n",
      "Iteration 47174, loss = 21.12705133\n",
      "Iteration 47175, loss = 21.12250367\n",
      "Iteration 47176, loss = 21.11795661\n",
      "Iteration 47177, loss = 21.11341015\n",
      "Iteration 47178, loss = 21.10886429\n",
      "Iteration 47179, loss = 21.10431903\n",
      "Iteration 47180, loss = 21.09977438\n",
      "Iteration 47181, loss = 21.09523033\n",
      "Iteration 47182, loss = 21.09068688\n",
      "Iteration 47183, loss = 21.08614403\n",
      "Iteration 47184, loss = 21.08160179\n",
      "Iteration 47185, loss = 21.07706015\n",
      "Iteration 47186, loss = 21.07251911\n",
      "Iteration 47187, loss = 21.06797868\n",
      "Iteration 47188, loss = 21.06343885\n",
      "Iteration 47189, loss = 21.05889965\n",
      "Iteration 47190, loss = 21.05436107\n",
      "Iteration 47191, loss = 21.04982313\n",
      "Iteration 47192, loss = 21.04528588\n",
      "Iteration 47193, loss = 21.04074938\n",
      "Iteration 47194, loss = 21.03621377\n",
      "Iteration 47195, loss = 21.03167931\n",
      "Iteration 47196, loss = 21.02714646\n",
      "Iteration 47197, loss = 21.02261611\n",
      "Iteration 47198, loss = 21.01808990\n",
      "Iteration 47199, loss = 21.01357065\n",
      "Iteration 47200, loss = 21.00906289\n",
      "Iteration 47201, loss = 21.00457213\n",
      "Iteration 47202, loss = 21.00010053\n",
      "Iteration 47203, loss = 20.99563384\n",
      "Iteration 47204, loss = 20.99113005\n",
      "Iteration 47205, loss = 20.98654299\n",
      "Iteration 47206, loss = 20.98190053\n",
      "Iteration 47207, loss = 20.97730374\n",
      "Iteration 47208, loss = 20.97280447\n",
      "Iteration 47209, loss = 20.96834270\n",
      "Iteration 47210, loss = 20.96382616\n",
      "Iteration 47211, loss = 20.95924245\n",
      "Iteration 47212, loss = 20.95467098\n",
      "Iteration 47213, loss = 20.95016477\n",
      "Iteration 47214, loss = 20.94567949\n",
      "Iteration 47215, loss = 20.94115099\n",
      "Iteration 47216, loss = 20.93658935\n",
      "Iteration 47217, loss = 20.93205321\n",
      "Iteration 47218, loss = 20.92755417\n",
      "Iteration 47219, loss = 20.92304764\n",
      "Iteration 47220, loss = 20.91850985\n",
      "Iteration 47221, loss = 20.91397046\n",
      "Iteration 47222, loss = 20.90945735\n",
      "Iteration 47223, loss = 20.90495376\n",
      "Iteration 47224, loss = 20.90043261\n",
      "Iteration 47225, loss = 20.89590038\n",
      "Iteration 47226, loss = 20.89138090\n",
      "Iteration 47227, loss = 20.88687463\n",
      "Iteration 47228, loss = 20.88236234\n",
      "Iteration 47229, loss = 20.87783895\n",
      "Iteration 47230, loss = 20.87331893\n",
      "Iteration 47231, loss = 20.86880988\n",
      "Iteration 47232, loss = 20.86430169\n",
      "Iteration 47233, loss = 20.85978578\n",
      "Iteration 47234, loss = 20.85526840\n",
      "Iteration 47235, loss = 20.85075810\n",
      "Iteration 47236, loss = 20.84625167\n",
      "Iteration 47237, loss = 20.84174132\n",
      "Iteration 47238, loss = 20.83722789\n",
      "Iteration 47239, loss = 20.83271801\n",
      "Iteration 47240, loss = 20.82821252\n",
      "Iteration 47241, loss = 20.82370608\n",
      "Iteration 47242, loss = 20.81919681\n",
      "Iteration 47243, loss = 20.81468867\n",
      "Iteration 47244, loss = 20.81018412\n",
      "Iteration 47245, loss = 20.80568044\n",
      "Iteration 47246, loss = 20.80117501\n",
      "Iteration 47247, loss = 20.79666943\n",
      "Iteration 47248, loss = 20.79216622\n",
      "Iteration 47249, loss = 20.78766466\n",
      "Iteration 47250, loss = 20.78316253\n",
      "Iteration 47251, loss = 20.77865989\n",
      "Iteration 47252, loss = 20.77415854\n",
      "Iteration 47253, loss = 20.76965886\n",
      "Iteration 47254, loss = 20.76515952\n",
      "Iteration 47255, loss = 20.76065986\n",
      "Iteration 47256, loss = 20.75616079\n",
      "Iteration 47257, loss = 20.75166303\n",
      "Iteration 47258, loss = 20.74716611\n",
      "Iteration 47259, loss = 20.74266929\n",
      "Iteration 47260, loss = 20.73817275\n",
      "Iteration 47261, loss = 20.73367711\n",
      "Iteration 47262, loss = 20.72918241\n",
      "Iteration 47263, loss = 20.72468821\n",
      "Iteration 47264, loss = 20.72019429\n",
      "Iteration 47265, loss = 20.71570096\n",
      "Iteration 47266, loss = 20.71120848\n",
      "Iteration 47267, loss = 20.70671670\n",
      "Iteration 47268, loss = 20.70222536\n",
      "Iteration 47269, loss = 20.69773449\n",
      "Iteration 47270, loss = 20.69324430\n",
      "Iteration 47271, loss = 20.68875484\n",
      "Iteration 47272, loss = 20.68426598\n",
      "Iteration 47273, loss = 20.67977761\n",
      "Iteration 47274, loss = 20.67528979\n",
      "Iteration 47275, loss = 20.67080266\n",
      "Iteration 47276, loss = 20.66631620\n",
      "Iteration 47277, loss = 20.66183029\n",
      "Iteration 47278, loss = 20.65734492\n",
      "Iteration 47279, loss = 20.65286015\n",
      "Iteration 47280, loss = 20.64837605\n",
      "Iteration 47281, loss = 20.64389256\n",
      "Iteration 47282, loss = 20.63940964\n",
      "Iteration 47283, loss = 20.63492728\n",
      "Iteration 47284, loss = 20.63044554\n",
      "Iteration 47285, loss = 20.62596444\n",
      "Iteration 47286, loss = 20.62148394\n",
      "Iteration 47287, loss = 20.61700401\n",
      "Iteration 47288, loss = 20.61252466\n",
      "Iteration 47289, loss = 20.60804594\n",
      "Iteration 47290, loss = 20.60356784\n",
      "Iteration 47291, loss = 20.59909033\n",
      "Iteration 47292, loss = 20.59461340\n",
      "Iteration 47293, loss = 20.59013707\n",
      "Iteration 47294, loss = 20.58566135\n",
      "Iteration 47295, loss = 20.58118625\n",
      "Iteration 47296, loss = 20.57671173\n",
      "Iteration 47297, loss = 20.57223781\n",
      "Iteration 47298, loss = 20.56776448\n",
      "Iteration 47299, loss = 20.56329177\n",
      "Iteration 47300, loss = 20.55881966\n",
      "Iteration 47301, loss = 20.55434814\n",
      "Iteration 47302, loss = 20.54987722\n",
      "Iteration 47303, loss = 20.54540691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 47304, loss = 20.54093719\n",
      "Iteration 47305, loss = 20.53646808\n",
      "Iteration 47306, loss = 20.53199957\n",
      "Iteration 47307, loss = 20.52753165\n",
      "Iteration 47308, loss = 20.52306433\n",
      "Iteration 47309, loss = 20.51859762\n",
      "Iteration 47310, loss = 20.51413151\n",
      "Iteration 47311, loss = 20.50966599\n",
      "Iteration 47312, loss = 20.50520108\n",
      "Iteration 47313, loss = 20.50073676\n",
      "Iteration 47314, loss = 20.49627305\n",
      "Iteration 47315, loss = 20.49180994\n",
      "Iteration 47316, loss = 20.48734742\n",
      "Iteration 47317, loss = 20.48288551\n",
      "Iteration 47318, loss = 20.47842419\n",
      "Iteration 47319, loss = 20.47396348\n",
      "Iteration 47320, loss = 20.46950337\n",
      "Iteration 47321, loss = 20.46504385\n",
      "Iteration 47322, loss = 20.46058494\n",
      "Iteration 47323, loss = 20.45612662\n",
      "Iteration 47324, loss = 20.45166891\n",
      "Iteration 47325, loss = 20.44721180\n",
      "Iteration 47326, loss = 20.44275528\n",
      "Iteration 47327, loss = 20.43829937\n",
      "Iteration 47328, loss = 20.43384405\n",
      "Iteration 47329, loss = 20.42938934\n",
      "Iteration 47330, loss = 20.42493522\n",
      "Iteration 47331, loss = 20.42048171\n",
      "Iteration 47332, loss = 20.41602879\n",
      "Iteration 47333, loss = 20.41157648\n",
      "Iteration 47334, loss = 20.40712476\n",
      "Iteration 47335, loss = 20.40267365\n",
      "Iteration 47336, loss = 20.39822313\n",
      "Iteration 47337, loss = 20.39377321\n",
      "Iteration 47338, loss = 20.38932390\n",
      "Iteration 47339, loss = 20.38487518\n",
      "Iteration 47340, loss = 20.38042706\n",
      "Iteration 47341, loss = 20.37597955\n",
      "Iteration 47342, loss = 20.37153263\n",
      "Iteration 47343, loss = 20.36708631\n",
      "Iteration 47344, loss = 20.36264059\n",
      "Iteration 47345, loss = 20.35819548\n",
      "Iteration 47346, loss = 20.35375096\n",
      "Iteration 47347, loss = 20.34930704\n",
      "Iteration 47348, loss = 20.34486372\n",
      "Iteration 47349, loss = 20.34042100\n",
      "Iteration 47350, loss = 20.33597888\n",
      "Iteration 47351, loss = 20.33153736\n",
      "Iteration 47352, loss = 20.32709644\n",
      "Iteration 47353, loss = 20.32265611\n",
      "Iteration 47354, loss = 20.31821639\n",
      "Iteration 47355, loss = 20.31377727\n",
      "Iteration 47356, loss = 20.30933875\n",
      "Iteration 47357, loss = 20.30490082\n",
      "Iteration 47358, loss = 20.30046350\n",
      "Iteration 47359, loss = 20.29602677\n",
      "Iteration 47360, loss = 20.29159065\n",
      "Iteration 47361, loss = 20.28715512\n",
      "Iteration 47362, loss = 20.28272020\n",
      "Iteration 47363, loss = 20.27828587\n",
      "Iteration 47364, loss = 20.27385214\n",
      "Iteration 47365, loss = 20.26941901\n",
      "Iteration 47366, loss = 20.26498648\n",
      "Iteration 47367, loss = 20.26055456\n",
      "Iteration 47368, loss = 20.25612323\n",
      "Iteration 47369, loss = 20.25169249\n",
      "Iteration 47370, loss = 20.24726236\n",
      "Iteration 47371, loss = 20.24283283\n",
      "Iteration 47372, loss = 20.23840390\n",
      "Iteration 47373, loss = 20.23397557\n",
      "Iteration 47374, loss = 20.22954783\n",
      "Iteration 47375, loss = 20.22512070\n",
      "Iteration 47376, loss = 20.22069416\n",
      "Iteration 47377, loss = 20.21626823\n",
      "Iteration 47378, loss = 20.21184289\n",
      "Iteration 47379, loss = 20.20741815\n",
      "Iteration 47380, loss = 20.20299401\n",
      "Iteration 47381, loss = 20.19857047\n",
      "Iteration 47382, loss = 20.19414753\n",
      "Iteration 47383, loss = 20.18972519\n",
      "Iteration 47384, loss = 20.18530345\n",
      "Iteration 47385, loss = 20.18088231\n",
      "Iteration 47386, loss = 20.17646176\n",
      "Iteration 47387, loss = 20.17204182\n",
      "Iteration 47388, loss = 20.16762247\n",
      "Iteration 47389, loss = 20.16320373\n",
      "Iteration 47390, loss = 20.15878558\n",
      "Iteration 47391, loss = 20.15436803\n",
      "Iteration 47392, loss = 20.14995108\n",
      "Iteration 47393, loss = 20.14553473\n",
      "Iteration 47394, loss = 20.14111898\n",
      "Iteration 47395, loss = 20.13670383\n",
      "Iteration 47396, loss = 20.13228928\n",
      "Iteration 47397, loss = 20.12787532\n",
      "Iteration 47398, loss = 20.12346197\n",
      "Iteration 47399, loss = 20.11904921\n",
      "Iteration 47400, loss = 20.11463706\n",
      "Iteration 47401, loss = 20.11022550\n",
      "Iteration 47402, loss = 20.10581454\n",
      "Iteration 47403, loss = 20.10140418\n",
      "Iteration 47404, loss = 20.09699442\n",
      "Iteration 47405, loss = 20.09258525\n",
      "Iteration 47406, loss = 20.08817669\n",
      "Iteration 47407, loss = 20.08376873\n",
      "Iteration 47408, loss = 20.07936136\n",
      "Iteration 47409, loss = 20.07495459\n",
      "Iteration 47410, loss = 20.07054842\n",
      "Iteration 47411, loss = 20.06614285\n",
      "Iteration 47412, loss = 20.06173788\n",
      "Iteration 47413, loss = 20.05733351\n",
      "Iteration 47414, loss = 20.05292974\n",
      "Iteration 47415, loss = 20.04852656\n",
      "Iteration 47416, loss = 20.04412399\n",
      "Iteration 47417, loss = 20.03972201\n",
      "Iteration 47418, loss = 20.03532063\n",
      "Iteration 47419, loss = 20.03091985\n",
      "Iteration 47420, loss = 20.02651967\n",
      "Iteration 47421, loss = 20.02212009\n",
      "Iteration 47422, loss = 20.01772111\n",
      "Iteration 47423, loss = 20.01332272\n",
      "Iteration 47424, loss = 20.00892494\n",
      "Iteration 47425, loss = 20.00452775\n",
      "Iteration 47426, loss = 20.00013116\n",
      "Iteration 47427, loss = 19.99573517\n",
      "Iteration 47428, loss = 19.99133978\n",
      "Iteration 47429, loss = 19.98694499\n",
      "Iteration 47430, loss = 19.98255079\n",
      "Iteration 47431, loss = 19.97815720\n",
      "Iteration 47432, loss = 19.97376420\n",
      "Iteration 47433, loss = 19.96937180\n",
      "Iteration 47434, loss = 19.96498000\n",
      "Iteration 47435, loss = 19.96058880\n",
      "Iteration 47436, loss = 19.95619819\n",
      "Iteration 47437, loss = 19.95180819\n",
      "Iteration 47438, loss = 19.94741878\n",
      "Iteration 47439, loss = 19.94302997\n",
      "Iteration 47440, loss = 19.93864177\n",
      "Iteration 47441, loss = 19.93425415\n",
      "Iteration 47442, loss = 19.92986714\n",
      "Iteration 47443, loss = 19.92548073\n",
      "Iteration 47444, loss = 19.92109491\n",
      "Iteration 47445, loss = 19.91670969\n",
      "Iteration 47446, loss = 19.91232507\n",
      "Iteration 47447, loss = 19.90794105\n",
      "Iteration 47448, loss = 19.90355763\n",
      "Iteration 47449, loss = 19.89917481\n",
      "Iteration 47450, loss = 19.89479258\n",
      "Iteration 47451, loss = 19.89041095\n",
      "Iteration 47452, loss = 19.88602992\n",
      "Iteration 47453, loss = 19.88164949\n",
      "Iteration 47454, loss = 19.87726966\n",
      "Iteration 47455, loss = 19.87289043\n",
      "Iteration 47456, loss = 19.86851179\n",
      "Iteration 47457, loss = 19.86413375\n",
      "Iteration 47458, loss = 19.85975631\n",
      "Iteration 47459, loss = 19.85537947\n",
      "Iteration 47460, loss = 19.85100323\n",
      "Iteration 47461, loss = 19.84662758\n",
      "Iteration 47462, loss = 19.84225253\n",
      "Iteration 47463, loss = 19.83787808\n",
      "Iteration 47464, loss = 19.83350423\n",
      "Iteration 47465, loss = 19.82913098\n",
      "Iteration 47466, loss = 19.82475833\n",
      "Iteration 47467, loss = 19.82038627\n",
      "Iteration 47468, loss = 19.81601481\n",
      "Iteration 47469, loss = 19.81164395\n",
      "Iteration 47470, loss = 19.80727369\n",
      "Iteration 47471, loss = 19.80290402\n",
      "Iteration 47472, loss = 19.79853496\n",
      "Iteration 47473, loss = 19.79416649\n",
      "Iteration 47474, loss = 19.78979862\n",
      "Iteration 47475, loss = 19.78543134\n",
      "Iteration 47476, loss = 19.78106467\n",
      "Iteration 47477, loss = 19.77669859\n",
      "Iteration 47478, loss = 19.77233311\n",
      "Iteration 47479, loss = 19.76796823\n",
      "Iteration 47480, loss = 19.76360395\n",
      "Iteration 47481, loss = 19.75924027\n",
      "Iteration 47482, loss = 19.75487718\n",
      "Iteration 47483, loss = 19.75051469\n",
      "Iteration 47484, loss = 19.74615280\n",
      "Iteration 47485, loss = 19.74179151\n",
      "Iteration 47486, loss = 19.73743081\n",
      "Iteration 47487, loss = 19.73307071\n",
      "Iteration 47488, loss = 19.72871121\n",
      "Iteration 47489, loss = 19.72435231\n",
      "Iteration 47490, loss = 19.71999401\n",
      "Iteration 47491, loss = 19.71563630\n",
      "Iteration 47492, loss = 19.71127919\n",
      "Iteration 47493, loss = 19.70692268\n",
      "Iteration 47494, loss = 19.70256677\n",
      "Iteration 47495, loss = 19.69821145\n",
      "Iteration 47496, loss = 19.69385673\n",
      "Iteration 47497, loss = 19.68950261\n",
      "Iteration 47498, loss = 19.68514909\n",
      "Iteration 47499, loss = 19.68079617\n",
      "Iteration 47500, loss = 19.67644384\n",
      "Iteration 47501, loss = 19.67209211\n",
      "Iteration 47502, loss = 19.66774098\n",
      "Iteration 47503, loss = 19.66339044\n",
      "Iteration 47504, loss = 19.65904051\n",
      "Iteration 47505, loss = 19.65469117\n",
      "Iteration 47506, loss = 19.65034242\n",
      "Iteration 47507, loss = 19.64599428\n",
      "Iteration 47508, loss = 19.64164673\n",
      "Iteration 47509, loss = 19.63729979\n",
      "Iteration 47510, loss = 19.63295343\n",
      "Iteration 47511, loss = 19.62860768\n",
      "Iteration 47512, loss = 19.62426252\n",
      "Iteration 47513, loss = 19.61991796\n",
      "Iteration 47514, loss = 19.61557400\n",
      "Iteration 47515, loss = 19.61123064\n",
      "Iteration 47516, loss = 19.60688787\n",
      "Iteration 47517, loss = 19.60254570\n",
      "Iteration 47518, loss = 19.59820413\n",
      "Iteration 47519, loss = 19.59386316\n",
      "Iteration 47520, loss = 19.58952278\n",
      "Iteration 47521, loss = 19.58518300\n",
      "Iteration 47522, loss = 19.58084382\n",
      "Iteration 47523, loss = 19.57650523\n",
      "Iteration 47524, loss = 19.57216725\n",
      "Iteration 47525, loss = 19.56782986\n",
      "Iteration 47526, loss = 19.56349306\n",
      "Iteration 47527, loss = 19.55915687\n",
      "Iteration 47528, loss = 19.55482127\n",
      "Iteration 47529, loss = 19.55048627\n",
      "Iteration 47530, loss = 19.54615187\n",
      "Iteration 47531, loss = 19.54181806\n",
      "Iteration 47532, loss = 19.53748485\n",
      "Iteration 47533, loss = 19.53315224\n",
      "Iteration 47534, loss = 19.52882022\n",
      "Iteration 47535, loss = 19.52448881\n",
      "Iteration 47536, loss = 19.52015798\n",
      "Iteration 47537, loss = 19.51582776\n",
      "Iteration 47538, loss = 19.51149814\n",
      "Iteration 47539, loss = 19.50716911\n",
      "Iteration 47540, loss = 19.50284067\n",
      "Iteration 47541, loss = 19.49851284\n",
      "Iteration 47542, loss = 19.49418560\n",
      "Iteration 47543, loss = 19.48985896\n",
      "Iteration 47544, loss = 19.48553292\n",
      "Iteration 47545, loss = 19.48120747\n",
      "Iteration 47546, loss = 19.47688262\n",
      "Iteration 47547, loss = 19.47255837\n",
      "Iteration 47548, loss = 19.46823471\n",
      "Iteration 47549, loss = 19.46391166\n",
      "Iteration 47550, loss = 19.45958920\n",
      "Iteration 47551, loss = 19.45526733\n",
      "Iteration 47552, loss = 19.45094606\n",
      "Iteration 47553, loss = 19.44662539\n",
      "Iteration 47554, loss = 19.44230532\n",
      "Iteration 47555, loss = 19.43798584\n",
      "Iteration 47556, loss = 19.43366696\n",
      "Iteration 47557, loss = 19.42934868\n",
      "Iteration 47558, loss = 19.42503100\n",
      "Iteration 47559, loss = 19.42071391\n",
      "Iteration 47560, loss = 19.41639741\n",
      "Iteration 47561, loss = 19.41208152\n",
      "Iteration 47562, loss = 19.40776622\n",
      "Iteration 47563, loss = 19.40345152\n",
      "Iteration 47564, loss = 19.39913741\n",
      "Iteration 47565, loss = 19.39482391\n",
      "Iteration 47566, loss = 19.39051100\n",
      "Iteration 47567, loss = 19.38619868\n",
      "Iteration 47568, loss = 19.38188697\n",
      "Iteration 47569, loss = 19.37757585\n",
      "Iteration 47570, loss = 19.37326532\n",
      "Iteration 47571, loss = 19.36895540\n",
      "Iteration 47572, loss = 19.36464608\n",
      "Iteration 47573, loss = 19.36033736\n",
      "Iteration 47574, loss = 19.35602925\n",
      "Iteration 47575, loss = 19.35172176\n",
      "Iteration 47576, loss = 19.34741491\n",
      "Iteration 47577, loss = 19.34310874\n",
      "Iteration 47578, loss = 19.33880332\n",
      "Iteration 47579, loss = 19.33449880\n",
      "Iteration 47580, loss = 19.33019544\n",
      "Iteration 47581, loss = 19.32589374\n",
      "Iteration 47582, loss = 19.32159469\n",
      "Iteration 47583, loss = 19.31730006\n",
      "Iteration 47584, loss = 19.31301304\n",
      "Iteration 47585, loss = 19.30873864\n",
      "Iteration 47586, loss = 19.30448310\n",
      "Iteration 47587, loss = 19.30024801\n",
      "Iteration 47588, loss = 19.29601616\n",
      "Iteration 47589, loss = 19.29173724\n",
      "Iteration 47590, loss = 19.28736637\n",
      "Iteration 47591, loss = 19.28294614\n",
      "Iteration 47592, loss = 19.27859101\n",
      "Iteration 47593, loss = 19.27433906\n",
      "Iteration 47594, loss = 19.27010863\n",
      "Iteration 47595, loss = 19.26580598\n",
      "Iteration 47596, loss = 19.26144235\n",
      "Iteration 47597, loss = 19.25711370\n",
      "Iteration 47598, loss = 19.25285351\n",
      "Iteration 47599, loss = 19.24859413\n",
      "Iteration 47600, loss = 19.24428019\n",
      "Iteration 47601, loss = 19.23994822\n",
      "Iteration 47602, loss = 19.23565765\n",
      "Iteration 47603, loss = 19.23139492\n",
      "Iteration 47604, loss = 19.22710754\n",
      "Iteration 47605, loss = 19.22279247\n",
      "Iteration 47606, loss = 19.21849236\n",
      "Iteration 47607, loss = 19.21421943\n",
      "Iteration 47608, loss = 19.20994159\n",
      "Iteration 47609, loss = 19.20564182\n",
      "Iteration 47610, loss = 19.20134288\n",
      "Iteration 47611, loss = 19.19706314\n",
      "Iteration 47612, loss = 19.19278761\n",
      "Iteration 47613, loss = 19.18849839\n",
      "Iteration 47614, loss = 19.18420430\n",
      "Iteration 47615, loss = 19.17992170\n",
      "Iteration 47616, loss = 19.17564629\n",
      "Iteration 47617, loss = 19.17136381\n",
      "Iteration 47618, loss = 19.16707525\n",
      "Iteration 47619, loss = 19.16279255\n",
      "Iteration 47620, loss = 19.15851699\n",
      "Iteration 47621, loss = 19.15423886\n",
      "Iteration 47622, loss = 19.14995544\n",
      "Iteration 47623, loss = 19.14567433\n",
      "Iteration 47624, loss = 19.14139902\n",
      "Iteration 47625, loss = 19.13712382\n",
      "Iteration 47626, loss = 19.13284488\n",
      "Iteration 47627, loss = 19.12856627\n",
      "Iteration 47628, loss = 19.12429181\n",
      "Iteration 47629, loss = 19.12001880\n",
      "Iteration 47630, loss = 19.11574365\n",
      "Iteration 47631, loss = 19.11146796\n",
      "Iteration 47632, loss = 19.10719493\n",
      "Iteration 47633, loss = 19.10292379\n",
      "Iteration 47634, loss = 19.09865183\n",
      "Iteration 47635, loss = 19.09437920\n",
      "Iteration 47636, loss = 19.09010807\n",
      "Iteration 47637, loss = 19.08583873\n",
      "Iteration 47638, loss = 19.08156952\n",
      "Iteration 47639, loss = 19.07729988\n",
      "Iteration 47640, loss = 19.07303099\n",
      "Iteration 47641, loss = 19.06876356\n",
      "Iteration 47642, loss = 19.06449680\n",
      "Iteration 47643, loss = 19.06022998\n",
      "Iteration 47644, loss = 19.05596355\n",
      "Iteration 47645, loss = 19.05169818\n",
      "Iteration 47646, loss = 19.04743370\n",
      "Iteration 47647, loss = 19.04316952\n",
      "Iteration 47648, loss = 19.03890565\n",
      "Iteration 47649, loss = 19.03464250\n",
      "Iteration 47650, loss = 19.03038024\n",
      "Iteration 47651, loss = 19.02611855\n",
      "Iteration 47652, loss = 19.02185722\n",
      "Iteration 47653, loss = 19.01759644\n",
      "Iteration 47654, loss = 19.01333643\n",
      "Iteration 47655, loss = 19.00907711\n",
      "Iteration 47656, loss = 19.00481828\n",
      "Iteration 47657, loss = 19.00055992\n",
      "Iteration 47658, loss = 18.99630222\n",
      "Iteration 47659, loss = 18.99204523\n",
      "Iteration 47660, loss = 18.98778883\n",
      "Iteration 47661, loss = 18.98353292\n",
      "Iteration 47662, loss = 18.97927759\n",
      "Iteration 47663, loss = 18.97502292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 47664, loss = 18.97076890\n",
      "Iteration 47665, loss = 18.96651542\n",
      "Iteration 47666, loss = 18.96226249\n",
      "Iteration 47667, loss = 18.95801017\n",
      "Iteration 47668, loss = 18.95375850\n",
      "Iteration 47669, loss = 18.94950742\n",
      "Iteration 47670, loss = 18.94525690\n",
      "Iteration 47671, loss = 18.94100696\n",
      "Iteration 47672, loss = 18.93675765\n",
      "Iteration 47673, loss = 18.93250895\n",
      "Iteration 47674, loss = 18.92826083\n",
      "Iteration 47675, loss = 18.92401328\n",
      "Iteration 47676, loss = 18.91976633\n",
      "Iteration 47677, loss = 18.91552000\n",
      "Iteration 47678, loss = 18.91127426\n",
      "Iteration 47679, loss = 18.90702911\n",
      "Iteration 47680, loss = 18.90278455\n",
      "Iteration 47681, loss = 18.89854058\n",
      "Iteration 47682, loss = 18.89429722\n",
      "Iteration 47683, loss = 18.89005446\n",
      "Iteration 47684, loss = 18.88581228\n",
      "Iteration 47685, loss = 18.88157069\n",
      "Iteration 47686, loss = 18.87732970\n",
      "Iteration 47687, loss = 18.87308932\n",
      "Iteration 47688, loss = 18.86884952\n",
      "Iteration 47689, loss = 18.86461032\n",
      "Iteration 47690, loss = 18.86037171\n",
      "Iteration 47691, loss = 18.85613370\n",
      "Iteration 47692, loss = 18.85189628\n",
      "Iteration 47693, loss = 18.84765946\n",
      "Iteration 47694, loss = 18.84342323\n",
      "Iteration 47695, loss = 18.83918760\n",
      "Iteration 47696, loss = 18.83495256\n",
      "Iteration 47697, loss = 18.83071812\n",
      "Iteration 47698, loss = 18.82648427\n",
      "Iteration 47699, loss = 18.82225101\n",
      "Iteration 47700, loss = 18.81801835\n",
      "Iteration 47701, loss = 18.81378629\n",
      "Iteration 47702, loss = 18.80955482\n",
      "Iteration 47703, loss = 18.80532395\n",
      "Iteration 47704, loss = 18.80109366\n",
      "Iteration 47705, loss = 18.79686398\n",
      "Iteration 47706, loss = 18.79263489\n",
      "Iteration 47707, loss = 18.78840639\n",
      "Iteration 47708, loss = 18.78417849\n",
      "Iteration 47709, loss = 18.77995118\n",
      "Iteration 47710, loss = 18.77572447\n",
      "Iteration 47711, loss = 18.77149835\n",
      "Iteration 47712, loss = 18.76727282\n",
      "Iteration 47713, loss = 18.76304790\n",
      "Iteration 47714, loss = 18.75882356\n",
      "Iteration 47715, loss = 18.75459982\n",
      "Iteration 47716, loss = 18.75037667\n",
      "Iteration 47717, loss = 18.74615412\n",
      "Iteration 47718, loss = 18.74193216\n",
      "Iteration 47719, loss = 18.73771080\n",
      "Iteration 47720, loss = 18.73349003\n",
      "Iteration 47721, loss = 18.72926986\n",
      "Iteration 47722, loss = 18.72505028\n",
      "Iteration 47723, loss = 18.72083129\n",
      "Iteration 47724, loss = 18.71661290\n",
      "Iteration 47725, loss = 18.71239511\n",
      "Iteration 47726, loss = 18.70817790\n",
      "Iteration 47727, loss = 18.70396130\n",
      "Iteration 47728, loss = 18.69974528\n",
      "Iteration 47729, loss = 18.69552986\n",
      "Iteration 47730, loss = 18.69131504\n",
      "Iteration 47731, loss = 18.68710081\n",
      "Iteration 47732, loss = 18.68288717\n",
      "Iteration 47733, loss = 18.67867413\n",
      "Iteration 47734, loss = 18.67446168\n",
      "Iteration 47735, loss = 18.67024983\n",
      "Iteration 47736, loss = 18.66603857\n",
      "Iteration 47737, loss = 18.66182790\n",
      "Iteration 47738, loss = 18.65761783\n",
      "Iteration 47739, loss = 18.65340835\n",
      "Iteration 47740, loss = 18.64919947\n",
      "Iteration 47741, loss = 18.64499118\n",
      "Iteration 47742, loss = 18.64078348\n",
      "Iteration 47743, loss = 18.63657638\n",
      "Iteration 47744, loss = 18.63236988\n",
      "Iteration 47745, loss = 18.62816396\n",
      "Iteration 47746, loss = 18.62395865\n",
      "Iteration 47747, loss = 18.61975392\n",
      "Iteration 47748, loss = 18.61554979\n",
      "Iteration 47749, loss = 18.61134625\n",
      "Iteration 47750, loss = 18.60714331\n",
      "Iteration 47751, loss = 18.60294096\n",
      "Iteration 47752, loss = 18.59873921\n",
      "Iteration 47753, loss = 18.59453805\n",
      "Iteration 47754, loss = 18.59033748\n",
      "Iteration 47755, loss = 18.58613751\n",
      "Iteration 47756, loss = 18.58193813\n",
      "Iteration 47757, loss = 18.57773934\n",
      "Iteration 47758, loss = 18.57354115\n",
      "Iteration 47759, loss = 18.56934356\n",
      "Iteration 47760, loss = 18.56514655\n",
      "Iteration 47761, loss = 18.56095014\n",
      "Iteration 47762, loss = 18.55675433\n",
      "Iteration 47763, loss = 18.55255911\n",
      "Iteration 47764, loss = 18.54836448\n",
      "Iteration 47765, loss = 18.54417044\n",
      "Iteration 47766, loss = 18.53997700\n",
      "Iteration 47767, loss = 18.53578416\n",
      "Iteration 47768, loss = 18.53159190\n",
      "Iteration 47769, loss = 18.52740024\n",
      "Iteration 47770, loss = 18.52320918\n",
      "Iteration 47771, loss = 18.51901871\n",
      "Iteration 47772, loss = 18.51482883\n",
      "Iteration 47773, loss = 18.51063954\n",
      "Iteration 47774, loss = 18.50645085\n",
      "Iteration 47775, loss = 18.50226276\n",
      "Iteration 47776, loss = 18.49807525\n",
      "Iteration 47777, loss = 18.49388834\n",
      "Iteration 47778, loss = 18.48970203\n",
      "Iteration 47779, loss = 18.48551631\n",
      "Iteration 47780, loss = 18.48133118\n",
      "Iteration 47781, loss = 18.47714664\n",
      "Iteration 47782, loss = 18.47296270\n",
      "Iteration 47783, loss = 18.46877935\n",
      "Iteration 47784, loss = 18.46459660\n",
      "Iteration 47785, loss = 18.46041443\n",
      "Iteration 47786, loss = 18.45623287\n",
      "Iteration 47787, loss = 18.45205189\n",
      "Iteration 47788, loss = 18.44787151\n",
      "Iteration 47789, loss = 18.44369172\n",
      "Iteration 47790, loss = 18.43951253\n",
      "Iteration 47791, loss = 18.43533393\n",
      "Iteration 47792, loss = 18.43115592\n",
      "Iteration 47793, loss = 18.42697851\n",
      "Iteration 47794, loss = 18.42280169\n",
      "Iteration 47795, loss = 18.41862546\n",
      "Iteration 47796, loss = 18.41444983\n",
      "Iteration 47797, loss = 18.41027479\n",
      "Iteration 47798, loss = 18.40610034\n",
      "Iteration 47799, loss = 18.40192649\n",
      "Iteration 47800, loss = 18.39775323\n",
      "Iteration 47801, loss = 18.39358056\n",
      "Iteration 47802, loss = 18.38940849\n",
      "Iteration 47803, loss = 18.38523701\n",
      "Iteration 47804, loss = 18.38106612\n",
      "Iteration 47805, loss = 18.37689583\n",
      "Iteration 47806, loss = 18.37272613\n",
      "Iteration 47807, loss = 18.36855702\n",
      "Iteration 47808, loss = 18.36438851\n",
      "Iteration 47809, loss = 18.36022058\n",
      "Iteration 47810, loss = 18.35605326\n",
      "Iteration 47811, loss = 18.35188652\n",
      "Iteration 47812, loss = 18.34772038\n",
      "Iteration 47813, loss = 18.34355483\n",
      "Iteration 47814, loss = 18.33938988\n",
      "Iteration 47815, loss = 18.33522551\n",
      "Iteration 47816, loss = 18.33106175\n",
      "Iteration 47817, loss = 18.32689857\n",
      "Iteration 47818, loss = 18.32273599\n",
      "Iteration 47819, loss = 18.31857400\n",
      "Iteration 47820, loss = 18.31441260\n",
      "Iteration 47821, loss = 18.31025180\n",
      "Iteration 47822, loss = 18.30609159\n",
      "Iteration 47823, loss = 18.30193197\n",
      "Iteration 47824, loss = 18.29777294\n",
      "Iteration 47825, loss = 18.29361451\n",
      "Iteration 47826, loss = 18.28945667\n",
      "Iteration 47827, loss = 18.28529943\n",
      "Iteration 47828, loss = 18.28114277\n",
      "Iteration 47829, loss = 18.27698671\n",
      "Iteration 47830, loss = 18.27283125\n",
      "Iteration 47831, loss = 18.26867637\n",
      "Iteration 47832, loss = 18.26452209\n",
      "Iteration 47833, loss = 18.26036840\n",
      "Iteration 47834, loss = 18.25621531\n",
      "Iteration 47835, loss = 18.25206280\n",
      "Iteration 47836, loss = 18.24791089\n",
      "Iteration 47837, loss = 18.24375958\n",
      "Iteration 47838, loss = 18.23960885\n",
      "Iteration 47839, loss = 18.23545872\n",
      "Iteration 47840, loss = 18.23130918\n",
      "Iteration 47841, loss = 18.22716024\n",
      "Iteration 47842, loss = 18.22301188\n",
      "Iteration 47843, loss = 18.21886412\n",
      "Iteration 47844, loss = 18.21471695\n",
      "Iteration 47845, loss = 18.21057038\n",
      "Iteration 47846, loss = 18.20642439\n",
      "Iteration 47847, loss = 18.20227900\n",
      "Iteration 47848, loss = 18.19813421\n",
      "Iteration 47849, loss = 18.19399000\n",
      "Iteration 47850, loss = 18.18984639\n",
      "Iteration 47851, loss = 18.18570337\n",
      "Iteration 47852, loss = 18.18156094\n",
      "Iteration 47853, loss = 18.17741911\n",
      "Iteration 47854, loss = 18.17327787\n",
      "Iteration 47855, loss = 18.16913722\n",
      "Iteration 47856, loss = 18.16499716\n",
      "Iteration 47857, loss = 18.16085770\n",
      "Iteration 47858, loss = 18.15671883\n",
      "Iteration 47859, loss = 18.15258055\n",
      "Iteration 47860, loss = 18.14844286\n",
      "Iteration 47861, loss = 18.14430577\n",
      "Iteration 47862, loss = 18.14016926\n",
      "Iteration 47863, loss = 18.13603336\n",
      "Iteration 47864, loss = 18.13189804\n",
      "Iteration 47865, loss = 18.12776331\n",
      "Iteration 47866, loss = 18.12362918\n",
      "Iteration 47867, loss = 18.11949564\n",
      "Iteration 47868, loss = 18.11536270\n",
      "Iteration 47869, loss = 18.11123034\n",
      "Iteration 47870, loss = 18.10709858\n",
      "Iteration 47871, loss = 18.10296741\n",
      "Iteration 47872, loss = 18.09883683\n",
      "Iteration 47873, loss = 18.09470684\n",
      "Iteration 47874, loss = 18.09057745\n",
      "Iteration 47875, loss = 18.08644865\n",
      "Iteration 47876, loss = 18.08232044\n",
      "Iteration 47877, loss = 18.07819282\n",
      "Iteration 47878, loss = 18.07406580\n",
      "Iteration 47879, loss = 18.06993937\n",
      "Iteration 47880, loss = 18.06581353\n",
      "Iteration 47881, loss = 18.06168828\n",
      "Iteration 47882, loss = 18.05756362\n",
      "Iteration 47883, loss = 18.05343956\n",
      "Iteration 47884, loss = 18.04931609\n",
      "Iteration 47885, loss = 18.04519321\n",
      "Iteration 47886, loss = 18.04107092\n",
      "Iteration 47887, loss = 18.03694923\n",
      "Iteration 47888, loss = 18.03282813\n",
      "Iteration 47889, loss = 18.02870762\n",
      "Iteration 47890, loss = 18.02458770\n",
      "Iteration 47891, loss = 18.02046837\n",
      "Iteration 47892, loss = 18.01634964\n",
      "Iteration 47893, loss = 18.01223149\n",
      "Iteration 47894, loss = 18.00811394\n",
      "Iteration 47895, loss = 18.00399698\n",
      "Iteration 47896, loss = 17.99988062\n",
      "Iteration 47897, loss = 17.99576484\n",
      "Iteration 47898, loss = 17.99164966\n",
      "Iteration 47899, loss = 17.98753507\n",
      "Iteration 47900, loss = 17.98342107\n",
      "Iteration 47901, loss = 17.97930766\n",
      "Iteration 47902, loss = 17.97519485\n",
      "Iteration 47903, loss = 17.97108263\n",
      "Iteration 47904, loss = 17.96697099\n",
      "Iteration 47905, loss = 17.96285995\n",
      "Iteration 47906, loss = 17.95874951\n",
      "Iteration 47907, loss = 17.95463965\n",
      "Iteration 47908, loss = 17.95053039\n",
      "Iteration 47909, loss = 17.94642172\n",
      "Iteration 47910, loss = 17.94231364\n",
      "Iteration 47911, loss = 17.93820615\n",
      "Iteration 47912, loss = 17.93409925\n",
      "Iteration 47913, loss = 17.92999295\n",
      "Iteration 47914, loss = 17.92588723\n",
      "Iteration 47915, loss = 17.92178211\n",
      "Iteration 47916, loss = 17.91767758\n",
      "Iteration 47917, loss = 17.91357364\n",
      "Iteration 47918, loss = 17.90947030\n",
      "Iteration 47919, loss = 17.90536754\n",
      "Iteration 47920, loss = 17.90126538\n",
      "Iteration 47921, loss = 17.89716381\n",
      "Iteration 47922, loss = 17.89306283\n",
      "Iteration 47923, loss = 17.88896244\n",
      "Iteration 47924, loss = 17.88486264\n",
      "Iteration 47925, loss = 17.88076344\n",
      "Iteration 47926, loss = 17.87666482\n",
      "Iteration 47927, loss = 17.87256680\n",
      "Iteration 47928, loss = 17.86846937\n",
      "Iteration 47929, loss = 17.86437253\n",
      "Iteration 47930, loss = 17.86027628\n",
      "Iteration 47931, loss = 17.85618063\n",
      "Iteration 47932, loss = 17.85208556\n",
      "Iteration 47933, loss = 17.84799109\n",
      "Iteration 47934, loss = 17.84389721\n",
      "Iteration 47935, loss = 17.83980392\n",
      "Iteration 47936, loss = 17.83571122\n",
      "Iteration 47937, loss = 17.83161911\n",
      "Iteration 47938, loss = 17.82752759\n",
      "Iteration 47939, loss = 17.82343667\n",
      "Iteration 47940, loss = 17.81934634\n",
      "Iteration 47941, loss = 17.81525659\n",
      "Iteration 47942, loss = 17.81116744\n",
      "Iteration 47943, loss = 17.80707888\n",
      "Iteration 47944, loss = 17.80299092\n",
      "Iteration 47945, loss = 17.79890354\n",
      "Iteration 47946, loss = 17.79481675\n",
      "Iteration 47947, loss = 17.79073056\n",
      "Iteration 47948, loss = 17.78664496\n",
      "Iteration 47949, loss = 17.78255994\n",
      "Iteration 47950, loss = 17.77847552\n",
      "Iteration 47951, loss = 17.77439169\n",
      "Iteration 47952, loss = 17.77030846\n",
      "Iteration 47953, loss = 17.76622581\n",
      "Iteration 47954, loss = 17.76214375\n",
      "Iteration 47955, loss = 17.75806229\n",
      "Iteration 47956, loss = 17.75398142\n",
      "Iteration 47957, loss = 17.74990113\n",
      "Iteration 47958, loss = 17.74582144\n",
      "Iteration 47959, loss = 17.74174234\n",
      "Iteration 47960, loss = 17.73766383\n",
      "Iteration 47961, loss = 17.73358592\n",
      "Iteration 47962, loss = 17.72950859\n",
      "Iteration 47963, loss = 17.72543185\n",
      "Iteration 47964, loss = 17.72135571\n",
      "Iteration 47965, loss = 17.71728015\n",
      "Iteration 47966, loss = 17.71320519\n",
      "Iteration 47967, loss = 17.70913082\n",
      "Iteration 47968, loss = 17.70505704\n",
      "Iteration 47969, loss = 17.70098385\n",
      "Iteration 47970, loss = 17.69691126\n",
      "Iteration 47971, loss = 17.69283925\n",
      "Iteration 47972, loss = 17.68876785\n",
      "Iteration 47973, loss = 17.68469704\n",
      "Iteration 47974, loss = 17.68062685\n",
      "Iteration 47975, loss = 17.67655728\n",
      "Iteration 47976, loss = 17.67248836\n",
      "Iteration 47977, loss = 17.66842017\n",
      "Iteration 47978, loss = 17.66435281\n",
      "Iteration 47979, loss = 17.66028651\n",
      "Iteration 47980, loss = 17.65622171\n",
      "Iteration 47981, loss = 17.65215925\n",
      "Iteration 47982, loss = 17.64810074\n",
      "Iteration 47983, loss = 17.64404910\n",
      "Iteration 47984, loss = 17.64000925\n",
      "Iteration 47985, loss = 17.63598804\n",
      "Iteration 47986, loss = 17.63198995\n",
      "Iteration 47987, loss = 17.62800371\n",
      "Iteration 47988, loss = 17.62398204\n",
      "Iteration 47989, loss = 17.61986572\n",
      "Iteration 47990, loss = 17.61567478\n",
      "Iteration 47991, loss = 17.61153210\n",
      "Iteration 47992, loss = 17.60750590\n",
      "Iteration 47993, loss = 17.60352257\n",
      "Iteration 47994, loss = 17.59946942\n",
      "Iteration 47995, loss = 17.59534003\n",
      "Iteration 47996, loss = 17.59123853\n",
      "Iteration 47997, loss = 17.58721460\n",
      "Iteration 47998, loss = 17.58319781\n",
      "Iteration 47999, loss = 17.57912127\n",
      "Iteration 48000, loss = 17.57502244\n",
      "Iteration 48001, loss = 17.57096917\n",
      "Iteration 48002, loss = 17.56694623\n",
      "Iteration 48003, loss = 17.56289453\n",
      "Iteration 48004, loss = 17.55881366\n",
      "Iteration 48005, loss = 17.55475227\n",
      "Iteration 48006, loss = 17.55071933\n",
      "Iteration 48007, loss = 17.54667664\n",
      "Iteration 48008, loss = 17.54261060\n",
      "Iteration 48009, loss = 17.53855033\n",
      "Iteration 48010, loss = 17.53451111\n",
      "Iteration 48011, loss = 17.53047135\n",
      "Iteration 48012, loss = 17.52641555\n",
      "Iteration 48013, loss = 17.52235928\n",
      "Iteration 48014, loss = 17.51831728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48015, loss = 17.51427862\n",
      "Iteration 48016, loss = 17.51022975\n",
      "Iteration 48017, loss = 17.50617804\n",
      "Iteration 48018, loss = 17.50213556\n",
      "Iteration 48019, loss = 17.49809762\n",
      "Iteration 48020, loss = 17.49405365\n",
      "Iteration 48021, loss = 17.49000633\n",
      "Iteration 48022, loss = 17.48596475\n",
      "Iteration 48023, loss = 17.48192765\n",
      "Iteration 48024, loss = 17.47788734\n",
      "Iteration 48025, loss = 17.47384406\n",
      "Iteration 48026, loss = 17.46980418\n",
      "Iteration 48027, loss = 17.46576817\n",
      "Iteration 48028, loss = 17.46173082\n",
      "Iteration 48029, loss = 17.45769121\n",
      "Iteration 48030, loss = 17.45365349\n",
      "Iteration 48031, loss = 17.44961885\n",
      "Iteration 48032, loss = 17.44558405\n",
      "Iteration 48033, loss = 17.44154777\n",
      "Iteration 48034, loss = 17.43751246\n",
      "Iteration 48035, loss = 17.43347946\n",
      "Iteration 48036, loss = 17.42944698\n",
      "Iteration 48037, loss = 17.42541374\n",
      "Iteration 48038, loss = 17.42138096\n",
      "Iteration 48039, loss = 17.41734983\n",
      "Iteration 48040, loss = 17.41331956\n",
      "Iteration 48041, loss = 17.40928911\n",
      "Iteration 48042, loss = 17.40525891\n",
      "Iteration 48043, loss = 17.40122985\n",
      "Iteration 48044, loss = 17.39720175\n",
      "Iteration 48045, loss = 17.39317390\n",
      "Iteration 48046, loss = 17.38914628\n",
      "Iteration 48047, loss = 17.38511943\n",
      "Iteration 48048, loss = 17.38109353\n",
      "Iteration 48049, loss = 17.37706813\n",
      "Iteration 48050, loss = 17.37304304\n",
      "Iteration 48051, loss = 17.36901853\n",
      "Iteration 48052, loss = 17.36499484\n",
      "Iteration 48053, loss = 17.36097182\n",
      "Iteration 48054, loss = 17.35694921\n",
      "Iteration 48055, loss = 17.35292708\n",
      "Iteration 48056, loss = 17.34890567\n",
      "Iteration 48057, loss = 17.34488497\n",
      "Iteration 48058, loss = 17.34086478\n",
      "Iteration 48059, loss = 17.33684507\n",
      "Iteration 48060, loss = 17.33282598\n",
      "Iteration 48061, loss = 17.32880758\n",
      "Iteration 48062, loss = 17.32478978\n",
      "Iteration 48063, loss = 17.32077247\n",
      "Iteration 48064, loss = 17.31675574\n",
      "Iteration 48065, loss = 17.31273966\n",
      "Iteration 48066, loss = 17.30872420\n",
      "Iteration 48067, loss = 17.30470929\n",
      "Iteration 48068, loss = 17.30069493\n",
      "Iteration 48069, loss = 17.29668119\n",
      "Iteration 48070, loss = 17.29266807\n",
      "Iteration 48071, loss = 17.28865553\n",
      "Iteration 48072, loss = 17.28464355\n",
      "Iteration 48073, loss = 17.28063216\n",
      "Iteration 48074, loss = 17.27662137\n",
      "Iteration 48075, loss = 17.27261119\n",
      "Iteration 48076, loss = 17.26860159\n",
      "Iteration 48077, loss = 17.26459255\n",
      "Iteration 48078, loss = 17.26058412\n",
      "Iteration 48079, loss = 17.25657629\n",
      "Iteration 48080, loss = 17.25256904\n",
      "Iteration 48081, loss = 17.24856238\n",
      "Iteration 48082, loss = 17.24455630\n",
      "Iteration 48083, loss = 17.24055081\n",
      "Iteration 48084, loss = 17.23654592\n",
      "Iteration 48085, loss = 17.23254162\n",
      "Iteration 48086, loss = 17.22853790\n",
      "Iteration 48087, loss = 17.22453477\n",
      "Iteration 48088, loss = 17.22053223\n",
      "Iteration 48089, loss = 17.21653028\n",
      "Iteration 48090, loss = 17.21252892\n",
      "Iteration 48091, loss = 17.20852814\n",
      "Iteration 48092, loss = 17.20452796\n",
      "Iteration 48093, loss = 17.20052837\n",
      "Iteration 48094, loss = 17.19652936\n",
      "Iteration 48095, loss = 17.19253094\n",
      "Iteration 48096, loss = 17.18853311\n",
      "Iteration 48097, loss = 17.18453587\n",
      "Iteration 48098, loss = 17.18053923\n",
      "Iteration 48099, loss = 17.17654316\n",
      "Iteration 48100, loss = 17.17254769\n",
      "Iteration 48101, loss = 17.16855280\n",
      "Iteration 48102, loss = 17.16455851\n",
      "Iteration 48103, loss = 17.16056480\n",
      "Iteration 48104, loss = 17.15657168\n",
      "Iteration 48105, loss = 17.15257915\n",
      "Iteration 48106, loss = 17.14858721\n",
      "Iteration 48107, loss = 17.14459586\n",
      "Iteration 48108, loss = 17.14060510\n",
      "Iteration 48109, loss = 17.13661492\n",
      "Iteration 48110, loss = 17.13262534\n",
      "Iteration 48111, loss = 17.12863634\n",
      "Iteration 48112, loss = 17.12464793\n",
      "Iteration 48113, loss = 17.12066011\n",
      "Iteration 48114, loss = 17.11667288\n",
      "Iteration 48115, loss = 17.11268623\n",
      "Iteration 48116, loss = 17.10870018\n",
      "Iteration 48117, loss = 17.10471471\n",
      "Iteration 48118, loss = 17.10072983\n",
      "Iteration 48119, loss = 17.09674554\n",
      "Iteration 48120, loss = 17.09276184\n",
      "Iteration 48121, loss = 17.08877873\n",
      "Iteration 48122, loss = 17.08479620\n",
      "Iteration 48123, loss = 17.08081427\n",
      "Iteration 48124, loss = 17.07683292\n",
      "Iteration 48125, loss = 17.07285216\n",
      "Iteration 48126, loss = 17.06887199\n",
      "Iteration 48127, loss = 17.06489241\n",
      "Iteration 48128, loss = 17.06091341\n",
      "Iteration 48129, loss = 17.05693501\n",
      "Iteration 48130, loss = 17.05295719\n",
      "Iteration 48131, loss = 17.04897996\n",
      "Iteration 48132, loss = 17.04500332\n",
      "Iteration 48133, loss = 17.04102727\n",
      "Iteration 48134, loss = 17.03705180\n",
      "Iteration 48135, loss = 17.03307692\n",
      "Iteration 48136, loss = 17.02910264\n",
      "Iteration 48137, loss = 17.02512894\n",
      "Iteration 48138, loss = 17.02115582\n",
      "Iteration 48139, loss = 17.01718330\n",
      "Iteration 48140, loss = 17.01321137\n",
      "Iteration 48141, loss = 17.00924002\n",
      "Iteration 48142, loss = 17.00526926\n",
      "Iteration 48143, loss = 17.00129909\n",
      "Iteration 48144, loss = 16.99732950\n",
      "Iteration 48145, loss = 16.99336051\n",
      "Iteration 48146, loss = 16.98939210\n",
      "Iteration 48147, loss = 16.98542428\n",
      "Iteration 48148, loss = 16.98145705\n",
      "Iteration 48149, loss = 16.97749041\n",
      "Iteration 48150, loss = 16.97352436\n",
      "Iteration 48151, loss = 16.96955889\n",
      "Iteration 48152, loss = 16.96559401\n",
      "Iteration 48153, loss = 16.96162972\n",
      "Iteration 48154, loss = 16.95766602\n",
      "Iteration 48155, loss = 16.95370290\n",
      "Iteration 48156, loss = 16.94974038\n",
      "Iteration 48157, loss = 16.94577844\n",
      "Iteration 48158, loss = 16.94181709\n",
      "Iteration 48159, loss = 16.93785632\n",
      "Iteration 48160, loss = 16.93389615\n",
      "Iteration 48161, loss = 16.92993656\n",
      "Iteration 48162, loss = 16.92597756\n",
      "Iteration 48163, loss = 16.92201915\n",
      "Iteration 48164, loss = 16.91806132\n",
      "Iteration 48165, loss = 16.91410409\n",
      "Iteration 48166, loss = 16.91014744\n",
      "Iteration 48167, loss = 16.90619138\n",
      "Iteration 48168, loss = 16.90223590\n",
      "Iteration 48169, loss = 16.89828102\n",
      "Iteration 48170, loss = 16.89432672\n",
      "Iteration 48171, loss = 16.89037301\n",
      "Iteration 48172, loss = 16.88641989\n",
      "Iteration 48173, loss = 16.88246736\n",
      "Iteration 48174, loss = 16.87851541\n",
      "Iteration 48175, loss = 16.87456405\n",
      "Iteration 48176, loss = 16.87061328\n",
      "Iteration 48177, loss = 16.86666309\n",
      "Iteration 48178, loss = 16.86271350\n",
      "Iteration 48179, loss = 16.85876449\n",
      "Iteration 48180, loss = 16.85481607\n",
      "Iteration 48181, loss = 16.85086823\n",
      "Iteration 48182, loss = 16.84692099\n",
      "Iteration 48183, loss = 16.84297433\n",
      "Iteration 48184, loss = 16.83902826\n",
      "Iteration 48185, loss = 16.83508277\n",
      "Iteration 48186, loss = 16.83113788\n",
      "Iteration 48187, loss = 16.82719357\n",
      "Iteration 48188, loss = 16.82324985\n",
      "Iteration 48189, loss = 16.81930671\n",
      "Iteration 48190, loss = 16.81536417\n",
      "Iteration 48191, loss = 16.81142221\n",
      "Iteration 48192, loss = 16.80748084\n",
      "Iteration 48193, loss = 16.80354005\n",
      "Iteration 48194, loss = 16.79959986\n",
      "Iteration 48195, loss = 16.79566025\n",
      "Iteration 48196, loss = 16.79172123\n",
      "Iteration 48197, loss = 16.78778279\n",
      "Iteration 48198, loss = 16.78384494\n",
      "Iteration 48199, loss = 16.77990768\n",
      "Iteration 48200, loss = 16.77597101\n",
      "Iteration 48201, loss = 16.77203492\n",
      "Iteration 48202, loss = 16.76809943\n",
      "Iteration 48203, loss = 16.76416451\n",
      "Iteration 48204, loss = 16.76023019\n",
      "Iteration 48205, loss = 16.75629645\n",
      "Iteration 48206, loss = 16.75236330\n",
      "Iteration 48207, loss = 16.74843074\n",
      "Iteration 48208, loss = 16.74449877\n",
      "Iteration 48209, loss = 16.74056738\n",
      "Iteration 48210, loss = 16.73663658\n",
      "Iteration 48211, loss = 16.73270636\n",
      "Iteration 48212, loss = 16.72877674\n",
      "Iteration 48213, loss = 16.72484770\n",
      "Iteration 48214, loss = 16.72091924\n",
      "Iteration 48215, loss = 16.71699138\n",
      "Iteration 48216, loss = 16.71306410\n",
      "Iteration 48217, loss = 16.70913741\n",
      "Iteration 48218, loss = 16.70521130\n",
      "Iteration 48219, loss = 16.70128579\n",
      "Iteration 48220, loss = 16.69736086\n",
      "Iteration 48221, loss = 16.69343651\n",
      "Iteration 48222, loss = 16.68951276\n",
      "Iteration 48223, loss = 16.68558959\n",
      "Iteration 48224, loss = 16.68166700\n",
      "Iteration 48225, loss = 16.67774501\n",
      "Iteration 48226, loss = 16.67382360\n",
      "Iteration 48227, loss = 16.66990278\n",
      "Iteration 48228, loss = 16.66598254\n",
      "Iteration 48229, loss = 16.66206289\n",
      "Iteration 48230, loss = 16.65814383\n",
      "Iteration 48231, loss = 16.65422536\n",
      "Iteration 48232, loss = 16.65030747\n",
      "Iteration 48233, loss = 16.64639017\n",
      "Iteration 48234, loss = 16.64247345\n",
      "Iteration 48235, loss = 16.63855733\n",
      "Iteration 48236, loss = 16.63464178\n",
      "Iteration 48237, loss = 16.63072683\n",
      "Iteration 48238, loss = 16.62681246\n",
      "Iteration 48239, loss = 16.62289868\n",
      "Iteration 48240, loss = 16.61898549\n",
      "Iteration 48241, loss = 16.61507288\n",
      "Iteration 48242, loss = 16.61116086\n",
      "Iteration 48243, loss = 16.60724943\n",
      "Iteration 48244, loss = 16.60333858\n",
      "Iteration 48245, loss = 16.59942832\n",
      "Iteration 48246, loss = 16.59551864\n",
      "Iteration 48247, loss = 16.59160955\n",
      "Iteration 48248, loss = 16.58770105\n",
      "Iteration 48249, loss = 16.58379314\n",
      "Iteration 48250, loss = 16.57988581\n",
      "Iteration 48251, loss = 16.57597907\n",
      "Iteration 48252, loss = 16.57207291\n",
      "Iteration 48253, loss = 16.56816735\n",
      "Iteration 48254, loss = 16.56426236\n",
      "Iteration 48255, loss = 16.56035797\n",
      "Iteration 48256, loss = 16.55645416\n",
      "Iteration 48257, loss = 16.55255094\n",
      "Iteration 48258, loss = 16.54864830\n",
      "Iteration 48259, loss = 16.54474625\n",
      "Iteration 48260, loss = 16.54084479\n",
      "Iteration 48261, loss = 16.53694391\n",
      "Iteration 48262, loss = 16.53304362\n",
      "Iteration 48263, loss = 16.52914391\n",
      "Iteration 48264, loss = 16.52524479\n",
      "Iteration 48265, loss = 16.52134626\n",
      "Iteration 48266, loss = 16.51744832\n",
      "Iteration 48267, loss = 16.51355096\n",
      "Iteration 48268, loss = 16.50965418\n",
      "Iteration 48269, loss = 16.50575800\n",
      "Iteration 48270, loss = 16.50186240\n",
      "Iteration 48271, loss = 16.49796738\n",
      "Iteration 48272, loss = 16.49407296\n",
      "Iteration 48273, loss = 16.49017911\n",
      "Iteration 48274, loss = 16.48628586\n",
      "Iteration 48275, loss = 16.48239319\n",
      "Iteration 48276, loss = 16.47850110\n",
      "Iteration 48277, loss = 16.47460961\n",
      "Iteration 48278, loss = 16.47071870\n",
      "Iteration 48279, loss = 16.46682837\n",
      "Iteration 48280, loss = 16.46293863\n",
      "Iteration 48281, loss = 16.45904948\n",
      "Iteration 48282, loss = 16.45516091\n",
      "Iteration 48283, loss = 16.45127293\n",
      "Iteration 48284, loss = 16.44738554\n",
      "Iteration 48285, loss = 16.44349873\n",
      "Iteration 48286, loss = 16.43961250\n",
      "Iteration 48287, loss = 16.43572687\n",
      "Iteration 48288, loss = 16.43184182\n",
      "Iteration 48289, loss = 16.42795735\n",
      "Iteration 48290, loss = 16.42407347\n",
      "Iteration 48291, loss = 16.42019018\n",
      "Iteration 48292, loss = 16.41630747\n",
      "Iteration 48293, loss = 16.41242535\n",
      "Iteration 48294, loss = 16.40854381\n",
      "Iteration 48295, loss = 16.40466287\n",
      "Iteration 48296, loss = 16.40078250\n",
      "Iteration 48297, loss = 16.39690272\n",
      "Iteration 48298, loss = 16.39302353\n",
      "Iteration 48299, loss = 16.38914493\n",
      "Iteration 48300, loss = 16.38526690\n",
      "Iteration 48301, loss = 16.38138947\n",
      "Iteration 48302, loss = 16.37751262\n",
      "Iteration 48303, loss = 16.37363636\n",
      "Iteration 48304, loss = 16.36976068\n",
      "Iteration 48305, loss = 16.36588559\n",
      "Iteration 48306, loss = 16.36201108\n",
      "Iteration 48307, loss = 16.35813716\n",
      "Iteration 48308, loss = 16.35426383\n",
      "Iteration 48309, loss = 16.35039108\n",
      "Iteration 48310, loss = 16.34651891\n",
      "Iteration 48311, loss = 16.34264734\n",
      "Iteration 48312, loss = 16.33877634\n",
      "Iteration 48313, loss = 16.33490594\n",
      "Iteration 48314, loss = 16.33103612\n",
      "Iteration 48315, loss = 16.32716688\n",
      "Iteration 48316, loss = 16.32329823\n",
      "Iteration 48317, loss = 16.31943017\n",
      "Iteration 48318, loss = 16.31556269\n",
      "Iteration 48319, loss = 16.31169579\n",
      "Iteration 48320, loss = 16.30782949\n",
      "Iteration 48321, loss = 16.30396376\n",
      "Iteration 48322, loss = 16.30009863\n",
      "Iteration 48323, loss = 16.29623407\n",
      "Iteration 48324, loss = 16.29237011\n",
      "Iteration 48325, loss = 16.28850673\n",
      "Iteration 48326, loss = 16.28464393\n",
      "Iteration 48327, loss = 16.28078172\n",
      "Iteration 48328, loss = 16.27692010\n",
      "Iteration 48329, loss = 16.27305906\n",
      "Iteration 48330, loss = 16.26919860\n",
      "Iteration 48331, loss = 16.26533873\n",
      "Iteration 48332, loss = 16.26147945\n",
      "Iteration 48333, loss = 16.25762075\n",
      "Iteration 48334, loss = 16.25376264\n",
      "Iteration 48335, loss = 16.24990511\n",
      "Iteration 48336, loss = 16.24604817\n",
      "Iteration 48337, loss = 16.24219181\n",
      "Iteration 48338, loss = 16.23833604\n",
      "Iteration 48339, loss = 16.23448085\n",
      "Iteration 48340, loss = 16.23062625\n",
      "Iteration 48341, loss = 16.22677224\n",
      "Iteration 48342, loss = 16.22291880\n",
      "Iteration 48343, loss = 16.21906596\n",
      "Iteration 48344, loss = 16.21521370\n",
      "Iteration 48345, loss = 16.21136202\n",
      "Iteration 48346, loss = 16.20751093\n",
      "Iteration 48347, loss = 16.20366043\n",
      "Iteration 48348, loss = 16.19981050\n",
      "Iteration 48349, loss = 16.19596117\n",
      "Iteration 48350, loss = 16.19211242\n",
      "Iteration 48351, loss = 16.18826425\n",
      "Iteration 48352, loss = 16.18441667\n",
      "Iteration 48353, loss = 16.18056968\n",
      "Iteration 48354, loss = 16.17672327\n",
      "Iteration 48355, loss = 16.17287744\n",
      "Iteration 48356, loss = 16.16903220\n",
      "Iteration 48357, loss = 16.16518754\n",
      "Iteration 48358, loss = 16.16134347\n",
      "Iteration 48359, loss = 16.15749999\n",
      "Iteration 48360, loss = 16.15365709\n",
      "Iteration 48361, loss = 16.14981477\n",
      "Iteration 48362, loss = 16.14597304\n",
      "Iteration 48363, loss = 16.14213189\n",
      "Iteration 48364, loss = 16.13829133\n",
      "Iteration 48365, loss = 16.13445135\n",
      "Iteration 48366, loss = 16.13061196\n",
      "Iteration 48367, loss = 16.12677315\n",
      "Iteration 48368, loss = 16.12293493\n",
      "Iteration 48369, loss = 16.11909729\n",
      "Iteration 48370, loss = 16.11526024\n",
      "Iteration 48371, loss = 16.11142377\n",
      "Iteration 48372, loss = 16.10758789\n",
      "Iteration 48373, loss = 16.10375259\n",
      "Iteration 48374, loss = 16.09991787\n",
      "Iteration 48375, loss = 16.09608374\n",
      "Iteration 48376, loss = 16.09225020\n",
      "Iteration 48377, loss = 16.08841724\n",
      "Iteration 48378, loss = 16.08458486\n",
      "Iteration 48379, loss = 16.08075307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48380, loss = 16.07692186\n",
      "Iteration 48381, loss = 16.07309124\n",
      "Iteration 48382, loss = 16.06926121\n",
      "Iteration 48383, loss = 16.06543176\n",
      "Iteration 48384, loss = 16.06160290\n",
      "Iteration 48385, loss = 16.05777463\n",
      "Iteration 48386, loss = 16.05394697\n",
      "Iteration 48387, loss = 16.05011991\n",
      "Iteration 48388, loss = 16.04629350\n",
      "Iteration 48389, loss = 16.04246777\n",
      "Iteration 48390, loss = 16.03864283\n",
      "Iteration 48391, loss = 16.03481886\n",
      "Iteration 48392, loss = 16.03099622\n",
      "Iteration 48393, loss = 16.02717562\n",
      "Iteration 48394, loss = 16.02335839\n",
      "Iteration 48395, loss = 16.01954700\n",
      "Iteration 48396, loss = 16.01574577\n",
      "Iteration 48397, loss = 16.01196122\n",
      "Iteration 48398, loss = 16.00819948\n",
      "Iteration 48399, loss = 16.00445618\n",
      "Iteration 48400, loss = 16.00069506\n",
      "Iteration 48401, loss = 15.99685261\n",
      "Iteration 48402, loss = 15.99291484\n",
      "Iteration 48403, loss = 15.98898684\n",
      "Iteration 48404, loss = 15.98517143\n",
      "Iteration 48405, loss = 15.98143198\n",
      "Iteration 48406, loss = 15.97764902\n",
      "Iteration 48407, loss = 15.97377526\n",
      "Iteration 48408, loss = 15.96989732\n",
      "Iteration 48409, loss = 15.96609731\n",
      "Iteration 48410, loss = 15.96233138\n",
      "Iteration 48411, loss = 15.95851492\n",
      "Iteration 48412, loss = 15.95465612\n",
      "Iteration 48413, loss = 15.95082992\n",
      "Iteration 48414, loss = 15.94704754\n",
      "Iteration 48415, loss = 15.94324996\n",
      "Iteration 48416, loss = 15.93941502\n",
      "Iteration 48417, loss = 15.93558690\n",
      "Iteration 48418, loss = 15.93179179\n",
      "Iteration 48419, loss = 15.92799789\n",
      "Iteration 48420, loss = 15.92417865\n",
      "Iteration 48421, loss = 15.92035599\n",
      "Iteration 48422, loss = 15.91655475\n",
      "Iteration 48423, loss = 15.91276045\n",
      "Iteration 48424, loss = 15.90895078\n",
      "Iteration 48425, loss = 15.90513462\n",
      "Iteration 48426, loss = 15.90133150\n",
      "Iteration 48427, loss = 15.89753644\n",
      "Iteration 48428, loss = 15.89373272\n",
      "Iteration 48429, loss = 15.88992245\n",
      "Iteration 48430, loss = 15.88611977\n",
      "Iteration 48431, loss = 15.88232447\n",
      "Iteration 48432, loss = 15.87852474\n",
      "Iteration 48433, loss = 15.87471952\n",
      "Iteration 48434, loss = 15.87091852\n",
      "Iteration 48435, loss = 15.86712358\n",
      "Iteration 48436, loss = 15.86332679\n",
      "Iteration 48437, loss = 15.85952589\n",
      "Iteration 48438, loss = 15.85572718\n",
      "Iteration 48439, loss = 15.85193312\n",
      "Iteration 48440, loss = 15.84813875\n",
      "Iteration 48441, loss = 15.84434160\n",
      "Iteration 48442, loss = 15.84054547\n",
      "Iteration 48443, loss = 15.83675271\n",
      "Iteration 48444, loss = 15.83296050\n",
      "Iteration 48445, loss = 15.82916666\n",
      "Iteration 48446, loss = 15.82537321\n",
      "Iteration 48447, loss = 15.82158209\n",
      "Iteration 48448, loss = 15.81779194\n",
      "Iteration 48449, loss = 15.81400107\n",
      "Iteration 48450, loss = 15.81021031\n",
      "Iteration 48451, loss = 15.80642109\n",
      "Iteration 48452, loss = 15.80263299\n",
      "Iteration 48453, loss = 15.79884483\n",
      "Iteration 48454, loss = 15.79505672\n",
      "Iteration 48455, loss = 15.79126962\n",
      "Iteration 48456, loss = 15.78748359\n",
      "Iteration 48457, loss = 15.78369794\n",
      "Iteration 48458, loss = 15.77991242\n",
      "Iteration 48459, loss = 15.77612757\n",
      "Iteration 48460, loss = 15.77234369\n",
      "Iteration 48461, loss = 15.76856041\n",
      "Iteration 48462, loss = 15.76477742\n",
      "Iteration 48463, loss = 15.76099491\n",
      "Iteration 48464, loss = 15.75721322\n",
      "Iteration 48465, loss = 15.75343225\n",
      "Iteration 48466, loss = 15.74965171\n",
      "Iteration 48467, loss = 15.74587159\n",
      "Iteration 48468, loss = 15.74209216\n",
      "Iteration 48469, loss = 15.73831347\n",
      "Iteration 48470, loss = 15.73453531\n",
      "Iteration 48471, loss = 15.73075759\n",
      "Iteration 48472, loss = 15.72698047\n",
      "Iteration 48473, loss = 15.72320405\n",
      "Iteration 48474, loss = 15.71942823\n",
      "Iteration 48475, loss = 15.71565290\n",
      "Iteration 48476, loss = 15.71187813\n",
      "Iteration 48477, loss = 15.70810399\n",
      "Iteration 48478, loss = 15.70433049\n",
      "Iteration 48479, loss = 15.70055753\n",
      "Iteration 48480, loss = 15.69678510\n",
      "Iteration 48481, loss = 15.69301328\n",
      "Iteration 48482, loss = 15.68924208\n",
      "Iteration 48483, loss = 15.68547147\n",
      "Iteration 48484, loss = 15.68170140\n",
      "Iteration 48485, loss = 15.67793191\n",
      "Iteration 48486, loss = 15.67416302\n",
      "Iteration 48487, loss = 15.67039473\n",
      "Iteration 48488, loss = 15.66662701\n",
      "Iteration 48489, loss = 15.66285985\n",
      "Iteration 48490, loss = 15.65909329\n",
      "Iteration 48491, loss = 15.65532732\n",
      "Iteration 48492, loss = 15.65156193\n",
      "Iteration 48493, loss = 15.64779712\n",
      "Iteration 48494, loss = 15.64403288\n",
      "Iteration 48495, loss = 15.64026924\n",
      "Iteration 48496, loss = 15.63650618\n",
      "Iteration 48497, loss = 15.63274370\n",
      "Iteration 48498, loss = 15.62898180\n",
      "Iteration 48499, loss = 15.62522048\n",
      "Iteration 48500, loss = 15.62145975\n",
      "Iteration 48501, loss = 15.61769960\n",
      "Iteration 48502, loss = 15.61394003\n",
      "Iteration 48503, loss = 15.61018104\n",
      "Iteration 48504, loss = 15.60642263\n",
      "Iteration 48505, loss = 15.60266481\n",
      "Iteration 48506, loss = 15.59890758\n",
      "Iteration 48507, loss = 15.59515092\n",
      "Iteration 48508, loss = 15.59139484\n",
      "Iteration 48509, loss = 15.58763935\n",
      "Iteration 48510, loss = 15.58388444\n",
      "Iteration 48511, loss = 15.58013011\n",
      "Iteration 48512, loss = 15.57637636\n",
      "Iteration 48513, loss = 15.57262320\n",
      "Iteration 48514, loss = 15.56887062\n",
      "Iteration 48515, loss = 15.56511862\n",
      "Iteration 48516, loss = 15.56136720\n",
      "Iteration 48517, loss = 15.55761636\n",
      "Iteration 48518, loss = 15.55386611\n",
      "Iteration 48519, loss = 15.55011644\n",
      "Iteration 48520, loss = 15.54636735\n",
      "Iteration 48521, loss = 15.54261884\n",
      "Iteration 48522, loss = 15.53887092\n",
      "Iteration 48523, loss = 15.53512357\n",
      "Iteration 48524, loss = 15.53137681\n",
      "Iteration 48525, loss = 15.52763064\n",
      "Iteration 48526, loss = 15.52388504\n",
      "Iteration 48527, loss = 15.52014002\n",
      "Iteration 48528, loss = 15.51639559\n",
      "Iteration 48529, loss = 15.51265174\n",
      "Iteration 48530, loss = 15.50890847\n",
      "Iteration 48531, loss = 15.50516578\n",
      "Iteration 48532, loss = 15.50142368\n",
      "Iteration 48533, loss = 15.49768215\n",
      "Iteration 48534, loss = 15.49394121\n",
      "Iteration 48535, loss = 15.49020085\n",
      "Iteration 48536, loss = 15.48646107\n",
      "Iteration 48537, loss = 15.48272187\n",
      "Iteration 48538, loss = 15.47898326\n",
      "Iteration 48539, loss = 15.47524523\n",
      "Iteration 48540, loss = 15.47150778\n",
      "Iteration 48541, loss = 15.46777091\n",
      "Iteration 48542, loss = 15.46403462\n",
      "Iteration 48543, loss = 15.46029891\n",
      "Iteration 48544, loss = 15.45656379\n",
      "Iteration 48545, loss = 15.45282924\n",
      "Iteration 48546, loss = 15.44909528\n",
      "Iteration 48547, loss = 15.44536190\n",
      "Iteration 48548, loss = 15.44162911\n",
      "Iteration 48549, loss = 15.43789689\n",
      "Iteration 48550, loss = 15.43416526\n",
      "Iteration 48551, loss = 15.43043420\n",
      "Iteration 48552, loss = 15.42670373\n",
      "Iteration 48553, loss = 15.42297384\n",
      "Iteration 48554, loss = 15.41924453\n",
      "Iteration 48555, loss = 15.41551581\n",
      "Iteration 48556, loss = 15.41178766\n",
      "Iteration 48557, loss = 15.40806010\n",
      "Iteration 48558, loss = 15.40433311\n",
      "Iteration 48559, loss = 15.40060671\n",
      "Iteration 48560, loss = 15.39688089\n",
      "Iteration 48561, loss = 15.39315565\n",
      "Iteration 48562, loss = 15.38943100\n",
      "Iteration 48563, loss = 15.38570692\n",
      "Iteration 48564, loss = 15.38198343\n",
      "Iteration 48565, loss = 15.37826052\n",
      "Iteration 48566, loss = 15.37453818\n",
      "Iteration 48567, loss = 15.37081643\n",
      "Iteration 48568, loss = 15.36709527\n",
      "Iteration 48569, loss = 15.36337468\n",
      "Iteration 48570, loss = 15.35965467\n",
      "Iteration 48571, loss = 15.35593525\n",
      "Iteration 48572, loss = 15.35221640\n",
      "Iteration 48573, loss = 15.34849814\n",
      "Iteration 48574, loss = 15.34478046\n",
      "Iteration 48575, loss = 15.34106336\n",
      "Iteration 48576, loss = 15.33734684\n",
      "Iteration 48577, loss = 15.33363090\n",
      "Iteration 48578, loss = 15.32991555\n",
      "Iteration 48579, loss = 15.32620077\n",
      "Iteration 48580, loss = 15.32248658\n",
      "Iteration 48581, loss = 15.31877296\n",
      "Iteration 48582, loss = 15.31505993\n",
      "Iteration 48583, loss = 15.31134748\n",
      "Iteration 48584, loss = 15.30763561\n",
      "Iteration 48585, loss = 15.30392432\n",
      "Iteration 48586, loss = 15.30021361\n",
      "Iteration 48587, loss = 15.29650349\n",
      "Iteration 48588, loss = 15.29279394\n",
      "Iteration 48589, loss = 15.28908497\n",
      "Iteration 48590, loss = 15.28537659\n",
      "Iteration 48591, loss = 15.28166879\n",
      "Iteration 48592, loss = 15.27796157\n",
      "Iteration 48593, loss = 15.27425492\n",
      "Iteration 48594, loss = 15.27054886\n",
      "Iteration 48595, loss = 15.26684338\n",
      "Iteration 48596, loss = 15.26313849\n",
      "Iteration 48597, loss = 15.25943417\n",
      "Iteration 48598, loss = 15.25573043\n",
      "Iteration 48599, loss = 15.25202727\n",
      "Iteration 48600, loss = 15.24832470\n",
      "Iteration 48601, loss = 15.24462270\n",
      "Iteration 48602, loss = 15.24092129\n",
      "Iteration 48603, loss = 15.23722046\n",
      "Iteration 48604, loss = 15.23352020\n",
      "Iteration 48605, loss = 15.22982053\n",
      "Iteration 48606, loss = 15.22612144\n",
      "Iteration 48607, loss = 15.22242293\n",
      "Iteration 48608, loss = 15.21872500\n",
      "Iteration 48609, loss = 15.21502765\n",
      "Iteration 48610, loss = 15.21133088\n",
      "Iteration 48611, loss = 15.20763470\n",
      "Iteration 48612, loss = 15.20393909\n",
      "Iteration 48613, loss = 15.20024406\n",
      "Iteration 48614, loss = 15.19654962\n",
      "Iteration 48615, loss = 15.19285575\n",
      "Iteration 48616, loss = 15.18916247\n",
      "Iteration 48617, loss = 15.18546976\n",
      "Iteration 48618, loss = 15.18177764\n",
      "Iteration 48619, loss = 15.17808610\n",
      "Iteration 48620, loss = 15.17439513\n",
      "Iteration 48621, loss = 15.17070475\n",
      "Iteration 48622, loss = 15.16701495\n",
      "Iteration 48623, loss = 15.16332573\n",
      "Iteration 48624, loss = 15.15963709\n",
      "Iteration 48625, loss = 15.15594903\n",
      "Iteration 48626, loss = 15.15226154\n",
      "Iteration 48627, loss = 15.14857464\n",
      "Iteration 48628, loss = 15.14488833\n",
      "Iteration 48629, loss = 15.14120259\n",
      "Iteration 48630, loss = 15.13751743\n",
      "Iteration 48631, loss = 15.13383285\n",
      "Iteration 48632, loss = 15.13014885\n",
      "Iteration 48633, loss = 15.12646543\n",
      "Iteration 48634, loss = 15.12278259\n",
      "Iteration 48635, loss = 15.11910034\n",
      "Iteration 48636, loss = 15.11541866\n",
      "Iteration 48637, loss = 15.11173756\n",
      "Iteration 48638, loss = 15.10805704\n",
      "Iteration 48639, loss = 15.10437711\n",
      "Iteration 48640, loss = 15.10069775\n",
      "Iteration 48641, loss = 15.09701897\n",
      "Iteration 48642, loss = 15.09334078\n",
      "Iteration 48643, loss = 15.08966316\n",
      "Iteration 48644, loss = 15.08598613\n",
      "Iteration 48645, loss = 15.08230967\n",
      "Iteration 48646, loss = 15.07863379\n",
      "Iteration 48647, loss = 15.07495850\n",
      "Iteration 48648, loss = 15.07128378\n",
      "Iteration 48649, loss = 15.06760965\n",
      "Iteration 48650, loss = 15.06393609\n",
      "Iteration 48651, loss = 15.06026311\n",
      "Iteration 48652, loss = 15.05659072\n",
      "Iteration 48653, loss = 15.05291890\n",
      "Iteration 48654, loss = 15.04924766\n",
      "Iteration 48655, loss = 15.04557701\n",
      "Iteration 48656, loss = 15.04190693\n",
      "Iteration 48657, loss = 15.03823744\n",
      "Iteration 48658, loss = 15.03456852\n",
      "Iteration 48659, loss = 15.03090018\n",
      "Iteration 48660, loss = 15.02723243\n",
      "Iteration 48661, loss = 15.02356525\n",
      "Iteration 48662, loss = 15.01989865\n",
      "Iteration 48663, loss = 15.01623263\n",
      "Iteration 48664, loss = 15.01256720\n",
      "Iteration 48665, loss = 15.00890234\n",
      "Iteration 48666, loss = 15.00523806\n",
      "Iteration 48667, loss = 15.00157436\n",
      "Iteration 48668, loss = 14.99791124\n",
      "Iteration 48669, loss = 14.99424870\n",
      "Iteration 48670, loss = 14.99058674\n",
      "Iteration 48671, loss = 14.98692536\n",
      "Iteration 48672, loss = 14.98326456\n",
      "Iteration 48673, loss = 14.97960434\n",
      "Iteration 48674, loss = 14.97594470\n",
      "Iteration 48675, loss = 14.97228564\n",
      "Iteration 48676, loss = 14.96862716\n",
      "Iteration 48677, loss = 14.96496926\n",
      "Iteration 48678, loss = 14.96131193\n",
      "Iteration 48679, loss = 14.95765519\n",
      "Iteration 48680, loss = 14.95399903\n",
      "Iteration 48681, loss = 14.95034344\n",
      "Iteration 48682, loss = 14.94668844\n",
      "Iteration 48683, loss = 14.94303401\n",
      "Iteration 48684, loss = 14.93938017\n",
      "Iteration 48685, loss = 14.93572690\n",
      "Iteration 48686, loss = 14.93207421\n",
      "Iteration 48687, loss = 14.92842211\n",
      "Iteration 48688, loss = 14.92477058\n",
      "Iteration 48689, loss = 14.92111963\n",
      "Iteration 48690, loss = 14.91746926\n",
      "Iteration 48691, loss = 14.91381947\n",
      "Iteration 48692, loss = 14.91017026\n",
      "Iteration 48693, loss = 14.90652163\n",
      "Iteration 48694, loss = 14.90287358\n",
      "Iteration 48695, loss = 14.89922610\n",
      "Iteration 48696, loss = 14.89557921\n",
      "Iteration 48697, loss = 14.89193290\n",
      "Iteration 48698, loss = 14.88828716\n",
      "Iteration 48699, loss = 14.88464200\n",
      "Iteration 48700, loss = 14.88099743\n",
      "Iteration 48701, loss = 14.87735343\n",
      "Iteration 48702, loss = 14.87371001\n",
      "Iteration 48703, loss = 14.87006717\n",
      "Iteration 48704, loss = 14.86642491\n",
      "Iteration 48705, loss = 14.86278323\n",
      "Iteration 48706, loss = 14.85914213\n",
      "Iteration 48707, loss = 14.85550161\n",
      "Iteration 48708, loss = 14.85186166\n",
      "Iteration 48709, loss = 14.84822230\n",
      "Iteration 48710, loss = 14.84458351\n",
      "Iteration 48711, loss = 14.84094530\n",
      "Iteration 48712, loss = 14.83730768\n",
      "Iteration 48713, loss = 14.83367063\n",
      "Iteration 48714, loss = 14.83003416\n",
      "Iteration 48715, loss = 14.82639827\n",
      "Iteration 48716, loss = 14.82276296\n",
      "Iteration 48717, loss = 14.81912822\n",
      "Iteration 48718, loss = 14.81549407\n",
      "Iteration 48719, loss = 14.81186049\n",
      "Iteration 48720, loss = 14.80822750\n",
      "Iteration 48721, loss = 14.80459508\n",
      "Iteration 48722, loss = 14.80096324\n",
      "Iteration 48723, loss = 14.79733198\n",
      "Iteration 48724, loss = 14.79370130\n",
      "Iteration 48725, loss = 14.79007120\n",
      "Iteration 48726, loss = 14.78644167\n",
      "Iteration 48727, loss = 14.78281273\n",
      "Iteration 48728, loss = 14.77918436\n",
      "Iteration 48729, loss = 14.77555657\n",
      "Iteration 48730, loss = 14.77192937\n",
      "Iteration 48731, loss = 14.76830274\n",
      "Iteration 48732, loss = 14.76467668\n",
      "Iteration 48733, loss = 14.76105121\n",
      "Iteration 48734, loss = 14.75742632\n",
      "Iteration 48735, loss = 14.75380200\n",
      "Iteration 48736, loss = 14.75017826\n",
      "Iteration 48737, loss = 14.74655511\n",
      "Iteration 48738, loss = 14.74293253\n",
      "Iteration 48739, loss = 14.73931053\n",
      "Iteration 48740, loss = 14.73568910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48741, loss = 14.73206826\n",
      "Iteration 48742, loss = 14.72844799\n",
      "Iteration 48743, loss = 14.72482831\n",
      "Iteration 48744, loss = 14.72120920\n",
      "Iteration 48745, loss = 14.71759067\n",
      "Iteration 48746, loss = 14.71397272\n",
      "Iteration 48747, loss = 14.71035534\n",
      "Iteration 48748, loss = 14.70673855\n",
      "Iteration 48749, loss = 14.70312233\n",
      "Iteration 48750, loss = 14.69950669\n",
      "Iteration 48751, loss = 14.69589163\n",
      "Iteration 48752, loss = 14.69227715\n",
      "Iteration 48753, loss = 14.68866325\n",
      "Iteration 48754, loss = 14.68504992\n",
      "Iteration 48755, loss = 14.68143718\n",
      "Iteration 48756, loss = 14.67782501\n",
      "Iteration 48757, loss = 14.67421342\n",
      "Iteration 48758, loss = 14.67060241\n",
      "Iteration 48759, loss = 14.66699197\n",
      "Iteration 48760, loss = 14.66338212\n",
      "Iteration 48761, loss = 14.65977284\n",
      "Iteration 48762, loss = 14.65616414\n",
      "Iteration 48763, loss = 14.65255602\n",
      "Iteration 48764, loss = 14.64894848\n",
      "Iteration 48765, loss = 14.64534151\n",
      "Iteration 48766, loss = 14.64173513\n",
      "Iteration 48767, loss = 14.63812932\n",
      "Iteration 48768, loss = 14.63452409\n",
      "Iteration 48769, loss = 14.63091944\n",
      "Iteration 48770, loss = 14.62731536\n",
      "Iteration 48771, loss = 14.62371187\n",
      "Iteration 48772, loss = 14.62010895\n",
      "Iteration 48773, loss = 14.61650661\n",
      "Iteration 48774, loss = 14.61290485\n",
      "Iteration 48775, loss = 14.60930366\n",
      "Iteration 48776, loss = 14.60570305\n",
      "Iteration 48777, loss = 14.60210303\n",
      "Iteration 48778, loss = 14.59850358\n",
      "Iteration 48779, loss = 14.59490470\n",
      "Iteration 48780, loss = 14.59130641\n",
      "Iteration 48781, loss = 14.58770869\n",
      "Iteration 48782, loss = 14.58411155\n",
      "Iteration 48783, loss = 14.58051499\n",
      "Iteration 48784, loss = 14.57691901\n",
      "Iteration 48785, loss = 14.57332360\n",
      "Iteration 48786, loss = 14.56972878\n",
      "Iteration 48787, loss = 14.56613453\n",
      "Iteration 48788, loss = 14.56254085\n",
      "Iteration 48789, loss = 14.55894776\n",
      "Iteration 48790, loss = 14.55535524\n",
      "Iteration 48791, loss = 14.55176330\n",
      "Iteration 48792, loss = 14.54817194\n",
      "Iteration 48793, loss = 14.54458116\n",
      "Iteration 48794, loss = 14.54099095\n",
      "Iteration 48795, loss = 14.53740133\n",
      "Iteration 48796, loss = 14.53381228\n",
      "Iteration 48797, loss = 14.53022381\n",
      "Iteration 48798, loss = 14.52663592\n",
      "Iteration 48799, loss = 14.52304862\n",
      "Iteration 48800, loss = 14.51946192\n",
      "Iteration 48801, loss = 14.51587582\n",
      "Iteration 48802, loss = 14.51229035\n",
      "Iteration 48803, loss = 14.50870557\n",
      "Iteration 48804, loss = 14.50512158\n",
      "Iteration 48805, loss = 14.50153858\n",
      "Iteration 48806, loss = 14.49795694\n",
      "Iteration 48807, loss = 14.49437742\n",
      "Iteration 48808, loss = 14.49080145\n",
      "Iteration 48809, loss = 14.48723167\n",
      "Iteration 48810, loss = 14.48367267\n",
      "Iteration 48811, loss = 14.48013130\n",
      "Iteration 48812, loss = 14.47661358\n",
      "Iteration 48813, loss = 14.47311325\n",
      "Iteration 48814, loss = 14.46958948\n",
      "Iteration 48815, loss = 14.46597708\n",
      "Iteration 48816, loss = 14.46227235\n",
      "Iteration 48817, loss = 14.45859168\n",
      "Iteration 48818, loss = 14.45502990\n",
      "Iteration 48819, loss = 14.45153392\n",
      "Iteration 48820, loss = 14.44798123\n",
      "Iteration 48821, loss = 14.44433988\n",
      "Iteration 48822, loss = 14.44070907\n",
      "Iteration 48823, loss = 14.43715977\n",
      "Iteration 48824, loss = 14.43363247\n",
      "Iteration 48825, loss = 14.43004719\n",
      "Iteration 48826, loss = 14.42642842\n",
      "Iteration 48827, loss = 14.42285126\n",
      "Iteration 48828, loss = 14.41931210\n",
      "Iteration 48829, loss = 14.41574861\n",
      "Iteration 48830, loss = 14.41215099\n",
      "Iteration 48831, loss = 14.40856881\n",
      "Iteration 48832, loss = 14.40501818\n",
      "Iteration 48833, loss = 14.40146114\n",
      "Iteration 48834, loss = 14.39787883\n",
      "Iteration 48835, loss = 14.39429969\n",
      "Iteration 48836, loss = 14.39074278\n",
      "Iteration 48837, loss = 14.38718726\n",
      "Iteration 48838, loss = 14.38361492\n",
      "Iteration 48839, loss = 14.38004070\n",
      "Iteration 48840, loss = 14.37648131\n",
      "Iteration 48841, loss = 14.37292622\n",
      "Iteration 48842, loss = 14.36936042\n",
      "Iteration 48843, loss = 14.36579114\n",
      "Iteration 48844, loss = 14.36223155\n",
      "Iteration 48845, loss = 14.35867687\n",
      "Iteration 48846, loss = 14.35511567\n",
      "Iteration 48847, loss = 14.35155089\n",
      "Iteration 48848, loss = 14.34799236\n",
      "Iteration 48849, loss = 14.34443837\n",
      "Iteration 48850, loss = 14.34088064\n",
      "Iteration 48851, loss = 14.33731993\n",
      "Iteration 48852, loss = 14.33376314\n",
      "Iteration 48853, loss = 14.33021014\n",
      "Iteration 48854, loss = 14.32665529\n",
      "Iteration 48855, loss = 14.32309823\n",
      "Iteration 48856, loss = 14.31954354\n",
      "Iteration 48857, loss = 14.31599183\n",
      "Iteration 48858, loss = 14.31243951\n",
      "Iteration 48859, loss = 14.30888577\n",
      "Iteration 48860, loss = 14.30533337\n",
      "Iteration 48861, loss = 14.30178322\n",
      "Iteration 48862, loss = 14.29823325\n",
      "Iteration 48863, loss = 14.29468252\n",
      "Iteration 48864, loss = 14.29113251\n",
      "Iteration 48865, loss = 14.28758415\n",
      "Iteration 48866, loss = 14.28403643\n",
      "Iteration 48867, loss = 14.28048847\n",
      "Iteration 48868, loss = 14.27694090\n",
      "Iteration 48869, loss = 14.27339453\n",
      "Iteration 48870, loss = 14.26984900\n",
      "Iteration 48871, loss = 14.26630362\n",
      "Iteration 48872, loss = 14.26275851\n",
      "Iteration 48873, loss = 14.25921427\n",
      "Iteration 48874, loss = 14.25567092\n",
      "Iteration 48875, loss = 14.25212798\n",
      "Iteration 48876, loss = 14.24858532\n",
      "Iteration 48877, loss = 14.24504332\n",
      "Iteration 48878, loss = 14.24150216\n",
      "Iteration 48879, loss = 14.23796156\n",
      "Iteration 48880, loss = 14.23442133\n",
      "Iteration 48881, loss = 14.23088162\n",
      "Iteration 48882, loss = 14.22734268\n",
      "Iteration 48883, loss = 14.22380438\n",
      "Iteration 48884, loss = 14.22026653\n",
      "Iteration 48885, loss = 14.21672916\n",
      "Iteration 48886, loss = 14.21319246\n",
      "Iteration 48887, loss = 14.20965644\n",
      "Iteration 48888, loss = 14.20612093\n",
      "Iteration 48889, loss = 14.20258591\n",
      "Iteration 48890, loss = 14.19905149\n",
      "Iteration 48891, loss = 14.19551773\n",
      "Iteration 48892, loss = 14.19198454\n",
      "Iteration 48893, loss = 14.18845186\n",
      "Iteration 48894, loss = 14.18491975\n",
      "Iteration 48895, loss = 14.18138826\n",
      "Iteration 48896, loss = 14.17785736\n",
      "Iteration 48897, loss = 14.17432701\n",
      "Iteration 48898, loss = 14.17079722\n",
      "Iteration 48899, loss = 14.16726801\n",
      "Iteration 48900, loss = 14.16373940\n",
      "Iteration 48901, loss = 14.16021137\n",
      "Iteration 48902, loss = 14.15668389\n",
      "Iteration 48903, loss = 14.15315698\n",
      "Iteration 48904, loss = 14.14963067\n",
      "Iteration 48905, loss = 14.14610493\n",
      "Iteration 48906, loss = 14.14257977\n",
      "Iteration 48907, loss = 14.13905517\n",
      "Iteration 48908, loss = 14.13553114\n",
      "Iteration 48909, loss = 14.13200771\n",
      "Iteration 48910, loss = 14.12848485\n",
      "Iteration 48911, loss = 14.12496255\n",
      "Iteration 48912, loss = 14.12144083\n",
      "Iteration 48913, loss = 14.11791969\n",
      "Iteration 48914, loss = 14.11439913\n",
      "Iteration 48915, loss = 14.11087914\n",
      "Iteration 48916, loss = 14.10735972\n",
      "Iteration 48917, loss = 14.10384088\n",
      "Iteration 48918, loss = 14.10032262\n",
      "Iteration 48919, loss = 14.09680493\n",
      "Iteration 48920, loss = 14.09328782\n",
      "Iteration 48921, loss = 14.08977128\n",
      "Iteration 48922, loss = 14.08625532\n",
      "Iteration 48923, loss = 14.08273993\n",
      "Iteration 48924, loss = 14.07922512\n",
      "Iteration 48925, loss = 14.07571088\n",
      "Iteration 48926, loss = 14.07219721\n",
      "Iteration 48927, loss = 14.06868413\n",
      "Iteration 48928, loss = 14.06517162\n",
      "Iteration 48929, loss = 14.06165968\n",
      "Iteration 48930, loss = 14.05814832\n",
      "Iteration 48931, loss = 14.05463753\n",
      "Iteration 48932, loss = 14.05112731\n",
      "Iteration 48933, loss = 14.04761768\n",
      "Iteration 48934, loss = 14.04410862\n",
      "Iteration 48935, loss = 14.04060013\n",
      "Iteration 48936, loss = 14.03709221\n",
      "Iteration 48937, loss = 14.03358488\n",
      "Iteration 48938, loss = 14.03007811\n",
      "Iteration 48939, loss = 14.02657193\n",
      "Iteration 48940, loss = 14.02306631\n",
      "Iteration 48941, loss = 14.01956127\n",
      "Iteration 48942, loss = 14.01605681\n",
      "Iteration 48943, loss = 14.01255292\n",
      "Iteration 48944, loss = 14.00904961\n",
      "Iteration 48945, loss = 14.00554687\n",
      "Iteration 48946, loss = 14.00204470\n",
      "Iteration 48947, loss = 13.99854311\n",
      "Iteration 48948, loss = 13.99504210\n",
      "Iteration 48949, loss = 13.99154166\n",
      "Iteration 48950, loss = 13.98804179\n",
      "Iteration 48951, loss = 13.98454250\n",
      "Iteration 48952, loss = 13.98104379\n",
      "Iteration 48953, loss = 13.97754564\n",
      "Iteration 48954, loss = 13.97404808\n",
      "Iteration 48955, loss = 13.97055108\n",
      "Iteration 48956, loss = 13.96705467\n",
      "Iteration 48957, loss = 13.96355882\n",
      "Iteration 48958, loss = 13.96006355\n",
      "Iteration 48959, loss = 13.95656886\n",
      "Iteration 48960, loss = 13.95307474\n",
      "Iteration 48961, loss = 13.94958119\n",
      "Iteration 48962, loss = 13.94608822\n",
      "Iteration 48963, loss = 13.94259583\n",
      "Iteration 48964, loss = 13.93910400\n",
      "Iteration 48965, loss = 13.93561276\n",
      "Iteration 48966, loss = 13.93212208\n",
      "Iteration 48967, loss = 13.92863199\n",
      "Iteration 48968, loss = 13.92514246\n",
      "Iteration 48969, loss = 13.92165351\n",
      "Iteration 48970, loss = 13.91816513\n",
      "Iteration 48971, loss = 13.91467733\n",
      "Iteration 48972, loss = 13.91119011\n",
      "Iteration 48973, loss = 13.90770345\n",
      "Iteration 48974, loss = 13.90421737\n",
      "Iteration 48975, loss = 13.90073187\n",
      "Iteration 48976, loss = 13.89724694\n",
      "Iteration 48977, loss = 13.89376258\n",
      "Iteration 48978, loss = 13.89027880\n",
      "Iteration 48979, loss = 13.88679559\n",
      "Iteration 48980, loss = 13.88331296\n",
      "Iteration 48981, loss = 13.87983090\n",
      "Iteration 48982, loss = 13.87634942\n",
      "Iteration 48983, loss = 13.87286851\n",
      "Iteration 48984, loss = 13.86938817\n",
      "Iteration 48985, loss = 13.86590841\n",
      "Iteration 48986, loss = 13.86242922\n",
      "Iteration 48987, loss = 13.85895060\n",
      "Iteration 48988, loss = 13.85547256\n",
      "Iteration 48989, loss = 13.85199510\n",
      "Iteration 48990, loss = 13.84851820\n",
      "Iteration 48991, loss = 13.84504188\n",
      "Iteration 48992, loss = 13.84156614\n",
      "Iteration 48993, loss = 13.83809097\n",
      "Iteration 48994, loss = 13.83461637\n",
      "Iteration 48995, loss = 13.83114235\n",
      "Iteration 48996, loss = 13.82766890\n",
      "Iteration 48997, loss = 13.82419602\n",
      "Iteration 48998, loss = 13.82072372\n",
      "Iteration 48999, loss = 13.81725199\n",
      "Iteration 49000, loss = 13.81378084\n",
      "Iteration 49001, loss = 13.81031026\n",
      "Iteration 49002, loss = 13.80684025\n",
      "Iteration 49003, loss = 13.80337082\n",
      "Iteration 49004, loss = 13.79990196\n",
      "Iteration 49005, loss = 13.79643368\n",
      "Iteration 49006, loss = 13.79296597\n",
      "Iteration 49007, loss = 13.78949883\n",
      "Iteration 49008, loss = 13.78603226\n",
      "Iteration 49009, loss = 13.78256627\n",
      "Iteration 49010, loss = 13.77910086\n",
      "Iteration 49011, loss = 13.77563601\n",
      "Iteration 49012, loss = 13.77217175\n",
      "Iteration 49013, loss = 13.76870805\n",
      "Iteration 49014, loss = 13.76524493\n",
      "Iteration 49015, loss = 13.76178238\n",
      "Iteration 49016, loss = 13.75832040\n",
      "Iteration 49017, loss = 13.75485900\n",
      "Iteration 49018, loss = 13.75139817\n",
      "Iteration 49019, loss = 13.74793792\n",
      "Iteration 49020, loss = 13.74447824\n",
      "Iteration 49021, loss = 13.74101913\n",
      "Iteration 49022, loss = 13.73756060\n",
      "Iteration 49023, loss = 13.73410263\n",
      "Iteration 49024, loss = 13.73064525\n",
      "Iteration 49025, loss = 13.72718843\n",
      "Iteration 49026, loss = 13.72373219\n",
      "Iteration 49027, loss = 13.72027652\n",
      "Iteration 49028, loss = 13.71682143\n",
      "Iteration 49029, loss = 13.71336691\n",
      "Iteration 49030, loss = 13.70991296\n",
      "Iteration 49031, loss = 13.70645959\n",
      "Iteration 49032, loss = 13.70300679\n",
      "Iteration 49033, loss = 13.69955456\n",
      "Iteration 49034, loss = 13.69610291\n",
      "Iteration 49035, loss = 13.69265182\n",
      "Iteration 49036, loss = 13.68920132\n",
      "Iteration 49037, loss = 13.68575138\n",
      "Iteration 49038, loss = 13.68230202\n",
      "Iteration 49039, loss = 13.67885323\n",
      "Iteration 49040, loss = 13.67540502\n",
      "Iteration 49041, loss = 13.67195737\n",
      "Iteration 49042, loss = 13.66851030\n",
      "Iteration 49043, loss = 13.66506381\n",
      "Iteration 49044, loss = 13.66161788\n",
      "Iteration 49045, loss = 13.65817253\n",
      "Iteration 49046, loss = 13.65472776\n",
      "Iteration 49047, loss = 13.65128355\n",
      "Iteration 49048, loss = 13.64783992\n",
      "Iteration 49049, loss = 13.64439686\n",
      "Iteration 49050, loss = 13.64095438\n",
      "Iteration 49051, loss = 13.63751247\n",
      "Iteration 49052, loss = 13.63407113\n",
      "Iteration 49053, loss = 13.63063036\n",
      "Iteration 49054, loss = 13.62719017\n",
      "Iteration 49055, loss = 13.62375055\n",
      "Iteration 49056, loss = 13.62031150\n",
      "Iteration 49057, loss = 13.61687302\n",
      "Iteration 49058, loss = 13.61343512\n",
      "Iteration 49059, loss = 13.60999779\n",
      "Iteration 49060, loss = 13.60656104\n",
      "Iteration 49061, loss = 13.60312485\n",
      "Iteration 49062, loss = 13.59968924\n",
      "Iteration 49063, loss = 13.59625420\n",
      "Iteration 49064, loss = 13.59281974\n",
      "Iteration 49065, loss = 13.58938584\n",
      "Iteration 49066, loss = 13.58595252\n",
      "Iteration 49067, loss = 13.58251978\n",
      "Iteration 49068, loss = 13.57908760\n",
      "Iteration 49069, loss = 13.57565600\n",
      "Iteration 49070, loss = 13.57222497\n",
      "Iteration 49071, loss = 13.56879451\n",
      "Iteration 49072, loss = 13.56536463\n",
      "Iteration 49073, loss = 13.56193531\n",
      "Iteration 49074, loss = 13.55850657\n",
      "Iteration 49075, loss = 13.55507841\n",
      "Iteration 49076, loss = 13.55165081\n",
      "Iteration 49077, loss = 13.54822379\n",
      "Iteration 49078, loss = 13.54479734\n",
      "Iteration 49079, loss = 13.54137146\n",
      "Iteration 49080, loss = 13.53794616\n",
      "Iteration 49081, loss = 13.53452143\n",
      "Iteration 49082, loss = 13.53109727\n",
      "Iteration 49083, loss = 13.52767368\n",
      "Iteration 49084, loss = 13.52425066\n",
      "Iteration 49085, loss = 13.52082822\n",
      "Iteration 49086, loss = 13.51740635\n",
      "Iteration 49087, loss = 13.51398505\n",
      "Iteration 49088, loss = 13.51056433\n",
      "Iteration 49089, loss = 13.50714417\n",
      "Iteration 49090, loss = 13.50372459\n",
      "Iteration 49091, loss = 13.50030558\n",
      "Iteration 49092, loss = 13.49688714\n",
      "Iteration 49093, loss = 13.49346928\n",
      "Iteration 49094, loss = 13.49005199\n",
      "Iteration 49095, loss = 13.48663527\n",
      "Iteration 49096, loss = 13.48321912\n",
      "Iteration 49097, loss = 13.47980354\n",
      "Iteration 49098, loss = 13.47638854\n",
      "Iteration 49099, loss = 13.47297410\n",
      "Iteration 49100, loss = 13.46956024\n",
      "Iteration 49101, loss = 13.46614696\n",
      "Iteration 49102, loss = 13.46273424\n",
      "Iteration 49103, loss = 13.45932210\n",
      "Iteration 49104, loss = 13.45591052\n",
      "Iteration 49105, loss = 13.45249952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49106, loss = 13.44908910\n",
      "Iteration 49107, loss = 13.44567924\n",
      "Iteration 49108, loss = 13.44226996\n",
      "Iteration 49109, loss = 13.43886124\n",
      "Iteration 49110, loss = 13.43545310\n",
      "Iteration 49111, loss = 13.43204554\n",
      "Iteration 49112, loss = 13.42863854\n",
      "Iteration 49113, loss = 13.42523211\n",
      "Iteration 49114, loss = 13.42182626\n",
      "Iteration 49115, loss = 13.41842098\n",
      "Iteration 49116, loss = 13.41501627\n",
      "Iteration 49117, loss = 13.41161213\n",
      "Iteration 49118, loss = 13.40820857\n",
      "Iteration 49119, loss = 13.40480557\n",
      "Iteration 49120, loss = 13.40140315\n",
      "Iteration 49121, loss = 13.39800130\n",
      "Iteration 49122, loss = 13.39460002\n",
      "Iteration 49123, loss = 13.39119932\n",
      "Iteration 49124, loss = 13.38779918\n",
      "Iteration 49125, loss = 13.38439962\n",
      "Iteration 49126, loss = 13.38100062\n",
      "Iteration 49127, loss = 13.37760220\n",
      "Iteration 49128, loss = 13.37420435\n",
      "Iteration 49129, loss = 13.37080708\n",
      "Iteration 49130, loss = 13.36741037\n",
      "Iteration 49131, loss = 13.36401424\n",
      "Iteration 49132, loss = 13.36061867\n",
      "Iteration 49133, loss = 13.35722368\n",
      "Iteration 49134, loss = 13.35382926\n",
      "Iteration 49135, loss = 13.35043541\n",
      "Iteration 49136, loss = 13.34704214\n",
      "Iteration 49137, loss = 13.34364943\n",
      "Iteration 49138, loss = 13.34025730\n",
      "Iteration 49139, loss = 13.33686573\n",
      "Iteration 49140, loss = 13.33347474\n",
      "Iteration 49141, loss = 13.33008432\n",
      "Iteration 49142, loss = 13.32669447\n",
      "Iteration 49143, loss = 13.32330519\n",
      "Iteration 49144, loss = 13.31991649\n",
      "Iteration 49145, loss = 13.31652835\n",
      "Iteration 49146, loss = 13.31314079\n",
      "Iteration 49147, loss = 13.30975380\n",
      "Iteration 49148, loss = 13.30636738\n",
      "Iteration 49149, loss = 13.30298153\n",
      "Iteration 49150, loss = 13.29959625\n",
      "Iteration 49151, loss = 13.29621154\n",
      "Iteration 49152, loss = 13.29282740\n",
      "Iteration 49153, loss = 13.28944384\n",
      "Iteration 49154, loss = 13.28606084\n",
      "Iteration 49155, loss = 13.28267842\n",
      "Iteration 49156, loss = 13.27929657\n",
      "Iteration 49157, loss = 13.27591529\n",
      "Iteration 49158, loss = 13.27253458\n",
      "Iteration 49159, loss = 13.26915444\n",
      "Iteration 49160, loss = 13.26577487\n",
      "Iteration 49161, loss = 13.26239587\n",
      "Iteration 49162, loss = 13.25901745\n",
      "Iteration 49163, loss = 13.25563959\n",
      "Iteration 49164, loss = 13.25226231\n",
      "Iteration 49165, loss = 13.24888559\n",
      "Iteration 49166, loss = 13.24550945\n",
      "Iteration 49167, loss = 13.24213388\n",
      "Iteration 49168, loss = 13.23875888\n",
      "Iteration 49169, loss = 13.23538445\n",
      "Iteration 49170, loss = 13.23201059\n",
      "Iteration 49171, loss = 13.22863730\n",
      "Iteration 49172, loss = 13.22526459\n",
      "Iteration 49173, loss = 13.22189244\n",
      "Iteration 49174, loss = 13.21852086\n",
      "Iteration 49175, loss = 13.21514986\n",
      "Iteration 49176, loss = 13.21177943\n",
      "Iteration 49177, loss = 13.20840956\n",
      "Iteration 49178, loss = 13.20504027\n",
      "Iteration 49179, loss = 13.20167155\n",
      "Iteration 49180, loss = 13.19830340\n",
      "Iteration 49181, loss = 13.19493581\n",
      "Iteration 49182, loss = 13.19156880\n",
      "Iteration 49183, loss = 13.18820236\n",
      "Iteration 49184, loss = 13.18483650\n",
      "Iteration 49185, loss = 13.18147120\n",
      "Iteration 49186, loss = 13.17810647\n",
      "Iteration 49187, loss = 13.17474231\n",
      "Iteration 49188, loss = 13.17137872\n",
      "Iteration 49189, loss = 13.16801571\n",
      "Iteration 49190, loss = 13.16465326\n",
      "Iteration 49191, loss = 13.16129139\n",
      "Iteration 49192, loss = 13.15793008\n",
      "Iteration 49193, loss = 13.15456935\n",
      "Iteration 49194, loss = 13.15120918\n",
      "Iteration 49195, loss = 13.14784959\n",
      "Iteration 49196, loss = 13.14449057\n",
      "Iteration 49197, loss = 13.14113211\n",
      "Iteration 49198, loss = 13.13777423\n",
      "Iteration 49199, loss = 13.13441692\n",
      "Iteration 49200, loss = 13.13106017\n",
      "Iteration 49201, loss = 13.12770400\n",
      "Iteration 49202, loss = 13.12434840\n",
      "Iteration 49203, loss = 13.12099337\n",
      "Iteration 49204, loss = 13.11763891\n",
      "Iteration 49205, loss = 13.11428502\n",
      "Iteration 49206, loss = 13.11093170\n",
      "Iteration 49207, loss = 13.10757895\n",
      "Iteration 49208, loss = 13.10422677\n",
      "Iteration 49209, loss = 13.10087516\n",
      "Iteration 49210, loss = 13.09752412\n",
      "Iteration 49211, loss = 13.09417365\n",
      "Iteration 49212, loss = 13.09082375\n",
      "Iteration 49213, loss = 13.08747442\n",
      "Iteration 49214, loss = 13.08412567\n",
      "Iteration 49215, loss = 13.08077749\n",
      "Iteration 49216, loss = 13.07742988\n",
      "Iteration 49217, loss = 13.07408287\n",
      "Iteration 49218, loss = 13.07073645\n",
      "Iteration 49219, loss = 13.06739067\n",
      "Iteration 49220, loss = 13.06404556\n",
      "Iteration 49221, loss = 13.06070125\n",
      "Iteration 49222, loss = 13.05735793\n",
      "Iteration 49223, loss = 13.05401599\n",
      "Iteration 49224, loss = 13.05067621\n",
      "Iteration 49225, loss = 13.04734006\n",
      "Iteration 49226, loss = 13.04401025\n",
      "Iteration 49227, loss = 13.04069148\n",
      "Iteration 49228, loss = 13.03739067\n",
      "Iteration 49229, loss = 13.03411360\n",
      "Iteration 49230, loss = 13.03085300\n",
      "Iteration 49231, loss = 13.02756629\n",
      "Iteration 49232, loss = 13.02418871\n",
      "Iteration 49233, loss = 13.02072164\n",
      "Iteration 49234, loss = 13.01728441\n",
      "Iteration 49235, loss = 13.01396681\n",
      "Iteration 49236, loss = 13.01071022\n",
      "Iteration 49237, loss = 13.00739311\n",
      "Iteration 49238, loss = 13.00398946\n",
      "Iteration 49239, loss = 13.00060088\n",
      "Iteration 49240, loss = 12.99729355\n",
      "Iteration 49241, loss = 12.99400443\n",
      "Iteration 49242, loss = 12.99065632\n",
      "Iteration 49243, loss = 12.98727758\n",
      "Iteration 49244, loss = 12.98394188\n",
      "Iteration 49245, loss = 12.98064219\n",
      "Iteration 49246, loss = 12.97731667\n",
      "Iteration 49247, loss = 12.97395829\n",
      "Iteration 49248, loss = 12.97061671\n",
      "Iteration 49249, loss = 12.96730587\n",
      "Iteration 49250, loss = 12.96398748\n",
      "Iteration 49251, loss = 12.96064424\n",
      "Iteration 49252, loss = 12.95730509\n",
      "Iteration 49253, loss = 12.95398795\n",
      "Iteration 49254, loss = 12.95067147\n",
      "Iteration 49255, loss = 12.94733823\n",
      "Iteration 49256, loss = 12.94400365\n",
      "Iteration 49257, loss = 12.94068393\n",
      "Iteration 49258, loss = 12.93736808\n",
      "Iteration 49259, loss = 12.93404143\n",
      "Iteration 49260, loss = 12.93071158\n",
      "Iteration 49261, loss = 12.92739156\n",
      "Iteration 49262, loss = 12.92407620\n",
      "Iteration 49263, loss = 12.92075416\n",
      "Iteration 49264, loss = 12.91742874\n",
      "Iteration 49265, loss = 12.91410968\n",
      "Iteration 49266, loss = 12.91079502\n",
      "Iteration 49267, loss = 12.90747648\n",
      "Iteration 49268, loss = 12.90415507\n",
      "Iteration 49269, loss = 12.90083768\n",
      "Iteration 49270, loss = 12.89752398\n",
      "Iteration 49271, loss = 12.89420832\n",
      "Iteration 49272, loss = 12.89089054\n",
      "Iteration 49273, loss = 12.88757518\n",
      "Iteration 49274, loss = 12.88426273\n",
      "Iteration 49275, loss = 12.88094962\n",
      "Iteration 49276, loss = 12.87763512\n",
      "Iteration 49277, loss = 12.87432199\n",
      "Iteration 49278, loss = 12.87101106\n",
      "Iteration 49279, loss = 12.86770030\n",
      "Iteration 49280, loss = 12.86438879\n",
      "Iteration 49281, loss = 12.86107800\n",
      "Iteration 49282, loss = 12.85776883\n",
      "Iteration 49283, loss = 12.85446029\n",
      "Iteration 49284, loss = 12.85115152\n",
      "Iteration 49285, loss = 12.84784313\n",
      "Iteration 49286, loss = 12.84453592\n",
      "Iteration 49287, loss = 12.84122955\n",
      "Iteration 49288, loss = 12.83792333\n",
      "Iteration 49289, loss = 12.83461737\n",
      "Iteration 49290, loss = 12.83131226\n",
      "Iteration 49291, loss = 12.82800803\n",
      "Iteration 49292, loss = 12.82470422\n",
      "Iteration 49293, loss = 12.82140068\n",
      "Iteration 49294, loss = 12.81809778\n",
      "Iteration 49295, loss = 12.81479571\n",
      "Iteration 49296, loss = 12.81149421\n",
      "Iteration 49297, loss = 12.80819306\n",
      "Iteration 49298, loss = 12.80489243\n",
      "Iteration 49299, loss = 12.80159255\n",
      "Iteration 49300, loss = 12.79829332\n",
      "Iteration 49301, loss = 12.79499452\n",
      "Iteration 49302, loss = 12.79169620\n",
      "Iteration 49303, loss = 12.78839854\n",
      "Iteration 49304, loss = 12.78510154\n",
      "Iteration 49305, loss = 12.78180505\n",
      "Iteration 49306, loss = 12.77850905\n",
      "Iteration 49307, loss = 12.77521364\n",
      "Iteration 49308, loss = 12.77191887\n",
      "Iteration 49309, loss = 12.76862467\n",
      "Iteration 49310, loss = 12.76533098\n",
      "Iteration 49311, loss = 12.76203784\n",
      "Iteration 49312, loss = 12.75874532\n",
      "Iteration 49313, loss = 12.75545338\n",
      "Iteration 49314, loss = 12.75216199\n",
      "Iteration 49315, loss = 12.74887114\n",
      "Iteration 49316, loss = 12.74558087\n",
      "Iteration 49317, loss = 12.74229119\n",
      "Iteration 49318, loss = 12.73900207\n",
      "Iteration 49319, loss = 12.73571351\n",
      "Iteration 49320, loss = 12.73242551\n",
      "Iteration 49321, loss = 12.72913809\n",
      "Iteration 49322, loss = 12.72585125\n",
      "Iteration 49323, loss = 12.72256496\n",
      "Iteration 49324, loss = 12.71927924\n",
      "Iteration 49325, loss = 12.71599408\n",
      "Iteration 49326, loss = 12.71270951\n",
      "Iteration 49327, loss = 12.70942550\n",
      "Iteration 49328, loss = 12.70614205\n",
      "Iteration 49329, loss = 12.70285916\n",
      "Iteration 49330, loss = 12.69957685\n",
      "Iteration 49331, loss = 12.69629511\n",
      "Iteration 49332, loss = 12.69301394\n",
      "Iteration 49333, loss = 12.68973333\n",
      "Iteration 49334, loss = 12.68645328\n",
      "Iteration 49335, loss = 12.68317381\n",
      "Iteration 49336, loss = 12.67989491\n",
      "Iteration 49337, loss = 12.67661657\n",
      "Iteration 49338, loss = 12.67333879\n",
      "Iteration 49339, loss = 12.67006159\n",
      "Iteration 49340, loss = 12.66678495\n",
      "Iteration 49341, loss = 12.66350889\n",
      "Iteration 49342, loss = 12.66023338\n",
      "Iteration 49343, loss = 12.65695845\n",
      "Iteration 49344, loss = 12.65368408\n",
      "Iteration 49345, loss = 12.65041028\n",
      "Iteration 49346, loss = 12.64713705\n",
      "Iteration 49347, loss = 12.64386439\n",
      "Iteration 49348, loss = 12.64059229\n",
      "Iteration 49349, loss = 12.63732076\n",
      "Iteration 49350, loss = 12.63404979\n",
      "Iteration 49351, loss = 12.63077940\n",
      "Iteration 49352, loss = 12.62750957\n",
      "Iteration 49353, loss = 12.62424031\n",
      "Iteration 49354, loss = 12.62097161\n",
      "Iteration 49355, loss = 12.61770348\n",
      "Iteration 49356, loss = 12.61443592\n",
      "Iteration 49357, loss = 12.61116893\n",
      "Iteration 49358, loss = 12.60790250\n",
      "Iteration 49359, loss = 12.60463664\n",
      "Iteration 49360, loss = 12.60137135\n",
      "Iteration 49361, loss = 12.59810663\n",
      "Iteration 49362, loss = 12.59484247\n",
      "Iteration 49363, loss = 12.59157888\n",
      "Iteration 49364, loss = 12.58831585\n",
      "Iteration 49365, loss = 12.58505339\n",
      "Iteration 49366, loss = 12.58179150\n",
      "Iteration 49367, loss = 12.57853018\n",
      "Iteration 49368, loss = 12.57526942\n",
      "Iteration 49369, loss = 12.57200923\n",
      "Iteration 49370, loss = 12.56874961\n",
      "Iteration 49371, loss = 12.56549055\n",
      "Iteration 49372, loss = 12.56223206\n",
      "Iteration 49373, loss = 12.55897414\n",
      "Iteration 49374, loss = 12.55571678\n",
      "Iteration 49375, loss = 12.55245999\n",
      "Iteration 49376, loss = 12.54920377\n",
      "Iteration 49377, loss = 12.54594811\n",
      "Iteration 49378, loss = 12.54269303\n",
      "Iteration 49379, loss = 12.53943850\n",
      "Iteration 49380, loss = 12.53618455\n",
      "Iteration 49381, loss = 12.53293116\n",
      "Iteration 49382, loss = 12.52967833\n",
      "Iteration 49383, loss = 12.52642608\n",
      "Iteration 49384, loss = 12.52317439\n",
      "Iteration 49385, loss = 12.51992327\n",
      "Iteration 49386, loss = 12.51667271\n",
      "Iteration 49387, loss = 12.51342272\n",
      "Iteration 49388, loss = 12.51017330\n",
      "Iteration 49389, loss = 12.50692444\n",
      "Iteration 49390, loss = 12.50367615\n",
      "Iteration 49391, loss = 12.50042842\n",
      "Iteration 49392, loss = 12.49718127\n",
      "Iteration 49393, loss = 12.49393467\n",
      "Iteration 49394, loss = 12.49068865\n",
      "Iteration 49395, loss = 12.48744319\n",
      "Iteration 49396, loss = 12.48419830\n",
      "Iteration 49397, loss = 12.48095397\n",
      "Iteration 49398, loss = 12.47771021\n",
      "Iteration 49399, loss = 12.47446702\n",
      "Iteration 49400, loss = 12.47122439\n",
      "Iteration 49401, loss = 12.46798233\n",
      "Iteration 49402, loss = 12.46474084\n",
      "Iteration 49403, loss = 12.46149991\n",
      "Iteration 49404, loss = 12.45825955\n",
      "Iteration 49405, loss = 12.45501975\n",
      "Iteration 49406, loss = 12.45178052\n",
      "Iteration 49407, loss = 12.44854186\n",
      "Iteration 49408, loss = 12.44530376\n",
      "Iteration 49409, loss = 12.44206623\n",
      "Iteration 49410, loss = 12.43882926\n",
      "Iteration 49411, loss = 12.43559286\n",
      "Iteration 49412, loss = 12.43235703\n",
      "Iteration 49413, loss = 12.42912176\n",
      "Iteration 49414, loss = 12.42588706\n",
      "Iteration 49415, loss = 12.42265293\n",
      "Iteration 49416, loss = 12.41941936\n",
      "Iteration 49417, loss = 12.41618635\n",
      "Iteration 49418, loss = 12.41295392\n",
      "Iteration 49419, loss = 12.40972204\n",
      "Iteration 49420, loss = 12.40649074\n",
      "Iteration 49421, loss = 12.40326000\n",
      "Iteration 49422, loss = 12.40002982\n",
      "Iteration 49423, loss = 12.39680022\n",
      "Iteration 49424, loss = 12.39357117\n",
      "Iteration 49425, loss = 12.39034270\n",
      "Iteration 49426, loss = 12.38711479\n",
      "Iteration 49427, loss = 12.38388744\n",
      "Iteration 49428, loss = 12.38066066\n",
      "Iteration 49429, loss = 12.37743445\n",
      "Iteration 49430, loss = 12.37420880\n",
      "Iteration 49431, loss = 12.37098372\n",
      "Iteration 49432, loss = 12.36775920\n",
      "Iteration 49433, loss = 12.36453525\n",
      "Iteration 49434, loss = 12.36131187\n",
      "Iteration 49435, loss = 12.35808905\n",
      "Iteration 49436, loss = 12.35486679\n",
      "Iteration 49437, loss = 12.35164510\n",
      "Iteration 49438, loss = 12.34842398\n",
      "Iteration 49439, loss = 12.34520342\n",
      "Iteration 49440, loss = 12.34198343\n",
      "Iteration 49441, loss = 12.33876401\n",
      "Iteration 49442, loss = 12.33554515\n",
      "Iteration 49443, loss = 12.33232685\n",
      "Iteration 49444, loss = 12.32910912\n",
      "Iteration 49445, loss = 12.32589196\n",
      "Iteration 49446, loss = 12.32267536\n",
      "Iteration 49447, loss = 12.31945932\n",
      "Iteration 49448, loss = 12.31624385\n",
      "Iteration 49449, loss = 12.31302895\n",
      "Iteration 49450, loss = 12.30981461\n",
      "Iteration 49451, loss = 12.30660084\n",
      "Iteration 49452, loss = 12.30338763\n",
      "Iteration 49453, loss = 12.30017499\n",
      "Iteration 49454, loss = 12.29696292\n",
      "Iteration 49455, loss = 12.29375140\n",
      "Iteration 49456, loss = 12.29054046\n",
      "Iteration 49457, loss = 12.28733008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49458, loss = 12.28412026\n",
      "Iteration 49459, loss = 12.28091101\n",
      "Iteration 49460, loss = 12.27770232\n",
      "Iteration 49461, loss = 12.27449420\n",
      "Iteration 49462, loss = 12.27128665\n",
      "Iteration 49463, loss = 12.26807966\n",
      "Iteration 49464, loss = 12.26487323\n",
      "Iteration 49465, loss = 12.26166737\n",
      "Iteration 49466, loss = 12.25846208\n",
      "Iteration 49467, loss = 12.25525735\n",
      "Iteration 49468, loss = 12.25205318\n",
      "Iteration 49469, loss = 12.24884958\n",
      "Iteration 49470, loss = 12.24564655\n",
      "Iteration 49471, loss = 12.24244408\n",
      "Iteration 49472, loss = 12.23924217\n",
      "Iteration 49473, loss = 12.23604083\n",
      "Iteration 49474, loss = 12.23284006\n",
      "Iteration 49475, loss = 12.22963985\n",
      "Iteration 49476, loss = 12.22644020\n",
      "Iteration 49477, loss = 12.22324112\n",
      "Iteration 49478, loss = 12.22004260\n",
      "Iteration 49479, loss = 12.21684465\n",
      "Iteration 49480, loss = 12.21364726\n",
      "Iteration 49481, loss = 12.21045044\n",
      "Iteration 49482, loss = 12.20725418\n",
      "Iteration 49483, loss = 12.20405849\n",
      "Iteration 49484, loss = 12.20086336\n",
      "Iteration 49485, loss = 12.19766880\n",
      "Iteration 49486, loss = 12.19447480\n",
      "Iteration 49487, loss = 12.19128137\n",
      "Iteration 49488, loss = 12.18808850\n",
      "Iteration 49489, loss = 12.18489619\n",
      "Iteration 49490, loss = 12.18170445\n",
      "Iteration 49491, loss = 12.17851328\n",
      "Iteration 49492, loss = 12.17532267\n",
      "Iteration 49493, loss = 12.17213262\n",
      "Iteration 49494, loss = 12.16894314\n",
      "Iteration 49495, loss = 12.16575422\n",
      "Iteration 49496, loss = 12.16256587\n",
      "Iteration 49497, loss = 12.15937808\n",
      "Iteration 49498, loss = 12.15619085\n",
      "Iteration 49499, loss = 12.15300419\n",
      "Iteration 49500, loss = 12.14981810\n",
      "Iteration 49501, loss = 12.14663257\n",
      "Iteration 49502, loss = 12.14344760\n",
      "Iteration 49503, loss = 12.14026320\n",
      "Iteration 49504, loss = 12.13707936\n",
      "Iteration 49505, loss = 12.13389608\n",
      "Iteration 49506, loss = 12.13071337\n",
      "Iteration 49507, loss = 12.12753123\n",
      "Iteration 49508, loss = 12.12434965\n",
      "Iteration 49509, loss = 12.12116863\n",
      "Iteration 49510, loss = 12.11798818\n",
      "Iteration 49511, loss = 12.11480829\n",
      "Iteration 49512, loss = 12.11162896\n",
      "Iteration 49513, loss = 12.10845020\n",
      "Iteration 49514, loss = 12.10527200\n",
      "Iteration 49515, loss = 12.10209437\n",
      "Iteration 49516, loss = 12.09891730\n",
      "Iteration 49517, loss = 12.09574080\n",
      "Iteration 49518, loss = 12.09256486\n",
      "Iteration 49519, loss = 12.08938948\n",
      "Iteration 49520, loss = 12.08621467\n",
      "Iteration 49521, loss = 12.08304042\n",
      "Iteration 49522, loss = 12.07986674\n",
      "Iteration 49523, loss = 12.07669362\n",
      "Iteration 49524, loss = 12.07352106\n",
      "Iteration 49525, loss = 12.07034907\n",
      "Iteration 49526, loss = 12.06717764\n",
      "Iteration 49527, loss = 12.06400677\n",
      "Iteration 49528, loss = 12.06083647\n",
      "Iteration 49529, loss = 12.05766674\n",
      "Iteration 49530, loss = 12.05449756\n",
      "Iteration 49531, loss = 12.05132895\n",
      "Iteration 49532, loss = 12.04816091\n",
      "Iteration 49533, loss = 12.04499343\n",
      "Iteration 49534, loss = 12.04182651\n",
      "Iteration 49535, loss = 12.03866015\n",
      "Iteration 49536, loss = 12.03549436\n",
      "Iteration 49537, loss = 12.03232913\n",
      "Iteration 49538, loss = 12.02916447\n",
      "Iteration 49539, loss = 12.02600037\n",
      "Iteration 49540, loss = 12.02283683\n",
      "Iteration 49541, loss = 12.01967386\n",
      "Iteration 49542, loss = 12.01651145\n",
      "Iteration 49543, loss = 12.01334960\n",
      "Iteration 49544, loss = 12.01018832\n",
      "Iteration 49545, loss = 12.00702760\n",
      "Iteration 49546, loss = 12.00386745\n",
      "Iteration 49547, loss = 12.00070786\n",
      "Iteration 49548, loss = 11.99754883\n",
      "Iteration 49549, loss = 11.99439036\n",
      "Iteration 49550, loss = 11.99123246\n",
      "Iteration 49551, loss = 11.98807512\n",
      "Iteration 49552, loss = 11.98491835\n",
      "Iteration 49553, loss = 11.98176214\n",
      "Iteration 49554, loss = 11.97860649\n",
      "Iteration 49555, loss = 11.97545140\n",
      "Iteration 49556, loss = 11.97229688\n",
      "Iteration 49557, loss = 11.96914292\n",
      "Iteration 49558, loss = 11.96598953\n",
      "Iteration 49559, loss = 11.96283670\n",
      "Iteration 49560, loss = 11.95968443\n",
      "Iteration 49561, loss = 11.95653272\n",
      "Iteration 49562, loss = 11.95338158\n",
      "Iteration 49563, loss = 11.95023100\n",
      "Iteration 49564, loss = 11.94708099\n",
      "Iteration 49565, loss = 11.94393153\n",
      "Iteration 49566, loss = 11.94078264\n",
      "Iteration 49567, loss = 11.93763432\n",
      "Iteration 49568, loss = 11.93448655\n",
      "Iteration 49569, loss = 11.93133935\n",
      "Iteration 49570, loss = 11.92819272\n",
      "Iteration 49571, loss = 11.92504664\n",
      "Iteration 49572, loss = 11.92190113\n",
      "Iteration 49573, loss = 11.91875618\n",
      "Iteration 49574, loss = 11.91561179\n",
      "Iteration 49575, loss = 11.91246797\n",
      "Iteration 49576, loss = 11.90932471\n",
      "Iteration 49577, loss = 11.90618202\n",
      "Iteration 49578, loss = 11.90303988\n",
      "Iteration 49579, loss = 11.89989831\n",
      "Iteration 49580, loss = 11.89675730\n",
      "Iteration 49581, loss = 11.89361686\n",
      "Iteration 49582, loss = 11.89047697\n",
      "Iteration 49583, loss = 11.88733765\n",
      "Iteration 49584, loss = 11.88419890\n",
      "Iteration 49585, loss = 11.88106070\n",
      "Iteration 49586, loss = 11.87792307\n",
      "Iteration 49587, loss = 11.87478600\n",
      "Iteration 49588, loss = 11.87164949\n",
      "Iteration 49589, loss = 11.86851355\n",
      "Iteration 49590, loss = 11.86537817\n",
      "Iteration 49591, loss = 11.86224335\n",
      "Iteration 49592, loss = 11.85910910\n",
      "Iteration 49593, loss = 11.85597540\n",
      "Iteration 49594, loss = 11.85284227\n",
      "Iteration 49595, loss = 11.84970970\n",
      "Iteration 49596, loss = 11.84657770\n",
      "Iteration 49597, loss = 11.84344625\n",
      "Iteration 49598, loss = 11.84031537\n",
      "Iteration 49599, loss = 11.83718505\n",
      "Iteration 49600, loss = 11.83405530\n",
      "Iteration 49601, loss = 11.83092611\n",
      "Iteration 49602, loss = 11.82779747\n",
      "Iteration 49603, loss = 11.82466941\n",
      "Iteration 49604, loss = 11.82154190\n",
      "Iteration 49605, loss = 11.81841496\n",
      "Iteration 49606, loss = 11.81528857\n",
      "Iteration 49607, loss = 11.81216275\n",
      "Iteration 49608, loss = 11.80903750\n",
      "Iteration 49609, loss = 11.80591280\n",
      "Iteration 49610, loss = 11.80278867\n",
      "Iteration 49611, loss = 11.79966510\n",
      "Iteration 49612, loss = 11.79654209\n",
      "Iteration 49613, loss = 11.79341964\n",
      "Iteration 49614, loss = 11.79029776\n",
      "Iteration 49615, loss = 11.78717644\n",
      "Iteration 49616, loss = 11.78405568\n",
      "Iteration 49617, loss = 11.78093548\n",
      "Iteration 49618, loss = 11.77781585\n",
      "Iteration 49619, loss = 11.77469677\n",
      "Iteration 49620, loss = 11.77157826\n",
      "Iteration 49621, loss = 11.76846031\n",
      "Iteration 49622, loss = 11.76534293\n",
      "Iteration 49623, loss = 11.76222610\n",
      "Iteration 49624, loss = 11.75910984\n",
      "Iteration 49625, loss = 11.75599414\n",
      "Iteration 49626, loss = 11.75287900\n",
      "Iteration 49627, loss = 11.74976442\n",
      "Iteration 49628, loss = 11.74665041\n",
      "Iteration 49629, loss = 11.74353695\n",
      "Iteration 49630, loss = 11.74042407\n",
      "Iteration 49631, loss = 11.73731174\n",
      "Iteration 49632, loss = 11.73419999\n",
      "Iteration 49633, loss = 11.73108881\n",
      "Iteration 49634, loss = 11.72797821\n",
      "Iteration 49635, loss = 11.72486822\n",
      "Iteration 49636, loss = 11.72175887\n",
      "Iteration 49637, loss = 11.71865025\n",
      "Iteration 49638, loss = 11.71554250\n",
      "Iteration 49639, loss = 11.71243592\n",
      "Iteration 49640, loss = 11.70933109\n",
      "Iteration 49641, loss = 11.70622910\n",
      "Iteration 49642, loss = 11.70313205\n",
      "Iteration 49643, loss = 11.70004370\n",
      "Iteration 49644, loss = 11.69697008\n",
      "Iteration 49645, loss = 11.69391855\n",
      "Iteration 49646, loss = 11.69088988\n",
      "Iteration 49647, loss = 11.68785981\n",
      "Iteration 49648, loss = 11.68476521\n",
      "Iteration 49649, loss = 11.68156419\n",
      "Iteration 49650, loss = 11.67833065\n",
      "Iteration 49651, loss = 11.67519409\n",
      "Iteration 49652, loss = 11.67216247\n",
      "Iteration 49653, loss = 11.66912014\n",
      "Iteration 49654, loss = 11.66598266\n",
      "Iteration 49655, loss = 11.66280788\n",
      "Iteration 49656, loss = 11.65970230\n",
      "Iteration 49657, loss = 11.65665447\n",
      "Iteration 49658, loss = 11.65357102\n",
      "Iteration 49659, loss = 11.65043086\n",
      "Iteration 49660, loss = 11.64730721\n",
      "Iteration 49661, loss = 11.64423546\n",
      "Iteration 49662, loss = 11.64116268\n",
      "Iteration 49663, loss = 11.63804897\n",
      "Iteration 49664, loss = 11.63493038\n",
      "Iteration 49665, loss = 11.63184569\n",
      "Iteration 49666, loss = 11.62877135\n",
      "Iteration 49667, loss = 11.62567237\n",
      "Iteration 49668, loss = 11.62256283\n",
      "Iteration 49669, loss = 11.61947338\n",
      "Iteration 49670, loss = 11.61639617\n",
      "Iteration 49671, loss = 11.61330518\n",
      "Iteration 49672, loss = 11.61020371\n",
      "Iteration 49673, loss = 11.60711366\n",
      "Iteration 49674, loss = 11.60403461\n",
      "Iteration 49675, loss = 11.60094833\n",
      "Iteration 49676, loss = 11.59785329\n",
      "Iteration 49677, loss = 11.59476461\n",
      "Iteration 49678, loss = 11.59168490\n",
      "Iteration 49679, loss = 11.58860170\n",
      "Iteration 49680, loss = 11.58551181\n",
      "Iteration 49681, loss = 11.58242540\n",
      "Iteration 49682, loss = 11.57934588\n",
      "Iteration 49683, loss = 11.57626500\n",
      "Iteration 49684, loss = 11.57317939\n",
      "Iteration 49685, loss = 11.57009562\n",
      "Iteration 49686, loss = 11.56701688\n",
      "Iteration 49687, loss = 11.56393801\n",
      "Iteration 49688, loss = 11.56085607\n",
      "Iteration 49689, loss = 11.55777502\n",
      "Iteration 49690, loss = 11.55469749\n",
      "Iteration 49691, loss = 11.55162053\n",
      "Iteration 49692, loss = 11.54854181\n",
      "Iteration 49693, loss = 11.54546346\n",
      "Iteration 49694, loss = 11.54238748\n",
      "Iteration 49695, loss = 11.53931243\n",
      "Iteration 49696, loss = 11.53623659\n",
      "Iteration 49697, loss = 11.53316087\n",
      "Iteration 49698, loss = 11.53008670\n",
      "Iteration 49699, loss = 11.52701361\n",
      "Iteration 49700, loss = 11.52394039\n",
      "Iteration 49701, loss = 11.52086722\n",
      "Iteration 49702, loss = 11.51779506\n",
      "Iteration 49703, loss = 11.51472397\n",
      "Iteration 49704, loss = 11.51165318\n",
      "Iteration 49705, loss = 11.50858250\n",
      "Iteration 49706, loss = 11.50551250\n",
      "Iteration 49707, loss = 11.50244346\n",
      "Iteration 49708, loss = 11.49937497\n",
      "Iteration 49709, loss = 11.49630671\n",
      "Iteration 49710, loss = 11.49323895\n",
      "Iteration 49711, loss = 11.49017202\n",
      "Iteration 49712, loss = 11.48710576\n",
      "Iteration 49713, loss = 11.48403985\n",
      "Iteration 49714, loss = 11.48097438\n",
      "Iteration 49715, loss = 11.47790961\n",
      "Iteration 49716, loss = 11.47484554\n",
      "Iteration 49717, loss = 11.47178194\n",
      "Iteration 49718, loss = 11.46871877\n",
      "Iteration 49719, loss = 11.46565621\n",
      "Iteration 49720, loss = 11.46259432\n",
      "Iteration 49721, loss = 11.45953298\n",
      "Iteration 49722, loss = 11.45647210\n",
      "Iteration 49723, loss = 11.45341178\n",
      "Iteration 49724, loss = 11.45035209\n",
      "Iteration 49725, loss = 11.44729298\n",
      "Iteration 49726, loss = 11.44423438\n",
      "Iteration 49727, loss = 11.44117631\n",
      "Iteration 49728, loss = 11.43811884\n",
      "Iteration 49729, loss = 11.43506195\n",
      "Iteration 49730, loss = 11.43200561\n",
      "Iteration 49731, loss = 11.42894980\n",
      "Iteration 49732, loss = 11.42589455\n",
      "Iteration 49733, loss = 11.42283988\n",
      "Iteration 49734, loss = 11.41978579\n",
      "Iteration 49735, loss = 11.41673223\n",
      "Iteration 49736, loss = 11.41367922\n",
      "Iteration 49737, loss = 11.41062678\n",
      "Iteration 49738, loss = 11.40757491\n",
      "Iteration 49739, loss = 11.40452360\n",
      "Iteration 49740, loss = 11.40147284\n",
      "Iteration 49741, loss = 11.39842263\n",
      "Iteration 49742, loss = 11.39537300\n",
      "Iteration 49743, loss = 11.39232392\n",
      "Iteration 49744, loss = 11.38927540\n",
      "Iteration 49745, loss = 11.38622744\n",
      "Iteration 49746, loss = 11.38318003\n",
      "Iteration 49747, loss = 11.38013319\n",
      "Iteration 49748, loss = 11.37708691\n",
      "Iteration 49749, loss = 11.37404119\n",
      "Iteration 49750, loss = 11.37099602\n",
      "Iteration 49751, loss = 11.36795141\n",
      "Iteration 49752, loss = 11.36490737\n",
      "Iteration 49753, loss = 11.36186388\n",
      "Iteration 49754, loss = 11.35882095\n",
      "Iteration 49755, loss = 11.35577858\n",
      "Iteration 49756, loss = 11.35273677\n",
      "Iteration 49757, loss = 11.34969552\n",
      "Iteration 49758, loss = 11.34665483\n",
      "Iteration 49759, loss = 11.34361469\n",
      "Iteration 49760, loss = 11.34057512\n",
      "Iteration 49761, loss = 11.33753610\n",
      "Iteration 49762, loss = 11.33449764\n",
      "Iteration 49763, loss = 11.33145974\n",
      "Iteration 49764, loss = 11.32842240\n",
      "Iteration 49765, loss = 11.32538562\n",
      "Iteration 49766, loss = 11.32234940\n",
      "Iteration 49767, loss = 11.31931374\n",
      "Iteration 49768, loss = 11.31627863\n",
      "Iteration 49769, loss = 11.31324409\n",
      "Iteration 49770, loss = 11.31021010\n",
      "Iteration 49771, loss = 11.30717667\n",
      "Iteration 49772, loss = 11.30414380\n",
      "Iteration 49773, loss = 11.30111149\n",
      "Iteration 49774, loss = 11.29807974\n",
      "Iteration 49775, loss = 11.29504854\n",
      "Iteration 49776, loss = 11.29201791\n",
      "Iteration 49777, loss = 11.28898783\n",
      "Iteration 49778, loss = 11.28595831\n",
      "Iteration 49779, loss = 11.28292935\n",
      "Iteration 49780, loss = 11.27990095\n",
      "Iteration 49781, loss = 11.27687311\n",
      "Iteration 49782, loss = 11.27384582\n",
      "Iteration 49783, loss = 11.27081910\n",
      "Iteration 49784, loss = 11.26779293\n",
      "Iteration 49785, loss = 11.26476732\n",
      "Iteration 49786, loss = 11.26174227\n",
      "Iteration 49787, loss = 11.25871778\n",
      "Iteration 49788, loss = 11.25569384\n",
      "Iteration 49789, loss = 11.25267047\n",
      "Iteration 49790, loss = 11.24964765\n",
      "Iteration 49791, loss = 11.24662539\n",
      "Iteration 49792, loss = 11.24360369\n",
      "Iteration 49793, loss = 11.24058254\n",
      "Iteration 49794, loss = 11.23756196\n",
      "Iteration 49795, loss = 11.23454193\n",
      "Iteration 49796, loss = 11.23152246\n",
      "Iteration 49797, loss = 11.22850355\n",
      "Iteration 49798, loss = 11.22548520\n",
      "Iteration 49799, loss = 11.22246741\n",
      "Iteration 49800, loss = 11.21945017\n",
      "Iteration 49801, loss = 11.21643349\n",
      "Iteration 49802, loss = 11.21341737\n",
      "Iteration 49803, loss = 11.21040181\n",
      "Iteration 49804, loss = 11.20738681\n",
      "Iteration 49805, loss = 11.20437236\n",
      "Iteration 49806, loss = 11.20135847\n",
      "Iteration 49807, loss = 11.19834514\n",
      "Iteration 49808, loss = 11.19533237\n",
      "Iteration 49809, loss = 11.19232016\n",
      "Iteration 49810, loss = 11.18930850\n",
      "Iteration 49811, loss = 11.18629740\n",
      "Iteration 49812, loss = 11.18328686\n",
      "Iteration 49813, loss = 11.18027688\n",
      "Iteration 49814, loss = 11.17726745\n",
      "Iteration 49815, loss = 11.17425858\n",
      "Iteration 49816, loss = 11.17125027\n",
      "Iteration 49817, loss = 11.16824252\n",
      "Iteration 49818, loss = 11.16523533\n",
      "Iteration 49819, loss = 11.16222869\n",
      "Iteration 49820, loss = 11.15922261\n",
      "Iteration 49821, loss = 11.15621709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49822, loss = 11.15321213\n",
      "Iteration 49823, loss = 11.15020772\n",
      "Iteration 49824, loss = 11.14720387\n",
      "Iteration 49825, loss = 11.14420058\n",
      "Iteration 49826, loss = 11.14119785\n",
      "Iteration 49827, loss = 11.13819567\n",
      "Iteration 49828, loss = 11.13519405\n",
      "Iteration 49829, loss = 11.13219299\n",
      "Iteration 49830, loss = 11.12919249\n",
      "Iteration 49831, loss = 11.12619254\n",
      "Iteration 49832, loss = 11.12319316\n",
      "Iteration 49833, loss = 11.12019432\n",
      "Iteration 49834, loss = 11.11719605\n",
      "Iteration 49835, loss = 11.11419833\n",
      "Iteration 49836, loss = 11.11120117\n",
      "Iteration 49837, loss = 11.10820457\n",
      "Iteration 49838, loss = 11.10520853\n",
      "Iteration 49839, loss = 11.10221304\n",
      "Iteration 49840, loss = 11.09921811\n",
      "Iteration 49841, loss = 11.09622374\n",
      "Iteration 49842, loss = 11.09322992\n",
      "Iteration 49843, loss = 11.09023666\n",
      "Iteration 49844, loss = 11.08724396\n",
      "Iteration 49845, loss = 11.08425182\n",
      "Iteration 49846, loss = 11.08126023\n",
      "Iteration 49847, loss = 11.07826920\n",
      "Iteration 49848, loss = 11.07527873\n",
      "Iteration 49849, loss = 11.07228881\n",
      "Iteration 49850, loss = 11.06929945\n",
      "Iteration 49851, loss = 11.06631065\n",
      "Iteration 49852, loss = 11.06332241\n",
      "Iteration 49853, loss = 11.06033472\n",
      "Iteration 49854, loss = 11.05734759\n",
      "Iteration 49855, loss = 11.05436102\n",
      "Iteration 49856, loss = 11.05137500\n",
      "Iteration 49857, loss = 11.04838954\n",
      "Iteration 49858, loss = 11.04540464\n",
      "Iteration 49859, loss = 11.04242029\n",
      "Iteration 49860, loss = 11.03943650\n",
      "Iteration 49861, loss = 11.03645327\n",
      "Iteration 49862, loss = 11.03347059\n",
      "Iteration 49863, loss = 11.03048847\n",
      "Iteration 49864, loss = 11.02750691\n",
      "Iteration 49865, loss = 11.02452590\n",
      "Iteration 49866, loss = 11.02154546\n",
      "Iteration 49867, loss = 11.01856556\n",
      "Iteration 49868, loss = 11.01558623\n",
      "Iteration 49869, loss = 11.01260745\n",
      "Iteration 49870, loss = 11.00962923\n",
      "Iteration 49871, loss = 11.00665156\n",
      "Iteration 49872, loss = 11.00367445\n",
      "Iteration 49873, loss = 11.00069790\n",
      "Iteration 49874, loss = 10.99772190\n",
      "Iteration 49875, loss = 10.99474646\n",
      "Iteration 49876, loss = 10.99177158\n",
      "Iteration 49877, loss = 10.98879725\n",
      "Iteration 49878, loss = 10.98582349\n",
      "Iteration 49879, loss = 10.98285027\n",
      "Iteration 49880, loss = 10.97987761\n",
      "Iteration 49881, loss = 10.97690551\n",
      "Iteration 49882, loss = 10.97393397\n",
      "Iteration 49883, loss = 10.97096298\n",
      "Iteration 49884, loss = 10.96799255\n",
      "Iteration 49885, loss = 10.96502267\n",
      "Iteration 49886, loss = 10.96205336\n",
      "Iteration 49887, loss = 10.95908459\n",
      "Iteration 49888, loss = 10.95611639\n",
      "Iteration 49889, loss = 10.95314874\n",
      "Iteration 49890, loss = 10.95018164\n",
      "Iteration 49891, loss = 10.94721510\n",
      "Iteration 49892, loss = 10.94424912\n",
      "Iteration 49893, loss = 10.94128370\n",
      "Iteration 49894, loss = 10.93831883\n",
      "Iteration 49895, loss = 10.93535451\n",
      "Iteration 49896, loss = 10.93239076\n",
      "Iteration 49897, loss = 10.92942756\n",
      "Iteration 49898, loss = 10.92646491\n",
      "Iteration 49899, loss = 10.92350282\n",
      "Iteration 49900, loss = 10.92054129\n",
      "Iteration 49901, loss = 10.91758031\n",
      "Iteration 49902, loss = 10.91461989\n",
      "Iteration 49903, loss = 10.91166002\n",
      "Iteration 49904, loss = 10.90870072\n",
      "Iteration 49905, loss = 10.90574196\n",
      "Iteration 49906, loss = 10.90278376\n",
      "Iteration 49907, loss = 10.89982612\n",
      "Iteration 49908, loss = 10.89686904\n",
      "Iteration 49909, loss = 10.89391251\n",
      "Iteration 49910, loss = 10.89095653\n",
      "Iteration 49911, loss = 10.88800111\n",
      "Iteration 49912, loss = 10.88504625\n",
      "Iteration 49913, loss = 10.88209194\n",
      "Iteration 49914, loss = 10.87913819\n",
      "Iteration 49915, loss = 10.87618500\n",
      "Iteration 49916, loss = 10.87323236\n",
      "Iteration 49917, loss = 10.87028027\n",
      "Iteration 49918, loss = 10.86732874\n",
      "Iteration 49919, loss = 10.86437777\n",
      "Iteration 49920, loss = 10.86142735\n",
      "Iteration 49921, loss = 10.85847749\n",
      "Iteration 49922, loss = 10.85552819\n",
      "Iteration 49923, loss = 10.85257943\n",
      "Iteration 49924, loss = 10.84963124\n",
      "Iteration 49925, loss = 10.84668360\n",
      "Iteration 49926, loss = 10.84373651\n",
      "Iteration 49927, loss = 10.84078999\n",
      "Iteration 49928, loss = 10.83784401\n",
      "Iteration 49929, loss = 10.83489859\n",
      "Iteration 49930, loss = 10.83195373\n",
      "Iteration 49931, loss = 10.82900942\n",
      "Iteration 49932, loss = 10.82606567\n",
      "Iteration 49933, loss = 10.82312247\n",
      "Iteration 49934, loss = 10.82017983\n",
      "Iteration 49935, loss = 10.81723775\n",
      "Iteration 49936, loss = 10.81429622\n",
      "Iteration 49937, loss = 10.81135524\n",
      "Iteration 49938, loss = 10.80841482\n",
      "Iteration 49939, loss = 10.80547495\n",
      "Iteration 49940, loss = 10.80253564\n",
      "Iteration 49941, loss = 10.79959689\n",
      "Iteration 49942, loss = 10.79665869\n",
      "Iteration 49943, loss = 10.79372104\n",
      "Iteration 49944, loss = 10.79078395\n",
      "Iteration 49945, loss = 10.78784742\n",
      "Iteration 49946, loss = 10.78491144\n",
      "Iteration 49947, loss = 10.78197601\n",
      "Iteration 49948, loss = 10.77904114\n",
      "Iteration 49949, loss = 10.77610683\n",
      "Iteration 49950, loss = 10.77317307\n",
      "Iteration 49951, loss = 10.77023986\n",
      "Iteration 49952, loss = 10.76730721\n",
      "Iteration 49953, loss = 10.76437512\n",
      "Iteration 49954, loss = 10.76144358\n",
      "Iteration 49955, loss = 10.75851259\n",
      "Iteration 49956, loss = 10.75558216\n",
      "Iteration 49957, loss = 10.75265229\n",
      "Iteration 49958, loss = 10.74972297\n",
      "Iteration 49959, loss = 10.74679420\n",
      "Iteration 49960, loss = 10.74386599\n",
      "Iteration 49961, loss = 10.74093833\n",
      "Iteration 49962, loss = 10.73801123\n",
      "Iteration 49963, loss = 10.73508468\n",
      "Iteration 49964, loss = 10.73215869\n",
      "Iteration 49965, loss = 10.72923325\n",
      "Iteration 49966, loss = 10.72630837\n",
      "Iteration 49967, loss = 10.72338404\n",
      "Iteration 49968, loss = 10.72046026\n",
      "Iteration 49969, loss = 10.71753704\n",
      "Iteration 49970, loss = 10.71461438\n",
      "Iteration 49971, loss = 10.71169227\n",
      "Iteration 49972, loss = 10.70877071\n",
      "Iteration 49973, loss = 10.70584971\n",
      "Iteration 49974, loss = 10.70292926\n",
      "Iteration 49975, loss = 10.70000937\n",
      "Iteration 49976, loss = 10.69709003\n",
      "Iteration 49977, loss = 10.69417125\n",
      "Iteration 49978, loss = 10.69125302\n",
      "Iteration 49979, loss = 10.68833534\n",
      "Iteration 49980, loss = 10.68541822\n",
      "Iteration 49981, loss = 10.68250165\n",
      "Iteration 49982, loss = 10.67958564\n",
      "Iteration 49983, loss = 10.67667018\n",
      "Iteration 49984, loss = 10.67375528\n",
      "Iteration 49985, loss = 10.67084093\n",
      "Iteration 49986, loss = 10.66792713\n",
      "Iteration 49987, loss = 10.66501389\n",
      "Iteration 49988, loss = 10.66210120\n",
      "Iteration 49989, loss = 10.65918907\n",
      "Iteration 49990, loss = 10.65627749\n",
      "Iteration 49991, loss = 10.65336646\n",
      "Iteration 49992, loss = 10.65045599\n",
      "Iteration 49993, loss = 10.64754607\n",
      "Iteration 49994, loss = 10.64463671\n",
      "Iteration 49995, loss = 10.64172790\n",
      "Iteration 49996, loss = 10.63881965\n",
      "Iteration 49997, loss = 10.63591195\n",
      "Iteration 49998, loss = 10.63300480\n",
      "Iteration 49999, loss = 10.63009821\n",
      "Iteration 50000, loss = 10.62719217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#http://www.machinelearningtutorial.net/2017/01/28/python-scikit-simple-function-approximation/\n",
    "\n",
    "np.random.seed(3)\n",
    "n = 20\n",
    "x = np.random.uniform(-15, 15, size = n)\n",
    "y = x**2 + 2*np.random.randn(n, )\n",
    "X = np.reshape(x ,[n, 1]) \n",
    "y = np.reshape(y ,[n ,])\n",
    "\n",
    "clf = MLPRegressor(alpha=0.001, hidden_layer_sizes = (10,), max_iter = 50000, \n",
    "                 activation = 'logistic', verbose = 'True', learning_rate = 'adaptive')\n",
    "\n",
    "\"\"\"\n",
    "clf = MLPRegressor(alpha=0.1, hidden_layer_sizes = (10,), max_iter = 50000, \n",
    "                 activation = 'logistic', verbose = 'True', learning_rate = 'adaptive')\n",
    "\"\"\"\n",
    "a = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa9cf98e780>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ = np.linspace(-15, 15, 160) # define axis\n",
    "\n",
    "pred_x = np.reshape(x_, [160, 1]) # [160, ] -> [160, 1]\n",
    "pred_y = clf.predict(pred_x) # predict network output given x_\n",
    "fig = plt.figure() \n",
    "plt.plot(x_, x_**2, color = 'b') # plot original function\n",
    "plt.scatter(x, y, color = 'r') # plot training data\n",
    "plt.plot(pred_x, pred_y, 'g') # plot network output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above code, play on the hyperparameters, number of samples, and increase noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

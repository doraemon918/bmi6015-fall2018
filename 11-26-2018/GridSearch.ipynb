{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for Deep Learning\n",
    "\n",
    "[link](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KerasClassifier in module keras.wrappers.scikit_learn:\n",
      "\n",
      "class KerasClassifier(BaseWrapper)\n",
      " |  Implementation of the scikit-learn classifier API for Keras.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KerasClassifier\n",
      " |      BaseWrapper\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  fit(self, x, y, sample_weight=None, **kwargs)\n",
      " |      Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x : array-like, shape `(n_samples, n_features)`\n",
      " |              Training samples where `n_samples` is the number of samples\n",
      " |              and `n_features` is the number of features.\n",
      " |          y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
      " |              True labels for `x`.\n",
      " |          **kwargs: dictionary arguments\n",
      " |              Legal arguments are the arguments of `Sequential.fit`\n",
      " |      \n",
      " |      # Returns\n",
      " |          history : object\n",
      " |              details about the training history at each epoch.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid shape for `y` argument.\n",
      " |  \n",
      " |  predict(self, x, **kwargs)\n",
      " |      Returns the class predictions for the given test data.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: array-like, shape `(n_samples, n_features)`\n",
      " |              Test samples where `n_samples` is the number of samples\n",
      " |              and `n_features` is the number of features.\n",
      " |          **kwargs: dictionary arguments\n",
      " |              Legal arguments are the arguments\n",
      " |              of `Sequential.predict_classes`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          preds: array-like, shape `(n_samples,)`\n",
      " |              Class predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, **kwargs)\n",
      " |      Returns class probability estimates for the given test data.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: array-like, shape `(n_samples, n_features)`\n",
      " |              Test samples where `n_samples` is the number of samples\n",
      " |              and `n_features` is the number of features.\n",
      " |          **kwargs: dictionary arguments\n",
      " |              Legal arguments are the arguments\n",
      " |              of `Sequential.predict_classes`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          proba: array-like, shape `(n_samples, n_outputs)`\n",
      " |              Class probability estimates.\n",
      " |              In the case of binary classification,\n",
      " |              to match the scikit-learn API,\n",
      " |              will return an array of shape `(n_samples, 2)`\n",
      " |              (instead of `(n_sample, 1)` as in Keras).\n",
      " |  \n",
      " |  score(self, x, y, **kwargs)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: array-like, shape `(n_samples, n_features)`\n",
      " |              Test samples where `n_samples` is the number of samples\n",
      " |              and `n_features` is the number of features.\n",
      " |          y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
      " |              True labels for `x`.\n",
      " |          **kwargs: dictionary arguments\n",
      " |              Legal arguments are the arguments of `Sequential.evaluate`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          score: float\n",
      " |              Mean accuracy of predictions on `x` wrt. `y`.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the underlying model isn't configured to\n",
      " |              compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n",
      " |              the `.compile()` method of the model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseWrapper:\n",
      " |  \n",
      " |  __init__(self, build_fn=None, **sk_params)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  check_params(self, params)\n",
      " |      Checks for user typos in `params`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          params: dictionary; the parameters to be checked\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: if any member of `params` is not a valid argument.\n",
      " |  \n",
      " |  filter_sk_params(self, fn, override=None)\n",
      " |      Filters `sk_params` and returns those in `fn`'s arguments.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          fn : arbitrary function\n",
      " |          override: dictionary, values to override `sk_params`\n",
      " |      \n",
      " |      # Returns\n",
      " |          res : dictionary containing variables\n",
      " |              in both `sk_params` and `fn`'s arguments.\n",
      " |  \n",
      " |  get_params(self, **params)\n",
      " |      Gets parameters for this estimator.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **params: ignored (exists for API compatibility).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Dictionary of parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Sets the parameters of this estimator.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **params: Dictionary of parameter names mapped to their values.\n",
      " |      \n",
      " |      # Returns\n",
      " |          self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseWrapper:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help (KerasClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7056732758869477\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy, pandas as pd\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = pd.read_csv(\"prims.csv\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset.iloc[:,:8]\n",
    "Y = dataset.iloc[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.763021 using {'batch_size': 20, 'epochs': 1000}\n",
      "0.585938 (0.030425) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.699219 (0.000000) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.705729 (0.030314) with: {'batch_size': 10, 'epochs': 70}\n",
      "0.727865 (0.009744) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.734375 (0.003189) with: {'batch_size': 10, 'epochs': 500}\n",
      "0.740885 (0.015073) with: {'batch_size': 10, 'epochs': 1000}\n",
      "0.605469 (0.016877) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.682292 (0.009207) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.699219 (0.027805) with: {'batch_size': 20, 'epochs': 70}\n",
      "0.718750 (0.014616) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.746094 (0.008438) with: {'batch_size': 20, 'epochs': 500}\n",
      "0.763021 (0.027126) with: {'batch_size': 20, 'epochs': 1000}\n",
      "0.638021 (0.019225) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.441406 (0.154811) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.348958 (0.024774) with: {'batch_size': 40, 'epochs': 70}\n",
      "0.348958 (0.024774) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.464844 (0.159249) with: {'batch_size': 40, 'epochs': 500}\n",
      "0.632812 (0.179092) with: {'batch_size': 40, 'epochs': 1000}\n",
      "0.584635 (0.037377) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.623698 (0.025976) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.548177 (0.147865) with: {'batch_size': 60, 'epochs': 70}\n",
      "0.687500 (0.011500) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.729167 (0.025976) with: {'batch_size': 60, 'epochs': 500}\n",
      "0.743490 (0.017566) with: {'batch_size': 60, 'epochs': 1000}\n",
      "0.554688 (0.062255) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.679687 (0.003189) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.673177 (0.018414) with: {'batch_size': 80, 'epochs': 70}\n",
      "0.657552 (0.016367) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.718750 (0.008438) with: {'batch_size': 80, 'epochs': 500}\n",
      "0.734375 (0.030425) with: {'batch_size': 80, 'epochs': 1000}\n",
      "0.613281 (0.011500) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.630208 (0.033197) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.657552 (0.016053) with: {'batch_size': 100, 'epochs': 70}\n",
      "0.638021 (0.023939) with: {'batch_size': 100, 'epochs': 100}\n",
      "0.544271 (0.146518) with: {'batch_size': 100, 'epochs': 500}\n",
      "0.611979 (0.162328) with: {'batch_size': 100, 'epochs': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy, pandas as pd\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "dataset = pd.read_csv(\"prims.csv\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset.iloc[:,:8]\n",
    "Y = dataset.iloc[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 70, 100,500,1000]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.690104 using {'learn_rate': 0.001, 'momentum': 0.6}\n",
      "0.657552 (0.037783) with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
      "0.666667 (0.031948) with: {'learn_rate': 0.001, 'momentum': 0.2}\n",
      "0.679688 (0.017758) with: {'learn_rate': 0.001, 'momentum': 0.4}\n",
      "0.690104 (0.016367) with: {'learn_rate': 0.001, 'momentum': 0.6}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.001, 'momentum': 0.8}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.001, 'momentum': 0.9}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
      "0.649740 (0.023510) with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.8}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.9}\n",
      "0.533854 (0.149269) with: {'learn_rate': 0.1, 'momentum': 0.0}\n",
      "0.544271 (0.146518) with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.1, 'momentum': 0.4}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.1, 'momentum': 0.6}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.1, 'momentum': 0.8}\n",
      "0.468750 (0.152927) with: {'learn_rate': 0.1, 'momentum': 0.9}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.2, 'momentum': 0.0}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.2, 'momentum': 0.4}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.2, 'momentum': 0.6}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.2, 'momentum': 0.8}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.2, 'momentum': 0.9}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.3, 'momentum': 0.0}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.3, 'momentum': 0.2}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.3, 'momentum': 0.4}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.3, 'momentum': 0.6}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.3, 'momentum': 0.8}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.3, 'momentum': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the learning rate and momentum\n",
    "import numpy, pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = pd.read_csv(\"prims.csv\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset.iloc[:,:8]\n",
    "Y = dataset.iloc[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
